<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CONTRASTIVE LEARNING WITH HARD NEGATIVE SAMPLES</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-01-24">24 Jan 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Joshua</forename><surname>Robinson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Massachusetts Institute of Technology Cambridge</orgName>
								<address>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ching-Yao</forename><surname>Chuang</surname></persName>
							<email>cychuang@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Massachusetts Institute of Technology Cambridge</orgName>
								<address>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Suvrit</forename><surname>Sra</surname></persName>
							<email>suvrit@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Massachusetts Institute of Technology Cambridge</orgName>
								<address>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Massachusetts Institute of Technology Cambridge</orgName>
								<address>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CONTRASTIVE LEARNING WITH HARD NEGATIVE SAMPLES</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-01-24">24 Jan 2021</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2010.04592v2[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T14:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>How can you sample good negative examples for contrastive learning? We argue that, as with metric learning, contrastive learning of representations benefits from hard negative samples (i.e., points that are difficult to distinguish from an anchor point). The key challenge toward using hard negatives is that contrastive methods must remain unsupervised, making it infeasible to adopt existing negative sampling strategies that use true similarity information. In response, we develop a new family of unsupervised sampling methods for selecting hard negative samples where the user can control the hardness. A limiting case of this sampling results in a representation that tightly clusters each class, and pushes different classes as far apart as possible. The proposed method improves downstream performance across multiple modalities, requires only few additional lines of code to implement, and introduces no computational overhead.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Owing to their empirical success, contrastive learning methods <ref type="bibr" target="#b7">(Chopra et al., 2005;</ref><ref type="bibr" target="#b15">Hadsell et al., 2006)</ref> have become one of the most popular self-supervised approaches for learning representations <ref type="bibr" target="#b34">(Oord et al., 2018;</ref><ref type="bibr" target="#b47">Tian et al., 2019;</ref><ref type="bibr" target="#b4">Chen et al., 2020a)</ref>. In computer vision, unsupervised contrastive learning methods have even outperformed supervised pre-training for object detection and segmentation tasks <ref type="bibr" target="#b30">(Misra &amp; Maaten, 2020;</ref><ref type="bibr" target="#b19">He et al., 2020)</ref>.</p><p>Contrastive learning relies on two key ingredients: notions of similar (positive) (x, x + ) and dissimilar (negative) (x, x − ) pairs of data points. The training objective, typically noise-contrastive estimation <ref type="bibr" target="#b14">(Gutmann &amp; Hyvärinen, 2010)</ref>, guides the learned representation f to map positive pairs to nearby locations, and negative pairs farther apart; other objectives have also been considered <ref type="bibr" target="#b4">(Chen et al., 2020a)</ref>. The success of the associated methods depends on the design of informative of the positive and negative pairs, which cannot exploit true similarity information since there is no supervision.</p><p>Much research effort has addressed sampling strategies for positive pairs, and has been a key driver of recent progress in multi-view and contrastive learning <ref type="bibr" target="#b2">(Blum &amp; Mitchell, 1998;</ref><ref type="bibr" target="#b54">Xu et al., 2013;</ref><ref type="bibr" target="#b1">Bachman et al., 2019;</ref><ref type="bibr" target="#b4">Chen et al., 2020a;</ref><ref type="bibr" target="#b48">Tian et al., 2020)</ref>. For image data, positive sampling strategies often apply transformations that preserve semantic content, e.g., jittering, random cropping, separating color channels, etc. <ref type="bibr" target="#b4">(Chen et al., 2020a;</ref><ref type="bibr" target="#b12">c;</ref><ref type="bibr" target="#b47">Tian et al., 2019)</ref>. Such transformations have also been effective in learning control policies from raw pixel data <ref type="bibr" target="#b42">(Srinivas et al., 2020)</ref>. Positive sampling techniques have also been proposed for sentence, audio, and video data <ref type="bibr" target="#b28">(Logeswaran &amp; Lee, 2018;</ref><ref type="bibr" target="#b34">Oord et al., 2018;</ref><ref type="bibr" target="#b37">Purushwalkam &amp; Gupta, 2020;</ref><ref type="bibr" target="#b40">Sermanet et al., 2018)</ref>.</p><p>Surprisingly, the choice of negative pairs has drawn much less attention in contrastive learning. Often, given an "anchor" point x, a "negative" x − is simply sampled uniformly from the training data, independent of how informative it may be for the learned representation. In supervised and metric learning settings, "hard" (true negative) examples can help guide a learning method to correct its mistakes more quickly <ref type="bibr" target="#b38">(Schroff et al., 2015;</ref><ref type="bibr" target="#b41">Song et al., 2016)</ref>. For representation learning, informative negative examples are intuitively those pairs that are mapped nearby but should be far apart. This idea is successfully applied in metric learning, where true pairs of dissimilar points are available, as opposed to unsupervised contrastive learning. the distribution over latent classes by ρ(c) for c ∈ C, we define the joint distribution p x,c (x, c) = p(x|c)ρ(c) whose marginal p(x) we refer to simply as p, and assume supp(p) = X . For simplicity, we assume ρ(c) = τ + is uniform, and let τ − = 1 − τ + be the probability of another class. Since the class-prior τ + is unknown in practice, it must either be treated as a hyperparameter, or estimated <ref type="bibr" target="#b8">(Christoffel et al., 2016;</ref><ref type="bibr">Jain et al., 2016)</ref>.</p><p>Let h : X → C be the true underlying hypothesis that assigns class labels to inputs. We write x ∼ x to denote the label equivalence relation h(x) = h(x ). We denote by p +</p><p>x (x ) = p(x |h(x ) = h(x)), the distribution over points with same label as x, and by p −</p><p>x (x ) = p(x |h(x ) = h(x)), the distribution over points with labels different from x. We drop the subscript x when the context is clear. Following the usual convention, we overload '∼' and also write x ∼ p to denote a point sampled from p.</p><p>For each data point x ∼ p, the noise-contrastive estimation (NCE) objective <ref type="bibr" target="#b14">(Gutmann &amp; Hyvärinen, 2010)</ref> for learning the representation f uses a positive example x + with the same label as x, and negative examples {x − i } N i=1 with (supposedly) different labels, h(x − i ) = h(x), sampled from q:</p><formula xml:id="formula_0">E x∼p, x + ∼p + x {x − i } N i=1 ∼q − log e f (x) T f (x + ) e f (x) T f (x + ) + Q N N i=1 e f (x) T f (x − i )</formula><p>.</p><p>(1)</p><p>The weighting parameter Q is introduced for the purpose of analysis. When N is finite we take Q = N , yielding the usual form of the contrastive objective. The negative sample distribution q is frequently chosen to be the marginal distribution p, or, in practice, an empirical approximation of it <ref type="bibr" target="#b47">(Tian et al., 2019;</ref><ref type="bibr" target="#b4">Chen et al., 2020a;</ref><ref type="bibr" target="#b12">c;</ref><ref type="bibr" target="#b19">He et al., 2020;</ref><ref type="bibr" target="#b6">Chen et al., 2020c;</ref><ref type="bibr" target="#b34">Oord et al., 2018;</ref><ref type="bibr" target="#b20">Hénaff et al., 2020)</ref>. In this paper we ask: is there a better way to choose q?</p><p>3 HARD NEGATIVE SAMPLING</p><p>In this section we describe our approach for hard negative sampling. We begin by asking what makes a good negative sample? To answer this question we adopt the following two guiding principles:</p><p>Principle 1. q should only sample "true negatives" x − i whose labels differ from that of the anchor x. Principle 2. The most useful negative samples are ones that the embedding currently believes to be similar to the anchor.</p><p>In short, negative samples that have different label from the anchor, but that are embedded nearby are likely to be most useful and provide significant gradient information during training. In metric learning there is access to true negative pairs, automatically fulfilling the first principle.</p><p>In unsupervised contrastive learning there is no supervision, so upholding Principle 1 is impossible to do exactly. In this paper we propose a method that upholds Principle 1 approximately, and simultaneously combines this idea with the key additional conceptual ingredient of "hardness" (encapsulated in Principle 2). The level of "hardness" in our method can be smoothly adjusted, allowing the user to select the hardness that best trades-off between an improved learning signal from hard negatives, and the harm due to the correction of false negatives being only approximate. This important since the hardest points are those closest to the anchor, and are expected to have a high propensity to have the same label. Therefore the damage from the approximation not removing all false negatives becomes larger for harder samples, creating the trade-off. As a special case our our method, when the hardness level is tuned fully down, we obtain the method proposed in <ref type="bibr" target="#b9">(Chuang et al., 2020)</ref> that only upholds Principle 1 (approximately) but not Principle 2. Finally, beyond Principles 1 and 2, we wish to design an efficient sampling method that does not add additional computational overhead during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">PROPOSED HARD SAMPLING METHOD</head><p>Our first goal is to design a distribution q on X that is allowed to depend on the embedding f and the anchor x. From q we sample a batch of negatives {x − i } N i=1 according to the principles noted above. We propose sampling negatives from the distribution q − β defined as</p><formula xml:id="formula_1">q − β (x − ) := q β (x − |h(x) = h(x − )), where q β (x − ) ∝ e βf (x) f (x − ) • p(x − ),</formula><p>for β ≥ 0. Note that q − β and q β both depend on x, but we suppress the dependance from the notation. The exponential term in q β is an unnormalized von Mises-Fisher distribution with mean direction f (x) and "concentration parameter" β <ref type="bibr" target="#b29">(Mardia &amp; Jupp, 2000)</ref>. There are two key components to q − β , corresponding to each principle: 1) conditioning on the event {h(x) = h(x − )} which guarantees that (x, x − ) correspond to different latent classes (Principle 1); 2) the concentration parameter β term controls the degree by which q β up-weights points x − that have large inner product (similarity) to the anchor x (Principle 2). Since f lies on the surface of a hypersphere of radius 1/t, we have</p><formula xml:id="formula_2">f (x) − f (x ) 2 = 2/t 2 − 2f (x) f (x )</formula><p>so preferring points with large inner product is equivalent to preferring points with small squared Euclidean distance.</p><p>Although we have designed q − β to have all of the desired components, it is not clear how to sample efficiently from it. To work towards a practical method, note that we can rewrite this distribution by adopting a PU-learning viewpoint <ref type="bibr">(Elkan &amp; Noto, 2008;</ref><ref type="bibr" target="#b12">Du Plessis et al., 2014;</ref><ref type="bibr" target="#b9">Chuang et al., 2020)</ref>. That is, by conditioning on the event {h(x) = h(x − )} we can split q β (x − ) as</p><formula xml:id="formula_3">q β (x − ) = τ − q − β (x − ) + τ + q + β (x − ),<label>(2)</label></formula><p>where q</p><formula xml:id="formula_4">+ β (x − ) = q β (x − |h(x) = h(x − )) ∝ e βf (x) f (x − ) • p + (x − ). Rearranging equation 2 yields a formula q − β (x − ) = q β (x − ) − τ + q + β (x −</formula><p>) /τ − for the negative sampling distribution q − β in terms of two distributions that are tractable since we have samples from p and can approximate samples from p + using a set of semantics-preserving transformations, as is typical in contrastive learning methods.</p><p>It is possible to generate samples from q β and (approximately from) q + β using rejection sampling. However, rejection sampling involves an algorithmic complication since the procedure for sampling batches must be modified. To avoid this, we instead take an importance sampling approach. To obtain this, first note that fixing the number Q and taking the limit N → ∞ in the objective (1) yields,</p><formula xml:id="formula_5">L(f, q) = E x∼p x + ∼p + x − log e f (x) T f (x + ) e f (x) T f (x + ) + QE x − ∼q [e f (x) T f (x − ) ] .<label>(3)</label></formula><p>The original objective (1) can be viewed as a finite negative sample approximation to L(f, q) (note implicitly L(f, q) depends on Q) . Inserting q = q − β and using the rearrangement of equation ( <ref type="formula" target="#formula_3">2</ref>) we obtain the following hardness-biased objective:</p><formula xml:id="formula_6">E x∼p x + ∼p + x   − log e f (x) T f (x + ) e f (x) T f (x + ) + Q τ − (E x − ∼q β [e f (x) T f (x − ) ] − τ + E v∼q + β [e f (x) T f (v) ])   .<label>(4)</label></formula><p>This objective suggests that we need only to approximate expectations E x − ∼q β [e f (x) T f (x − ) ] and v) ] over q β and q + β (rather than explicily sampling). This can be achieved using classical Monte-Carlo importance sampling techniques using samples from p and p + as follows:</p><formula xml:id="formula_7">E v∼q + β [e f (x) T f (</formula><formula xml:id="formula_8">E x − ∼q β [e f (x) T f (x − ) ] = E x − ∼p [e f (x) T f (x − ) q β /p] = E x − ∼p [e (β+1)f (x) T f (x − ) /Z β ], E v∼q + β [e f (x) T f (v) ] = E v∼p + [e f (x) T f (v) q + β /p + ] = E v∼p + [e (β+1)f (x) T f (v) /Z + β ],</formula><p>where Z β , Z + β are the partition functions of q β and q + β respectively. The right hand terms readily admit empirical approximations by replacing p and p + with p </p><formula xml:id="formula_9">(x) = 1 N N i=1 δ x − i (x) and p+ (x) = 1 M M i=1 δ x + i (x)</formula><formula xml:id="formula_10">β = E x − ∼p [e βf (x) T f (x − ) ] and Z + β = E x + ∼p + [e βf (x) T f (x + )</formula><p>] which themselves are expectations over p and p + and therefore admit empirical estimates,</p><formula xml:id="formula_11">Z β = 1 N N i=1 e βf (x) f (x − i ) , Z + β = 1 M M i=1 e βf (x) f (x + i ) .</formula><p>It is important to emphasize the simplicity of the implementation of our proposed approach. Since we propose to reweight the objective instead of modifying the sampling procedure, only two extra lines of code are needed to implement our approach, with no additional computational overhead. PyTorch-style pseudocode for the objective is given in Fig. <ref type="figure" target="#fig_0">13</ref> in Appendix D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">ANALYSIS OF HARD NEGATIVE SAMPLING</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">HARD SAMPLING INTERPOLATES BETWEEN MARGINAL AND WORST-CASE NEGATIVES</head><p>Intuitively, the concentration parameter β in our proposed negative sample distribution q − β controls the level of "hardness" of the negative samples. As discussed earlier, the debiasing method of <ref type="bibr" target="#b9">Chuang et al. (2020)</ref> can be recovered as a special case: taking β = 0 to obtain the distribution q − 0 . This case amounts to correcting for the fact that some samples in a negative batch sampled from p will have the same label as the anchor. But what interpretation does large β admit? Specifically, what does the distribution q − β converge to in the limit β → ∞, if anything? We show that in the limit q − β approximates an inner solution to the following zero-sum two player game.</p><formula xml:id="formula_12">inf f sup q∈Π L(f, q) = E x∼p x + ∼p + x − log e f (x) T f (x + ) e f (x) T f (x + ) + QE x − ∼q [e f (x) T f (x − ) ] . (<label>5</label></formula><formula xml:id="formula_13">)</formula><p>where Π = {q = q(•; x, f ) : supp q(•; x, f ) ⊆ {x ∈ X : x x}, ∀x ∈ X } is the set of distributions with support that is disjoint from points with the same class as x (without loss of generality we assume {x ∈ X : x x} is non-empty). Since q = q(•; x, f ) depends on x and f it can be thought of as a family of distributions. The formal statement is as follows. Proposition 3. Let L * (f ) = sup q∈Π L(f, q). Then for any t &gt; 0 and f : X → S d−1 /t we observe the convergence L(f,</p><formula xml:id="formula_14">q − β ) −→ L * (f ) as β → ∞. Proof. See Appendix A.1.</formula><p>To develop a better intuitive understanding of the worst case negative distribution objective L * (f ) = sup q∈Π L(f, q), we note that the supremum can be characterized analytically. Indeed,</p><formula xml:id="formula_15">sup q∈Π L(f, q) = −E x∼p x + ∼p + x f (x) T f (x + ) + sup q∈Π E x∼p x + ∼p + x log e f (x) T f (x + ) + QE x − ∼q [e f (x) T f (x − ) ] = −E x∼p x + ∼p + x f (x) T f (x + ) + E x∼p x + ∼p + x log e f (x) T f (x + ) + Q • sup q∈Π E x − ∼q [e f (x) T f (x − ) ] .</formula><p>The supremum over q can be pushed inside the expectation since q is a family of distribution indexed by x, reducing the problem to maximizing E x − ∼q [e f (x) T f (x − ) ], which is solved by any q * whose support is a subset of arg sup x − :x − x e f (x) T f (x − ) if the supremum is attained. However, computing such points involves maximizing a neural network. Instead of taking this challenging route, using q − β defines a lower bound by placing higher probability on x − for which f (x) T f (x − ) is large. This lower bound becomes tight as β → ∞ (Proposition 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">OPTIMAL EMBEDDINGS ON THE HYPERSPHERE FOR WORST-CASE NEGATIVE SAMPLES</head><p>What desirable properties does an optimal contrastive embedding (global minimizer of L) possess that make the representation generalizable? To study this question, we first analyze the distribution of an optimal embedding f * on the hypersphere when negatives are sampled from the adversarial worst-case distribution. We consider a different limiting viewpoint of objective (1) as the number of negative samples N → ∞. Following the formulation of <ref type="bibr">Wang &amp; Isola (2020)</ref> we take Q = N in (1), and subtract log N . This changes neither the set of minimizers, nor the geometry of the loss surface. Taking the number of negative samples N → ∞ yields the limiting objective,</p><formula xml:id="formula_16">L ∞ (f, q) = E x∼p x + ∼p + x − log e f (x) T f (x + ) E x − ∼q [e f (x) T f (x − ) ] . (<label>6</label></formula><formula xml:id="formula_17">)</formula><p>Theorem 4. Suppose the downstream task is classification (i.e. C is finite), and let</p><formula xml:id="formula_18">L * ∞ (f ) = sup q∈Π L ∞ (f, q) . The infimum inf f : measurable L * ∞ (f )</formula><p>is attained, and any f * achieving the global minimum is such that f * (x) = f * (x + ) almost surely. Furthermore, letting v c = f * (x) for any x such that h(x) = c (so v c is well defined up to a set of x of measure zero), f * is characterized as being any solution to the following ball-packing problem,</p><formula xml:id="formula_19">max {vc∈S d−1 /t} c∈C c∈C ρ(c) • min c =c v c − v c 2 . (<label>7</label></formula><formula xml:id="formula_20">)</formula><p>Proof. See Appendix A.2. Interpretation: The first component of the result is that f * (x) = f * (x + ) almost surely for an optimal f * . That is, an optimal embedding f * must be invariant across pairs of similar inputs x, x + . The second component is characterizing solutions via the classical geometrical Ball-Packing Problem of Tammes (1930) (Eq. 7) that has only been solved exactly for uniform ρ, for specific of|C| and typically for S<ref type="foot" target="#foot_2">2</ref>  <ref type="bibr" target="#b39">(Schütte &amp; Van der Waerden, 1951;</ref><ref type="bibr" target="#b32">Musin &amp; Tarasov, 2015;</ref><ref type="bibr" target="#b46">Tammes, 1930)</ref>. When the distribution ρ over classes is uniform this problem is solved by a set of|C| points on the hypersphere such that the average squared-2 distance from a point to the nearest other point is as large as possible. In other words, suppose we wish to place |C| number of balls<ref type="foot" target="#foot_1">1</ref> on S d−1 so that they do not intersect. Then solutions to Tammes' Problem ( <ref type="formula" target="#formula_19">7</ref>) expresses (twice) the largest possible average squared radius that the balls can have. So, we have a ball-packing problem where instead of trying to pack as many balls as possible of a fixed size, we aim to pack a fixed number of balls (one for each class) to have as big radii as possible. Non-uniform ρ adds importance weights to each fixed ball. In summary, solutions of the problem min f L * ∞ (f ) are a maximum margin clustering. This understanding of global minimizers of L * ∞ (f ) = sup q∈Π L ∞ (f, q) can further developed into a better understanding of generalization on downstream tasks. The next result shows that representations that achieve small excess risk on the objective L * ∞ still separate clusters well in the sense that a simple 1-nearest neighbor classifier achieves low classification error. Theorem 5. Suppose ρ is uniform on</p><formula xml:id="formula_21">C and f is such that L * ∞ (f ) − inf f measurable L * ∞ ( f ) ≤ ε with ε ≤ 1. Let {v * c ∈ S d−1 /t} c∈C be a solution to Problem 7, and define the constant ξ = min c,c − :c =c − v * c − v * c− &gt; 0.</formula><p>Then there exists a set of vectors {v c ∈ S d−1 /t} c∈C such that the 1-nearest neighbor classifier ĥ(x) = arg min c∈C f (x) − v c (ties broken arbitrarily) achieves misclassification risk,</p><formula xml:id="formula_22">P x,c ( ĥ(x) = c) ≤ 8ε (ξ 2 − 2|C| (1 + 1/t)ε 1/2 ) 2 Proof. See Appendix A.3.</formula><p>In particular, P( ĥ(x) = c) = O(ε) as ε → 0, and in the limit ε → 0 we recover the invariance claim of Theorem 4 as a special case. The result can be generalized to arbitrary ρ by replacing|C| in the bound by 1/ min c ρ(c). The result also implies that it is possible to build simple classifiers for tasks that involve only a subset of classes from C, or classes that are a union of classes from C. The constant</p><formula xml:id="formula_23">ξ = min c,c − :c =c − v * c − v * c−</formula><p>&gt; 0 is a purely geometrical property of spheres, and describes the minimum separation distance between a set of points that solves the Tammes' ball-packing problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EMPIRICAL RESULTS</head><p>Next, we evaluate our hard negative sampling method empirically, and apply it as a modification to state-of-the-art contrastive methods on image, graph, and text data. For all experiments β is treated as a hyper-parameter (see ablations in Fig. <ref type="figure">2</ref> for more understanding of how to pick β). Values for M and τ + must also be determined. We fix M = 1 for all experiments, since taking M &gt; 1 would increase the number of inputs for the forward-backward pass. Lemma 11 in the appendix gives a theoretical justification for the choice of M = 1. Choosing the class-prior τ + can be done in two ways: estimating it from data <ref type="bibr" target="#b8">(Christoffel et al., 2016;</ref><ref type="bibr">Jain et al., 2016)</ref>, or treating it as a hyper-parameter. The first option requires the possession of labeled data before contrastive training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">IMAGE REPRESENTATIONS</head><p>We begin by testing the hard sampling method on vision tasks using the STL10, CIFAR100 and CIFAR10 data. We use SimCLR <ref type="bibr" target="#b4">(Chen et al., 2020a)</ref> as the baseline method, and all models are trained for 400 epochs. The results in Fig. <ref type="figure">2</ref> show consistent improvement over SimCLR (q = p) and the particular case of our method with β = 0 proposed in <ref type="bibr" target="#b9">(Chuang et al., 2020</ref>) (called debiasing) on STL10 and CIFAR100. For N = 510 negative examples per data point we observe absolute improvements of 3% and 7.3% over SimCLR on CIFAR100 and STL10 respectively, and absolute improvements over the best debiased baseline of 1.9% and 3.2%. On tinyImageNet (Tab. 1) we observe an absolute improvement of 3.6% over SimCLR, while on CIFAR10 there is a slight improvement for smaller N , which disappears at larger N . See Appendix C.1 results using MoCo-v2 for large negative batch size, and Appendix D.1 for full setup details. Figure 2: Classification accuracy on downstream tasks. Embeddings trained using hard, debiased, and standard (β = 0, τ + = 0) versions of SimCLR, and evaluated using linear readout accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">GRAPH REPRESENTATIONS</head><p>SimCLR Debiased Hard (β = 1)</p><p>53.4% 53.7% 57.0%</p><p>Table <ref type="table">1</ref>: Top-1 linear readout on tinyIm-ageNet. Class prior is set to τ + = 0.01.</p><p>Second, we consider hard negative sampling in the context of learning graph representations. We use the state-of-theart InfoGraph method introduced by Sun et al. (2020) as the baseline, which is suitable for downstream graph-level classification. The objective is of a slightly different form from the NCE loss. Because of this we use a generalization of the formulation presented in Section 3 (See Appendix B for details). In doing so, we illustrate that it is easy to adapt our hard sampling method to other contrastive frameworks.</p><p>Fig. <ref type="figure">3</ref> shows the results of fine-tuning an SVM <ref type="bibr" target="#b3">(Boser et al., 1992;</ref><ref type="bibr" target="#b10">Cortes &amp; Vapnik, 1995)</ref> on the fixed, learned embedding for a range of different values of β. Hard sampling does as well as InfoGraph in all cases, and better in 6 out of 8 cases. For ENZYMES and REDDIT, hard negative samples improve the accuracy by 3.2% and 2.4%, respectively, for DD and PTC by 1 − 2%, and for IMDB-B and MUTAG by at least 0.5%. Usually, multiple different choices of β &gt; 0 were competitive with the InfoGraph baseline: 17 out of the 24 values of β &gt; 0 tried (across all 8 datasets) achieve accuracy as high or better than InfoGraph (β = 0).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">SENTENCE REPRESENTATIONS</head><p>Third, we test hard negative sampling on learning representations of sentences using the quickthoughts (QT) vectors framework introduced by Logeswaran &amp; Lee (2018), which uses adjacent sentences (before/after) as positive samples. Embeddings are trained using the unlabeled BookCorpus dataset <ref type="bibr" target="#b26">(Kiros et al., 2015)</ref>, and evaluated following the protocol of <ref type="bibr" target="#b28">Logeswaran &amp; Lee (2018)</ref> on six downstream tasks. The results are reported in  <ref type="bibr">Fig. 4 (left,</ref><ref type="bibr">middle)</ref> shows that for vision problems, taking larger β does not necessarily lead to better representations. In contrast, when one uses true positive pairs during training (green curve, uses label information for positive but not negative pairs), the downstream performance monotonically increases with β until convergence (Fig. <ref type="figure">4</ref> , middle). Interestingly, this is achieved without using label information for the negative pairs. This observation suggests an explanation for why bigger β hurts performance in practice. Debiasing (conditioning on the event {h(x) = h(x − )}) using the true p + corrects for sampling x − with the same label as x. However, since in practice we approximate p + using a set of data transformations, we can only partially correct. This is harmful for large β since this regime strongly prefers x − for which f (x − ) is close to f (x), many of whom will have the same label as x if not corrected for. We note also that by annealing β (gradually decreasing β to 0 throughout training; see Appendix D.1 for details) it is possible to be more robust to the choice of initial β, with marginal impact on downstream accuracy compared to the best fixed value of β.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">DOES AVOIDING FALSE NEGATIVES IMPROVE HARD SAMPLING?</head><p>Our proposed hard negative sampling method conditions on the event {h(x) = h(x − )} in order to avoid false negatives (termed "debiasing" <ref type="bibr" target="#b9">(Chuang et al., 2020)</ref>). But does this help? To test this, we train four embeddings: hard sampling with and without debiasing, and uniform sampling (β = 0) with and without debiasing. The results in Fig. <ref type="figure">4</ref> (right) show that hard sampling with debiasing obtains the highest linear readout accuracy on STL10, only using hard sampling or only debiasing yields (in this case) similar accuracy. All improve over the SimCLR baseline. Fig. <ref type="figure">5</ref> compares the histograms of cosine similarities of positive and negative pairs for the four learned representations. The representation trained with hard negatives and debiasing assigns much lower similarity score to a pair of negative samples than other methods. On the other hand, the SimCLR baseline assigns higher cosine similarity scores to pairs of positive samples. However, to discriminate positive and negative pairs, a key property is the amount of overlap of positive and negative histograms. Our hard sampling method achieves less overlap than SimCLR, by better trading off higher dissimilarity of negative pairs with less similarity of positive pairs. Similar tradeoffs are observed for the debiased objective, and hard sampling without debiasing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">HOW DO HARD NEGATIVES AFFECT OPTIMIZATION?</head><p>Fig. <ref type="figure" target="#fig_0">11</ref> (in Appendix C due to space constraints) shows the performance on STL10 and CIFAR100 of SimCLR versus using hard negatives throughout training. We use weighted k-nearest neighbors with k = 200 as the classifier and evaluate each model once every five epochs. Hard sampling with β = 1 leads to much faster training: on STL10 hard sampling takes only 60 epochs to reach the same performance as SimCLR does in 400 epochs. On CIFAR100 hard sampling takes only 125 epochs to reach the same performance as SimCLR does in 400 epochs. We speculate that the speedup is, in part, due to hard negatives providing non-negligible gradient information during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>We argue for the value of hard negatives in unsupervised contrastive representation learning, and introduce a simple hard negative sampling method. Our work connects two major lines of work: contrastive learning, and negative mining in metric learning. Doing so requires overcoming an apparent roadblock: negative mining in metric learning uses pairwise similarity information as a core component, while contrastive learning is unsupervised. Our method enjoys several nice aspects: having desirable theoretical properties, a very simple implementation that requires modifying only a couple of lines of code, not changing anything about the data sampling pipeline, introducing zero extra computational overhead, and handling false negatives in a principled way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A ANALYSIS OF HARD SAMPLING A.1 HARD SAMPLING INTERPOLATES BETWEEN MARGINAL AND WORST-CASE NEGATIVES</head><p>We begin by proving Proposition 3. Recall that the proposition stated the following. Proposition 6. Let L * (f ) = sup q∈Π L(f, q). Then for any t &gt; 0 and measurable f :</p><formula xml:id="formula_24">X → S d−1 /t we observe the convergence L(f, q − β ) −→ L * (f ) as β → ∞.</formula><p>Proof. Consider the following essential supremum,</p><formula xml:id="formula_25">M (x) = ess sup x − ∈X :x − x f (x) T f (x − ) = sup{m &gt; 0 : m ≥ f (x) T f (x − ) a.s. for x − ∼ p − }.</formula><p>The second inequality holds since supp(p) = X . We may rewrite</p><formula xml:id="formula_26">L * (f ) = E x∼p x + ∼p + x − log e f (x) T f (x + ) e f (x) T f (x + ) + Qe M (x) , L(f, q − β ) = E x∼p x + ∼p + x   − log e f (x) T f (x + ) e f (x) T f (x + ) + QE x − ∼q − β [e f (x) T f (x − ) ]   .</formula><p>The difference between these two terms can be bounded as follows,</p><formula xml:id="formula_27">L * (f ) − L(f, q − β ) ≤ E x∼p x + ∼p + x − log e f (x) T f (x + ) e f (x) T f (x + ) + Qe M (x) + log e f (x) T f (x + ) e f (x) T f (x + ) + QE x − ∼q − β [e f (x) T f (x − ) ] = E x∼p x + ∼p + x log e f (x) T f (x + ) + QE x − ∼q − β [e f (x) T f (x − ) ] − log e f (x) T f (x + ) + Qe M (x) ≤ e 1/t Q + 1 • E x∼p x + ∼p + x e f (x) T f (x + ) + QE x − ∼q − β [e f (x) T f (x − ) ] − e f (x) T f (x + ) − Qe M (x) = e 1/t Q Q + 1 • Ex∼p E x − ∼q − β [e f (x) T f (x − ) ] − e M (x) ≤ e 1/t • E x∼p E x − ∼q − β e M (x) − e f (x) T f (x − )</formula><p>where for the second inequality we have used the fact that f lies on the hypersphere of radius 1/t to restrict the domain of the logarithm to values greater than (Q + 1)e −1/t . Because of this the logarithm is Lipschitz with parameter e 1/t /(Q + 1). Using again the fact that f lies on the hypersphere we know that f (x) T f (x − ) ≤ 1/t 2 and hence have the following inequality,</p><formula xml:id="formula_28">E x∼p E q − β e M (x) − e f (x) T f (x − ) ≤ e 1/t 2 E x∼p E q − β M (x) − f (x) T f (x − ) Let us consider the inner expectation E β (x) = E q − β M (x) − f (x) T f (x − ) . Note that since f is bounded, E β (x) is uniformly bounded in x.</formula><p>Therefore, in order to show the convergence L(f, q − β ) → L * (f ) as β → ∞, it suffices by the dominated convergence theorem to show that E β (x) → 0 pointwise as β → ∞ for arbitrary fixed x ∈ X .</p><p>From now on we denote M = M (x) for brevity, and consider a fixed x ∈ X . From the definition of q − β it is clear that q − β p − . That is, since q − β = c • p − for some (non-constant) c, it is absolutely continuous with respect to p − . So M (x) ≥ f (x) T f (x − ) almost surely for x − ∼ q − β , and we may therefore drop the absolute value signs from our expectation. Define the following event</p><formula xml:id="formula_29">G ε = {x − : f (x) f (x − ) ≥ M − ε}</formula><p>where G is refers to a "good" event. Define its complement B ε = G c ε where B is for "bad". For a fixed x ∈ X and ε &gt; 0 consider,</p><formula xml:id="formula_30">E β (x) = E x − ∼q − β M (x) − f (x) T f (x − ) = P x − ∼q − β (G ε ) • E x − ∼q − β M (x) − f (x) T f (x − ) |G ε + P x − ∼q − β (B ε ) • E x − ∼q − β M (x) − f (x) T f (x − ) |B ε ≤ P x − ∼q − β (G ε ) • ε + 2P x − ∼q − β (B ε ) ≤ ε + 2P x − ∼q − β (B ε ).</formula><p>We need to control P x − ∼q − β (B ε ). Expanding,</p><formula xml:id="formula_31">P x − ∼q − β (B ε ) = X 1 f (x) T f (x − ) &lt; M (x) − ε e βf (x) T f (x − ) • p − (x − ) Z β dx −</formula><p>where Z β = X e βf (x) T f (x − ) p − (x − )dx − is the partition function of q − β . We may bound this expression by,</p><formula xml:id="formula_32">X 1 f (x) T f (x − ) &lt; M − ε e β(M −ε) • p − (x − ) Z β dx − ≤ e β(M −ε) Z β X 1 f (x) T f (x − ) &lt; M − ε p − (x − )dx − = e β(M −ε) Z β P x − ∼p − (B ε ) ≤ e β(M −ε) Z β Note that Z β = X e βf (x) T f (x − ) p − (x − )dx − ≥ e β(M −ε/2) P x − ∼p − (f (x) T f (x − ) ≥ M − ε/2).</formula><p>By the definition of M = M (x) the probability ρ ε = P x − ∼p − (f (x) T f (x − ) ≥ M − ε/2) &gt; 0, and we may therefore bound,</p><formula xml:id="formula_33">P x − ∼q − β (B ε ) = e β(M −ε) e β(M −ε/2) ρ ε = e −βε/2 /ρ ε −→ 0 as β → ∞.</formula><p>We may therefore take β to be sufficiently big so as to make</p><formula xml:id="formula_34">P x − ∼q − β (B ε ) ≤ ε and therefore E β (x) ≤ 3ε. In other words, E β (x) −→ 0 as β → ∞.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 OPTIMAL EMBEDDINGS ON THE HYPERSPHERE FOR WORST-CASE NEGATIVE SAMPLES</head><p>In order to study properties of global optima of the contrastive objective using the adversarial worst case hard sampling distribution recall that we have the following limiting objective,</p><formula xml:id="formula_35">L ∞ (f, q) = E x∼p x + ∼p + x − log e f (x) T f (x + ) E x − ∼q β [e f (x) T f (x − ) ] . (<label>8</label></formula><formula xml:id="formula_36">)</formula><p>We may separate the logarithm of a quotient into the sum of two terms plus a constant,</p><formula xml:id="formula_37">L ∞ (f, q) = L align (f ) + L unif (f, q) − 1/t 2 where L align (f ) = E x,x + f (x) − f (x + ) 2 /2 and L unif (f, q) = E x∼p log E x − ∼q e f (x) f (x − ) .</formula><p>Here we have used the fact that f lies on the boundary of the hypersphere of radius 1/t, which gives us the following equivalence between inner products and squared Euclidean norm,</p><formula xml:id="formula_38">2/t 2 − 2f (x) f (x + ) = f (x) 2 + f (x + ) 2 − 2f (x) f (x + ) = f (x) − f (x + ) 2 . (9)</formula><p>Taking supremum to obtain L * ∞ (f ) = sup q∈Π L ∞ (f, q) we find that the second expression simplifies to,</p><formula xml:id="formula_39">L * unif (f ) = sup q∈Π L unif (f, q) = E x∼p log sup x − x e f (x) f (x − ) = E x∼p sup x − x f (x) f (x − ).</formula><p>Using Eqn. ( <ref type="formula">9</ref>), this can be re-expressed as,</p><formula xml:id="formula_40">E x∼p sup x − x f (x) f (x − ) = −E x∼p inf x − x f (x) − f (x − ) 2 /2 + 1/t 2 . (<label>10</label></formula><formula xml:id="formula_41">)</formula><p>The forthcoming theorem exactly characterizes the global optima of min f L * ∞ (f ) Theorem 7. Suppose the downstream task is classification (i.e. C is finite), and let</p><formula xml:id="formula_42">L * ∞ (f ) = sup q∈Π L ∞ (f, q) . The infimum inf f : measurable L * ∞ (f )</formula><p>is attained, and any f * achieving the global minimum is such that f * (x) = f * (x + ) almost surely. Furthermore, letting v c = f * (x) for any x such that h(x) = c (so v c is well defined up to a set of x of measure zero), f * is characterized as being any solution to the following ball-packing problem,</p><formula xml:id="formula_43">max {vc∈S d−1 /t} c∈C c∈C ρ(c) • min c =c v c − v c 2 . (<label>11</label></formula><formula xml:id="formula_44">)</formula><p>Proof. Any minimizer of L align (f ) has the property that f (x) = f (x + ) almost surely. So, in order to prove the first claim, it suffices to show that there exist functions f ∈ arg inf f L * unif (f ) for which f (x) = f (x + ) almost surely. This is because, at that point, we have shown that arg min f L align (f ) and arg min f L * unif (f ) intersect, and therefore any solution of L * ∞ (f ) = L align (f ) + L * unif (f ) must lie in this intersection.</p><p>To this end, suppose that f ∈ arg min f L * unif (f ) but that f (x) = f (x + ) with non-zero probability. We shall show that we can construct a new embedding f such that f (x) = f (x + ) almost surely, and</p><formula xml:id="formula_45">L * unif ( f ) ≤ L * unif (f ).</formula><p>Due to Eqn. (10) this last condition is equivalent to showing,</p><formula xml:id="formula_46">E x∼p inf x − x f (x) − f (x − ) 2 ≥ E x∼p inf x − x f (x) − f (x − ) 2 . (<label>12</label></formula><formula xml:id="formula_47">)</formula><p>Fix a c ∈ C, and let</p><formula xml:id="formula_48">x c ∈ arg max x:h(x)=c inf x − x f (x) − f (x − ) 2 .</formula><p>The maximum is guaranteed to be attained, as we explain now. Indeed we know the maximum is attained at some point in the closure ∂{x : h(x) = c} ∪ {x : h(x) = c}. Since X is compact and connected, any point</p><formula xml:id="formula_49">x ∈ ∂{x : h(x) = c} \ {x : h(x) = c} is such that inf x − x f (x) − f (x − ) 2 = 0 since x must belong to {x : h(x) = c</formula><p>} for some other c . Such an x cannot be a solution unless all points in {x : h(x) = c} also achieve 0, in which case we can simply take x c to be a point in the interior of {x : h(x) = c}. Now, define f (x) = f (x c ) for any x such that h(x) = c and f (x) = f (x) otherwise. Let us first aim to show that Eqn. ( <ref type="formula" target="#formula_46">12</ref>) holds for this f . Let us begin to expand the left hand side of Eqn. ( <ref type="formula" target="#formula_46">12</ref>), Published as a conference paper at ICLR 2021</p><formula xml:id="formula_50">E x∼p inf x − x f (x) − f (x − ) 2 = E ĉ∼ρ E x∼p(•|ĉ) inf x − x f (x) − f (x − ) 2 = ρ(c)E x∼p(•|c) inf x − x f (x) − f (x − ) 2 + (1 − ρ(c))E ĉ∼ρ(•|ĉ =c) E x∼p(•|ĉ) inf x − x f (x) − f (x − ) 2 = ρ(c)E x∼p(•|c) inf x − x f (x c ) − f (x − ) 2 + (1 − ρ(c))E ĉ∼ρ(•|ĉ =c) E x∼p(•|ĉ) inf x − x f (x) − f (x − ) 2 = ρ(c) inf x − xc f (x c ) − f (x − ) 2 + (1 − ρ(c))E ĉ∼ρ(•|ĉ =c) E x∼p(•|ĉ) inf h(x − ) =ĉ f (x) − f (x − ) 2 (13)</formula><p>By construction, the first term can be lower bounded by</p><formula xml:id="formula_51">inf x − xc f (x c ) − f (x − ) 2 ≥ E x∼p(•|c) inf h(x − ) =c f (x) − f (x − ) 2</formula><p>for any x such that h(x) = c. To lower bound the second term, consider any fixed ĉ = c and x ∼ p(•|ĉ) (so h(x) = ĉ). Define the following two subsets of the input space</p><formula xml:id="formula_52">X A = {f (x − ) : f (x − ) = ĉ for x − ∈ X } A = {f (x − ) ∈ X : f (x − ) = ĉ for x − ∈ X }.</formula><p>Since by construction the range of f is a subset of the range of f , we know that A ⊆ A. Combining this with the fact that f (x) = f (x) whenever h(x) = ĉ = c we see,</p><formula xml:id="formula_53">inf h(x − ) =ĉ f (x) − f (x − ) 2 = inf h(x − ) =ĉ f (x) − f (x − ) 2 = inf u∈ A f (x) − u 2 ≥ inf u∈A f (x) − u 2 = inf h(x − ) =ĉ f (x) − f (x − ) 2</formula><p>Using these two lower bounds we may conclude that Eqn. ( <ref type="formula">13</ref>) can be lower bounded by,</p><formula xml:id="formula_54">ρ(c)E x∼p(•|c) inf h(x − ) =c f (x) − f (x − ) 2 + (1 − ρ(c))E ĉ∼ρ(•|ĉ =c) E x∼p(•|ĉ) inf h(x − ) =ĉ f (x) − f (x − ) 2 which equals E x∼p inf x − x f (x) − f (x − ) 2 .</formula><p>We have therefore proved Eqn. (12). To summarize the current progress; given an embedding f we have constructed a new embedding f that attains lower L unif loss and which is constant on x such that f is constant on {x : h(x) = c}. Enumerating C = {c 1 , c 2 . . . , c |C| }, we may repeatedly apply the same argument to construct a sequence of embeddings f 1 , f 2 , . . . , f |C| such that f i is constant on each of the following sets {x : h(x) = c j } for j ≤ i . The final embedding in the sequence</p><formula xml:id="formula_55">f * = f |C| is such that L * unif (f * ) ≤ L * unif (f )</formula><p>and therefore f * is a minimizer. This embedding is constant on each of {x : h(x) = c j } for j = 1, 2, . . . ,|C|. In other words, f * (x) = f * (x + ) almost surely. We have proved the first claim.</p><p>Obtaining the second claim is a matter of manipulating L * ∞ (f * ). Indeed, we know that</p><formula xml:id="formula_56">L * ∞ (f * ) = L * unif (f * ) − 1/t 2 and defining v c = f * (x) = f (x c ) for each c ∈ C, this expression is minimized if and only if f * attains, max f E x∼p inf x − x f (x) − f (x − ) 2 = max f E c∼ρ E x∼p(•|c) inf h(x − ) =c f (x) − f (x − ) 2 = max f c∈C ρ(c) • inf h(x − ) =c f (x) − f (x − ) 2 = max {vc∈S d−1 /t} c∈C c∈C ρ(c) • min c =c v c − v c 2</formula><p>where the final equality inserts f * as an optimal f and reparameterizes the maximum to be over the set of vectors {v c ∈ S d−1 /t} c∈C . (ties broken arbitrarily)</p><formula xml:id="formula_57">A.3 DOWNSTREAM GENERALIZATION Theorem 8. Suppose ρ is uniform on C and f is such that L * ∞ (f ) − inf f measurable L * ∞ ( f ) ≤ ε with ε ≤ 1. Let {v * c ∈ S d−1 /</formula><p>achieves misclassification risk,</p><formula xml:id="formula_58">P( ĥ(x) = c) ≤ 8ε (ξ 2 − 2|C| (1 + 1/t)ε 1/2 ) 2</formula><p>Proof. To begin, using the definition of ĥ we know that for any 0 &lt; δ &lt; ξ,</p><formula xml:id="formula_59">P x,c ( ĥ(x) = c) = P x,c f (x) − v c ≤ min c − :c − =c f (x) − v c − ≥ P x,c f (x) − v c ≤ δ, and δ ≤ min c − :c − =c f (x) − v c − ≥ 1 − P x,c f (x) − v c &gt; δ − P x,c min c − :c − =c f (x) − v c − &lt; δ</formula><p>So to prove the result, our goal is now to bound these two probabilities. To do so, we use the bound on the excess risk. Indeed, combining the fact</p><formula xml:id="formula_60">L * ∞ (f ) − inf f measurable L * ∞ ( f ) ≤ ε with the notational rearrangements before Theorem 7 we observe that E x,x + f (x) − f (x + ) 2 ≤ 2ε.</formula><p>We have,</p><formula xml:id="formula_61">2ε ≥ E x,x + f (x) − f (x + ) 2 = E c∼ρ E x + ∼p(•|c) E x∼p(•|c) f (x) − f (x + ) 2 .</formula><p>For fixed c, x + , let x c ∈ arg min {x</p><formula xml:id="formula_62">+ :h(x + )=c} E x∼p(•|c) f (x) − f (x + )</formula><p>2 where we extend the minimum to be over the closure, a compact set, to guarantee it is attained. Then we have</p><formula xml:id="formula_63">2ε ≥ E c∼ρ E x + ∼p(•|c) E x∼p(•|c) f (x) − f (x + ) 2 ≥ E c∼ρ E x∼p(•|c) f (x) − v c 2</formula><p>where we have now defined v c = f (x c ) for each c ∈ C. Note in particular that v c lies on the surface of the hypersphere S d−1 /t. This enables us to obtain the follow bound using Markov's inequality,</p><formula xml:id="formula_64">P x,c f (x) − v c &gt; δ = P x,c f (x) − v c 2 &gt; δ 2 ≤ E x,c f (x) − v c 2 δ 2 ≤ 2ε δ 2 .</formula><p>so it remains still to bound</p><formula xml:id="formula_65">P x,c min c − :c − =c f (x) − v c − &lt; δ . Defining ξ = min c,c − :c =c − v c − v c− ,</formula><p>we have the following fact (proven later).</p><formula xml:id="formula_66">Fact (see lemma 9): ξ ≥ ξ 2 − 2|C| (1 + 1/t) √ ε.</formula><p>Using this fact we are able to get control over the tail probability as follows,</p><formula xml:id="formula_67">P x,c min c − :c − =c f (x) − v c − &lt; δ ≤ P x,c f (x) − v c &gt; ξ − δ ≤ P x,c f (x) − v c &gt; ξ − ξ 2 − 2|C| (1 + 1/t)ε 1/2 − δ = P x,c f (x) − v c 2 &gt; ( ξ 2 − 2|C| (1 + 1/t)ε 1/2 − δ) 2 ≤ 2ε ( ξ 2 − 2|C| (1 + 1/t)ε 1/2 − δ) 2 .</formula><p>where this inequality holds for for any</p><formula xml:id="formula_68">0 ≤ δ ≤ ξ 2 − 2|C| (1 + 1/t)ε 1/2 .</formula><p>Gathering together our tail probability bounds we find that P x,c ( ĥ</p><formula xml:id="formula_69">(x) = c) ≥ 1 − 2ε δ 2 − 2ε ( √ ξ 2 −2|C|(1+1/t)ε 1/2 −δ) 2 for any 0 ≤ δ ≤ ξ 2 − 2|C| (1 + 1/t)ε 1/2 . That is, P x,c ( ĥ(x) = c) ≤ 2ε δ 2 + 2ε ( ξ 2 − 2|C| (1 + 1/t)ε 1/2 − δ) 2</formula><p>Since this holds for any</p><formula xml:id="formula_70">0 ≤ δ ≤ ξ 2 − 2|C| (1 + 1/t)ε 1/2 , P x,c ( ĥ(x) = c) ≤ min 0≤δ≤ √ ξ 2 −2|C|ε 2ε δ 2 + 2ε ( ξ 2 − 2|C| (1 + 1/t)ε 1/2 − δ) 2 .</formula><p>Elementary calculus shows that the minimum is attained at δ =</p><formula xml:id="formula_71">√ ξ 2 −2|C|(1+1/t)ε 1/2 2</formula><p>. Plugging this in yields the final bound,</p><formula xml:id="formula_72">P( ĥ(x) = c) ≤ 8ε (ξ 2 − 2|C| (1 + 1/t)ε 1/2 ) 2 .</formula><p>Lemma 9. Consider the same setting as introduced in Theorem 5. In particular define</p><formula xml:id="formula_73">ξ = min c,c − :c =c − v c − v c− , ξ = min c,c − :c =c − v * c − v * c− .</formula><p>where {v * c ∈ S d−1 /t} c∈C is a solution to Problem 7, and</p><formula xml:id="formula_74">{v c ∈ S d−1 /t} c∈C is defined via v c = f (x c ) with x c ∈ arg min {x + :h(x + )=c} E x∼p(•|c) f (x) − f (x + ) 2 for each c ∈ C. Then we have, ξ ≥ ξ 2 − 2|C| (1 + 1/t)ε 1/2 . Proof. Define, X = min c − :c − =c v c − v c− 2 , X * = min c − :c − =c v * c − v * c− 2 .</formula><p>X and X * are random due to the randomness of c ∼ ρ. We can split up the following expectation by conditioning on the event {X ≤ X * } and its complement,</p><formula xml:id="formula_75">E|X − X * | = P(X ≥ X * )E[X − X * ] + P(X ≤ X * )E[X * − X].<label>(14)</label></formula><p>Using L * ∞ (f )−inf f measurable L * ∞ ( f ) ≤ ε and the notational re-writing of the objective L * ∞ introduced before Theorem 7, we observe the following fact, whose proof we give in a separate lemma after the conclusion of this proof.</p><p>Fact (see lemma 10):</p><formula xml:id="formula_76">EX * − 2(1 + 1/t) √ ε ≤ EX ≤ EX * . This fact implies in particular E[X − X * ] ≤ 0 and E[X * − X] ≤ 2(1 + 1/t) √ ε. Inserting both inequalities into Eqn. 14 we find that E|X − X * | ≤ 2(1 + 1/t) √ ε. In other words, since ρ is uniform, 1 |C| c∈C min c − :c − =c v c − v c− 2 − min c − :c − =c v * c − v * c− 2 ≤ 2(1 + 1/t) √ ε.</formula><p>From which we can say that for any c ∈ C , min</p><formula xml:id="formula_77">c − :c − =c v c − v c− 2 − min c − :c − =c v * c − v * c− 2 ≤ 2|C| (1 + 1/t) √ ε. So min c − :c − =c v c − v c− ≥ min c − :c − =c v * c − v * c− 2 − 2|C| (1 + 1/t)ε 1/2 ≥ ξ 2 − 2|C| (1 + 1/t)ε 1/2 .</formula><p>Since this holds for any c ∈ C , we conclude that ξ ≥ ξ 2 − 2|C| (1 + 1/t)ε 1/2 . Lemma 10. Consider the same setting as introduced in Theorem 5. Define also,</p><formula xml:id="formula_78">X = min c − :c − =c v c − v c− 2 , X * = min c − :c − =c v * c − v * c− 2 , where v c = f (x c ) with x c ∈ arg min {x + :h(x + )=c} E x∼p(•|c) f (x) − f (x + ) 2 for each c ∈ C. We have, EX * − 2(1 + 1/t) √ ε ≤ EX ≤ EX * .</formula><p>Proof. By Theorem 7 we know there is an f * attaining the minimum inf f measurable L * ∞ ( f ) and that this f * attains L * align (f * ) = 0, and also minimizes the uniformity term L * unif (f ), taking the value</p><formula xml:id="formula_79">L * unif (f * ) = E c∼ρ max c − :c − =c v * c v * c − .</formula><p>Because of this we find,</p><formula xml:id="formula_80">L * unif (f ) ≤ L * ∞ (f ) − L * ∞ (f * ) + L * align (f * ) − L * align (f ) + L * unif (f * ) ≤ L * ∞ (f ) − L * ∞ (f * ) + L * unif (f * ) ≤ ε + L * unif (f * ) = ε + E c∼ρ max c − :c − =c v * c v * c − .</formula><p>Since we would like to bound</p><formula xml:id="formula_81">E c∼ρ max c − :c − =c v c v c − in terms of E c∼ρ max c − :c − =c v * c v * c − , this observation means that is suffices to bound E c∼ρ max c − :c − =c v c v c − in terms of L * unif (f ).</formula><p>To this end, note that for a fixed c, and x such that h(x) = c we have,</p><formula xml:id="formula_82">sup x − x f (x) f (x − ) = sup x − x v c f (x − ) + (f (x) − v c ) f (x − ) = sup x − x v c f (x − ) − f (x) − v c /t ≥ max x − ∈{xc} c∈C v c f (x − ) − f (x) − v c /t = max c − =c v c v c − − f (x) − v c /t</formula><p>where the inequality follows since {x c } c∈C is a subset of the closure of {x − : x − x}. Taking expectations over c, x,</p><formula xml:id="formula_83">L * unif (f ) = E x,c sup x − x f (x) f (x − ) ≥ E c∼ρ max c − =c v c v c − − E x,c f (x) − v c /t ≥ E c∼ρ max c − =c v c v c − − E x,c f (x) − v c 2 /t ≥ E c∼ρ max c − =c v c v c − − √ ε/t.</formula><p>So since ε ≤ √ ε, we have found that</p><formula xml:id="formula_84">E c∼ρ max c − =c v c v c − ≤ √ ε/t + ε + E c∼ρ max c − :c − =c v * c v * c − ≤ (1 + 1/t) √ ε + E c∼ρ max c − :c − =c v * c v * c − .</formula><p>Of course we also have,</p><formula xml:id="formula_85">E c∼ρ max c − :c − =c v * c v * c − = L * unif (f * ) ≤ E c∼ρ max c − :c − =c v c v c −</formula><p>since the embedding f (x) = v c whenever h(x) = c is also a feasible solution. Combining these two inequalities with the simple identity x y = 1/t 2 − x − y 2 /2 for all length 1/t vectors x, y, we find,</p><formula xml:id="formula_86">1/t 2 − E c∼ρ max c − :c − =c v * c − v * c − 2 /2 ≤ 1/t 2 − E c∼ρ max c − :c − =c v c − v c − 2 /2 ≤ 1/t 2 − E c∼ρ max c − :c − =c v * c − v * c − 2 /2 + (1 + 1/t) √ ε.</formula><p>Subtracting 1/t 2 and multiplying by −2 yields the result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B GRAPH REPRESENTATION LEARNING</head><p>We describe in detail the hard sampling method for graphs whose results are reported in Section 5.2. Before getting that point, in the interests of completeness we cover some required background details on the InfoGraph method of <ref type="bibr" target="#b44">Sun et al. (2020)</ref>. For further information see the original paper <ref type="bibr" target="#b44">(Sun et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 BACKGROUND ON GRAPH REPRESENTATIONS</head><p>We observe a set of graphs G = {G j ∈ G} n j=1 sampled according to a distribution p over an ambient graph space G. Each node u in a graph G is assumed to have features h (0) u living in some Euclidean space. We consider a K-layer graph neural network, whose k-th layer iteratively computes updated embeddings for each node v ∈ G in the following way,</p><formula xml:id="formula_87">h (k) v = COMBINE (k)   h (k−1) v , AGGREGATE (k) h (k−1) v , h (k−1) u , e uv : u ∈ N (v)  </formula><p>where COMBINE (k) and AGGREGATE (k) are parameterized learnable functions and N (v) denotes the set of neighboring nodes of v. The K embeddings for a node u are collected together to obtain a single final summary embedding for u. As recommended by <ref type="bibr" target="#b54">Xu et al. (2019)</ref> we use concatenation,</p><formula xml:id="formula_88">h u = h u (G) = CONCAT {h (k)</formula><p>u } K k=1 to obtain an embedding in R d . Finally, the node representations are combined together into a length d graph level embedding using a readout function,</p><formula xml:id="formula_89">H(G) = READOUT {h u } u∈G</formula><p>which is typically taken to be a simple permutation invariant function such as the sum or mean. The InfoGraph method aims to maximize the mutual information between the graph level embedding H(G) and patch-level embeddings h u (G) using the following objective,</p><formula xml:id="formula_90">max h E G∼p 1 |G| u∈G I h u (G); H(G)</formula><p>In practice the population distribution p is replaced by its empirical counterpart, and the mutual information I is replaced by a variational approximation I T . In line with <ref type="bibr" target="#b44">Sun et al. (2020)</ref> we use the Jensen-Shannon mutual information estimator as formulated by <ref type="bibr" target="#b33">Nowozin et al. (2016)</ref>. It is defined using a neural network discriminator T : R 2d → R as,</p><formula xml:id="formula_91">I T h u (G); H(G) = E G∼p −sp(−T h u (G), H(G) ) −E (G,G )∼p×p sp(T h u (G), H(G ) )</formula><p>where sp(z) = log(1+e z ) denotes the softplus function. The finial objective is the joint maximization over h and T ,</p><formula xml:id="formula_92">max θ,ψ E G∼p 1 |G| u∈G I T h u (G); H(G)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 HARD NEGATIVE SAMPLING FOR LEARNING GRAPH REPRESENTATIONS</head><p>In order to derive a simple modification of the NCE hard sampling technique that is appropriate for use with InfoGraph, we first provide a mildly generalized view of hard sampling. Recall that the NCE contrastive objective can be decomposed into two constituent pieces,</p><formula xml:id="formula_93">L(f, q) = L align (f ) + L unif (f, q)</formula><p>where q is in fact a family of distributions q(x − ; x) over x − that is indexed by the possible values of the anchor x. L align performs the role of "aligning" positive pairs (embedding near to one-another), while L unif repels negative pairs. The hard sampling framework aims to solve,</p><formula xml:id="formula_94">inf f sup q L(f, q).</formula><p>In the case of NCE loss we take,</p><formula xml:id="formula_95">L align (f ) = −E x∼p x + ∼p + x f (x) T f (x + ), L unif (f, q) = E x∼p x + ∼p + x log e f (x) T f (x + ) + QE x − ∼q [e f (x) T f (x − ) ] .</formula><p>View this view, we can easily adapt to the InfoGraph framework, taking</p><formula xml:id="formula_96">L align (h, T ) = −E G∼p 1 |G| u∈G sp(−T h u (G), H(G) ), L unif (h, T, q) = −E G∼p 1 |G| u∈G E G ∼q sp(T h u (G), H(G ) )</formula><p>Denote by p the distribution over nodes u ∈ R s defined by first sampling G ∼ p, then sampling u ∈ G uniformly over all nodes of G. Then these two terms can be simplified to</p><formula xml:id="formula_97">L align (h, T ) = −E u∼ psp(−T h u (G), H(G) ), L unif (h, T, q) = −E (u,G )∼ p×q sp(T h u (G), H(G ) )</formula><p>At this point it becomes clear that, just as with NCE, a distribution q * ∈ arg max q L(f, q) in the InfoGraph framework if it is supported on arg max G ∈G sp(T h u (G), H(G ) ). Although this is still hard to compute exactly, it can be approximated by, The vision experiments in the main body of the paper are all based off the SimCLR framework <ref type="bibr" target="#b4">(Chen et al., 2020a)</ref>. They use a relatively small batch size (up to 512). In order to test whether our hard negatives sampling method can help when the negative batch size is very large, we also run experiments using MoCo-v2 with standard negative memory bank size N = 65536 <ref type="bibr" target="#b19">(He et al., 2020;</ref><ref type="bibr" target="#b6">Chen et al., 2020c)</ref>. We adopt the official MoCo-v2 code<ref type="foot" target="#foot_3">2</ref> . Embeddings are trained for 200 epochs, with batch size 128. To study the affect of varying the concentration parameter β on the learned embeddings Figure <ref type="figure" target="#fig_8">9</ref> plots cosine similarity histograms of pairs of similar and dissimilar points. The results show that for β moving from 0 through 0.5 to 2 causes both the positive and negative similarities to gradually skew left. In terms of downstream classification, an important property is the relative difference in similarity between positive and negative pairs. In this case β = 0.5 find the best balance (since it achieves the highest downstream accuracy). When β is taken very large (β = 6), we see a change in conditions. Both positive and negative pairs are assigned higher similarities in general. Visually it seems that the positive and negative histograms for β = 6 overlap a lot more than for smaller values, which helps explain why the linear readout accuracy is lower for β = 6 .</p><formula xml:id="formula_98">q β u (G ) ∝ exp βT (h u (G), H(G)) • p(G ).</formula><p>Figure <ref type="figure" target="#fig_0">12</ref> gives real examples of hard vs. uniformly sampled negatives. Given an anchor x (a monkey) and trained embedding f (trained on STL10 using standard SimCLR for 400 epochs), we sample a batch of 128 images. The top row shows the ten negatives x − that have the largest inner product f (x) f (x − ), while the bottom row is a random sample from from the same batch. Negatives with the largest inner product with the anchor correspond to the items in the batch are the most important terms in the objective since they are given the highest weighting by q − β . Figure <ref type="figure" target="#fig_0">12</ref> shows that "real" hard negatives are conceptually similar to the idea as proposed in Figure <ref type="figure" target="#fig_0">1</ref>: hard negatives are semantically similar to the anchor, possessing various similarities, including color (browns and greens), texture (fur), and objects (animals vs machinery).   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D EXPERIMENTAL DETAILS</head><p>Figure <ref type="figure" target="#fig_0">13</ref> shows PyTorch-style pseudocode for the standard objective, the debiased objective, and the hard sampling objective. The proposed hard-sample loss is very simple to implement, requiring only two extra lines of code compared to the standard objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 VISUAL REPRESENTATIONS</head><p>We implement SimCLR in PyTorch. We use a ResNet-50 <ref type="bibr" target="#b18">(He et al., 2016)</ref> as the backbone with embedding dimension 2048 (the representation used for linear readout), and projection head into the lower 128-dimensional space (the embedding used in the contrastive objective). We use the Adam optimizer <ref type="bibr" target="#b25">(Kingma &amp; Ba, 2015)</ref> with learning rate 0.001 and weight decay 10 −6 . Code available at https://github.com/joshr17/HCL. Since we adopt the SimCLR framework, the number of negative samples N = 2(batch size − 1). Since we always take the batch size to be a power of 2 <ref type="bibr">(16,</ref><ref type="bibr">32,</ref><ref type="bibr">64,</ref><ref type="bibr">128,</ref><ref type="bibr">256)</ref> the negative batch sizes are 30, 62, 126, 254, 510 respectively. Unless otherwise stated, all models are trained for 400 epochs.</p><p>Annealing β Method: We detail the annealing method whose results are given in Figure <ref type="figure">4</ref>. The idea is to reduce the concentration parameter down to zero as training progresses. Specifically, suppose we have e number of total training epochs. We also specify a number of "changes" to the concentration parameter we shall make. We initialize the concentration parameter β 1 = β (where this β is the number reported in Figure <ref type="figure">4</ref>), then once every e/ epochs we reduce β i by β/ . In other words, if we are currently on β i , then β i+1 = β i − β/ , and we switch from β i to β i+1 in epoch number i • e/ . The idea of this method is to select particularly difficult negative samples early on order to obtain useful gradient information early on, but later (once the embedding is already quite good) we reduce the "hardness" level so as to reduce the harmful effect of only approximately correcting for false negatives (negatives with the same labels as the anchor).</p><p>Recall that L align (f ) = E x,x + f (x) − f (x + ) 2 /2 is termed alignment, and <ref type="bibr">Wang &amp; Isola (2020)</ref> show that the contrastive objective jointly optimize alignment and uniformity. Lemma 11 therefore shows that as training evolves, the variance of the X = e f (x) T f (v) where x ∼ p and v ∼ q + β is bounded by a term that we expect to see becoming small, suggesting that using a single sample (M = 1) to approximate this expectation is not unreasonable. We cannot, however, say more than this since we have no guarantee that L align (f ) goes to zero.</p><p>Proof. Fix an x and recall that we are considering q + β (•) = q + β (•; x). First let X be an i.i.d. copy of X, and note that, conditioning on x, we have 2Var(X|x) = Var(X|x) + Var(X |x) = Var(X − X |x) ≤ E (X − X ) 2 |x . Bounding this difference,</p><formula xml:id="formula_99">E (X − X ) 2 |x = E v,v ∼q + β e f (x) f (v) − e f (x) f (v ) 2 ≤ E v,v ∼q + β e 1/t 2 f (x) f (v) − f (x) f (v ) 2 ≤ e 1/t 4 E v,v ∼q + β f (x) f (v) − f (v ) 2 = e 1/t 4 t 2 E v,v ∼q + β f (v) − f (v ) 2 ≤ O E v,v ∼p + f (v) − f (v ) 2</formula><p>where the first inequality follows since f lies on the sphere of radius 1/t, the second inequality by Cauchy-Schwarz, the third again since f lies on the sphere of radius 1/t, and the fourth since q + β is absolutely continuous with respect to p + with bounded ratio. Figure <ref type="figure" target="#fig_0">14</ref>: In cases where the learned embedding is not normalized to lie on a hypersphere we found that clipping the negatives to live in a fixed range (in this case [−2, 2]) stabilizes optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 GRAPH REPRESENTATIONS</head><p>All datasets we benchmark on can be downloaded at www.graphlearning.io from the TU-Dataset repository of graph classification problems <ref type="bibr" target="#b31">(Morris et al., 2020)</ref>. Information on basic statistics of the datasets is included in Tables <ref type="table" target="#tab_3">3 and 4</ref>. For fair comparison to the original In-foGraph method, we adopt the official code, which can be found at https://github.com/ fanyun-sun/InfoGraph. We modify only the gan_losses.py script, adding in our proposed hard sampling via reweighting. For simplicity we trained all models using the same set of hyperparameters: we used the GIN architecture <ref type="bibr" target="#b54">(Xu et al., 2019)</ref> with K = 3 layers and embedding dimension d = 32. Each model is trained for 200 epochs with batch size 128 using the Adam optimizer <ref type="bibr" target="#b25">(Kingma &amp; Ba, 2015)</ref>. with learning rate 0.001, and weight decay of 10 −6 . Each embedding is evaluated using the average accuracy 10-fold cross-validation using an SVM as the classifier (in line with the approach taken by <ref type="bibr" target="#b31">Morris et al. (2020)</ref>). Each experiment is repeated from scratch 10 times, and the distribution of results from these 10 runs is plotted in Figure <ref type="figure">3</ref>.</p><p>Since the graph embeddings are not constrained to lie on a hypersphere, for a batch we clip all the inner products to live in the interval [−2, 2] while computing the reweighting, as illustrated in Figure <ref type="figure" target="#fig_0">14</ref>. We found this to be important for stabilizing optimization. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3 SENTENCE REPRESENTATIONS</head><p>We adopt the official quick-thoughts vectors experimental settings, which can be found at https: //github.com/lajanugen/S2V. We keep all hyperparameters at the default values and change only the s2v-model.py script. Since the official BookCorpus dataset <ref type="bibr" target="#b26">Kiros et al. (2015)</ref> is not available, we use an unofficial version obtained using the following repository: https://github. com/soskek/bookcorpus. Since the sentence embeddings are also not constrained to lie on a hypersphere, we use the same clipping trick as for the graph embeddings, illustrated in Figure <ref type="figure" target="#fig_0">14</ref>.</p><p>After training on the BookCorpus dataset, we evaluate the embeddings on six different classification tasks: paraphrase identification (MSRP) <ref type="bibr" target="#b11">(Dolan et al., 2004)</ref>, question type classification (TREC) <ref type="bibr" target="#b50">(Voorhees &amp; Harman, 2002)</ref>, opinion polarity (MPQA) <ref type="bibr" target="#b52">(Wiebe et al., 2005)</ref>, subjectivity classification (SUBJ) <ref type="bibr" target="#b35">(Pang &amp; Lee, 2004)</ref>, product reviews (CR) <ref type="bibr" target="#b21">(Hu &amp; Liu, 2004)</ref>, and sentiment of movie reviews (MR) <ref type="bibr" target="#b36">(Pang &amp; Lee, 2005)</ref>.</p><p>Comparison with <ref type="bibr" target="#b23">Kalantidis et al. (2020)</ref>: <ref type="bibr" target="#b23">Kalantidis et al. (2020)</ref> also consider ways to sample negatives, and propose a mixing strategy for hard negatives, called MoCHi. The main points of difference are: 1) MoCHi considers the benefit of hard negatives, but does not consider the possibility of false negatives (Principle 1), which we found to be valuable. 2) MoCHi introduces three extra hyperparameters, while our method introduces only two (β, τ + ). If we discard Principle 1 (i.e. τ + ) then only β requires tuning. 3) our method introduces zero computational overhead by utilizing within-batch reweighting, whereas MoCHi involves a small amount of extra computation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Schematic illustration of negative sampling methods for the example of classifying species of tree. Top row: uniformly samples negative examples (red rings); mostly focuses on very different data points from the anchor (yellow triangle), and may even sample examples from the same class (triangles, vs. circles). Bottom row: Hard negative sampling prefers examples that are (incorrectly) close to the anchor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>respectively (δ w denotes the Dirac delta function centered at w). The only unknowns left are the partition functions, Z</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>= 0.5, τ + = 0.1) Hard (β = 1, τ + = 0.1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Figure4: Left: the effect of varying concentration parameter β on linear readout accuracy. Middle: linear readout accuracy as concentration parameter β varyies, in the case of contrastive learning (fully unsupervised), using true positive samples (uses label information), and an annealing method that improves robustness to the choice of β (see Appendix D.1 for details). Right: STL10 linear readout accuracy for hard sampling with and without debiasing, and non-hard sampling (β = 0) with and without debiasing. Best results come from using both simultaneously.</figDesc><graphic url="image-11.png" coords="9,401.62,92.31,69.23,69.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>t} c∈C be a solution to Problem 7, and define ξ = min c,c − :c =c − v * c − v * c− &gt; 0. Then there exists a set of vectors {v c ∈ S d−1 /t} c∈C such that the following 1-nearest neighbor classifier, ĥ(x) = ĉ, where ĉ = arg min c∈C f (x) − v c</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Hard negative sampling using MoCo-v2 framework. Results show that hard negative samples can still be useful when the negative memory bank is very large (in this case N = 65536).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: The effect of varying concentration parameter β on linear readout accuracy for CI-FAR10. (Complements the left and middle plot from Figure 4.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Histograms of cosine similarity of pairs of points with different label (bottom) and same label (top) for embeddings trained on CIFAR100 with different values of β. Histograms overlaid pairwise to allow for easy comparison.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Histograms of cosine similarity of pairs of points with the same label (top) and different labels (bottom) for embeddings trained on CIFAR100 with four different objectives. H=Hard Sampling, D=Debiasing. Histograms overlaid pairwise to allow for convenient comparison.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 :Figure 11 :</head><label>1011</label><figDesc>Figure 10: Histograms of cosine similarity of pairs of points with the same label (top) and different labels (bottom) for embeddings trained on CIFAR10 with four different objectives. H=Hard Sampling, D=Debiasing. Histograms overlaid pairwise to allow for convenient comparison.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>Since p + (x + ) = p(x + |h(x)) only depends on c = h(x), rather than x itself, taking expectations over x ∼ p is equivalent to taking expectations over c ∼ ρ. Further, ρ(c)p(v|c)p(v |c) = p(v)p(v |c) = p(v)p + v (v ). So E c∼ρ E v,v ∼p + f (v) − f (v ) 2 = E x,x + f (x) − f (x + ) 2 = 2L align (f ), wherex ∼ p and x + ∼ p + x . Thus we obtain the lemma.1 # pos : exp of inner products for positive examples 2 # neg : exp of inner products for negative examples 3 negatives trick before computing reweighting 9 reweight = 2 * neg / max( neg.max().abs(), neg.min().abs() ) 10 reweight = (beta * reweight) / reweight.mean() 11 Neg = max((-N * tau_plus * pos + reweight * neg).sum() / (1-tau_plus), e ** (-1/t)) 12 hard_loss = -log( pos.sum() / (pos.sum() + Neg))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 .</head><label>2</label><figDesc>Hard sampling outperforms or equals the QT Classification accuracy on downstream tasks. We compare graph representations on four classification tasks. Accuracies are obtained by fine-tuning an SVM readout function, and are the average of 10 runs, each using 10-fold cross validation. Results in bold indicate best performer. baseline in 5 out of 6 cases, the debiased baseline<ref type="bibr" target="#b9">(Chuang et al., 2020)</ref> in 4 out of 6, and both in 3 out of 6 cases. Setting τ + &gt; 0 led to numerical issues in optimization for hard sampling.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">InfoGraph ( = 0)</cell><cell></cell><cell cols="3">Hard ( = 1)</cell><cell></cell><cell>Hard ( = 2)</cell><cell>Hard ( = 10)</cell></row><row><cell></cell><cell></cell><cell>DD</cell><cell>0.65</cell><cell></cell><cell>PTC</cell><cell></cell><cell></cell><cell></cell><cell>REDDIT-B</cell><cell>0.77</cell><cell>PROTEINS</cell></row><row><cell>Accuracy</cell><cell>0.675 0.700 0.775 0.750 0.725 0.55 0.60</cell><cell>72.5% 72.8% 72.2% 73.8% ENZYMES</cell><cell>0.60 0.50 0.55 0.875 0.900 0.925</cell><cell cols="4">55.3% 57.1% 56.2% 56.9% MUTAG</cell><cell>0.85 0.75 0.80 0.74 0.76</cell><cell>81.0% 83.4% 82.8% 80.0% IMDB-B</cell><cell>0.76 0.75 0.73 0.74 0.50 0.52</cell><cell>74.5% 74.2% 74.1% 74.5% IMDB-M</cell></row><row><cell></cell><cell>0.50</cell><cell></cell><cell>0.850</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.72</cell><cell>0.48</cell></row><row><cell></cell><cell>0.45</cell><cell>50.4% 51.2% 51.4% 53.6%</cell><cell>0.825</cell><cell cols="6">86.8% 86.4% 87.3% 87.3% Average Accuracy 72.2% 72.6% 72.6% 72.8% 0.70</cell><cell>0.46</cell><cell>49.6% 49.2% 49.4% 49.6%</cell></row><row><cell cols="3">Figure 3: Objective</cell><cell></cell><cell></cell><cell>MR</cell><cell cols="4">CR SUBJ MPQA TREC</cell><cell>MSRP</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(Acc) (F1)</cell></row><row><cell></cell><cell></cell><cell cols="3">QT (β = 0, τ + = 0)</cell><cell cols="2">76.8 81.3</cell><cell cols="2">86.6</cell><cell>93.4</cell><cell>89.8</cell><cell>73.6</cell><cell>81.8</cell></row><row><cell></cell><cell></cell><cell cols="5">Debiased (τ + = 0.01) 76.2 82.9</cell><cell cols="2">86.9</cell><cell>93.7</cell><cell>89.1</cell><cell>74.7</cell><cell>82.7</cell></row><row><cell></cell><cell></cell><cell cols="5">Hard (β = 1, τ + = 0) 77.1 82.5</cell><cell cols="2">87.0</cell><cell>92.9</cell><cell>89.2</cell><cell>73.9</cell><cell>82.2</cell></row><row><cell></cell><cell></cell><cell cols="5">Hard (β = 2, τ + = 0) 77.4 83.6</cell><cell cols="2">86.8</cell><cell>93.4</cell><cell>88.7</cell><cell>73.5</cell><cell>82.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Classification</figDesc><table /><note>accuracy on downstream tasks. Sentence representations are learned using quick-thoughts (QT) vectors on the BookCorpus dataset and evaluated on six classification tasks. Evaluation of binary classification tasks (MR, CR, SUBJ, MPQA) uses 10-fold cross validation. 6 A CLOSER LOOK AT HARD SAMPLING 6.1 ARE HARDER SAMPLES NECESSARILY BETTER? By setting β to large values, one can focus on only the hardest samples in a training batch. But is this desirable?</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Basic statistics for graph datasets.</figDesc><table><row><cell>Dataset</cell><cell>DD</cell><cell cols="3">PTC REDDIT-B PROTEINS</cell></row><row><cell>No. graphs</cell><cell>1178</cell><cell>344</cell><cell>2000</cell><cell>1113</cell></row><row><cell>No. classes</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>2</cell></row><row><cell cols="3">Avg. nodes 284.32 14.29</cell><cell>429.63</cell><cell>39.06</cell></row><row><cell cols="3">Avg. Edges 715.66 14.69</cell><cell>497.75</cell><cell>72.82</cell></row><row><cell>Dataset</cell><cell cols="4">ENZYMES MUTAG IMDB-B IMDB-M</cell></row><row><cell>No. graphs</cell><cell>600</cell><cell>188</cell><cell>1000</cell><cell>1500</cell></row><row><cell>No. classes</cell><cell>6</cell><cell>2</cell><cell>2</cell><cell>3</cell></row><row><cell>Avg. nodes</cell><cell>32.63</cell><cell>17.93</cell><cell>19.77</cell><cell>13.00</cell></row><row><cell>Avg. Edges</cell><cell>62.14</cell><cell>19.79</cell><cell>96.53</cell><cell>65.94</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Basic statistics for graph datasets.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">Code available at: https://github.com/joshr17/HCL</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1">For a manifold M ⊆ R d , we say C ⊂ M is a ball if it is connected, and there exists a Euclidean ball B = {x ∈ R d : x</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2">≤ R} for which C = M ∩ B.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_3">https://github.com/facebookresearch/moco</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Anchor</head><p>Hard negatives Uniform negatives Figure <ref type="figure">13</ref>: Pseudocode for our proposed new hard sample objective, as well as the original NCE contrastive objective, and debiased contrastive objective. In each case we take the number of positive samples to be M = 1. The implementation of our hard sampling method only requires two additional lines of code compared to the standard objective.</p><p>We also found the annealing in the opposite direction ("down") achieved similar performance.</p><p>Bias-variance of empirical estimates in hard-negative objective: Recall the final hard negative samples objective we derive is,</p><p>This objective admits a practical counterpart by using empirical approximations to v) ]. In practice we use a fairly large number of samples (e.g. N = 510) to approximate the first expectation, and only M = 1 samples to approximate the second. Clearly in both cases the resulting estimator is unbiased. Further, since the first expectation is approximated using many samples, and the integrand is bounded, the resulting estimator is well concentrated (e.g. apply Hoeffding's inequality out-of-the-box). But what about the second expectation? This might seem uncontrolled since we use only one sample, however it turns out that the random variable X = e f (x) T f (v) where x ∼ p and v ∼ q + β has variance that is bounded by L align (f ). Lemma 11. Consider the random variable X = e f (x) T f (v) where x ∼ p and v ∼ q + β . Then Var(X) ≤ O L align (f ) .</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A theoretical analysis of contrastive unsupervised representation learning</title>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hrishikesh</forename><surname>Khandeparkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Khodak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orestis</forename><surname>Plevrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikunj</forename><surname>Saunshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conference on Machine Learning (ICML)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5628" to="5637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning representations by maximizing mutual information across views</title>
		<author>
			<persName><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Buchwalter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="15535" to="15545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Combining labeled and unlabeled data with co-training</title>
		<author>
			<persName><forename type="first">Avrim</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eleventh annual conference on Computational learning theory</title>
				<meeting>the eleventh annual conference on Computational learning theory</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="92" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A training algorithm for optimal margin classifiers</title>
		<author>
			<persName><forename type="first">Bernhard</forename><forename type="middle">E</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabelle</forename><forename type="middle">M</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth annual workshop on Computational learning theory</title>
				<meeting>the fifth annual workshop on Computational learning theory</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="144" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conference on Machine Learning (ICML)</title>
				<imprint>
			<date type="published" when="2020">2020a</date>
			<biblScope unit="page" from="10709" to="10719" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Big self-supervised models are strong semi-supervised learners</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<date type="published" when="2020">2020b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Improved baselines with momentum contrastive learning</title>
		<author>
			<persName><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04297</idno>
		<imprint>
			<date type="published" when="2020">2020c</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning a similarity metric discriminatively, with application to face verification</title>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="539" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Class-prior estimation for learning from positive and unlabeled data</title>
		<author>
			<persName><forename type="first">Marthinus</forename><surname>Christoffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="221" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Debiased Contrastive Learning</title>
		<author>
			<persName><forename type="first">Ching-Yao</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Yen-Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Support-Vector Networks</title>
		<author>
			<persName><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources</title>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on Computational Linguistics</title>
				<meeting>the 20th international conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">350</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning classifiers from only positive and unlabeled data</title>
		<author>
			<persName><forename type="first">Du</forename><surname>Marthinus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Plessis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masashi</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGKDD international conference on Knowledge discovery and data mining</title>
				<imprint>
			<date type="published" when="2008">2014. 2008</date>
			<biblScope unit="page" from="213" to="220" />
		</imprint>
		<respStmt>
			<orgName>Charles Elkan and Keith Noto</orgName>
		</respStmt>
	</monogr>
	<note>Advances in Neural Information Processing Systems (NeurIPS)</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep metric learning with hierarchical triplet loss</title>
		<author>
			<persName><forename type="first">Weifeng</forename><surname>Ge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Europ. Conference on Computer Vision (ECCV)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="269" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Noise-Contrastive Estimation: A new estimation principle for unnormalized statistical models</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvärinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conference on Artificial Intelligence and Statistics (AISTATS)</title>
				<meeting>Int. Conference on Artificial Intelligence and Statistics (AISTATS)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="297" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1735" to="1742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Smart mining for deep metric learning</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Harwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Gustavo</forename><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Drummond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conference on Computer Vision (ICCV)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2821" to="2829" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Contrastive multi-view representation learning on graphs</title>
		<author>
			<persName><forename type="first">Kaveh</forename><surname>Hassani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Hosein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khasahmadi</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conference on Machine Learning (ICML)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3451" to="3461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Data-efficient image recognition with contrastive predictive coding</title>
		<author>
			<persName><forename type="first">Aravind</forename><surname>Olivier J Hénaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><forename type="middle">De</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Fauw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName><surname>Van Den Oord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conference on Machine Learning (ICML)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6661" to="6671" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Estimating the class prior and posterior from noisy positives and unlabeled data</title>
		<author>
			<persName><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining</title>
				<meeting>the tenth ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2004">2004. 2016</date>
			<biblScope unit="page" from="2693" to="2701" />
		</imprint>
	</monogr>
	<note>Advances in Neural Information Processing Systems (NeurIPS)</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep Chakraborty, and Erik Learned-Miller. Unsupervised hard example mining from videos for improved object detection</title>
		<author>
			<persName><forename type="first">Souyoung</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aruni</forename><surname>Roychowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huaizu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Prasad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Europ. Conference on Computer Vision (ECCV)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="307" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Hard negative mixing for contrastive learning</title>
		<author>
			<persName><forename type="first">Yannis</forename><surname>Kalantidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bulent</forename><surname>Mert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noe</forename><surname>Sariyildiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Pion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diane</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName><surname>Larlus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Prannay</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Teterwak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Sarna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Maschinot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ce</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.11362</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Supervised contrastive learning</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Skip-Thought Vectors</title>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Russ R Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raquel</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanja</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3294" to="3302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Graph matching networks for learning the similarity of graph structured objects</title>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenjie</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Dullien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conference on Machine Learning (ICML)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3835" to="3845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An efficient framework for learning sentence representations</title>
		<author>
			<persName><forename type="first">Lajanugen</forename><surname>Logeswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Directional Statistics</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Mardia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jupp</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>John Wiley and Sons Ltd</publisher>
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Self-supervised learning of pretext-invariant representations</title>
		<author>
			<persName><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6707" to="6717" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Tudataset: A collection of benchmark datasets for learning with graphs</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nils</forename><forename type="middle">M</forename><surname>Kriege</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franka</forename><surname>Bause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristian</forename><surname>Kersting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petra</forename><surname>Mutzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marion</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graph Representation Learning and Beyond, ICML Workshop</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The tammes problem for n= 14</title>
		<author>
			<persName><forename type="first">Alexey</forename><forename type="middle">S</forename><surname>Oleg R Musin</surname></persName>
		</author>
		<author>
			<persName><surname>Tarasov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Experimental Mathematics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="460" to="468" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Training generative neural samplers using variational divergence minimization</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Botond</forename><surname>Cseke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryota</forename><surname>Tomioka</surname></persName>
		</author>
		<author>
			<persName><surname>Gan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="271" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Representation learning with contrastive predictive coding</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd annual meeting on</title>
				<meeting>the 42nd annual meeting on</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">271</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd annual meeting on association for computational linguistics</title>
				<meeting>the 43rd annual meeting on association for computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="115" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Demystifying contrastive self-supervised learning: Invariances, augmentations and dataset biases</title>
		<author>
			<persName><forename type="first">Senthil</forename><surname>Purushwalkam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.13916</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Schütte</surname></persName>
		</author>
		<author>
			<persName><surname>Van Der Waerden</surname></persName>
		</author>
		<title level="m">Auf welcher kugel haben 5, 6, 7, 8 oder 9 punkte mit mindestabstand eins platz? Mathematische Annalen</title>
				<imprint>
			<date type="published" when="1951">1951</date>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page" from="96" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Time-contrastive networks: Self-supervised learning from video</title>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Corey</forename><surname>Lynch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yevgen</forename><surname>Chebotar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jasmine</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Schaal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Google</forename><surname>Brain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<biblScope unit="page" from="1134" to="1141" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deep metric learning via lifted structured feature embedding</title>
		<author>
			<persName><forename type="first">Hyun</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="4004" to="4012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">CURL: Contrastive unsupervised representations for reinforcement learning</title>
		<author>
			<persName><forename type="first">Aravind</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Laskin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conference on Machine Learning (ICML)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="10360" to="10371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Stochastic class-based hard example mining for deep metric learning</title>
		<author>
			<persName><forename type="first">Yumin</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wonsik</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyoung</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="7251" to="7259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">InfoGraph: Unsupervised and semisupervised graph-level representation learning via mutual information maximization</title>
		<author>
			<persName><forename type="first">Fan-Yun</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikas</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Locality and compositionality in zero-shot learning</title>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Sylvain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linda</forename><surname>Petrini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">On the origin of number and arrangement of the places of exit on the surface of pollen-grains</title>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Merkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lambertus</forename><surname>Tammes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1930">1930</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1" to="84" />
		</imprint>
	</monogr>
	<note>Recueil des travaux botaniques néerlandais</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Contrastive Multiview Coding</title>
		<author>
			<persName><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Europ. Conference on Computer Vision (ECCV)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="770" to="786" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">What makes for good views for contrastive learning?</title>
		<author>
			<persName><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.10243</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Deep Graph Infomax</title>
		<author>
			<persName><forename type="first">Petar</forename><surname>Velickovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>William L Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devon</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><surname>Hjelm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Ellen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donna</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName><surname>Harman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Understanding contrastive representation learning through alignment and uniformity on the hypersphere</title>
		<author>
			<persName><forename type="first">Tongzhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conference on Machine Learning (ICML)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9574" to="9584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Annotating expressions of opinions and emotions in language. Language resources and evaluation</title>
		<author>
			<persName><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="165" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Sampling matters in deep embedding learning</title>
		<author>
			<persName><surname>Chao-Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><surname>Krahenbuhl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conference on Computer Vision (ICCV)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2840" to="2848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">How powerful are graph neural networks?</title>
		<author>
			<persName><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1304.5634</idno>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Learning Representations (ICLR)</title>
				<editor>
			<persName><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2013">2013. 2019</date>
		</imprint>
	</monogr>
	<note>A survey on multi-view learning</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
