<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Lei</forename><surname>Zhang</surname></persName>
							<email>leizhang@cqu.edu.cn</email>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">David</forename><surname>Zhang</surname></persName>
							<email>csdzhang@comp.polyu.edu.hk</email>
						</author>
						<author>
							<persName><surname>Zhang</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">College of Communication Engineering</orgName>
								<orgName type="institution">Chongqing University</orgName>
								<address>
									<postCode>400044</postCode>
									<settlement>Chongqing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">The Hong Kong Polytech-nic University</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D3485E4406E3044026FDC7EA779BA7AE</idno>
					<idno type="DOI">10.1109/TNNLS.2016.2607757</idno>
					<note type="submission">Manuscript received March 6, 2016; revised June 4, 2016, August 7, 2016, and August 15, 2016; accepted September 9, 2016.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T04:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Classification</term>
					<term>cost matrix</term>
					<term>cost-sensitive learning</term>
					<term>extreme learning machine (ELM)</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Conventional extreme learning machines (ELMs) solve a Moore-Penrose generalized inverse of hidden layer activated matrix and analytically determine the output weights to achieve generalized performance, by assuming the same loss from different types of misclassification. The assumption may not hold in cost-sensitive recognition tasks, such as face recognitionbased access control system, where misclassifying a stranger as a family member may result in more serious disaster than misclassifying a family member as a stranger. Though recent cost-sensitive learning can reduce the total loss with a given cost matrix that quantifies how severe one type of mistake against another, in many realistic cases, the cost matrix is unknown to users. Motivated by these concerns, this paper proposes an evolutionary cost-sensitive ELM, with the following merits: 1) to the best of our knowledge, it is the first proposal of ELM in evolutionary cost-sensitive classification scenario; 2) it well addresses the open issue of how to define the cost matrix in cost-sensitive learning tasks; and 3) an evolutionary backtracking search algorithm is induced for adaptive cost matrix optimization. Experiments in a variety of cost-sensitive tasks well demonstrate the effectiveness of the proposed approaches, with about 5%-10% improvements.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>E XTREME learning machine (ELM) was proposed by Huang et al. <ref type="bibr" target="#b0">[1]</ref> for generalized single-hidden-layer feedforward neural networks (SLFNs) in order to overcome the drawbacks of gradient-based methods, such as the local minima, learning rate, stopping criteria, and learning epochs, as Huang et al. <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b3">[4]</ref> have further provided the rigorous proof of universal approximation of ELM with much milder condition that almost any nonlinear piecewise continuous function can be used as the activation functions in hidden nodes of ELM. Different from traditional learning algorithms, ELM not only tends to reach the smallest training error but also the smallest norm of the output weights for better generalization performance of SLFN, according to the Bartlett's theory <ref type="bibr" target="#b4">[5]</ref>. The most recent advances of ELM about its biological understanding and fast deep learning perspectives can be found in <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b8">[9]</ref>.</p><p>ELM, in which the input weights and hidden biases were randomly selected and the output weights were analytically determined using Moore-Penrose generalized inverse, has also been proved to be efficient and effective for regression and classification tasks <ref type="bibr" target="#b9">[10]</ref>- <ref type="bibr" target="#b13">[14]</ref>. An excellent review of ELM can refer to as <ref type="bibr" target="#b14">[15]</ref>. However, ELM may require more hidden neurons than gradient descent algorithms due to the randomly selected input weights and hidden biases <ref type="bibr" target="#b15">[16]</ref>.</p><p>Different versions of improved ELM have been proposed. Inspired by Mercer condition, a kernel ELM (KELM) was proposed for robust classification <ref type="bibr" target="#b9">[10]</ref>. Under kernels, a sequential ELM approach <ref type="bibr" target="#b16">[17]</ref> was also proposed for online learning by using the kernel recursive least squares, an extension of kernel adaptive filtering. In addition, a recursive orthogonal least-square method combined with sequential partial orthogonalization was incorporated into ELM, which formulates a new parsimonious ELM <ref type="bibr" target="#b17">[18]</ref> and has been used for nonlinear time-series modeling. Considering that the dense weights of ELM easily lead to overfitting, a sparse Bayesian ELM <ref type="bibr" target="#b18">[19]</ref> was proposed to improve the robustness by pruning the redundant hidden neurons in learning phase, such that the model is insensitive to hidden neurons. It is known that in ELM, the hidden nodes are generally frozen, such that the learning ability may be limited. Therefore, an ELM with adaptive growth of hidden nodes was proposed in <ref type="bibr" target="#b19">[20]</ref>, and achieved automated design of networks. It was also verified that more compact network architecture can be achieved. Since ELM randomly selects the input weights and biases for feature mapping, in <ref type="bibr" target="#b15">[16]</ref>, a differential evolutionary-based ELM (E-ELM) was proposed to optimize the random input weights and tend to improve the generalization performance with compact networks. Though "evolutionary" concept is also used, essential difference between the proposed evolutionary cost-sensitive ELM (ECSELM) and E-ELM is witnessed. In particular, our proposed ECSELM is to conduct an optimal cost-sensitive learning for handling the same-loss problem supposed in ELM, but not aim at optimizing the random weights and bias addressed in E-ELM. For tackling a recognition task with imbalanced data sets that are quite common in various applications, a weighted ELM (WELM) <ref type="bibr" target="#b20">[21]</ref> is proposed, where each training sample was assigned with larger weight to strengthen the impact of minority class and smaller weight to weak the impact of majority class. Furthermore, a boosting WELM was also proposed with an AdaBoost framework for sample imbalance <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref> and a CSELM <ref type="bibr" target="#b23">[24]</ref> was proposed for sample imbalance weighting. ELM, due to its efficacy, has drawn a significant amount of interest from researchers in various fields, such as face recognition (FR) <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b24">[25]</ref>, activity recognition <ref type="bibr" target="#b25">[26]</ref>, action recognition <ref type="bibr" target="#b26">[27]</ref>, and handwritten character recognition <ref type="bibr" target="#b27">[28]</ref>.</p><p>Up to now, ELM with many variants has been widely used for classification and regression. However, all the existing ELM-based recognition methods tend to achieve lower error rate by supposing the same loss for any misclassification, which, however, may not hold in many applications, for instance, FR-based access control system, as different mistakes may lead to different losses. In particular, it would be a serious disaster if the system misclassifies a stranger as a family member and allowed to enter the room. Instead, misclassifying a family member as a stranger and not allowed to enter the room may be less serious. The different losses in an FR system have been first paid an attention by formulating a cost-sensitive classification task <ref type="bibr" target="#b28">[29]</ref>.</p><p>Subspace methods, such as principal component analysis (PCA) <ref type="bibr" target="#b29">[30]</ref>, linear discriminant analysis (LDA) <ref type="bibr" target="#b30">[31]</ref>, manifold learning-based locality preserving projections (LPP) <ref type="bibr" target="#b31">[32]</ref>, margin fisher analysis (MFA) <ref type="bibr" target="#b32">[33]</ref>, and their kernelized and tensorized variants <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref>, have been proposed. Recently, their cost-sensitive variants, such as CSPCA, CSLDA, CSLPP, and CSMFA, have also been surveyed for FR in <ref type="bibr" target="#b35">[36]</ref> and <ref type="bibr" target="#b36">[37]</ref>. Cost-sensitive learning can reduce the loss with a predefined cost matrix that quantifies how severe one type of mistake against another type of mistake, but in many realistic cases, the cost matrix is unknown or difficult to define by users <ref type="bibr" target="#b28">[29]</ref>, such that the learned subspace is not optimal with poor classification performance. Note that the misclassification loss is produced due to incorrectly classifying one sample in the i th class as the j th class. In many realistic cases, users only know that one type of mistake is more serious than another type, but it is difficult to specify a cost value of a mistake. Liu and Zhou <ref type="bibr" target="#b37">[38]</ref> first attempt to address the problem of cost matrix definition using a cost interval (CI) (e.g., a possible cost range) instead of a precise cost value, but it brings a large computational cost, and the CI should be manually predefined, such that the cost-matrix definition is still an open topic in cost-sensitive learning. Learning a cost matrix is extremely desired to be resolved for cost-sensitive system. In terms of the final classification task, a good cost matrix should not degrade the recognition accuracy. Therefore, our goal is to optimize the cost matrix for improving the final classification, where the cost-sensitive behavior is modeled.</p><p>Motivated by the above-mentioned open problems of ELM and cost-sensitive learning, an ECSELM is proposed in this paper, which on one hand brings a CSELM with the lowest misclassification loss at the first time, and simultaneously learns an optimal cost matrix automatically on the other hand during CSELM learning. To the best of our knowledge, this is the first proposal of CSELM as a new perspective. This paper is also a forward-looking work for automatic cost matrix determination. Note that the proposed method has essential difference from that of <ref type="bibr" target="#b23">[24]</ref>, which does not focus on the cost matrix learning, yet only defines the weights.</p><p>The remainder of this paper is as follows. Section II presents the related work of ELMs. The proposed ECSELM and algorithms are formulated in Section III. Experiments on multimodal data set for attractiveness prediction are employed in Section IV. Experiments on face data sets for FR and verification are conducted in Section V. Experiments on E-NOSE data set for gases recognition (GR) are presented in Section VI. The performance evaluation of classifiers is given in Section VII. The parameter sensitivity analysis is conducted in Section VIII. The complexity analysis is discussed in Section IX. Finally, Section X concludes this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. SLFN and ELM</head><p>Given N samples [x 1 , x 2 , . . . , x N ] and their corresponding targets [t 1 , t 2 , . . . , t N ], where</p><formula xml:id="formula_0">x i = [x i1 , x i1 , . . . , x in ] T ∈ R n and t i = [t i1 , t i1 , . . . , t im ] T ∈ R m , standard SLFN with L hidden nodes and activation function H(x) is modeled as L j =1 β j H w T j • x i + b j = t i , i = 1, . . . , N<label>(1)</label></formula><p>where w j = [w j 1 , . . . , w j n ] T is the input weight vector connecting the j th hidden node and the n input nodes, β j = [β j 1 , . . . , β j m ] T is the output weight vector connecting the j th hidden node and the m output nodes, and b j is the bias of the j th hidden node. In ELM <ref type="bibr" target="#b0">[1]</ref>, input weights w and hidden biases b are randomly generated independently of the training data.</p><p>The representation (1) can be written compactly as</p><formula xml:id="formula_1">H • β = T<label>(2)</label></formula><p>where</p><formula xml:id="formula_2">β = [β 1 , β 2 , . . . , β L ] T , T = [t 1 , t 2 , . . . , t N ]</formula><p>T , H N×L is the hidden layer output matrix, and the i th column of H is the output of the i th hidden neuron with respect to inputs x 1 , x 2 , . . . , x N . Finding the minimum norm least square solution of the linear system (2) is equivalent to train an SLFN. When the number of hidden neurons L = N, H is a square matrix and invertible. However, in most cases, the number L N, and H is nonsquare, and therefore, the minimum norm least square solution can be solved as</p><formula xml:id="formula_3">β = H † T<label>(3)</label></formula><p>where H † is the Moore-Penrose generalized inverse of H.</p><p>ELM <ref type="bibr" target="#b0">[1]</ref> is to minimize the training error and the 2 -norm of the output weights, which can be formulated as</p><formula xml:id="formula_4">min L ELM = 1 2 β 2 + C • 1 2 • N i=1 ξ i 2 s.t. : H(x i )β = t i -ξ i , i = 1, . . . , N<label>(4)</label></formula><p>where C is the regularization parameter and ξ i denotes the residual of prediction. As described in <ref type="bibr" target="#b0">[1]</ref> and <ref type="bibr" target="#b9">[10]</ref>, by solving problem (4), the output weights can be easily and analytically determined as</p><formula xml:id="formula_5">β = H † T = ⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩ H T I C + HH T -1 T, N &lt; L I C + H T H -1 H T T, N ≥ L (<label>5</label></formula><formula xml:id="formula_6">)</formula><p>where I is an identity matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Kernel ELM</head><p>One can apply Mercer's condition on ELM and formulate a KELM <ref type="bibr" target="#b9">[10]</ref>. A kernel in ELM is defined as</p><formula xml:id="formula_7">ELM = HH T (6)</formula><p>where ELMi,</p><formula xml:id="formula_8">j = H(x i ) • H(x j ) = K (x i , x j ).</formula><p>Then, for the case where the number of training samples is not huge (i.e., N &lt; L), the output of KELM classifier <ref type="bibr" target="#b5">(6)</ref> with respect to the input x can be represented as</p><formula xml:id="formula_9">y = H (x) H T I C +HH T -1 T = ⎡ ⎢ ⎣ K (x, x 1 ) . . . K (x, x N ) ⎤ ⎥ ⎦ T I C + ELM -1</formula><p>T.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Weighted ELM</head><p>The WELM was proposed to address the problem of imbalanced samples <ref type="bibr" target="#b20">[21]</ref>. In contrast to the ELM, a constant weight matrix W associated with the number of each class is embedded in the objective function. Therefore, the optimization problem can be rewritten as</p><formula xml:id="formula_11">min L WELM = 1 2 β 2 + C • W • 1 2 • N i=1 ξ i 2 s.t. : H(x i )β = t i -ξ i , i = 1, . . . , N.<label>(8)</label></formula><p>In general, each training sample was assigned with larger weight to strength the impact of minority class and smaller weight to weak the majority class. In particular, two WELM schemes called as W 1 ELM and W 2 ELM were given</p><formula xml:id="formula_12">W 1 ELM : W cc = 1 # Class c (9) W 2 ELM : W cc = ⎧ ⎪ ⎨ ⎪ ⎩ 0.618 #Class c , if #Class c &gt; AVG(#Class c) 1 #Classc , otherwise. (<label>10</label></formula><formula xml:id="formula_13">)</formula><p>where #Class c is the number of samples belonging to class c and AVG(#Class c) is the average number. Notably, 0.618 denotes the golden ratio <ref type="bibr" target="#b20">[21]</ref>. New trend on ELM is referred as <ref type="bibr" target="#b38">[39]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED APPROACHES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Cost-Sensitive Extreme Learning Machine</head><p>Cost-sensitive learning is an important topic in machine learning. However, CSELM is first proposed as a new perspective for ELMs. In the proposed approach, a cost matrix specifying different costs with respect to different types of misclassification is integrated into the popular ELM, such that the proposed CSELM can be adapted to cost-sensitive learning tasks and scenarios.</p><p>The cost matrix M of N samples can be represented as</p><formula xml:id="formula_14">M = ⎡ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎣ 0 M 12 • • • M 1q • • • M 1N M 21 0 • • • M 2q • • • M 2N . . . . . . . . . . . . • • • . . . M q1 M q2 • • • 0 • • • M q N . . . . . . • • • . . . . . . . . . M N1 M N2 • • • M Nq • • • 0 ⎤ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎦ N×N (<label>11</label></formula><formula xml:id="formula_15">)</formula><p>where M i, j denotes the misclassification loss that classifies the i th sample as the j th sample, and the diagonal elements of zero denote the correct classification without loss. Then, the proposed CSELM for recognition and regression is shown as</p><formula xml:id="formula_16">min L CSELM = 1 2 β 2 + C • diag(B) • 1 2 • N i=1 ξ i 2 s.t. : H(x i )β = t i -ξ i , i = 1, . . . , N (<label>12</label></formula><formula xml:id="formula_17">)</formula><p>where B is a cost information vector with entries B i = j (W • M) i j and W N×N is a diagonal weighted matrix assigned for each training sample whose coefficient can be calculated as <ref type="bibr" target="#b8">(9)</ref>, such that the cost information vector B on the error term is also an effective tradeoff between the samples' imbalance and the misclassification loss. Note that there is essential difference between (8) and <ref type="bibr" target="#b11">(12)</ref>, in that a constant matrix W in (8) is simply calculated in terms of the sample number, while in <ref type="bibr" target="#b11">(12)</ref>, we seriously consider the misclassification loss by an unsolved cost information vector B in cost-sensitive tasks. Therefore, the learning of M is a key part of CSELM. t i and ξ i denote the label vector and error vector with respect to the sample x i , for multiclass recognition. If x i belongs to the cth class, the cth position of t i is set as 1, and -1 otherwise.</p><p>With a fixed B, the representation ( <ref type="formula" target="#formula_16">12</ref>) is a convex optimization problem, which can be solved as</p><formula xml:id="formula_18">L CSELM (β, ξ i , α i ) = 1 2 β 2 + C • diag(B) • 1 2 • N i=1 ξ i 2 -α i • (H(x i )β -t i + ξ i ) (<label>13</label></formula><formula xml:id="formula_19">)</formula><p>where α i is the Lagrange multiplier.</p><p>To derive the output weights, we calculate the derivatives of L CSELM with respect to β, ξ i , α i as follows:</p><formula xml:id="formula_20">⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩ ∂L(β, ξ i , α i ) ∂β = 0 → β = H T α ∂L(β, ξ i , α i ) ∂ξ i = 0 → α i = C • diag(B) • ξ i , i = 1, . . . , N ∂L(β, ξ i , α i ) ∂α i = 0 → H(x i )β -t i +ξ i , i = 1, . . . , N. (<label>14</label></formula><formula xml:id="formula_21">)</formula><p>Then, the output weights associated with B can be solved as</p><formula xml:id="formula_22">β B = H † T = ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ H T • I C +diag (B) HH T -1 • diag(B) • T, N &lt; L I C +H T diag(B)H -1 • H T • diag(B) • T, N ≥ L (<label>15</label></formula><formula xml:id="formula_23">)</formula><p>where H † is the Moore-Penrose generalized inverse of H, which can be represented as</p><formula xml:id="formula_24">H = ⎡ ⎢ ⎢ ⎢ ⎣ H(w 1 x 1 + b 1 ) H(w 2 x 1 + b 2 ) • • • H(w L x 1 + b L ) H(w 1 x 2 + b 1 ) H(w 2 x 2 + b 2 ) • • • H(w L x 2 + b L ) . . . . . . . . . . . . H(w 1 x N + b 1 ) H(w 2 x N + b 2 ) • • • H(w L x N + b L ) ⎤ ⎥ ⎥ ⎥ ⎦ . (<label>16</label></formula><formula xml:id="formula_25">)</formula><p>In this paper, the "radbas" function is empirically used as the feature mapping (activation) H(•), which is shown as</p><formula xml:id="formula_26">H(w, b, x) = exp(-w • x + b 2 ). (<label>17</label></formula><formula xml:id="formula_27">)</formula><p>Accordingly, sigmoid, Laplacian, and polynomial function can also be used as a hidden layer activation function.</p><p>The output z of a test instance y can be solved with two cases of small sample and huge samples, respectively, as</p><formula xml:id="formula_28">z = H(y) • β B = ⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩ H(y) • H T • I C + diag(B HH T ) -1 • diag(B) • T, N &lt; L H(y) • I C + H T diag(B)H -1 • H T • diag(B) • T, N ≥ L. (<label>18</label></formula><formula xml:id="formula_29">)</formula><p>Similarly, the kernel version of ECSELM can also be introduced as <ref type="bibr" target="#b5">(6)</ref>. In the testing process of multiclass classification, one can then declare the predicted label of test instance y as</p><formula xml:id="formula_30">ĉ = arg max c∈{1,...,k} {z ∈ R k |z = H(y) • β B } c (<label>19</label></formula><formula xml:id="formula_31">)</formula><p>where k denotes the number of classes. Notably, it can be figured out from ( <ref type="formula" target="#formula_22">15</ref>) and ( <ref type="formula" target="#formula_28">18</ref>) that the output weight and the final decision have dependency on the cost information vector B, which can be calculated by the weighting matrix W and the cost matrix M jointly, and hence, the next step is to solve the cost information vector B instead of the cost matrix and the weighting matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Evolutionary CSELM</head><p>The ECSELM introduces evolutionary search into the framework of CSELM for cost matrix optimization. As we mentioned before, the cost matrix is generally determined in an empirical way, which may easily lead to poor generalization performance for cost-sensitive tasks. To address this problem, the cost matrix is also at the first time to be automatically optimized by an evolutionary algorithm (EA). On the basis</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 ECSELM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input:</head><p>The training set {x i } N i=1 , the training target matrix T. Initialize: the weighting matrix W and cost matrix M. Procedure: 1. Randomly select input weights w and hidden biases b.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Compute the cost information vector B with</head><formula xml:id="formula_32">B i = j (W • M) i j .</formula><p>3. Compute the hidden layer output matrix H of training set and the feature mapping H (y) using ( <ref type="formula" target="#formula_24">16</ref>) and ( <ref type="formula" target="#formula_26">17</ref>). 4. Compute the output weights β B using (15). 5. Obtain the optimal B * by solving the optimization problem (21) using Algorithm 2. 6. Compute the optimal output weights β B * by substituting B * to <ref type="bibr" target="#b14">(15)</ref>.</p><formula xml:id="formula_33">Output: β B * .</formula><p>of the CSELM, the ECSELM is to find the optimal cost matrix M, which makes a better prediction through the output weights β M with respect to M, such that the total loss between the predicted value and the ground truth reaches the minimum as follows:</p><formula xml:id="formula_34">min M i L{t i , f CSELM (x i , β M )} s.t. l 1 ≤ M i, j ≤ l 2 , M i,i = 0 i = 1, . . . , N; j = 1, . . . , N<label>(20)</label></formula><p>where l 1 and l 2 are the low and upper bounds, N is the number of training samples, L is the classification or regression loss function, t i is the label vector of sample x i , and f CSELM denotes the proposed CSELM decision function. However, it can be found that the output weight matrix β, as shown in <ref type="bibr" target="#b14">(15)</ref>, is associated with B, which is indeed calculated by multiplying an unknown/known weighted matrix W with the unknown cost matrix M. For convenience, the optimization problem <ref type="bibr" target="#b19">(20)</ref> seeking for M can thus be intuitively transformed as the following:</p><formula xml:id="formula_35">B * = arg min B i L{t i , f CSELM (x i , β B )} s.t. l 1 ≤ B i ≤ l 2 (<label>21</label></formula><formula xml:id="formula_36">)</formula><p>where l 1 and l 2 are the new bounds. By solving <ref type="bibr" target="#b20">(21)</ref>, i.e., the optimization of the CSELM classifier/predictor model in decision level, the optimal output weight matrix β B * can be obtained simultaneously with respect to the optimal cost information vector B * .</p><p>Then, the predicted output in decision level of test instance y can be represented as</p><formula xml:id="formula_37">ĉ = arg max c∈{1,...,k} {z ∈ R k |z = H(y) • β B * }. (<label>22</label></formula><formula xml:id="formula_38">)</formula><p>The proposed ECSELM is summarized in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Optimization</head><p>To find the optimal B, EA is employed intuitively under the only boundary constraint. EA is a population-based stochastic search strategy that search for near-optimal solutions. EA tries to evolve an individual into a new individual with better fitness by a trial individual, which can be generated using various genetic operators on the raw individuals, such that ongoing new effort is made on EA. In this paper, we leverage a new EA, i.e., backtracking search optimization algorithm (BSA) structured in <ref type="bibr" target="#b39">[40]</ref> to learn the cost matrix simultaneously. BSA, as a random search method with three basic genetic operators: selection, mutation, and crossover used to generate trial individuals, has a simple structure, such that it is effective, fast, and capable of solving multimodal problems. It can be briefly described as four stages in implementation: initialization, selection-I, recombination, and selection-II. For details, the basic steps of BSA are formulated as follows.</p><p>1) Initialization: Generation and evaluation of a population</p><formula xml:id="formula_39">P P i, j ∼ U l j d , l j u , i = 1, . . . , N; j = 1, . . . , D (23) F i = ObjFun i (P i ), i = 1, . . . , N (<label>24</label></formula><formula xml:id="formula_40">)</formula><p>where P is encoded by the solution form of B, N and D denote the population size and problem dimension, l j d and l j u denote the low and upper bounds with respect to the j th element, U denotes uniform distribution, and ObjFun(•) denotes the objective function <ref type="bibr" target="#b20">(21)</ref>.</p><p>1) Selection-I: Update step for historical population Q</p><formula xml:id="formula_41">Q i, j ∼ U l j d , l j u (25) if a &lt; b then Q = P ∀a, b ∼ U (0, 1)<label>(26)</label></formula><formula xml:id="formula_42">Q = permuting(Q) (<label>27</label></formula><formula xml:id="formula_43">)</formula><p>where permuting(•) is a random shuffling function and a and b are two random number of uniform distribution. The historical population is for memory characteristics. 2) Recombination: Update step for solution population P new Binary mapping matrix C N×D |0 -1 (28)</p><formula xml:id="formula_44">P new = P + 3r • C (Q -P) (29) P new(i, j ) = ⎧ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎩ l j d , if rand 1 &lt; rand 2 and P new(i, j ) &lt; l j d rand × l j u -l j d + l j d , otherwise l j u , if rand 1 &lt; rand 2 and P new(i, j ) &gt; l j u rand × (l j u -l j d + l j d , otherwise<label>(30)</label></formula><p>where P new(i, j ) represents the j th element of the i th individual, denotes dot product, r ∼ N(0,1), rand 1 , and rand 2 ∼U(0,1), and N(0,1) denotes standard normal distribution. Then, evaluate the new population by computing</p><formula xml:id="formula_45">F i = ObjFun i P new {i }), i = 1, . . . , N<label>(31)</label></formula><p>where P new {i } denotes the i th individual of the population. </p><formula xml:id="formula_46">P new = P new F i &lt; F i P F i ≥F i i = 1, . . . , N (32) F g min = min F F i ≥ F i F F i &lt; F i i = 1, . . . , N<label>(33)</label></formula><formula xml:id="formula_47">G opt = P new ind opt |ind opt = min F F i ≥F i F F i &lt; F i (<label>34</label></formula><formula xml:id="formula_48">)</formula><p>where ind opt denotes the index of the optimal individual. In particular, the proposed ECS framework for problem solution is summarized in Algorithm 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. HUMAN BEAUTY DATA ANALYSIS</head><p>Human beauty analysis is an emerging subject in computer vision and biometric community. Ancient Greek scholars measure the vertical and horizontal distances among eyes, nose, mouth, and so on, and propose some general rules, such as golden ratio, to evaluate the attractiveness of faces. Facial attractiveness assessment using geometric and appearancebased features coupled with pattern recognition techniques has been studied separately <ref type="bibr" target="#b40">[41]</ref>- <ref type="bibr" target="#b43">[44]</ref>. We explore human beauty analysis in this paper, because it is recognized as a costsensitive learning task <ref type="bibr" target="#b44">[45]</ref>, and, therefore, used to evaluate the proposed method.</p><p>Recently, a public multimodality beauty (M 2 B) database, which includes three sub data sets: facial images, dressing images, and vocal data, of female persons from eastern and  western cultural races has been released online for human beauty study <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b46">[47]</ref>. In this section, we will exploit the proposed ECSELM method on the M 2 B database for facial, dressing, and vocal attractiveness assessment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. M 2 B Database</head><p>In the M 2 B database, the facial, dressing, and vocal features were from 620 eastern females (i.e., Chinese, Korean, and Japanese) and 620 western females (i.e., Caucasian, consisting of Angles, Celtic, Latin, and Germanic). For facial beauty analysis, geometric (denoted as "G") and appearance (denoted as "A")-based features were studied separately. The specific details of facial, dressing, and vocal feature extraction methods and the attractiveness score acquisition in different modalities can be found in <ref type="bibr" target="#b45">[46]</ref>. The facial, dressing, and vocal features with 300, 300, and 50 dimensions after PCA reduction were used. Some examples of facial images of eastern and western females with landmark points and some examples of dressing images have been shown in Figs. <ref type="figure" target="#fig_0">1</ref> and<ref type="figure" target="#fig_1">2</ref>, respectively. We observe from Fig. <ref type="figure" target="#fig_0">1</ref> that the facial images in the M 2 B database contain abrupt features, such as illumination, poses, occlusions, and expressions. These features also contribute to facial attractiveness; while in existing work, only fontal faces with restricted setting were used in facial beauty analysis. The attractiveness scores (ground truth) of facial, dressing, and vocal features for each person were normalized within <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b9">10]</ref> from k-wise ratings of raters <ref type="bibr" target="#b45">[46]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Parameters Setting</head><p>In experiments, two parameters L and C are involved in ECSELM. The number L of hidden neurons is selected from 100 to 500, and the penalty parameter C is selected from 2 0 to 2 30 . The parameter sensitivity of the algorithms is explored in Section VIII by changing the C value and the number L for presenting the best results. In optimization, both the maximum population size and the search epochs are set as 100, and the lower and upper boundary is set as -1 and 1, respectively.</p><p>Notably, the population size and epochs can be accordingly adjusted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Attractiveness Assessment: Beauty Recognition</head><p>To qualitatively evaluate the beauty, the raw attractiveness scores within <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b9">10]</ref> for facial, dressing, and vocal features have been divided into five levels of 1 (1-2), 2 (2-4), 3 (4-6), 4 (6-8), and 5 <ref type="bibr" target="#b7">(8)</ref><ref type="bibr" target="#b8">(9)</ref><ref type="bibr" target="#b9">(10)</ref>, which correspond to the beauty quality of "poor," "fair," "good," "very good," and "excellent," respectively. In experiment, the attractiveness assessment of eastern (denoted as "E") and western (denoted as "W ") females is studied separately. A total of 400 females are randomly selected as training set, and the remaining 220 females are determined as testing set. Then, we run each procedure ten times under each experiment, and the average rank-1 recognition accuracy (i.e., the ratio between the number of correctly recognized samples and the number of total testing samples) and the standard deviation for each method have been provided. The compared methods are divided into three categories.</p><p>1) The comparisons with ELM-based methods, including basic ELM, KELM, W 1 ELM, W 2 ELM, and E-ELM, are explored.</p><p>2) The comparisons with subspace methods and their cost-sensitive extensions, including CSPCA, CSLDA, CSLPP, and CSMFA, are presented.</p><p>3) The comparisons with generic classifiers, including k-nearest neighbors (kNNs), support vector machine (SVM), and least square SVM (LSSVM), are provided. We also compare with CISVM <ref type="bibr" target="#b37">[38]</ref>, which was first proposed for addressing the cost-sensitive matrix problem using CI. In addition, we have compared a cost-sensitive ordinal regression (CSOR) <ref type="bibr" target="#b44">[45]</ref> that is used for facial beauty. The rank-1 recognition results of human attractiveness using ELM-based methods are presented in Table <ref type="table" target="#tab_1">I</ref>, from which we find that the recognition rate obtained by ECSELM for each task is about 10% higher than other ELMs. The appearancebased features ("A") outperform geometric feature ("G") in attractiveness assessment. The reason may be that the faces contain different types of abrupt features, such as illumination, poses, color, texture, and so on. The results of costsensitive subspace methods, e.g., CSPCA, CSLDA, CSLPP, and CSMFA, are shown in Table <ref type="table" target="#tab_1">II</ref>, from which we can find that the ECSELM still outperforms other subspace learning methods.</p><p>Table <ref type="table" target="#tab_3">III</ref> presents the comparisons with the generic classifiers (e.g., kNN, SVM, and LSSVM) and two cost-sensitive methods (e.g., CISVM and CSOR). The number of NNs is empirically set as 30. We can observe that the following holds.</p><p>1) For different tasks, CISVM seems to be worse than other methods. The reason may be that CISVM tends to address the problem of cost matrix using CI instead of a precise cost value, but CI is still predefined and task-dependent. In addition, the training complexity of SVM increases, depending on the specific size of the CI.    2) Though CSOR is improved compared with SVM by introducing cost-sensitive element, the cost matrix construction is prior defined and lack of flexible property for different tasks and new environments. 3) ECSELM performs the best recognition accuracy with an approximate 10% improvement. In attractiveness assessment of five levels, the cumulative score, measured in recognition <ref type="bibr" target="#b47">[48]</ref>- <ref type="bibr" target="#b51">[52]</ref>, is also used to evaluate the proposed methods. The cumulative score can be defined as CumScore(ϑ) = N e≤ϑ /N test × 100% <ref type="bibr" target="#b34">(35)</ref> where ϑ denotes the tolerated error level and N e≤ϑ denotes the number of testing instances whose absolute error e is between the predicted label and the true label less than ϑ (ϑ = 0, 1, 2, . . . , k -1). N test denotes the number of total testing instances and k is the class number. Cum Score(0) denotes the rank-1 recognition. The CumScore curves by using ELM and subspace-based methods have been shown in Figs. <ref type="figure" target="#fig_2">3</ref><ref type="figure">4</ref><ref type="figure">5</ref>, from which we can see that the proposed ECSELM shows the best performance. Besides, the attractiveness score estimation and further comparisons with the NN, ridge regression, neural network, dual-supervised feature-attribute-task (DFAT) <ref type="bibr" target="#b45">[46]</ref>, and latent DFAT (LDFAT) <ref type="bibr" target="#b46">[47]</ref> methods are exploited by strictly following <ref type="bibr" target="#b45">[46]</ref> with a standard twofold cross-validation test in experiments. The cross-validation process is repeated ten times, and the average value is presented to be the final results. In estimation of the attractiveness scores, which is  The results of facial, dressing, and vocal attractiveness score estimation are shown in Table <ref type="table" target="#tab_5">IV</ref>. Some results other than ELM methods are simply copied from <ref type="bibr" target="#b45">[46]</ref> and <ref type="bibr" target="#b46">[47]</ref>. The proposed ECSELM shows a competitive performance by comparing with the state-of-the-art LDFAT. Comparatively, vocal attractiveness score prediction is better than dressing and facial attractiveness prediction. To study the aesthetic difference between cultures or races, we have conducted the cross culture experiment, that is, we learn a model from the one culture and tests on the other culture, denoted as E → W and W → E, alternatively. The results of between-culture are shown in Table <ref type="table" target="#tab_5">V</ref>, from which, we can find that the ECSELM shows the lowest MAE for prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. FACE DATA ANALYSIS</head><p>In this section, we conduct FR and face verification experiments using the proposed methods. This section aims at testing the usefulness of the proposed methods, while the comparisons with those FR methods are not concentrated, because this paper is not specifically presented for FR. We test on two benchmark face data sets: AR face database <ref type="bibr" target="#b49">[50]</ref> that contains the faces of 100 persons (50 males and 50 females) and the challenging labeled faces in the wild (LFW) <ref type="bibr" target="#b52">[53]</ref> that consists of 13 233 images of 5749 people in unrestricted environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experiment on AR Data Set</head><p>We follow the same experimental setting as <ref type="bibr" target="#b51">[52]</ref> in which seven facial images per person from session 1 with illumination and expression changes were used for training and the other seven images per person with the same condition from session 2 were used for testing. Eigenface <ref type="bibr" target="#b53">[54]</ref> with 300 dimensions after PCA is used as feature in experiment. For fair comparisons, we follow the same train/test split for all methods.</p><p>We have compared the proposed evolutionary cost-sensitive methods with generic classifiers, such as NN, nearest subspace and linear SVM, cost-sensitive subspace analysisbased methods (e.g., CSPCA, CSLPP, CSMFA, and CSLDA), and ELM-based methods (e.g., ELM, KELM, WELM, and E-ELM). In addition, three specialized cost sensitive FR methods, including multiclass cost-sensitive </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RECOGNITION RATE (%) OF ELM AND COST-SENSITIVE SUBSPACE-BASED METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE VII COMPARISONS WITH BASELINES AND STATE-OF-THE-ART COST-SENSITIVE FRS</head><p>kNN (mckNN) <ref type="bibr" target="#b28">[29]</ref>, multiclass cost-sensitive SVM (mcSVM) <ref type="bibr" target="#b54">[55]</ref>, and multiclass cost-sensitive kernel logistic regression (mcKLR) <ref type="bibr" target="#b28">[29]</ref>, are also compared in this paper. The kernel case of ECSELM is considered in FR application. Some baseline results are from the literature <ref type="bibr" target="#b51">[52]</ref>.</p><p>The results of the ELM with penalty coefficient C = 2 5 and subspace-based methods are presented in Another merit of ECSELM is that, it can predict the label of a given instance intuitively without using multiclass voting mechanism addressed in SVM. Note that the result of CISVM is not given, because there is no report for its use in FR. With rigorous consideration, we have downloaded their released codes of CISVM and run the codes on AR data. The obtained recognition accuracy is approximately 28%. Furthermore, the CumScore curves with error level ϑ change from 0 to 99 (100 classes in AR) Fig. <ref type="figure">6</ref>. CumScore curves of all the methods. Fig. <ref type="figure">7</ref>. Sample images of one "the same" pair and one "not the same" pair from LFW. are described in Fig. <ref type="figure">6</ref>, which clearly demonstrates that the proposed CSELM and ECSELM outperform other methods for FR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experiment on LFW Data Set</head><p>In this section, we evaluate our methods on the LFW data set, which is commonly regarded as a challenging data set for unrestricted face verification and matching in the wild, since the faces taken from Yahoo! News show large variations in pose, illumination, expression, age, and so on. Two pairs of faces are shown in Fig. <ref type="figure">7</ref>. The data set is organized into two views.</p><p>1) In view 1, a set consisting of 2200 pairs for training and 1000 pairs for testing is developed for model selection. 2) In view 2, 6000 pairs for tenfold cross validation are developed. In each fold, 600 pairs with 300 similar pairs and 300 dissimilar pairs are contained. Note that the experimental setup for face verification is different from the standard FR that fair pairs are given and the decision on each pair is generally made as "the same" (positive pair) or "not the same" (negative pair) without knowing the identity information of each person.</p><p>For this data set, the state-of-the-art metric learning methods <ref type="bibr" target="#b55">[56]</ref>, <ref type="bibr" target="#b56">[57]</ref> are generally explored over intrapersonal subspace instead of the generic classifiers (e.g., SVM). To make the proposed methods applicable in LFW, the feature vector that can reflect the similarity information is set for each pair. We do the experiments by following the standard protocol of LFW, and the experimental setup is presented as follows.</p><p>For face feature extraction, two kinds of feature descriptors, i.e., local binary patterns and scale invariant feature transformation (SIFT), are used, respectively. Each face is then represented as a 300-D vector after PCA <ref type="bibr" target="#b55">[56]</ref>. Due to the lack of full class label information, for evaluating the proposed methods in this scenario, we represent a face pair using five similarity metrics: correlation coefficient, Euclidean distance, cosine distance, Mahalanobis distance, and bilinear similarity function with positive semidefinite matrix learned in <ref type="bibr" target="#b55">[56]</ref>. Hence, a 5-D vector is formulated to represent each similar/dissimilar pair, and a binary classifier is trained using our proposed methods. Following the tenfold cross-validation protocol for performance evaluation on view 2, the mean verification accuracies of tenfold are reported.</p><p>The results of ELMs and cost-sensitive subspace methods are reported in Table <ref type="table" target="#tab_8">VIII</ref>, from which we can observe that the following holds. 1) ELM-based methods outperform the subspace methods regularly with similar effect in AR experiments. Nevertheless, the standard deviations of ELMs are higher than others. The possible reason is that the hidden layer output matrix of ELM is activated with randomly generated weights and bias. 2) CSMFA shows the worst face verification performance among all the methods. The possible reason is that the constructed locality graph using kNNs of each input sample fails on the LFW database consisting of many face pairs, such that the intrasample information is lost.</p><p>3) The proposed ECSELM outperforms other methods by comparing with cost-sensitive subspace methods and conventional ELM methods.</p><p>Furthermore, we compare our ECSELM with several stateof-the-art metric learning methods, such as side informationbased linear discriminant analysis <ref type="bibr" target="#b57">[58]</ref>, keep it simple and straightforward metric learning <ref type="bibr" target="#b58">[59]</ref>, cosine similarity metric learning (CSML) <ref type="bibr" target="#b59">[60]</ref>, information theoretic metric learning <ref type="bibr" target="#b60">[61]</ref>, logistic discriminant metric learning <ref type="bibr" target="#b61">[62]</ref>, distance metric learning with eigenvalue <ref type="bibr" target="#b62">[63]</ref>, large margin local metric learning (LMLML) <ref type="bibr" target="#b56">[57]</ref>, and similarity metric learning over subspace (SubSML) <ref type="bibr" target="#b55">[56]</ref>, which have been well tested on LFW. The comparison results are shown in Table <ref type="table" target="#tab_9">IX</ref>, from which we have following observations. 1) Among the metric learning methods, SubSML shows the best performance on both feature descriptors, which reflects the effect of Mahalanobis distance metric and bilinear function in SubSML. Notably, the results of CSML and LMLML on SIFT are not given, because they were not reported in <ref type="bibr" target="#b56">[57]</ref> and <ref type="bibr" target="#b59">[60]</ref>. 2) Our proposed ECSELM performs significantly the best recognition among the state-of-the-art metric learning methods for both descriptors. Besides, a new prospective that group metrics can be integrated as input features for face verification by learning a binary classifier.</p><p>VI. E-NOSE DATA ANALYSIS E-NOSE is a multisensor system comprised of a sensor array with partial specificity coupled with pattern recognition algorithm <ref type="bibr" target="#b63">[64]</ref>, which can also be recognized as cost-sensitive problem. In this section, we will explore the proposed methods on E-NOSE database for new application of GR, and validate the generality of the proposed methods in cost-sensitive recognition task. The E-NOSE database is prepared based on six kinds of gases (i.e., six classes problem), such as formaldehyde (HCHO), benzene (C 6 H 6 ), toluene (C 7 H 8 ), carbon monoxide (CO), ammonia (NH 3 ), and nitrogen dioxide (NO 2 ) in <ref type="bibr" target="#b64">[65]</ref>- <ref type="bibr" target="#b66">[67]</ref>. The number of samples for each gas is 188, 72, 66, 58, 60, and 38, respectively. The steady state response of each sensor is extracted as feature, and a feature vector is formulated as one sample. Two thirds of samples per class randomly selected as training set. The rank-1 recognition of each class, average recognition rate (ARR), and total recognition rate (TRR) are computed. Notably, ARR is the ratio of the summation of all recognition rates and class number, while TRR is the ratio between the number of correctly classified samples for all classes and the total number of samples. The comparisons with ELM methods, subspace methods, and existing methods are conducted. The rank-1 recognition results of ELM-based methods and subspace-based learning methods coupled with the NN classifier are presented in Table <ref type="table" target="#tab_9">X</ref>, from which we observe that ECSELM performs the best recognition performance with 97.17% of ARR and 98.15% of TRR.</p><p>For comparison with existing methods in E-NOSE classification, we have conducted the experiments using several popular methods, such as SVM, LDA, partial least squarediscriminant analysis (PLS-DA), and their kernel extensions, e.g., kernel SVM, kernel LDA, and kernel PLS-DA in Table <ref type="table" target="#tab_10">XI</ref>, which also clearly demonstrates that the proposed  CSELM and ECSELM methods show the best performance. In addition, LDA and SVM methods after PCA preprocessing (i.e., PCA-LDA and PCA-SVM) are also compared. Note that the one-against-one scheme is used in SVM-and LDA-based methods.</p><p>From a variety of applications, the generality of the proposed methods is effectively revealed in preliminary, though more tests in large-scale databases can be done to make an effort on the potential of the proposed methods. From the perspective of algorithm, the complexity, computational cost, and the convergence of the proposed approach are optimistic. ELM is popular due to their fast computation and good effectiveness. ECSELM is proposed under an evolutionary costsensitive learning framework. EAs are widely used to solve different types of optimization problems for their rapid search in the whole solution space with heuristic and bioinspired update strategies <ref type="bibr" target="#b67">[68]</ref>, <ref type="bibr" target="#b68">[69]</ref>, but EAs do not guarantee finding the global optimum solution for a problem. However, EA has global exploration in the entire search space and local exploitation abilities to find the best solution near a new solution it has discovered <ref type="bibr" target="#b69">[70]</ref>, <ref type="bibr" target="#b70">[71]</ref>. In this paper, the instinct optimization involves three bioinspired genetic operators, i.e., mutation, crossover, and selection. The optimal or near-optimal solutions of the proposed methods can be obtained with finite iterations and a low computational cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. PERFORMANCE EVALUATION OF CLASSIFIERS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. ROC, AUC, and Confusion Matrix Analysis</head><p>The performance of different methods has also been analyzed by using Receiver Operating Characteristic (ROC) curve, Area under ROC Curve (AUC), and confusion matrix on three data sets, such as LFW face data, M 2 B data, and E-NOSE data. LFW data are recognized to be a binary classification task, and therefore, ROC and AUC are presented in Fig. <ref type="figure">8</ref>, from which we can observe that the proposed ECSELM method outperforms other methods.</p><p>The E-NOSE and M 2 B data are used as multiclassification tasks, such that the confusion matrix is used for validating the cost-sensitive classification performance, which is shown in Figs. 9 and 10, respectively. The confusion </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Statistical Significance</head><p>In this paper, we apply the popular t-test and nonparametric Kruskal-Wallis method for statistical significance test of nine different methods on multiple test data sets <ref type="bibr" target="#b71">[72]</ref> in a pairwise manner. The summarized recognition results are shown in Table <ref type="table" target="#tab_11">XII</ref>. Two variables H and p are computed using t-test on the results from each pair of classifiers, where p denotes the probability of observing the given results, H = 1 denotes that the null hypothesis is rejected, and H = 0 denotes that the null hypothesis cannot be rejected. The test results are   shown in Table <ref type="table" target="#tab_12">XIII</ref>, from which we can clearly observe that the proposed ECSELM method statistically outperforms other methods at the significant level = 5%. The Kruskal-Wallis test can also demonstrate the statistical significance of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PARAMETER SENSITIVITY ANALYSIS</head><p>In the proposed model, there is only one model parameter, i.e., the tradeoff coefficient For different data sets, the parameter variation may show different performance. So, we use different C values from the set {2 0 , 2 5 , 2 10 , 2 20 , 2 30 }. Fig. <ref type="figure" target="#fig_6">11</ref> shows the performance variations with different penalty coefficient C on FR, LFW, and E-NOSE data, from which we see that our method and standard ELM are not sensitive to the tradeoff parameter variation, and better performance for AR, LFW, and E-NOSE can be obtained when C is set as 2 5 , 2 10 , and 2 20 , respectively. Notably, WELM is denoted by W 2 ELM.</p><p>In addition, we also studied the performance variation with different numbers of hidden neurons, i.e., L.</p><p>By fixing the best C for each data, we select L from the set {100, 200, 300, 400, 500}, and run the ELMs in FR, LFW, and E-NOSE data. The results are shown in Fig. <ref type="figure" target="#fig_7">12</ref>, from which we observe that the there is no large performance variation of the proposed method with respect to L, while the performance of ELM drops dramatically for LFW and E-NOSE data analysis when L is larger than 200. So, the best L for AR, LFW, and E-NOSE can be set as 300, 100, and 200, respectively. The hidden layer output matrix of KELM calculated by training samples through a kernel mapping is not associated with L, so the recognition rate of KELM is unchanged. We see that the proposed method is more robust to the variation of model parameter and hidden neurons. Note that E-ELM introduces the differential evolutionary method for optimizing the random weights and bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IX. COMPUTATIONAL COMPLEXITY AND TIME ANALYSIS</head><p>The proposed algorithms are computationally efficient. For ECSELM, the main steps in Algorithm 1 involve computing the matrix inverse ((I/C) + diag(B)HH T ) -1 or ((I/C) + H T diag(B)H) -1 , and the search of the optimal cost information vector B in Algorithm 2. The hidden layer output matrix H can be precomputed. The complexity of matrix multiplication for two matrices of size m × n and n × p can be O(mnp). The complexity of Algorithm 2 depends on the population size N, problem dimensions D (i.e., the length of vector B), and the number epochs of iterations, i.e., O(N • epochs). In the proposed ECSELM, the abovementioned matrix computing is included in the loop, i.e.,</p><formula xml:id="formula_49">O(N • epochs • m • n • p).</formula><p>With a Naïve MATLAB implementation, the algorithms are run on a 2.5-GHz Windows machine with 4-GB RAM. The computational time based on LFW data set is presented in Table <ref type="table" target="#tab_13">XIV</ref>, from which we observe that the following holds.</p><p>1) KELM and E-ELM need more computations than ELM and WELM. This is caused by computing the output weights on a higher dimensional kernel matrix and evolutionary search. 2) CSPCA and CSLPP cost too much time comparably.</p><p>For the former, the time is spent on the covariance 3) The CSMFA costs the most time (6731.9 s) among all the methods. The reason is that the time is mostly spent on the computation of the locality graph where kNNs should be searched for each input vector. 4) By inheriting the very low computational complexity of the conventional ELM, the proposed ECSELM is faster than cost sensitive subspace methods except the CSLDA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X. CONCLUSION AND FUTURE WORK</head><p>We have proposed in this paper an ECSELM to address the robustness of ELM in cost-sensitive learning tasks, where different misclassification losses are fully studied. In particular, the proposed evolutionary cost-sensitive framework is explored for guiding the users to freely and automatically determine the cost matrix that are task specific. To the best of our knowledge, it is the first work to provide a new evolutionary cost-sensitive perspective for ELM. In addition, there is no specific approach solving the cost matrix that is commonly defined manually in different scenarios. Extensive experiments have been employed on a variety of application scenarios, such as human beauty, FR, face verification, and E-NOSE. Experimental results and comparisons with several popular methods demonstrate the extremely prominent efficacy and competitive potentials of the proposed approaches for different tasks.</p><p>In the future work, it is also challenging to make more insight of ELMs for exploring its deep learning capability, and bring some new perspectives. In addition, how to improve the EA by appropriate population generation as indicated in <ref type="bibr" target="#b72">[73]</ref> is also motivated. Furthermore, ensemble ELMs may be a good direction, for example, as indicated in recent work <ref type="bibr" target="#b73">[74]</ref>; a twin ELM framework by integrating two different asymmetric ELMs that are learned with least square and maximum likelihood algorithms was proposed. More interestingly, as shown in the latest work <ref type="bibr" target="#b74">[75]</ref>, an idea that the input weights of ELM may not need to be generated randomly was proposed, and proved that they can be replaced with low-discrepancy sequences. Therefore, these interesting directions of ELM research can be further explored in the near future. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Examples of faces (first row) and their landmark faces (second row). The first three faces in each row denote eastern females, and the last three faces are from western.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Examples of eastern (first five) and western (last five) dressing images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Cumulative scores of facial attractiveness recognition using (a)-(c) ELM-based methods and (d)-(f) subspace-based methods. (a) and (d) Eastern. (b) and (e) Western. (c) and (f) Eastern + western.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .Fig. 5 .</head><label>45</label><figDesc>Fig. 4. Cumulative scores of dressing attractiveness recognition using (a)-(c) ELM-based methods and (d)-(f) subspace-based methods. (a) and (d) Eastern. (b) and (e) Western. (c) and (f) Eastern + western.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Confusion matrix analysis based on E-NOSE data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Confusion matrix analysis based on M 2 B data (i.e., facial, dress, and vocal data). (a) Confusion matrix on the Eastern facial feature of M 2 B data. (b) Confusion matrix on the Western facial feature of M 2 B data. (c) Confusion matrix on the Eastern dress feature of M 2 B data. (d) Confusion matrix on the Western dress feature of M 2 B data. (e) Confusion matrix on the Eastern vocal feature of M 2 B data. (f) Confusion matrix on the Western vocal feature of M 2 B data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Performance variation with respect to the parameter C = 2 p in ELM-based methods. (a) AR with L = 300. (b) LFW with L = 100. (c) E-NOSE with L = 200.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Performance variation with respect to the number of hidden neurons L in ELMs. (a) AR with C = 2 5 . (b) LFW with C = 2 10 . (c) E-NOSE with C = 2 20 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Lei</head><label></label><figDesc>Zhang (M'14) received the Ph.D. degree in circuits and systems from the College of Communication Engineering, Chongqing University, Chongqing, China, in 2013. He was selected as a Hong Kong Scholar in China in 2013. He was a Post-Doctoral Fellow with The Hong Kong Polytechnic University, Hong Kong, from 2013 to 2015. He is currently a Professor/Distinguished Research Fellow with Chongqing University. He has authored over 40 scientific papers in top journals, including the IEEE TRANSACTIONS ON IMAGE PROCESSING, the IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, the IEEE TRANSACTIONS ON MULTIMEDIA, the IEEE TRANSAC-TIONS ON SYSTEMS, MAN, AND CYBERNETICS: SYSTEMS, the IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, the IEEE SENSORS JOURNAL, the Information Fusion, the Sensors &amp; Actuators B, and the Analytica Chimica Acta. His current research interests include machine learning, pattern recognition, computer vision, and intelligent systems. Dr. Zhang was a recipient of the Outstanding Doctoral Dissertation Award of Chongqing, China, in 2015, the Hong Kong Scholar Award in 2014, the Academy Award for Youth Innovation of Chongqing University in 2013, and the New Academic Researcher Award for Doctoral Candidates from the Ministry of Education, China, in 2012. David Zhang (F'09) received the B.Sc Degree in computer science from Peking University, Beijing, China, in 1974, the M.Sc. and Ph.D. degrees in computer science from the Harbin Institute of Technology (HIT), Harbin, China, in 1982 and 1985, respectively, and the second Ph.D. degree in electrical and computer engineering from the University of Waterloo, Waterloo, ON, Canada, in 1994. From 1986 to 1988, he was a Post-Doctoral Fellow with Tsinghua University, Beijing, and then an Associate Professor with Academia Sinica, Beijing. Since 2005, he has been a Chair Professor with The Hong Kong Polytechnic University, Hong Kong, where he is currently the Founding Director of the Biometrics Research Centre supported by the Hong Kong SAR Government in 1998. He also serves as a Visiting Chair Professor with Tsinghua University and an Adjunct Professor with Peking University, Shanghai Jiao Tong University, Shanghai, China, HIT, and the University of Waterloo. He is the Book Editor of the International Series on Biometrics (Springer) and the Organizer of the International Conference on Biometrics Authentication. He has authored over ten books, 300 international journal papers, and 30 patents from USA/Japan/Hong Kong/China. Dr. Zhang is a Croucher Senior Research Fellow, the Distinguished Speaker of the IEEE Computer Society, and a Fellow of IAPR. He is the Founder and the Editor-in-Chief of the International Journal of Image and Graphics and an Associate Editor of over ten international journals, including IEEE Transactions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The population size N, problem dimension D, lower and upper bounds l d and l u , the maximal iterations epoch;</figDesc><table><row><cell>Procedure:</cell><cell></cell><cell></cell></row><row><cell cols="2">1. Initialization: 1.1. Population generation P i, j ← U l</cell><cell cols="2">j d , l</cell><cell>j u using (23);</cell></row><row><cell cols="4">1.2. Objective function evaluation using (24);</cell></row><row><cell>while iteration&lt;epoch do</cell><cell></cell><cell></cell></row><row><cell cols="4">2. Selection-I: update step for historical population.</cell></row><row><cell>2.1. Historical population Q i, j ← U l</cell><cell cols="2">j d , l</cell><cell>j u using (25);</cell></row><row><cell cols="4">2.2. Redefine Q ← P using 'if-then' rule in (26) for</cell></row><row><cell>memory;</cell><cell></cell><cell></cell></row><row><cell cols="4">2.3. Permute Q ← per muti ng(Q) by shuffling (27);</cell></row><row><cell cols="4">3. Recombination: update step for solution population.</cell></row><row><cell cols="4">3.1. Generate crossover mapping matrix using (28);</cell></row><row><cell cols="4">3.2. Mutate for new population using (29);</cell></row><row><cell>3.3. Boundary control with (30);</cell><cell></cell><cell></cell></row><row><cell cols="4">3.4. Objective function evaluation with the new population</cell></row><row><cell>using (31);</cell><cell></cell><cell></cell></row><row><cell cols="4">4. Selection-II: update step for new solution population,</cell></row><row><cell>global minimum and optimal solution.</cell><cell></cell><cell></cell></row><row><cell>4.1. Update population using (32);</cell><cell></cell><cell></cell></row><row><cell cols="4">4.2. Update the global minimum F best := F gmin using (33);</cell></row><row><cell cols="4">4.3. Update the optimal solution using (34)</cell></row><row><cell>end while Output: B</cell><cell></cell><cell></cell></row></table><note><p>3) Selection-II: Update step for new solution population P new , global minimum F g min , and the optimal Algorithm 2 ECS Framework Input: * . solution G opt</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I</head><label>I</label><figDesc>RANK-1 RECOGNITION ACCURACY (%) OF FACIAL, DRESSING, AND VOCAL ATTRACTIVENESS USING ELM-BASED METHODS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III RANK</head><label>III</label><figDesc>-1 RECOGNITION ACCURACY (%) OF FACIAL, DRESSING, AND VOCAL ATTRACTIVENESS USING BASELINE CLASSIFIERS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>|/N test is used for performance measurement and comparison, where N test is the number of test instances and ŷi and t i are the estimated score and the ground truth of instance i , respectively.</figDesc><table><row><cell>TABLE IV</cell></row><row><cell>MAE OF ATTRACTIVENESS SCORES ESTIMATION</cell></row><row><cell>scaled within [1, 10], the mean absolute error (MAE) defined as MAE = N test i=1 | ŷi -t i</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE V MAE</head><label>V</label><figDesc>OF CROSS-CULTURE ATTRACTIVENESS ESTIMATION</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VI</head><label>VI</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table VI</head><label>VI</label><figDesc></figDesc><table><row><cell>, from</cell></row><row><cell>which we have the following observations.</cell></row><row><cell>1) KELM shows an obvious superiority (87.1%) in recog-</cell></row><row><cell>nition compared with the conventional ELM (81.9%)</cell></row><row><cell>and WELM (82.7%). More significantly, the pro-</cell></row><row><cell>posed CSELM performs a recognition rate of 89.4%</cell></row><row><cell>with 2.3% improvement compared with KELM, which</cell></row><row><cell>clearly demonstrates the effect of cost-sensitive learning</cell></row><row><cell>in ELM.</cell></row><row><cell>2) In the subspace-based methods, CSLPP performs the</cell></row><row><cell>worst. The possible reason is that the characteristic of</cell></row><row><cell>low-dimensional embedding in manifold with LPP is not</cell></row><row><cell>dominant in the AR database, and make the learned</cell></row><row><cell>projection fail. Compared with CSPCA and CSMFA,</cell></row><row><cell>CSLDA shows much better performance due to its</cell></row><row><cell>discriminative ability. ELMs show better flexibility and</cell></row><row><cell>competitiveness in recognition than subspace methods.</cell></row><row><cell>To evaluate our ECSELM methods, we present the results of</cell></row><row><cell>several popular classifiers and three cost-sensitive FR methods</cell></row><row><cell>in Table VII, from which we have following observations.</cell></row><row><cell>1) The cost-sensitive FR methods (e.g., mckNN, mcSVM,</cell></row><row><cell>and mcKLR) outperform the conventional classifiers,</cell></row><row><cell>with 92.2% recognition rate obtained by mcKLR as</cell></row><row><cell>a kernel logistic regression. Comparatively, mcSVM</cell></row><row><cell>obtains an inferior performance (86.6%).</cell></row><row><cell>2) The proposed ECSELM method shows the best recogni-</cell></row><row><cell>tion performance (92.7%) among all the existing meth-</cell></row><row><cell>ods presented in this paper. Compared with CSELM in</cell></row><row><cell>Table VI, a further improvement of 3.3% recognition</cell></row><row><cell>accuracy is obtained. The superior performance demon-</cell></row><row><cell>strates that the proposed evolutionary cost-sensitive</cell></row><row><cell>learning in this paper can effectively improve FR.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE VIII RECOGNITION</head><label>VIII</label><figDesc>RATE (%) OF ELM AND COST-SENSITIVE SUBSPACE-BASED METHODSTABLE IX RECOGNITION RATE (%) COMPARISONS WITH STATE-OF-THE-ART METRIC LEARNING METHODS ON LFW</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE X RANK</head><label>X</label><figDesc>-1 RECOGNITION OF GASES USING ELM-BASED METHODS AND SUBSPACE ANALYSIS-BASED NN CLASSIFIERS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE XI RANK</head><label>XI</label><figDesc>-1 RECOGNITION RATE (%) OF GASES USING BASELINES AND GENERAL CLASSIFIERS FOR E-NOSE Fig. 8. ROC AUC analysis on LFW data.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>TABLE XII SUMMARIZED</head><label>XII</label><figDesc>RECOGNITION ACCURACY (%) ON MULTIPLE TEST DATA FOR STATISTICAL SIGNIFICANCE TEST</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>TABLE XIII STATISTICAL</head><label>XIII</label><figDesc>HYPOTHESIS TEST BY USING T-TEST METHOD OF EIGHT PAIRS OF CLASSIFIERS ON MULTIPLE TESTING DATA SETS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>TABLE XIV TOTAL</head><label>XIV</label><figDesc>TRAINING AND TESTING TIME ON LFW DATA SET OF ONEFOLD matrix computation with a large training set. For the latter, an NN graph constructed on the training set costs most time. Comparatively, ELMs have much higher computational efficiency than subspace methods.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank the Associate Editor and anonymous reviewers for their valuable comments, which greatly improved the quality of this paper.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the National Natural Science Foundation of China under Grant 61401048 and in part by the Research Fund for Central Universities.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Extreme learning machine: Theory and applications</title>
		<author>
			<persName><forename type="first">G.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-K</forename><surname>Siew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="489" to="501" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Universal approximation using incremental constructive feedforward networks with random hidden nodes</title>
		<author>
			<persName><forename type="first">G.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-K</forename><surname>Siew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="879" to="892" />
			<date type="published" when="2006-07">Jul. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Convex incremental extreme learning machine</title>
		<author>
			<persName><forename type="first">G.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="3056" to="3062" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Enhanced random search based incremental extreme learning machine</title>
		<author>
			<persName><forename type="first">G.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<idno>nos. 16-18</idno>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="3460" to="3468" />
			<date type="published" when="2008-10">Oct. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The sample complexity of pattern classification with neural networks: The size of the weights is more important than the size of the network</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="525" to="536" />
			<date type="published" when="1998-03">Mar. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Extreme learning machines trends &amp; controversies</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intell. Syst</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="30" to="59" />
			<date type="published" when="2013-12">Nov./Dec. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">What are extreme learning machines? Filling the gap between frank Rosenblatt&apos;s dream and John von Neumann&apos;s puzzle</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognit. Comput</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="263" to="278" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Local receptive fields based extreme learning machine</title>
		<author>
			<persName><forename type="first">G.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L C</forename><surname>Kasun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Vong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Intell. Mag</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="18" to="29" />
			<date type="published" when="2015-05">May 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Extreme learning machine for multilayer perceptron</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-B</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="809" to="821" />
			<date type="published" when="2016-04">Apr. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Extreme learning machine for regression and multiclass classification</title>
		<author>
			<persName><forename type="first">G.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B, Cybern</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="513" to="529" />
			<date type="published" when="2012-04">Apr. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Optimization method based extreme learning machine for classification</title>
		<author>
			<persName><forename type="first">G.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="155" to="163" />
			<date type="published" when="2010-12">Dec. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Human face recognition based on multidimensional PCA and extreme learning machine</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Minhas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">M</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Sid-Ahmed</surname></persName>
		</author>
		<idno>nos. 10-11</idno>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="2588" to="2597" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Semi-random projection for dimensionality reduction and extreme learning machine in high-dimensional space</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Intell. Mag</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="30" to="41" />
			<date type="published" when="2015-08">Aug. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Weighted tanimoto extreme learning machine with case study in drug discovery</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Czarnecki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Intell. Mag</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="19" to="29" />
			<date type="published" when="2015-08">Aug. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Trends in extreme learning machines: A review</title>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>You</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="48" />
			<date type="published" when="2015-01">Jan. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Evolutionary extreme learning machine</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1759" to="1763" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Online sequential extreme learning machine with kernels</title>
		<author>
			<persName><forename type="first">S</forename><surname>Scardapane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Comminiello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Scarpiniti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Uncini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2214" to="2220" />
			<date type="published" when="2015-09">Sep. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Parsimonious extreme learning machine using recursive orthogonal least squares</title>
		<author>
			<persName><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Er</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1828" to="1841" />
			<date type="published" when="2014-10">Oct. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Sparse Bayesian extreme learning machine for multi-classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-M</forename><surname>Vong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-K</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="836" to="843" />
			<date type="published" when="2014-04">Apr. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Universal approximation of extreme learning machine with adaptive growth hidden nodes</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-B</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="365" to="371" />
			<date type="published" when="2012-02">Feb. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Weighted extreme learning machine for imbalance learning</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="229" to="242" />
			<date>Feb</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Boosting weighted ELM for imbalanced learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wenyin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="page" from="15" to="21" />
			<date type="published" when="2014-03">Mar. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Cost-sensitive AdaBoost algorithm for ordinal regression based on extreme learning machine</title>
		<author>
			<persName><forename type="first">A</forename><surname>Riccardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fernández-Navarro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carloni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1898" to="1909" />
			<date type="published" when="2014-10">Oct. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Cost-sensitive extreme learning machine</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. ADMA</title>
		<meeting>Int. Conf. ADMA</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="478" to="488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Face recognition based on extreme learning machine</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-B</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="2541" to="2551" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Cross-person activity recognition using reduced kernel extreme learning machine</title>
		<author>
			<persName><forename type="first">W.-Y</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q.-H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-M</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2014-05">May 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Dynamic action recognition based on dynemes and extreme learning machine</title>
		<author>
			<persName><forename type="first">A</forename><surname>Iosifidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tefas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit. Lett</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="1890" to="1898" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Handwritten character recognition using wavelet energy and extreme learning machine</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Chacko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Vimal Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Raju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Babu Anto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Mach. Learn. Cybern</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="149" to="161" />
			<date type="published" when="2012-06">Jun. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Cost-sensitive face recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1758" to="1769" />
			<date type="published" when="2010-10">Oct. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Eigenfaces for recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Turk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cognit. Neurosci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="86" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Eigenfaces vs. Fisherfaces: Recognition using class specific linear projection</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Hespanha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="711" to="720" />
			<date type="published" when="1997-07">Jul. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Face recognition using Laplacianfaces</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="328" to="340" />
			<date type="published" when="2005-03">Mar. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Graph embedding and extensions: A general framework for dimensionality reduction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="51" />
			<date type="published" when="2007-01">Jan. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A parameter-free framework for general supervised subspace learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="69" to="76" />
			<date type="published" when="2007-03">Mar. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multilinear discriminant analysis for face recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="212" to="220" />
			<date type="published" when="2007-01">Jan. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Cost-sensitive subspace analysis and extensions for face recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-P</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="510" to="519" />
			<date type="published" when="2013-03">Mar. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Cost-sensitive subspace learning for face recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">P</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. CVPR</title>
		<meeting>IEEE Conf. CVPR</meeting>
		<imprint>
			<date type="published" when="2010-06">Jun. 2010</date>
			<biblScope unit="page" from="2661" to="2666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning with cost intervals</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGKDD</title>
		<meeting>ACM SIGKDD<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="403" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">New trends of learning in computational intelligene</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-A</forename><surname>Toh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Widrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Intell. Mag</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="16" to="17" />
			<date type="published" when="2015-05">May 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Backtracking search optimization algorithm for numerical optimization problems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Civicioglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Comput</title>
		<imprint>
			<biblScope unit="volume">219</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="8121" to="8144" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Quantitative analysis of human facial beauty using geometric features</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="940" to="950" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Prediction of facial attractiveness from facial proportions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Chau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2326" to="2334" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Predicting facial beauty without landmarks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="434" to="447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Facial attractiveness: Beauty and the machine</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Eisenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dror</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ruppin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="119" to="142" />
			<date type="published" when="2006-01">Jan. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Cost-sensitive ordinal regression for fully automatic facial beauty assessment</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="334" to="342" />
			<date type="published" when="2014-04">Apr. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Sense beauty via face, dressing, and/or voice</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Multimedia</title>
		<meeting>ACM Multimedia</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="239" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Towards decrypting attractiveness via multi-modality cues</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Multimedia Comp. Commun. Appl</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">28</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Human age estimation with regression on discriminative aging manifold</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="578" to="584" />
			<date type="published" when="2008-06">Jun. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Image-based human age estimation by manifold learning and locally adjusted robust regression</title>
		<author>
			<persName><forename type="first">G</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1178" to="1188" />
			<date type="published" when="2008-07">Jul. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Automatic age estimation based on facial aging patterns</title>
		<author>
			<persName><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Smith-Miles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2234" to="2240" />
			<date type="published" when="2007-12">Dec. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">The AR face database</title>
		<author>
			<persName><forename type="first">A</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Benavente</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVC</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<date type="published" when="1998">1998</date>
			<pubPlace>Barcelona, Spain</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Fisher discrimination dictionary learning for sparse representation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Vis. (ICCV)</title>
		<meeting>Int. Conf. Comput. Vis. (ICCV)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="543" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Labeled faces in the wild: A database for studying face recognition in unconstrained environments</title>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dept. Comput. Sci., Univ. Massachusetts Amherst</title>
		<imprint>
			<biblScope unit="page" from="7" to="49" />
			<date type="published" when="2007-10">Oct. 2007</date>
			<pubPlace>Amherst, MA, USA, Tech</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Eigenfaces for recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Turk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cognit. Neuroscience</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="86" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Multicategory support vector machines, theory, and application to the classification of microarray data and satellite radiance data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wahba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">465</biblScope>
			<biblScope unit="page" from="67" to="81" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Similarity metric learning for face recognition</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICCV</title>
		<meeting>IEEE ICCV</meeting>
		<imprint>
			<date type="published" when="2013-12">Dec. 2013</date>
			<biblScope unit="page" from="2408" to="2415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Bohné</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gentric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
		<title level="m">Large margin local metric in Proc. ECCV</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="679" to="694" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Side-information based linear discriminant analysis for face recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. BMVC</title>
		<meeting>BMVC</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Large scale metric learning from equivalence constraints</title>
		<author>
			<persName><forename type="first">M</forename><surname>Köstinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hirzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wohlhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2012-06">Jun. 2012</date>
			<biblScope unit="page" from="2288" to="2295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Cosine similarity metric learning for face verification</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Comput. Vis. ACCV</title>
		<meeting>Comput. Vis. ACCV</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="709" to="720" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Informationtheoretic metric learning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="209" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Is that you? Metric learning approaches for face identification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Guillaumin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Verbeek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICCV</title>
		<meeting>IEEE ICCV</meeting>
		<imprint>
			<date type="published" when="2009-10">Sep./Oct. 2009</date>
			<biblScope unit="page" from="498" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Distance metric learning with eigenvalue optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2012-01">Jan. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Bartlett</surname></persName>
		</author>
		<title level="m">Electronic Noses. Principles and Applications</title>
		<meeting><address><addrLine>Oxford, U.K.</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford Univ. Press</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Classification of multiple indoor air contaminants by an electronic nose and a hybrid support vector machine</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sens. Actuators B</title>
		<imprint>
			<biblScope unit="volume">174</biblScope>
			<biblScope unit="page" from="114" to="125" />
			<date type="published" when="2012-11">Nov. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Performance study of multilayer perceptrons in a low-cost electronic nose</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Instrum. Meas</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1670" to="1679" />
			<date type="published" when="2014-07">Jul. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A new kernel discriminant analysis framework for electronic nose recognition</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Anal. Chim. Acta</title>
		<imprint>
			<biblScope unit="volume">816</biblScope>
			<biblScope unit="page" from="8" to="17" />
			<date type="published" when="2014-03">Mar. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Differential evolution algorithm with strategy adaptation for global numerical optimization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="398" to="417" />
			<date type="published" when="2009-04">Apr. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">The particle swarm-explosion, stability, and convergence in a multidimensional complex space</title>
		<author>
			<persName><forename type="first">M</forename><surname>Clerc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="58" to="73" />
			<date type="published" when="2002-02">Feb. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">A comparative study of artificial bee colony algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Akay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Comput</title>
		<imprint>
			<biblScope unit="volume">214</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="108" to="132" />
			<date type="published" when="2009-08">Aug. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">GSA: A gravitational search algorithm</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rashedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nezamabadi-Pour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saryazdi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">179</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="2232" to="2248" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Statistical comparisons of classifiers over multiple data sets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Demšar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2006-01">Jan. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Building gene networks with time-delayed regulations</title>
		<author>
			<persName><forename type="first">I</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Rajapakse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit. Lett</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="2133" to="2137" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Two efficient twin ELM methods with prediction interval</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2058" to="2071" />
			<date type="published" when="2015-09">Sep. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Low-discrepancy points for deterministic assignment of hidden weights in extreme learning machines</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cervellera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Macciò</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="891" to="896" />
			<date type="published" when="2016-04">Apr. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
