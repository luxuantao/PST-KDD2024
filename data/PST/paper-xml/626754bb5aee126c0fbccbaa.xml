<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Counterfactual Learning To Rank for Utility-Maximizing Query Autocompletion</title>
				<funder ref="#_zEqqJab">
					<orgName type="full">National Science Foundation Graduate Research Fellowship</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-04-22">22 Apr 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Adam</forename><surname>Block</surname></persName>
							<email>ablock@mit.edu</email>
						</author>
						<author>
							<persName><forename type="first">Rahul</forename><surname>Kidambi</surname></persName>
							<email>rahul.g.kidambi@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><forename type="middle">N</forename><surname>Hill</surname></persName>
							<email>daniehil@amazon.com</email>
						</author>
						<author>
							<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Inderjit</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
							<email>inderjit@cs.utexas.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Massachusetts Institute of Technology Cambridge</orgName>
								<address>
									<region>Massachusetts</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Amazon Search Berkeley</orgName>
								<address>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Amazon Music San Francisco</orgName>
								<address>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">UT</orgName>
								<address>
									<settlement>Austin Austin, Texas</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Counterfactual Learning To Rank for Utility-Maximizing Query Autocompletion</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-04-22">22 Apr 2022</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3477495.3531958</idno>
					<idno type="arXiv">arXiv:2204.10936v1[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>? Information systems ? Recommender systems</term>
					<term>Query intent</term>
					<term>Query suggestion</term>
					<term>Query log analysis</term>
					<term>Learning to rank Query Auto-Complete, Learning to Rank, Counterfactual Estimation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Conventional methods for query autocompletion aim to predict which completed query a user will select from a list. A shortcoming of this approach is that users often do not know which query will provide the best retrieval performance on the current information retrieval system, meaning that any query autocompletion methods trained to mimic user behavior can lead to suboptimal query suggestions. To overcome this limitation, we propose a new approach that explicitly optimizes the query suggestions for downstream retrieval performance. We formulate this as a problem of ranking a set of rankings, where each query suggestion is represented by the downstream item ranking it produces. We then present a learning method that ranks query suggestions by the quality of their item rankings. The algorithm is based on a counterfactual learning approach that is able to leverage feedback on the items (e.g., clicks, purchases) to evaluate query suggestions through an unbiased estimator, thus avoiding the assumption that users write or select optimal queries. We establish theoretical support for the proposed approach and provide learning-theoretic guarantees. We also present empirical results on publicly available datasets, and demonstrate real-world applicability using data from an online shopping store.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Query autocompletion (QAC) systems <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b53">54]</ref> recommend candidate query completions given a partially typed query, and QAC has become a standard feature of many retrieval systems that are currently in practical use. We argue that the goal of QAC is not only to reduce the user's typing effort, but also to help users discover the best queries for their information needs. Unfortunately, there is a disconnect between how most current QAC systems are trained and the ultimate goal of finding improved queries. In particular, most QAC systems are trained to mimic user behavior, either predicting how the user will complete the query or which query suggestion the user will select. This means that a conventional QAC system can only become as good at suggesting queries as the users it was trained on, which may lead to substantial suboptimality.</p><p>To overcome this limitation, we present a new framework for training QAC systems, which we call the utility-aware QAC approach. The name reflects that the QAC system is aware of the utility (i.e. ranking performance) that each query suggestion achieves given the current production ranker, and that it directly optimizes the retrieval performance of the queries it suggests. The key insight is to make use of downstream feedback that users eventually provide on the items (e.g. products purchased and content streamed) to evaluate each suggested query instead of considering previous users' queries as the gold standard to emulate. This new focus allows our approach to circumvent the issue that users may not know which queries provide good rankings given the current system.</p><p>From a technical perspective, the utility-aware QAC approach formulates the task of learning a QAC system as that of learning a ranking of rankings. In particular, each query suggestion is evaluated by the quality of the item ranking it produces. The goal of the utilitiy-aware QAC is to rank the query suggestions by the quality of their item rankings given the partial query that the user already typed. A key machine learning challenge lies in how to estimate the quality of the item rankings of each of the query suggestions in the training set, given that we only have access to interaction feedback (e.g. purchases) for a small subset of query suggestions and items. We overcome this problem by taking a counterfactual learning approach, where we develop an estimator of ranking performance that is unbiased in expectation under standard position-bias models <ref type="bibr" target="#b28">[29]</ref>. This results in a new training objective for QAC models that directly optimizes the efficacy of the queries suggested by the QAC system. Note that at test time, the system will not have access to any utility estimate as the user's desired document is obviously not known; the goal is for the ranker to use the interaction of features relevant to the user (such as a prefix or contextual data) and the query to predict the downstream utility of different queries, and then to surface high quality suggestions to reduce downstream user effort. Thus, it is critical for the utility-awareness of the proposed framework to incorporate the downstream effect somewhere in the objective, as we do, and thus not rely on access to a utility estimate at test time.</p><p>We now list our primary contributions.</p><p>? We introduce a novel framework for training utility-aware QAC systems given biased, item-level feedback. In particular, we propose a realistic theoretical model and a learning method that can train a utility-aware QAC system given an arbitrary class of potential ranking functions. ? We provide a theoretical analysis and show that under mild conditions on the function class used for QAC ranking and for a known position-bias model with full support, our approach to training QAC rankers is consistent in the sense that it will identify the best-in-class QAC ranker given sufficient training data. We also state and prove a non-asymptotic anologue of this result. ? Finally, we investigate empirically how well the utilitiyaware QAC approach performs by instantiating our method, both on public benchmarks and on a real-world dataset from an online shopping store. The latter demonstrates real-world practicality, while the former gives insight into how various features of the utilitiy-aware QAC approach contribute to improved efficacy.</p><p>We emphasize that our proposed framework is invoked only at training time and thus does not affect latency at inference time. In particular, our framework naturally adapts to essentially any QAC approach and can scale to extremely large (tens of millions) query and document universes and thus can realistically be deployed in many practical settings. The structure of the paper is as follows.</p><p>We first provide a brief survey of related work. We then formally propose the utility-aware QAC framework as a "ranking of rankings" and continue by proposing an unbiased estimator of utility, given possibly biased data. We proceed by stating a nonasymptotic generalization bound for a ranker trained in our framework, which in turn implies consistency. We then move on to describe the practical instantiation of our framework along with a description of the experimental setup. We conclude by presenting the results of our experiments. All proofs are deferred to Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related Work</head><p>Query auto-complete system: QAC has been studied extensively in the literature -particular efforts include suggesting top-k queries given a prefix <ref type="bibr" target="#b48">[49]</ref> and contextual, personalized, time-sensitive and diversified recommendation of query completions for real time applications <ref type="bibr">[2, 8-10, 38, 39, 54]</ref>. See <ref type="bibr" target="#b6">[7]</ref> for a survey of these methods. Common to the above approaches is the fact that they work in a two-stage retrieve and rank framework, where, given a prefix, a candidate set of query completions is retrieved and then re-ranked using context, popularity and other metrics, and the resulting top-? queries are shown to the user. Techniques from eXtreme multi-label learning <ref type="bibr" target="#b53">[54]</ref> have also been applied to retrieval for QAC systems <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b56">57]</ref>. These approaches optimize for user engagement measured in the form of clicks on the presented queries. This line of work is different from the goals of this paper in that we minimize downstream user effort as opposed to maximizing user engagement. Another class of QAC approaches include ones based on neural language models, performing generation/re-ranking <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b40">41]</ref>. However, these approaches may not be suitable to real-time deployment owing to latency issues and their propensity to offer non-sensical suggestions in the generative setting.</p><p>Ranking in full and partial information settings: Ranking in the full information setting has been studied extensively, including extensions to partial relevance judgements <ref type="bibr" target="#b25">[26]</ref>. For a survey of detailed developments in the pairwise learning to rank framework, see <ref type="bibr" target="#b4">[5]</ref>. This line of work assumes the relevance judgements can be used to optimize metrics of interest. Recognizing the biased nature of feedback received by data collected through deploying a ranking algorithm, <ref type="bibr" target="#b28">[29]</ref> developed a de-biased learning to rank approach with provable guarantees; this method then inspired a plethora of extensions, generalizations, and applications to other domains such as <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b54">55]</ref>. We employ a similar debiasing strategy for purposes of estimating utilities in order to develop an unbiased utilitiy-aware learning to rank approach.</p><p>Counterfactual estimation/reasoning: At a high level, this work is motivated by principles of counterfactual estimation/learning with logged bandit feedback developed by <ref type="bibr" target="#b3">[4]</ref>. The utilitiy-aware ranking problem is related to the general estimation/learning from logged contextual bandit feedback framework that has been studied in a series of papers <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b41">[42]</ref><ref type="bibr" target="#b42">[43]</ref><ref type="bibr" target="#b43">[44]</ref><ref type="bibr" target="#b44">[45]</ref><ref type="bibr" target="#b51">52]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PROBLEM SETUP</head><p>Before providing the formal setup, we first need to review common notions from the literature (see <ref type="bibr" target="#b28">[29]</ref> for more details). In standard "full information" Learning to Rank (LTR), the learner desires a policy that maps from queries Q to a ranked list of documents A, attempting to place documents relevant to the query near the top of the list. Relevance is measured by a score rel(?, ?) that is assumed to be known during training but not at inference time. In the sequel, for the sake of simplicity, we restrict our focus to relevances in {0, 1} but we note that our techniques are applicable to real valued relevances. In the context of QAC systems, the 'documents' are query completions which are ranked according to their relevance to a context, such as a prefix. The quality of a given document ranker, denoted by rank, evaluated at a query ? is measured by an additive utility function ?(?, rank); examples include Mean Reciprocal Rank (MRR) and Discounted Cumulative Gain (DCG) <ref type="bibr" target="#b24">[25]</ref>. To evaluate the ranker, it is common to consider the value of ?(?, rank) averaged over some distribution of queries.</p><p>In contradistinction to the traditional LTR setting, our goal is to produce a ranking of rankings given a context, where the learner associates an element of a set of pre-determined rankings to each context. Thus, we consider a space of contexts X that represent partial queries, a universe of query completions Q, and set of documents A. Crucially, in our setting, there is a given document ranker that maps a query to a ranked list of documents: Definition 1. There exists a fixed function rank : Q ? (N ? {?}) A that acts as a ranker of documents given a query, i.e., rank ? is a function mapping articles to ranks. We denote by rank ? (?) the rank of document ? given query ? and consider rank ? (?) = ? to suggest that the query ? does not return the document ?. By abuse of notation, we also denote the set of documents returned by a query, {?| rank ? (?) &lt; ?} by ? when there is no risk of confusion.</p><p>Our goal is to produce a query ranking policy, ? : X ? (N ? {?}) Q that highly ranks queries leading to contextually relevant documents with minimal effort. Thus, we are concerned with relevances rel(?, ?) between contexts and documents and, given a context ?, are attempting to find queries ? such that rank ? (?) is small for documents ? when rel(?, ?) is large. With full information on all relevance labels, where the learner has offline access to ?(?, rank), a natural approach to the ranking-of-rankings problem would be to define relevance between context and query as rel(?, ?) = ?(?, rank). Then, given a (possibly different) additive utility function ?, we can quantify the quality of a query ranker ? evaluated on a context ? using these scores. Given a distribution of contexts, we evaluate the query-ranking policy as follows:</p><formula xml:id="formula_0">?(?) = E ?(?, ?)<label>(1)</label></formula><p>Thus, we see that the ranking of rankings problem with full information can be reduced to LTR. In the QAC setting, the context ? is data associated to a user, such as a typed prefix while relevances are often measured by clicks. We also suppose the learner has offline access to the fixed document retrieval system from Definition 1.</p><p>Given that the QAC and the document retrieval system are trained separately, it is reasonable to take the latter as a black box that can be queried offline.</p><p>Definition 2. An offline ranking system returns rank ? (?) given a (?, ?) pair.</p><p>While Definition 2 allows the learner to query the document ranker, one couldn't hope to do this during inference time (owing to latency constraints), thus requiring a reliance on a pre-trained ranker, ?. Much as in traditional LTR, we aim to choose an ? maximizing ?(?), for which we use an empirical proxy:</p><formula xml:id="formula_1">?(?) = 1 ? ? ?? ?=1 ?(? ? , ?)<label>(2)</label></formula><p>The law of large numbers tells us that ? converges to ? as ? ? ? under the following generative process: Definition 3. Data are generated such that we receive ? contexts ? ? sampled independently from a fixed population distribution.</p><p>Given a function class F of candidate rankers, we can optimize ? instead of ?, leading to the classically studied Empirical Risk Minimizer (ERM). Convergence rates of ? to the optimal ranker ? * (that which maximizes ?) can then be established depending on the complexity of the function class F on the basis of empirical process theory <ref type="bibr" target="#b46">[47]</ref>. This analysis, however, is predicated on the assumption that ?(?) can be evaluated, which in turn requires known relevances rel(?, ?) between documents and contexts. As noted in <ref type="bibr" target="#b28">[29]</ref>, even in the LTR setting, collecting such relevance scores can be challenging, commonly generated by human judges making potentially inconsistent determinations. To escape these difficulties, we use logged data, as elaborated below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RANKING OF RANKINGS WITH PARTIAL INFORMATION</head><p>In the previous section, we saw that the ranking of rankings task in a full-information setting can be reduced to the standard LTR task, but noted that acquiring reliable data in this regime presents its own challenges. In standard LTR, <ref type="bibr" target="#b28">[29]</ref> proposed using logged data to estimate relevance between queries and documents. As many services keep data on user searches and clicks, these logs provide a rich source of information on what documents the customers themselves consider to be relevant to their context. Despite the quality and quantity of the log data, their use to measure relevance still requires care as relevance observed by the learner is a function both of relevance between context and document and, critically, whether or not the customer associated to the context actually observed the document. Following <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b36">37]</ref>, we assume the probability of observation is dependent on the rank and we apply inverse propensity scoring to produce an unbiased estimate of ?.</p><p>More formally, we consider the following model. Given query ? and document ?, we denote the event that document ? was observed by the customer given query ? by ? (?, ?). Given a context ?, we denote by ? (?, ?, ?) the event that a document is clicked (and its relevance logged) and suppose this occurs if and only if the document is observed and the document is relevant, i.e., ? (?, ?, ?) = ? (?, ?) rel(?, ?). We suppose the following distribution of ? (?, ?): Definition 4. The data generation process from log data has the events {? (?, ?)|? ? Q, ? ? A} live on a probability space such that the events are independent across queries. We further assume that there exists a known probability distribution {? ? } on N ? {?} such that P(? (?, ?) = 1) = ? rank ? (?) for all ?, ?, where ? ? = 0.</p><p>The most restrictive part of Definition 4 is the assumption of the known click propensity model. Such a model can be estimated in various ways <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b49">50]</ref>, and we do not concern ourselves with specifying a particular model. In our experiments below, we consider a simple model where ? ? ? 1 ? ; furthermore, we demonstrate that the proposed framework can offer gains even in situations when the propensities are mis-specified.</p><p>We focus on the most natural reward for a query given a context: the probability of a click. Thus we define the utility of a query as</p><formula xml:id="formula_2">? (?, ?) = P(? (?, ?, ?) = 1 for some ? ? ?)<label>(3)</label></formula><p>The learner aims to produce a query ranker, which takes in a context and returns a ranking of queries. Thus if</p><formula xml:id="formula_3">? * (?) ? argmax ? ?? (?) ? (?, ?)<label>(4)</label></formula><p>the goal is for the query ranker to rank near the top queries ? ? ? (?) such that ? (?, ?) is as close as possible to ? (?, ? * (?)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">COUNTERFACTUAL UTILITY ESTIMATION</head><p>If we knew the relevances of all context-document pairs, we would have access to ? (?, ?) and could proceed as described in Section 2. Because we only have access to log data, we need to form an estimate of the utility of different queries given the data at hand.</p><p>The following describes what we need from the logs: Definition 5. Let ? denote a pre-trained function mapping a context ? to the set of proposed queries. A data point in the logs</p><formula xml:id="formula_4">? ? , ? ? , ? ? , rank ? ? (? ? ) consists of context ?, query ? ? ? ? (? ? ) chosen arbitrarily, document ? ? ? ? ? such that ? (?, ?, ?) = 1, and rank ? (? ? ).</formula><p>Given a data point (?, ?, ?, rank ? (?)), we consider the following estimator of utility for all ? ? ? (?):</p><formula xml:id="formula_5">? (?, ?|?, ?) = ?? ? ?? ? (?,?,?)=1 ? rank ? (?) ? rank ? (?)<label>(5)</label></formula><p>We first note that our estimator, motivated by the Inverse Propensity Scoring (IPS) of <ref type="bibr" target="#b28">[29]</ref>, is unbiased. Proposition 6. Suppose we are in the setting of Definitions 1, 2, 3, 4, and 5. Then ? is an unbiased estimator of the utility, i..e, E [ ? (?, ?|?, ?)|?, ?] = ? (?, ?).</p><p>Given that our estimator is unbiased, we might now hope to control its variance. Unfortunately, as the next result shows, this is not possible without further assumptions: Proposition 7. For any constant ?, there exist queries ? and ?, a context ?, and document ? such that Assumptions 1, 2, 3, 4, and 5 hold and Var( ? (?, ?|?, ?)) &gt; ?.</p><p>This makes intuitive sense: there is no reason that it should be easy to estimate the utility of a query ? if we only have data from a query ? that is very different from ?. Thus, in order to estimate utilities well, we need to control this difference. The following assumption controls this difference quantitatively: Assumption 8. We assume that there is a positive constant ? &lt; ? such that</p><formula xml:id="formula_6">sup ? max ?,? ?? (?) max ? (?,?)=1 ? rank ? (?) ? rank ? (?) ? ?<label>(6)</label></formula><p>It is important to note that Assumption 8 makes no reference to the probability ratio with respect to irrelevant documents. Thus, ? and ? can be arbitrarily different in ranking irrelevant documents. This is similar to the full coverage assumptions used in the off-policy evaluation and learning literature <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b51">52]</ref>. Note that such a bound on the ratio of probabilities can be enforced through clipping weights <ref type="bibr" target="#b41">[42]</ref> which reveals a bias-variance tradeoff when running the resulting estimation procedure. Owing to this, Assumption 8 is not very restrictive, as practitioners often treat documents as irrelevant if they appear in the logs only with very large ranks. Under Assumption 8, and using Equation <ref type="bibr" target="#b16">(17)</ref> we are able to control our estimator's variance: Proposition 9. Suppose we are in the setting of Definitions 1, 2, 2, 3, 4, and 5, as well as Assumption 8. Then ? (?, ?|?, ?) ? ? <ref type="bibr" target="#b6">(7)</ref> Var( ? (?, ?|?, ?)) ? ?? (?, ?) -? (?, ?) 2 (8)</p><p>Our utility estimator gets better the closer that ? is to ? (in terms of the rankings they produce on relevant documents). We now proceed to prove a generalization bound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">GENERALIZATION UNDER PARTIAL INFORMATION</head><p>In this section, we state a generalization bound for our ranking of rankings in the above model. We restrict our focus to a variant of the Pairwise Learning to Rank model <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b25">26]</ref>, where we are given a dataset containing groups of features and targets. Within each group, we subtract the features of all pairs with different target values, and label this difference 1 if the first target is larger than the second and -1 otherwise. We then train a classifier, such as a logistic regression model, on these data to predict the assigned labels. To produce a ranking given features, we call the classifier, which returns a real number between 0 and 1, interpreted as a probability that one is better than the other and then rank the candidates by their predicted probabilities, within group.</p><p>For the sake of simplicity, we focus our theoretical analysis on the problem of minimizing average loss in utility obtained by transposing any two elements in the ranking. This metric is particularly well suited to theoretical analysis with respect to PLTR and is a natural generalization to the problem of ranking more than two items while keeping target score values relevant to the loss considered in such works as <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b12">13]</ref>, among others.</p><p>Given query ranker ? : X ? (N?{?}) Q , for a context ?, queries</p><formula xml:id="formula_7">?, ? ? ? ? (?), let ? (?, ?, ? ? ) = -sign rank ? (?) (?) -rank ? (?) (? ? )</formula><p>with sign(0) chosen arbitrarily, where we denote by rank ? (?) the rank of query ? according to the ranker ?; because there is no overlap between contexts, queries, and documents, there is no risk of confusion with the document ranker defined earlier. In other words, ? (?, ?, ? ? ) is 1 if ? (?) ranks ? ahead of ? ? and -1 otherwise.</p><p>We then formally define the loss of a query ranker to be:</p><formula xml:id="formula_8">?(?, ?) = 1 |? (?) | 2 ?? ?,? ? ?? (?) (? (?, ?) -? (?, ? ? ))? (?, ?, ? ? )<label>(9)</label></formula><p>Taking expectations yields ?(?). As noted in Section 3, we don't have access to utilities since we work in the partial information setting; instead we have access to (relative) utility estimates ? (?, ?|?, ?). Thus, we consider:</p><formula xml:id="formula_9">?(?) = E ? ? ? ? ? ? 1 |? (?) | 2 ?? ?,? ? ?? (?) ( ? (?, ?|?, ?) -? (?, ? ? |?, ?))? (?, ?, ? ? ) ? ? ? ? ? ? (10)</formula><p>The tower property of expectations, linearity, and Proposition 6 show that the difference between these losses is merely notational: Lemma 10. Under the setting of Definitions 1, 2 3, 4, and 5, for any query ranker ? : X ? (N ? {?}) Q , we have ?(?) = ?(?).</p><p>Thus, minimizing ? is the same as minimizing ?; unfortunately, we don't have access to ? either as we don't know the population distribution. We consider the empirical version, ? ? (?), defined as:</p><formula xml:id="formula_10">1 ? ? ?? ?=1 1 |? (? ? ) | 2 ?? ?,? ? ?? (? ? ) ( ? (? ? , ?|? ? , ? ? ) -? (? ? , ? ? |? ? , ? ? ))? (? ? , ?, ? ? )<label>(11)</label></formula><p>The learner has access to ? ? and can thus optimize over some class of rankers F . We consider ? ? ? argmin ? ? F ? ? (?), the ERM. We wish to analyze the difference in performance between ? ? and the best ranker in the class F , i.e., we hope that ?(? ? ) -?(? * ) is small, where ? * ? argmin ? ? F ?(?). Classical theory of empirical processess <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b46">47]</ref> suggests that generalization error depends on the complexity of the function class, through the Rademacher complexity. Letting F ? = {? (?, ?, ? ? )|? ? F } where ? (?, ?, ? ? ) is as in Eq. ( <ref type="formula" target="#formula_8">9</ref>), we let the Rademacher complexity be defined as</p><formula xml:id="formula_11">? ? (F ) = E sup ? ? F ? 1 ? ? ?? ?=1 ? ? ? (? ? , ? ? , ? ? ? )<label>(12)</label></formula><p>where the ? ? are independent Rademacher random variables, the ? ? are chosen independently according to the distribution on X, and the ? ? , ? ? ? are a fixed set of queries. As a concrete example, it is easy to show that if F is linear, then ? ? (F ) = ? ?? -1/2 with a constant depending on the norm of the parameter vector. There is a great wealth of classical theory on controlling ? ? (F ) in many interesting regimes and we refer the reader to <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b46">47]</ref> for more details. By adding queries with zero utility, we may suppose that |? (?)| = ? for all ?. We now state the generalization bound: Theorem 11. Suppose definitions 1, 2 3, 4, 5, and Assumption 8 holds. Let F be any class of query rankers ? : X ? (N ? {?}) Q . Then we can control the generalization error as follows:</p><formula xml:id="formula_12">E ?(? ? ) -?(? * ) ? 4? ? ? ? 2 ? ? (F ) = ? 1 ? ?<label>(13)</label></formula><p>where the expectation is taken with respect to the data used to construct ? ? , ? ? is the expected number of queries relevant to at least one ? ? for 1 ? ? ? ?, and the equality holds for parametric function classes F .</p><p>As discussed in the previous section, a linear dependence on ? is unavoidable in the absence of further assumptions. The quantity ? is obviously bounded by |Q| but can in general be much smaller if, for most contexts, only a small number of queries are relevant. Without further structural assumptions on the query universe, it is impossible to escape such a dependence as there is no ability to transfer knowledge about one set of queries to another. From the bound, it seems like increasing ? can only be advantageous, but this is not quite true because increasing ? weakens the loss function's ability to distinguish queries ranked near the top; for practical applications, users rarely look sufficiently far down a ranked list for large ? to be relevant. What is clear from this bound, however, is that our approach is consistent and utility-aware ranking with partial information is well-grounded in theory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">PRACTICAL INSTANTIATION</head><p>We discuss the practical instantiation of the principles developed in Sections 3-5. We first present the system architecture and then describe the setup used to evaluate the efficacy of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">System Architecture</head><p>For computational reasons, the QAC pipeline involves two steps <ref type="bibr" target="#b53">[54]</ref>: we first retrieve a set of possible query completions and second re-rank this set. Both steps are utility-aware.</p><p>6.1.1 Query Retrieval. Selecting a small subset of possible query completions is beneficial during both training and inference. For training, this is related to the PLTR reduction, described above, where the number of samples for the classification task grows quadratically with the number of queries per context. Moreover, owing to latency requirements (typically around 100 milliseconds) of practical QAC systems with query universes ranging from 100K to 100M, evaluating all possible queries for a given prefix is impractical. Thus, logarithmic time query retrieval strategies can be achieved in practice by relying on techniques from eXtreme multi-label learning <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b56">57]</ref> and maximum inner product search <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b47">48]</ref>, among others.</p><p>In this work, we apply Prediction for Enormous and Correlated Output Spaces (PECOS) <ref type="bibr" target="#b56">[57]</ref>, proposed in the context of eXtreme multi-label learning, to perform candidate query retrieval. Building on <ref type="bibr" target="#b53">[54]</ref>, we use hierarchical clustering to index queries and train linear classifiers for each node in the tree; PECOS then uses beam search to retrieve relevant query completions given the context. To make the retriever utility-aware, we include as relevant to a context only sufficiently high-utility queries as training data.</p><p>6.1.2 Query Re-Ranking. While the query retrieval system optimizes recall so as to not exclude optimal queries, re-ranking is required to improve precision at the top ranks. There are many ranking metrics <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b29">30]</ref> and algorithms based on gradient boosting and deep neural networks with the PLTR objective have been widely adopted in practice <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b35">36]</ref>. In this work, we use the former, implemented in the library xgboost <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Experimental Setup</head><p>Given the log data, we first partition the training set in three parts, with one set used to train the query retriever, the second used to train the query ranker and the third used for evaluating the entire pipeline. In order to train the retriever model, we must feed it proposed alternative queries. To generate these candidates, we use the log data itself, along with the document ranker.</p><p>Specifically, the document ranker and the log data together induce a bipartite graph, with the queries on one side and the documents on the other, as illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>. An edge exists between a query and a document if the document is returned by the ranker given the query. We thus use the production ranker and the logged data in the retriever-training set to construct this bipartite graph and take as proposed alternative queries those that are neighbors of the logged document. As an example, suppose that ? 1 were recorded with the logged document being ? 1 . Then the set of possible alternative queries would be {? 1 , ? 4 }. If instead ? 2 were recorded as the logged document, the set of alternative queries would be {? 1 , ? 2 , ? 3 }. We make the retriever utility-aware by further filtering this set to include only queries with estimated utility at least 1. In the example above, suppose that rank ? 1 (? 1 ) = 5, rank ? 2 (? 1 ) = 10 and rank ? 3 (? 1 ) = 2. Then the set of alternative queries returned given a log entry of (? 1 , ? 1 ) would be {? 1 , ? 3 }, as ? 2 has estimated utility less than one. We then train the retriever using the prefixes as contexts and the proposed alternative queries as labels. The retriever returns the proposed queries given the context. The production ranker is then used to find the documents given the retrieved queries. This ranking is then used to calculate utilities. Note that different queries can return the same document but in a different order. For instance, ? 1 ranks ? 3 third while ? 2 ranks ? 3 first. Now, given the trained context-to-query retrieval model, we turn to the second partition of the log data. Using this retriever, we surface a list of proposed alternative queries for each log entry. We use the production ranker to get the ranks of the logged document given the alternative queries; these ranks are then used to estimate the utility of the query. Finally, we train a ranking model with these utilities as targets. The process is illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>.</p><p>At inference time, for each logged entry, we use the query retriever followed by the ranker to return a ranked list of queries optimized for utility. We can then use the production ranker to get the rank of the logged document in a query according to this policy and evaluate the average utility. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">EXPERIMENTAL RESULTS</head><p>We present detailed results on a benchmark eXtreme Multi-label learning dataset adapted to our setting (see Appendix B), as well as demonstrating efficacy in a real world setting on a proprietary dataset from an online shopping store.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Dataset Setup/Description</head><p>7.1.1 Amazon Titles Dataset. We use the Amazon Titles dataset, collected by <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32]</ref> and made available as LF-AmazonTitles-1.3M on <ref type="bibr" target="#b2">[3]</ref>. This dataset has been collected by scraping the Amazon product catalogue. In raw form, each datum consists of the title of an Amazon product together with some metadata, with labels consisting of other products suggested by Amazon on the web page of the first product. The dataset consists of 1, 305, 265 labels and 2, 248, 619 training points, where again, each label is another Amazon product. We filter and keep the top 50, 000 most frequent labels, thereby making the induced bipartite graph described above more dense. We then train a PECOS model <ref type="bibr" target="#b56">[57]</ref> on the entire training set to serve as our document retrieval/product ranking system. After the product ranker is trained, we generate our logs according to a certain known click propensity model. We restrict ourselves to the probability of a product observation being inversely proportional to the rank of the product given the query; a click is recorded if the observed product is relevant. We created a log with 3, 842, 425 samples using the above sampling procedure. We then split the log using a (.6, .3, .1) split on the instances, using the first set to train the candidate retriever (again a PECOS model), the second set to train the ranking model, and the last set to be used as a test set to validate our results. To train the candidate retriever, we sampled prefixes by choosing a random truncation point after the first word in the title, and throwing away any prefixes that are too short. We passed through the retriever training set 15 times with this procedure, but only once for each of the ranker training and test sets. For computational reasons, we then subsample the ranking train set by half. The sizes of the data sets are summarized in Table <ref type="table" target="#tab_0">1</ref>.</p><p>We then use the retriever to generate a set of candidate queries associated to each prefix in the ranker training set and the test set. In order to train a ranker, we need to featurize the prefixes and candidate queries. To do this, we use a pre-trained model from the transformers library <ref type="bibr" target="#b52">[53]</ref>, specifically the bert-base-uncased model <ref type="bibr" target="#b16">[17]</ref>, after normalizing the queries and prefixes to remove punctuation and make lower case. We then use XGBoost <ref type="bibr" target="#b10">[11]</ref> with the PLTR objective to fit a ranker with the utilities as labels. For all of our experiments, we used a depth 8 base classifier with 200 boosting rounds and all other parameters set to the default values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.2">Data From Online</head><p>Store. There are some key differences in how we set up the experiments for data from an online store.</p><p>First, we have no need to simulate log data and no need to train a document ranker as we are given logged data with all required information relating to the context, prefix, and document ranker. Second, we use extra contextual information beyond simply the prefix in order to suggest and rank queries. Third, we featurize the contexts and proposed queries in a different way, relying on features developed internally by the online shopping store. Other than this, the pipeline and evaluation are identical. For instance, the candidate retriever we utilize is the PECOS model <ref type="bibr" target="#b56">[57]</ref> and is trained on the estimated utilities. The query re-ranker is a gradient boosted decision tree for which we use XGBoost <ref type="bibr" target="#b10">[11]</ref> with the PLTR objective to fit a ranker with the utilities as labels. The data are proprietary and we consider this section a demonstration of the verisimilitude of our model setting above, as well as positive evidence that the proposed system works in the real world.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Evaluation Metrics and Baselines</head><p>We compare different QAC policies to the baseline logged query by assuming a click propensity model on the presented queries and reporting the position-weighted (relative) utility (denoted as Utility@k), defined as:</p><formula xml:id="formula_13">Utility@k = ? ?? ?=1 ? ? ? ? (?, ? ? | q, ?),</formula><p>where, {? ? } ? ?=1 is a ranked list of queries returned by a ranking policy that being evaluated, ? (?) is the utility estimator defined in Eq. ( <ref type="formula" target="#formula_2">3</ref>), ?, ? are respectively the context, a relevant document that the user clicks on by using the logged query q. We denote by ? ? the click propensity model associated to the queries; for our metric, we consider ? ? ? ? -1 . Note that Utility@1 is just the average utility of the top-ranked query according to the policy under consideration. We also consider Utility@5 and Utility@10, although we observe in our experiments that the relative quality of different QAC policies largely does not depend on which ? is used. We remark that our notion of position-weighted utility comes directly from our model and corresponds to the factor increase of the probability of finding a relevant document under the click propensity model. Alternatives such as Mean Recipricol Rank (MRR) and Discounted Cumulative Gain (DCG) are not well-suited to measure the utility; thus, while the utility-aware ranker may be less competitive on these metrics, they do not naturally fit into the current framework. As such, we restrict our focus to the central theme of the paper: downstream utility.</p><p>We compare the proposed approach against a variety of baselines:</p><p>? Unbiased: retrieval following by re-ranking system with utilities estimated using Eq. ( <ref type="formula" target="#formula_2">3</ref>). ? PECOS: retrieval system's performance when trained with utilities estimated using Eq. ( <ref type="formula" target="#formula_2">3</ref>). This serves to highlight the impact of the re-ranking step. ? Oracle: evaluates a ranking policy that returns the best query in terms of utility, which requires knowing utility for test data and is thus not implementable. This serves to highlight the gap one can hope to bridge by developing more powerful classes of re-ranking algorithms. Note that only Utility@1 is meaningful for this policy. ? Logged: The (relative) utility of the logged query. Note that this is the baseline to which the other policies are compared. By Eq. ( <ref type="formula" target="#formula_2">3</ref>), the logged queries always have relative utility 1.0. Note that only Utility@1 is meaningful for this policy. ? Random: Performance of a policy that returns queries retrieved by the PECOS retriever in a uniformly random order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Empirical Results -Amazon Titles Dataset</head><p>In this section we describe our results on the Amazon Titles data. In Section 7.3.1 we compare our approach to the baselines described in Section 7.2; in Section 7.3.2 we explore the how increasing the amount of data affects the quality of our ranker; in Section 7.3.3 we compare our proposed utility estimator from Eq. ( <ref type="formula" target="#formula_2">3</ref>) to other natural alternatives; and in Section 7.3.4 we demonstrate that our approach is robust to misspecification of the click propensity model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.1">Core Results</head><p>. Table <ref type="table" target="#tab_1">2</ref> presents the core results comparing the proposed approach against various baselines presented in Section 7.2. We also plot the average utility at each position ? for 1 ? ? ? 5, according to each policy in Fig. <ref type="figure">3</ref>. Taken together, these results suggest that the proposed QAC framework significantly outperforms the benchmark Logged policy in addition to policies that only rely on the retriever (PECOS and Random). Note that the proposed re-ranker has the potential to be improved upon since the (indadmissable) oracle strategy results in still better queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.2">Does more Data lead to a Better Ranker?</head><p>We examine the effect that increasing the size of the data set has on the quality of the utility-aware ranker, summarized in Fig. <ref type="figure">4</ref>. We subsample the log data at sizes 1%, 10%, and 50% and train the utility-aware ranker on each of these data sets, demonstrating a clear upward trend. While we evaluate under the Position-Weighted Utility truncated at 5 here, utility at 1 and 10 exhibit similar behavior, as can be seen in Appendix C. As predicted from Theorem 11, the performance of the utility-aware ranker increases with the sample size. Note that while the utility still does not approach the quality of Oracle even with more than 1.6 million samples, it is not clear that the Oracle policy is even included in the set of policies achievable by our base classifier.  the ranker to use utility estimates other than our unbiased estimator. In this series of ablation experiments, at each step we take away more information available to the ranker and demonstrate the necessity of some of our assumptions. The performance of these ablations is summarized in Fig. <ref type="figure" target="#fig_5">5</ref> with metrics in Table <ref type="table" target="#tab_2">3</ref>. For each of these experiments, with notation from Definition 5, we observe a log entry (?, ?, ?, rank ? (?)) where ? is the prefix, ? is the logged query, and ? is the logged document. We change only how we estimate the quality of a new query ? with respect to the prefix ?. We begin by considering a ranker trained by neglecting the biased nature of clicks in the logged data, described as:</p><p>? Biased Estimates, trained on utility estimates that are not de-biased by multiplying by an inverse propensity score. In particular, we train our ranker on targets ? rank ? (?) , which, due to the nature of log collection, amount to biased estimates of the objective.     As expected (refer to Table <ref type="table" target="#tab_2">3</ref>), removing the click propensity correction adds bias to the estimates and hurts the quality of the final ranker. Second, we try to model the user experience, where a user who knows for which document she is searching can reason about likely queries; because users tend to not explore deep into the ranking, we suppose that the user is only able to reason correctly about queries leading to a desired document ranked sufficiently highly. We refer to this policy as prescience, the ability of the ranker to see only whether or not a relevant document is ranked by the query in a high position, but without knowledge of the precise position of the relevant document. Formally, for fixed ? ? N ? {?}, we consider:</p><p>? Prescient@k, trained on utility estimates 1[rank ? (?) ? ?], assigning positive utility to queries ranking a relevant document sufficiently high. We train these policies for ? ? {1, 5, ?}, denoted by Prescient@1, Prescient@5, and Prescient. The average utilities at each rank are summarized in Fig. <ref type="figure" target="#fig_7">6</ref> with metrics in Table <ref type="table" target="#tab_2">3</ref>. Unsurprisingly, the ranker trained on the unbiased estimates does better than any of the prescient policies and the quality of the Prescient@k models decreases along with ?. Note that this second fact is not obvious as there are two competing factors contributing information to the Prescient@k data: first, with a higher ?, the training data provide strictly more information about which queries contain documents relevant to which contexts (with ? = ? simply binarizing our estimated utility); second, with a lower ?, the training data provide more positional information about which queries rank relevant documents more highly. Thus, there are two competing effects, although the first effect clearly dominates in our experiments.</p><p>Somewhat surprisingly, Prescient is better than Biased Estimates. We suspect that this is an artifact of the specific PLTR reduction that xgboost uses, where, without instance weighing, the magnitude of the utility is irrelevant. Unsurprisingly, as ? decreases, the quality of the Prescient@k policy tends in the same direction, corresponding to the fact that less information is available to the ranker.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7.3.4</head><p>How robust is the proposed approach to mis-specification of click propensities? We also consider what happens when we mis-specify the click propensity model. Having simulated the logs Table <ref type="table">4</ref>: Position-Weighted Utilities of the proposed strategy when trained with mis-specified click propensity models. Despite mis-specification, it is worthwhile noting that each of these estimators still outperforms the logging policy that has a relative utility of 1.0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ranking Policy</head><p>Utility@1 Utility@5 Utility@10 Propensity0.5 ? For a fixed ? &gt; 0, denote by Misspecified(?) a utility-aware ranker trained using the click propensity model ? ? ? ? -? .</p><p>We try ? ? {.5, 2} and refer to these models as Misspecified (0.5) and Misspecified (2). The average utilities against ranks are summarized in Fig. <ref type="figure" target="#fig_8">7</ref> with metrics included in Table <ref type="table">4</ref>. Once again, we see that our utility-estimate-trained ranker outperforms the misspecified ranker, although the misspecification does not destroy performance. Interestingly, mis-specification is more tolerable if we make the tails fatter than if we shrink the tails. This is unsurprising given Proposition 9, which says that the variance of the estimator depends on the maximum of the restricted likelihood ratio; the fatter the tail, the lower this bound. Thus, while mis-specifying the click propensity model introduces bias, if we over-fatten the tails we can also significantly reduce variance, as observed in <ref type="bibr" target="#b28">[29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Empirical Results -Data from an Online Shopping Store</head><p>Considering data from a real world online shopping store, we present an empirical validation of the utility-aware QAC system by comparing our utility-aware estimation procedure against baselines described in Section 7.2; in particular, we consider the utility-aware ranker (Unbiased), the retriever (PECOS), the Oracle, and the Random policies. Our results are presented in table <ref type="table" target="#tab_3">Table 5</ref>. Once again we see a clear advantage of the proposed approach over the PECOS model. The primary difference between this setting and that of the simulated data above is that the utilities are much higher. In fact, we believe that the retriever is much better at surfacing highutility queries both due to the added contextual information and the volume of data on which each model was trained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>In this work, we consider a utility maximizing perspective to optimizing QAC systems and cast it as one of optimizing a ranking of rankings task. We then present an approach to learn such a ranking policy given logs of biased clickthrough data by proposing an unbiased utility estimator, bounding its variance and generalization error of the policy under standard learning theoretic conditions. We present experimental results on simulated data and real-world clickthrough QAC logs. We present ablation studies that include how the method performs with a mis-specified click propensity model. Questions for future work include how we can go beyond additive utilities, such as considering sub-modular utility functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A PROOFS</head><p>Proof of Proposition 6. Unravelling definitions, we have:</p><formula xml:id="formula_14">? (?, ?|?, ?) = ?? ? ?? ? (?,?)=1 ? rank ? (?) ? rank ? (?) ? (?, ?)<label>(14)</label></formula><p>Taking expectations with respect to ? (?, ?) yields utility ? (?, ?). ? Proof of Proposition 7. Note, first, that Var( ? (?, ?|?, ?)) =</p><formula xml:id="formula_15">E ? ? ? ? ? ? ? ? ? ?? ? ?? ? (?,?)=1 ? rank ? (?) ? rank ? (? ? ) ? rank ? (? ? ) ? (?, ?)? (?, ? ? ) ? ? ? ? ? ? ? ? ? -? (?, ?) 2 (16) = ?? ? ?? ? (?,?)=1 ? 2 rank ? (?) ? rank ? (?) -? (?, ?) 2<label>(15)</label></formula><p>where Eq. ( <ref type="formula">16</ref>) follows from expanding the definition of ? and the fact that it is an unbiased estimator and Eq. ( <ref type="formula" target="#formula_16">17</ref>) follows from the fact that ? (?, ?)? (?, ? ? ) = ? (?, ?)? ?? ? with ? ?? ? the Kronecker ?. Suppose there is a unique ? ? ? ? ? ? ; following from eq: 17:</p><p>Var( ? (?, ?|?, ?)) = ? = ? + 1 concludes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?</head><p>Proof of Proposition 9. The first statement is clear from the definition of utility. The second statement follows immediately from Eq. <ref type="bibr" target="#b16">(17)</ref>. ?</p><p>Proof of Lemma 10. This follows from the tower property of conditional expectation, linearity, and Proposition 6. ?</p><p>Proof of Theorem 11. By Lemma 10, it suffices to consider ? instead of ?. From learning theory (see <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b46">47]</ref>) we know that</p><formula xml:id="formula_17">E ?(? ? ) -?(? * ) ? 2E sup ? ? F ? ? (?) -?(?)<label>(19)</label></formula><p>We now use the classical symmetrization technique to control the right hand side by</p><formula xml:id="formula_18">? ? (F ). Let ? ?,? ? (?) = ? (? ? , ?|? ? , ? ? ) -? (? ? , ? ? |? ? , ? ? )<label>(20)</label></formula><p>and ? ?,? ? (?) be the event that ?, ? ? ? ? (?). Furthermore, let E |? denote expectation conditional on the set of ? 1 , . . . , ? ? . Then a standard symmetrization approach yields: </p><formula xml:id="formula_19">E |? sup ? ? F ? ? (?) -?(?)<label>(21)</label></formula><p>Where (a) follows since supremum of a sum is controlled by sum of suprema, (b) follows from positive homogeneity of expectation and supremum, (c) owing to independence of ? ? , and because these are equal in distribution to the collection of ? ? (2? ?,? ? (?) -1), and (d) follows by contraction and because Proposition 9 implies that, as 0 ? ? ? ?, |?| satisfies the same bound. Finally, in the outside sum, the ?, ? ? ? ? ? (? ? ). We ignore queries whose utilities are zero because ? is also zero. Thus number of terms in the sum is bounded by second binomial coefficient of number of queries relevant to at least one ? ? . Taking expectations concludes the proof. ?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B SIMULATING LOG DATA FROM XMC DATA</head><p>We describe our conversion of XMC dataset into the utility-aware ranking problem. To demonstrate our results, we require a dataset with (1) raw text queries, (2) a document retrieval system, and (3) sufficient density in the induced bipartite graph between queries and documents. We need clickthrough logs including queries, relevant documents, and their ranks given a logged query. We consider the XMC dataset as consisting of contexts in the form of raw text and a set of labels associated to that context. We view the raw text as queries and labels as documents. It is clear that (1) holds; furthermore, (3) is a feature of the specific data set. To obtain (2), we train a PECOS model <ref type="bibr" target="#b56">[57]</ref> where the contexts are queries and labels are the documents. This PECOS model is treated as the master document ranker that returns ranked list of products given a query. We generate log data as follows. We sample a query ? from the dataset. We use the PECOS model to produce ranked list of items rank ? . We use a click propensity model where P(? (?) = 1) ? rank ? (?) -1 for each ? returned by the ranker. If ? is relevant for the query ?, then we record ?, ?, and rank ? (?). Otherwise, we throw out the sample and repeat. To get the rank of the relevant product ? given a different query ? ? , we can simply find ? in rank ? ? . For each entry, we randomly truncate the logged query anywhere after the end of the first word and record the resulting prefix. The log data thus consists of a prefix, a query, a product, and a position.</p><p>The above approach is justified in that it is actually fairly similar to the way in which many production product catalogs are constructed. While the production ranker may use more features and consider a more complicated, business-oriented objective, the basic principle remains the same. Similarly, our generation of log data is reasonably close to that which occurs in practice, with the caveat that the click propensity model is likely more involved in practice. The prefixes to queries are often recorded in practice, but, in order to increase the size of the data set, random truncation is also a reasonable strategy and we use it in our implementation on the real data from an online shopping store as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C EXTRA FIGURES</head><p>In this appendix, we compile figures relevant to our experiments for which we did not have space in the main text, in particular the effect of increasing the training set size on the other two weighted utility metrics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example bipartite graph induced by log data and document ranker. Alternative queries for ? 1 are ? 2 , ? 3 if ? 2 is logged and ? 4 if ? 1 is logged.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: Illustration of the construction of the data set used to train ranker. The retriever returns the proposed queries given the context. The production ranker is then used to find the documents given the retrieved queries. This ranking is then used to calculate utilities. Note that different queries can return the same document but in a different order. For instance, ? 1 ranks ? 3 third while ? 2 ranks ? 3 first.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>7. 3 . 3</head><label>33</label><figDesc>What is the impact of de-biased utility estimator Eq. (3) over other biased alternatives? We consider what happens when we train</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Figure 3: Average utilities at each position according to different policies. Note the utilitiy-aware Ranker performs best.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Utilities at each position according to different policies. Biased Estimates is trained on utility estimates not adjusted using the inverse propensity score.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Utilities at each position according to different policies. Note that prescience hurts performance relative to the unbiased utility estimates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure7: Average utilities at each position according to different policies. Misspecified (0.5) is the ranker trained on utility estimates assuming ? ? ? ? -1 2 , Misspecified (2) is the ranker trained on utility estimates assuming ? ? ? ? -2 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :Figure 9 :</head><label>89</label><figDesc>Figure 8: Average utility of first ranked query according to the Utility-Aware Ranker trained on samples of different sizes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Dataset statistics for LF-AmazonTitles-1.3M experiment.</figDesc><table><row><cell></cell><cell cols="2">Retriever Train Ranker Train</cell><cell>Test</cell></row><row><cell># Samples</cell><cell>25, 981, 965</cell><cell>1, 541, 700</cell><cell>386, 648</cell></row><row><cell># Distinct Contexts</cell><cell>294, 538</cell><cell>147, 411</cell><cell>48, 621</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Comparing Position-Weighted Utilities of the proposed framework against core baseline methods outlined in Section 7.2. See Section 7.3.1 for more details.</figDesc><table><row><cell>Ranking Policy</cell><cell cols="3">Utility@1 Utility@5 Utility@10</cell></row><row><cell>Logged</cell><cell>1.000</cell><cell>-</cell><cell>-</cell></row><row><cell>PECOS</cell><cell>1.000</cell><cell>.9128</cell><cell>.8692</cell></row><row><cell>Oracle</cell><cell>2.587</cell><cell>-</cell><cell>-</cell></row><row><cell>Random</cell><cell>.7867</cell><cell>.7867</cell><cell>.7867</cell></row><row><cell>Unbiased (proposed)</cell><cell>1.297</cell><cell>1.232</cell><cell>1.185</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Comparing Position-Weighted Utilities of proposed framework (with un-biased utility estimates) against biased utility estimators described in Section 7.3.3.</figDesc><table><row><cell>Ranking Policy</cell><cell cols="3">Utility@1 Utility@5 Utility@10</cell></row><row><cell>Biased Estimates</cell><cell>1.200</cell><cell>1.176</cell><cell>1.146</cell></row><row><cell>Prescient</cell><cell>1.240</cell><cell>1.222</cell><cell>1.178</cell></row><row><cell>Prescient@5</cell><cell>1.233</cell><cell>1.179</cell><cell>1.131</cell></row><row><cell>Prescient@1</cell><cell>1.131</cell><cell>1.104</cell><cell>1.076</cell></row><row><cell>Unbiased (proposed)</cell><cell>1.297</cell><cell>1.232</cell><cell>1.185</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5 :</head><label>5</label><figDesc>Performance of different ranking policies on data from an online shopping store. know that the probability of a click is inversely proportional to the rank. In this experiment, we keep the logs the same, but estimate the utility with a different click propensity model:</figDesc><table><row><cell></cell><cell></cell><cell>1.244</cell><cell cols="2">1.221</cell><cell>1.174</cell></row><row><cell cols="2">Propensity2</cell><cell>1.192</cell><cell cols="2">1.158</cell><cell>1.128</cell></row><row><cell cols="2">Unbiased (proposed)</cell><cell>1.297</cell><cell cols="2">1.232</cell><cell>1.185</cell></row><row><cell>Ranking Policy</cell><cell cols="5">Logged Unbiased PECOS Oracle Random</cell></row><row><cell>Utility@1</cell><cell>1.0</cell><cell>1.979</cell><cell>1.535</cell><cell>3.890</cell><cell>1.290</cell></row><row><cell>ourselves, we</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>? ?,? ? (?)? ?,? ? (?)? (? ? , ?, ? ? ) ?,? ? (?)(2? ?,? ? (?))? (? ? , ?, ? ? ) ? ? ? ?,? ? (?)? (? ? , ?, ? ? ) (2? ?,? ? (?) -1)+? ?,? ? (?)? (? ? , ?, ? ? ) ?,? ? (?)? (? ? , ?, ? ? )<ref type="bibr" target="#b24">(25)</ref> </figDesc><table><row><cell cols="2">? 2E |?</cell><cell cols="2">? ? ? ? ? ? ? ? F sup</cell><cell>1 ?</cell><cell>? ?? ?=1</cell><cell>? ?</cell><cell>1 ? 2</cell><cell>?? ?,? ?</cell><cell>? ? ? ? ? ?</cell><cell>(22)</cell></row><row><cell>(?) ?</cell><cell>1 ? 2</cell><cell>?? ?,? ?</cell><cell cols="4">E |? sup ? ? F</cell><cell>1 ?</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(23)</cell></row><row><cell>(?) ?</cell><cell>1 ? 2</cell><cell>?? ?,? ?</cell><cell cols="2">E |?</cell><cell cols="3">sup ? ? F</cell><cell>1 ?</cell><cell>? ?=1 (24)</cell></row><row><cell>(?) ?</cell><cell>2 ? 2</cell><cell>?? ?,? ?</cell><cell cols="4">E |? sup ? ? F</cell><cell>1 ?</cell><cell></cell></row><row><cell>(?) ?</cell><cell>2? ? 2</cell><cell>?? ?,? ?</cell><cell cols="4">E |? sup ? ? F</cell><cell>1 ?</cell><cell></cell></row></table><note><p>? ?? ?=1 ? ? ? ? ?? ?=1 ? ? ? ? ?? ?=1 ? ? ? (? ? , ?, ? ? )</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>AB acknowledges support from the <rs type="funder">National Science Foundation Graduate Research Fellowship</rs> under Grant No. <rs type="grantNumber">1122374</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_zEqqJab">
					<idno type="grant-number">1122374</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Generalization Bounds for the Area Under the ROC Curve</title>
		<author>
			<persName><forename type="first">Shivani</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thore</forename><surname>Graepel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ralf</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sariel</forename><surname>Har-Peled</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<ptr target="http://jmlr.org/papers/v6/agarwal05a.html" />
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="393" to="425" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Context-sensitive query auto-completion</title>
		<author>
			<persName><forename type="first">Ziv</forename><surname>Bar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-Yossef</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Naama</forename><surname>Kraus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="107" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dahiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Prabhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Varma</surname></persName>
		</author>
		<ptr target="http://manikvarma.org/downloads/XC/XMLRepository.html" />
		<title level="m">The extreme classification repository: Multi-label datasets and code</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Counterfactual Reasoning and Learning Systems</title>
		<author>
			<persName><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joaquin</forename><surname>Qui?onero-Candela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denis</forename><forename type="middle">X</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Max</forename><surname>Chickering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elon</forename><surname>Portugaly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipankar</forename><surname>Ray</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1209.2355</idno>
		<ptr target="http://leon.bottou.org/papers/tr-bottou-2012" />
		<editor>Patrice Simard, and Ed Snelson</editor>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">From RankNet to LambdaRank to LambdaMART: An Overview</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Burges</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Microsoft Research</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning to Rank using Gradient Descent</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName><surname>Burges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erin</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lazier</forename><surname>Renshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deeds</forename><surname>Ari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamilton</forename><surname>Matt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hullender</forename><surname>Nicole</surname></persName>
		</author>
		<author>
			<persName><surname>Greg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML&apos;05</title>
		<meeting><address><addrLine>Bonn, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Survey of Query Auto Completion in Information Retrieval</title>
		<author>
			<persName><forename type="first">Fei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="273" to="363" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Time-sensitive Personalized Query Auto-Completion</title>
		<author>
			<persName><forename type="first">Fei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shangsong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1599" to="1608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Prefix-Adaptive and Time-Sensitive Personalized Query Auto Completion</title>
		<author>
			<persName><forename type="first">Fei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shangsong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2452" to="2466" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Diversifying Query Auto-Completion</title>
		<author>
			<persName><forename type="first">Fei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ridho</forename><surname>Reinanda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">33</biblScope>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">XGBoost: A Scalable Tree Boosting System</title>
		<author>
			<persName><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<idno type="DOI">10.1145/2939672.2939785</idno>
		<ptr target="https://doi.org/10.1145/2939672.2939785" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>San Francisco, California, USA; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">XGBoost: A Scalable Tree Boosting System</title>
		<author>
			<persName><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<idno>CoRR abs/1603.02754</idno>
		<ptr target="http://arxiv.org/abs/1603.02754" />
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Ranking and empirical minimization of U-statistics</title>
		<author>
			<persName><forename type="first">St?phan</forename><surname>Cl?men?on</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G?bor</forename><surname>Lugosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Vayatis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="844" to="874" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Performance of recommender algorithms on top-n recommendation tasks</title>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Cremonesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Turrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="39" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fast, Accurate Detection of 100, 000 Object Classes on a Single Machine</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">L</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">A</forename><surname>Ruzon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sudheendra</forename><surname>Vijayanarasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Yagnik</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2013.237</idno>
		<ptr target="http://doi.ieeecomputersociety.org/10.1109/CVPR.2013.237" />
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1814" to="1821" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Learning to Attend, Copy, and Generate for Session-Based Query Suggestion</title>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sascha</forename><surname>Rothe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enrique</forename><surname>Alfonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Fleury</surname></persName>
		</author>
		<idno>CoRR abs/1708.03418</idno>
		<ptr target="http://arxiv.org/abs/1708.03418" />
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-1423</idno>
		<ptr target="https://doi.org/10.18653/v1/n19-1423" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<title level="s">Long and Short Papers</title>
		<editor>
			<persName><forename type="first">Jill</forename><surname>Burstein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Christy</forename><surname>Doran</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thamar</forename><surname>Solorio</surname></persName>
		</editor>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06-02">2019. June 2-7, 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A probabilistic theory of pattern recognition</title>
		<author>
			<persName><forename type="first">Luc</forename><surname>Devroye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laszlo</forename><surname>Gyorfi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabor</forename><surname>Lugosi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Miroslav</forename><surname>Dud?k</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<idno>CoRR abs/1103.4601</idno>
		<ptr target="http://arxiv.org/abs/1103.4601" />
		<title level="m">Doubly Robust Policy Evaluation and Learning</title>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">More Robust Doubly Robust Off-policy Evaluation</title>
		<author>
			<persName><forename type="first">Mehrdad</forename><surname>Farajtabar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinlam</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Ghavamzadeh</surname></persName>
		</author>
		<idno>CoRR abs/1802.03493</idno>
		<ptr target="http://arxiv.org/abs/1802.03493" />
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Accelerating Large-Scale Inference with Anisotropic Vector Quantization</title>
		<author>
			<persName><forename type="first">Ruiqi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Lindgren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quan</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Simcha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Chern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjiv</forename><surname>Kumar</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">ICML (Proceedings of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="3887" to="3896" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Support vector learning for ordinal regression</title>
		<author>
			<persName><forename type="first">R</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Graepel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Obermayer</surname></persName>
		</author>
		<idno type="DOI">10.1049/cp:19991091</idno>
		<ptr target="https://doi.org/10.1049/cp" />
	</analytic>
	<monogr>
		<title level="m">1999 Ninth International Conference on Artificial Neural Networks ICANN 99. (Conf. Publ</title>
		<imprint>
			<date type="published" when="1999">1999. 19991091</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="97" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A generalization of sampling without replacement from a finite universe</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JASA</title>
		<imprint>
			<date type="published" when="1952">1952. 1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Personalized Language Model for Query Auto-Completion</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Jaech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<idno>CoRR abs/1804.09661</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Cumulated gain-based evaluation of IR techniques</title>
		<author>
			<persName><forename type="first">Kalervo</forename><surname>J?rvelin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaana</forename><surname>Kek?l?inen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="422" to="446" />
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Optimizing Search Engines Using Clickthrough Data</title>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<idno type="DOI">10.1145/775047.775067</idno>
		<ptr target="https://doi.org/10.1145/775047.775067" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>Edmonton, Alberta, Canada; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
	<note>KDD &apos;02)</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A Support Vector Method for Multivariate Performance Measures</title>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="377" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Deep Learning with Logged Bandit Feedback</title>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In ICLR. &quot;OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Unbiased learning-to-rank with biased feedback</title>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Schnabel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Tenth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="781" to="789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Online and Stochastic Gradient Methods for Non-decomposable Loss Functions</title>
		<author>
			<persName><forename type="first">Purushottam</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harikrishna</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prateek</forename></persName>
		</author>
		<idno>CoRR abs/1410.6776</idno>
		<ptr target="http://arxiv.org/abs/1410.6776" />
		<imprint>
			<date type="published" when="2014">Jain 0002. 2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Inferring Networks of Substitutable and Complementary Products</title>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="DOI">10.1145/2783258.2783381</idno>
		<ptr target="https://doi.org/10.1145/2783258.2783381" />
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Association for Computing Machinery</publisher>
			<biblScope unit="page" from="785" to="794" />
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Image-Based Recommendations on Styles and Substitutes</title>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Targett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinfeng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anton</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><surname>Hengel</surname></persName>
		</author>
		<idno type="DOI">10.1145/2766462.2767755</idno>
		<ptr target="https://doi.org/10.1145/2766462.2767755" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Santiago, Chile; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="43" to="52" />
		</imprint>
	</monogr>
	<note>SIGIR &apos;15)</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Fast Label Embeddings for Extremely Large Output Spaces</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Mineiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikos</forename><surname>Karampatziakis</surname></persName>
		</author>
		<idno>CoRR abs/1412.6547</idno>
		<ptr target="http://arxiv.org/abs/1412.6547" />
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A Neural Language Model for Query Auto-Completion</title>
		<author>
			<persName><forename type="first">Dae</forename><surname>Hoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Park</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Rikio</forename><surname>Chiba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1189" to="1192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Parabel: Partitioned Label Trees for Extreme Classification with Application to Dynamic Search Advertising</title>
		<author>
			<persName><forename type="first">Yashoteja</forename><surname>Prabhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anil</forename><surname>Kag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shrutendra</forename><surname>Harsola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
	<note>Rahul Agrawal, and Manik Varma</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Are Neural Rankers still Outperformed by Gradient Boosted Decision Trees?</title>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honglei</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rama</forename><surname>Kumar Pasumarthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Najork</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>In ICLR. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Unbiased Comparative Evaluation of Ranking Functions</title>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Adith Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Frazier</surname></persName>
		</author>
		<author>
			<persName><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval</title>
		<meeting>the 2016 ACM International Conference on the Theory of Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning to personalize query auto-completion</title>
		<author>
			<persName><forename type="first">Milad</forename><surname>Shokouhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="103" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Time-sensitive query auto-completion</title>
		<author>
			<persName><forename type="first">Milad</forename><surname>Shokouhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kira</forename><surname>Radinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="601" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Asymmetric LSH (ALSH) for Sublinear Time Maximum Inner Product Search (MIPS)</title>
		<author>
			<persName><forename type="first">Anshumali</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ping</forename><surname>Li</surname></persName>
		</author>
		<idno>CoRR abs/1405.5869</idno>
		<ptr target="http://arxiv.org/abs/1405.5869" />
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">A Hierarchical Recurrent Encoder-Decoder For Generative Context-Aware Query Suggestion</title>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hossein</forename><surname>Vahabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christina</forename><surname>Lioma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><forename type="middle">Grue</forename><surname>Simonsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<idno>CoRR abs/1507.02221</idno>
		<ptr target="http://arxiv.org/abs/1507.02221" />
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Learning from Logged Implicit Exploration Data</title>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">L</forename><surname>Strehl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sham</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
		<idno>CoRR abs/1003.0120</idno>
		<ptr target="http://arxiv.org/abs/1003.0120" />
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">Yi</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lequn</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Santacatterina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<title level="m">CAB: Continuous Adaptive Blending Estimator for Policy Evaluation and Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Batch learning from logged bandit feedback through counterfactual risk minimization</title>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=2886805" />
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1731" to="1755" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Off-policy evaluation for slate recommendation</title>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akshay</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alekh</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miroslav</forename><surname>Dud?k</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damien</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Imed</forename><surname>Zitouni</surname></persName>
		</author>
		<idno>CoRR abs/1605.04812</idno>
		<ptr target="http://arxiv.org/abs/1605.04812" />
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Probability in high dimension</title>
		<author>
			<persName><forename type="first">Ramon</forename><surname>Van Handel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>PRINCETON UNIV NJ</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">High-dimensional statistics: A non-asymptotic viewpoint</title>
		<author>
			<persName><forename type="first">Wainwright</forename><surname>Martin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="volume">48</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Hashing for Similarity Search: A Survey</title>
		<author>
			<persName><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingkuan</forename><surname>Heng Tao Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianqiu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><surname>Ji</surname></persName>
		</author>
		<idno>CoRR abs/1408.2927</idno>
		<ptr target="http://arxiv.org/abs/1408.2927" />
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Efficient Neural Query Auto Completion</title>
		<author>
			<persName><forename type="first">Sida</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiwei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huiji</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Long</surname></persName>
		</author>
		<idno>CoRR abs/2008.02879</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning to Rank with Selection Bias in Personal Search</title>
		<author>
			<persName><forename type="first">Xuanhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Najork</surname></persName>
		</author>
		<idno type="DOI">10.1145/2911451.2911537</idno>
		<ptr target="https://doi.org/10.1145/2911451.2911537" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Pisa, Italy; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="115" to="124" />
		</imprint>
	</monogr>
	<note>SIGIR &apos;16)</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Position bias estimation for unbiased learning to rank in personal search</title>
		<author>
			<persName><forename type="first">Xuanhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nadav</forename><surname>Golbandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Najork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Eleventh ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="610" to="618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Optimal and Adaptive Off-policy Evaluation in Contextual Bandits</title>
		<author>
			<persName><forename type="first">Yu-Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alekh</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miroslav</forename><surname>Dud?k</surname></persName>
		</author>
		<idno>CoRR abs/1612.01205</idno>
		<ptr target="http://arxiv.org/abs/1612.01205" />
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-Art Natural Language Processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R?mi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName><surname>Rush</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/2020.emnlp-demos.6" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Session-Aware Query Auto-completion using Extreme Multi-label Ranking</title>
		<author>
			<persName><forename type="first">Nishant</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajat</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">N</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arya</forename><surname>Mazumdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inderjit</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<idno>CoRR abs/2012.07654</idno>
		<ptr target="https://arxiv.org/abs/2012.07654" />
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Unbiased offline recommender evaluation for missing-not-atrandom implicit feedback</title>
		<author>
			<persName><forename type="first">Longqi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM Conference on Recommender Systems</title>
		<meeting>the 12th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="279" to="287" />
		</imprint>
	</monogr>
	<note>Serge Belongie, and Deborah Estrin</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">PD-Sparse: A Primal and Dual Sparse Approach to Extreme Multiclass and Multilabel Classification</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>En-Hsu Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangru</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inderjit</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">48</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Pecos: Prediction for enormous and correlated output spaces</title>
		<author>
			<persName><forename type="first">Hsiang-Fu</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inderjit S</forename><surname>Dhillon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.05878</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
