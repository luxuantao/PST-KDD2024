<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cryptographically Sound and Machine-Assisted Verification of Security Protocols</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Michael</forename><surname>Backes</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM Zurich Research Laboratory</orgName>
								<address>
									<settlement>Rüschlikon</settlement>
									<country>Switzerland †</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Christian</forename><surname>Jacobi</surname></persName>
							<email>cjacobi@de.ibm.com</email>
							<affiliation key="aff1">
								<orgName type="institution">IBM Deutschland Entwicklung GmbH</orgName>
								<address>
									<addrLine>Processor Development 2</addrLine>
									<settlement>Böblingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Cryptographically Sound and Machine-Assisted Verification of Security Protocols</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">814E1ABBC59156E7E2B3AF65C207E91E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>cryptography</term>
					<term>specification</term>
					<term>verification</term>
					<term>PVS</term>
					<term>semantics</term>
					<term>simulatability</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We consider machine-aided verification of suitably constructed abstractions of security protocols, such that the verified properties are valid for the concrete implementation of the protocol with respect to cryptographic definitions. In order to link formal methods and cryptography, we show that integrity properties are preserved under step-wise refinement in asynchronous networks with respect to cryptographic definitions, so formal verifications of our abstractions carry over to the concrete counterparts. As an example, we use the theorem prover PVS to formally verify a system for ordered secure message transmission, which yields the first example ever of a formally verified but nevertheless cryptographically sound proof of a security protocol. We believe that a general methodology for verifying cryptographic protocols cryptographically sound can be derived by following the ideas of this example.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Nowadays, formal analysis and verification of security protocols is getting more and more attention in both theory and practice. One main goal of protocol verification is to consider the cryptographic aspects of protocols in order to obtain complete and mathematically rigorous proofs with respect to cryptographic definitions. We speak of (cryptographically) sound proofs in this case. Ideally, these proofs should be performed machine-aided in order to eliminate (or at least minimize) human inaccuracies. As formally verifying cryptographic protocols presupposes abstractions of them, which are suitable for formal methods, it has to be ensured that properties proved for these abstract specifications carry over to the concrete implementations.</p><p>Both formal verification and cryptographically sound proofs have been investigated very well from their respective communities during the last years. Especially the formal verification has been subject of lots of papers in the literature, e.g., <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b15">16]</ref>. The underlying abstraction is almost always based on the Dolev-Yao model <ref type="bibr" target="#b6">[7]</ref>. Here cryptographic operations, e.g., E for encryption and D for decryption, are considered as operators in a free algebra where only certain predefined cancellation rules hold, i.e., twofold encryption of a message m does not yield another message from the basic message space but the term E(E(m)). A typical cancellation rule is D(E(m)) = m. † Work was done while both authors were affiliated with Saarland University. This abstraction simplifies proofs of larger protocols considerably. Unfortunately, these formal proofs lack a link to the rigorous security definitions in cryptography. The main problem is that the abstraction requires that no equations hold except those that can be derived within the algebra. Cryptographic definitions do not aim at such statements. For example, encryption is only required to keep cleartexts secret, but there is no restriction on structure in the ciphertexts. Hence a protocol that is secure in the Dolev-Yao framework is not necessarily secure in the real world even if implemented with provably secure cryptographic primitives, cf. <ref type="bibr" target="#b16">[17]</ref> for a concrete counterexample. Thus, the appropriateness of this approach is at least debatable.</p><p>On the other hand, we have the computational view whose definitions are based on complexity theory, e.g., <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b4">5]</ref>. Here, protocols can be rigorously proven with respect to cryptographic definitions, but these proofs are not feasible for formal verification because of the occurrence of probabilities and complexity-theoretic restrictions, so they are both prone to errors and simply too complex for larger systems.</p><p>Unfortunately, achieving both points at the same time seems to be a very difficult task. To the best of our knowledge, no cryptographic protocol has been formally verified such that this verification is valid for the concrete implementation with respect to the strongest possible cryptographic definitions, cf. the Related Literature for more details.</p><p>Our goal is to link both approaches to get the best overall result: proofs of cryptographic protocols that allow abstraction and the use of formal methods, but retain a sound cryptographic semantics. Moreover, these proofs should be valid for completely asynchronous networks and the strongest cryptographic definitions possible, e.g., security against adaptive chosen ciphertext attack <ref type="bibr" target="#b4">[5]</ref> in case of asymmetric encryption.</p><p>In this paper, we address the verification of integrity properties such that these properties automatically carry over from the abstract specification to the concrete implementation. Our work is motivated by the work of Pfitzmann and Waidner which have already shown in <ref type="bibr" target="#b17">[18]</ref> that integrity properties are preserved under refinement for a synchronous timing model. However, a synchronous definition of time is difficult to justify in the real world since no notion of rounds is naturally given there and it seems to be very difficult to establish them for the Internet, for example. In contrast to that, asynchronous scenarios are attractive, because no assumptions are made about network delays and the relative execution speed of the parties. Moreover, <ref type="bibr" target="#b17">[18]</ref> solely comprises the theoretical background, since they neither investigated the use of nor actually used formal proof tools for the verification of a concrete example.</p><p>Technically, the first part of our work can be seen as an extension of the results of <ref type="bibr" target="#b17">[18]</ref> to asynchronous scenarios as presented in <ref type="bibr" target="#b18">[19]</ref>. This extension is not trivial since synchronous time is much easier to handle; moreover, both models do not only differ in the definition of time but also in subtle, but important details. The second part of this paper is dedicated to the actual verification of a concrete cryptographic protocol: secure message transmission with ordered channels <ref type="bibr" target="#b3">[4]</ref>. This yields the first example of a machine-aided proof of a cryptographic protocol in asynchronous networks such that the proven security is equivalent to the strongest cryptographic definition possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Literature. An extended version of this work is available as an IBM Research</head><p>Report <ref type="bibr" target="#b2">[3]</ref>. The goal of retaining a sound cryptographic semantics and nevertheless provide abstract interfaces for formal methods is pursued by several researchers: our approach is based on the model for reactive systems in asynchronous networks recently introduced in <ref type="bibr" target="#b18">[19]</ref>, which we believe to be really close to this goal. As we already mentioned above, Pfitzmann and Waidner have shown in <ref type="bibr" target="#b17">[18]</ref> that integrity properties are preserved for reactive systems, but only under a synchronous timing model and they have neither investigated the use of formal methods nor the verification of a concrete example. Other possible ways to achieve this goal have been presented in <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b0">1]</ref>, e.g., but these either do not provide abstractions for using formal methods, or they are based on unfaithful abstractions -following the approach of Dolev and Yao <ref type="bibr" target="#b6">[7]</ref> -in the sense that no secure cryptographic implementation of them is known.</p><p>In <ref type="bibr" target="#b1">[2]</ref>, Abadi and Rogaway have shown that a slight variation of the standard Dolev-Yao abstraction is cryptographically faithful specifically for symmetric encryption. However, their results hold only for passive adversaries and for a synchronous timing model, but the authors already state that active adversaries and an asynchronous definition of time are important goals to strive for. Another interesting approach has been presented by Guttman et. al. <ref type="bibr" target="#b10">[11]</ref>, which starts adapting the strand space theory to concrete cryptographic definitions. However, their results are specific for the Wegman-Carter system so far. Moreover, as this system is information-theoretically secure, its security proof is much easier to handle than asymmetric primitives since no reduction proofs against underlying number-theoretic assumptions have to be made.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Reactive Systems in Asynchronous Networks</head><p>In this section we briefly sketch the model for reactive systems in asynchronous networks from <ref type="bibr" target="#b18">[19]</ref>. All details not necessary for understanding are omitted. Machines are represented by probabilistic state-transition machines, similar to probabilistic I/O automata <ref type="bibr" target="#b13">[14]</ref>. For complexity we consider every automaton to be implemented as a probabilistic Turing machine; complexity is measured in the length of its initial state, i.e., the initial worktape content (often a security parameter k in unary representation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">General System Model and Simulatability</head><p>A system consists of several possible structures. A structure is a pair ( M , S ) of a set M of connected correct machines and a subset S of the free ports<ref type="foot" target="#foot_0">1</ref> , called specified ports. Roughly, specified ports provide certain services to the honest users. In a standard cryptographic system, the structures are derived from one intended structure and a trust model. The trust model consists of an access structure ACC and a channel model χ. Here ACC contains the possible sets H of indices of uncorrupted machines (among the intended ones), and χ designates whether each channel is secure, reliable (authentic but not private) or insecure. Each structure can be completed to a configuration by adding an arbitrary user machine H and adversary machine A. H connects only to ports in S and A to the rest, and they may interact. The general scheduling model in <ref type="bibr" target="#b18">[19]</ref> gives each connection c a buffer, and the machine with the corresponding clock port c ! can schedule a message when it makes a transition. In real asynchronous cryptographic systems, all connections are typically scheduled by A. Thus a configuration is a runnable system, i.e., one gets a probability space of runs and views of individual machines in these runs. For a configuration conf , we denote the random variables over this probability space by run conf ,k and view conf ,k , respectively. For a polynomial l, we further obtain random variables for l-step prefixes of the runs, denoted by run conf ,k,l(k) . Moreover, a run r can be restricted to a set S of ports which is denoted by r S .</p><p>Simulatability essentially means that whatever can happen to certain users in the real system can also happen to the same users in the ideal (abstract) system: For every structure struc 1 = ( M1 , S 1 ) of the real system, every user H, and every adversary A 1 there exists an adversary A 2 on a corresponding ideal structure struc 2 = ( M2 , S 2 ), such that the view of H in the two configurations is indistinguishable, cf. Figure <ref type="figure">1</ref>. Indistinguishability is a well-defined cryptographic notion from <ref type="bibr" target="#b21">[22]</ref>. We write this Sys real ≥ sec Sys id</p><formula xml:id="formula_0">H H A 2 A 1 S S M u M v TH M 3 ∀ ∀ ∃ Real configuration Ideal configuration M 1 ^∈ f(M 1 , S) M2</formula><p>Fig.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1.</head><p>Overview of the simulatability definition. The view of H must be indistinguishable in the two configurations. In this example, H = {1, 2}. and say that Sys real is at least as secure as Sys id . In general, a mapping f may denote the correspondence between ideal and real structures and one writes ≥ f sec , but with the further restriction that f maps identical sets of specified ports. An important feature of the system model is transitivity of ≥ sec , i.e., the preconditions Sys 1 ≥ sec Sys 2 and Sys 2 ≥ sec Sys 3 together imply Sys 1 ≥ sec Sys 3 <ref type="bibr" target="#b18">[19]</ref>.</p><p>In a typical ideal system, each structure contains only one machine TH called trusted host, whereas structures of real systems typically consist of several machines M i , one for each honest user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Integrity Properties</head><p>In this section, we show how the relation "at least as secure as" relates to integrity properties a system should fulfill, e.g., safety properties expressed in temporal logic. As a rather general version of integrity properties, independent of the concrete formal language, we consider those that have a linear-time semantics, i.e., that correspond to a set of allowed traces of in-and outputs. We allow different properties for different sets of specified ports, since different requirements of various parties in cryptography are often made for different trust assumptions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 1 (Integrity Properties</head><p>). An integrity property Req for a system Sys is a function that assigns a set of valid traces at the ports in S to each set S with ( M , S ) ∈ Sys. More precisely such a trace is a sequence (v i ) i∈N of values over port names and Σ * , so that v i is of the form v i := p∈S {p : v p,i } and v p,i ∈ Σ * . We say that Sys fulfills Req a) perfectly (written Sys |= perf Req) if for any configuration conf = ( M , S , H, A) ∈ Conf(Sys), the restrictions r S of all runs of this configuration to the specified ports S lie in Req(S ). In formulas, [(run conf ,k S )] ⊆ Req(S ) for all k, where [•] denotes the carrier set of a probability distribution. b) statistically for a class SMALL (Sys |= SMALL Req) if for any configuration conf = ( M , S , H, A) ∈ Conf(Sys), the probability that Req(S ) is not fulfilled is small, i.e., for all polynomials l (and as a function of k),</p><formula xml:id="formula_1">P (run conf ,k ,l(k ) S ∈ Req(S )) ∈ SMALL.</formula><p>The class SMALL must be closed under addition and contain any function g less than or equal to any function g ∈ SMALL. c) computationally (Sys |= poly Req) if for any polynomial configuration conf = ( M , S , H, A) ∈ Conf poly (Sys), the probability that Req(S ) is not fulfilled is negligible, i.e., P (run conf ,k S ∈ Req(S )) ∈ NEGL.</p><p>For the computational and statistical case, the trace has to be finite. Note that a) is normal fulfillment. We write "|=" if we want to treat all three cases together. 3</p><p>Obviously, perfect fulfillment implies statistical fulfillment for every non-empty class SMALL and statistical fulfillment for a class SMALL implies fulfillment in the computational case if SMALL ⊆ NEGL.</p><p>We now prove that integrity properties of abstract specifications carry over to their concrete counterparts in the sense of simulatability, i.e., if the properties are valid for a specification, the concrete implementation also fulfills concrete versions of these goals. As specifications are usually built by only one idealized, deterministic machine TH, they are quite easy to verify using formal proof systems, e.g., PVS. Now, our result implies that these verified properties automatically carry over to the (usually probabilistic) implementation without any further work.</p><p>The actual proof will be done by contradiction, i.e., we will show that if the real system does not fulfill its goals, the two systems can be distinguished. However, in order to exploit simulatability, we have to consider an honest user that connects to all specified ports. Otherwise, the contradiction might stem from those specified ports which are connected to the adversary, but those ports are not considered by simulatability. The following lemma will help us to circumvent this problem: Lemma 1. Let a system Sys be given. For every configuration conf = ( M , S , H, A) ∈ Conf(Sys), there is a configuration conf s = ( M , S , H s , A s ) ∈ Conf(Sys) with S ⊆ ports(H s ), such that run conf S = run confs S , i.e., the probability of the runs restricted to the set S of specified ports is identical in both configurations. If conf is polynomialtime, then conf s is also polynomial-time.</p><p>2</p><p>We omit the proof due to space constraints and refer to <ref type="bibr" target="#b2">[3]</ref>.</p><p>Lemma 2. The statistical distance ∆(φ(var k ), φ(var k )) between a function φ of two random variables is at most ∆(var k , var k ). 2</p><p>This is a well-known fact, hence we omit the easy proof.</p><p>Theorem 1 (Conservation of Integrity Properties). Let a system Sys 2 be given that fulfills an integrity property Req, i.e., Sys 2 |= Req, and let Sys 1 ≥ f sec Sys 2 for an arbitrary mapping f . Then also Sys 1 |= Req. This holds in the perfect and statistical sense, and in the computational sense if membership in the set Req(S ) is decidable in polynomial time for all S .</p><p>2</p><p>Proof. Req is well-defined on Sys 1 , since simulatability implies that for each ( M1 , S 1 ) ∈ Sys 1 there exists ( M2 , S 2 ) ∈ f ( M1 , S 1 ) with S 1 = S 2 . We will now prove that if Sys 1 does not fulfill the property, the two systems can be distinguished yielding a contradiction. Assume that a configuration conf 1 = ( M1 , S 1 , H, A 1 ) of Sys 1 contradicts the theorem. As already described above, we need an honest user that connects to all specified ports. This is precisely what Lemma 1 does, i.e., there is a configuration conf s,1 in which the user connects to all specified ports, with run conf s,1 S1 = run conf 1 S1 , so conf s,1 also contradicts the theorem. Note that all specified ports are now connected to the honest user; thus, we can exploit simulatability. <ref type="foot" target="#foot_1">2</ref> Because of our precondition Sys 1 ≥ f sec Sys 2 , there exists an indistinguishable configuration conf s,2 = ( M , S , H s , A 2 ) of Sys 2 , i.e., view conf s,1 (H s ) ≈ view conf s,2 (H s ). By assumption, the property is fulfilled for this configuration (perfectly, statistically, or computationally). Furthermore, the view of H s in both configurations contains the trace at S := S 1 = S 2 , i.e., the trace is a function S of the view.</p><p>In the perfect case, the distribution of the views is identical. This contradicts the assumption that [(run conf s,1 ,k S )] ⊆ Req(S ) while [(run conf s,2 ,k S )] ⊆ Req(S ).</p><p>In the statistical case, let any polynomial l be given. The statistical distance ∆(view conf s,1 ,k,l(k) (H s ), view conf s,2 ,k,l(k) (H s )) is a function g(k) ∈ SMALL. We apply Lemma 2 to the characteristic function 1 v S ∈Req(S ) on such views v. This gives |P (run conf s,1 ,k,l(k) S ∈ Req(S )) -P (run conf s,2 ,k,l(k) S ∈ Req(S ))| ≤ g(k). As SMALL is closed under addition and under making functions smaller, this gives the desired contradiction.</p><p>In the computational case, we define a distinguisher Dis: Given the view of machine H s , it extracts the run restricted to S and verifies whether the result lies in Req(S ). If yes, it outputs 0, otherwise 1. This distinguisher is polynomial-time (in the security parameter k) because the view of H s is of polynomial length, and membership in Req(S ) was required to be polynomial-time decidable. Its advantage in distinguishing is</p><formula xml:id="formula_2">|P (Dis(1 k , view conf s,1 ,k ) = 1) -P (Dis(1 k , view conf s,2 ,k ) = 1)| = |P (run conf s,1 ,k S ∈ Req(S )) -P (run conf s,2 ,k S ∈ Req(S ))|.</formula><p>Since the second term is negligible by assumption, and NEGL is closed under addition, the first term also has to be negligible, yielding the desired contradiction.</p><p>In order to apply this theorem to integrity properties formulated in a logic, e.g., temporal logic, we have to show that abstract derivations in the logic are valid with respect to the cryptographic sense. This can be proven similar to the version with synchronous time, we only include it for reasons of completeness (without proof). Here "⊆" and "'∩" are interpreted pointwise, i.e., for each S . This holds in the perfect and statistical sense, and in the computational sense if for a) membership in Req </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Verification of the Ordered Channel Specification</head><p>In this section we review the specification for secure message transmission with ordered channels <ref type="bibr" target="#b3">[4]</ref>, and we formally verify that message reordering is in fact prevented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Secure Message Transmission with Ordered Channels</head><p>Let n and M := {1, . . . , n} denote the number of participants and the set of indices respectively. The specification is of the typical form Sys spec = {({TH H }, S H )|H ⊆ M}, i.e., there is one structure for every subset of the machines, denoting the honest users. The remaining machines are corrupted, i.e., they are absorbed into the adversary. The ideal machine TH H models initialization, sending and receiving of messages. A user u can initialize communications with other users by inputting a command of the form (snd init) to the port in u ? of TH H . In real systems, initialization corresponds to key generation and authenticated key exchange. Sending of messages to a user v is triggered by a command (send, m, v). If v is honest, the message is stored in an internal array deliver spec u,v of TH H together with a counter indicating the number of the message. After that, a command (send blindly, i, l, v) is output to the adversary, l and i denote the length of the message m and its position in the array, respectively. This models that the adversary will notice in the real world that a message has been sent and he might also be able to know the length of that message. Because of the underlying asynchronous timing model, TH H has to wait for a special term (receive blindly, u, i) or (rec init, u) sent by the adversary, signaling, that the message stored at the ith position of deliver spec u,v should be delivered to v , or that a connection between u and v should be initialized. In the first case, TH H reads (m, j) := deliver spec u,v [i] and checks whether msg out spec u,v ≤ j holds for a message counter msg out spec u,v . If the test is successful the message is delivered at out v ! and the counter is set to j + 1, otherwise TH H outputs nothing. The condition msg out spec u,v ≤ j ensures that messages can only be delivered in the order they have been received by TH H , i.e., neither replay attacks nor reordering messages is possible for the adversary; cf. <ref type="bibr" target="#b3">[4]</ref> for details. The user will receive inputs of the form (receive, u, m) and (rec init, u), respectively. If v is dishonest, TH H will simply output (send, m, v) to the adversary. Finally, the adversary can send a message m to a user u by sending a command (receive, v, m) to the port from adv u ? of TH H for a corrupted user v, and he can also stop the machine of any user by sending a command (stop) to a corresponding port of TH H , which corresponds to exceeding the machine's runtime bound in the real world.</p><p>In contrast to the concrete implementation, which we will review later on, the machine TH H is completely deterministic, hence it can be expressed very well within a formal proof system, which supports the required data structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The Integrity Property</head><p>The considered specification has been designed to fulfill the property that the order of messages is maintained during every trace of the configuration. Thus, for arbitrary traces, arbitrary users u, v ∈ H, u = v, and any point in time, the messages from v received so far by u via TH H should be a sublist of the messages sent from v to TH H aimed for forwarding to u. The former list is called receive-list, the latter send-list.</p><p>In order to obtain trustworthy proofs, we formally verify the integrity property in the theorem proving system PVS <ref type="bibr" target="#b14">[15]</ref>. This will be described in the following. For reasons of readability and brevity, we use standard mathematical notation instead of PVS syntax. The PVS sources are available online. <ref type="foot" target="#foot_2">3</ref>The formalization of the machine TH H in PVS is described in <ref type="bibr" target="#b3">[4]</ref>. We assume that the machine operates on an input set I TH H (short I), a state set States TH H (short S ), and an output set O TH H (short O). For convenience, the transition function δ TH H : I × S → S × O is split into δ : I × S → S and ω : I × S → O, which denote the next-state and output part of δ TH H , respectively. The function δ TH H is defined in PVS's specification language, which contains a complete functional programming language. PVS provides natural, rational, and real numbers, arithmetic, lists, arrays, etc. Furthermore, custom datatypes (including algebraic abstract datatypes) are supported.</p><p>In order to formulate the property, we need a PVS-suited, formal notation of (infinite) runs of a machine, of lists, of what it means that a list l 1 is a sublist of a list l 2 , and we need formalizations of the receive-list and send-list. to inputs i(t) ∈ I M . A given input sequence i defines a sequence of states s i : N → States M of the machine M by the following recursive construction:</p><formula xml:id="formula_3">s i (0) := s init , s i (t + 1) := δ(i(t), s i (t)).</formula><p>The sequence s i is called state-trace of M under i. The output sequence o i : N → O of the run is defined as o i (t) := ω(i(t), s i (t)).</p><p>We omit the index i if the input sequence is clear from the context. For components x of the state type, we write x(t) for the content of x in s(t), e.g., we write deliver spec u,v (t) to denote the content at time t of the list deliver spec u,v , which is part of the state of TH H . 3</p><p>These definitions precisely match the model-intern definition of views, cf. <ref type="bibr" target="#b18">[19]</ref>. In the context of TH H , the input sequence i consists of the messages that the honest users and the adversary send to TH H . In the following, a list l 1 being a sublist of a list l 2 is expressed by l 1 ⊆ l 2 , l 1 being a sublist of the k-prefix of l 2 by l 1 ⊆ k l 2 .</p><p>Lemma 3. Let l 1 , l 2 be lists over some type T , let k ∈ N 0 . It holds:</p><formula xml:id="formula_4">k &lt; length(l 2 ) ∧ l 1 ⊆ k l 2 =⇒ append(nth(l 2 , k), l 1 ) ⊆ k+1 l 2 ,</formula><p>that is, one may append the k th element (counted from 0) of l 2 to l 1 while preserving the prefix-sublist property. </p><formula xml:id="formula_5">recvlist i u,v (t) :=          null if t = -1, append(m, recvlist i u,v (t -1)) if t ≥ 0 ∧ o i (t) = (receive, m, u) at out v !. recvlist i u,v (t -1) otherwise sendlist i u,v (t) :=          null if t = -1, append(m, sendlist i u,v (t -1)) if t ≥ 0 ∧ i(t) = (send, m, v) at in u ?. sendlist i u,v (t -1)<label>otherwise</label></formula><p>3</p><p>We now are ready to give a precise, PVS-suited formulation of the integrity property we are aiming to prove: machine for each honest participant. It uses asymmetric encryption and digital signatures as cryptographic primitives, which satisfy the strongest cryptographic definition possible, i.e., security against adaptive chosen-ciphertext attack in case of encryption (e.g., <ref type="bibr" target="#b5">[6]</ref>) and security against existential forgery under adaptive chosen-message attacks in case of digital signatures (e.g., <ref type="bibr" target="#b9">[10]</ref>).</p><p>A user u can let his machine create signature and encryption keys that are sent to other users over authenticated channels. Messages sent from user u to user v are signed and encrypted by M u and sent to M v over an insecure channel, representing a real network. Similar to TH H each machine maintains internal counters used for discarding messages that are out of order. The adversary schedules the communication between correct machines and it can send arbitrary messages m to arbitrary users. Now the validity of the integrity property of the concrete implementation immediately follows from the Preservation Theorem and the verification of the abstract specification. More precisely, we have shown that the specification fulfills its integrity property of Theorem 3 perfectly, which especially implies computational fulfillment. As Sys impl ≥ poly sec Sys spec has already been shown in <ref type="bibr" target="#b3">[4]</ref>, our proof of integrity carries over to the concrete implementation for the computational case according to Theorem 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we have addressed the problem how cryptographic protocols in asynchronous networks can be verified both machine-aided and sound with respect to the definitions of cryptography. We have shown that the verification of integrity properties of our abstract specifications automatically carries over to the cryptographic implementations, and that logic derivations among integrity properties are valid for the concrete systems in the cryptographic sense, which makes them accessible to theorem provers. As an example, we have formally verified the scheme for ordered secure message transmission <ref type="bibr" target="#b3">[4]</ref> using the theorem proving system PVS <ref type="bibr" target="#b14">[15]</ref>. This yields the first formal verification of an integrity property of a cryptographic protocol whose security is equivalent to the underlying cryptography with respect to the strongest cryptographic definitions possible.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Theorem 2 .</head><label>2</label><figDesc>a) If Sys |= Req 1 and Req 1 ⊆ Req 2 , then also Sys |= Req 2 . b) If Sys |= Req 1 and Sys |= Req 2 , then also Sys |= Req 1 ∩ Req 2 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Definition 2 (</head><label>2</label><figDesc>Input sequence, state trace, output sequence). Let M be a machine with input set I M , state set States M , output set O M , state transition function δ, and output transition function ω. Call s init ∈ States M the initial state. An input sequence i : N → I M for machine M is a function mapping the time (modeled as the set N)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>2 (S ) is decidable in polynomial time for all S . 2 If we now want to apply this theorem to concrete logics, we have to show that the common deduction rules hold. For modus ponens, e.g., if one has derived that a and a → b are valid in a given model, then b is also valid in this model. If Req a etc. denote the semantics of the formulas, i.e., the trace sets they represent, we have to show that (Sys |= Req a and Sys |= Req a→b ) implies Sys |= Req b . From Theorem 2b we conclude Sys |= Req a ∩ Req a→b . Obviously, Req a ∩ Req a→b = Req a∧b ⊆ Req b holds, so the claim follows from Theorem 2a.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>A port is called free if its corresponding port does not belong to a machine in M . These ports are connected to the users and the adversary.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>In the proof for the synchronous timing model, this problem was avoided by combining the honest user and the adversary to the new honest user. However, this combination would yield an invalid configuration in the asynchronous model.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>http://www.zurich.ibm.com/∼mbc/OrdSecMess.tgz</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Theorem 3. For any TH H input sequence i, for any u, v ∈ H, u = v, and any point in time t ∈ N, it holds recvlist i u,v (t) ⊆ sendlist i u,v (t).</p><p>(1)</p><p>In the following, we omit the index i. 2</p><p>Proof (sketch). The proof is split into two parts: we prove recvlist u,v (t -1) ⊆ deliver spec u,v (t) and deliver spec u,v (t) ⊆ sendlist u,v (t -1). The claim of the theorem then follows from transitivity of sublists.</p><p>The claim deliver spec u,v (t) ⊆ sendlist u,v (t -1) is proved by induction on t. Both induction base and step are proved in PVS by the built-in strategy (grind), which performs automatic definition expanding and rewriting with sublist-related lemmas.</p><p>The claim recvlist u,v (t-1) ⊆ deliver spec u,v (t) is more complicated. The claim is also proved by induction on t. However, it is easy to see that the claim is not inductive: in case of a (receive blindly, u, i) at from adv v ?, TH H outputs (receive, m, u) to out v !, where (m, j) := deliver spec u,v [i], i.e., m is the ith message of the deliver spec u,v list (cf. Section 4.1, or <ref type="bibr" target="#b3">[4]</ref> for more details). By the definition of the receive-list, the message m is appended to recvlist u,v . In order to prove that recvlist u,v ⊆ deliver spec u,v is preserved during this transition, it is necessary to know that the receive list was a sublist of the prefix of the deliver spec u,v list that does not reach to m. It would suffice to know that</p><p>Then the claim follows from Lemma 3.</p><p>We therefore strengthen the invariant to comprise the prefix-sublist property. However, the value i in the above prefix-sublist relation stems from the input (receive blindly, u, i), and hence is not suited to state the invariant. To circumvent this problem, we recursively construct a sequence last rcv blindly u,v (t) which holds the parameter i of the last valid (receive blindly, u, i) received by TH H on from adv v ?; then recvlist u,v (t -1) ⊆ l deliver spec u,v (t) with l = last rcv blindly u,v (t)</p><p>is an invariant of the system. We further strengthen this invariant by asserting that last rcv blindly u,v (t) and the j's stored in the deliver spec u,v list grow monotonically. Together this yields the inductive invariant. We omit the details and again refer the to the PVS files available online. 3   Applying Definition 1 of integrity properties, we can now define that the property Req holds for an arbitrary trace tr if and only if Equation 1 holds for all u, v ∈ H, u = v, and the input sequence i of the given trace tr. Thus, Theorem 3 can be rewritten in the notation of Definition 1 as [(run conf ,k S )] ⊆ Req(S ) for all k, i.e., we have shown that the specification Sys spec perfectly fulfills the integrity property Req.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">The Concrete Implementation</head><p>For understanding it is sufficient to give a brief review of the concrete implementation Sys impl , a detailed description can be found in <ref type="bibr" target="#b3">[4]</ref>. Sys impl is of the typical form Sys impl = {( MH , S H ) | H ⊆ M}, where MH = {M u | u ∈ H}, i.e., there is one</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A calculus for cryptographic protocols: The spi calculus</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Computation</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="70" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Reconciling two views of cryptography: The computational soundness of formal encryption</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rogaway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st IFIP International Conference on Theoretical Computer Science</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>1st IFIP International Conference on Theoretical Computer Science</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">1872</biblScope>
			<biblScope unit="page" from="3" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cryptographically sound and machine-assisted verification of security protocols</title>
		<author>
			<persName><forename type="first">M</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jacobi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Research Report RZ</title>
		<imprint>
			<biblScope unit="volume">3468</biblScope>
			<date type="published" when="2002">2002</date>
			<publisher>IBM Research</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deriving cryptographically sound implementations using composition and formally verified bisimulation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jacobi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pfitzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th Symposium on Formal Methods Europe (FME 2002), volume 2391 of Lecture Notes in Computer Science</title>
		<meeting>11th Symposium on Formal Methods Europe (FME 2002), volume 2391 of Lecture Notes in Computer Science</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="310" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Relations among notions of security for public-key encryption schemes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bellare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pointcheval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rogaway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Cryptology: CRYPTO &apos;98</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">1462</biblScope>
			<biblScope unit="page" from="26" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Practical public key cryptosystem provably secure against adaptive chosen ciphertext attack</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shoup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Cryptology: CRYPTO &apos;98</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">1462</biblScope>
			<biblScope unit="page" from="13" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">On the security of public key protocols</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dolev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="198" to="208" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Probabilistic encryption</title>
		<author>
			<persName><forename type="first">S</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Micali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="270" to="299" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The knowledge complexity of interactive proof systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Micali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rackoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="186" to="207" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A digital signature scheme secure against adaptive chosen-message attacks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Micali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Rivest</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="281" to="308" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The faithfulness of abstract protocol analysis: Message authentication</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Guttman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Thayer Fabrega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zuck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th ACM Conference on Computer and Communications Security</title>
		<meeting>8th ACM Conference on Computer and Communications Security</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="186" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A probabilistic poly-time framework for protocol analysis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lincoln</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Scedrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th ACM Conference on Computer and Communications Security</title>
		<meeting>5th ACM Conference on Computer and Communications Security</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="112" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Breaking and fixing the Needham-Schroeder public-key protocol using FDR</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd International Conference on Tools and Algorithms for the Construction and Analysis of Systems (TACAS)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>2nd International Conference on Tools and Algorithms for the Construction and Analysis of Systems (TACAS)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">1055</biblScope>
			<biblScope unit="page" from="147" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Distributed Algorithms</title>
		<author>
			<persName><forename type="first">N</forename><surname>Lynch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Morgan Kaufmann Publishers</publisher>
			<pubPlace>San Francisco</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">PVS: A prototype verification system</title>
		<author>
			<persName><forename type="first">S</forename><surname>Owre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Rushby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th International Conference on Automated Deduction (CADE)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>11th International Conference on Automated Deduction (CADE)</meeting>
		<imprint>
			<publisher>springer</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">607</biblScope>
			<biblScope unit="page" from="748" to="752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The inductive approach to verifying cryptographic protocols</title>
		<author>
			<persName><forename type="first">L</forename><surname>Paulson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cryptology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="85" to="128" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Cryptographic security of reactive systems. Presented at the DERA/RHUL Workshop on Secure Architectures and Information Flow</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pfitzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Waidner</surname></persName>
		</author>
		<ptr target="http://www.elsevier.nl/cas/tree/store/tcs/free/noncas/pc/menu.htm" />
	</analytic>
	<monogr>
		<title level="m">Electronic Notes in Theoretical Computer Science (ENTCS)</title>
		<imprint>
			<date type="published" when="2000-03">March 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Composition and integrity preservation of secure reactive systems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pfitzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Waidner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th ACM Conference on Computer and Communications Security</title>
		<meeting>7th ACM Conference on Computer and Communications Security</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="245" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A model for asynchronous reactive systems and its application to secure message transmission</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pfitzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Waidner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 22nd IEEE Symposium on Security &amp; Privacy</title>
		<meeting>22nd IEEE Symposium on Security &amp; Privacy</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="184" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Modelling and verifying key-exchange protocols using CSP and FDR</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Roscoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th IEEE Computer Security Foundations Workshop (CSFW)</title>
		<meeting>8th IEEE Computer Security Foundations Workshop (CSFW)</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="98" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Security properties and CSP</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 17th IEEE Symposium on Security &amp; Privacy</title>
		<meeting>17th IEEE Symposium on Security &amp; Privacy</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="174" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Theory and applications of trapdoor functions</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 23rd IEEE Symposium on Foundations of Computer Science (FOCS)</title>
		<meeting>23rd IEEE Symposium on Foundations of Computer Science (FOCS)</meeting>
		<imprint>
			<date type="published" when="1982">1982</date>
			<biblScope unit="page" from="80" to="91" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
