<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Automatic Tuberculosis Screening Using Chest Radiographs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Stefan</forename><surname>Jaeger</surname></persName>
							<email>stefan.jaeger@nih.gov</email>
						</author>
						<author>
							<persName><forename type="first">Alexandros</forename><surname>Karargyris</surname></persName>
							<email>alexandros.karargyris@nih.gov</email>
						</author>
						<author>
							<persName><forename type="first">Sema</forename><surname>Candemir</surname></persName>
							<email>sema.candemir@nih.gov</email>
						</author>
						<author>
							<persName><forename type="first">Les</forename><surname>Folio</surname></persName>
							<email>les.folio@nih.gov</email>
						</author>
						<author>
							<persName><forename type="first">Jenifer</forename><surname>Siegelman</surname></persName>
							<email>jen.siegelman@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Fiona</forename><surname>Callaghan</surname></persName>
							<email>fiona.callaghan@nih.gov</email>
						</author>
						<author>
							<persName><forename type="first">Zhiyun</forename><surname>Xue</surname></persName>
							<email>zhiyun.xue@nih.gov</email>
						</author>
						<author>
							<persName><forename type="first">Kannappan</forename><surname>Palaniappan</surname></persName>
							<email>palaniappank@missouri.edu</email>
						</author>
						<author>
							<persName><forename type="first">Rahul</forename><forename type="middle">K</forename><surname>Singh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sameer</forename><surname>Antani</surname></persName>
							<email>sameer.antani@nih.gov</email>
						</author>
						<author>
							<persName><forename type="first">George</forename><surname>Thoma</surname></persName>
							<email>george.thoma@nih.gov</email>
						</author>
						<author>
							<persName><forename type="first">Yi-Xiang</forename><surname>Wang</surname></persName>
							<email>wang@cuhk.edu.hk</email>
						</author>
						<author>
							<persName><forename type="first">Pu-Xuan</forename><surname>Lu</surname></persName>
							<email>lupuxuan@126.com</email>
						</author>
						<author>
							<persName><forename type="first">Clement</forename><forename type="middle">J</forename><surname>Mcdonald</surname></persName>
							<email>clement.mcdonald@nih.gov</email>
						</author>
						<author>
							<persName><forename type="first">Y.-X</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">P.-X</forename><surname>Lu</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">U.S. National Library of Medicine</orgName>
								<address>
									<postCode>20894</postCode>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">is with Radiology and Imaging Sciences</orgName>
								<orgName type="department" key="dep2">Clinical Center</orgName>
								<orgName type="institution">National Institutes of Health</orgName>
								<address>
									<postCode>20892</postCode>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Department of Radiology</orgName>
								<orgName type="department" key="dep2">Brigham and Women&apos;s Hospital</orgName>
								<orgName type="institution">Harvard Medical School</orgName>
								<address>
									<postCode>02115</postCode>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Missouri-Columbia</orgName>
								<address>
									<postCode>65211</postCode>
									<settlement>Columbia</settlement>
									<region>MO</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Department of Imaging and Interventional Radiol-ogy</orgName>
								<orgName type="institution" key="instit1">Prince of Wales Hospital</orgName>
								<orgName type="institution" key="instit2">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shatin, Hong Kong</settlement>
									<region>NT</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department" key="dep1">Department of Radiology</orgName>
								<orgName type="department" key="dep2">The Shenzhen No. 3 People&apos;s Hospital</orgName>
								<orgName type="institution">Guangdong Medical College</orgName>
								<address>
									<postCode>518020</postCode>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Automatic Tuberculosis Screening Using Chest Radiographs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D1CC7647F303E64F0878D79649376504</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. AUTOMATIC TUBERCULOSIS SCREENING USING CHEST RADIOGRAPHS 1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Tuberculosis is a major health threat in many regions of the world. Opportunistic infections in immunocompromised HIV/AIDS patients and multi-drug-resistant bacterial strains have exacerbated the problem, while diagnosing tuberculosis still remains a challenge. When left undiagnosed and thus untreated, mortality rates of patients with tuberculosis are high. Standard diagnostics still rely on methods developed in the last century. They are slow and often unreliable. In an effort to reduce the burden of the disease, this paper presents our automated approach for detecting tuberculosis in conventional posteroanterior chest radiographs. We first extract the lung region using a graph cut segmentation method. For this lung region, we compute a set of texture and shape features, which enable the x-rays to be classified as normal or abnormal using a binary classifier. We measure the performance of our system on two datasets: a set collected by the tuberculosis control program of our local county's health department in the United States, and a set collected by Shenzhen Hospital, China. The proposed computer-aided diagnostic system for TB screening, which is ready for field deployment, achieves a performance that approaches the performance of human experts. We achieve an area under the ROC curve (AUC) of 87% (78.3% accuracy) for the first set, and an AUC of 90% (84% accuracy) for the second set. For the first set, we compare our system performance with the performance of radiologists. When trying not to miss any positive cases, radiologists achieve an accuracy of about 82% on this set, and their false positive rate is about half of our system's rate.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Index Terms-computer-aided detection and diagnosis, lung, pattern recognition and classification, segmentation, tuberculosis, x-ray imaging</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>T UBERCULOSIS (TB) is the second leading cause of death from an infectious disease worldwide, after HIV, with a mortality rate of over 1.2 million people in 2010 <ref type="bibr" target="#b0">[1]</ref>. With about one-third of the world's population having latent TB, and an estimated nine million new cases occurring every year, TB is a major global health problem <ref type="bibr" target="#b1">[2]</ref>. TB is an infectious disease caused by the bacillus Mycobacterium tuberculosis, which typically affects the lungs. It spreads through the air when people with active TB cough, sneeze, or otherwise expel infectious bacteria. TB is most prevalent in sub-Saharan Africa and Southeast Asia, where widespread poverty and malnutrition reduce resistance to the disease. Moreover, opportunistic infections in immunocompromised HIV/AIDS patients have exacerbated the problem <ref type="bibr" target="#b2">[3]</ref>. The increasing appearance of multi-drug resistant TB has further created an urgent need for a cost effective screening technology to monitor progress during treatment.</p><p>Several antibiotics exist for treating TB. While mortality rates are high when left untreated, treatment with antibiotics greatly improves the chances of survival. In clinical trials, cure rates over 90% have been documented <ref type="bibr" target="#b0">[1]</ref>. Unfortunately, diagnosing TB is still a major challenge. The definitive test for TB is the identification of Mycobacterium tuberculosis in a clinical sputum or pus sample, which is the current gold standard <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b1">[2]</ref>. However, it may take several months to identify this slow-growing organism in the laboratory. Another technique is sputum smear microscopy, in which bacteria in sputum samples are observed under a microscope. This technique was developed more than 100 years ago <ref type="bibr" target="#b0">[1]</ref>. In addition, several skin tests based on immune response are available for determining whether an individual has contracted TB. However, skin tests are not always reliable. The latest development for detection are molecular diagnostic tests that are fast and accurate, and that are highly sensitive and specific. However, further financial support is required for these tests to become commonplace <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b1">[2]</ref>.</p><p>In this paper, we present an automated approach for detecting TB manifestations in chest x-rays (CXRs), based on our earlier work in lung segmentation and lung disease classification <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>. An automated approach to x-ray reading allows mass screening of large populations that could not be managed manually. A posteroanterior radiograph (xray) of a patient's chest is a mandatory part of every evaluation for TB <ref type="bibr" target="#b6">[7]</ref>. The chest radiograph includes all thoracic anatomy and provides a high yield, given the low cost and single source <ref type="bibr" target="#b7">[8]</ref>. Therefore, a reliable screening system for TB detection using radiographs would be a critical step towards more powerful TB diagnostics. The TB detection system presented here is a prototype that we developed for AMPATH (The Academic Model Providing Access to Healthcare) <ref type="bibr" target="#b8">[9]</ref>. AMPATH is a partnership between Moi University School of Medicine and Moi Teaching and Referral Hospital, Kenya, and a consortium of U.S. medical schools under the leadership of Indiana University. AMPATH provides drug treatment and health education for HIV/AIDS control in Kenya. HIV and TB co-infections are very common due to the weakened immune system. It is therefore important to detect patients with TB infections, not only to cure the TB infection itself but also to avoid drug incompatibilities. However, the shortage of radiological services in Kenya necessitates both an efficient and inexpensive screening system for TB. Medical personnel with little radiology background need to be able to operate the screening system. The target platform for our automated system are portable x-ray scanners, which allow screening of large parts of the population in rural areas. At-risk individuals identified by our system are then referred to a major hospital for treatment.</p><p>Figure <ref type="figure" target="#fig_0">1</ref> shows examples of normal CXRs without signs of TB. These examples are from our Montgomery County (MC) dataset that we describe in more detail in Section III. Figure <ref type="figure" target="#fig_1">2</ref> shows positive examples with manifestations of TB, which are from the same dataset. Typical manifestations of TB in chest x-rays are, for example, infiltrations, cavitations, effusions, or miliary patterns. For instance, CXR A and C in Figure <ref type="figure" target="#fig_1">2</ref> have infiltrates in both lungs. CXR B is a good example of pleural TB, which is indicated by the abnormal shape of the costophrenic angle of the right lung. In CXR D, we see irregular infiltrates in the left lung with a large area of cavitation. Additionally, there is scarring in the right apical region. CXR E shows peripheral infiltrates in the left lung. Finally, CXR F shows TB scars resulting from an older TB infection. Readers can find more illustrative examples of abnormal CXRs with TB in the references <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b7">[8]</ref>.</p><p>In this paper, we describe how we discriminate between normal and abnormal CXRs with manifestations of TB, using image processing techniques. We structure the paper as follows: Section II discusses related work and shows the stateof-the-art. Section III briefly describes the datasets we use for our experiments. In Section IV, we present our approach with lung segmentation, feature computation, and classification. A presentation of our practical experiments follows in Section V. Finally, a brief summary with the main results concludes the paper. Note that some of the features we use in this paper are identical to the features used in one of our earlier publications <ref type="bibr" target="#b5">[6]</ref>. However, the lung boundary detection algorithm in this paper differs from the one used in our earlier publication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>The advent of digital chest radiography and the possibility of digital image processing has given new impetus to computer-aided screening and diagnosis. Still, despite its omnipresence in medical practice, the standard CXR is a very complex imaging tool. In the last ten years, several ground-breaking papers have been published on computeraided diagnosis (CAD) in CXRs. However, there is no doubt that more research is needed to meet the practical performance requirements for deployable diagnostic systems. In a recent survey, van Ginneken et al. state that forty-five years after the initial work on computer-aided diagnosis in chest radiology, there are still no systems that can accurately read chest radiographs <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>. Automated nodule detection is becoming one of the more mature applications of decision support/automation for CXR and CT. Several studies have been published evaluating the capability of commercially available CAD systems to detect lung nodules <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>. The result is that CAD systems can successfully assist radiologists in diagnosing lung cancer <ref type="bibr" target="#b19">[20]</ref>. However, nodules represent only one of many manifestations of TB in radiographs.</p><p>In recent years, due to the complexity of developing fullfledged CAD systems for x-ray analysis, research has concentrated on developing solutions for specific subproblems <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b13">[14]</ref>. The segmentation of the lung field is a typical task that any CAD system needs to support for a proper evaluation of CXRs. Other segmentations that may be helpful include the segmentation of the ribs, heart, and clavicles <ref type="bibr" target="#b21">[22]</ref>. For example, van Ginneken et al. compared various techniques for lung segmentation, including active shapes, rule-based methods, pixel classification, and various combinations thereof <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>. Their conclusion was that pixel classification provided very good performance on their test data. Dawoud presented an iterative segmentation approach that combines intensity information with shape priors trained on the publicly available JSRT database (see Section III) <ref type="bibr" target="#b23">[24]</ref>.</p><p>Depending on the lung segmentation, different feature types and ways to aggregate them have been reported in the literature. For example, van Ginneken et al. subdivide the lung into overlapping regions of various sizes and extract features from each region <ref type="bibr" target="#b24">[25]</ref>. To detect abnormal signs of diffuse textural nature they use the moments of responses to a multiscale filter bank. In addition, they use the difference between corresponding regions in the left and right lung fields as features. A separate training set is constructed for each region and final classification is done by voting and a weighted integration.</p><p>Many of the CAD papers dealing with abnormalities in chest radiographs do so without focusing on any specific disease. Only a few CAD systems specializing in TB detection have been published, such as <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>. For example, Hogeweg et al. combined a texture-based abnormality detection system with a clavicle detection stage to suppress false positive responses <ref type="bibr" target="#b25">[26]</ref>. In <ref type="bibr" target="#b28">[29]</ref>, the same group uses a combination of pixel classifiers and active shape models for clavicle segmentation. Note that the clavicle region is a notoriously difficult region for TB detection because the clavicles  can obscure manifestations of TB in the apex of the lung. Freedman et al. showed in a recent study that an automatic suppression of ribs and clavicles in CXRs can significantly increase a radiologist's performance for nodule detection <ref type="bibr" target="#b29">[30]</ref>.</p><p>A cavity in the upper lung zones is a strong indicator that TB has developed into a highly infectious state <ref type="bibr" target="#b26">[27]</ref>.  <ref type="bibr" target="#b30">[31]</ref>. They report classification rates comparable to rates achieved with region classification on CXRs with known disease locations. More information on existing TB screening systems can be found in our recent survey <ref type="bibr" target="#b31">[32]</ref>.</p><p>In addition to x-ray based CAD systems for TB detection, several systems based on other diagnostic means have been reported in the literature. For example, Pangilinan et al. presented a stepwise binary classification approach for reduction of false positives in tuberculosis detection from smeared slides <ref type="bibr" target="#b32">[33]</ref>. Furthermore, automated systems based on bacteriological examination with new diagnostic tests have been reported recently, such as GeneXpert (Cepheid, Sunnyvale, CA, USA) <ref type="bibr" target="#b33">[34]</ref>. Currently, these tests are still expensive. Nevertheless, with costs decreasing over time, these systems may become an option for poorer countries. It is also possible, and indeed very promising, to combine these new systems with x-ray based systems. For the time being, however, these systems are out of the scope of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. DATA</head><p>For our experiments, we use three CXR sets. On the first two sets we train and test our classifiers, and on the third set we train our lung models. The images used in this study were de-identified by the data providers and are exempted from IRB review at their institutions. The data was exempted from IRB review (No. 5357) by the NIH Office of Human Research Protections Programs.</p><p>Our first set, the MC set, is a representative subset of a larger CXR repository collected over many years within the tuberculosis control program of the Department of Health and Human Services of Montgomery County (MC), Maryland <ref type="bibr" target="#b5">[6]</ref>. The MC set contains 138 posteroanterior CXRs, among which 80 CXRs are normal and 58 CXRs are abnormal with manifestations of TB. All images of the MC set are in 12-bit grayscale, captured with an Eureka stationary x-ray machine (CR). The abnormal CXRs cover a wide range of TB-related abnormalities, including effusions and miliary patterns. For the MC set, we know the ground-truth radiology reports that have been confirmed by clinical tests, patient history, etc.</p><p>Our second CXR set, the Shenzhen set, is from Shenzhen No.3 Hospital in Shenzhen, Guangdong providence, China. Shenzhen Hospital is one of the largest hospitals in China for infectious diseases, with a focus both on their prevention and treatment. The CXRs we received from Shenzhen Hospital are from out-patient clinics. They were captured within a one month period, mostly in September 2012, as part of the daily routine at Shenzhen Hospital, using a Philips DR Digital Diagnost system. The set contains 340 normal CXRs and 275 abnormal CXRs with TB. For the Shenzhen set, we have the radiologist readings, which we consider as ground-truth.</p><p>We train our lung models on a third set from the Japanese Society of Radiological Technology (JSRT). The JSRT data is the result of a study investigating the detection performance of radiologists for solitary pulmonary nodules <ref type="bibr" target="#b34">[35]</ref>. The data was collected from 14 medical centers and comprises 247 CXRs. All CXR images have a size of 2048 × 2048 pixels and a gray-scale color depth of 12 bits. Among the 247 CXRs, 93 CXRs are normal and 154 CXRs are abnormal. Each of the abnormal CXRs contains one pulmonary nodule classified into one of five degrees of subtlety, ranging from extremely subtle to obvious. However, in the JSRT images, the nodules hardly affect the lung shapes. The nodules are either well within the lung boundary or they are so subtle that the effects on lung shape are minor. We can therefore take advantage of the entire JSRT database to train our shape model for a typical normal lung. To do so, we use the segmentation masks provided by van Ginneken et al. <ref type="bibr" target="#b21">[22]</ref>. Their SCR dataset (Segmentation in Chest Radiographs) contains the manually generated lung field masks for each CXR in the JSRT database. For example, Figure <ref type="figure">3</ref> shows an abnormal CXR from the JSRT database together with the outline of the left and the right lung as specified in the SCR data. Note that the left mid lung field in Figure <ref type="figure">3</ref> contains a cancer nodule.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. METHOD</head><p>This section presents our implemented methods for lung segmentation, feature computation, and classification. Figure <ref type="figure">4</ref> shows the architecture of our system with the different processing steps, which the following sections will discuss in more detail. First, our system segments the lung of the input CXR using a graph cut optimization method in combination with a lung model. For the segmented lung field, our system then computes a set of features as input to a pre-trained binary classifier. Finally, using decision rules and thresholds, the classifier outputs its confidence in classifying the input CXR as a TB positive case, for example. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Graph Cut Based Lung Segmentation</head><p>We model lung segmentation as an optimization problem that takes properties of lung boundaries, regions, and shapes into account <ref type="bibr" target="#b3">[4]</ref>. In general, segmentation in medical images has to cope with poor contrast, acquisition noise due to hardware constraints, and anatomical shape variations. Lung segmentation is no exception in this regard. We therefore incorporate a lung model that represents the average lung shape of selected training masks. We select these masks according to their shape similarity as follows: We first linearly align all training masks to a given input CXR. Then, we compute the vertical and horizontal intensity projections of the histogram equalized images. To measure the similarity between projections of the input CXR and the training CXRs, we use the Bhattacharyya coefficient. We then use the average mask computed on a subset of the most similar training masks as an approximate lung model for the input CXR. In particular, we use a subset containing the five most similar training masks to compute the lung model. This empirical number produced the best results in our experiments. Increasing the subset size to more than five masks will decrease the lung model accuracy because the shapes of the additional masks will typically differ from the shape of the input x-ray.</p><p>As training masks, we use the publicly available JSRT set <ref type="bibr" target="#b34">[35]</ref> for which ground truth lung masks are available <ref type="bibr" target="#b21">[22]</ref>. The pixel intensities of the lung model are the probabilities of the pixels being part of the lung field. Figure <ref type="figure" target="#fig_3">5</ref> shows a typical lung model we computed. Note that the ground-truth masks do not include the posterior inferior lung region behind the diaphragm. Our approach, and most segmentation approaches in the literature, exclude this region because manifestations of TB are less likely here.</p><p>In a second step, we employ a graph cut approach <ref type="bibr" target="#b35">[36]</ref> and model the lung boundary detection with an objective function. To formulate the objective function, we define three requirements a lung region has to satisfy: a) the lung region should be consistent with typical CXR intensities expected in a lung region, b) neighboring pixels should have consistent labels, and c) the lung region needs to be similar to the lung model we computed. Mathematically, we can describe the resulting optimization problem as follows <ref type="bibr" target="#b3">[4]</ref>: Let f = {f 1 , f 2 , ..., f p , ..., f N } be a binary vector whose components f p correspond to foreground (lung region) and background label assignments to pixel p ∈ P , where P is the set of pixels in the CXR, and N is the number of pixels. According to our method, the optimal configuration of f is given by the minimization of the following objective function:</p><formula xml:id="formula_0">E(f ) = E d (f ) + E s (f ) + E m (f ),<label>(1)</label></formula><p>where E d , E s and E m represent the region, boundary, and lung model properties of the CXR, respectively. The region term E d (f ) considers image intensities as follows:</p><formula xml:id="formula_1">E d (f ) = 1 I max   (p,S)∈C |I p -I S | + (p,T )∈C |I p -I T |   , (2)</formula><p>where I p is the intensity of pixel p and C is the set of edges representing the cut. I S and I T are the intensities of foreground and background regions. We learn these intensities on the training masks and represent them using a source (S) and terminal node (T ). I max is the maximum intensity value of the input image. Eq. 2 ensures that labels for each pixel are assigned based on the pixel's similarity to the foreground and background intensities.</p><p>The boundary constraints between lung border pixels p and q are formulated as follows,</p><formula xml:id="formula_2">E s (f ) = (p,q)∈C exp(-(I p -I q ) 2 ).<label>(3)</label></formula><p>This term uses the sum of the exponential intensity differences of pixels defining the cut. The sum is minimum when the intensity differences are maximum.</p><p>Our average lung model is a 2D array which contains the probabilities of a pixel p being part of the lung field. Based on this model, we define the lung region requirement as follows:</p><formula xml:id="formula_3">E m (f ) = (p,T )∈C P r p + (p,S)∈C (1 -P r p ),<label>(4)</label></formula><p>where P r p is the probability of pixel p being part of the lung model. This term describes the probability of pixels labeled as lung belonging to the background, and the probability of pixels labeled as background belonging to the lung, according to the lung model. We want to minimize both probabilities.</p><p>Using the three energy terms given above, we minimize the objective function with a fast implementation of mincut/max-flow algorithm <ref type="bibr" target="#b36">[37]</ref>. The minimum-cut is then the optimal foreground/background configuration of f for the input CXR <ref type="bibr" target="#b3">[4]</ref>. Note that Eq. 4 extends our earlier work in <ref type="bibr" target="#b4">[5]</ref>, in which we did not use a lung model. Compared to our work in <ref type="bibr" target="#b3">[4]</ref>, we simplified Eqs. 2, 3, and 4 so that they describe properties of the cut.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Features</head><p>To describe normal and abnormal patterns in the segmented lung field, we experimented with two different feature sets. Our motivation is to use features that can pick up subtle structures in an CXR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Object Detection Inspired Features -Set A:</head><p>As our first set, we use features that we have successfully applied to microscopy images of cells for which we classified the cell cycle phase based on appearance patterns <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref>. It is the same set that we have used in our earlier TB classification work <ref type="bibr" target="#b5">[6]</ref>. This set is versatile and can also be applied to object detection applications, for example in <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>.</p><p>The first set is a combination of shape, edge, and texture descriptors <ref type="bibr" target="#b5">[6]</ref>. For each descriptor, we compute a histogram that shows the distribution of the different descriptor values across the lung field. Each histogram bin is a feature, and all features of all descriptors put together form a feature vector that we input to our classifier. Through empirical experiments, we found that using 32 bins for each histogram gives us good practical results <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>. In particular, we use the following shape and texture descriptors <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref>:</p><formula xml:id="formula_4">• Intensity histograms (IH) • Gradient Magnitude Histograms (GM) • Shape descriptor histograms (SD) SD = tan -1 λ 1 λ 2 ,<label>(5)</label></formula><p>where λ 1 and λ 2 are the eigenvalues of the Hessian matrix, with</p><formula xml:id="formula_5">λ 1 ≤ λ 2 . • Curvature descriptor histograms (CD) CD = tan -1 λ 2 1 + λ 2 2 1 + I(x, y) ,<label>(6)</label></formula><p>with 0 ≤ CD ≤ π/2, where I(x, y) denotes the pixel intensity for pixel (x, y). The normalization with respect to intensity makes this descriptor independent of image brightness.</p><p>• Histogram of oriented gradients (HOG) is a descriptor for gradient orientations weighted according to gradient magnitude <ref type="bibr" target="#b42">[43]</ref>. The image is divided into small connected regions, and for each region a histogram of gradient directions or edge orientations for the pixels within the region is computed. The combination of these histograms represents the descriptor. HOG has been successfully used in many detection systems <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b39">[40]</ref>. • Local binary patterns (LBP) is a texture descriptor that codes the intensity differences between neighboring pixels by a histogram of binary patterns <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b47">[48]</ref>. LBP is thus a histogram method in itself. The binary patterns are generated by thresholding the relative intensity between the central pixel and its neighboring pixels. Because of its computational simplicity and efficiency, LBP is successfully used in various computer vision applications <ref type="bibr" target="#b48">[49]</ref>, often in combination with HOG <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b49">[50]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b50">[51]</ref>. With each descriptor quantized into 32 histogram bins, our overall number of features is thus 6 * 32 = 192.</p><p>The eigenvalues of the Hessian matrix needed for the shape and curvature descriptors in Eq. 5 and Eq. 6 were computed using a modification of the multiscale approach by Frangi et al. <ref type="bibr" target="#b51">[52]</ref>, <ref type="bibr" target="#b52">[53]</ref>. The Hessian describes the second order surface curvature properties of the local image intensity surface. This can be seen from the local behavior in the vicinity of a pixel x o in an image I by means of the second order Taylor series expansion:</p><formula xml:id="formula_6">I(x, s) ≈ I(x 0 , s) + (x -x 0 ) T ∇I(x 0 , s)<label>(7)</label></formula><formula xml:id="formula_7">+ 1 2 (x -x 0 ) T H(x 0 , s)(x -x 0 )</formula><p>where ∇I(x 0 , s) stands for the gradient vector and H(x 0 , s) is the Hessian matrix, both computed at pixel x o and scale s.</p><p>For each scale, we apply Gaussian filters as follows <ref type="bibr" target="#b51">[52]</ref>:</p><formula xml:id="formula_8">∂ ∂x I(x o , s) = s γ I(x o ) * ∂ ∂x G(x o , s)<label>(8)</label></formula><p>where G(x o , s) is the n-dimensional Gaussian for pixel x o and scale s, and γ is a weight parameter. With γ = 1, all scales are weighted equally. The Gaussian G(x o , s) is given by</p><formula xml:id="formula_9">G(x o , s) = 1 (2πs 2 ) n e -xo 2 2s 2<label>(9)</label></formula><p>Our approach uses the maximum filter response across all scales. The main application in <ref type="bibr" target="#b51">[52]</ref>  <ref type="bibr">(Frangi et al.)</ref> was to enhance blood vessels, which have mostly thin elongated shapes, through filtering. On the other hand, our goal is to detect nodular patterns by capturing the spherical or elliptical shapes in the local intensity curvature surface. We therefore use the following structure response SR filter based on the eigenvalues λ 1 and λ 2 :</p><formula xml:id="formula_10">SR = 1 -e - √ k•|λ1 * λ2|<label>(10)</label></formula><p>A large filter response value of SR indicates the presence of large circular or elongated blobs, and is designed to detect nodular features in CXR images. In the case of very thin linear features, the structural response tends toward zero, with |λ 2 | &gt;&gt; |λ 1 | ≈ 0. For very large eigenvalues the filter response approaches one. The final eigenvalues that we use to compute the shape descriptor SD and the curvature descriptor CD are the eigenvalues that provide the largest filter response over ten different Gaussian filter scales, namely s = 2, 4, 6, . . . , 20.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) CBIR-based Image Features -Set B:</head><p>For our second feature set, Set B, we use a group of low-level features motivated by content-based image retrieval (CBIR) <ref type="bibr" target="#b53">[54]</ref>, <ref type="bibr" target="#b54">[55]</ref>. This feature collection includes intensity, edge, texture and shape moment features, which are typically used by CBIR systems. The entire feature vector has 594 dimensions, which is more than three times larger than the feature vector of Set A, and which allows us to evaluate the effect of high-dimensional feature spaces on classification accuracy. We extract most of the features, except for Hu moments and shape features, based on the Lucene image retrieval library, LIRE <ref type="bibr" target="#b55">[56]</ref>, <ref type="bibr" target="#b56">[57]</ref>, <ref type="bibr" target="#b57">[58]</ref>. In particular, Feature Set B contains the following features:</p><p>• Tamura texture descriptor: The Tamura descriptor is motivated by the human visual perception <ref type="bibr" target="#b58">[59]</ref>. The descriptor comprises a set of six features. We only use three of these features, which have the strongest correlation with human perception: contrast, directionality, and coarseness. • CEDD and FCTH: CEDD (color and edge direction descriptor) <ref type="bibr" target="#b59">[60]</ref> and FCTH (fuzzy color and texture histogram) <ref type="bibr" target="#b60">[61]</ref> incorporate color and texture information in one histogram. They differ in the way they capture texture information. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Classification</head><p>To detect abnormal CXRs with TB, we use a support vector machine (SVM), which classifies the computed feature vectors into either normal or abnormal. An SVM in its original form is a supervised non-probabilistic classifier that generates hyperplanes to separate samples from two different classes in a space with possibly infinite dimension <ref type="bibr" target="#b66">[67]</ref>, <ref type="bibr" target="#b67">[68]</ref>. The unique characteristic of an SVM is that it does so by computing the hyperplane with the largest margin; i.e. the hyperplane with the largest distance to the nearest training data point of any class. Ideally, the feature vectors of abnormal CXRs will have a positive distance to the separating hyperplane, and feature vectors of normal CXRs will have a negative distance. The larger the distance the more confident we are in the class label. We therefore use these distances as confidence values to compute the ROC curves in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. System Implementation</head><p>While implementation in the field is under the direction of AMPATH, and out of the control of the authors, the current system architecture and status of the project is as follows: AMPATH has finished mounting a portable x-ray machine on a light truck that has been modified to allow radiographic imaging. For example, the truck has been shielded against radiation and has been equipped with an on-board power generation unit and a desk for patient evaluation. The x-ray machine is connected to a portable workstation provided by the manufacturer that acts as a DICOM node, pushing images in a PACS framework. In the initial testing phase, our software runs on a second portable computer that is connected to the workstation of the x-ray machine. The communication module of our software, which we implemented in Java, listens to the DICOM workstation. This module can automatically receive DICOM files and store them locally. It can also invoke the screening methods described in this paper and output the classification results (normal/abnormal) and their confidence values. Because we coded many of our algorithms, such as segmentation, feature extraction, and classification in Matlab, we created Java wrappers for these functions and integrated them into our Java code. We also added a straightforward user interface that indicates whether a given x-ray is abnormal.</p><p>The truck will start its round trip from Moi University, and all x-rays will be processed on-board by our software. Depending on the availability of long-range wireless connections, the screening results will be transmitted on the fly to the truck's basis at Moi University or saved until the return of the truck.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. RESULTS</head><p>This section presents a practical evaluation of our work. We show lung segmentation examples and we evaluate our features both in combination and individually. We also compare the performance of our proposed TB detection system with the performance of systems reported in the literature, including the performance of human experts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Lung Segmentation Using Graph Cut</head><p>Figure <ref type="figure" target="#fig_4">6</ref> shows three examples of our lung segmentation applied to CXRs from the MC dataset. The leftmost CXR has calcifications in the right upper lung and extensive irregular infiltrates in the left lung with a large area of cavitation. The CXR in the middle of Figure <ref type="figure" target="#fig_4">6</ref> shows scars in the right upper lung, and the rightmost CXR has scars in the left upper lung and some infiltrates as well. Figure <ref type="figure" target="#fig_4">6</ref> also shows the outlines of our segmentation masks for all three lungs. We can see that the segmentation masks capture the general shape of the lungs. Due to the use of a lung model, the infiltrates have not impaired the quality of the segmentations, especially in the leftmost CXR. We can see a slight leakage of the segmentation in the apical regions for the second and third CXR. The lower outlines toward the diaphragm could also be tighter in these images.</p><p>We compare our segmentation algorithm with the lung boundary detection algorithms in the literature. For the comparison, we use the graph cut implementation of our segmentation described in <ref type="bibr" target="#b4">[5]</ref>. As performance measure, we used the overlap measure Ω:</p><formula xml:id="formula_11">Ω = T P T P + F P + F N , (<label>11</label></formula><formula xml:id="formula_12">)</formula><p>where T P is the correctly identified lung area (true positive), F P is the incorrectly identified lung area (false positive), and F N is the missed lung area (false negative). Table <ref type="table" target="#tab_2">I</ref> shows the comparison results. We can see that our segmentation method (GC, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, with best parameter settings) performs reasonably well, though there are better segmentation methods reported in the literature. Our segmentation performance is 4.5% lower than the human performance reported for the JSRT set, which is 94.6%. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Avg ± std Min Median Max Hybrid Voting <ref type="bibr" target="#b21">[22]</ref> 0.949 ± 0.020 0.818 0.953 0.978 Human Observer <ref type="bibr" target="#b21">[22]</ref> 0.946 ± 0.018 0.822 0.949 0.972 PC postprocessed <ref type="bibr" target="#b21">[22]</ref> 0.945 ± 0.022 0.823 0.951 0.972 Hybrid ASM-PC <ref type="bibr" target="#b21">[22]</ref> 0.934 ± 0.037 0.706 0.945 0.968 Hybrid AAM-PC <ref type="bibr" target="#b21">[22]</ref> 0.933 ± 0.026 0.762 0.939 0.966 MISCP <ref type="bibr" target="#b68">[69]</ref> 0.930 ± 0.045 ---ASMOF <ref type="bibr" target="#b69">[70]</ref> 0.927 ± 0.032 0.745 0.936 0.946 ASM-SIFT <ref type="bibr" target="#b70">[71]</ref> 0.920 ± 0.031 0.783 0.928 0.961 ASM <ref type="bibr" target="#b21">[22]</ref> 0.903 ± 0.057 0.601 0.924 0.960 GC <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref> 0.901 ± 0.054 0.541 0.911 0.969 ASM <ref type="bibr" target="#b70">[71]</ref> 0.870 ± 0.074 0.608 0.892 0.954 AAM <ref type="bibr" target="#b21">[22]</ref> 0.847 ± 0.095 0.017 0.874 0.956 Mean shape <ref type="bibr" target="#b21">[22]</ref> 0.713 ± 0.075 0.460 0.713 0.891 We have since significantly improved performance to achieve state-of-the-art results and these will be reported in a companion paper <ref type="bibr" target="#b71">[72]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Descriptor Evaluation for Feature Set A</head><p>We evaluate the performance of Feature Set A on the MC dataset. For each CXR in the MC dataset, we compute the descriptors in Feature Set A (see Section IV-B) and concatenate them into a single feature vector. We then apply a leaveone-out evaluation scheme, using the SVM-classifier described in Section IV-C. According to the leave-one-out scheme, we classify each feature vector (CXR) in the MC dataset with a classifier trained on the remaining feature vectors (CXRs) of the MC dataset. We thus train as many classifiers as there are CXRs in the MC dataset (138 altogether). To get a better understanding of the performance of individual descriptors and descriptor groups, we perform leave-one-out evaluations for all possible descriptor subsets. Figure <ref type="figure" target="#fig_5">7</ref> shows the recognition rates we obtain. The x-axis of Figure <ref type="figure" target="#fig_5">7</ref> represents the different descriptor combinations, where each possible descriptor subset is coded as a 6-digit binary index. Each bit indicates the membership of one of the descriptors mentioned above. The yaxis of Figure <ref type="figure" target="#fig_5">7</ref> shows the area under the ROC curve (AUC) and the accuracies for each descriptor combination (ACC); see the red and black curve, respectively. To compute the accuracy in Figure <ref type="figure" target="#fig_5">7</ref>, we use the natural decision boundaries of the linear SVM classifier. We thus consider any pattern classified with positive confidence value as abnormal and any pattern with negative confidence as normal. Whenever we report classification results in the following, we will use this standard classification scheme. Accuracy and AUC are highly correlated, with the AUC being higher than the accuracy for most descriptor combinations. The jagged shape of both curves indicates that some descriptors are less likely to increase the performance when added to the descriptor mix. Nevertheless, we see that both the AUC and the accuracy tend to increase with larger descriptor sets. In fact, we achieve the highest AUC value of 86.9%, with an accuracy of 78.3%, when we add all descriptors to the descriptor set. Note that we have removed one feature from the set originally proposed in our earlier publication <ref type="bibr" target="#b5">[6]</ref>. The set presented here is now optimal in the sense that removing one feature reduces the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Machine Performance</head><p>We present machine classification results for our two datasets, namely the County (MC) dataset from our local TB clinic, USA, and the set from Shenzhen Hospital, China.</p><p>1) Montgomery County: Figure <ref type="figure" target="#fig_6">8</ref> shows the ROC curve that we obtain when using all descriptors of Feature Set A. The ROC curve shows different possible operating points depending on the confidence threshold for the SVM classifier. The y-coordinate indicates the sensitivity (or recall) of our system, while the x-coordinate indicates the corresponding false positive rate, which is one minus the specificity. The area under the ROC curve (AUC) in Figure <ref type="figure" target="#fig_6">8</ref> is 86.9%, with an overall classification accuracy of 78.3%. According to the ROC curve in Figure <ref type="figure" target="#fig_6">8</ref>, we achieve a sensitivity of about 95% when we accept a false positive rate that is slightly higher than 40%. This means that our specificity is a bit lower than 60% in this case.</p><p>2) Shenzhen Hospital: We repeated the same experiments on the set from Shenzhen Hospital. Figure <ref type="figure">9</ref> shows the ROC curve that we computed for this set, again using the full Feature Set A. We see that the ROC curve is slightly better than the ROC curve for the data from our local TB clinic in Figure <ref type="figure" target="#fig_6">8</ref>. In fact, the AUC is approximately 88%. The classification accuracy is also slightly better. We computed an accuracy of about 82.5% for this set, which shows that we can provide consistent performance across different datasets, and for practically relevant data.</p><p>We also computed the performance results for our second feature set, Set B. Interestingly, with this feature set, we achieve a similar performance. Using a linear support vector machine, we obtain an accuracy of about 82% and an AUC of 88.5%. Thus, increasing the feature dimensionality does not lead to any improvement in performance.</p><p>For comparison purposes, we list the AUC values for our two x-ray sets and our two feature sets again in Table <ref type="table" target="#tab_2">II</ref> feature set computed on the Montgomery x-ray set, which is lower.</p><p>For the Shenzhen data and Feature Set B, we experimented with different classification methods to see how the performance varies across different architectures. Table <ref type="table" target="#tab_2">III</ref> shows the performance results, accuracy (ACC) and area under the ROC curve (AUC), for the following architectures: support vector machine (SVM) with linear (L), polynomial (PK), and radial basis function kernels (RBF), backpropagation neural network (NN), alternating decision tree (ADT), and linear logistic regression (LLR). The first column of Table <ref type="table" target="#tab_2">III</ref>  the performance for the linear support vector machine that we reported above. It is slightly higher than the rate for the polynomial and radial kernels; in particular the accuracy is higher for the linear machine. We experimented with different C-values for the support vector machines, and found that the standard value (C = 1) provides the best performance in our case, with only slight differences in general. Table <ref type="table" target="#tab_2">III</ref> shows that the AUC is relatively stable across different architectures, with the linear logistic regression providing a slightly better overall performance.</p><p>3) Comparison with other Systems in the Literature: In the literature, only a few papers have reported performance numbers for full-fledged TB screening systems, for example <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b25">[26]</ref>. Many papers evaluate only part of the detection problem and concentrate on sub-problems, such as cavity detection <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b26">[27]</ref>. Judging by the ROC curves, the performance of our system is comparable to the performance of some existing systems that address the problem in its entirety. For instance, the AUC value of our system is higher than the AUC values reported for the systems in <ref type="bibr" target="#b24">[25]</ref> and <ref type="bibr" target="#b30">[31]</ref>. Our AUC value is also slightly higher than the AUC value reported by Hogeweg et al., who use a combination of texture and shape abnormality detectors <ref type="bibr" target="#b25">[26]</ref>. However, for a fair comparison of these systems, we would have to evaluate each system on the same dataset. Currently, the training sets in <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b25">[26]</ref> are not publicly available. As yet, there is no publicly available CXR set of sufficient size that would allow training of a TB screening system. For the time being, we have to content ourselves with the fact that some existing systems provide reasonable performances across different datasets. We plan to make both our sets, the MC set as well as the Shenzhen set, available to the research community, so that other researchers can compare their performance. For a more detailed overview of existing TB screening systems, we refer readers to our recent survey in <ref type="bibr" target="#b31">[32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Comparison with Human Performance</head><p>In the following, we compare our system performance with human reading performance of two earlier studies reported in the literature. We also conducted our own independent observer study, asking two radiologists to read the MC CXR set (LF, JS).</p><p>1) Earlier Studies: Van't Hoog et al. investigated the performance of clinical officers in a tuberculosis prevalence survey <ref type="bibr" target="#b72">[73]</ref>. Their study shows that clinical officers with sufficient training, rather than medical officers, can achieve an acceptable performance when screening CXRs for any abnormality. Van't Hoog et al. therefore recommend training of clinical officers for TB screening programs in regions where medical personnel with radiological expertise is rare. In their study, two experts achieve sensitivities of 81% and 83%, respectively, when screening CXRs of patients with bacteriologically confirmed TB for any abnormality. The corresponding specificities are 80% and 74%, respectively. On the other hand, three clinical officers achieve a sensitivity of 95% and a specificity of 73% for the same task. Note that each of the experts has a lower sensitivity than the group of clinical officers. We can compare these numbers with the ROC curve in Figure <ref type="figure" target="#fig_6">8</ref>, which shows the performance of our automatic system. We see that humans still perform better than our automatic system, and also better than other systems reported in the literature. Nevertheless, our system performs reasonably well and its performance, while inferior, is within reach of the clinical officers' performance in the study of Van't Hoog et al. For the same sensitivity provided by the clinical officers (95%), our system achieves a specificity that is about 15% lower than the specificity of the clinical officers.</p><p>In another recent study, Maduskar et al. showed that automatic chest radiograph reading for detection of TB has similar performance as clinical officers and certified readers <ref type="bibr" target="#b73">[74]</ref>. They collected a dataset of 166 digital CXRs in Zambia, containing 99 positive and 67 negative cases confirmed by sputum cultures. In their observer study, four clinical officers and two certified readers scored all x-rays between zero and hundred. Maduskar et al. compared the human performance with the performance of their software, which uses the same score range. They computed the areas under the ROC curves and obtained values between 70% (clinical officers) and 72% (software), showing that there is no significant difference between human and machine performance. This result is in accordance with our own study, in which we compared the performance of our system with human performance (see below).</p><p>2) Our Study: In our study, we asked two radiologists to provide a second and third reading for our MC CXR set. Both radiologists work at a United States clinical center and hospital, respectively. We made them aware of the purpose of our screening project, that is, to detect tuberculosis in a population from an endemic region who is otherwise to be considered healthy. As a result the recommendations for evaluation of TB screening from the WHO Lime book were considered in the decision making process, in particular the use of intentional overreading <ref type="bibr" target="#b0">[1]</ref>. To present the CXR data to the radiologists, we adapted our Firefly labeling tool, allowing the radiologists to see the CXRs online and store their readings in a database <ref type="bibr" target="#b74">[75]</ref>. Table <ref type="table" target="#tab_7">IV</ref>  After their individual readings, both radiologists convened to come to a consensus decision, reconciling readings for which they have disagreed. For the remaining discrepant cases, they agreed the findings were consistent with TB. Table <ref type="table" target="#tab_6">V</ref> shows a comparison of their consensus decision with the labels from our local TB clinic. We consider the latter to be groundtruth labels because they are based on clinical data as well as patient data to which both radiologists had no access. In    ). This is because we have not optimized the true positive rate for our classifier. If we do so, we can see from the ROC curve in Figure <ref type="figure" target="#fig_6">8</ref>, that in order for the sensitivity to be close to 100%, our false positive rate would be slighter higher than 60%. This is about twice as high as the false positive rate for the radiologist's consensus decision in Table <ref type="table" target="#tab_6">V</ref>, which is about 31%. Finally, in Table <ref type="table" target="#tab_7">VII</ref>, we compare the correct and incorrect classification results of the two radiologists and the machine. In terms of classification performance, the radiologists are not significantly better than the machine (McNemar test, p = 0.54). Note that the number of CXRs for which both the machine and the consensus are wrong is remarkably low. The combined human-machine performance with a significantly lower error rate of 4.3%, compared to the machine-only error rate of 21.7% and the human consensus error of 18.1%, suggests using our system for computer-aided diagnosis and offering a verifying second opinion of radiologist readings. This can help improve human performance because it is unlikely that both the radiologist and the machine classify the same CXR incorrectly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>We have developed an automated system that screens CXRs for manifestations of TB. The system is currently set up for practical use in Kenya, where it will be part of a mobile system for TB screening in remote areas. When given a CXR as input, our system first segments the lung region using an optimization method based on graph cut. This method combines intensity information with personalized lung atlas models derived from the training set. We compute a set of shape, edge, and texture features as input to a binary classifier, which then classifies a given input image into either normal or abnormal.</p><p>In this paper, we compare two different established feature sets: one set typically used for object recognition and the other used in image retrieval applications. We also experiment with different classifier architectures. Both feature sets and most of the classifier architectures we tested, provide a similar performance. To improve the performance further, we could try to improve the lung segmentation, which provides average performance compared to other systems in the literature. One approach would be to find optimal weights for the terms in the graph cut energy function. Another possibility would be to use more atlas-based lung models for computing the average lung model (see our companion paper <ref type="bibr" target="#b71">[72]</ref>). We could also try to partition the lung into different regions, as some of the existing CAD systems do. It is surprising that we achieve a relatively high performance compared to other approaches by using only global features. This may indicate that the combination of local features in the literature is still suboptimal. A final verdict on this issue can only be made once public benchmark data becomes available. Due to the lack of this data for TB detection in CXRs, it is currently difficult to do a fair comparison of the few existing systems that have been reported in the literature. We therefore plan to make both our datasets publicly available. One of these sets, the Shenzhen set, is from a high-incidence area. For both sets, we achieve an AUC of 87% and 90%, respectively. Furthermore, our performance, while still lower than human performance, is reasonably close to the performance of radiologists. In an independent observer study with two radiologists, who were trying not to miss any positive case, our false positive rate is twice as high according to the ROC curve. The likelihood that both the radiologists and the machine reach a wrong conclusion is very low. This shows that it should be possible to reach human performance in the future, or at least have a system that can assist radiologists and public health providers in the screening and decision process. These comparison results have encouraged us to test our system in the field under realistic conditions. In future experiments, we will evaluate our system on larger datasets that we will collect using our portable scanners in Kenya.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head><p>The Montgomery County x-ray set as well as the Shenzhen Hospital x-ray set are available for research purposes upon review of request for data. To submit the request, please visit the following webpage:http://archive.nlm.nih.gov/. Under the "Repositories" tab, a link points to a page with more information on our chest images, including contact information.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Examples of normal CXRs in the MC dataset.</figDesc><graphic coords="3,79.19,53.09,146.52,120.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Examples of abnormal CXRs in the MC dataset. CXR A has a cavitary infiltrate on the left and a subtle infiltrate in the right lower lung. CXR B is an example of pleural TB. Note that the blunted right costophrenic angle indicates a moderate effusion. CXR C has infiltrates in both lungs. CXR D shows irregular infiltrates in the left lung with cavitation and scarring of the right apex. CXR E shows peripheral infiltrates in the left lung. CXR F shows signs of TB, indicated by the retraction of bilateral hila superiorly, which is more pronounced on the right.</figDesc><graphic coords="3,385.49,332.39,146.82,178.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .Fig. 4 .</head><label>34</label><figDesc>Fig. 3. JSRT CXR with manual ground-truth lung segmentation. Note the nodule overlying the left posterior fifth and sixth ribs.</figDesc><graphic coords="4,368.91,59.33,137.03,137.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. CXR and its calculated lung model.</figDesc><graphic coords="5,158.59,53.29,139.92,120.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Example lung segmentations for MC CXRs. Note the over-segmentation in the apices. The CXR on the left-hand side has irregular infiltrates in the left lung. The CXR in the middle has small non-calcified nodules in the upper lobes. Grouped non-calcified nodules are visible in the CXR on the right-hand side. Note also that we do not include the posterior inferior lung region behind the diaphragm, similar to other lung segmentation methods in the literature.</figDesc><graphic coords="8,233.59,53.59,144.32,175.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Exhaustive evaluation of all possible feature subsets. The red curve plots ROC performance (AUC) and the black curve is the classifier accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. ROC curve for MC data and Feature Set A.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>•</head><label></label><figDesc>Hu moments: These moments are widely used in image analysis. They are invariant under image scaling, translation, and rotation<ref type="bibr" target="#b61">[62]</ref>. We use the DISCOVIR system (Distributed Content-based Visual Information Retrieval) to extract Hu moments<ref type="bibr" target="#b62">[63]</ref>.</figDesc><table><row><cell>• CLD and EHD edge direction features: CLD (color layout</cell></row><row><cell>descriptor) and EHD (edge histogram descriptor) are</cell></row><row><cell>MPEG-7 features [64]. CLD captures the spatial layout</cell></row><row><cell>of the dominant colors on an image grid consisting of</cell></row><row><cell>8 by 8 blocks and is represented using DCT (discrete</cell></row><row><cell>cosine transform) coefficients. EHD represents the local</cell></row><row><cell>edge distribution in the image, i.e. the relative frequency</cell></row><row><cell>of occurrence of five types of edges (vertical, horizon-</cell></row><row><cell>tal, 45-degree diagonal, 135-degree diagonal, and non-</cell></row><row><cell>directional) in the sub-images.</cell></row></table><note><p><p><p><p><p><p>• Primitive length, edge frequency, and autocorrelation: These are well-known texture analysis methods, which use statistical rules to describe the spatial distribution and relation of gray values</p><ref type="bibr" target="#b64">[65]</ref></p>.</p>• Shape features: We use a collection of shape features provided by the standard Matlab implementation (regionprops)</p><ref type="bibr" target="#b65">[66]</ref></p>, such as the area or elliptical shape features of local patterns.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I OVERLAP</head><label>I</label><figDesc>SCORES ON JSRT DATASET COMPARED TO GOLD STANDARD SEGMENTATION.</figDesc><table /><note><p>GC: GRAPH CUT, PC: PIXEL CLASSIFICATION, MISCP: MINIMAL INTENSITY AND SHAPE COST PATH, ASMOF: ACTIVE SHAPE MODEL WITH OPTIMAL FEATURES, ASM: ACTIVE SHAPE MODEL, AAM: ACTIVE APPEARANCE MODEL.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>, using our linear SVM. Table II also contains the result for the second Fig.9. ROC curve for Shenzhen data and Feature Set A.</figDesc><table><row><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>True positive rate</cell><cell>0.4 0.5 0.6 0.7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">False positive rate</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Feature Set A Feature Set B</cell></row><row><cell cols="4">Montgomery County</cell><cell></cell><cell>86.9</cell><cell></cell><cell>80.1</cell></row><row><cell cols="4">Shenzhen Hospital</cell><cell></cell><cell>88.0</cell><cell></cell><cell>88.5</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">TABLE II</cell><cell></cell></row><row><cell cols="8">CLASSIFICATION PERFORMANCE (AUC) ON MONTGOMERY COUNTY AND</cell></row><row><cell cols="8">SHENZHEN CXRS FOR FEATURE SET A AND FEATURE SET B.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>shows the agreement of both radiologists on the MC data. A plus sign indicates CXRs as TB positive (abnormal) by one of the radiologists, and the minus sign represents CXRs classified as normal. According to TableIV, both radiologists agree in 84.8% of the cases (95% CI:[77.7,90.3], using exact one-sample test of proportion). The corresponding kappa value is (κ = 0.69, 95% CI:[0.52,0.86]). This signifies moderate agreement.</figDesc><table><row><cell></cell><cell cols="2">Radiologist B</cell><cell></cell></row><row><cell></cell><cell>+</cell><cell>-</cell><cell></cell></row><row><cell>Radiologist A</cell><cell>+ 69 -6</cell><cell>15 48</cell><cell>84 54</cell></row><row><cell></cell><cell>75</cell><cell>63</cell><cell>138</cell></row><row><cell></cell><cell>TABLE IV</cell><cell></cell><cell></cell></row><row><cell cols="4">RADIOLOGIST AGREEMENT ON MONTGOMERY CXRS.</cell></row></table><note><p>classified</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE V COMPARISON</head><label>V</label><figDesc>OF HUMAN CONSENSUS PERFORMANCE WITH GROUND TRUTH OF MONTGOMERY CXRS.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table V ,</head><label>V</label><figDesc>the number of false negatives is zero, which means the radiologists succeeded in detecting all TB positive cases. Therefore, the sensitivity (recall) is 100% (95% CI:[93.<ref type="bibr" target="#b7">8,</ref>100]). The specificity is 68.8% (95% CI:[57.4,78.7]), so there is a considerable number of false positives, namely 25. Both radiologists agree in 81.9% of the cases with the groundtruth data (95% CI:[74.4,87.9]), which is a relatively low recognition rate due to overreading and trying not to miss any potential positive TB case.In TableVI, we compare our machine output with the ground-truth data, using again the standard classification scheme that considers patterns classified with positive confidence as abnormal. Here, the agreement with the ground-truth</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Machine</cell></row><row><cell></cell><cell></cell><cell>+</cell><cell>-</cell></row><row><cell>Ground Truth</cell><cell>+ -</cell><cell cols="2">43 15 15 65</cell><cell>58 80</cell></row><row><cell></cell><cell></cell><cell cols="3">58 80 138</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors thank Dr. S. Qasba, Medical Director of Montgomery County's TB Control program, for providing the CXRs for the MC set. The views and opinions of authors expressed in this paper do not necessarily state or reflect those of the United States Government or any agency thereof, and they may not be used for advertising or product endorsement purposes.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Manuscript received August 13, 2013. This research is supported by the Intramural Research Program of the National Institutes of Health (NIH), National Library of Medicine (NLM), Lister Hill National Center for Biomedical Communications (LHNCBC). It is partially funded by US NIH NIBIB Award R33-EB00573 (K.P.).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName><surname>Who</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Global Tuberculosis Report. World Health Organization</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Global Tuberculosis Control 2011</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>World Health Organization</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">The Global Plan to Stop TB 2011-2015</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Stop</surname></persName>
		</author>
		<author>
			<persName><surname>Partnership</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>World Health Organization</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Graph-cut based automatic lung boundary detection in chest radiographs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Candemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Palaniappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Thoma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Healthcare Technology Conference: Translational Engineering in Health &amp; Medicine</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="31" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multi-class regularization parameter learning for graph cut image segmentation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Candemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Palaniappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Akgul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Biomedical Imaging</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1473" to="1476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Detecting tuberculosis in radiographs using combined lung masks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karargyris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Thoma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. IEEE Engineering in Medicine and Biology Society</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="4978" to="4981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Reexamining the role of radiography in tuberculosis case finding</title>
		<author>
			<persName><forename type="first">C</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Int. J. of Tuberculosis and Lung Disease</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1279" to="1279" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Chest Imaging: An Algorithmic Approach to Learning</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Folio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Tuberculosis screening of chest radiographs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Thoma</surname></persName>
		</author>
		<ptr target="spie.org/x48510.xml" />
	</analytic>
	<monogr>
		<title level="j">SPIE Newsroom</title>
		<imprint>
			<date type="published" when="2011">September 2013. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Radiographic manifestations of tuberculosis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Daley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gotway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jasmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">A primer for Clinicians</title>
		<meeting><address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<publisher>Francis J. Curry National Tuberculosis Center</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Tuberculosis: A radiologic review</title>
		<author>
			<persName><forename type="first">J</forename><surname>Burrill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Conder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Misra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiographics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1255" to="1273" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Diagnostic Atlas of Intrathoracic Tuberculosis in Children</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>International Union Against Tuberculosis and Lung Disease</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Pulmonary tuberculosis: the essentials</title>
		<author>
			<persName><forename type="first">A</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">210</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="307" to="322" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Computer-aided diagnosis in chest radiography: Beyond nodules</title>
		<author>
			<persName><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hogeweg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Prokop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Radiology</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="226" to="230" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Computer-aided diagnosis in radiology: A research plan</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lodwick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Investigative Radiology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">72</biblScope>
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The coding of Roentgen images for computer analysis as applied to lung cancer</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lodwick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Keats</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dorst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">185</biblScope>
			<date type="published" when="1963">1963</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Computer-aided nodule detection on digital chest radiography: validation test on consecutive t1 cases of resectable lung cancer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Soeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Okafuji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yoshitake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yabuuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Yoshino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Honda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Doi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Digital Imaging</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="376" to="382" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Computer-aided diagnosis for the detection and classification of lung cancers on chest radiographs: ROC analysis of radiologists&apos; performance</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shiraishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Abe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Engelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Macmahon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Doi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Academic radiology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="995" to="1003" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Improved detection of lung nodules on chest radiographs using a commercial computer-aided diagnosis system</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kakeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Moriya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Aoki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nakata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Oda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katsuragawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Doi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Roentgenology</title>
		<imprint>
			<biblScope unit="volume">182</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="505" to="510" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Current status and future potential of computer-aided diagnosis in medical imaging</title>
		<author>
			<persName><forename type="first">K</forename><surname>Doi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Radiology</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="19" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Computeraided diagnosis in chest radiography: a survey</title>
		<author>
			<persName><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ter Haar Romeny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Viergever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1228" to="1241" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Segmentation of anatomical structures in chest radiographs using supervised methods: a comparative study on a public database</title>
		<author>
			<persName><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stegmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Loog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Analysis</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="40" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Automatic segmentation of lung fields in chest radiographs</title>
		<author>
			<persName><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ter Haar</surname></persName>
		</author>
		<author>
			<persName><surname>Romeny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Physics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2445" to="2455" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fusing shape information in lung segmentation in chest radiographs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dawoud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Analysis and Recognition</title>
		<imprint>
			<biblScope unit="page" from="70" to="78" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automatic detection of abnormalities in chest radiographs using local texture analysis</title>
		<author>
			<persName><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katsuragawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ter Haar Romeny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Doi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Viergever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="139" to="149" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fusion of local and global detection systems to detect tuberculosis in chest radiographs</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hogeweg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dawson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ayles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Computing and Computer-Assisted Intervention (MICCAI)</title>
		<imprint>
			<biblScope unit="page" from="650" to="657" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A hybrid knowledge-guided detection technique for screening of infectious pulmonary tuberculosis from chest radiographs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2646" to="2656" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Automated cavity detection of infectious pulmonary tuberculosis in chest radiographs</title>
		<author>
			<persName><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mandal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. IEEE Engineering in Medicine and Biology Society (EMBS)</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="5178" to="5181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Clavicle segmentation in chest radiographs</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hogeweg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>De Jong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maduskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Analysis</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1490" to="1502" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Lung nodules: Improved detection with software that suppresses the rib and clavicle on chest radiographs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Freedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Seibel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bromley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">260</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="265" to="273" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Dissimilarity-based classification in the absence of local ground truth: Application to the diagnostic interpretation of chest radiographs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Arzhaeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tax</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1768" to="1776" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Automatic screening for tuberculosis in chest radiographs: a survey</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karargyris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Candemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Siegelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Folio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Thoma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quantitative Imaging in Medicine and Surgery</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="89" to="99" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Application of stepwise binary decision classification for reduction of false positives in tuberculosis detection from smeared slides</title>
		<author>
			<persName><forename type="first">C</forename><surname>Pangilinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Divekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Coetzee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fourie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lure</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Imaging and Signal Processing in Healthcare and Technology</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Rapid molecular detection of tuberculosis and rifampin resistance</title>
		<author>
			<persName><forename type="first">C</forename><surname>Boehme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nabeta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hillemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nicol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shenai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Krapp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tahirli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Blakemore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rustomjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New England Journal of Medicine</title>
		<imprint>
			<biblScope unit="volume">363</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1005" to="1015" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Development of a digital image database for chest radiographs with and without a lung nodule</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shiraishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katsuragawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ikezoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Matsumoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kobayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Komatsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matsui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fujita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kodera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Doi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Roentgenology</title>
		<imprint>
			<biblScope unit="volume">174</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="74" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Graph cuts and efficient n-d image segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Funka-Lea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="109" to="131" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Fast approximate energy minimization via graph cuts</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1222" to="1239" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dual channel colocalization for cell cycle analysis using 3D confocal microscopy</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Casas-Delucchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Palaniappan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Pattern Recognition</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="2580" to="2583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Classification of cell cycle phases in 3D confocal microscopy using PCNA and chromocenter features</title>
	</analytic>
	<monogr>
		<title level="m">Indian Conf. on Computer Vision, Graphics, and Image Processing</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="412" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Efficient feature extraction and likelihood fusion for vehicle tracking in low frame rate airborne video</title>
		<author>
			<persName><forename type="first">K</forename><surname>Palaniappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bunyak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ersoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ganguli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Haridas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Seetharaman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Information Fusion</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Computer-aided renal cancer quantification and classification from contrast-enhanced CT via histograms of curvaturerelated features</title>
		<author>
			<persName><forename type="first">M</forename><surname>Linguraru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gautam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Linehan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. IEEE Engineering in Medicine and Biology Society</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="6679" to="6682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Persistent target tracking using likelihood fusion in wide-area and full motion video sequences</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pelapur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Candemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bunyak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Poostchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Seetharaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Palaniappan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Information Fusion (FUSION)</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2420" to="2427" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comp. Vision Patt. Recog</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="886" to="893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">An integrated system for moving object classification in surveillance videos</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hampapur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Advanced Video and Signal Based Surveillance</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="52" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A twostage approach to people and vehicle detection with hog-based SVM</title>
		<author>
			<persName><forename type="first">F</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cekander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sawhney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Performance Metrics for Intelligent Systems Workshop</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">An HOG-LBP human detector with partial occlusion handling</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Computer Vision</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="32" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Multiresolution gray-scale and rotation invariant texture classification with local binary patterns</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mäenpää</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="971" to="987" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A comparative study of texture measures with classification based on feature distributions</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Harwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="51" to="59" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Dynamic texture recognition using local binary patterns with an application to facial expressions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="915" to="928" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Pedestrian detection: An evaluation of the state of the art</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dollar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wojek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="743" to="761" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Rotationally invariant hashing of median binary patterns for texture classification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hafiane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Seetharaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Palaniappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zavidovique</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Image Analysis and Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="619" to="629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Multiscale vessel enhancement filtering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Frangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Niessen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vincken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Viergever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Epifluorescence-based quantitative microvasculature remodeling using geodesic level-sets and shape-based evolution</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bunyak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Palaniappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Glinskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Glinskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Glinsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Huxley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. IEEE Engineering in Medicine and Biology Society (EMBS)</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="3134" to="3137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">ITI&apos;s participation in the ImageCLEF 2012 medical retrieval and classification tasks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Thoma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">CLEF 2012 Working Notes</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">GeoIRIS: Geospatial information retrieval and indexing system -Content mining, semantics modeling, and complex queries</title>
		<author>
			<persName><forename type="first">C.-R</forename><surname>Shyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Klaric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Palaniappan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="839" to="852" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">LIRE: Lucene Image Retrieval: an extensible Java CBIR library</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chatzichristofis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Int. Conf. on Multimedia</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1085" to="1088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Content-based image retrieval with LIRE</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Int. Conf. on Multimedia</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="735" to="738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">LIRE (Lucene Image Retrieval): an open source library for contentbased image retrieval</title>
		<ptr target="https://code.google.com/p/lire/" />
		<imprint>
			<date type="published" when="2013-09">September 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Robust texture features for still-image retrieval</title>
		<author>
			<persName><forename type="first">P</forename><surname>Howarth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rüger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEE Proceedings -Vision, Image and Signal Processing</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">152</biblScope>
			<biblScope unit="page" from="868" to="874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">CEDD: color and edge directivity descriptor: a compact descriptor for image indexing and retrieval</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chatzichristofis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Boutalis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="312" to="322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">FCTH: Fuzzy color and texture histogram -a low level feature for accurate image retrieval</title>
	</analytic>
	<monogr>
		<title level="m">Int. Workshop on Image Analysis for Multimedia Interactive Services</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="191" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Visual pattern recognition by moment invariants</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IRE Trans. Information Theory</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="187" />
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">DISCOVIR</title>
		<ptr target="http://appsrv.cse.cuhk.edu.hk/∼miplab/discovir/" />
	</analytic>
	<monogr>
		<title level="m">Distributed Content-based Visual Information Retrieval System</title>
		<imprint>
			<date type="published" when="2013-09">September 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Caliph &amp; Emir: MPEG-7 photo annotation and retrieval</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Multimedia</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="925" to="926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Statistical texture analysis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shobha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of World Academy of Science, Engineering and Technology</title>
		<meeting>of World Academy of Science, Engineering and Technology</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1264" to="1269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title/>
		<author>
			<persName><surname>Matlab</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>The MathWorks Inc</publisher>
		</imprint>
	</monogr>
	<note>version 7.4.0.287 (R2007a</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">The nature of statistical learning theory</title>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Springer Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<title level="m">Advances in kernel methods: support vector learning</title>
		<imprint>
			<publisher>The MIT press</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Minimal shape and intensity cost path segmentation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Seghers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Loeckx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Maes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suetens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1115" to="1129" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Active shape model segmentation with optimal features</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ginneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Frangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Staal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Romeny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Viergever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="924" to="933" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Segmenting lung fields in serial chest radiographs using both populationbased and patient-specific shape statistics</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="481" to="494" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Lung segmentation in chest radiographs using anatomical atlases with non-rigid registration</title>
		<author>
			<persName><forename type="first">S</forename><surname>Candemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Palaniappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Musco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karargyris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Thoma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Medical Imaging</title>
		<imprint/>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">High sensitivity of chest radiograph reading by clinical officers in a tuberculosis prevalence survey</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hoog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Meme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Van Deutekom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mithika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Olunga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Onyino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Borgdorff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Int. J. of Tuberculosis and Lung Disease</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1308" to="1314" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Performance evaluation of automatic chest radiograph reading for detection of tuberculosis (TB): a comparative study with clinical officers and certified readers on TB suspects in sub-Saharan Africa</title>
		<author>
			<persName><forename type="first">P</forename><surname>Maduskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hogeweg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ayles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>European Congress of Radiology</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Firefly -web-based interactive tool for the visualization and validation of image processing algorithms</title>
		<author>
			<persName><forename type="first">D</forename><surname>Beard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>University of Missouri</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s thesis</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
