<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Evolutionary algorithms with preference polyhedron for interval multi-objective optimization problems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013-01-31">31 January 2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Dunwei</forename><surname>Gong</surname></persName>
							<email>dwgong@vip.163.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Electrical Engineering</orgName>
								<orgName type="institution">China University of Mining and Technology</orgName>
								<address>
									<postCode>221116</postCode>
									<settlement>Xuzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jing</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Electrical Engineering</orgName>
								<orgName type="institution">China University of Mining and Technology</orgName>
								<address>
									<postCode>221116</postCode>
									<settlement>Xuzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Science</orgName>
								<orgName type="institution">Huaihai Institute of Technology</orgName>
								<address>
									<postCode>222005</postCode>
									<settlement>Lianyungang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xinfang</forename><surname>Ji</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information and Electrical Engineering</orgName>
								<orgName type="institution">China University of Mining and Technology</orgName>
								<address>
									<postCode>221116</postCode>
									<settlement>Xuzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">School of Information and Electrical Engineering</orgName>
								<orgName type="institution">China University of Mining and Technology</orgName>
								<address>
									<postCode>221116</postCode>
									<settlement>Xuzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Evolutionary algorithms with preference polyhedron for interval multi-objective optimization problems</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2013-01-31">31 January 2013</date>
						</imprint>
					</monogr>
					<idno type="MD5">D50A3E84242791E7CAE0B64E5852755D</idno>
					<idno type="DOI">10.1016/j.ins.2013.01.020</idno>
					<note type="submission">Received 29 July 2011 Received in revised form 18 January 2013 Accepted 24 January 2013</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Evolutionary algorithm Interaction Multi-objective optimization Interval Preference polyhedron</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multi-objective optimization problems (MOPs) with interval parameters are ubiquitous in real-world applications. Existing evolutionary optimization methods, however, aim to obtain a set of well-converged and evenly-distributed Pareto-optimal solutions. In this paper, we presented a novel evolutionary algorithm (EA) that interacts with a decision maker (DM) during the optimization process to obtain the most preferred solution. The theory of preference polyhedron for the optimization problem with interval parameters was developed first. An interactive evolutionary algorithm (IEA) for MOPs with interval parameters was then proposed based on the theory of preference polyhedron. The algorithm periodically provides a set of non-dominated solutions to the DM; a preference polyhedron is constructed in the objective space by taking the worst solution chosen by the DM as the vertex. The solutions with the same rank are sorted based on the polyhedron constructed. Finally, our method was empirically evaluated on several MOPs with interval parameters where the value functions were used to simulate the DM's responses. The numerical results indicated that our method is simpler and more efficient than the a posteriori method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>When tackling optimization problems in real-word applications, it is usually required to simultaneously consider several conflicting objectives. In general, these objectives and/or constraints always contain uncertain parameters, such as fuzzy numbers, random variables, and intervals. Such problems are called uncertain MOPs.</p><p>Existing methods for solving uncertain optimization problems can be mainly classified into three categories: random programming <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b12">13]</ref>, fuzzy programming <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b31">32]</ref> and interval programming <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b22">23]</ref>, based on the types of uncertain parameters <ref type="bibr" target="#b18">[19]</ref>. Uncertain parameters in the optimization problems, which are solved by random programming or fuzzy programming, are random variables, whose probability distributions are known a priori, or fuzzy numbers, whose membership functions are also known in advance. However, the applications of random programming and fuzzy programming are quite limited due to the difficulties in specifying the accurate probability distributions or appropriate membership functions in real applications. Uncertain parameters in the optimization problems solved by interval programming are intervals. In the application of such programming, the upper and lower limits or the midpoints and the radius of these intervals should be given beforehand. It is usually easy to acquire the values of these parameters. In addition, random variables or fuzzy numbers can be transformed into intervals by the confidence level <ref type="bibr" target="#b10">[11]</ref> or the a-cut set <ref type="bibr" target="#b31">[32]</ref>. Thus, the optimization problems with random parameters or fuzzy parameters can be transformed into the ones with interval parameters. Consequently, the study of optimization problems with interval parameters is very important in theory and application. In this paper, We study the multi-objective optimization problem (MOP) with interval parameters.</p><p>Evolutionary algorithms (EAs) are a type of stochastic global optimization methods inspired by nature evolution and genetic mechanisms. Since EAs can simultaneously search for a number of Pareto-optimal solutions in a single run, they are well acknowledged as efficient for MOPs, such as VEGA <ref type="bibr" target="#b27">[28]</ref> and NSGA-II <ref type="bibr" target="#b6">[7]</ref>.</p><p>Traditional evolutionary multi-objective optimization (EMO) methods are not applicable for solving the MOPs with interval parameters, due to the objective values being intervals. There are two approaches to solve the MOPs with interval parameters by EAs in the existing literatures: one is to transform optimization problems with interval parameters into deterministic MOPs <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b18">19]</ref>; the other is to compare the quality of solutions by defining a dominant relationship between two solutions whose objective values are intervals <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b22">23]</ref>.</p><p>Like traditional EMO methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b27">28]</ref>, EAs for MOPs with interval parameters <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b22">23]</ref> aim to obtain a set of well-converged and evenly-distributed Pareto-optimal solutions. However, in practice, one must choose the most preferred solution. Thus, compared with single-objective optimization problems, in MOPs, there are at least two equally important tasks: optimization for finding Pareto-optimal solutions and decision-making for choosing the most preferred solution <ref type="bibr" target="#b2">[3]</ref>. The relationship between the two tasks leads to three different kinds of methods: the first one is to make decision before optimization, called a priori methods; the second one is to make decision after optimization, called a posteriori methods; and the last one is to make decision during optimization, called interactive methods.</p><p>A priori methods require the DM to pre-specify her/his preferences, e.g., a set of weights on different objectives. However, it is rather difficult to specify preferences without a good knowledge of problems. In a posteriori methods, a decision-making event is executed after an approximation Pareto-optimal set has been generated, which implies elaborate selection from a large set of candidates. Interactive methods have the following advantages <ref type="bibr" target="#b2">[3]</ref>: <ref type="bibr" target="#b0">(1)</ref> preference information requested from the DM is usually much simpler than that required by a priori methods; <ref type="bibr" target="#b1">(2)</ref> it has moderate computational requirements in comparison with a posteriori methods; (3) as the DM controls the search process, she/he gets more involved in the process, and could be more confident about the final solution. Therefore, interactive methods are very promising and specifically applicable for interactively solving complicated MOPs.</p><p>Rachmawati and Srinivasan <ref type="bibr" target="#b24">[25]</ref>, Jiao et al. <ref type="bibr" target="#b19">[20]</ref>, and Said et al. <ref type="bibr" target="#b26">[27]</ref> derived the most preferred solution/region by using the relative importance of objectives, reference points and aspiration levels, respectively. Recent developments, which will be summarized in Section 2, show that eliciting the DM's preference information during the optimization process and constructing the DM's preference model received more and more attentions. Related methods fall into the following three categories: machine learning based methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b21">22]</ref>, fit based methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b29">30]</ref> and preference convex cone/polyhedron cone based methods <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b28">29]</ref>. For the first two types of methods, pairwise comparisons of all candidates in the objective space are conducted. For the last one, it is necessary to choose only the best or the worst one from all candidates in the objective space, which alleviates the DM's burden in evaluations and avoids selecting an appropriate explicit value function.</p><p>There exist various interactive EMO algorithms for deterministic MOPs. So far, to the best of our knowledge, there have been no interactive methods for MOPs with interval parameters. Therefore, seeking the DM's most preferred solution for a MOP with interval parameters deserves a careful study.</p><p>In this study, we proposed a preference-based EA for MOPs with interval parameters by employing the framework of NSGA-II, which incorporates an optimization-cum-decision-making procedure. In order to alleviate the DM's burden in evaluations, a preference polyhedron is created to approximate the DM's value function by using convex cones <ref type="bibr" target="#b20">[21]</ref>, and is used to guide the search toward the DM's preferred region. Some preliminary results of this study were presented in <ref type="bibr" target="#b30">[31]</ref>, here we extend the methodology and propose the following new features:</p><p>(1) Presenting the rigorous proof of each theorem.</p><p>(2) Generalizing the method of constructing a preference polyhedron to the case of any number of objectives.</p><p>(3) Performing the complexity analysis of the proposed algorithm. The advantage of our method is that we do not need to know the exact form of the value function, but only assume that it is quasi-concave and non-decreasing. The quasi-concavity of the value function is necessary for its maximization problem to have a unique solution <ref type="bibr" target="#b5">[6]</ref>. When the DM's evaluation is rational, non-decreasing is inherent for the value function. Consequently, the above assumption is realistic.</p><p>The main contributions of our study are: (1) the theory of a preference polyhedron was investigated, which not only enriches the knowledge of interval mathematics, but also lays the foundation of interval multiple criteria decision making;</p><p>(2) the preference polyhedron for a MOP with interval parameters was constructed to reduce the number of evaluations, avoid choosing a proper explicit preference function, and to implicitly sort solutions; (3) a criterion incorporating the DM's preferences to choose the solutions with the same rank was presented toward guide the search toward the DM's preferred region.</p><p>The remainder of this paper is structured as follows. In Section 2, the related work in the literature is reviewed. Section 3 presents the theory of preference polyhedron in the context of uncertainty. In Section 4, the framework of our algorithm is presented in detail. Applications of our method to typical MOPs with interval parameters are given in Section 5. Section 6 summarizes the main results of our work and suggests some new research directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Limbourg et al. <ref type="bibr" target="#b22">[23]</ref> discussed a MOP with noises in objectives, whose values are expressed by intervals. Based on an order relation of intervals, a dominant relationship is defined and employed to sort solutions. Accordingly, an algorithm, i.e. imprecision-propagating multi-objective evolutionary algorithm (IP-MOEA), for MOPs with interval parameters is developed.</p><p>We <ref type="bibr" target="#b15">[16]</ref> have studied MOPs with interval parameters. The dominant relationship between two solutions and the crowding measure of a solution are defined based on interval objectives, and the method of selecting optimal solutions is proposed based on the rank and the crowding measure.</p><p>The purpose of the above methods is to find a set of well-converged and evenly-distributed Pareto-optimal solutions. In practice, one must obtain the most preferred solution.</p><p>Krettek et al. <ref type="bibr" target="#b21">[22]</ref> proposed a novel interactive EMO, which combines an EA with an instance based supervised online learning scheme for the DM's preferences. The interactive decision-making is repeated every s generations. After clustering the current Pareto-optimal set, the DM expresses her/his preferences by pairwise comparison of cluster prototypes in term of mutual quality and comparability, and her/his preferences are learned by the preference estimation based on the pairwise similarity.</p><p>Battiti and Passerini <ref type="bibr" target="#b1">[2]</ref> adopted the methodology of reactive search optimization (RSO) for interactive EMO. RSO follows the paradigm of ''learning while optimizing,'' through the use of online machine learning techniques as an integral part of a self-tuning optimization scheme. The aim of the learning is to construct the approximation function of the DM's preferences.</p><p>The above two methods progressively acquire the DM's preference information during the optimization process. The DM's value function is approximately constructed by machine learning techniques, which guides subsequent evolutions.</p><p>Deb et al. <ref type="bibr" target="#b7">[8]</ref> suggested an interactive EMO method based on preferences. A strictly increasing value function is modeled by using the preference information progressively from the DM after every few generations of an EMO algorithm. A preference based dominant principle and termination criterion are used to direct the search toward more preferred solutions. Results on 2-5-objective optimization problems demonstrate the simplicity of the proposed approach and its future promise.</p><p>Sinha et al. <ref type="bibr" target="#b29">[30]</ref> proposed a generalized polynomial value function to fit the DM's preference information. The number of product terms in this polynomial function is variable. This makes the algorithm more efficient to eliminate cases whose value function cannot fit the DM's preferences. The proposed generic polynomial function was incorporated into the algorithm in <ref type="bibr" target="#b7">[8]</ref>, whose performance was evaluated on 3 and 5-objective test problems with constraints.</p><p>These two methods fit the DM's preferences by an optimization procedure based on the preference information periodically provided by the DM. Explicit value functions can be obtained by these methods, while the type of functions should be chosen a priori.</p><p>Korhonen et al. <ref type="bibr" target="#b20">[21]</ref> developed an interactive method for solving discrete, deterministic multiple criteria problems assuming that the DM has an implicit and quasi-concave increasing value function. Some convex cones are generated by the DM's pairwise comparisons. Any solution that is dominated by these cones may be eliminated and will be forgotten forever. Therefore, this method can greatly reduce the DM's evaluations.</p><p>Fowler et al. <ref type="bibr" target="#b13">[14]</ref> focused on multi-objective knapsack problems. They presented an interactive EMO for quasi-concave preference functions based on the theory of <ref type="bibr" target="#b20">[21]</ref>. In this algorithm, the solutions are periodically presented to the DM for her/his evaluations, and the resulting preference information is used to form preference cones consisting of non-dominated solutions. The cones implicitly rank solutions and guide the search toward the DM's preferred region.</p><p>Sinha et al. <ref type="bibr" target="#b28">[29]</ref> proposed a preference based methodology, where information provided by the DM in the intermediate runs of an EMO algorithm is used to construct a polyhedral cone. This polyhedral cone is used to reduce the search space and to conduct a more focused search. The dominant principle is modified to look for better solutions lying in the preferred region.</p><p>The advantages of the above two methods are described as follows. It is unnecessary to know the explicit type of the DM's value function. The worst/best solution and other candidates are used to form a convex cone/poly-hedral cone reflecting the DM's preferences. The dominant relationship is modified on the basis of this implicit value function, and the search is focused on the preferred region.</p><p>The above methods effectively solve practical MOPs to find the DM's most preferred solution, and numerical experiments confirm their capabilities in solving many-objective optimization problems as well. Nevertheless, they apply solely to deterministic MOPs.</p><p>In this study, we progressively acquire the DM's preference information during the optimization process to construct the DM's preference model. There have been no approaches to assist the DM making decision by convex cone in case of the values of candidates being intervals so far. To address this problem, we should investigate the fundamental theory of the DM's preference model, i.e. preference polyhedron, in the objective space where the objective values are intervals. Both the construction and application of the preference polyhedron are the major contributions of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Preference polyhedron for interval MOPs</head><p>The theory of preference polyhedron is developed in this section. The problem investigated is formulated first; then the definitions of convex set and quasi-concave function for intervals are given based on those in <ref type="bibr" target="#b25">[26]</ref>; finally, the theory and application of preference polyhedron are presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Problem description</head><p>Consider the following MOP with interval parameters:</p><formula xml:id="formula_0">max f ðx; cÞ ¼ ðf 1 ðx; c 1 Þ; f 2 ðx; c 2 Þ; Á Á Á ; f m ðx; c m ÞÞ s:t: x 2 S # R n c i ¼ ðc i1 ; c i2 ; . . . ; c il Þ; i ¼ 1; 2; . . . ; m; c ik ¼ c ik ; c ik ½ ; k ¼ 1; 2; . . . ; l<label>ð1Þ</label></formula><p>where x is an n-dimensional decision variable, S is the decision space of x, f i (x, c i ) is the ith objective function with interval parameters for each i = 1, 2, . . . , m, c i is an interval vector parameter, where c ik is the kth component of c i with c ik and c ik being its lower and upper limits, respectively. Each objective value in ( <ref type="formula" target="#formula_0">1</ref>) is an interval due to its interval parameters, and the value of the ith objective is denoted as</p><formula xml:id="formula_1">f i ðx; c i Þ , f i ðx; c i Þ; f i ðx; c i Þ h i .</formula><p>For the introduction of interval arithmetic, please refer to <ref type="bibr" target="#b23">[24]</ref>.</p><p>The following basic concepts associated with MOPs with interval parameters can be derived from the definition of interval dominant relationship 1 IP proposed in <ref type="bibr" target="#b22">[23]</ref>.</p><p>Definition 1. For the MOP with interval parameters formulated by (1) and x ⁄ 2 S, x ⁄ is called a Pareto-optimal solution of the problem, provided that no x 0 2 S exists, such that x 0 1 IP x ⁄ .</p><p>It is easy to observe that the above definition of Pareto-optimal solution is very similar to the traditional one, except that the interval dominant relationship is utilized.</p><p>Definition 2. The collection of all Pareto-optimal solutions is called a Pareto-optimal set. Definition 3. The collection of objective intervals (or hyper-volume) associated with Pareto-optimal solutions is called a Pareto front.</p><p>In general, there are several Pareto-optimal solutions for a MOP. Assume that there are M non-dominated solutions, then at most M À 1 pairwise comparisons are required to find the most preferred one. For most problems, fewer comparisons are needed <ref type="bibr" target="#b20">[21]</ref>. The method proposed in <ref type="bibr" target="#b20">[21]</ref> will be extended to the case where the values of candidates are intervals. Therefore, the definitions involved in the method are introduced in the following subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Convex set and quasi-concave function for intervals</head><p>Denote the set of all closed intervals on R as I(R) and a sub-space on R m as</p><formula xml:id="formula_2">D = D 1 Â D 2 Â Á Á Á Â D m # R m ,</formula><p>then the set of all m-dimensional interval vectors on D can be denoted as</p><formula xml:id="formula_3">I(D) = {AjA = (a 1 , a 2 , . . . , a m ) 2 I(R m ), a i 2 I(D i ), i = 1, 2, . . . , m}. Definition 4. For "A, B 2 I(D), if kA þ ð1 À kÞB 2 IðDÞ; k 2 ½0; 1<label>ð2Þ</label></formula><formula xml:id="formula_4">is held, I(D) is called a convex interval set on I(R m ). Definition 5. If A 1 , A 2 , . . . , A g are m-dimensional interval vectors in I(D), then E ¼ eje ¼ X g i¼1 l i A i ; X g i¼1 l i ¼ 1; l i P 0 ( )<label>ð3Þ</label></formula><p>is called a convex polyhedron generated by A 1 , A 2 , . . . , A g . Fig. <ref type="figure" target="#fig_1">1</ref> illustrates a convex polyhedron generated by 2-dimensional interval vectors A 1 , A 2 , . . . , A 5 .</p><p>It is worth noting that in a real space, a point lying in a convex polyhedron, which is generated by some points, must be a linear combination of these points. This, however, is not true in an interval space, because not all vertices of a hyper-cube lying in a convex polyhedron, which is generated by some hyper-cubes, are linear combinations of these hyper-cubes for the same values of l i , i = 1, 2, . . . , m. Therefore, in an interval space, there exist two types of hyper-cubes in a convex polyhedron: one is a linear combination of those hyper-cubes which generate the polyhedron, as C in Fig. <ref type="figure" target="#fig_2">2a</ref>; the other is not, as C 0 in Fig. <ref type="figure" target="#fig_2">2a</ref>. For the second case, there must exist a hyper-cube which is a linear combination of these hyper-cubes, containing or being contained by the second type of hyper-cubes, just as C 0 and C in Fig. <ref type="figure" target="#fig_2">2a</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 6. Let F(H) be an interval function defined on a convex interval set I(D). For</head><formula xml:id="formula_5">"A, B 2 D and k 2 [0, 1], if F(kA + (1 À k)B) P IN min{F(A), F(B)} is held, F(H) is called a quasi-concave interval function.</formula><p>Remark. Interval a is no less than interval b, iff the lower and upper limits of a are no less than those of b, i.e.,</p><formula xml:id="formula_6">a P IN b () a P b ^ a P b:<label>ð4Þ</label></formula><p>A quasi-concave interval function can be obtained by replacing real arguments of a quasi-concave real function with intervals from Eq. (4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Preference polyhedron</head><p>Two theorems are given in this subsection, whose applications are explained with two examples. The proofs of these theorems are given in Appendices A and B, respectively.</p><p>As stated before, at most M À 1 pairwise comparisons are required to find the most preferred one from M non-dominated solutions. Given that a DM has a quasi-concave and increasing (implicit) value function, Korhonen et al. <ref type="bibr" target="#b20">[21]</ref> proposed a method to prune certain candidates that are not used in comparisons, so that the comparisons are reduced. If incorporating it into EMO methods in an interactive way, user fatigue will be alleviated to some extent. The method, however, is  inapplicable for solving interval multiple criteria decision making problems, the theory in <ref type="bibr" target="#b20">[21]</ref> should be tailored to the case of interval candidates. The following theory are thus developed.</p><p>Theorem 1. Assume that a quasi-concave interval function F(H) is defined in an m-dimensional metric space, i.e., the objective space of problem <ref type="bibr" target="#b0">(1)</ref>. Consider the distinct candidates g i 2 I(R m ), i = 1, 2, . . . , g, i.e., the objective values corresponding to nondominated solutions, where g is the number of candidates. Let the convex polyhedron E be generated by these candidates, and assume that F(g k ) = min i F(g i ), if y lies in E, then F(y) P IN F(g k ) or F(y)kF(g k ).</p><p>Theorem 2. Assume that the conditions are the same as those of Theorem 1, and F(g i ) </p><formula xml:id="formula_7">&gt; IN F(g k ),i -k. If y 0 lies in Z and y 0 -g k , where Z ¼ zjz ¼ P g i¼1;i-k l i ðg k À g i Þ; l i P 0 n o , it follows that F(g k ) P IN F(y 0 ) or F(g k )kF(y 0 ).</formula><p>It can be observed that the case where either F(y)kF(g k ) or F(g k )kF(y 0 ) seldom occurs in the proofs in appendixes. So we omit this case hereinafter. We illustrate the applications of these theorems with two simple examples whose objective spaces are 2-dimensional, shown in Fig. <ref type="figure" target="#fig_2">2</ref>. For two candidates, say A and B, if A is preferred to B in Fig. <ref type="figure" target="#fig_2">2a</ref>, it follows that any candidate lying in the light grey region is at least as preferred as B from Theorem 1, and any candidate lying in the black region is not preferred to B according to Theorem 2. Similarly, for three candidates, say g 1 , g 2 and g 3 , if g 3 is the worst one in Fig. <ref type="figure" target="#fig_2">2b</ref>, any candidate lying in the light grey region is at least as preferred as g 3 , and any candidate lying in the dark grey region is not preferred to g 3 . Further, any candidate lying in the region generated by g 1 and g 2 is at least as preferred as g 3 . Accordingly, any candidate lying in the black region is not preferred to g 3 . Then, we can draw the following conclusion: any candidate lying in either the dark grey region or the black one is not preferred to g 3 . Thus, when a decision is made among many candidates, all lying in the black region, shown in Fig. <ref type="figure" target="#fig_2">2a</ref>, as well as in the dark grey and black regions, shown in Fig. <ref type="figure" target="#fig_2">2b</ref>, can be eliminated. Consequently, the number of evaluations can be greatly reduced.</p><p>It can be observed from Fig. <ref type="figure" target="#fig_2">2</ref> that all solutions can be divided into three categories: the preferred, non-preferred and uncertain preference solutions, suggesting that solutions can be sorted based on the convex polyhedron in Fig. <ref type="figure" target="#fig_2">2</ref>, called the preference polyhedron in this study. Accordingly, the regions where the objective values associated with these three types of solutions locate are called the preferred, non-preferred and uncertain preference regions, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">IEA with preference polyhedron</head><p>We propose an IEA for MOPs with interval parameters based on the preference polyhedron in this section. In the framework of NSGA-II, providing that an EA for MOPs with interval parameters has evolved s generations, we provide the DM with g &gt; m sparse ones from the non-dominated solutions every s generations. The DM is requested to choose the worst one from them, and choose the best one from them and the recent best one to obtain her/his most preferred one. With these optimal solutions presented to the DM, we create a preference polyhedron in the objective space, elucidated in Section 4.1. Until the next s generations, we use the constructed preference polyhedron to sort the solutions with the same rank, described in Section 4.2. When the termination criterion is met, the DM is asked to select the most preferred one from the objective values associated with non-dominated and the recent best solutions. The detailed steps are described as follows:</p><p>Step 1: Initialize a population P(0) of size N; let t = 0 and an EA for MOPs with interval parameters is executed for s generations; the value of t is incremented by one after each generation.</p><p>Step 2: If (t À 1) mod s = 0, and the number of non-dominated solutions is larger than m, choose g sparse optimal solutions; otherwise, go to Step 4.</p><p>Step 3: Select the worst and the best solutions, and construct a preference polyhedron with the worst solution as the vertex in the objective space.</p><p>Step 4: Employ the tournament selection of size 2, and perform crossover and mutation operations to create an offspring Q(t) of size N.</p><p>Step 5: Combine P(t) and Q(t), and denote the combination as R(t).</p><p>Step 6: Rank solutions based on the preference polyhedron, and select the first N superior solutions to form P(t + 1).</p><p>Step 7: Judge whether the algorithm's termination criterion is met. If yes, choose the most preferred solution; otherwise, let t = t + 1, and go to Step 2.</p><p>Fig. <ref type="figure" target="#fig_4">3</ref> illustrates the flowchart of the proposed algorithm, and the method proposed in this study lies in the shadow areas. As can be seen from Fig. <ref type="figure" target="#fig_4">3</ref>, the difference between the proposed algorithm and NSGA-II, as well as IP-MOEA, is that the proposed algorithm interacts with a DM and sorts the solutions with the same rank based on the DM's preference information.</p><p>Note that IP-MOEA is employed to evolve an initial population for s generations in this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Constructing preference polyhedron</head><p>A method for constructing a preference polyhedron of an interval MOP with any number of objectives is elaborated in this subsection.</p><p>For simplicity, we simplify the DM's preferred and non-preferred regions as follows:</p><p>(1) For the preferred region, we extend it to the light grey region in Fig. <ref type="figure" target="#fig_0">4</ref>, suggesting that we regard a part of uncertain preference solutions as the preferred ones. (2) For the non-preferred region, we change it to the black region, shown in Fig. <ref type="figure" target="#fig_6">4b</ref>, or the dark grey and black regions, shown in Fig. <ref type="figure" target="#fig_6">4a</ref>, indicating that a part of non-preferred solutions are considered as the uncertain preference ones.</p><p>In fact, the above treatment only tentatively amplifies the DM's preferred region and reduces the non-preferred one, and the efficiency of seeking the most preferred solution may be reduced. The preferred region, nevertheless, shrinks with the DM progressively specifying her/his preferences, and the most preferred solution is finally obtained. Therefore, this treatment does not impact on the search toward the DM's preferred region.</p><p>It is worth noting that the preference polyhedron is constructed on an approximation Pareto front, the endpoints of the polyhedron are also those of the front. Consequently, we should find the maximal value in each objective to construct the preference polyhedron. As the objective values are intervals, the minimal value of the lower limit and the maximal value of the upper limit of all intervals in each objective are selected as the minimal and maximal values in corresponding objective. The above values and the worst one chosen by the DM are used to construct a polyhedron in the objective space. The detailed steps of constructing a preference polyhedron are as follows:</p><p>First, select the worst value, denoted as g k , from g objectives, i.e. g 1 , g 2 , . . . , g g . For instance, g 3 is the worst one among g 1 , g 2 and g 3 in Fig. <ref type="figure" target="#fig_6">4a</ref>, and g k in Fig. <ref type="figure" target="#fig_6">4b</ref> and<ref type="figure">c</ref>, respectively. The location of g k in the objective space may be one of the following two cases: (1) a component of the worst value is the minimal one in corresponding objective, say j, as g 3 in Fig. <ref type="figure" target="#fig_6">4a</ref>, and g k in Fig. <ref type="figure" target="#fig_6">4b;</ref><ref type="figure"></ref> (2) all components of the worst value are not the minimal one in corresponding objective, as g k in Fig. <ref type="figure" target="#fig_6">4c</ref>. No matter what situations, we find the maximal value in each objective from the remaining g À 1 objective values, denoted as Finally, m + 1 hyper-planes can be constructed using g k and f b i ; i ¼ 1; 2; . . . ; m, which form a convex polyhedron. To be more specific, assume that a hyper-plane is constructed using m candidates, i.e., An open polyhedron, i.e., preference polyhedron in this study, is thus derived by removing the hyper-plane not containing g k . When the number of objectives is 2, the above method for constructing a preference polyhedron is the same as that proposed in <ref type="bibr" target="#b30">[31]</ref>.</p><formula xml:id="formula_9">f b i ; i ¼ 1; 2; Á Á Á ; m, respectively.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Ranking individuals based on preference polyhedron</head><p>A ranking scheme based on the DM's preference information is described in this subsection. The detailed method is presented as follows: first, the dominant relationship based on intervals <ref type="bibr" target="#b22">[23]</ref> is used to sort R(t); second, the individuals with the same rank are classified into three categories: the preferred, uncertain preference and non-preferred individuals; finally, the individuals with both the same rank and category are further ranked based on the crowding metric <ref type="bibr" target="#b22">[23]</ref>. The larger the crowding metric of an individual, the better its performance is.</p><p>To be more specific, we sort the individuals with the same rank using the constructed preference polyhedron in Section 4.1. The individuals in the objective space have three possible locations w.r.t. the polyhedron: (1) inside the polyhedron, i.e., lies in the light gray regions in Fig. <ref type="figure" target="#fig_0">4</ref>; they are placed first when sorting; (2) below the polyhedron, i.e., lies in the black regions in Fig. <ref type="figure" target="#fig_0">4</ref>; they are placed last; (3) outside the polyhedron, e.g., outside the region formed by lines L 1 and L 2 in the context of 2 objectives; they are placed in the middle.</p><p>It can be observed from Fig. <ref type="figure" target="#fig_0">4</ref> that no matter what situation of g k , the region formed by the hyper-planes includes the interior and bottom of the polyhedron. If g k is under the hyper-plane formed by f b 1 ; f b 2 ; . . . ; f b m , an individual is preferred as it lies both in the region formed by the hyper-planes and above g k ; conversely, an individual both in the region formed by the hyper-planes and below g k is non-preferred.</p><p>The above ranking method is applicable for selecting individuals in Step 4. The detailed process of selecting individuals is presented as follows. Randomly select two individuals from the population. Compare them by using the dominant relationship based on intervals <ref type="bibr" target="#b22">[23]</ref>, and select the one with a lower rank. If their ranks are same, compare them by using the preference polyhedron, and select the one in the order of the preferred, uncertain preference and non-preferred. If they have the same preference, select the one with a larger crowding metric; otherwise, randomly choose one.</p><p>It is worth noting that if all individuals with the same rank have the same preference, then no DM's preference information is incorporated into an EA for MOPs with interval parameters. In this circumstance, our algorithm will be degraded to IP-MOEA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Complexity analysis of proposed algorithm</head><p>The complexity of an iteration of the entire procedure is studied in this subsection. The basic operators and their worstcase complexities are as follows:</p><p>(1) Non-dominated sorting is O(8N 2 ). ( <ref type="formula" target="#formula_3">2</ref> Based on the above analysis, the overall complexity of the proposed algorithm is O((2N) m ), which is governed by calculating the hyper-volume. Since the number of individuals with both the same rank and preference in the proposed algorithm is generally smaller than that with the same rank in IP-MOEA, the number of calculating hyper-volume in the proposed algorithm is smaller than that in IP-MOEA. CPU time of the proposed algorithm is thus less than that of the a posteriori method, i.e., an approximation Pareto-optimal set is generated by IP-MOEA, and a decision-making is executed at the end of the algorithm. However, if we use another metric or approximately calculate the hyper-volume to distinguish the individuals with the same rank, the complexity of the proposed algorithm will be governed by non-dominated sorting, and CPU time of the proposed algorithm may be more than that of the a posteriori method, in that the proposed algorithm is imperative to construct the preference polyhedrons and sort individuals based on them, which adds another overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Applications to interval MOPs</head><p>The proposed algorithm's performances were evaluated by optimizing seven benchmark MOPs. The implementation environment was as follows: Pentium (R) Dual-Core CPU, 2G RAM, and Matlab7.0.1. Each algorithm was run for 20 times independently. The mean and median of the results were recorded. The numerical results were analyzed by using nonparametric tests, which do not need prior assumptions related to samples, and can use small size of samples <ref type="bibr" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Test problems</head><p>Four popular 2-objective, two 3-objective, and one 5-objective optimization problems, including 2-objective ZDT1, ZDT2, ZDT4 and ZDT6 from <ref type="bibr" target="#b6">[7]</ref>, 3-objective DTLZ1 and DTLZ2, as well as 5-objective DTLZ2 from <ref type="bibr" target="#b8">[9]</ref> were chosen as benchmark problems. As the objective values of the above optimization problems are deterministic, an imprecision factor d <ref type="bibr" target="#b22">[23]</ref> was employed to make them be intervals. More precisely, for 2-objective ones, the imprecision factors for each objective were sinð10p P i x i Þ and sinð20p P i x i Þ, respectively; for 3-objective ones, the imprecision factors for each objective were sinð10p P i x i Þ, sinð20p P i x i Þ, and sinð40p P i x i Þ, respectively; when optimizing 5-objective one, the imprecision factor, being the same for each objective, was sinð10p P i x i Þ. The corresponding interval MOPs were denoted as ZDT I 1, ZDT I 2, ZDT I 4, ZDT I 6, DTLZ I 1, DTLZ I 2(3d), and DTLZ I 2(5d), respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Value functions</head><p>Inspired by <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30]</ref>, the quasi-concave increasing value functions listed in Table <ref type="table">1</ref> were used to simulate the DM to make decisions. They were used to choose the worst and best ones from the objective values corresponding to the chosen non-dominated solutions, and to evaluate the DM's satisfaction with the solutions. In the experiments, the quasi-concavity of the above functions is necessary, however, whether their forms are explicit or not has little effect on the numerical results. We merely utilized these value functions to simulate the DM's response, which does not mean that the DM's preference information is known a priori. In fact, the DM's preference information was progressively acquired in our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Parameter settings</head><p>Our algorithm was run for 200 generations with the population size of 40 in the context of 2 objectives, and 100 generations with the population size of 100 in the context of 3 and 5 objectives. Simulated binary crossover and polynomial mutation operators <ref type="bibr" target="#b6">[7]</ref> were employed, and the crossover and mutation probabilities were set to 0.9 and 1/30, respectively. In addition, both the distribution indices for crossover and mutation operators were 20. The number of decision variables, in the range of [0, 1], was 30 for these seven test problems. The objectives were normalized <ref type="bibr" target="#b32">[33]</ref> for the MOPs with 3 and 5 objectives. Furthermore, Monte Carlo simulation <ref type="bibr" target="#b0">[1]</ref> was used to approximate exact values of hyper-volume by taking the number of sampling points as 10,000 if the number of objectives is 5.</p><p>There are another two parameters in our algorithm: the number of generations between two consecutive DM calls, s, and the number of individuals provided to the DM for evaluation, g. In order to actually simulate the DM's interactions, the maximal number of DM calls and the maximal value of g were 20 and 8, respectively, in the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Performance measures</head><p>The following four indicators were employed to investigate the performances of our algorithm in the experiments:</p><p>(1) The best value of the preference function (V metric, for short), calculated by one of functions listed in Table <ref type="table">1</ref>. This indicator measures the degree of the DM's satisfaction with an evaluated individual. (2) The number of uncertain preference individuals (U metric, for short). This indicator reflects the degree of the DM's cognition on the evaluated individuals. (3) The angle between lines L 1 and L 2 for 2-objective optimization problems (A metric, for short). This indicator reflects the degree of the DM's cognition on the evaluated individuals as well. The larger the A metric, the clearer the DM's preference is, and the easier the DM's preferred solution is to be found. (4) CPU time, (T metric, for short). This indicator measures the efficiency of a method.</p><p>It should be noted that an interactive EMO algorithm is composed of optimization and decision-making, i.e. interaction. Correspondingly, CPU time of the algorithm is composed of the time needed by optimization and that by interaction. Furthermore, decision-making during the course of evolution is very time-consuming, and the time of interaction is in general far more than that of optimization. Therefore, the more frequent the DM call, the more the CPU time of an interactive algorithm is, suggesting that increasing the number of DM calls will prolong the CPU time of the algorithm. The value functions were used to simulate the DM's interactions in the experiments, the time of decision-making is thus far less than that of optimization, and can be omitted compared with that of optimization. Consequently, strictly speaking, the CPU time in the experiments is only the time of optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Results and analysis</head><p>As stated before, there have been no interactive methods for MOPs with interval parameters, so we have no comparative interactive methods. Additionally, the DM's preference information is acquired by choosing the worst one from a number of candidates, this type of preference information cannot be provided before optimization, an a priori method is thus inapplicable for being a comparative one in this study. In the light of the above consideration, the experiments aim mainly to investigate the performances of our method. Therefore, the experiments were divided into four groups. The first and the second Table <ref type="table">1</ref> Value functions used to emulate the DM's decision-making.</p><p>interval MOPs value function</p><formula xml:id="formula_10">ZDT I 1, ZDT I 2 ( f 1 + 0.4) 2 + (f 2 + 5.5) 2 ZDT I 4, ZDT I 6 1.25f 1 + 1.50f 2 DTLZ I 1, DTLZ I 2 (3d) 1.25f 1 + 1.50f 2 + 2.9047f 3 DTLZ I 2 (5d) (f 1 + 0.4) 2 + (f 2 + 2.1) 2 + (f 3 + 0.8) 2 + (f 4 + 3) 2 + (f 5 + 2.5) 2</formula><p>ones studied two properties of our method, including the construction of the preference polyhedron in a 2-dimensional objective space, and convergence in 2 and 3-dimensional objective spaces. The third and the fourth ones examined the influences of different DM calls and different values of g on the performances of our method, respectively. Particularly, one DM call means that decision-making is executed at the end of the algorithm in the third group. In this case, our method is degraded to an a posteriori one, i.e., an approximation Pareto-optimal set is generated by IP-MOEA, and the value functions listed in Table <ref type="table">1</ref> are used to select the most preferred solution from the set. As a consequence, we also compared our method with the a posteriori one in this group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.1.">Constructing preference polyhedron</head><p>The number of DM calls was set to be 20 in the first group of experiments. Fig. <ref type="figure" target="#fig_8">5</ref> depicts three types of preference polyhedrons constructed at the 51st generation.</p><p>Different types of preference polyhedrons represent different directions and ranges of the search. For instance, the first type, shown as the first figure of Fig. <ref type="figure" target="#fig_8">5</ref>, shows that the upper left direction is the DM's preference direction, and the upper left part of the region formed by two dotted lines is the DM's preferred region.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.2.">Convergence of our algorithm</head><p>The number of DM calls and the value of g were set to be 20 and 8, respectively, in the second group of experiments. In Fig. <ref type="figure" target="#fig_9">6</ref>, the asterisk, the fork, the box and the diamond represent the best point of 4th, 8th, 12th and 16th DM call, respectively, the circle and the plush sigh omitted in the context of 3 objectives represent the DM's most preferred point and the Pareto front, respectively, and the dotted lines/planes are the contours of value functions in the objective space. Fig. <ref type="figure" target="#fig_9">6</ref> illustrates the course of searching for the most preferred point.</p><p>It can be clearly observed from Fig. <ref type="figure" target="#fig_9">6</ref> that:</p><p>(1) V metric of the best point increases along with the evolution of a population for all 2 and 3-objective optimization problems, indicating that the best point is more and more suitable for the DM's preferences. <ref type="bibr" target="#b1">(2)</ref> The best point converges to the most preferred point, which suggests that our algorithm is convergent and the DM can surely achieve her/his most preferred solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.3.">Influence of s on our algorithm's performance</head><p>The value of g was set to be 8 in the third group of experiments. Fig. <ref type="figure" target="#fig_10">7</ref> shows the curves of V metrics w.r.t. the number of generations for different DM calls. It can be observed from Fig. <ref type="figure" target="#fig_10">7</ref> that:</p><p>(1) For the same DM calls, V metric increases along with the evolution of a population, indicating that the obtained solution is more and more suitable for the DM's preferences. (2) For the same generation, V metric increases along with the increase of the DM calls, suggesting that the more frequent the interaction, the better the most preferred solution is. The interactive method thus clearly outperforms the a posteriori method. The above conclusion was also confirmed by Table <ref type="table" target="#tab_0">2</ref>. It can also be seen from Table <ref type="table" target="#tab_0">2</ref> that for all optimization problems, T metrics generally increase along with the decrease of the DM calls except for 5-objective DTLZ I 2.</p><p>A non-parametric test, the Wilcoxon matched-pairs signed-ranks test, was applied to V and T metrics of our method and the a posteriori method. It is a pairwise test that aims to detect a significant difference between two means of samples <ref type="bibr" target="#b9">[10]</ref>.</p><p>The means of V and T metrics obtained by our method and the a posteriori method together with p-values, which were calculated by the statistical software package SPSS V.19.0, were listed in Table <ref type="table" target="#tab_1">3</ref>, where the symbol ''⁄'' indicates that our method has no significant difference with the a posteriori method at a level of significance a = 0.1. It can be seen from Table <ref type="table" target="#tab_1">3</ref> that, V metrics obtained by our method are significantly larger than those obtained by IP-MOEA for optimization problem ZDT I 1, ZDT I 2, and DTLZ I 2, while the differences between the two methods on V metric are insignificant for optimization problems ZDT I 4, ZDT I 6, and DTLZ I 1. Similarly, CPU time of our method is significantly less than that of the a posteriori method except for DTLZ I 2 with 5 objectives, as the hyper-volume was approximately calculated in context of 5 objectives. The above numerical results coincide with the analysis in Section 4.3. This implies that compared with the a posteriori method, our method can find the DM's most preferred solutions rapidly for most benchmark optimization problems under consideration. For the 5-objective optimization problem, the most preferred solution obtained by our method is significantly superior to that obtained by the a posteriori method in terms of CPU time.</p><p>Fig. <ref type="figure">8</ref> illustrates the curves of U metrics w.r.t. the number of generations for different DM calls. When the number of DM calls is 1, since no preference polyhedrons are constructed, we take U metric as zero. The curve in this case overlaps with coordinate axis of representing the generation, so there are only two distinct curves in each figure of Fig. <ref type="figure">8</ref>. It can be observed from Fig. <ref type="figure">8</ref> that in the same generation, U metrics have no obvious relationship with the DM calls in early stage of evolution in the context of 2 objectives, more specifically, before 120th, 110th, 162nd, and 146th generation for four optimization problems, respectively. U metrics decrease along with the increase of the DM calls in later stage, especially for ZDT I 1 and ZDT I 2. This implies that for 2-objective optimization problems, the DM calls seldom affect the evolution in early stage, whereas the increase of the DM calls can make the DM's preferences clearer in later stage. The possible reason is that the number of non-dominated individuals of a population is small, and the performance of different individuals can be compared by the dominant relationship in early stage. However, the number of non-dominated individuals of the population increases along with the evolution of a population in later stage, as a result, more and more interactions are necessary to compare the individuals with the same ranks. However, in the same generation, U metrics increase along with the DM calls except for few generations in the context of 3 and 5 objectives. The possible reason is that for 3 and 5-objective optimization problems, there may be many non-dominated solutions during the whole evolution, so more DM calls are necessary.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.4.">Influence of g on our algorithm's performance</head><p>The number of DM calls was set to be 10 in the last group of experiments. Fig. <ref type="figure">9</ref> shows the curves of V metrics w.r.t. the number of generations for different values of g.</p><p>As it can be observed from Fig. <ref type="figure">9</ref>:</p><p>(1) For the same value of g, V metrics increase along with the number of generations for all optimization problems, indicating that the obtained optimal solution is more and more suitable for the DM's preferences.</p><p>(2) In the same generation, V metrics increase along with the increase of the value of g for all optimization problems, suggesting that the larger the value of g, the easier the DM finds the most preferred solution.</p><p>Fig. <ref type="figure" target="#fig_1">10</ref> shows the curves of U metrics w.r.t. the number of generations for different values of g. It is worth noting that the minimal values of g are 4 and 6 in the context of 3 and 5 objectives, respectively. We can observe from Fig. <ref type="figure" target="#fig_1">10</ref> that for 2objective optimization problems, in the same generation, U metrics decrease along with the increase of the value of g, which implies that the larger the value of g, the clearer the DM's preference is. For 3 and 5-objective optimization problems, in the same generation, U metrics as g being 8 are obviously smaller than those as g being 3, however, have no distinct differences with those as g being 6. This means that a larger value of g is necessary to make the DM's preference clearer in the context of many objectives, which will increase the DM's burden in evaluations.</p><p>Another non-parametric test, i.e., the Friedman two-way analysis of variance by ranks, was employed to analyze the results of the proposed method for different values of g over all optimization problems. It is a multi-comparison test that aims to detect a significant difference between the medians of two or more samples <ref type="bibr" target="#b9">[10]</ref>. It should be pointed out that for 5-objective DTLZ I 2, there are only two samples, so the Wilcoxon matched-pairs Signed-Ranks test was employed. Tables 4-6 display the medians of U, T and A metrics, the medians of U and T metrics, as well as the means of U and T metrics w.r.t. different values of g for 2, 3 as well as 5-objective optimization problems, respectively. P-values, calculated by  the statistical software package SPSS V.19.0, were also presented in these three tables, where the symbol ''⁄'' indicates that all methods have no significant differences at a level of significance a = 0.1. It can be observed from Tables 4-6 that:</p><p>(1) For 2-objective optimization problems, at least two of U metrics obtained by different values of g have significant differences. Combined with the medians of U metrics in Table <ref type="table" target="#tab_2">4</ref>, it can be concluded that U metrics increase along with the decrease of g. Whereas, for 3 and 5-objective optimization problems, the above tendency is insignificant except for 3-objective DTLZ I 2. This is because for many-objective optimization problems, slight differences of the values of g are insufficient to distinctly compare their influences on U metric. Nevertheless, the results indeed reveal that the larger the value of g, the smaller the U metrics are. (2) For 2-objective optimization problems except for ZDT I 4, at least two of A metrics obtained by different values of g have significant differences, suggesting that A metrics decrease along with the decrease of g for most 2-objective optimization problems. The above two conclusions further indicate that for most optimization problems, the larger the value of g, the clearer the DM's preference is. (3) For all optimization problems, some p-values on T metrics are smaller than 0.1, whereas the others are opposite, suggesting that CPU time of our method has no close relationship with the value of g. This is because a larger value of g will make the DM's preference clearer and may lead the most preferred solution to be rapidly achieved; whereas a larger value of g will result in longer time to construct the preference polyhedron. Therefore, it is difficult to reveal their relationships at present. Based on the above numerical results and analysis, we draw the following conclusions: (1) for most test problems, our method outperforms the a posteriori method, and rapidly achieves the most preferred solution more suitable for the DM's preferences; (2) if both the number of DM calls and the value of g increase, our algorithm's performances will be significantly improved, while the DM's burden in evaluations will also be increased; (3) no matter which value function is used, the numerical results are consistent, indicating the type of value function has little effect on the numerical results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions and future work</head><p>MOPs with interval parameters are ubiquitous. However, there exist few effective approaches to deal with this kind of problems due to the intrinsic complexity.</p><p>We focused on these problems and presented an interactive evolutionary approach to deal with this kind of problems. The preference polyhedron was constructed to sort the individuals, and to guide the search toward the DM's preferred region.</p><p>The key contributions of our algorithm were to construct the preference polyhedron and to sort individuals by using the above polyhedron.</p><p>As analyzed in the experiments, the increase of DM calls and the value of g can obviously improve our algorithm's performances. The DM's burden in evaluations, however, is increased. If we elicit the DM's preference information from the constructed preference polyhedron, and use it to further distinguish the solutions with both the same rank and preference, or incorporate it into genetic operators, our algorithm will be more efficient without increasing the DM's burden. Therefore, making the best of the DM's preference information is our future research topic.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>( 4 )</head><label>4</label><figDesc>Adding a new performance indicator, i.e., CPU time, to measure the efficiency of the proposed method. (5) Extending the experiments to interval MOPs with 3 and 5-objectives. (6) Conducting two non-parametric statistical tests, i.e., Wilcoxon and Friedman tests, to analyze the experimental results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Convex polyhedron generated by 2-dimensional interval vectors.</figDesc><graphic coords="5,175.75,54.71,186.92,156.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Applications of theorems.</figDesc><graphic coords="5,93.54,257.22,351.77,187.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Remark.</head><label></label><figDesc>Interval a is incomparable interval b in the sense of intervals, iff a and b have the inclusion relation, i.e., akb () a # b or b# a:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Flowchart of proposed algorithm.</figDesc><graphic coords="7,161.58,54.71,213.01,327.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>g k ; f b 1 ; . . . ; f b iÀ1 ; f b iþ1 ; . . . ; f b m . For the first case, f b 1 ; . . . ; f b iÀ1 ; f b iþ1 ; . . . ; f b m can fall into two categories: one is those whose lower limits of the objective values are smaller than that of g k in the jth objective; the other is those whose upper limits of the objective values are larger than that of g k . The hyper-plane is formed by the points corresponding to the lower limits of all objective values in the first category, those corresponding to the upper limits of all objective values in the second one, and the midpoint of g k . For the second case, the desired hyper-plane is formed by the points corresponding to the lower limits of objective values f b 1 ; . . . ; f b iÀ1 ; f b iþ1 ; . . . ; f b m . There is a hyper-plane formed by the midpoints of f b1 ; f b 2 ; . . . ; f b m , which does not contain g k . In particular, when the number of objectives is 2 or 3, the above hyper-plane is a line or a plane.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Three position locations of g k in objective space, where g 3 is g k in (a).</figDesc><graphic coords="8,185.73,54.71,178.32,416.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>) Construction of the preference polyhedron is O(mg), owing to selecting the maximal/minimal ones from the objective values. (3) Sorting based on the preference polyhedron is O(2N(m + 1)). (4) Crowding metric [23] assignment is O((2N) m ), resulting from the complexity of calculating the hyper-volume being O((2N) m ) in [1]. (5) Crowding metric sorting is O(2Nlog(2N)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Three types of preference polyhedrons.</figDesc><graphic coords="12,160.21,64.06,228.89,590.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Course of searching for most preferred point.</figDesc><graphic coords="13,53.86,54.71,430.36,536.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Curves of V metrics w.r.t. number of generations when g = 8.</figDesc><graphic coords="14,89.35,54.71,368.84,590.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 9 .Fig. 10 .</head><label>910</label><figDesc>Fig. 9. Curves of V metrics w.r.t. number of generations for 20 DM calls.</figDesc><graphic coords="17,82.21,59.36,372.03,589.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2</head><label>2</label><figDesc>Means of V and T metrics w.r.t. different DM calls.</figDesc><table><row><cell>DM calls</cell><cell>20</cell><cell>10</cell><cell>5</cell><cell>2</cell><cell>1</cell></row><row><cell>ZDT I 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>V metric</cell><cell>25.90</cell><cell>23.52</cell><cell>22.45</cell><cell>21.93</cell><cell>19.49</cell></row><row><cell>T metric</cell><cell>13.79</cell><cell>14.58</cell><cell>14.87</cell><cell>15.12</cell><cell>16.26</cell></row><row><cell>ZDT I 2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>V metric</cell><cell>26.74</cell><cell>24.61</cell><cell>23.67</cell><cell>23.54</cell><cell>20.81</cell></row><row><cell>T metric</cell><cell>16.38</cell><cell>17.09</cell><cell>17.74</cell><cell>18.17</cell><cell>19.27</cell></row><row><cell>ZDT I 4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>V metric</cell><cell>À43.94</cell><cell>À46.07</cell><cell>À48.86</cell><cell>À48.98</cell><cell>À52.92</cell></row><row><cell>T metric</cell><cell>14.31</cell><cell>13.57</cell><cell>13.71</cell><cell>15.49</cell><cell>16.82</cell></row><row><cell>ZDT I 6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>V metric</cell><cell>À6.49</cell><cell>À6.58</cell><cell>À6.61</cell><cell>À7.11</cell><cell>À7.28</cell></row><row><cell>T metric</cell><cell>15.42</cell><cell>15.79</cell><cell>16.18</cell><cell>16.46</cell><cell>18.68</cell></row><row><cell>DTLZ I 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>V metric</cell><cell>5.32</cell><cell>5.32</cell><cell>5.31</cell><cell>5.30</cell><cell>5.30</cell></row><row><cell>T metric</cell><cell>35.41</cell><cell>33.94</cell><cell>37.87</cell><cell>39.43</cell><cell>44.50</cell></row><row><cell>DTLZ I 2(3d)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>V metric</cell><cell>5.09</cell><cell>5.07</cell><cell>5.03</cell><cell>5.01</cell><cell>5.01</cell></row><row><cell>T metric</cell><cell>29.17</cell><cell>28.86</cell><cell>29.10</cell><cell>31.19</cell><cell>35.35</cell></row><row><cell>DTLZ I 2(5d)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>V metric</cell><cell>41.50</cell><cell>41.35</cell><cell>41.23</cell><cell>41.33</cell><cell>41.25</cell></row><row><cell>T metric</cell><cell>145.43</cell><cell>140.44</cell><cell>132.75</cell><cell>134.14</cell><cell>135.74</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3</head><label>3</label><figDesc>Comparison between our method and a posteriori method and p-values obtained by Wilcoxon test.</figDesc><table><row><cell></cell><cell>V metric</cell><cell></cell><cell></cell><cell>T metric</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Our method</cell><cell>a posteriori method</cell><cell>p-Value</cell><cell>Our method</cell><cell>a posteriori method</cell><cell>p-Value</cell></row><row><cell>ZDT I 1</cell><cell>25.90</cell><cell>19.49</cell><cell>.000</cell><cell>13.78</cell><cell>16.26</cell><cell>.037</cell></row><row><cell>ZDT I 2</cell><cell>26.74</cell><cell>20.81</cell><cell>.000</cell><cell>16.38</cell><cell>19.27</cell><cell>.065</cell></row><row><cell>ZDT I 4</cell><cell>À43.94</cell><cell>À52.92</cell><cell>.313 ⁄</cell><cell>14.31</cell><cell>16.82</cell><cell>.004</cell></row><row><cell>ZDT I 6</cell><cell>À6.49</cell><cell>À7.28</cell><cell>.108 ⁄</cell><cell>15.42</cell><cell>18.68</cell><cell>.002</cell></row><row><cell>DTLZ I 1</cell><cell>5.32</cell><cell>5.30</cell><cell>.204 ⁄</cell><cell>35.41</cell><cell>44.50</cell><cell>.000</cell></row><row><cell>DTLZ I 2(3d)</cell><cell>5.09</cell><cell>5.01</cell><cell>.006</cell><cell>29.17</cell><cell>35.35</cell><cell>.000</cell></row><row><cell>DTLZ I 2(5d)</cell><cell>41.50</cell><cell>41.25</cell><cell>.003</cell><cell>145.43</cell><cell>135.74</cell><cell>.000</cell></row></table><note><p>Fig. 8. Curves of U metrics w.r.t. number of generations when g = 8.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4</head><label>4</label><figDesc>Medians of U, T, and A metrics w.r.t. values of g for 2-objective optimization problems and p-values obtained by</figDesc><table><row><cell>Friedman test.</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>U metric</cell><cell>T metric</cell><cell>A metric</cell></row><row><cell>ZDT I 1</cell><cell></cell><cell></cell><cell></cell></row><row><cell>g = 3</cell><cell>25.35</cell><cell>16.3</cell><cell>19.80</cell></row><row><cell>g = 6</cell><cell>12.73</cell><cell>14.43</cell><cell>19.87</cell></row><row><cell>g = 8</cell><cell>7.47</cell><cell>12.82</cell><cell>22.88</cell></row><row><cell>p-Value</cell><cell>.000</cell><cell>.000</cell><cell>.015</cell></row><row><cell>ZDT I 2</cell><cell></cell><cell></cell><cell></cell></row><row><cell>g = 3</cell><cell>24.88</cell><cell>16.50</cell><cell>18.04</cell></row><row><cell>g = 6</cell><cell>13.40</cell><cell>16.79</cell><cell>22.29</cell></row><row><cell>g = 8</cell><cell>7.96</cell><cell>15.25</cell><cell>26.71</cell></row><row><cell>p-Value</cell><cell>.000</cell><cell>.387 ⁄</cell><cell>.004</cell></row><row><cell>ZDT I 4</cell><cell></cell><cell></cell><cell></cell></row><row><cell>g = 3</cell><cell>22.58</cell><cell>15.67</cell><cell>1.55</cell></row><row><cell>g = 6</cell><cell>14.29</cell><cell>12.75</cell><cell>2.65</cell></row><row><cell>g = 8</cell><cell>11.59</cell><cell>12.81</cell><cell>2.70</cell></row><row><cell>p-Value</cell><cell>.000</cell><cell>.000</cell><cell>.522 ⁄</cell></row><row><cell>ZDT I 6</cell><cell></cell><cell></cell><cell></cell></row><row><cell>g = 3</cell><cell>25.17</cell><cell>17.40</cell><cell>13.09</cell></row><row><cell>g = 6</cell><cell>9.89</cell><cell>14.00</cell><cell>24.18</cell></row><row><cell>g = 8</cell><cell>6.66</cell><cell>15.21</cell><cell>25.12</cell></row><row><cell>p-Value</cell><cell>.000</cell><cell>.010</cell><cell>.010</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5</head><label>5</label><figDesc>Medians of U and T metrics w.r.t. values of g for 3 -objective optimization problems and p-values obtained by Friedman test.</figDesc><table><row><cell></cell><cell>U metric</cell><cell>T metric</cell></row><row><cell>DTLZ I 1</cell><cell></cell><cell></cell></row><row><cell>g = 4</cell><cell>37.23</cell><cell>37.72</cell></row><row><cell>g = 6</cell><cell>34.84</cell><cell>35.38</cell></row><row><cell>g = 8</cell><cell>33.33</cell><cell>35.00</cell></row><row><cell>p-Value</cell><cell>.142 ⁄</cell><cell>.003</cell></row><row><cell>DTLZ I 2(3d)</cell><cell></cell><cell></cell></row><row><cell>g = 4</cell><cell>40.70</cell><cell>27.48</cell></row><row><cell>g = 6</cell><cell>32.52</cell><cell>27.98</cell></row><row><cell>g = 8</cell><cell>27.32</cell><cell>28.86</cell></row><row><cell>p-Value</cell><cell>.001</cell><cell>.000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6</head><label>6</label><figDesc>Means of U and T metrics w.r.t. values of g for 5-objective optimization problems and p-values obtained by Wilcoxon test.</figDesc><table><row><cell></cell><cell>U metric</cell><cell>T metric</cell></row><row><cell>DTLZ I 2(5d)</cell><cell></cell><cell></cell></row><row><cell>g = 6</cell><cell>35.55</cell><cell>145.43</cell></row><row><cell>g = 8</cell><cell>29.28</cell><cell>143.26</cell></row><row><cell>p-Value</cell><cell>.191 ⁄</cell><cell>.332 ⁄</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>D. Gong et al. / Information Sciences 233 (2013) 141-161</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>D. Gong et al. / Information Sciences 233 (2013) 141-161</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was jointly supported by National Natural Science Foundation of China, Grant No. 61105063, Program for New Century Excellent Talents in Universities, Grant No. NCET-07-0802, and Natural Science Foundation of HHIT, Grant No. KQ12015. Thanks to Prof. Zhonghai Ding, The University of Nevada Las Vegas, Prof. Jianyong Sun, The University of Abertay Dundee, Dr. Huanhuan Chen, The University of Birmingham, and Dr. Edward C. Mignot, Shandong University, for linguistic advice.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. The proof of Theorem 1</head><p>Proof. The discussion is divided into the following two cases:</p><p>(1) If y 2 E, i.e., y is a linear combination of g i , i = 1, 2, . . . , g, then there exist coefficients l i P 0;</p><p>from the inclusion isotonicity <ref type="bibr" target="#b23">[24]</ref>. We have F(Y) P IN F(g k ) from case (1), and F(y) P IN F(g k ) from Eq. ( <ref type="formula">4</ref>) or F(y)k F(g k ) from Eq. ( <ref type="formula">5</ref>), which completes the proof. h</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B. The proof of Theorem 2</head><p>Proof. The discussion is divided into the following two cases:</p><p>(1) If</p><p>y 00 is a linear combination of points g 1- , . . . , g kÀ1 , g k+1 , . . . , g g . Proof of Theorem 1 follows that F(y 00 ) P min i-k F(g i ). If we define l</p><p>that g k = ly 0 + (1 À l)y 00 . Because F is quasi-concave, we have F(g k ) P IN min{F(y 00 ), F(y 0 )}. The statement min i-k F(g i ) &gt; -IN F(g k ) is held from hypothesis, suggesting that F(g k ) P IN F(y 0 ). (2) If y 0 R Z, then there must exist a Y 0 2 Z, such that y 0 # Y 0 or Y 0 # y 0 . We have either F(y 0 ) # F(Y 0 ) or F(Y 0 ) # F(y 0 ) from the inclusion isotonicity, and F(g k ) P IN F(Y 0 ) from case <ref type="bibr" target="#b0">(1)</ref>. F(g k ) P IN F(y 0 ) is easily obtained from Eq. (4) or F(g k )kF(y 0 ) from Eq. ( <ref type="formula">5</ref>), which completes the proof. h</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">HypE: an algorithm for fast hypervolume-based many-objective optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="76" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Brain-computer evolutionary multiobjective optimization: a genetic algorithm adapting to the decision maker</title>
		<author>
			<persName><forename type="first">R</forename><surname>Battiti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Passerini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="671" to="687" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Multiobjective Optimization-Interactive and Evolutionary Approaches</title>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Miettinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Slowinski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Springer</publisher>
			<pubPlace>Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A stochastic programming approach to cash management in banking</title>
		<author>
			<persName><forename type="first">J</forename><surname>Catro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">192</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="963" to="974" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Convergence of multi-objective evolutionary algorithms to a uniformly distributed representation of the Pareto front</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">F</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="3336" to="3355" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wainwright</surname></persName>
		</author>
		<title level="m">Fundamental Methods of Mathematical Economics</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill College</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>fourth ed.</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A fast and elitist multiobjective genetic algorithm: NSGA-II</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pratap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mrystivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="182" to="197" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An interactive evolutionary multi-objective optimization method based on progressively approximated value functions</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wallenius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="723" to="739" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Scalable test problems for evolutionary multiobjective optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laumanns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Congress on Evolutionary Computation</title>
		<meeting>the IEEE Congress on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="825" to="830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A practical tutorial on the use of nonparametric statistical tests as a methodology for comparing evolutionary and swarm interlligence algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Derrac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Garcı ´a</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="18" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Handling uncertainty in evolutionary multiobjective optimization: SPGA</title>
		<author>
			<persName><forename type="first">H</forename><surname>Eskandari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Congress on Evolutionary Computation</title>
		<meeting>the IEEE Congress on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="4130" to="4137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Increasing selective pressure towards the best compromise in evolutionary multiobjective optimization: the extended NOSGA method</title>
		<author>
			<persName><forename type="first">E</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Coello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="56" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Short-term hydropower production planning by stochastic programming</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Fleten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Kristoffersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers and Operations Research</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2656" to="2671" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Interactive evolutionary multi-objective optimization for quasi-concave preference functions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Fowler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Gel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Koksalan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Marquis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wallenius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="417" to="425" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A study on the use of non-parametric tests for analyzing the evolutionay algorithms&apos; behaviour: a case study on the CEC&apos;2005 special session on real parameter optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Garecı ´a</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lozano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Heuristics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="617" to="644" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Evolutionary optimization algorithm for multi-objective optimization problems with interval parameters</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Fifth IEEE International Conference on Bio-Inspired Computing: Theories and Applications</title>
		<meeting>Fifth IEEE International Conference on Bio-Inspired Computing: Theories and Applications</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="411" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Evolutionary algorithms for optimization problems with uncertainties and hybrid indices</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page" from="4124" to="4138" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A fuzzy approach to hierarchical multiobjective programming problems and its application to an industrial pollution control problem</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sakawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fuzzy Sets and Systems</title>
		<imprint>
			<biblScope unit="volume">160</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="3309" to="3322" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A nonlinear interval number programming method for uncertain optimization problems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">188</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A hybrid multiobjective immune algorithm with region preference for decision makers</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Congress on Evolutionary Computation</title>
		<meeting>the IEEE Congress on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Solving the discrete multiple criteria problem using convex cones</title>
		<author>
			<persName><forename type="first">P</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wallenius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zionts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1336" to="1345" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Interactive evolutionary multiobjective optimization for hydraulic valve controller parameters</title>
		<author>
			<persName><forename type="first">J</forename><surname>Krettek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bertram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ewald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lausch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/ASME International Conference on Advanced Intelligent Mechatronics</title>
		<meeting>the IEEE/ASME International Conference on Advanced Intelligent Mechatronics</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="816" to="821" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An optimizaiton algorithm for imprecise multi-objective problem functions</title>
		<author>
			<persName><forename type="first">P</forename><surname>Limbourg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Aponte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Congress on Evolutionary Computation</title>
		<meeting>the IEEE Congress on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="459" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Kearfott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Cloud</surname></persName>
		</author>
		<title level="m">Introduction to Interval Analysis</title>
		<meeting><address><addrLine>SIAM, Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Incorporating the notion of relative importance of objectives in evolutionary multiobjective optimization</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rachmawati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="530" to="546" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Rockafellar</surname></persName>
		</author>
		<title level="m">Convex Analysis</title>
		<meeting><address><addrLine>New Jersey</addrLine></address></meeting>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The r-dominance: a new dominance relation for interactive evolutionary multicriteria decision making</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Said</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bechikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ghédira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="801" to="818" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multiple objective optimization with vector evaluated genetic algorithms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Schaffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Conference on Genetic Algorithms</title>
		<meeting>the First International Conference on Genetic Algorithms</meeting>
		<imprint>
			<date type="published" when="1985">1985</date>
			<biblScope unit="page" from="93" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An interactive evolutionary multiobjective optimization method based on polyhedral cones</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wallenius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Learning and Intelligent Optimization Conference</title>
		<meeting>Learning and Intelligent Optimization Conference</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="318" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Progressively interactive evolutionary multiobjective optimization method using generalized polynomial value functions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wallenius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Congress on Evolutionary Computation</title>
		<meeting>the IEEE Congress on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Solving interval multi-objective optimization problems using evolutionary algorithms with preference polyhedron</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Genetic and Evolutionary Computation Conference</title>
		<meeting>Genetic and Evolutionary Computation Conference</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="729" to="736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A fuzzy multiobjective linear programming</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fuzzy Sets and Systems</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="72" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Evolutionary optimization methods for hybrid index optimization problems and application</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Control and Decision</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="352" to="356" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
