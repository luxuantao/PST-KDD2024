<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-02-25">25 Feb 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Meta AI</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="laboratory">Channel GPT</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department" key="dep1">Direct MetaICL Channel MetaICL Direct GPT-J Channel GPT-J Direct</orgName>
								<orgName type="department" key="dep2">GPT-3 Channel</orgName>
								<address>
									<addrLine>fairseq 6.7B Channel fairseq 6.7B Direct fairseq 13B Channel fairseq 13B Direct</addrLine>
									<postCode>GPT-3 35 40 45 50 55 60 65 70</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xinxi</forename><surname>Lyu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
							<email>artetxe@fb.com</email>
							<affiliation key="aff1">
								<orgName type="department">Meta AI</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="laboratory">Channel GPT</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department" key="dep1">Direct MetaICL Channel MetaICL Direct GPT-J Channel GPT-J Direct</orgName>
								<orgName type="department" key="dep2">GPT-3 Channel</orgName>
								<address>
									<addrLine>fairseq 6.7B Channel fairseq 6.7B Direct fairseq 13B Channel fairseq 13B Direct</addrLine>
									<postCode>GPT-3 35 40 45 50 55 60 65 70</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
							<email>mikelewis@fb.com</email>
							<affiliation key="aff1">
								<orgName type="department">Meta AI</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="laboratory">Channel GPT</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department" key="dep1">Direct MetaICL Channel MetaICL Direct GPT-J Channel GPT-J Direct</orgName>
								<orgName type="department" key="dep2">GPT-3 Channel</orgName>
								<address>
									<addrLine>fairseq 6.7B Channel fairseq 6.7B Direct fairseq 13B Channel fairseq 13B Direct</addrLine>
									<postCode>GPT-3 35 40 45 50 55 60 65 70</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
							<email>hannaneh@cs.washington.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Allen Institute for AI</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Meta AI</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="laboratory">Channel GPT</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department" key="dep1">Direct MetaICL Channel MetaICL Direct GPT-J Channel GPT-J Direct</orgName>
								<orgName type="department" key="dep2">GPT-3 Channel</orgName>
								<address>
									<addrLine>fairseq 6.7B Channel fairseq 6.7B Direct fairseq 13B Channel fairseq 13B Direct</addrLine>
									<postCode>GPT-3 35 40 45 50 55 60 65 70</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">GPT-3 Channel</orgName>
								<address>
									<addrLine>GPT-2 Channel GPT-2 Direct MetaICL Channel MetaICL Direct GPT-J Channel GPT-J Direct fairseq 6.7B Channel fairseq 6.7B Direct fairseq 13B Channel fairseq 13B Direct</addrLine>
									<postCode>GPT-3 25 30 35 40 45 50 55 60</postCode>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-02-25">25 Feb 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2202.12837v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large language models (LMs) are able to incontext learn-perform a new task via inference alone by conditioning on a few inputlabel pairs (demonstrations) and making predictions for new inputs. However, there has been little understanding of how the model learns and which aspects of the demonstrations contribute to end task performance. In this paper, we show that ground truth demonstrations are in fact not required-randomly replacing labels in the demonstrations barely hurts performance, consistently over 12 different models including GPT-3. Instead, we find that other aspects of the demonstrations are the key drivers of end task performance, including the fact that they provide a few examples of (1) the label space, (2) the distribution of the input text, and (3) the overall format of the sequence. Together, our analysis provides a new way of understanding how and why in-context learning works, while opening up new questions about how much can be learned from large language models through inference alone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MetaICL (774M)</head><p>GPT-J (6B) GPT-3 (175B) 25 30 35 40 45 50 55 60 65 Macro-F1 (%) Classification No Demos Demos w/ gold labels Demos w/ random labels MetaICL (774M) GPT-J (6B) GPT-3 (175B) 35 40</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Large language models (LMs) have shown impressive performance on downstream tasks by simply conditioning on a few input-label pairs (demonstrations); this type of inference has been referred to as in-context learning <ref type="bibr" target="#b5">(Brown et al., 2020)</ref>. Despite incontext learning consistently outperforming zeroshot inference on a wide range of tasks <ref type="bibr" target="#b59">(Zhao et al., 2021;</ref><ref type="bibr" target="#b26">Liu et al., 2021)</ref>, there is little understanding of how it works and which aspects of the demonstrations contribute to end task performance.</p><p>In this paper, we show that ground truth demonstrations are in fact not required for effective incontext learning (Section 4). Specifically, replacing the labels in demonstrations with random labels barely hurts performance (Figure <ref type="figure">1</ref>). The result is consistent over 12 different models including the GPT-3 family <ref type="bibr" target="#b40">(Radford et al., 2019;</ref><ref type="bibr">Min et al.,</ref> Figure <ref type="figure">1</ref>: Results in classification (top) and multichoice tasks (bottom), using three LMs with varying size. Reported on six datasets on which GPT-3 is evaluated; the channel method is used. See Section 4 for the full results. In-context learning performance drops only marginally when labels in the demonstrations are replaced by random labels.</p><p>2021b; <ref type="bibr" target="#b54">Wang and Komatsuzaki, 2021;</ref><ref type="bibr">Artetxe et al., 2021;</ref><ref type="bibr" target="#b5">Brown et al., 2020)</ref>. This strongly suggests, counter-intuitively, that the model does not rely on the input-label mapping in the demonstrations to perform the task.</p><p>Further analysis investigates which parts of demonstrations actually do contribute to the performance. We identify possible aspects of demonstrations (e.g., the label space and the distribution of the input text) and evaluate a series of variants of the demonstrations to quantify the impact of each (Section 5). We find that: (1) the label space and the distribution of the input text specified by the demonstrations are both key to in-context learning (regardless of whether the labels are correct for individual inputs); (2) specifying the overall format is also crucial, e.g., when the label space is unknown, using random English words as labels is significantly better than using no labels; and (3) meta-training with an in-context learning objective <ref type="bibr">(Min et al., 2021b</ref>) magnifies these effects-the models almost exclusively exploit simpler aspects of the demonstrations like the format rather than the input-label mapping.</p><p>In summary, our analysis provides a new way of understanding the role of the demonstrations in in-context learning. We empirically show that the model (1) counter-intuitively does not rely on the ground truth input-label mapping provided in the demonstrations as much as we thought (Section 4), and (2) nonetheless still benefits from knowing the label space and the distribution of inputs specified by the demonstrations (Section 5). We also include a discussion of broader implications, e.g., what we can say about the model learning at test time, and avenues for future work (Section 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Large language models have been key to strong performance in a wide range of downstream tasks <ref type="bibr" target="#b12">(Devlin et al., 2019;</ref><ref type="bibr" target="#b40">Radford et al., 2019;</ref><ref type="bibr" target="#b27">Liu et al., 2019;</ref><ref type="bibr" target="#b41">Raffel et al., 2020;</ref><ref type="bibr" target="#b24">Lewis et al., 2020)</ref>. While finetuning has been a popular approach to transfer to new tasks <ref type="bibr" target="#b12">(Devlin et al., 2019)</ref>, it is often impractical to finetune a very large model (e.g. ?10B parameters). <ref type="bibr" target="#b5">Brown et al. (2020)</ref> propose in-context learning as an alternative way to learn a new task. As depicted in Figure <ref type="figure" target="#fig_0">2</ref>, the LM learns a new task via inference alone by conditioning on a concatenation of the training data as demonstrations, without any gradient updates.</p><p>In-context learning has been the focus of significant study since its introduction. Prior work proposes better ways of formulating the problem <ref type="bibr" target="#b59">(Zhao et al., 2021;</ref><ref type="bibr" target="#b19">Holtzman et al., 2021;</ref><ref type="bibr">Min et al., 2021a)</ref>, better ways of choosing labeled examples for the demonstrations <ref type="bibr" target="#b26">(Liu et al., 2021;</ref><ref type="bibr" target="#b29">Lu et al., 2021;</ref><ref type="bibr" target="#b44">Rubin et al., 2021)</ref>, metatraining with an explicit in-context learning objective <ref type="bibr" target="#b7">(Chen et al., 2021;</ref><ref type="bibr">Min et al., 2021b)</ref>, and learning to follow instructions as a variant of incontext learning <ref type="bibr">(Mishra et al., 2021b;</ref><ref type="bibr" target="#b15">Efrat and Levy, 2020;</ref><ref type="bibr" target="#b56">Wei et al., 2022;</ref><ref type="bibr" target="#b45">Sanh et al., 2022)</ref>. At the same time, some work reports brittleness and over-sensitivity for in-context learning <ref type="bibr" target="#b29">(Lu et al., 2021;</ref><ref type="bibr" target="#b59">Zhao et al., 2021;</ref><ref type="bibr">Mishra et al., 2021a)</ref>.</p><p>Relatively less work has been done to understand why in-context learning works. <ref type="bibr" target="#b57">Xie et al. (2022)</ref> provide theoretical analysis that in-context learning can be formalized as Bayesian inference that uses the demonstrations to recover latent concepts. <ref type="bibr" target="#b42">Razeghi et al. (2022)</ref> show that in-context learn- Model # Params Public Meta-trained</p><formula xml:id="formula_0">GPT-2 Large 774M MetaICL 774M GPT-J 6B fairseq 6.7B ? 6.7B fairseq 13B ? 13B GPT-3 175B ?</formula><p>Table <ref type="table">1</ref>: A list of LMs used in the experiments: GPT-2 <ref type="bibr" target="#b40">(Radford et al., 2019)</ref>, MetaICL <ref type="bibr">(Min et al., 2021b)</ref>, GPT-J <ref type="bibr" target="#b54">(Wang and Komatsuzaki, 2021)</ref>, fairseq LMs <ref type="bibr">(Artetxe et al., 2021)</ref> and <ref type="bibr">GPT-3 (Brown et al., 2020)</ref>. 'Public' indicates whether the model weights are public; 'Meta-trained' indicates whether the model is meta-trained with an in-context learning objective.</p><p>? We use dense models in <ref type="bibr">Artetxe et al. (2021)</ref> and refer them as fairseq LMs for convenience. ? We use the Davinci API (the base version, not the instruct version) and assume it to be 175B, following <ref type="bibr" target="#b16">Gao et al. (2021)</ref> and <ref type="bibr">Artetxe et al. (2021)</ref>.</p><p>ing performance is highly correlated with term frequencies in the pretraining data. To the best of our knowledge, this paper is the first that provides an empirical analysis that investigates why in-context learning achieves performance gains over zero-shot inference. We find that the ground truth input-label mapping in the demonstrations has only a marginal effect, and measure the impact of finer-grained aspects of the demonstrations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setup</head><p>We describe the experimental setup used in our analysis (Section 4 and 5).</p><p>Models. We experiment with 12 models in total. We include 6 language models (Table <ref type="table">1</ref>), all of which are decoder-only, dense LMs. We use each LM with two inference methods, direct and channel, following <ref type="bibr">Min et al. (2021a)</ref>. The sizes of LMs vary from 774M to 175B. We include the largest dense LM (GPT-3) and the largest publicly released dense LM (fairseq 13B) at the time of con-Figure <ref type="figure">3</ref>: Results when using no-demonstrations, demonstrations with gold labels, and demonstrations with random labels in classification (top) and multi-choice tasks (bottom). Note that the first eight models are evaluated on 16 classification and 10 multi-choice datasets, and the last four models are evaluated on 3 classification and 3 multi-choice datasets. See Figure <ref type="figure">11</ref> for numbers comparable across all models. Model performance with random labels is very close to performance with gold labels (more discussion in Section 4.1).</p><p>ducting experiments. We also include MetaICL, which is initialized from GPT-2 Large and then meta-trained on a collection of supervised datasets with an in-context learning objective, and ensure that our evaluation datasets do not overlap with those used at meta-training time.</p><p>Evaluation Data. We evaluate on 26 datasets, including sentiment analysis, paraphrase detection, natural language inference, hate speech detection, question answering, and sentence completion (full list and references provided in Appendix A). 1 We use these datasets because they (1) are true lowresource datasets with less than 10K training examples, (2) include well-studied benchmarks from GLUE <ref type="bibr" target="#b53">(Wang et al., 2018)</ref> and SuperGLUE <ref type="bibr">(Wang et al., 2019a)</ref>, and (3) cover diverse domains including science, social media, finance, and more.</p><p>The 26 datasets can be further broken down into 16 classification tasks and 10 multi-choice tasks.</p><p>Other Details. We use k = 16 examples as demonstrations by default for all experiments in the paper, unless otherwise specified. Examples are sampled at uniform from the training data. We choose a set of k training examples using 5 different random seeds and run experiments 5 times. For fairseq 13B and GPT-3, due to limited resources, we experiment with a subset of 6 datasets 2 and 3</p><p>1 For convenience, we use 'labels' to refer to the output for the task, though our datasets include non-classification tasks.</p><p>2 Three classification and three multi-choice: MRPC, RTE, Tweet_eval-hate, OpenbookQA, CommonsenseQA, COPA. random seeds. We report Macro-F1 for classification tasks and Accuracy for multi-choice tasks. We compute per-dataset average over seeds, and then report macro-average over datasets. We use the minimal templates in forming an input sequence from an example. We refer to Appendix B for more details.<ref type="foot" target="#foot_0">3</ref> 4 Ground Truth Matters Little</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Gold labels vs. random labels</head><p>To see the impact of correctly-paired inputs and labels in the demonstrations-which we call the ground truth input-label mapping-we compare the following three methods. <ref type="foot" target="#foot_1">4</ref>No demonstrations is a typical zero-shot method that does not use any labeled data. A prediction is made via argmax y?C P (y|x), where x is the test input and C is a small discrete set of possible labels.</p><p>Demonstrations w/ gold labels are used in a typical in-context learning method with k labeled examples (x 1 , y 1 )...(x k , y k ). A concatenation of k input-label pairs is used to make a prediction via argmax y?C P (y|x 1 , y 1 ...x k , y k , x).</p><p>Demonstrations w/ random labels are formed with random labels, instead of gold labels from the labeled data.</p><p>Each k) is paired with ?i that is randomly sampled at uniform from C. A concatenation of (x 1 , ?1 )...(x k , ?k ) is then used to make a prediction via argmax y?C P (y|x 1 , ?1 ...x k , ?k , x).</p><formula xml:id="formula_1">x i (1 ? i ? GPT-J (Classification) MetaICL (Multi-choice) GPT-J (Multi-</formula><p>Results are reported in Figure <ref type="figure">3</ref>. First, using the demonstrations with gold labels significantly improves the performance over no demonstrations, as it has been consistently found in much of prior work <ref type="bibr" target="#b5">(Brown et al., 2020;</ref><ref type="bibr" target="#b59">Zhao et al., 2021;</ref><ref type="bibr" target="#b26">Liu et al., 2021)</ref>. We then find that replacing gold labels with random labels only marginally hurts performance. The trend is consistent over nearly all models: models see performance drop in the range of 0-5% absolute. There is less impact in replacing labels in multi-choice tasks (1.7% on average) than in classification tasks (2.6% absolute). This result indicates that the ground truth inputlabel pairs are not necessary to achieve performance gains. This is counter-intuitive, given that correctly paired training data is critical in typical supervised training-it informs the model of the expected input-label correspondence required to perform the downstream task. Nonetheless, the models do achieve non-trivial performance on the downstream tasks. This strongly suggests that the models are capable of recovering the expected inputlabel correspondence for the task; however, it is not directly from the pairings in the demonstrations.</p><p>It is also worth noting that there is particularly little performance drop in MetaICL: 0.1-0.9% absolute. This suggests that meta-training with an explicit in-context learning objective actually encourages the model to essentially ignore the inputlabel mapping and exploit other components of the demonstrations (more discussion in Section 5.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ablations</head><p>For additional ablations, we experiment with 5 classification and 4 multi-choice datasets.<ref type="foot" target="#foot_3">5</ref>  Does the number of correct labels matter? To further examine the impact of correctness of labels in the demonstrations, we conduct an ablation study by varying the number of correct labels in the demonstrations. We evaluate "Demonstrations w/ a% correct labels" (0 ? a ? 100) which consist of k ? a/100 correct pairs and k ? (1 -a/100) incorrect pairs (see Algorithm 1 in Appendix B).</p><p>Here, a = 100 is the same as typical in-context learning, i.e., demonstrations w/ gold labels. Results are reported in Figure <ref type="figure">4</ref>. Model performance is fairly insensitive to the number of correct labels in the demonstrations. In fact, always using incorrect labels significantly outperforms nodemonstrations, e.g., preserving 92%, 100% and 97% of improvements from using the demonstrations with MetaICL in classification, MetaICL in multi-choice, and GPT-J in multi-choice, respectively. GPT-J in classification is an outlier where performance depends relatively more on the number of correct labels of the demonstrations-it achieves higher performance with a larger number of correct labels. Still, always using incorrect labels is significantly better than no demonstrations.</p><p>Is the result consistent with varying k? We study the impact of the number of input-label pairs (k) in the demonstrations. Results are reported in Figure <ref type="figure" target="#fig_1">5</ref>. First, using the demonstrations signifi-CommonsenseQA, COPA and ARC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GPT-J (Classification)</head><p>MetaICL (Multi-choice) GPT-J (Multi-choice) cantly outperforms the no demonstrations method even with small k (k = 4), and performance drop from using gold labels to using random labels is consistently small across varying k, in the range of 0.8-1.6%. 6 Interestingly, model performance does not increase much as k increases when k ? 8, both with gold labels and with random labels. This is in contrast with typical supervised training where model performance rapidly increases as k increases, especially when k is small. We hypothesize that larger labeled data is beneficial mainly for supervising the input-label correspondence, and other components of the data like the example inputs, example labels and the data format are easier to recover from the small data, which is potentially a reason for minimal performance gains from larger k (more discussion in Section 5).</p><p>Is the result consistent with better templates? While we use minimal templates by default, we also explore manual templates, i.e., templates that are manually written in a dataset-specific manner, taken from prior work (details in Appendix B). Figure <ref type="figure">6</ref> shows that the trend-replacing gold labels with random labels barely hurting performanceholds with manual templates. It is worth noting that using manual templates does not always outperform using minimal templates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Why does In-Context Learning work?</head><p>Section 4 shows that the ground truth input-label mapping in the demonstrations has little impact to performance gains from in-context learning. This section further examines what other aspects of the demonstrations lead to good performance of incontext learning.</p><p>We identify four aspects of the demonstrations (x 1 , y 1 )...(x k , y k ) that potentially provide learning signal (depicted in Figure <ref type="figure">7</ref>). 6 With an exception of 4.4% in classification with k = 4, likely due to a high variance with a very small value of k.</p><p>Circulation revenue has increased by 5% in Finland.</p><p>\n Positive</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Format (The use of pairs)</head><p>=</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Distribution of inputs Label space Demonstrations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Test example</head><p>Input-label mapping</p><p>Panostaja did not disclose the purchase price. \n Neutral</p><p>Paying off the national debt will be extremely painful. \n Negative</p><p>The acquisition will have an immediate positive impact. \n ?</p><p>Figure <ref type="figure">7</ref>: Four different aspects in the demonstrations: the input-label mapping, the distribution of the input text, the label space, and the use of input-label pairing as the format of the demonstrations.</p><p>1. The input-label mapping, i.e., whether each input x i is paired with a correct label y i .</p><p>2. The distribution of the input text, i.e., the underlying distribution that x 1 ...x k are from.</p><p>3. The label space, i.e., the space covered by y 1 ...y k .</p><p>4. The format-specifically, the use of inputlabel pairing as the format.<ref type="foot" target="#foot_4">7</ref> </p><p>As we did in Section 4 for the input-label mapping, we design a series of variants of the demonstrations that quantify the impact of each aspect in isolation (Section 5.1-5.3). We then additionally discuss the trend of the models meta-trained with an in-context learning objective (Section 5.4). For all experiments, models are evaluated on five classification and four multi-choice datasets as in Section 4.2. Implementation details are reported in Appendix B; Table 4 in the Appendix provides example demonstrations for each variant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Impact of the distribution of the input text</head><p>We experiment with OOD demonstrations which include out-of-distribution (OOD) text instead of Accuracy (%) the inputs from unlabeled training data. Specifically, a set of k sentences {x i,rand } k i=1 are randomly sampled from an external corpus, and replace x 1 ...x k in the demonstrations. This variant assesses the impact of the distribution of the input text, while keeping the label space and the format of the demonstrations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-choice</head><p>Results. Figure <ref type="figure">8</ref> shows that using out-ofdistribution inputs instead of the inputs from the training data significantly drops the performance when Channel MetaICL, Direct GPT-J or Channel GPT-J are used, both in classification and multichoice, by 3-16% in absolute. In the case of Direct GPT-J in multi-choice, it is even significantly worse than no demonstrations. Direct MetaICL is an exception, which we think is the effect of meta-training (discussion in Section 5.4).</p><p>This suggests that in-distribution inputs in the demonstrations substantially contribute to performance gains. This is likely because conditioning on the in-distribution text makes the task closer to lan-guage modeling, since the LM always conditioned on the in-distribution text during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Impact of the label space</head><p>We also experiment with demonstrations w/ random English words that use random English words as labels for all k pairs. Specifically, we sample a random subset of English words C rand where |C rand | = |C|, and randomly pair ?i ? C rand with x i . This variant assesses the impact of the label space, while keeping the distribution of the input text and the format of the demonstrations.</p><p>Results. Based on Figure <ref type="figure" target="#fig_2">9</ref>, direct models and channel models exhibit different patterns. With direct models, the performance gap between using random labels within the label space and using random English words is significant, ranging between 5-16% absolute. This indicates that conditioning on the label space significantly contributes to performance gains. This is true even for multi-choice tasks where there is no fixed set of labels-we  Variants of demonstrations without keeping the format ( and ) are overall not better than no demonstrations ( ). Keeping the format is especially significant when it is possible to achieve substantial gains with the label space but without the inputs ( vs. in Direct MetaICL), or with the input distribution but without the labels ( vs. in Channel MetaICL and Channel GPT-J). More discussion in Section 5.3.</p><p>hypothesize that multi-choice tasks still do have a particular distribution of the choices (e.g., objects like "Bolts" or "Screws" in the OpenBookQA dataset) that the model uses.</p><p>On the other hand, removing the output space does not lead to significant drop in the channel models: there is 0-2% drop in absolute, or sometimes even an increase. We hypothesize that this is because the channel models only condition on the labels, and thus are not benefiting from knowing the label space. This is in contrast to direct models which must generate the correct labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Impact of the use of input-label pairing</head><p>Section 5.1 and 5.2 focus on variants which keep the format of the demonstrations as much as possible. In this section, we explore a series of variants that change the format, e.g., keep the input text only without labels, or keep the labels only without inputs. Specifically, we evaluate (1) demonstrations with no labels where the LM is conditioned on the concatenation of x 1 ...x k , and (2) demonstrations with labels only where the LM is conditioned on the concatenation of y 1 ...y k .</p><p>Results. Based on Figure <ref type="figure" target="#fig_3">10</ref>, removing the format is not substantially better than no demonstrations (even worse in some cases), indicating the importance of the format. This is likely because conditioning on a sequence of input-label pairs triggers the model to mimic the overall format and complete the new example as expected, when the test input is given.</p><p>More interestingly, keeping the format plays a significant role in retaining a large portion of perfor-mance gains by only using the inputs or only using the labels. For instance, with Direct MetaICL, it is possible to retain 95% and 82% of improvements from in-context learning (demonstrations with gold labels) by simply sampling random sentences from a corpus and randomly pairing them with the label set ( in Figure <ref type="figure" target="#fig_3">10</ref>) in classification and multichoice, respectively. Similarly, with the channel models, it is possible to retain 82%, 87%, 86% and 75% of improvements from in-context learning by simply pairing each input from the unlabeled training data with a random English word ( in Figure <ref type="figure" target="#fig_3">10</ref>) in MetaICL classification, GPT-J classification, MetaICL multi-choice and GPT-J multichoice, respectively. For all of these cases, removing inputs instead of using OOD inputs, or removing labels instead of using random English words is significantly worse, indicating that keeping the format of the input-label pairs is the key.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Impact of meta-training</head><p>Different from other models, MetaICL is trained with an in-context learning objective, in line with recent work that uses multi-task training on a large collection of supervised datasets (called metatraining) for generalization to new tasks <ref type="bibr" target="#b0">(Aghajanyan et al., 2021;</ref><ref type="bibr" target="#b20">Khashabi et al., 2020;</ref><ref type="bibr" target="#b56">Wei et al., 2022;</ref><ref type="bibr" target="#b45">Sanh et al., 2022)</ref>. We aim to better understand the role of this meta-training in relation with our findings by closely examining the result of MetaICL. In particular, we observe that the patterns we see so far are even more evident with MetaICL than with other models. For instance, the ground truth input-label mapping matters even less, and keeping the format of the demonstrations matters even more. There is nearly zero influence of the input-label mapping and the input distribution in Direct MetaICL, and the input-label mapping and the output space in Channel MetaICL.</p><p>Based on this observation, we hypothesize that meta-training encourages the model to exclusively exploit simpler aspects of the demonstrations and to ignore others. This is based on our intuition that (1) the input-label mapping is likely harder to exploit, (2) the format is likely easier to exploit, and (3) the space of the text that the model is trained to generate is likely easier to exploit than the space of the text that the model conditions on.<ref type="foot" target="#foot_5">8</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion &amp; Conclusion</head><p>In this paper, we study the role of the demonstrations with respect to the success of in-context learning. We find that the ground truth input-label mapping in the demonstrations matters significantly less than one might think-replacing gold labels with random labels in the demonstrations only marginally lowers the performance. We then identify a series of aspects in the demonstrations and examine which aspect actually contributes to performance gains. Results reveal that (1) gains are mainly coming from independent specification of the input space and the label space, (2) the models can still retain up to 95% of performance gains by using either the inputs only or the label set only if the right format is used, and (3) meta-training with an in-context learning objective magnifies these trends. Together, our findings lead to a set of broader indications about in-context learning, as well as avenues for future work.</p><p>Does the model learn at test time? If we take a strict definition of learning: capturing the inputlabel correspondence given in the training data, then our findings suggest that LMs do not learn new tasks at test time. Our experiments in Section 4.2 show that when the task is defined by the demonstrations to predict 'negative' to a positive review and 'positive' to a negative review, the model still predicts 'positive' and 'negative' to positive and negative reviews, respectively.</p><p>However, learning a new task can be interpreted more broadly: it may include adapting to specific input and label distributions and the format sug-gested by the demonstrations, and ultimately getting to make a prediction more accurately. With this definition of learning, the model does learn the task from the demonstrations. Our experiments indicate that the model does make use of aspects of the demonstrations and achieve performance gains.</p><p>Capacity of LMs. Our findings indicate that the model does well on a downstream task without relying on the input-label correspondence from the demonstrations. This suggests that the model has learned the (implicit notion of) input-label correspondence from the language modeling objective alone, e.g., associating a positive review with the word 'positive'. This is in line with <ref type="bibr" target="#b43">Reynolds and McDonell (2021)</ref> who claim that the demonstrations are for task location and the intrinsic ability to perform the task is obtained at pretraining time. <ref type="foot" target="#foot_6">9</ref>On one hand, this suggests that the language modeling objective has led to great zero-shot capacity, even if it is not always evident from the naive zero-shot accuracy. On the other hand, this suggests that in-context learning is unlikely to work on a task whose input-label correspondence is not already captured in the LM, e.g., when the task semantics are not close enough to language modeling. This leads to the research question of how to make progress in NLP problems that in-context learning does not solve: whether we need a better way of extracting the input-label mappings that are already stored in the LM, a better variant of the LM objective that learns a wider range of task semantics, or explicit supervision through fine-tuning on the labeled data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Connection to instruction-following models.</head><p>Prior work has found it promising to train the model that reads the natural language description of the task (called instructions) and performs a new task at inference <ref type="bibr">(Mishra et al., 2021b;</ref><ref type="bibr" target="#b15">Efrat and Levy, 2020;</ref><ref type="bibr" target="#b56">Wei et al., 2022;</ref><ref type="bibr" target="#b45">Sanh et al., 2022)</ref>. We think the demonstrations and instructions largely have the same role to LMs, and hypothesize that our findings hold for instruction-following models: the instructions prompt the model to recover the capacity it already has, but do not supervise the model to learn novel task semantics. We leave analysis on instruction-following models for future work.</p><p>Significantly improved zero-shot performance. One of our key findings is that it is possible to achieve nearly k-shot performance without using any labeled data, by simply pairing each unlabeled input with a random label and using it as the demonstrations. This means our zero-shot baseline level is significantly higher than previously thought. 10  Gains from the demonstrations with random labels over the previous zero-shot method (no demonstrations) are up to 20% absolute in classification and up to 15% absolute in multi-choice tasks. Future work can further improve the zero-shot performance with relaxed assumptions in access to the unlabeled training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Experimental Details</head><p>Example template We follow <ref type="bibr" target="#b58">Ye et al. (2021)</ref>; <ref type="bibr">Min et al. (2021b);</ref><ref type="bibr" target="#b28">Logan IV et al. (2021)</ref> in using the minimal format to transform the input to a sequence (e.g. a concatenation of multiple inputs) and using the label words from each dataset as it is. We also explore manual templates taken from prior work <ref type="bibr" target="#b19">(Holtzman et al., 2021;</ref><ref type="bibr" target="#b59">Zhao et al., 2021)</ref> as reported in Section 4.2, although we find that using these templates is not consistently better than using minimal templates. We thus run main experiments with minimal templates. Example templates are provided in Table <ref type="table" target="#tab_7">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Format of the demonstrations</head><p>We follow the standard of each model for formatting the demonstrations, either from exploration in prior work or the example code provided in the official tutorial. For GPT-2, we separate the input and the label,  and each demonstration example with a space. For MetaICL, GPT-J and GPT-3, we separate the input and the label with a newline (\n), and each demonstration example with three newlines. For fairseq models, we use a newline to separate the input and the label as well as each demonstration example.</p><p>Details in variants of the demonstrations For "demonstrations w/ a% accurate labels" (0 ? a ? 100), we use k ? a/100 correct pairs and k ? (1 -a/100) incorrect pairs in a random order, as described in Algorithm 1. For "OOD demonstrations", we use CC-News <ref type="bibr" target="#b39">(Nagel, 2016)</ref> as an external corpus. We consider the length of the text during sampling, so that sampled sentences have similar length to the test input. For "demonstrations with random English words", we use pypi.org/ project/english-words for the set of En- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C More Experimental Results</head><p>C.1 Gold labels vs. random labels Figure <ref type="figure">11</ref> shares the same interface as Figure <ref type="figure">3</ref>, but all models are evaluated on 3 classification and 3 multi-choice datasets and are thus comparable to each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 More variants of the demonstrations</head><p>We explored demonstrations with a constant label where all labels in the demonstrations are replaced with a constant text, "answer". Specifically, a prediction is made via argmax y?C P (y|x 1 , answer...x k , answer, x). This can be viewed as another way to remove the impact of the label space while keeping the impact of the distribution of the input text. However, results are consistently worse than the results of demonstrations with random English labels.</p><p>We think this is because constant labels actually change the format of the demonstrations, since they can be viewed as part of a separator between different demonstration examples.</p><p>We also explored demonstrations with the test input where all inputs in the demonstrations are replaced with the test input, each paired with a random label. Specifically, a prediction is made via argmax y?C P (y|x, ?1 ...x, ?k , x), where ?i (1 ? i ? k) is randomly sampled at uniform from C. This variant is seemingly a reasonable choice given that it satisfies the condition that the inputs in the demonstrations come from the same distribution as the test input (since they are identical), and using random labels is as good as using gold labels. Nonetheless, we find that this variant is significantly worse than most other methods with demonstrations. We think this is because using the constant input for all demonstration example significantly changes the format of the sequence, since the input can be viewed as part of a separator between different demonstration examples. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An overview of in-context learning. The demonstrations consist of k input-label pairs from the training data (k = 3 in the figure).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Ablations on varying numbers of examples in the demonstrations (k). Models that are the best under 13B in each task category (Channel MetaICL and Direct GPT-J, respectively) are used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 9 :</head><label>9</label><figDesc>Figure9: Impact of the label space. Evaluated in classification (top) and multi-choice (bottom). The impact of the label space can be measured by comparing and . The gap is significant in the direct models but not in the channel models (discussion in Section 5.2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 10 :</head><label>10</label><figDesc>Figure10: Impact of the format, i.e., the use of the input-label pairs. Evaluated in classification (top) and multichoice (bottom). Variants of demonstrations without keeping the format ( and ) are overall not better than no demonstrations ( ). Keeping the format is especially significant when it is possible to achieve substantial gains with the label space but without the inputs ( vs. in Direct MetaICL), or with the input distribution but without the labels ( vs. in Channel MetaICL and Channel GPT-J). More discussion in Section 5.3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Results with varying number of correct labels in the demonstrations. Channel and Direct used for classification and multi-choice, respectively. Performance with no demonstrations (blue) is reported as a reference.</figDesc><table><row><cell>25 30 35 40 45 50 55 60 65 Accuracy (%)</cell><cell>100% correct</cell><cell>75% correct</cell><cell>50% correct</cell><cell>25% correct</cell><cell>0% correct</cell><cell>No Demos</cell><cell>choice)</cell></row><row><cell>Figure 4:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Figure 6: Results with minimal templates and manual templates. '+T' indicates that manual templates are used. Channel and Direct used for classification and multi-choice, respectively.</figDesc><table><row><cell>25 30 35 40 45 50 55 60 65 Accuracy (%)</cell><cell>No demos</cell><cell>Gold labels</cell><cell>Random labels</cell><cell>No demos + T</cell><cell>Gold labels + T</cell><cell>Random labels + T</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Impact of the distribution of the inputs. Evaluated in classification (top) and multi-choice (bottom). The impact of the distribution of the input text can be measured by comparing and . The gap is substantial, with an exception in Direct MetaICL (discussion in Section 5.1).</figDesc><table><row><cell>25 30 35 40 45 50 Accuracy (%) 55 60 25 30 35 40 45 50 60 55 Macro-F1 (%)</cell><cell>Direct MetaICL Direct MetaICL</cell><cell cols="2">Channel MetaICL Channel MetaICL Multi-choice Direct GPT-J Direct GPT-J Classification</cell><cell>Channel GPT-J Channel GPT-J</cell><cell>I: Input distribution M: Input-Label Mapping L: Label space F: Format No demonstrations OOD + Random labels Gold labels Random labels</cell><cell>F</cell><cell>L</cell><cell>I</cell><cell>M</cell></row><row><cell cols="2">Figure 8: Direct MetaICL 25 30 35 40 45 50 Macro-F1 (%) 55 60</cell><cell cols="2">Channel MetaICL Classification Direct GPT-J</cell><cell>Channel GPT-J</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>25 30 35 40 45 50 55 60</cell><cell>Direct MetaICL</cell><cell>Channel MetaICL</cell><cell>Direct GPT-J</cell><cell>Channel GPT-J</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>26 datasets used for experiments, classified into 6 task categories. # Train and # Test indicate the number of training and test examples of the dataset. Note that # train is based on the original training dataset but we use k random samples for k-shot evaluation.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Figure 11: Results of No-demonstration, Gold demonstration and Random demonstration on 3 classification datasets (top) and 3 multi-choice datasets (bottom). Details in Section 4.1. This figure is for providing numbers that are comparable across models-full results with more datasets are reported in Figure 3.</figDesc><table><row><cell>55 60</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>No Demos</cell><cell cols="2">Classification Demos w/ gold labels</cell><cell cols="3">Demos w/ random labels</cell><cell></cell><cell></cell></row><row><cell>35 40 45 50 Macro-F1 (%)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>30</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>25 65 70</cell><cell>Direct GPT-2</cell><cell>Channel GPT-2</cell><cell>Direct MetaICL</cell><cell>Channel MetaICL</cell><cell>Direct GPT-J No Demos</cell><cell cols="5">Channel GPT-J Multi-choice Direct fairseq 6.7B Demos w/ gold labels Demos w/ random labels Channel fairseq 6.7B fairseq 13B Direct</cell><cell>Channel fairseq 13B</cell><cell>Direct GPT-3</cell><cell>Channel GPT-3</cell></row><row><cell>45 50 55 60 Accuracy (%)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>40</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>35</cell><cell>Direct GPT-2</cell><cell>Channel GPT-2</cell><cell>Direct MetaICL</cell><cell>Channel MetaICL</cell><cell>Direct GPT-J</cell><cell>Channel GPT-J</cell><cell cols="2">Direct fairseq 6.7B</cell><cell>Channel fairseq 6.7B</cell><cell>Direct fairseq 13B</cell><cell>Channel fairseq 13B</cell><cell>Direct GPT-3</cell><cell>GPT-3 Channel</cell></row><row><cell cols="7">Algorithm 1 Forming the demonstrations with an</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">accuracy of a%.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">1: procedure FORMDEMONS({(xi, yi)} k i=1 , a)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2:</cell><cell cols="5">D ? [] // demonstration to be formed</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>3:</cell><cell cols="5">n ? k ? a/100 // number of correct pairs</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>4:</cell><cell cols="4">G ? Sample(Range(1, k), n)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>5:</cell><cell cols="3">for i ? Range(1, k) do</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>6:</cell><cell cols="5">if i ? G then // add correct pair</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>7:</cell><cell cols="3">D.append((xi, yi))</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>8:</cell><cell cols="3">else // add incorrect pair</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>9:</cell><cell cols="5">D.append((xi, Sample(C -yi)))</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>10:</cell><cell>return D</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">glish words, which consists of 61,569 words.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">Table 4 provides a list of example demonstra-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">tions for each method used in Section 5.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>Cisco pared spending to compensate for sluggish sales . [SEP] sentence 2: In response to sluggish sales , Cisco pared spending . \n {equivalent|not_equivalent} Manual Cisco pared spending to compensate for sluggish sales . \n The question is: In response to sluggish sales , Cisco pared spending . True or False? \n The answer is:{True|False} RTE Minimal sentence 1: The girl was found in Drummondville. [SEP] sentence 2: Drummondville contains the girl. \n {entailment|not_entailment} Manual The girl was found in Drummondville. \n The question is: Drummondville contains the girl. True or False? \n The answer is:{True|False} Tweet_eval-hate Minimal The Truth about #Immigration \n {hate|non-hate} Manual Tweet: The Truth about #Immigration \n Sentiment: {against|favor} SICK Minimal sentence 1: A man is screaming. [SEP] sentence 2: A man is scared. \n {contradiction|entailment|neutral} Manual A man is screaming. \n The question is: A man is scared. True or False? \n The answer is: {False|True|Not sure} poem-sentiment Minimal willis sneered: \n {negative|no_impact|positive} Manual willis sneered: \n The sentiment is: {negative|no_impact|positive} OpenbookQA Minimal What creates a valley? \n {feet|rock|water|sand} Manual The question is: What creates a valley? \n The answer is: {feet|rock|water|sand} CommonsenseQA Minimal What blocks sunshine? \n {summer|park|desktop|sea|moon} Manual The question is: What blocks sunshine? \n The answer is: {summer|park|desktop|sea|moon} COPA Minimal Effect: I coughed. \n {Cause: I inhaled smoke.|Cause: I lowered my voice.} Manual I coughed because {I inhaled smoke.|I lowered my voice.} ARC Minimal Which biome has the most vegetation? \n {desert|forest|grassland|tundra} Manual The question is: Which biome has the most vegetation? \n The answer is: {desert|forest| grassland|tundra} A list of minimal templates taken from Ye et al. (2021); Min et al. (2021b) and manual templates taken from Holtzman et al. (2021); Zhao et al. (2021). Details provided in Appendix B. See Figure 6 for discussion in empirical results. The input and the label are in the red text and in the blue text, respectively. Note that | is used to separate different options for the labels. Input distribution Label space Input-label mapping ) Circulation revenue has increased by 5% in Finland and 4% in Sweden in 2008. \n positive Panostaja did not disclose the purchase price. \n neutral Demos w/ random labels (Format Input distribution Label space Input-label mapping ) Circulation revenue has increased by 5% in Finland and 4% in Sweden in 2008. \n neutral Panostaja did not disclose the purchase price. \n negative OOD Demos w/ random labels (Format Input distribution Label space Input-label mapping ) Colour-printed lithograph. Very good condition. Image size: 15 x 23 1/2 inches. \n neutral Many accompanying marketing claims of cannabis products are often well-meaning. \n negative Demos w/ random English words (Format Input distribution Label space Input-label mapping ) Circulation revenue has increased by 5% in Finland and 4% in Sweden in 2008. \n unanimity Panostaja did not disclose the purchase price. \n wave Demos w/o labels (Format Input distribution Label space Input-label mapping ) Circulation revenue has increased by 5% in Finland and 4% in Sweden in 2008. Panostaja did not disclose the purchase price.</figDesc><table><row><cell>Dataset</cell><cell>Type</cell><cell>Example</cell></row><row><cell>MRPC</cell><cell>Minimal</cell><cell>sentence 1:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>Example demonstrations when using methods in Section 5. The financial_phrasebank dataset with C = {"positive", "neutral", "negative"} is used. Red text indicates the text is sampled from an external corpus; blue text indicates the labels are randomly sampled from the label set; purple text indicates a random English word.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>All experiments are reproducible from github.com/ Alrope123/rethinking-demonstrations.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>Without loss of generality, all methods in Section 4 and</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2"><p>are described based on the direct method, but can be trivially converted to the channel method by flipping x and y.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>Classification includes: MRPC, RTE, Tweet_eval-hate, SICK, poem-sentiment; Multi-choice includes OpenbookQA,</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4"><p>There are many aspects of the format, such as the separation between the input and the output, or different arrangements of the demonstrations. We only focus on the aspect of using of input-label pairing (instead of using inputs only or outputs only) and leave other aspects as future work.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5"><p>That is, the direct model exploits the label space better than the input distribution, and the channel model exploits the input distribution better than the label space.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_6"><p>However, while<ref type="bibr" target="#b43">Reynolds and McDonell (2021)</ref> claims that the demonstrations are thus unnecessary, we think using the demonstrations is actually the most unambiguous and the easiest way to prompt the model to perform a task.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We thank <rs type="person">Gabriel Ilharco</rs>, <rs type="person">Julian Michael</rs> and <rs type="person">Ofir Press</rs> for their comments in the paper.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Armen</forename><surname>Aghajanyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anchit</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akshat</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xilun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sonal</forename><surname>Gupta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.11038</idno>
		<title level="m">Muppet: Massive multi-task representations with pre-finetuning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Bhosale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Victoria Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinivasan</forename><surname>Iyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.10684</idno>
		<title level="m">Ramakanth Pasunuru, et al. 2021. Efficient large scale language modeling with mixtures of experts</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The second pascal recognising textual entailment challenge</title>
		<author>
			<persName><forename type="first">Roy</forename><surname>Bar-Haim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Giampiccolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Idan</forename><surname>Szpektor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the second PASCAL challenges workshop on recognising textual entailment</title>
		<meeting>the second PASCAL challenges workshop on recognising textual entailment</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">TweetEval: Unified benchmark and comparative evaluation for tweet classification</title>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Barbieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jose</forename><surname>Camacho-Collados</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Espinosa Anke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonardo</forename><surname>Neves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of EMNLP</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The fifth pascal recognizing textual entailment challenge</title>
		<author>
			<persName><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Giampiccolo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>In TAC</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">10 We take the perspective that using the unlabeled training data is permitted, following prior work</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<editor>
			<persName><forename type="first">Clemens</forename><surname>Winter</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Chris</forename><surname>Hesse</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Eric</forename><surname>Sigler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mateusz</forename><surname>Litwin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</editor>
		<meeting><address><addrLine>Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish</addrLine></address></meeting>
		<imprint>
			<publisher>Kodirov et al</publisher>
			<date type="published" when="2015">2015. 2019. 2021. 2020</date>
		</imprint>
	</monogr>
	<note>Language models are few-shot learners</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">CODAH: An adversarially-authored question answering dataset for common sense</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike D'</forename><surname>Arcy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alisa</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Downey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for NLP</title>
		<meeting>the 3rd Workshop on Evaluating Vector Space Representations for NLP</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Yanda</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiqi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">He</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.07814</idno>
		<title level="m">Meta-learning via language model in-context tuning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Think you have solved question answering? try arc, the ai2 reasoning challenge</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isaac</forename><surname>Cowhey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carissa</forename><surname>Schoenick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>ArXiv</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The pascal recognising textual entailment challenge</title>
		<author>
			<persName><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Glickman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning Challenges Workshop</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Hate Speech Dataset from a White Supremacy Forum</title>
		<author>
			<persName><forename type="first">Ona</forename><surname>De Gibert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naiara</forename><surname>Perez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Abusive Language Online</title>
		<meeting>the 2nd Workshop on Abusive Language Online</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Aitor Garc?a-Pablos, and Montse Cuadros</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandy</forename><surname>Simons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judith</forename><surname>Tonhauser</surname></persName>
		</author>
		<title level="m">The commitmentbank: Investigating projection in naturally occurring discourse. Proceedings of Sinn und Bedeutung</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Climate-fever: A dataset for verification of real-world climate claims</title>
		<author>
			<persName><forename type="first">T</forename><surname>Diggelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><forename type="middle">L</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jannis</forename><surname>Bulian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimiliano</forename><surname>Ciaramita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Leippold</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>ArXiv</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automatically constructing a corpus of sentential paraphrases</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Workshop on Paraphrasing</title>
		<meeting>the Third International Workshop on Paraphrasing</meeting>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Avia</forename><surname>Efrat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11982</idno>
		<title level="m">The turking test: Can language models understand instructions? arXiv preprint</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Golding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hoppe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Phang</surname></persName>
		</author>
		<author>
			<persName><surname>He</surname></persName>
		</author>
		<author>
			<persName><surname>Thite</surname></persName>
		</author>
		<author>
			<persName><surname>Nabeshima</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00027</idno>
		<title level="m">The pile: an 800gb dataset of diverse text for language modeling 2020</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The third pascal recognizing textual entailment challenge</title>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Giampiccolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-PASCAL workshop on textual entailment and paraphrasing</title>
		<meeting>the ACL-PASCAL workshop on textual entailment and paraphrasing</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">SemEval-2012 task 7: Choice of plausible alternatives: An evaluation of commonsense causal reasoning</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melissa</forename><surname>Roemmele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The First Joint Conference on Lexical and Computational Semantics</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>Se-mEval</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Surface form competition: Why the highest probability answer isn&apos;t always right</title>
		<author>
			<persName><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vered</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">UnifiedQA: Crossing format boundaries with a single qa system</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of EMNLP</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Qasc: A dataset for question answering via sentence composition</title>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michal</forename><surname>Guerquin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation zero-shot learning</title>
		<author>
			<persName><forename type="first">Elyor</forename><surname>Kodirov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenyong</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaogang</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The winograd schema challenge</title>
		<author>
			<persName><forename type="first">Hector</forename><forename type="middle">J</forename><surname>Levesque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ernest</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leora</forename><surname>Morgenstern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth International Conference on Principles of Knowledge Representation and Reasoning</title>
		<meeting>the Thirteenth International Conference on Principles of Knowledge Representation and Reasoning</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">BART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal ; Abdelrahman Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ves</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020">Marjan Ghazvininejad,. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Datasets: A community library for natural language processing</title>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Villanova Del Moral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suraj</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariama</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lewis</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Tunstall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gunjan</forename><surname>?a?ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhavitvya</forename><surname>Chhablani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><surname>Brandeis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Teven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angelina</forename><surname>Patry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Mcmillan-Major</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cl?ment</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Th?o</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Matussi?re</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stas</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Bekman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibault</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Goehringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fran?ois</forename><surname>Mustar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Lagunas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP: System Demonstrations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">Jiachang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dinghan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Carin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.06804</idno>
		<title level="m">What makes good in-context examples for gpt-3? arXiv preprint</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Cutting down on prompts and parameters: Simple few-shot learning with language models</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename><surname>Robert L Logan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivana</forename><surname>Bala?evic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.13353</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity</title>
		<author>
			<persName><forename type="first">Yao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Bartolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alastair</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08786</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Good debt or bad debt: Detecting semantic orientations in economic texts</title>
		<author>
			<persName><forename type="first">Pekka</forename><surname>Malo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pekka</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jyrki</forename><surname>Wallenius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pyry</forename><surname>Takala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Assoc. Inf. Sci. Technol</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A SICK cure for the evaluation of compositional distributional semantic models</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Marelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Menini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raffaella</forename><surname>Bernardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Zamparelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Effective transfer learning for identifying similar questions: Matching user questions to covid-19 faqs</title>
		<author>
			<persName><forename type="first">Clara</forename><forename type="middle">H</forename><surname>Mccreery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Namit</forename><surname>Katariya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anitha</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manish</forename><surname>Chablani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Amatriain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Can a suit of armor conduct electricity? a new dataset for open book question answering</title>
		<author>
			<persName><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">2021a. Noisy channel language model prompting for few-shot text classification</title>
		<author>
			<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.04106</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<title level="m">MetaICL: Learning to learn in context</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">2021a. Reframing instructional prompts to gptk&apos;s language</title>
		<author>
			<persName><forename type="first">Swaroop</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chitta</forename><surname>Baral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.07830</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Chitta Baral, and Hannaneh Hajishirzi. 2021b. Cross-task generalization via natural language crowdsourcing instructions</title>
		<author>
			<persName><forename type="first">Swaroop</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08773</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Ethos: an online hate speech detection dataset</title>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Mollas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zoe</forename><surname>Chrysopoulou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stamatis</forename><surname>Karlos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grigorios</forename><surname>Tsoumakas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>ArXiv</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Nagel</surname></persName>
		</author>
		<ptr target="http://web.archive.org/save/http://commoncrawl.org/2016/10/news-dataset-available" />
		<title level="m">CC-News</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>OpenAI blog</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Impact of pretraining term frequencies on few-shot reasoning</title>
		<author>
			<persName><forename type="first">Yasaman</forename><surname>Razeghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename><surname>Robert L Logan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.07206</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Prompt programming for large language models: Beyond the few-shot paradigm</title>
		<author>
			<persName><forename type="first">Laria</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Mcdonell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">Ohad</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.08633</idno>
		<title level="m">Learning to retrieve prompts for in-context learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Multitask prompted training enables zero-shot task generalization</title>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">H</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lintang</forename><surname>Sutawika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zaid</forename><surname>Alyafeai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Chaffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Stiegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><surname>Raja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manan</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saiful Bari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urmish</forename><surname>Thakker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanya</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eliza</forename><surname>Szczechla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taewoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gunjan</forename><surname>Chhablani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nihal</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debajyoti</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Tian-Jian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matteo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Manica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng Xin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harshit</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Bawden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<editor>
			<persName><forename type="first">Trishala</forename><surname>Neeraj</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jos</forename><surname>Rozen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Abheesht</forename><surname>Sharma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Andrea</forename><surname>Santilli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thibault</forename><surname>Fevry</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jason</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">Alan</forename><surname>Fries</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ryan</forename><surname>Teehan</surname></persName>
		</editor>
		<meeting><address><addrLine>Stella Biderman, Leo Gao, Tali Bers, Thomas Wolf</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">It&apos;s not just size that matters: Small language models are also few-shot learners</title>
		<author>
			<persName><forename type="first">Timo</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Sch?tze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Investigating societal biases in a poetry composition system</title>
		<author>
			<persName><forename type="first">Emily</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Uthus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Gender Bias in Natural Language Processing</title>
		<meeting>the Second Workshop on Gender Bias in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">DREAM: A challenge data set and models for dialogue-based reading comprehension</title>
		<author>
			<persName><forename type="first">Kai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianshu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>TACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Quarel: A dataset and models for answering questions about qualitative relationships</title>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">QuaRTz: An open-domain dataset of qualitative relationship questions</title>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Commonsenseqa: A question answering challenge targeting commonsense knowledge</title>
		<author>
			<persName><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Superglue: A stickier benchmark for general-purpose language understanding systems</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yada</forename><surname>Pruksachatkun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Glue: A multi-task benchmark and analysis platform for natural language understanding</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><surname>Samuel R Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Black-boxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aran</forename><surname>Komatsuzaki</surname></persName>
		</author>
		<ptr target="https://github.com/kingoflolz/mesh-transformer-jax" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A survey of zero-shot learning: Settings, methods, and applications</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><forename type="middle">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunyan</forename><surname>Miao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>TIST</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Finetuned language models are zero-shot learners</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">An explanation of in-context learning as implicit bayesian inference</title>
		<author>
			<persName><forename type="first">Sang</forename><surname>Michael Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditi</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Crossfit: A few-shot learning challenge for crosstask generalization in nlp</title>
		<author>
			<persName><forename type="first">Qinyuan</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Calibrate before use: Improving few-shot performance of language models</title>
		<author>
			<persName><forename type="first">Tony</forename><forename type="middle">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<author>
			<persName><surname>Malo</surname></persName>
		</author>
		<title level="m">A Full Datasets We include 26 datasets as follows: fi-nancial_phrasebank</title>
		<imprint>
			<publisher>Dolan and Brockett</publisher>
			<date type="published" when="2005">2014. 2020. 2005. 2012. 2020. 2005</date>
			<biblScope unit="page" from="glue" to="rte" />
		</imprint>
	</monogr>
	<note>climate_fever. Dagan et al.</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">The choice of datasets is made following low-resource datasets in Min et al. (2021b), with the exact same set of k-shot train data using 5 random seeds</title>
		<author>
			<persName><surname>Bar-Haim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">tweet_eval-stance_atheism</title>
		<editor>
			<persName><forename type="first">Clark</forename></persName>
		</editor>
		<imprint>
			<date type="published" when="2006">2006. 2007. 2009. 2019. 2014. 2018. 2020. 2020. 2020. 2020. 2020. 2020. 2020. 2019. 2018. 2019. 2012. 2019</date>
			<biblScope unit="page" from="quartz" to="with_knowledge" />
		</imprint>
	</monogr>
	<note>ethos-national_origin. codah. dream. Tafjord et al., 2019b), quartz-no_knowledge. Tafjord et al., 2019b. We use the HuggingFace version of the data. Lhoest et al., 2021) and use the development data for evaluation, following Ye et al. (2021). See Table 2 for statistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
