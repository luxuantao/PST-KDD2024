<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An automatic method for lung segmentation and reconstruction in chest X-Ray using deep neural networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-06-06">June 6, 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Johnatan</forename><forename type="middle">Carvalho</forename><surname>Souza</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jo</forename><surname>Ão Ot</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bandeira</forename><surname>Diniz</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jonnison</forename><forename type="middle">Lima</forename><surname>Ferreira</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Giovanni</forename><surname>Lucca Franc ¸a Da Silva</surname></persName>
						</author>
						<author>
							<persName><forename type="first">João</forename><surname>Otávio</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Giovanni</forename><surname>Lucca</surname></persName>
						</author>
						<author>
							<persName><roleName>Aristófanes</roleName><forename type="first">França</forename><surname>Da Silva</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Corrêa</forename><surname>Silva</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Anselmo</forename><surname>Cardoso De Paiva</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Arist ófanes Corr êa Silva</orgName>
								<address>
									<settlement>Anselmo Cardoso de Paiva</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Computer Methods and Programs in Biomedicine</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Jo ão Ot ávio Bandeira Diniz</orgName>
								<address>
									<settlement>Jonnison Lima Ferreira</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Giovanni Lucca Franc ¸a da Silva</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Arist ófanes Corr êa Silva</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="laboratory">Applied Computing Group (NCA -UFMA</orgName>
								<orgName type="institution">Federal University of Maranhao</orgName>
								<address>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An automatic method for lung segmentation and reconstruction in chest X-Ray using deep neural networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-06-06">June 6, 2019</date>
						</imprint>
					</monogr>
					<idno type="MD5">5B4C244EC57793C1210BED44E2D4E507</idno>
					<idno type="DOI">10.1016/j.cmpb.2019.06.005</idno>
					<note type="submission">Received date: 11 March 2019 Revised date: 24 May 2019 Accepted date: 5 June 2019 Preprint submitted to Computer Methods and Programs in Biomedicine</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Lung segmentation</term>
					<term>Lung reconstruction</term>
					<term>Chest x-ray</term>
					<term>Convolutional Neural Networks</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Paiva, An automatic method for lung segmentation and reconstruction in chest X-Ray using deep neural networks, Computer Methods and Programs in Biomedicine (2019),</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In present day, the world has available a variety of important threedimensional examination techniques, such as computer tomography (CT) and magnetic resonance imaging (MRI). For chest screening and detection of lung diseases, for example, CT has been recognized as an successful approach to 5 reduce lung cancer mortality <ref type="bibr" target="#b0">[1]</ref>. Several works in the literature have performed lung segmentation and nodule detection in CT scans <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>. These exams, however, have limited availability in most parts of the world, mainly due to their high cost <ref type="bibr" target="#b3">[4]</ref>.</p><p>For the above mentioned reason, chest X-ray (CXR) is still among the 10 most used imaging tests worldwide, representing at least one third of all exams in a typical radiology department <ref type="bibr">[5]</ref>. The main advantage of CXR is the economical viability. Even in underdeveloped countries, modern digital radiography machines are affordable <ref type="bibr">[6]</ref>. In this context, CXR is certainly a very important diagnosis tool that helps identity a large variety of lung diseases 15 around the world <ref type="bibr">[7]</ref>.</p><p>Due to these factors, millions of CXRs are generated annually. According to the National Health Service (UK), in 2017/18 over 22.9 million X-ray images</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>were requested in the United Kingdom, which represents 55.63% of all imaging tests, including magnetic resonance (MRI) and computed tomography (CT) 20 <ref type="bibr">[8]</ref>. Among these X-Ray exams, 2.2 millions are CXRs. This represents a considerable diagnosis workload, considering the shortage of radiologists worldwide <ref type="bibr" target="#b3">[4,</ref><ref type="bibr">9]</ref>.</p><p>A CXR provides a large amount of information about a patient. The correct interpretation of this information is a major challenge to radiologists, <ref type="bibr" target="#b14">25</ref> and requires a high degree of skill, experience, and concentration <ref type="bibr">[10]</ref>. The distinction of abnormal structures such as infiltrates from normal blood vessels, for example, is a challenging task even for experienced radiologists <ref type="bibr">[10]</ref>.</p><p>Frequently, when radiologists rate the severity of abnormal findings, large interobserver and even intraobserver differences occur <ref type="bibr">[11]</ref>. <ref type="bibr" target="#b19">30</ref> Due to the clinical importance and the complicated nature of CXR, researchers continue to explore the use of image processing and machine learning techniques to develop computational methods to assist radiologists in reading chest images <ref type="bibr">[12]</ref>. Typically, these techniques are combined to develop computer-aided detection (CAD) systems, which provide support to radiologists 35 in the challenging task of identifying abnormalities on patients. Two of the key steps that are required to compose CAD systems are segmentation <ref type="bibr">[13]</ref><ref type="bibr">[14]</ref><ref type="bibr" target="#b5">[15]</ref><ref type="bibr" target="#b6">[16]</ref> and classification <ref type="bibr" target="#b7">[17]</ref> into medical images.</p><p>An important step of CAD systems for CXRs is lung segmentation <ref type="bibr">[6]</ref>. It provides structural information of shape irregularities and size measurements of 40 the lungs, which can be used to analyze severe clinical conditions such as pleural effusion, emphysema, and pneumothorax <ref type="bibr" target="#b8">[18]</ref>. Since a lung segmentation mask specifically determines the lung region, it also determines the non-lung region by exclusion, which minimizes the effects of imaging artifacts in the CAD system <ref type="bibr" target="#b9">[19]</ref>. <ref type="bibr" target="#b34">45</ref> One of the major challenges of lung segmentation in CXR is to include in the segmentation mask the regions of the lung field overlapped by abnormal structures. In good scenarios, where patients are healthy, or in cases which they have only a small nodule, for example, CAD methods are usually able</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>to provide reliable segmentations, because the contrast between the lung fields 50 and their boundaries is maintained overall. However, in more complicated (and also frequent) scenarios, patients may have diseases that affect their lungs with dense abnormalities, such as opacities and consolidations <ref type="bibr" target="#b10">[20,</ref><ref type="bibr">21]</ref>. In general, these abnormalities are ill-defined structures that overlap the lung field with high intensity pixels, which results in lower contrast between the lungs and their 55 boundaries. For this reason, the segmentation task in CXR becomes significantly more complex in these cases <ref type="bibr" target="#b12">[22]</ref>.</p><p>Given the presented scenario, the purpose of this work is to present an automatic lung segmentation method that addresses this problem by performing a reconstruction step on the affected lung regions. The proposed method is 60 basically divided into four steps: (a) image acquisition, where we detail the materials used in our method; (b) initial segmentation, which is based on an AlexNet deep convolutional network (CNN) model <ref type="bibr">[23]</ref>; (c) reconstruction, which is based on a ResNet18 CNN model <ref type="bibr" target="#b13">[24]</ref>; and (d) final segmentation, obtained by combining the outputs of both CNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>65</head><p>The proposed method encompasses a series of contributions, in which we highlight: (1) advances in AlexNet based on pixel classification for initial segmentation of lung in CXR; (2) use of a reconstruction step based on ResNet18 that refines the initial segmentation; (3) a method based on lungs with dense anomalies, making the method robust in segmenting even when it difficult to 70 differentiate from healthy tissue; (4) a robust methodology capable of fully automated segmentation of lung in CXR. For these reasons, we believe the proposed method provides an efficient segmentation step to any CAD system. This paper is organized as follows. In Section 2 we present a review of the related works in the literature. In Section 3 we present and detail the materials 75 and the proposed method used for lung segmentation in CXRs. In Section 4 we detail the experiments and the obtained results. In Section 5, we present a discussion regarding the advantages and limitations of our method. Finally, in Section 6, we show our conclusions and perspectives for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related works 80</head><p>Over the last decades, the scientific community have been publishing a number of methods for lung segmentation in CXR. In this section, we present some of the most relevant works in this research area. According to Van Ginneken et al. <ref type="bibr">[12]</ref>, these methods can be divided in rule-based methods, pixel classification schemes, deformable models, and hybrid methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>85</head><p>Zheng et al. <ref type="bibr" target="#b14">[25]</ref> proposed a semi-automatic rule-based method that uses the anatomical information provided by the exam to determine initial borders for the lung fields. The method has simple steps such as binarization and morphological operations, and uses a contour smoothing technique and projection curve to perform the segmentation. Using a private dataset of 40 exams, this method 90 obtained an average accuracy of 95%.</p><p>Pixel classification methods explore the intensity differences of the inner and outer regions of the lung. Annangi et al. <ref type="bibr" target="#b15">[26]</ref> proposed a method that uses the contrast difference between lung fields and borders to orientate an active contour technique. The method obtained an average Dice coefficient of 0.88 in a dataset 95 of 1130 CXR images obtained from several hospitals in China.</p><p>Deformable models are popular sets of methods that have been extensively studied and applied in medical image segmentation because they can be applied to segment a large set of biological structures <ref type="bibr" target="#b16">[27]</ref>. Xu et al. <ref type="bibr" target="#b17">[28]</ref> proposed an optimized active shape model (ASM) for lung field segmentation. The 100 method, called ERF-ASM, was proposed to address one of the main limitations of typical ASMs, which is the need for an initialization sufficiently close to the target. Experimental results demonstrated a significant enhance of performance compared to other ASMs. Tests were performed on a combination of two datasets, totalling 143 images, in which was reported an average accuracy of 105 95%, an average sensitivity of 91%, and an average specificity of 97%.</p><p>Another recent method based on deformable models is presented by Candemir et al. <ref type="bibr" target="#b12">[22]</ref>. In this work, they present a nonrigid registration-driven lung segmentation method using image retrieval-based patient specific adaptive</p><formula xml:id="formula_0">A C C E P T E D M A N U S C R I P T</formula><p>lung models that detects lung boundaries. The method consists of three main Van Ginneken and ter Haar Romeny <ref type="bibr" target="#b19">[30]</ref> proposed a robust hybrid method 130 that combines a rule-based segmentation with a pixel classification approach. The use of these two complementary techniques achieved an average accuracy of 94% on a dataset of 230 images. In addition, the authors highlight that their method is very fast and can be implemented in any standard computer.</p><p>The fast advances of hardware power, particularly in GPUs, enabled deep 135 learning approaches to become very popular in the last years. Methods based on convolutional neural networks (CNN) and recurrent neural networks, for example, achieved unprecedented results in many research areas such as computer vision, natural language processing and voice recognition. These advances also reflected in methods of image processing for medical images,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>in which promising results were obtained in a wide range of tasks, such as segmentation of lungs <ref type="bibr" target="#b20">[31,</ref><ref type="bibr" target="#b21">32]</ref>, brain <ref type="bibr" target="#b22">[33]</ref>, breast <ref type="bibr" target="#b22">[33]</ref>, spinal cord <ref type="bibr" target="#b23">[34]</ref>, among others . For instance, Kalinovsky and Kovalev <ref type="bibr" target="#b24">[35]</ref> proposed a method in which an encoder-decoder convolutional neural network (ED-CNN) is used to perform lung segmentation. Experiments were performed in a dataset of 354 chest x-rays, 145 in which was achieved an average accuracy of 96.2%.</p><p>Another recent work published by Saidy and Lee <ref type="bibr" target="#b25">[36]</ref>, proposed the use of a semantic segmentation based on a fully connected network for lung segmentation in the JSRT dataset. The network is called SegNet and similar to the work of Kalinovsky and Kovalev <ref type="bibr" target="#b24">[35]</ref> uses an encoder-decoder approach. It is designed 150 to map low-resolution features to input resolution for pixel-wise classification in order to produce features that are useful for accurate boundary localization. The authors achieved average dice index of 96%, sensitivity of 95% and specificity of 99%.</p><p>According to Hooda et al. <ref type="bibr" target="#b26">[37]</ref>, automatic analysis of chest radiographs 155 using computer-aided diagnosis (CAD) systems is pivotal to perform mass screening and detect early signs of various abnormalities in patients. In a chest radiographic CAD system, segmentation of lung fields is a pre-requisite step to precisely define region-of-interest and is subsequently used by other stages of the CAD system. They present a variant of fully-convolutional network that 160 performs segmentation of lung in CXRs. The architecture achieves the testing accuracy of 98.92% and testing Jaccard of 95.88% on the JSRT dataset.</p><p>Mittal et al. <ref type="bibr" target="#b27">[38]</ref> proposed a method also based in deep learning. The network is called LF-SegNet, according to the authors a fully convolutional encoder-decoder network for segmenting lung Fields from CXRs. The 165 authors list the difficulty of the manual segmentation task and how automatic segmentation may be important for assisting specialist physicians. Also, the method has as contribution a new unique architecture that can do an automatic segmentation of the lungs. The method was tested in the JSRT and MC datasets, and the results were 98.73% of accuracy and 95.10% of Jaccard index.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T and Kovalev <ref type="bibr" target="#b24">[35]</ref>, Saidy and Lee <ref type="bibr" target="#b25">[36]</ref> use fully-connected networks for lung segmentation. The advantage of using these networks is that there is no need for a feature engineering to determine the best ones for a classifier to be able to differentiate classes, when using convolutional layers the network will be in charge of finding the most representative features for the problem. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Materials and method</head><p>The proposed method for lung segmentation in CXRs consists of four steps, as illustrated in spacing in both horizontal and vertical directions is 0.0875 mm. In addition, the MC dataset has gold standard lung segmentation masks (Figure <ref type="figure" target="#fig_3">2</ref>), which were marked under the supervision of a radiologist and made available by Candemir et al. <ref type="bibr" target="#b12">[22]</ref>.    As mentioned in the beginning of this section, the initial segmentation is obtained by the classification of CXR patches. Explicitly, our purpose is to 280 build a model that is able to distinguish lung patches from non-lung patches.</p><p>For this reason, during the training phase of our CNN model, patches can be extracted without overlap, that is, side by side. However, in order to generate a finer lung segmentation mask, we need to extract and classify the CXR patches with overlap. In other words, patches have to be extracted with a small stride, 285 such as 1 or 2. This stride value is directly related to the smoothness of the output segmentation masks, and also to the number of model predictions, which translates to computational cost.</p><p>In this work we classify all patches in the CXR image using a stride of 2. If a CXR patch is classified as lung, then its respective patch in the segmentation 290 mask will have its four central pixels painted white, that is, set to 255. On the other hand, CXR patches classified as non-lung will have their respective patches in the segmentation mask painted black, that is, set to 0. In this way, we determine our segmentation of the lungs. Figure <ref type="figure" target="#fig_9">5</ref> (B) illustrates the result of this process. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4.">Post-processing</head><p>After the plotting of all lung patches, we observed that a considerable amount of false positives was generated in the resultant segmentation masks. Since morphological operations have been extensively used for false positive reduction in a large variety of works including lung segmentation <ref type="bibr" target="#b30">[41]</ref><ref type="bibr" target="#b31">[42]</ref><ref type="bibr" target="#b32">[43]</ref>, we chose to apply 300 some of these techniques in our post-processing step, which consists of: (1) an erosion, (2) a dilation, (3) an area filter that keeps the two largest objects, and</p><p>(4) a closing operation. The area filtering technique has been used to perform simple lung segmentation routines in CXR <ref type="bibr" target="#b32">[43,</ref><ref type="bibr" target="#b33">44]</ref>, and is based mainly on the prior knowledge that the lungs are the two largest objects in a CXR image. for the purpose of post-processing. However, this was the set of parameters that achieved the best results. Figure <ref type="figure" target="#fig_9">5</ref> shows the result the post-processing in 310 a CXR image. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Reconstruction</head><p>In good scenarios, where patients are healthy and the CXRs show lungs in good conditions, our initial segmentation alone is able to achieve great results.</p><p>However, in problematic cases such as the ones mentioned in Section 1, our 315 first CNN may not include in the initial segmentation mask the lung regions severely affected by opacities or consolidations. This is due to the fact that the model uses texture information to perform segmentation, and therefore contrast difference is an extremely important factor. Figure <ref type="figure" target="#fig_10">6</ref> illustrates a case where the initial segmentation is compromised by the above mentioned situation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>320</head><p>In order to provide a solution to these particular cases, and therefore  Inspired by the segmentor network in <ref type="bibr" target="#b34">[45]</ref> we modify ResNet-18 <ref type="bibr" target="#b13">[24]</ref> to generate a reconstructed mask from the initial segmentation obtained in the previous step. Figure <ref type="figure" target="#fig_12">7</ref> details the architecture of our reconstruction network. We take the output of the last resblock of ResNet-18 and pass it to a fully connected (FC) layer to perform upsampling. Then, the output of the FC layer is passed to a final max pooling layer, which results in the reconstruction of the 340 lung regions. The final reconstructed mask is obtained after a fine smoothing using a median filter with kernel size of 5×5.</p><p>In our reconstruction network we use batch normalization <ref type="bibr" target="#b35">[46]</ref> right after each convolutional layer and before activation. The max pooling layers use kernels of size 3×3 with stride 2, and for all the convolutions in the resblocks 345 we use filters of size 3×3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Final segmentation</head><p>The final step of the proposed method is the combination of initial segmentation and reconstruction into a single mask. We achieve this by performing a binary OR operation on the two segmentation masks. Figure <ref type="figure" target="#fig_9">350</ref> 8 shows an example of this process. As explained in Section 3.3, the main benefit of the reconstruction is that it is able to recover a considerable portion of the missing lung regions. However, it also seems to erode the reconstructed mask in a certain level, which deforms the contour previously established in the initial segmentation. Since the purpose 360 of the reconstruction is to recover lung regions while keeping the previously segmented ones, we combine both masks to provide a final segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>In this section, we present the results of the proposed method for lung segmentation. Initially, we briefly present the metrics used for performance 365 evaluation, then we detail the experiments and discuss the results. In addition,</p><p>we present a set of study cases for further analysis, and also discuss and compare our method with other related works.</p><p>We highlight that the proposed method is implemented entirely in Python, in which we used mainly the Keras deep learning library <ref type="bibr" target="#b36">[47]</ref> with Tensorflow</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>370</head><p>[48] as back-end. The machine used in our experiments consists of an Intel Core i7-7700K CPU, 16GB of RAM, and two Nvidia GeForce GTX 1080-Ti graphic cards, running on Windows 10 operating system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Evaluation metrics</head><p>In order to evaluate the performance of the proposed method, we use a set 375 of metrics widely used and accepted by the scientific community to the assess medical image segmentation methods <ref type="bibr" target="#b37">[49]</ref>. The used evaluation metrics are the Dice similarity coefficient, the Jaccard index, also known as Intersection over Union, Accuracy, Sensitivity, and Specificity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experimental results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>380</head><p>This section presents an analysis of results of each step of the proposed method, organized in the following order: 1) Dataset preparation; 2) Initial</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>segmentation results; and 3) Final segmentation results. We also provide in this section a detailed analysis of 4) Case studies, and a 5) Comparison with related works.  The number of patches generated to train the CNN in the initial segmentation step (Section 3.2) is detailed in Table <ref type="table" target="#tab_2">1</ref>.  <ref type="table" target="#tab_2">1</ref> that the number of non-lung patches is approximately two times higher than the number of lung patches. This happens because the lung fields occupy less space in a CXR than the other structures 405 overall, and consequently this is reflected on the number of generated patches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>In addition, we ignore the patches extracted solely from the background, that is, the patches that contain only pixels equals to zero. This is done for two reasons: the number of patches generated in each class becomes less unbalanced;</p><p>and we spare processing time by not submitting patches without any relevant  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Initial segmentation results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>415</head><p>As described in Section 3.2, the initial segmentation is obtained using our AlexNet-based CNN, which performs patch classification. Using a batch size of 128, the training of this CNN model consisted of 500 epochs. We used stochastic gradient descent as optimizer to minimize the difference between the ground truth and the network output, and the loss function used was the binary cross 420 entropy <ref type="bibr" target="#b38">[50]</ref>. The learning rate was set to a fixed valued of 0.01. Weights were initialized using a normalized initialization <ref type="bibr" target="#b39">[51]</ref> and updated using the standard backpropagation algorithm <ref type="bibr" target="#b29">[40]</ref>. This set of parameters was selected after several training experiments, in which this was the one that obtained the best results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>425</head><p>During validation, our model obtained 95.36% of sensitivity, 97.85% of specificity, and 97.02% of accuracy. In the test phase, it achieved 94% of sensitivity, 97.44% of specificity, and 96,22% of accuracy, which demonstrates that our model was capable of satisfactorily learning the patterns of both lung and non-lung patches in CXR without overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>As mentioned in Section 3.2 the initial segmentation consists of several steps.</p><p>The post-processing is used to refine the output of our first CNN by reducing false positives. Table <ref type="table" target="#tab_3">2</ref> shows the results of the initial segmentation before and after post-processing.   As detailed in Section 3.4 the final output of our method is the combination of the initial segmentation and the reconstruction masks. Table <ref type="table" target="#tab_4">3</ref> presents the 465 performance overview of our proposed method, showing the results for each of the segmentation steps. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>Analyzing the results on Table <ref type="table" target="#tab_4">3</ref>, we can observe that the final segmentation reached 97.54% of sensitivity, which represents a 4% increase, compared to the initial segmentation, to the detriment of an average decrease of 1% on the 470 other metrics. This significant increase of sensitivity is due to the many lung regions that the reconstruction was able to include in the final segmentation.</p><p>It is worth mentioning that the sensitivity rate is extremely important for our method because it represents the rate of lung pixels correctly segmented, which is directly related to the objective of our work. Figure <ref type="figure" target="#fig_2">11</ref> shows the results of 475 the final segmentation for two cases. Despite having achieved lower quantitative results than the initial segmentation, the final segmentation is considered successful for most cases.</p><p>Our reconstruction was able to include in the segmentation mask several lung regions that were overlap by abnormal structures in the original CXR images. 480 However, as described in Section 3.4, the disadvantage of this step is that it erodes the segmentation contour in a certain level. As a result, we lose part of the true positive pixels on the borders. In other words, part of the lung regions correctly established by the initial segmentation is lost on the reconstruction step, typically the regions of the border.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>In addition, there are many cases that the initial segmentation provides extremely precise contours, as illustrated in Figure <ref type="figure" target="#fig_18">10</ref>. In such cases, the reconstruction can not provide any further enhancement to the initial segmentation, and therefore only decreases the performance metrics due to the eroding factor. These are the main reasons for the results of the final 490 segmentation being lower than the initial segmentation for some metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Case studies</head><p>In this section we present a set of case studies with the purpose of analyzing the influence of the reconstruction step in the proposed method.</p><p>Such cases illustrate the most common situations of the application of our lung 495 segmentation method on the MC dataset. We show and discuss the following cases: (1) reconstruction was not necessary, but was able to keep a good result;</p><p>(2) reconstruction was not necessary and notably affected the quality of the initial segmentation; and (3) reconstruction was necessary and was able to improve the quality of the segmentation. The first case study shows the application of the proposed method on the MCUCXR 0100 0 exam. In this case, the initial segmentation alone was capable of determining very precise lung contours, as illustrated in Figure <ref type="figure" target="#fig_21">12A</ref>, where the contour in red indicates the initial segmentation and the contour in 505 green indicates the ground truth. The initial segmentation obtained 99.12% of sensitivity, 99.18% of specificity and 98.10% of Dice, while the final segmentation 99.46% of sensitivity, 98.28% of specificity and 96.73% of Dice. In spite of the reconstruction step being considered unnecessary in this exam, its application on the initial segmentation mask did not worsened the results in any significant 510 aspect. As a matter of fact, this case is considered a success, since it still maintained a great correspondence with the marking of the specialist, as showed in Figure <ref type="figure" target="#fig_21">12B</ref> (red contour indicates final segmentation and green contour indicates ground truth).  It is also the main reason for the final segmentation not being able to improve the performance rates for most metrics. We consider this case a fail, since it significantly affected the quality of the initial segmentation, which had 530 previously determined lung contours very similar to the ground truth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3.">Case study 3 -MCUCXR 0108 1</head><p>The last case study details the application of the proposed method on the MCUCXR 0108 1 exam. From Figure <ref type="figure" target="#fig_24">14A</ref> we can see that the initial segmentation is missing a considerable part of the lung field in the right side </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Comparison with related works</head><p>In this section, we present a comparative analysis of the proposed method and the related works mentioned in Section 2.</p><p>Zheng et al. <ref type="bibr" target="#b14">[25]</ref> proposed a semi-automatic method that uses anatomical information provided by exam to determine initial borders for the lung fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>555</head><p>The method was tested in a private dataset of 40 exams, and obtained an accuracy of 95%. Despite achieving a high accuracy rate, this method is semiautomatic. Our method is completely automatic, and there is no need for anatomical information, in addition the accuracy achieved was almost 97%.</p><p>A method based on pixel classification was proposed by Annangi et al. <ref type="bibr" target="#b15">[26]</ref>.</p><p>560</p><p>The method uses edge information to guide an active contouring technique. The method obtained an Dice index of 88%. It is observed that this method used techniques based on active contours, this type of technique requires a starting point from where the algorithm will shape the contours until finding the ideal contour based on a stop condition. In our method, we propose the use of two Another work that uses deformable models is proposed in Candemir et al. <ref type="bibr" target="#b12">[22]</ref>. This work uses non-rigid registration methods followed by adaptive models for detection of lung edges. By using non-rigid registration techniques, 580 the method ultimately requires an initial image to which the entire base will be registered, conditioning the entire performance of the method to this registration. For this reason, we chose not to use any registrations in our method, making it fully automatic and independent of a fixed image. While the registration-based work of Candemir et al. <ref type="bibr" target="#b12">[22]</ref> reported a Dice of 96% using Some works that use encoder-decoder networks are proposed by Kalinovsky and Kovalev <ref type="bibr" target="#b24">[35]</ref>, Saidy and Lee <ref type="bibr" target="#b25">[36]</ref>, and Mittal et al. <ref type="bibr" target="#b27">[38]</ref> reaching very 600 promising metrics in the task of lung segmentation. Both works present the images with marking to the network and it is in charge to learn the features and in the future to classify new images in regions of lung and non-lung. An advantage of our method in relation to these is that we insert a reconstruction step, which is concerned with the existence of possible anomalies that make 605 the segmentation task more difficult. Concerned about this, we ensure that our method is more robust in the task of CXR segmentation of patients with abnormalities, such as tuberculosis.</p><p>Finally, a hybrid method is presented by Ngo and Carneiro <ref type="bibr" target="#b18">[29]</ref>, which used deep learning techniques along with deformable models. By doing this, the 610 author inserts two relevant techniques for lung segmentation in his method, the first capable of prior segmentation and the second capable of refining such segmentation. The authors achieved 96.5% accuracy as a result. It is believed that by using a reconstruction network to refine an initial segmentation, we make the method more robust and invariant to initial parameters. Also, our 615 method was able to achieve 96.97% accuracy.</p><p>Table <ref type="table" target="#tab_5">4</ref> shows the relationship between these works and the proposed method.</p><p>As we can see in the Table <ref type="table" target="#tab_5">4</ref>, there are several methods in the literature that investigate lung segmentation in CXR. Also, it is seen that over the years the 620 techniques have become increasingly robust and have always achieved results higher than 90% in all validation metrics. This shows how fundamental is the search for increasingly automatic computational methodologies in the task of lung segmentation.</p><p>However, we emphasize that our method is fully automatic, which uses 625 two convolutional neural networks, capable of not only segmenting the lungs, but also reconstructing the marking that can be compromised by regions of anomalies such as turberculosis. We also emphasize that our method reached validation metrics superior to most of the works of the literature, showing how promising and robust our method is. With this, we can demonstrate the 630 feasibility of using our method for the task of lung segmentation in CXRs.</p><formula xml:id="formula_1">A C C E P T E D M A N U S C R I P T</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion</head><p>The proposed method has shown great robustness in the task of lung of providing a segmentation that includes the regions affected by dense abnormalities, the reconstruction can also include false positives, and remove true positives, and therefore decrease the quantitative results.</p><p>3. The results obtained by the proposed method can be considered excellent, 695 being among the bests in the literature. However, the reconstruction step decreases some of the performance metrics. We believe this limitation could be mitigated or even overcame by exploring the use of contour enhancement techniques.</p><p>4. Finally, it is worth mentioning that deep learning models, such as the 700 CNNs used in our work, typically have a great number of parameters.</p><p>Frequently, this set of parameters is empirically determined by the user, which may not provide optimal results. This specific situation is another limitation of the proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>All the above-mentioned observations aggregate value to this work. The 705 many positive aspects listed in this section have enabled the proposed method to achieve excellent results. It is worth mentioning that, as far as we know, the literature does not have any lung segmentation methodology that provides a solution to the specific problem of dense abnormalities. We highlight that, even with some limitations, the proposed method was capable to achieve 710 outstanding results, and for these reasons, we believe we our work provides a very important contribution, for being an innovative, robust and promising automated segmentation method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>This paper presented a fully automatic method for lung field segmentation The proposed method is validated on a public database, namely Montgomery County Chest X-ray dataset, which contains CXR exams from normal patients 725 but also from several patients with manifestations of tuberculosis. For this reason, the MC dataset is very heterogeneous and complex, which results in a challenging task that most likely illustrates realistic scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Work evaluation</head><p>The use of an AlexNet-based CNN for patch classification was quite robust.  Despite not being able to improve some of the performance metrics, the reconstruction step was of great importance in the proposed method. It helped overcome the limitation of the previous step, which resulted in better qualitative results. Though, it is worth mentioning that the sensitivity rates were considerably improved by this step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>740</head><p>The combination of the techniques mentioned in this paper was able to achieve great results. We believe that, in general, this work represents a great contribution to the scientific community. In spite of all its limitations, it has shown great robustness for the fact that even on such a diverse and complex dataset it has achieved a prominent place among the best works in the literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>745</head><p>In addition, the way techniques were used and adapted to perform lung segmentation is very innovative and may inspire other authors in new coming works. It is worth mentioning that most computer-aided detection systems rely on a robust segmentation method. We therefore believe that the proposed method is very promising and relevant. 750</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Future work</head><p>Despite having obtained promising results, the proposed method can be improved in some of aspects. Following, we present some of the current limitations of our work that could be overcome on future work.</p><p>The main limitation of this work that should be addressed is the fact that 755 the reconstruction does not always guarantee a quantitative improvement of the segmentation. Since false positives can be incorrectly included, and true positives removed, we believe that by using an active contour based technique, such as level set, in order to enhance the reconstructed segmentation.</p><p>Regardless of the MC dataset being a very complex and heterogeneous, it </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>110 stages: 1 )</head><label>1</label><figDesc>a content-based image retrieval approach for identifying training images (with masks) most similar to the patient CXR using a partial radon transform and Bhattacharyya shape similarity measure, 2) creating the initial patient-specific anatomical model of lung shape using SIFT-flow for deformable registration of training masks to the patient CXR, and 3) extracting refined lung 115 boundaries using a graph cuts optimization approach with a customized energy function. According to the authors, this method has surpassed the state of art in several previous works. The methodology was tested in two datasets: Japanese Society of Radiological Technology (JSRT) Database, where it achieved a Dice coefficient index of 96,7%; and Montgomery County Dataset (MC), in which 120 they achieved 96% of the same index. According to Ngo and Carneiro [29], computer-aided diagnosis of digital chest X-ray (CXR) images critically depends on the automated segmentation of the lungs, which is a challenging problem due to the presence of strong edges at the rib cage and clavicle, the lack of a consistent lung shape among 125 different individuals, and the appearance of the lung apex. It has resulted in the publication in the last decades of robust hybrid methods, which are generally based on the combination of different techniques, for example, techniques based on pixel classification and deformable models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>200</head><label></label><figDesc>Based on these advantages, disadvantages and limitations in related works, we propose a fully automatic and hybrid method capable of efficiently A C C E P T E D M A N U S C R I P T segmenting lung into CXR. As we have seen in the literature, the deep learning methods have surpassed the state of the art in several image domains. In proposing our method, we attempted to encompass two problems: lung 205 segmentation, and reconstruction of segmentation in lungs with tuberculosis, since CXR exams in tuberculous patients present regions of high intensity, often considered regions that are non-lungs, and we can segment these lungs in a robust way. Therefore, we propose the use of two deep learning networks, the first capable of initially segmenting the lungs and the second capable of 210 reconstructing regions with tuberculosis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 .Figure 1 :</head><label>11</label><figDesc>Figure 1: Steps of the proposed method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A sample from Montgomery County dataset. (A) A chest x-ray image and (B) its ground truth lung segmentation mask.</figDesc><graphic coords="12,201.60,466.46,167.17,87.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>3. 2 . 3 . 2 . 1 .</head><label>2321</label><figDesc>Initial segmentation 235 After acquisition of the image dataset, we train a deep CNN model to obtain an initial segmentation of the lung regions. This task can be divided into four substeps: division of CXRs into patches; classification of patches using the CNN A C C E P T E D M A N U S C R I P T model; generating the segmentation masks by plotting the patches classified as lung; and post-processing. 240 Division into patches Initially, we scale all CXR images to 512×512, which is a resolution that satisfactorily retains the structural details of the exam, while significantly reducing the model's computational cost. Since images in the MC dataset may have two different dimensions (4020×4892 and 4892×4020), we scale images in 245 a way that their proportions are not deformed. Scaling is done by, initially, placing the original CXR image in the center of a background image of size 4892×4892 and pixels equal to zero, and then resizing it to the final resolution of 512×512. After scaling, images are divided into patches of size 32×32, which will be 250 used as input to the CNN model in the next substep. But first, we label these patches in two classes: lung and non-lung. The criterion used for labeling is based on the proportion of lung pixels and non-lung pixels. Patches that contain 20% or more pixels of lung, according to the ground truth, are labeled as lung. Otherwise, they are labeled as non-lung. The parameters patch size of 255 32×32 and the threshold for being lung patch of 20% were defined empirically after several experiments. Figure 3 illustrates the processes of dividing an CXR image in patches and labeling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Patch division and labeling: The ground truth mask (A) is used as reference to label patches in a CXR image (B).</figDesc><graphic coords="13,126.38,514.50,317.62,120.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The CNN architecture used for initial segmentation.</figDesc><graphic coords="14,118.02,489.37,334.32,110.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>295</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>305</head><label></label><figDesc>The structuring elements used in the morphological operations are: a cross of size 19×19 in the erosion, an ellipse of size 15×15 in the dilation, and an A C C E P T E D M A N U S C R I P T ellipse of size 19×19 in the closing. Other sets of parameters have been tested</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Initial segmentation: A chest x-ray sample (A), the generated mask with false positives (B), and the post-processed segmentation mask (C).</figDesc><graphic coords="16,151.45,226.76,267.47,92.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Compromised initial segmentation: A chest x-ray image (A) showing patient with severe lung lesions, the initial segmentation generated (B), and the ground truth mask (C).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>330</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: The CNN architecture used for lung reconstruction.</figDesc><graphic coords="17,118.02,398.57,334.32,207.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Process of obtaining the final segmentation.</figDesc><graphic coords="18,134.74,450.61,300.90,144.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>385</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>410</head><label></label><figDesc>information to the CNN model. In general, patches from lung and non-lung classes have different texture patterns, specially in normal patients, as illustrated in Figure9. In cases aggravated by dense pulmonary lesions, however, this factor becomes less evident.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Patch samples: (A) Three lung patches and (B) three non-lung patches.</figDesc><graphic coords="21,151.45,293.76,267.48,63.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>435post-processing, all the other metrics were significantly improved. It is worth mentioning that the increases of Dice and Jaccard indexes were considerably large, which translates to improved segmentation masks with fewer false positives, since these indexes indicate the overlap and similarity between objects.It was obtained almost 9% of improvement of Dice coefficient and over 14% of 440 Jaccard index. Figure10shows the results of our initial segmentation for two images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Initial segmentation examples. (A) Original CXR image, (B) initial segmentation, (C) post-processed segmentation, and (D) ground truth.</figDesc><graphic coords="22,151.45,452.65,267.46,145.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Final segmentation examples. (A) Original CXR image, (B) initial segmentation, (C) reconstruction, (D) final segmentation, and (E) ground truth.</figDesc><graphic coords="24,118.02,313.98,334.33,152.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>500 4 . 3 . 1 .</head><label>431</label><figDesc>Case study 1 -MCUCXR 0100 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Case study 1 -MCUCXR 0100 0. (A) Initial segmentation (red) vs ground truth (green), and (B) final segmentation (red) vs ground truth (green).</figDesc><graphic coords="26,134.74,151.23,300.90,161.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>4. 3 . 2 .</head><label>32</label><figDesc>Case study 2 -MCUCXR 0102 0 515The second case study shows the application of our lung segmentation method on the MCUCXR 0102 0 exam. In Figure13Awe can observe that the initial segmentation once again was able to determine very precise lung boundaries (red contour indicates initial segmentation and green contour indicates ground truth). However, after the final segmentation step, one 520 can observe that the result was compromised with several false positives, as illustrated in Figure13B(red contour indicates final segmentation and green contour indicates ground truth). The initial segmentation obtained 98.68% of sensitivity, 99.12% of specificity and 98.23% of Dice, while the final segmentation obtained 99.73% of sensitivity, 94.77% of specificity and 93.64% of Dice. Despite 525 occurring most frequently in smaller scales, it still represents one of the most common cases of the application of the proposed method in the MC dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Case study 2 -MCUCXR 0102 0. (A) Initial segmentation (red) vs ground truth (green), and (B) final segmentation (red) vs ground truth (green).</figDesc><graphic coords="27,134.74,151.23,300.90,159.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>535Figure 14 :</head><label>14</label><figDesc>Figure 14B (red contour indicates final segmentation and green contour indicates ground truth). In this particular case, it was obtained in the initial segmentation 540</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head></head><label></label><figDesc>S C R I P Tconvolutional neural networks to achieve optimal segmentation for the lungs, thus, we insert classifiers capable of segmentation without needing a starting point. In addition, our method reached a Dice of 93.56%.Deformable models are proposed by Xu et al.<ref type="bibr" target="#b17">[28]</ref> for segmentation of lungs in CXR. The authors proposed a new active shape model called ERF-ASM. Even 570 bypassing the limitation of addressing an initiation criterion close to the ideal, this method still needs an initial segmentation to model the final contour of the lungs. This method achieved an accuracy of 95%. The method proposed by our work does not require an initialization criterion because it uses two convolutional neural networks, the first one responsible for the initial segmentation and the 575 second to refine the mask obtained initially. Even so, our method overcomes the work of Xu et al.<ref type="bibr" target="#b17">[28]</ref> in all validation metrics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head></head><label></label><figDesc>585the MC dataset, our fully automatic method achieved 93.56% of the same index.The method proposed by Van Ginneken et al.[12]  proposed a hybrid technique using rule-based segmentation and pixel classification. As we talk about the other works, these techniques are directed, and use information of intensity of pixels. When inserting a classifier based on CNN, we inserted a 590 certain intelligence to our method, making it more robust in the segmentation of lung.The method proposed by Hooda et al.<ref type="bibr" target="#b26">[37]</ref> presents a fully-convolutional network that performs segmentation of lungs. The work presents a high value of accuracy and Jaccard on the JSRT dataset. The JSRT dataset, unlike MC,A C C E P T E D MA N U S C R I P T method when applied to the MC base using a reconstruction step to treat the anomaly problem presents very promising results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>715</head><label></label><figDesc>in CXR. For this purpose, several techniques are used, which include two convolutional neural networks, and other image processing techniques such as morphological operations and filtering. In order to generate an initial segmentation, we use one CNN model, which is based on AlexNet, to perform patch classification. Then, a second CNN model, which is based on ResNet18, is 720 used to perform a reconstruction of missing parts of the lung field. Finally, the output of the proposed method is obtained by the combination of both initial segmentation and reconstruction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>730</head><label></label><figDesc>In general, it provided outstanding results for an initial segmentation step, since it was able to determine very precise lung boundaries for most of the normalA C C E P T E D MA N U S C R I P T lungs. Due to the extreme texture difference, one limitation of this step is that it was not possible to segment lung regions overlapped by dense lesions. However, this problem is addressed in the further step of reconstruction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head></head><label></label><figDesc>735</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>760</head><label></label><figDesc>contains only 138 exams, which can be considered a small number of samples, specially for training deep learning models. Therefore, in order to validate ourA C C E P T E D M A N U S C R I P Twork, provide a more robust lung segmentation method, and enable a better comparison with the literature, as future work we suggest that other public or private CXR databases are used in the experiments.765Finally, since CNN models typically have a large number of empirically determined parameters, we suggest that optimization methods, such as evolutionary algorithms, should be used to obtain improved CNN architectures for both models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Number of patches generated for training, validation, and test.</figDesc><table><row><cell>Dataset</cell><cell cols="4">Training Validation Test Total</cell></row><row><cell>Montgomery County</cell><cell>80</cell><cell>20</cell><cell>38</cell><cell>138</cell></row><row><cell>Lung patches</cell><cell>5,136</cell><cell>1,316</cell><cell cols="2">2,804 9,256</cell></row><row><cell>Non-lung patches</cell><cell>10,279</cell><cell>2,656</cell><cell cols="2">5,121 18,052</cell></row><row><cell cols="2">It can be observed in Table</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Initial segmentation results before, and after post-processing.</figDesc><table><row><cell cols="4">Initial Segmentation Sensitivity Specificity Accuracy</cell><cell>Dice</cell><cell>Jaccard</cell></row><row><cell>Before post-processing</cell><cell>97.01%</cell><cell>91.33%</cell><cell>92.70%</cell><cell>85.68%</cell><cell>75.08%</cell></row><row><cell>After post-processing</cell><cell>93.54%</cell><cell>98.72%</cell><cell>97.57%</cell><cell>94.41%</cell><cell>89.64%</cell></row><row><cell cols="6">It can be observed that despite the sensitivity rate has decreased after</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Results of the reconstruction performed by the ResNet18-based CNN on the test set.</figDesc><table><row><cell cols="4">Segmentation Sensitivity Specificity Accuracy</cell><cell>Dice</cell><cell>Jaccard</cell></row><row><cell>Initial</cell><cell>93.54%</cell><cell>98.72%</cell><cell>97.57%</cell><cell>94.41%</cell><cell>89.64%</cell></row><row><cell>Final</cell><cell>97.54%</cell><cell>96.79%</cell><cell>96.97%</cell><cell>93.56%</cell><cell>88.07%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Comparison of results of the proposed method and related works.</figDesc><table><row><cell>Work</cell><cell>Dataset</cell><cell>Disease</cell><cell>Technique</cell><cell>Sen</cell><cell>Acc</cell><cell>Dice</cell><cell>Jaccard</cell></row><row><cell>Zheng et al. [25]</cell><cell>Private</cell><cell>No</cell><cell>Semi-automatic</cell><cell>-</cell><cell>95%</cell><cell>-</cell><cell>-</cell></row><row><cell>Annangi et al. [26]</cell><cell>Private</cell><cell>No</cell><cell>Semi-automatic</cell><cell>-</cell><cell>-</cell><cell>88%</cell><cell>-</cell></row><row><cell>Xu et al. [28]</cell><cell>Private</cell><cell>No</cell><cell>Semi-automatic</cell><cell>91%</cell><cell>95%</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>JSRT</cell><cell>No</cell><cell></cell><cell>-</cell><cell>-</cell><cell>96.7%</cell><cell>95.4%</cell></row><row><cell>Candemir et al. [22]</cell><cell></cell><cell></cell><cell>Semi-automatic</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>MC</cell><cell>Yes</cell><cell></cell><cell>-</cell><cell>-</cell><cell>96%</cell><cell>94.1%</cell></row><row><cell>Van Ginneken et al. [12]</cell><cell>Private</cell><cell>No</cell><cell>Semi-automatic</cell><cell>-</cell><cell>94%</cell><cell>-</cell><cell>-</cell></row><row><cell>Kalinovsky and Kovalev [35]</cell><cell>Private</cell><cell>No</cell><cell>Automatic</cell><cell>-</cell><cell>96.2%</cell><cell>-</cell><cell>-</cell></row><row><cell>Saidy and Lee [36]</cell><cell>JSRT</cell><cell>No</cell><cell>Automatic</cell><cell>95%</cell><cell>-</cell><cell>96%</cell><cell>-</cell></row><row><cell>Ngo and Carneiro [29]</cell><cell>JSRT</cell><cell>No</cell><cell>Semi-automatic</cell><cell>-</cell><cell>96.5%</cell><cell>-</cell><cell>-</cell></row><row><cell>Hooda et al. [37]</cell><cell>JSRT</cell><cell>No</cell><cell>Automatic</cell><cell>-</cell><cell>98.92%</cell><cell>-</cell><cell>95.88%</cell></row><row><cell>Mittal et al. [38]</cell><cell>JSRT+MC</cell><cell>No</cell><cell>Automatic</cell><cell>-</cell><cell>98.73%</cell><cell>-</cell><cell>95.10%</cell></row><row><cell>Proposed Method</cell><cell>MC</cell><cell>Yes</cell><cell>Automatic</cell><cell cols="4">97.54% 96.97% 93.56% 88.07%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>does not have dense abnormalities such as tuberculosis, only nodules. Our</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>Engineering 13 (2) (2010) 235-246.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="436" xml:id="foot_2"><p></p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements 770</head><p>The authors acknowledge CAPES, CNPq and FAPEMA for the financial support.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>Dataset, which is a public database of chest X-rays that contains some 645 patients with manifestations of tuberculosis. It is worth mentioning that our results in this database are very promising, and for this reason the proposed method has achieved a prominent place among other important works.</p><p>3. Although our work focuses on reconstruction for the segmentation of 650 abnormal lungs, it is worth mentioning that our initial segmentation alone is capable to provide excellent results comparable to other relevant works in the literature.</p><p>4. In the proposed method lung segmentation is a fully automated process performed entirely by two CNN models, which are very robust tools 655 that perform implicit feature extraction and selection. This is a positive aspect because it eliminates the need for empirically determining the set of features to be used in the learning process, and the techniques to be used in feature selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Despite the fact that our initial segmentation achieve expressive results,</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>660</head><p>we used another CNN model to enhance the segmentation for more complex cases. We address the problem of lung segmentation with dense abnormalities by performing a reconstruction step, and to the best of our knowledge, this is the first method that addresses these cases explicitly.</p><p>6. The reconstruction step is performed by a ResNet-18-based CNN, which 665 is a deep neural network architecture that uses the concept of residual learning to accelerate and improve the learning process, providing better segmentation results.</p><p>7. We propose a fully automatic method that performs not only the regular lung segmentation, but also that provides a solution to the more complex </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Reduced lung-cancer mortality with low-dose computed tomographic screening</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">L S T R</forename><surname>Team</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New England Journal of Medicine</title>
		<imprint>
			<biblScope unit="volume">365</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="395" to="409" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Novel and powerful 3D adaptive crisp active contour method applied in the segmentation of CT lung images</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Rebouças Filho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Cortez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Da Silva Barros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">H C</forename><surname>Albuquerque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M R</forename><surname>Tavares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="503" to="516" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Automatic 3D pulmonary nodule detection in CT images: a survey</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">R S</forename><surname>Valente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Cortez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Neto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">H C</forename><surname>De Albuquerque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M R</forename><surname>Tavares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer methods and programs in biomedicine</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page" from="91" to="107" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep learning with lung segmentation and bone shadow exclusion techniques for chest x-ray analysis of lung cancer</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gordienko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kochura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Alienin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Rokovyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stirenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Theory and Applications of Fuzzy Systems and Soft Computing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="638" to="647" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName><surname>A C C E P T E D M A N U S C R I P T</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Segmentation and simulation of objects represented in images using physical principles</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Gonçalves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M R</forename><surname>Tavares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Jorge</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Computational methods for the image segmentation of pigmented 820 skin lesions: a review</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mercedes Filho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Papa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M R</forename><surname>Tavares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer methods and programs in biomedicine</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="page" from="127" to="141" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Effective features to classify skin lesions in dermoscopic images</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M R</forename><surname>Tavares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="92" to="101" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Automatic estimation of heart boundaries and cardiothoracic ratio from chest x-ray images</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Dallal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Arbabshirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer-Aided Diagnosis</title>
		<imprint>
			<biblScope unit="volume">825</biblScope>
			<biblScope unit="page">101340</biblScope>
			<date type="published" when="2017">2017. 2017</date>
			<publisher>International Society for Optics and Photonics</publisher>
		</imprint>
	</monogr>
	<note>Medical Imaging</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised 830 classification and localization of common thorax diseases</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bagheri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="3462" to="3471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Imaging in tuberculosis</title>
		<author>
			<persName><forename type="first">E</forename><surname>Skoura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zumla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bomanji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Infectious Diseases</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="87" to="93" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<ptr target="/chest-x-ray-lung-disease.html" />
		<title level="m">The Radiology Assistant: Chest X-Ray -Lung disease</title>
		<imprint>
			<date type="published" when="2018">50d95b0ab4b90. 2019-02-06, 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Lung segmentation 840 in chest radiographs using anatomical atlases with nonrigid registration</title>
		<author>
			<persName><forename type="first">S</forename><surname>Candemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Palaniappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Musco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karargyris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Thoma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="577" to="590" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improved method for automatic identification of lung regions in chest radiographs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kallergi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical 850 Imaging 2000: Image Processing</title>
		<imprint>
			<publisher>International Society for Optics and Photonics</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">3979</biblScope>
			<biblScope unit="page" from="1138" to="1147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A region based active contour method for x-ray lung segmentation using prior shape and low level features</title>
		<author>
			<persName><forename type="first">P</forename><surname>Annangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thiruvenkadam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 IEEE international symposium on 855 biomedical imaging: from nano to macro</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="892" to="895" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deformable models in medical image analysis: a survey</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mcinerney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="108" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">An edge-region force guided active shape approach for automatic lung field detection in chest 860 radiographs</title>
		<author>
			<persName><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mandal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computerized Medical Imaging and Graphics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="452" to="463" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Lung segmentation in chest radiographs using distance regularized level set and deep-structured learning and inference</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Carneiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">865</biblScope>
			<biblScope unit="page" from="2140" to="2143" />
		</imprint>
	</monogr>
	<note>Image Processing</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automatic segmentation of lung fields in chest radiographs</title>
		<author>
			<persName><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Ter Haar</surname></persName>
		</author>
		<author>
			<persName><surname>Romeny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical physics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2445" to="2455" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Lung field segmentation in chest radiographs: a historical review, current status, and expectations from deep learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hooda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sofat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Image Processing</title>
		<imprint>
			<biblScope unit="volume">870</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="937" to="952" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Convolutional neural network-based PSO for lung nodule false positive reduction on CT images</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L F</forename><surname>Da Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L A</forename><surname>Valente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>De Paiva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gattass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer methods and programs in biomedicine</title>
		<imprint>
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="page" from="109" to="118" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Detection of white matter lesion regions in MRI using SLIC0 and convolutional neural network</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H B</forename><surname>Diniz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L A</forename><surname>Valente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">O B</forename><surname>Diniz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gattass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ventura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Muniz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Gasparetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer methods and programs in biomedicine</title>
		<imprint>
			<biblScope unit="volume">167</biblScope>
			<biblScope unit="page" from="49" to="63" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">880 Spinal cord detection in planning CT for radiotherapy through adaptive template matching, IMSLIC and convolutional neural networks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">O B</forename><surname>Diniz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H B</forename><surname>Diniz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L A</forename><surname>Valente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Paiva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Methods and Programs in Biomedicine</title>
		<imprint>
			<biblScope unit="volume">170</biblScope>
			<biblScope unit="page" from="53" to="67" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Lung image segmentation using deep learning methods and convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kalinovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Chest X-Ray Image Segmentation Using Encoder-Decoder Convolutional Network</title>
		<author>
			<persName><forename type="first">L</forename><surname>Saidy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Consumer Electronics-Taiwan (ICCE-TW)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="2" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">An Efficient Variant of Fully-Convolutional Network for Segmenting Lung Fields from Chest Radiographs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hooda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sofat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wireless 890 Personal Communications</title>
		<idno type="ISSN">1572-834X</idno>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1559" to="1579" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<author>
			<persName><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hooda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sofat</surname></persName>
		</author>
		<author>
			<persName><surname>Lf-Segnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">A Fully Convolutional Encoder-Decoder Network for Segmenting Lung Fields from Chest Radiographs</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="511" to="529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Convolutional networks and applications in vision</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Farabet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISCAS</title>
		<imprint>
			<biblScope unit="volume">2010</biblScope>
			<biblScope unit="page" from="253" to="256" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Computer-aided detection 900 of multiple sclerosis lesions in brain magnetic resonance images: False positive reduction scheme consisted of rule-based, level set method, and support vector machine</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Arimura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kakeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Magome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yamashita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Toyofuku</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ohki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Higashida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Korogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computerized Medical Imaging and Graphics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="404" to="413" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Localization of hard exudates in retinal 905 fundus image by mathematical morphology operations, in: Computer and Knowledge Engineering (ICCKE), 2012 2nd International eConference on</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G F</forename><surname>Eadgahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pourreza</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="185" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Fully automatic lung segmentation and rib suppression methods to improve nodule detection in chest 910 radiographs</title>
		<author>
			<persName><forename type="first">E</forename><surname>Soleymanpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Pourreza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of medical signals and sensors</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">191</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Automated lung segmentation in digitized posteroanterior chest radiographs</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Armato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Giger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Macmahon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Academic radiology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="245" to="255" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Ehsani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mottaghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Segan</forename></persName>
		</author>
		<title level="m">Segmenting and generating 915 the invisible</title>
		<imprint/>
	</monogr>
	<note>arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<title level="m">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://www.tensorflow.org/" />
		<title level="m">TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="volume">920</biblScope>
		</imprint>
	</monogr>
	<note>Keras. software available from tensorflow.org</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">An introduction to medical statistics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>Oxford, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">The cross-entropy method: a unified approach to combinatorial optimization, Monte-Carlo simulation, and machine learning</title>
		<author>
			<persName><forename type="first">L.-Y</forename><surname>Deng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thirteenth international conference on artificial intelligence and statistics</title>
		<meeting>the thirteenth international conference on artificial intelligence and statistics</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
