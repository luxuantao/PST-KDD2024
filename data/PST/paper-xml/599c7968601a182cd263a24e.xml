<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Learning for Hate Speech Detection in Tweets</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Pinkesh</forename><surname>Badjatiya</surname></persName>
							<email>pinkesh.badjatiya@research.iiit.ac.in</email>
							<affiliation key="aff0">
								<orgName type="institution">IIIT-H</orgName>
								<address>
									<settlement>Hyderabad</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">https://en.wikipedia.org/wiki</orgName>
								<address>
									<settlement>Tay (bot)</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shashank</forename><surname>Gupta</surname></persName>
							<email>shashank.gupta@research.iiit.ac.in</email>
							<affiliation key="aff0">
								<orgName type="institution">IIIT-H</orgName>
								<address>
									<settlement>Hyderabad</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">https://en.wikipedia.org/wiki</orgName>
								<address>
									<settlement>Tay (bot)</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Manish</forename><surname>Gupta</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IIIT-H</orgName>
								<address>
									<settlement>Hyderabad</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<address>
									<region>Microsoft</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">https://en.wikipedia.org/wiki</orgName>
								<address>
									<settlement>Tay (bot)</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IIIT-H</orgName>
								<address>
									<settlement>Hyderabad</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">https://en.wikipedia.org/wiki</orgName>
								<address>
									<settlement>Tay (bot)</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Learning for Hate Speech Detection in Tweets</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3041021.3054223</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Hate speech detection on Twitter is critical for applications like controversial event extraction, building AI chatterbots, content recommendation, and sentiment analysis. We define this task as being able to classify a tweet as racist, sexist or neither. The complexity of the natural language constructs makes this task very challenging. We perform extensive experiments with multiple deep learning architectures to learn semantic word embeddings to handle this complexity. Our experiments on a benchmark dataset of 16K annotated tweets show that such deep learning methods outperform state-of-the-art char/word n-gram methods by ∼18 F1 points.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>With the massive increase in social interactions on online social networks, there has also been an increase of hateful activities that exploit such infrastructure. On Twitter, hateful tweets are those that contain abusive speech targeting individuals (cyber-bullying, a politician, a celebrity, a product) or particular groups (a country, LGBT, a religion, gender, an organization, etc.). Detecting such hateful speech is important for analyzing public sentiment of a group of users towards another group, and for discouraging associated wrongful activities. It is also useful to filter tweets before content recommendation, or learning AI chatterbots from tweets 1 .</p><p>The manual way of filtering out hateful tweets is not scalable, motivating researchers to identify automated ways. In this work, we focus on the problem of classifying a tweet as racist, sexist or neither. The task is quite challenging due to the inherent complexity of the natural language constructsdifferent forms of hatred, different kinds of targets, different ways of representing the same meaning. Most of the earlier work revolves either around manual feature extraction <ref type="bibr" target="#b5">[6]</ref> or use representation learning methods followed by a linear classifier <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4]</ref>. However, recently deep learning methods have shown accuracy improvements across a large number of complex problems in speech, vision and text applications. To the best of our knowledge, we are the first to experiment with deep learning architectures for the hate speech detection task.</p><p>In this paper, we experiment with multiple classifiers such as Logistic Regression, Random Forest, SVMs, Gradient Boosted Decision Trees (GBDTs) and Deep Neural Networks(DNNs). The feature spaces for these classifiers are in turn defined by task-specific embeddings learned using three deep learning architectures: FastText, Convolutional Neural Networks (CNNs), Long Short-Term Memory Networks (LSTMs). As baselines, we compare with feature spaces comprising of char n-grams <ref type="bibr" target="#b5">[6]</ref>, TF-IDF vectors, and Bag of Words vectors (BoWV).</p><p>Main contributions of our paper are as follows: (1) We investigate the application of deep learning methods for the task of hate speech detection. <ref type="bibr" target="#b1">(2)</ref> We explore various tweet semantic embeddings like char n-grams, word Term Frequency-Inverse Document Frequency (TF-IDF) values, Bag of Words Vectors (BoWV) over Global Vectors for Word Representation (GloVe), and task-specific embeddings learned using FastText, CNNs and LSTMs. (3) Our methods beat stateof-the-art methods by a large margin (∼18 F1 points better).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">PROPOSED APPROACH</head><p>We first discuss a few baseline methods and then discuss the proposed approach. In all these methods, an embedding is generated for a tweet and is used as its feature representation with a classifier. Baseline Methods: As baselines, we experiment with three broad representations. (1) Char n-grams: It is the state-ofthe-art method <ref type="bibr" target="#b5">[6]</ref> which uses character n-grams for hate speech detection. (2) TF-IDF: TF-IDF are typical features used for text classification. (3) BoWV: Bag of Words Vector approach uses the average of the word (GloVe) embeddings to represent a sentence. We experiment with multiple classifiers for both the TF-IDF and the BoWV approaches. Proposed Methods: We investigate three neural network architectures for the task, described as follows. For each of the three methods, we initialize the word embeddings with either random embeddings or GloVe embeddings. (1) CNN: Inspired by Kim et. al <ref type="bibr" target="#b2">[3]</ref>'s work on using CNNs for sentiment classification, we leverage CNNs for hate speech detection. We use the same settings for the CNN as described in <ref type="bibr" target="#b2">[3]</ref>. (2) LSTM: Unlike feed-forward neural networks, recurrent neural networks like LSTMs can use their internal memory to process arbitrary sequences of inputs. Hence, we use LSTMs to capture long range dependencies in tweets, which may play a role in hate speech detection. All of these networks are trained (fine-tuned) using labeled data with back-propagation. Once the network is learned, a new tweet is tested against the network which classifies it as racist, sexist or neither. Besides learning the network weights, these methods also learn task-specific word embeddings tuned towards the hate speech labels. Therefore, for each of the networks, we also experiment by using these embeddings as features and various other classifiers like SVMs and GBDTs as the learning method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset and Experimental Settings</head><p>We experimented with a dataset of 16K annotated tweets made available by the authors of <ref type="bibr" target="#b5">[6]</ref>. Of the 16K tweets, 3383 are labeled as sexist, 1972 as racist, and the remaining are marked as neither sexist nor racist. For the embedding based methods, we used the GloVe <ref type="bibr" target="#b4">[5]</ref> pre-trained word embeddings. GloVe embeddings 2 have been trained on a large tweet corpus (2B tweets, 27B tokens, 1.2M vocab, uncased). We experimented with multiple word embedding sizes for our task. We observed similar results with different sizes, and hence due to lack of space we report results using embedding size=200. We performed 10-Fold Cross Validation and calculated weighted macro precision, recall and F1-scores.</p><p>We use 'adam' for CNN and LSTM, and 'RMS-Prop' for FastText as our optimizer. We perform training in batches of size 128 for CNN &amp; LSTM and 64 for FastText. More details on the experimental setup can be found from our publicly available source code 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results and Analysis</head><p>Table <ref type="table" target="#tab_0">1</ref> shows the results of various methods on the hate speech detection task. Part A shows results for baseline methods. Parts B and C focus on the proposed methods where part B contains methods using neural networks only, while part C uses average of word embeddings learned by DNNs as features for GBDTs. We experimented with mul-2 http://nlp.stanford.edu/projects/glove/ 3 https://github.com/pinkeshbadjatiya/twitter-hatespeech As the table shows, our proposed methods in part B are significantly better than the baseline methods in part A. Among the baseline methods, the word TF-IDF method is better than the character n-gram method. Among part B methods, CNN performed better than LSTM which was better than FastText. Surprisingly, initialization with random embeddings is slightly better than initialization with GloVe embeddings when used along with GBDT. Finally, part C methods are better than part B methods. The best method is "LSTM + Random Embedding + GBDT" where tweet embeddings were initialized to random vectors, LSTM was trained using back-propagation, and then learned embeddings were used to train a GBDT classifier. Combinations of CNN, LSTM, FastText embeddings as features for GBDTs did not lead to better results. Also note that the standard deviation for all these methods varies from 0.01 to 0.025.</p><p>To verify the task-specific nature of the embeddings, we show top few similar words for a few chosen words in Table 2 using the original GloVe embeddings and also embeddings learned using DNNs. The similar words obtained using deep neural network learned embeddings clearly show the "hatred" towards the target words, which is in general not visible at all in similar words obtained using GloVe.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CONCLUSIONS</head><p>In this paper, we investigated the application of deep neural network architectures for the task of hate speech detection. We found them to significantly outperform the existing methods. Embeddings learned from deep neural network models when combined with gradient boosted decision trees led to best accuracy values. In the future, we plan to explore the importance of the user network features for the task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison of Various Methods (Embedding Size=200 for GloVe as well as for Random Embedding)</figDesc><table><row><cell></cell><cell>Method</cell><cell>Prec Recall F1</cell></row><row><cell></cell><cell>Char n-gram+Logistic Regression [6]</cell><cell>0.729 0.778 0.753</cell></row><row><cell>Part A: Baselines</cell><cell>TF-IDF+Balanced SVM TF-IDF+GBDT BoWV+Balanced SVM</cell><cell>0.816 0.816 0.816 0.819 0.807 0.813 0.791 0.788 0.789</cell></row><row><cell></cell><cell>BoWV+GBDT</cell><cell>0.800 0.802 0.801</cell></row><row><cell></cell><cell>CNN+Random Embedding</cell><cell>0.813 0.816 0.814</cell></row><row><cell>Part B: DNNs Only</cell><cell>CNN+GloVe FastText+Random Embedding FastText+GloVe LSTM+Random Embedding</cell><cell>0.839 0.840 0.839 0.824 0.827 0.825 0.828 0.831 0.829 0.805 0.804 0.804</cell></row><row><cell></cell><cell>LSTM+GLoVe</cell><cell>0.807 0.809 0.808</cell></row><row><cell>Part C: DNNs + GBDT Classi-fier</cell><cell cols="2">CNN+GloVe+GBDT CNN+Random Embedding+GBDT FastText+GloVe+GBDT FastText+Random Embedding+GBDT 0.886 0.887 0.886 0.864 0.864 0.864 0.864 0.864 0.864 0.853 0.854 0.853 LSTM+GloVe+GBDT 0.849 0.848 0.848 LSTM+Random Embedding+GBDT 0.930 0.930 0.930</cell></row><row><cell cols="3">(3) FastText: FastText [2] represents a document by aver-</cell></row><row><cell cols="3">age of word vectors similar to the BoWV model, but allows</cell></row><row><cell cols="3">update of word vectors through Back-propagation during</cell></row><row><cell cols="3">training as opposed to the static word representation in the</cell></row><row><cell cols="3">BoWV model, allowing the model to fine-tune the word rep-</cell></row><row><cell cols="2">resentations according to the task.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Embeddings learned using DNNs clearly show the "racist" or "sexist" bias for various words.</figDesc><table><row><cell>Target</cell><cell cols="5">Similar words using GloVe Similar words using task-</cell></row><row><cell>Word</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>specific embeddings learned</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>using DNNs</cell></row><row><cell cols="5">pakistan karachi, pakistani, lahore,</cell><cell>mohammed, murderer, pe-</cell></row><row><cell></cell><cell cols="4">india, taliban, punjab, is-</cell><cell>dophile, religion, terrorism,</cell></row><row><cell></cell><cell cols="2">lamabad</cell><cell></cell><cell></cell><cell>islamic, muslim</cell></row><row><cell>female</cell><cell>male,</cell><cell>woman,</cell><cell cols="2">females,</cell><cell>sexist, feminists, feminism,</cell></row><row><cell></cell><cell cols="4">women, girl, other, artist,</cell><cell>bitch, feminist, blonde,</cell></row><row><cell></cell><cell cols="2">girls, only, person</cell><cell></cell><cell></cell><cell>bitches, dumb, equality,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>models, cunt</cell></row><row><cell cols="5">muslims christians, muslim, hindus,</cell><cell>islam,</cell><cell>prophet,</cell><cell>quran,</cell></row><row><cell></cell><cell>jews,</cell><cell>terrorists,</cell><cell></cell><cell>islam,</cell><cell>slave, jews, slavery, pe-</cell></row><row><cell></cell><cell>sikhs,</cell><cell cols="2">extremists,</cell><cell>non-</cell><cell>dophile, terrorist, terror-</cell></row><row><cell></cell><cell cols="2">muslims, buddhists</cell><cell></cell><cell></cell><cell>ism, hamas, murder</cell></row><row><cell cols="6">tiple classifiers but report results mostly for GBDTs only,</cell></row><row><cell cols="3">due to lack of space.</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Hate Speech Detection with Comment Embeddings</title>
		<author>
			<persName><forename type="first">N</forename><surname>Djuric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Grbovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Radosavljevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bhamidipati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="29" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.01759</idno>
		<title level="m">Bag of Tricks for Efficient Text Classification</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Convolutional Neural Networks for Sentence Classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Abusive Language Detection in Online User Content</title>
		<author>
			<persName><forename type="first">C</forename><surname>Nobata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="145" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">GloVe: Global Vectors for Word Representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hateful Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Waseem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="88" to="93" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
