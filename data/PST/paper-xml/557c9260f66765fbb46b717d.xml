<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">790D650E89A4E81CD7BCF7F2DF03F707</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Signal Enhancement-A Composite Property Mapping Algorithm</head><p>Abstract-A signal enhancement algorithm is developed which seeks to recover a signal from noise-contaminated distorted measurements made on that signal. This ob,ject is achieved bj utilizing a set of properties which the signal is known o r is hypothesized as possessing. The measured signal is modified to the smallest degree necessary so as to sequentially possess each of the individual properties. Conditions for the algorithm's convergence are established in which the primary requirement is that a composite property mapping be closed. This is a relatively unrestrictive condition in comparison to that required of most existing signal enhancement algorithms.</p><p>One of the more interesting and important uses of signal enhancement is concerned with applications in which the signal being enhanced is represented in a data or correlation matrix format. I n such applications, the eigencharacterization and structure (e.&amp;, Toeplitz) of the matrix often provides useful signal properties. Several important property mappings for finding a matrix that possesses a specified linear structure or eigencharacterization and which lies closest to a given matrix are developed. It is shown that each of these property mappings is closed and can therefore be used as candidate property mappings in the proposed signal enhancement algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION signal processing problem of considerable interdis-</head><p>A ciplinary interest is concerned with the task of recovering a signal from a noise-contaminated distorted measurement made on that signal. The measured signal can take on such distinctive forms as being a series of discrete-time signal observations set of autocorrelation lag estimates sampled two-dimensional image excitation-response observations made in a system It often happens that the underlying signal is known to possess certain well-defined attributes or properties. The issue addressed in this paper is that of using these signal properties so as to achieve a superior signal enhancement relative to existing methods. Conceptually, a signal enhancement is accomplished through the process of slightly modifying the measured signal so that the modified signal possesses the prescribed theoretical properties. Intuitively, this enhanced signal would provide a better representation of the underlying signal than did the original identification application. measured signal. A systematic signal enhancement algorithm that achieves this signal property matching is developed in Sections 11-IV. It is shown that the proposed algorithm's convergence is dependent on the signal properties being associated with closed operators, a relatively unrestrictive requirement.</p><p>The proposed signal enhancement algorithm can be an effective tool for both standard and nonstandard signal processing applications. Its true utility is dependent on the user's ability in selecting signal properties which characterize a given application. To illustrate this point, the problem of finding a symmetric sequence with nonnegative Fourier transform that lies closest to a given sequence is addressed in Section V . The ability to achieve such approximations is useful in digital filter synthesis and spectral analysis tasks. Application of the signal enhancement algorithm to this problem results in an efficient iterative approximating procedure.</p><p>One of the more interesting and important uses of the signal enhancement algorithm is made with respect to applications in which the measured data are represented in the form of a matrix. The significance of such applications can be appreciated by noting the frequent appearance of data and correlation matrices in signal process problems. The underlying matrix is frequently known to possess certain theoretical properties such as having a Toeplitz structure, being positive semidefinite, or having a prescribed eigencharacterization. The measurement process, however, usually results in a matrix which fails to possess all (or any) of these properties. Techniques are developed in Sections VI-VI11 for finding a matrix that possesses the prescribed properties which lies closest to the given measured matrix. These concepts are put to use in Section IX where the direction-of-arrival array processing application is examined. It is there shown that the signal enhancement enables the widely used MUSIC array processing algorithm to produce effective bearing estimations in a signal-to-noise environment 5-10 dB lower than would have been otherwise possible. The modeling of data by a sum of exponential signals using the signal enhancement algorithm is treated in Section X.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">FUNDAMENTAL CONCEPTS</head><p>To make the signal enhancement development widely applicable, it is posed in a general metric space setting [81. A metric space is a pair ( X , d ) in which X is a set of elements and d ( x , y ) is a metric that measures the dis-0096-351 818810100-0049$01 .OO O 1988 IEEE tance between any two elements x and y of the set X. For the purposes of this paper, the elements of the metric space are referred to as signals and may consist of such entities as the set of all real or complex valued n-tuples as typifying many standard signal processing applications the set of real or complex valued tn X 12 matrices which appear in such applications as spectral analysis, image processing, and signal processing continuous time versions of the above signal formats.</p><p>Whatever the case, it is postulated that the signal to be recovered possesses a set of well-defined properties. These properties in turn induce associated sets in the signal set X as the following definition formalizes and Fig. <ref type="figure">1</ref> illustrates.</p><p>Definition 1: Let ( X , d ) denote a metric space whose elements x are referred to as signals. Furthermore, let the property sets Sk be specified by sk = { x E X: x possesses property P,:</p><formula xml:id="formula_0">3 for 1 I k I M . ( 1 )</formula><p>The set of signals in X which possess the M properties P I , P 2 , . . * , P, is then given by the set intersection s = s , n s 2 n . . . ns,.</p><p>(</p><p>sumed to be nonempty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>0</head><p>S is referred to as the composite property set and is as-In many studies, the signal set Xis restricted to be either an inner product space or a normed vector space in order to render a relatively straightforward analysis. This approach is not adopted here since it is unnecessary for the developments that follow. By taking this less restrictive approach, the resultant signal enhancement procedure is applicable to a broader and more relevant class of signal enhancement problems that encompass inner product and normed vector space interpretations as special cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . Futidatnt~ntul Sigrid Enhnncrrnent Problem</head><p>As suggested earlier, we are concerned with applications in which there is given a measurement signal x that should theoretically lie in the composite property set S. Inevitable instrumentation error, however, usually results in the measured signal lying outside S. If this measurement error is reasonably small, an appealing procedure for approximating the underlying signal would be to find a signal in S which lies closest to the measured signal x. This auxiliary (enhanced) signal would then possess the desired properties (or attributes) and "be close" to the measured signal. Intuitively, this enhanced signal would more accurately portray the salient characteristics of the underlying signal. An enhanced signal is then formally obtained by solving the optimization problem inf d ( x , y )</p><p>( 3 ) in which "inf" denotes the greatest lower bound operator. Unfortunately, for many useful selections of the signal properties, a solution to this optimization problem is intractable. This is due to the requirement that the solution must simultaneously lie in each of the property sets SI, s2, * . . , S, and this set intersection can be extremely complex (e.g., it is often nonconvex). In such cases, it is necessary to appeal to algorithmic procedures for obtaining an approximation of an optimal solution. An algorithm which is effective in this regard is now presented.</p><formula xml:id="formula_2">y t s</formula><p>111. SIGNAL PROPERTY MAPPINGS From problem definition ( 3 ) , it is clear that the nature of an optimum solution is closely linked to the individual property sets S, which constitute the composite property set S. In order to render a tractable solution procedure, it is beneficial to decompose the original problem into M subproblems related to each of the individual property sets. In particular, let us consider the generally much simpler task of finding those signals in the set SI, which lie closest to an arbitrary signal In what follows, it is convenient to interpret Fk( * ) as being a mapping (operator) that maps the signal x into the solution set F k ( x ) , that is,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fh x + F ~( x ) .</head><p>( 5 )</p><p>This mapping interpretation is shown in Fig. <ref type="figure" target="#fig_3">2</ref> where the diagonal lined portion of S, designates the solution set Fk ( x ) . It is tacitly assumed that signal property P, and metric d a r e such that at least one solution to optimization problem (4) exists (i.e., F k ( x ) is nonempty). A uniqueness of solution requirement, however, is not imposed since that would unnecessarily restrict the types of signal properties which could be considered. As such, property mapping F, is unusual in that it need not be the standard point-to-point variety found in most mathematical applications. More generally, FA is a point-to-set mapping.  Using this signal mapping approach, there is then generated the set of property mappings Fl, F2, . . ' , F M ( 6 )</p><p>with each mapping related to one of the M original signal properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . Composite Property Mapping</head><p>In the signal enhancement algorithm to be described in the next section, the composite property mapping plays a dominant role. This mapping is composed of a sequential application of the individual signal property mappings as specified by</p><formula xml:id="formula_3">F = F M * * . F,F,.<label>(7)</label></formula><p>Application of this mapping to a general signal x is to be interpreted in the standard fashion whereby the solution sets F l ( x ) , F 2 ( F I ( x ) ) , F 3 ( F 2 ( F 1 ( x ) ) ) , etc., are sequentially determined. The composite property mapping F is generally also a point-to-set mapping. It should be noted that any ordered arrangement of the M signal property mappings F , , F2, . . . , FM could have been used in forming the composite mapping F (e.g., F2 F I * * * FM ). Since the property mappings are typically not commutative, each of the M ! reordered mappings generally produces its own distinctive composite property mapping. It may happen that some ordered combinations are superior to others insofar as the performance of the signal enhancement algorithm to be described is concerned.</p><p>By interpreting the elementary property mappings as being point-to-set mappings, we are able to use the considerable power of the general theory of algorithms as developed by Zangwill <ref type="bibr">[12]</ref>. In Zangwill's approach, the notion of a closed mapping for point-to-set mappings plays a prominent role. The notion of a closed mapping is a imply y E F ( x ) . The point-to-set mapping F is said to be closed on the set XI if it is closed at each point of XI The right-directed arrow notation appearing in this definition designates vector sequence convergence. It is interesting to note that when F is a point-to-point mapping, then continuity of F at x implies that F is closed at x but the converse need not follow. Since the requirement that composite property mapping F be closed plays such a fundamental role in the signal enhancement algorithm, it is appropriate that we examine conditions on the individual 5gnal property mappings which ensure this requirement. This can be a particularly demanding task for many relatively complex behaved signal property mappings. Fortunately, the following two corollaries can considerably ease this burden. A proof of these corollaries is found in [6] and <ref type="bibr">[12]</ref>.</p><p>Lemma I : Let F,: X 2 + X , and F2: XI + X2 be pointto-set mappings. If F2 is closed at x, F , is closed on F 2 ( x ) and X2 is compact, then the composite mapping F I F2 is closed at x. 0 Lemma 2: Let F,: X2 + X , be a point-to-set mapping and F2: XI + X 2 be a point-to-point mapping. If F2 is continuous at x and F , is closed on F2 ( x ) , then the com-0 IV. SIGNAL ENHANCEMENT ALGORITHM In the study of algorithms, the concept of a mapping's fixed point is fundamental. Although the notion of fixed points is usually associated with operators that are oneto-one, it is directly extended to one-to-many operators. Specifically, the element x is ajxedpoint of the mapping F if x E F ( x ) . It is to be further noted that if x E S, then x is a fixed point of the composite property mapping F. With this in mind, algorithms used for finding fixed points of operators are logical candidates for finding an approximate solution to optimization problem (3). The following theorem describes conditions under which the method of successive corrections can be used for obtaining an approximate solution.</p><p>Theorem I : Let the point-to-set composite property mapping F be closed and distant reducing relative to a reference signal x, E S. Furthermore, let the set { y E X : <ref type="figure">d ( y ,</ref><ref type="figure">x,</ref><ref type="figure" target="#fig_0">) I d ( x ,</ref><ref type="figure">x,</ref>)) define a closed and bounded set where x denotes the signal to be approximated by an element in S. Finally, consider any signal sequence as generated according to the algorithmic rule posite mapping F , F2 is closed at x. generalization of the concept of continuity as applied to</p><formula xml:id="formula_4">xk E F ( x ~-~) fork 2 1 ( 8 )</formula><p>standard point-to-point mappings. As is shortly shown, convergence of the proposed signal enhancement is dependent on the composite property mapping F being closed. With this in mind, the following definition of closed mapping is offered [6], [ 121. Dejnition 2: Let F be a point-to-set mapping of the set X into itself. F is said to be closed at the point x E X if the assumptions</p><formula xml:id="formula_5">Xk + X J'k + J' with Xk E x with J', E F ( X k )</formula><p>in which the initial signal xo used in this iteration is taken to be x. It then follows that any sequence so generated contains a subsequence which converges to an element of 0 A proof of this theorem is obtained by a direct application of Zangwill's Global Convergence Theorem in which the continuous metric functional d ( y , x,) plays the role of the continuous function Z there employed [ 121. It is important to appreciate the fact that if F is a point-toset mapping, then the signal sequence { xk } generated by the composite property set S.</p><p>the rule (8) is not unique. Nonetheless, we are assured that any sequence so generated always contains a subsequence which converges to a signal in S. It is worthwhile to note that in all signal enhancement applications tried to date, it has been found that the entire sequence converges. As in all descent-type algorithms, however, this signal need not be a solution to the original optimization problem ( 3 ) .</p><p>The convergence conditions spelled out in this theorem are not very restrictive insofar as many standard and nonstandard signal processing problems are concerned. This will be illustrated by the practical applicatipns treated in Sections V, IX, and X . It is interesting to note that signal enhancement algorithm (8) includes many widely used signal enhancement algorithms as special cases. For example, the convex projection algorithm of Youla-Webb requires that the signal property sets S, be restricted to be closed and convex and the metric d to be an inner product [ l l ] . As is shortly shown, however, the ability to use nonconvex sets is essential in many important signal processing applications. Another feature which distinguishes the proposed algorithm from other signal enhancement procedures is the ability to use an other than inner product metric measure. This can provide a useful degree of flexibility in certain applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CLOSEST POSITIVE SEQUENCE APPLICATION</head><p>The signal enhancement algorithm can be applied to a surprisingly large number of important signal processing problems. This usually entails some degree of ingenuity on the user's part insofar as identifying the specific signal properties that apply to a given problem. To illustrate this point, we now study the important problem of finding a sequence that has a nonnegative Fourier transform which lies closest to a given sequence [ l ] . Positive sequences play a fundamental role in such applications as filter synthesis, data windowing, and spectral analysis. A sequence is said to be positive if its Fourier transform is nonnegative real for all frequencies. The realness requirement indicates that a necessary but not sufficient condition for a sequence to be positive is that it be conjugate symmetric</p><formula xml:id="formula_6">[i.e., x( -n ) = x(n)].</formula><p>The importance of a positive sequence arises from the fact that its Fourier transform may always be factorized as</p><formula xml:id="formula_7">X( w ) = A ( w ) A* ( w ) = 1 A ( w ) I*,</formula><p>where A ( w ) designates the Fourier transform of a strictly causal sequence. Considerable interest has been directed toward finite length positive sequences. General tests for the nonnegativeness of such Fourier transforms are very involved and computationally intensive for relatively moderate sequence lengths.</p><p>We shall now apply the signal enhancement algorithm (8) to the task of finding a length 2q + 1 positive sequence that closely approximates a given 2q + 1 length nonpositive sequence. In this development, it is beneficial to embed the problem into the subspace of conjugate symmetric sequences of length N or less in which the length parameter N is selected to be much larger than 2q + 1 .</p><p>This subspace is denoted by CSN, and every sequence in CSN can be uniquely represented as an N X 1 vector, that is, <ref type="bibr" target="#b8">( 9 )</ref> where the conjugated elements appearing on the right side of this vector correspond to the negative time elements.</p><formula xml:id="formula_8">x = [ x ( O ) , x( l ) , x ( 2 ) , * * -, x ( 2 ) , x( l ) ] '</formula><p>A conjugate symmetric sequence of length 2q + 1 would have N -2q -1 of its middle elements zero in this representation.</p><p>The primary reason for using representation (9) arises from the fact that the N-point discrete Fourier transform (DFT) of any conjugate sequence of length N o r less may be computed using the standard relationship</p><p>In this expression, F N designates the N X N Fourier transform matrix with elements <ref type="bibr" target="#b8">9)</ref>. The N x 1 Fourier coefficient vector X is guaranteed to be real since x is here restricted to be conjugate symmetric. A necessary condition for a conjugate symmetric sequence to be positive is that each component of its DFT X be nonnegative. This is a consequence of the fact that the kth component of X corresponds to the sequence's Fourier transform evaluated at frequency w = 27rk/N for 0 I k I N -1. With this in mind, it follows that the nonnegativeness of X becomes a necessary and sufficient condition for the positiveness of a conjugate symmetric sequence x as N approaches infinity. In what is to follow, it is assumed that N has been chosen sufficiently large so that the nonnegativeness of X provides a satisfactorily accurate test for x to be a positive sequence.</p><formula xml:id="formula_9">F N ( k , n ) = exp ( -j 2 7 r [ k - 11 [ n -1 ] / N ) for 1 I k , n I N while x designates a general length N conjugate symmetric sequence of form<label>(</label></formula><p>The following two properties as applied to conjugate symmetric sequences are used in the signal enhancement algorithm:</p><formula xml:id="formula_10">X = FNx.</formula><p>(10) P 1: sequence is of length 2q + 1 P 2 : sequence is positive.</p><p>Using the standard Euclidean norm measure in vector space CSN, the property mapping characterizations for these properties are readily obtained. In particular, the unique length 2q + 1 conjugate symmetric sequence which lies closest to a general N length conjugate symmetric sequence x is found to be</p><formula xml:id="formula_11">F , x = [x(O), . * * ,x(q), o,o, 0, . -* , 0, 0 , 0, x(q), . . , x( l ) ] ' . (11)</formula><p>Namely, all components of { x ( n ) } with index magnitudes larger than q are set to zero. In a similar fashion, the unique positive conjugate symmetric sequence which lies closest to a general N length conjugate symmetric sequence x is given by</p><formula xml:id="formula_12">F2x = F , ' [ F N x ] + = F,' [XI'.</formula><p>In this expression, the N X 1 vector [ F N x ] + has its components specified by in which X = FNx designates the DFT of the length N conjugate symmetric sequence x while the function sgn ( a ) equals one if the real number CY is positive and is minus one otherwise.</p><p>In accordance with the results of the last section, it is readily established that the composite property mapping Fl F2 satisfies the requirements outlined in Theorem 1 for a convergent signal enhancement algorithm. The desired signal enhancement algorithm associated with the length 24 + 1 positive sequence approximation is then given by</p><formula xml:id="formula_13">xk = Fl F2xk-I for k I 1. (<label>14</label></formula><formula xml:id="formula_14">)</formula><p>In this algorithm, the initial vector x, is generated from the original length 24 + 1 conjugate symmetric sequence being approximated in which N -24 -1 zeros are inserted.</p><p>Numerical Example: To illustrate the importance and effectiveness of algorithm (14), we shall now apply it to data windows which are used extensively in the signal processing of experimental data. In particular, the data being analyzed are often multiplied by a data window to achieve desired effects. Ideally, the data window should have a positive Fourier transform. Unfortunately, most of the commonly used windows (e.&amp;., rectangular, Hamming, Hanning, etc.) are not so characterized. By applying algorithm (14) to such a window, however, it is possible to find an approximating window that has a positive Fourier transform. To illustrate this concept, let us consider the symmetric Hanning window of length 21 as specified by</p><p>x ( n ) = 0.5 + 0.5 COS ( a n / l O ) for -10 I II I 10.</p><p>Values of this window for 0 I n 5 10 are listed in Table <ref type="table" target="#tab_1">I</ref>, and its Fourier transform is given by the solid line plot shown in Fig. <ref type="figure">3</ref> . This transform is seen to take on negative values over certain frequency intervals. We shall now use the proposed signal enhancement algorithm (14) to find a length 21 positive sequence which closely approximates the above nonpositive Hanning sequence. Upon setting N = 512, application of this signal enhancement algorithm to the above length 2 1 sequence is found to produce the positive approximating sequence given in Table <ref type="table" target="#tab_1">I</ref>. The algorithm converged in 10 iterations. This sequence is identical to that found using a much more complex gradient based algorithm specifically developed for finding closest approximating positive sequences [ 11. The Fourier transform of this approximating sequence is given by the dashed curve displayed in Fig. <ref type="figure">3</ref> which is seen to be positive as required. As examples, the excitation-response matrix found in system identification, the data matrix used in linear prediction and exponential modeling applications, and the correlation matrix found in various signal processing applications each fall into this category. Typically, the underlying matrix is known to possess certain characteristic properties such as having a Hermitian-Toeplitz structure, possessing a prespecified rank, or being positive semidefinite. Due to measurement noise and other effects, the empirically generated matrix almost always fails to possess all (or any) of the theoretical properties. It would therefore be useful to find a matrix which possesses the specified structure or eigencharacterization and that lies closest to the given matrix. In this and the next section, a number of relevant matrix properties and their associated matrix (signal) property mappings are investigated. It is shown that each of these norm reducing mappings is closed and can therefore be used as a component of a convergent signal enhancement algorithm. A formal definition of the matrix signal set to be studied is now given.</p><p>Dejnition 3: The metric space C"' I' consists of all m X n complex valued matrices on which the Frobenius metric is used to measure the distance between any two m X n matrices X and Y. The distance between any matrix X and the reference zero matrix is designated by This distance measure is commonly referred to as the Fro-0 It is worthwhile to note that although the results to be now presented are directed toward complex valued matri-benius norm (or size) of matrix X . ces, they are readily simplified for the case of real valued matrices. This generally entails replacing any complex conjugate transpose operations ( * ) that appear by transpose operations ( ' ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . Subset of Matrices with a Given Rank</head><p>In a variety of applications, the underlying physical attributes dictate that a given matrix should possess a prescribed rank. The widely employed singular value decomposition (SVD) representation provides a particularly useful tool for characterizing this class of matrices [4], <ref type="bibr">[IO]</ref>.</p><p>Theorem 2: Let S'"' denote the closed nonconvex set of rn x n matrices contained in C" which have rank p or less wherep I min ( m , n ) . Let X be an arbitrary matrix in C" " whose singular valued decomposition (SVD) is given by</p><formula xml:id="formula_15">r x = c ukukv; k = I</formula><p>where r = min ( m , n ) , the uk are real nonnegative singular values which are ordered in the monotonically nonincreasing fashion Uk 2 uk+ I , and the uk and vk are the corresponding m X 1 and n X 1 orthonormal left and right singular vectors, respectively. It then follows that if up # u p + l , the unique matrix X ( p ) of rank p or less contained in S'p' that lies closest to X in the minimum Frobenius norm sense is given by the property mapping</p><formula xml:id="formula_16">X ( P ) = F ' P ' ( X )</formula><p>The property mapping F'p' is a continuous (and therefore closed) point-to-point mapping at all matrices whose singular values satisfy up # up + I . When up is positive and up = up + however, F'p' is a point-to-set mapping that is closed but not continuous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>0</head><p>The fact that S(,) is closed follows from the finite dimension of X , while its nonconvexity is established by noting that the sum of two rankp matrices can have a rank greater than p . Characterizations (18) and ( <ref type="formula">19</ref>) are well known and can be found in various texts (e.g., <ref type="bibr" target="#b3">[4]</ref> and <ref type="bibr">[lo]</ref>). The fact that F'p' is a closed mapping is proven in a companion paper <ref type="bibr">[7]</ref>. A related theorem dealing with the singular value distribution that arises frequently in signal processing applications is now given.</p><p>Theorem 3: Let S ( p ) denote the closed nonconvex set of m x n matrices contained in C" whose smallest r p singular values are equal where r = min ( m , n ). It then follows that for any matrix X in C" whose singular values are such that up # up + , , the unique matrix X,,) contained in S ( p ) that lies closest to X in the minimum Frobenius norm sense is given by the matrix property mapping</p><formula xml:id="formula_17">P I = c ukukv; -u c ukv; (20) k = I k = p + l = c ukukv;. k = I</formula><p>Furthermore, if X is not contained in S ( p j then the norm of X is larger than the norm of X,,). Specifically, ( 18) r Furthermore, if X is not contained in S',', then the norm of X is larger than the norm of X ( p ) , namely,</p><formula xml:id="formula_18">+ 1 [ i . I 2. (22)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>r -p k = , + i</head><p>Finally, the matrix property mapping F(/,) is a continuous (and therefore closed) point-to-point mapping at all matrices whose singular values satisfy a/, # l . On the other hand, F,,, is a point-to-set mapping that is closed but not continuous at all matrices whose singular values 0 To prove this theorem, use is made of the fact that the SVD representation for any matrix X contained in C"' ''I can be expressed as L E V * . In this representation, C is the m x n matrix whose elements are all zero except for its diagonal elements which are equal to the uk singular values, U and X are m x m and n x n orthogonal matrices, respectively, whose columns are the u1 and vk singular vectors. By definition, any matrix X I contained in S,/)) can be represented as UICl V : where C, is an m x n matrix whose elements are all zero except for its diagonals whereby the first p diagonal elements are equal to the p largest singular values of XI and its next r-p singular values are equal to a nonnegative constant. It then follows that IIX -XI IIF = ( 1 uCV* -UICl VT /IF = I/ C -U2CT Vz IjF where U2 = U*Ul and Vz = V * V I are each orthogonal matrices. Finding a matrix in SI,) which lies closest to X is specified by Eo whose elements are all zero except for its diagonals which have the singular values entries specified by (20).</p><p>It is seen that the property mappings F ' " ) and F,/&gt;, are not point-to-point or continuous at matrices whose nonzero pth and p + 1st singular values are equal. Nonetheless, even if these two singular values are theoretically unequal, computational difficulties can still arise. Specifically, if the two eigenvalues a,, and CJ[, + , differ by an amount that is on the order of a computer's precision, an ill-conditioned situation may result. This behavior is one of the primary reasons why resolving two closely spaced (in frequency) sinusoids in additive white noise is such a challenging task. Namely, for this situation, the associated data matrix has its smallest signal singular value almost equal to the noise singular values with this tendency increasing for lower SNR's.</p><p>In the field of spectral estimation as well as in other applications, a square positive semidefinite Hermitian matrix (e.g., the correlation matrix) often plays a central role. With this in mind, the following result is offered.</p><p>Theorem 4: Let H r Z X " denote the subspace of n x n Hermitian matrices and let H + denote the closed convex set of II x n positive semidefinite Hermitian matrices. Any matrix X E H" ' may be represented as satisfy u/) = CJ !, + , in which a,, is nonzero.</p><formula xml:id="formula_19">I1 x = c h k U &amp; ( 2 3 ) k = l</formula><p>where the A1 are the tz real valued eigenvalues of Hermitian matrix X and the uk are their associated eigenvectors. The eigenvalues are arranged in a monotonically nonincreasing fashion ( Ai 2 Ak + I ) with the first ''p" being taken as positive while the remaining n-p are nonpositive. The unique matrix X + contained in H + , which lies closest to X in the Frobcnius norm sense, is then given by the (24) point-to-point mapping for all matrices in H" 'I. Finding that matrix in H C which lies closest to X is then equivalent to finding a matrix in H + which lies closest to E. Using the fact that the diagonal elements of any positive semidefinite matrix are nonnegative real. the closest positive semidefinite matrix approximation to C is readily shown to be the diagonal matrix whose diagonal elements are u, for 1 I k cc p and are zero otherwise. This corresponds to the optimal matrix selection (24).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. LINEAR STRUCTURED MATRICES</head><p>In numerous signal processing and system theory applications, the structural composition of a given class of matrices is of fundamental importance. Intuitively, the notion of matrix structure suggests that the elements of a matrix are interrelated in some prescribed fashion. A formal definition of what we mean by the concept of matrix structure is now given. The matrix class Q. is said to have a structure induced by the functions e ) and to have "p" degrees of freedom.</p><p>If the functions a(,( 0 ) are linear, the matrix set Q. is said to have a linear structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>0</head><p>A number of prominent matrix classes are characterized by a functional relationship of form (25). For example, the class of m X IZ Vandermonde matrices is identified by the nonlinear functions ul, ( e ) = [ 6,]' ~ ' in which the degrees of freedom p = n . On the other hand,the class of m X n Toeplitz matrices is linear, as is readily established by first noting that any Toeplitz matrix is completely identified by knowledge of its first column and first row. If -</p><formula xml:id="formula_20">1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 - on C"' ".</formula><p>With this preliminary development completed, let us now direct our attention to the classes of linear structured matrices. In particular, any linear class may be generated by a matrix operation as the following lemma indicates.</p><p>Lemma 3: Each m x n linear structured matrix set LA with p degrees of freedom may be equivalently expressed as of Hermitian, Hankel, block Toeplitz, Toeplitz + Hankel, etc., matrices each have a linear structure.</p><formula xml:id="formula_21">LA = {X E C m x n : X = T-' ( A % ) for all 8 E C p } A . Matrix Approximation</formula><p>In the development to follow, we shall be concerned with the problem of finding an m X n matrix belonging to a class of linear structured matrices denoted by L that best approximates a given m X n matrix X . A solution to this problem is motivated by the observation that in many practical problems, an underlying matrix should theoretically possess the attributes identifying a linear structured matrix class L. Practical considerations, however, often result in a measured matrix X that does not possess the desired linear structure. As such, a matrix which possesses the prerequisite structure and lies closest to X is sought. A solution to the following optimization problem: provides the required approximation where I/ IIF denotes the Frobenius norm (16). It is possible to employ standard vector analysis methods in solving optimization problem (26). In this approach, matrices are first represented in a column vector format. This representation process makes use of the fact that the vector spaces C"" and C'" " are isomorphic [8]. As such, there exists a one-to-one linear transformation which maps every m X n matrix in C" "I into a unique mn X 1 vector in C"". This mapping consists of a specific ordering (or rearrangement) of the mn components of matrix X into the mn components of its corresponding vector representation x. There exist many such orderings of which the concatenation of columns or rows are the two most popular.'</p><p>If T denotes the specific reordering linear transformation method employed, we then have</p><formula xml:id="formula_22">x = T ( X ) and X = T -l ( x ) . (<label>27</label></formula><formula xml:id="formula_23">)</formula><p>Furthermore, since there is a one-to-one correspondence between the elements of X and x, it follows that T preserves norms in the sense that</p><formula xml:id="formula_24">IIXIIE = IIXIIF<label>(28)</label></formula><p>where 11 x IIE designates the standard Euclidean norm defined on C"" while )) X )IF is the Frobenius matrix norm 'The concatenation of column vectors method is widely employed in which the first ni elements of the vector representation x correspond to the first column of matrix X, the second ,n elements of x correspond to the second column of X , and so forth, that is. r ( i + jtnm ) = X ( i , J ) for 1 5 i 5 m and I 5 j 5 t i .</p><p>(29) where A is an mn x p characteristic matrix of rankp that identifies the linear structured matrix set. All linear structured matrix sets are closed and convex subspaces. Furthermore, the linear matrix subspaces LA and LB are equal if and only if there exists an invertible mn X mn matrix C such that A = CB.</p><p>To prove this lemma, it is noted that by definition every matrix belonging to a specific linear structured matrix subspace has elements which are linear combinations of a p X 1 parameter vector. The matrix A takes the role of the ul,( * a ) functionals in Definition 4 which identify the specific class. Furthermore, the vector 8 is an mn X 1 remesentation of the matrix T -' ( A 0 ) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>\ I</head><p>Example I : To illustrate the concepts of Lemma 3, let us consider the class of 3 x 2 Toeplitz matrices. A general 3 X 2 Toeplitz matrix X, its associated concatenated column vector representation x = T ( X ) , and the corre- where 0 = [ e , O2 O3 O4Ir. From these expressions, it is clear that the entities X and x are equivalent. Moreover, the vector representation x is seen to have four degrees of freedom (i.e., the 8,, 0 2 , 0 3 , 0,) due to the Toeplitz nature of X in which x = A%. 0 With the above concepts in mind, a straightforward procedure for determining the matrix contained in a specified linear structured matrix subspace that lies closest to a general matrix is available. This procedure employs to a general matrix is available. This procedure employs standard vector space approximation methods and is formalized in the following theorem.</p><p>Theorem 5: Let LA designate the closed convex linear structured matrix subspace of C" 'I as generated by the mn x p characteristic matrix A of rank p . The matrix X, E L A which lies closest to an arbitrary matrix X in C" is given by the continuous point-to-point matrix property mapping</p><formula xml:id="formula_25">xA = FA(x) = T-I(A[A*A]-'A*T(X)).<label>(30)</label></formula><p>x, = AIA*A]-lA*x.</p><p>(31 1</p><formula xml:id="formula_26">IIxAIIF = \lxllF ifXELA<label>(32)</label></formula><p>IIXAllF &lt; IIXIIF i f X @ LA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="0">(33)</head><p>Moreover, the vectors associated with the matrices X and XA, as specified by x = T ( X ) and x, = T ( X, ), are related</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Since the linear operator A [ A * A ] -I A * is a projection operator with null space N ( A * ) , it further follows that</head><p>To prove this theorem, let x be the vector representation of the matrix X to be approximated by a matrix in L A . Any vector representation of an element in L, must take the form A8 where 8 E C p . To achieve the desired optimal approximation, it is necessary to select 8 so as to mini-</p><formula xml:id="formula_27">mize 11 x -A8 11 = 11 X -T p 1 ( A 8 )</formula><p>11 where use of identity (28) has been made. Using standard techniques, the optimal choice is found to be 8 = [A*A]-IA*x. The optimal approximating matrix therefore has the vector representation xA = A [A*A]-IA*x. As a practical comment, this vector determination is the most demanding computational task insofar as finding the closest approximating matrix (30). As Example 1 illustrates, however, the A matrix which characterizes many widely employed matrix structures is sparse, thereby leading to a relatively straightforward determination of X,.</p><p>VIII. SUMS OF, AND BLOCK PARTITIONED, LINEAR STRUCTURED MATRICES In various applications, it happens that a matrix under investigation is theoretically composed of either a sum of specific linear structured matrices, or is partitioned into sets of specific linear structured matrices. The following example is given to illustrate these concepts.</p><p>Example 2: Consider the following two matrices:</p><p>" 1 ll "; [:</p><formula xml:id="formula_28">X = 8 2 81 + 42 $3 a n d Y = . 8 3 8 2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="43">$4</head><p>$ 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="42">43</head><p>The 3 x 2 matrix X is the sum of a Toeplitz and Hankel matrix whose underlying 8 x 1 parameter vector is given by 8, = [ e l , 82, 83, 84, 41, $ 2 , 43, $ 4 1 ' . On the other hand, the 4 x 2 matrix Y is a block Toeplitz-Hankel matrix whose underlying 6 x l parameter vector is given by 8, = [ e l , 8 2 , 1 9 ~, 4,, &amp;, &amp; I r . If the 4, are related in a linear fashion to the 8, (e.g., 4, = 28,), the parameter 0</p><p>For applications of the nature of the above example, it is possible to adapt the optimization concepts described in Theorem 5 to treat linear structures of this type. The following two theorems capture the essentials of this approximation.</p><p>Theorem 6: Let Lk designate the closed convex linear structured subspace of C"' 'I as generated by the mn X p characteristic matrix A, of rank p for 1 I k 5 K . Furthermore, consider the set of m x n matrices as governed</p><formula xml:id="formula_29">. X = c A k 8 for8 E C" . (34)</formula><p>This matrix class consists of all m x n matrices which are represented as X = XI + X2 + * + XK in which X, = A,8 for 1 I k I K in which 8 is any vector in Cp. The matrix subspace L A has a linear structure with its mn x p characteristic matrix given by vectors 8, and 8, will be of lower dimension.</p><formula xml:id="formula_30">K 1 by L -A E c m x t i . 4 , = I K A = c A,.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="0">(35) , = I</head><p>A proof of this theorem is a direct consequence of the definition of the matrix set LA as given by expression (29). To find a matrix in L A which lies closest to an arbitrary m X n matrix, one simply uses Theorem 5 in which the characteristic matrix is specified by (35) Theorem 7: Consider the class of m x n matrices L which are partitioned in a prespecified manner with the submatrices composing this partition being designated by XI, x2, -. . , XK. Moreover, let each of these partitioned matrices be represented as X, = A k 8 for 1 I k I K in which 8 is a given p x 1 vector and A , are fixed matrices.</p><p>It then follows that L is a linear structured subspace of dimension p which is induced by the characteristic matrices A,, A 2 , . . . , A,. The matrix x" contained in L which lies closest to an arbitrary matrix X E C" " in the minimum Frobenius sense has partitioned components A , 8 '</p><p>where the vector 8" is specified by</p><formula xml:id="formula_31">1-1 r K 1</formula><p>where X, denotes the mth partition component of the matrix x.</p><p>n</p><p>To prove this theorem, one simultaneously minimizes the Euclidean norm of the error vector xk -A k 8 where xk designates the vector representation of the kth partition matrix X,.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IX. A DIRECTION-OF-ARRIVAL ESTIMATION</head><p>APPLICATION Signal preprocessing forms one of the more important uses of the signal enhancement algorithm. Specifically, . . the signal enhancement algorithm is used to first "clean up" the data being processed, and then a more traditional signal processing method is applied to the enhanced signal. Using this two step procedure, a significant improvement in the performance of standard signal processing methods can be realized. To illustrate this approach, we now consider the standard problem in which the signals measured by an array of sensors are to be used to estimate the direction-of-arrivals of incident plane waves. A variety of signal processing methods have been proposed for solving this problem <ref type="bibr">[ 5 ]</ref> . The eigenspace based MUSIC algorithm serves as one of the most widely employed of the high resolution direction-of-arrival algorithms <ref type="bibr" target="#b8">[9]</ref>. A brief description of the direction-of-arrival problem is now given.</p><p>In the direction-of-arrival problem, an array composed of M sensors and a set of signals x,,, ( t ) measured at each of its sensors for I P m I M is given. The task at hand is to then use these signals to form an estimate of the bearing (i.e., direction) that one or more incident plane waves have with respect to the array. For purposes of simplification, it is assumed that the array is linear and that adjacent sensors are spaced d units apart. If there are p narrow-band plane waves incident on the array, the signals arriving at the nzth array element may be then modeled as PI, 191</p><formula xml:id="formula_32">I'</formula><p>x,,,(t) = X A~ exp ( -j [ w , r + 4, + w , ( m -1)</p><formula xml:id="formula_33">k = 1 . d c o s ( d , ) / c ] ) + w,,,(<label>t) (37)</label></formula><p>for I I m c: M . In this expression, w , designates the common center frequency of the p incident plane waves, A k , Cbl, and dk are their amplitudes, phase angles, and bearing angles, respectively, while c is the medium's propagation velocity and w,,, ( r ) is additive sensor noise that is taken to be white with power u'.</p><p>To perform the signal processing digitally, the p sensor signals are next sampled at the time instants f,, to give rise to the set of discrete-time signals x,,, ( t,,) for 1 P m P M and 1 P n I N . These sampled values are arranged in the M x 1 snapshot vectors format, that is, x(t,,) = [Xl(t,,)&gt; X2(t,r)? . * . 9 X M ( t , J I ' for 1 I n 5 N.</p><p>( 3 8 )</p><p>Using these noise corrupted data, it is desired to obtain an estimate of the number of plane waves impinging on the array (i.e., p ) and also to estimate their corresponding bearing angles (i.e., the 19,). This is typically achieved by forming an estimate of the array's M x M spatial correlation matrix as defined by</p><formula xml:id="formula_34">R = E { . x ( r ) x ( r ) * } (39)</formula><p>where E denotes the expected value operator.</p><p>To properly employ the signal enhancement algorithm, we now make use of properties known to be possessed by the spatial correlation matrix. Specifically, due to the fact the linear array is composed of equispaced sensors and that the p incident plane waves are narrow-band and incoherent, it is well known that the spatial correlation matrix R possesses the following two properties [SI, <ref type="bibr" target="#b8">[9]</ref>: R has its smallest eigenvalue equal to the sensor noise power (T' and this eigenvalue has a multiplicity Mp R is a Hermitian-Toeplitz matrix.</p><p>Although we shall not use this property in the signal enhancement, R is also a positive semidefinite matrix.</p><p>When the MUSIC method 191 is applied to the theoretical spatial correlation matrix R, a perfect identification of the bearing angles is obtained. Unfortunately, when an estimate of the spatial correlation matrix is used, relatively poor bearing estimates can arise. As a result, application of the MUSIC algorithm often yields unacceptably poor bearing estimates. This is particularly true when the sensor noise is large or when some of the incident plane waves have nearly equal bearing angles. Improved MUSIC derived bearing estimates can be achieved, however, by using the signal enhancement algorithm to slightly modify the given spatial correlation matrix estimate so that it possesses the above two ideal properties. Intuitively, this enhanced spatial correlation matrix estimate would form a more compatible approximation of R and therefore lead to superior bearing angle estimates.</p><p>The matrix property mappings that correspond to the above two properties have been described in Sections VI and VII. In particular, the rank p property mapping F" as given in ( <ref type="formula">22</ref>) and the Hermitian-Toeplitz property FA of form (30) correspond to these ideal properties. The characteristic matrix A identifying linear structure mapping FA used in expression (30) is chosen so as to yield the required Hermitian-Toeplitz structure. The signal enhancement algorithm for the bearing estimation problem then consists of the iteration</p><formula xml:id="formula_35">X , = F A F , p , ( X k _ I ) fork r 1 (40)</formula><p>where the initial matrix X,, is specified by a given spatial correlation matrix estimate [ e.g., the standard data matrix product X*X where the columns of X are the snapshot vectors (38)].</p><p>Numerical Example: To test the proposed signal enhancement algorithm, signal model (37) was employed to generate the data to be analyzed. Specifically, the number of incoherent incident plane waves was taken to be p = 2 with each having a unit amplitude and bearing angles of 8 , = 85" and d 2 = 95". The complex valued additive Gaussian white noise variance was selected so that the individual sinusoid signal-to-noise ratio (SNR) was -12 dB. Furthermore, the number of sensors in the array was set at M = 10, with an adjacent sensor separation of d = X / 3 . The number of snapshots was taken to be N = 500, and the uniform sampling scheme was chosen so that w, T equaled 0 . 6 ~.</p><p>Using this data model, the MUSIC algorithm was next In a variety of applications, there is given a measurement signal which characterizes a dynamic phenomenon. Without loss of generality, this signal is assumed to be observed over the time interval 1 I n I N so that the data to be analyzed are specified by</p><p>In theoretical studies, it is often hypothesized that this data segment is perfectly represented as a pth-order exponential signal, that is, employed to form bearing estimates from the standard data matrix product X*X estimate of the spatial correlation matrix. To obtain a measure of statistical repeatability, ten independent generations of the spatial correlation matrix estimate were made, and the ten resultant MUSIC bearing estimates are shown in superimposed fashion in Fig. <ref type="figure" target="#fig_11">4(a)</ref>. From these estimates, the inability to detect the two incident plane waves in any of the ten trial runs is evident. This inability is due to the relatively small number of array sensors and to the high level of additive noise which is manifested in inaccurate spatial correlation matrix estimates.</p><p>To measure the effectiveness of the signal enhancement to overcome this poor performance, algorithm (40) was applied to the same ten spatial correlation matrix estimates to yield enhanced correlation matrix estimates which possess the required properties of having a Hermitian-Toeplitz structure and having all but its largest two eigenvalues equal. Algorithm convergence typically occurred in about ten iterations. These enhanced correlation matrix estimates were then used in the MUSIC algorithm to produce the bearing estimates depicted in Fig. <ref type="figure" target="#fig_11">4(b)</ref>. It is apparent that a resolution of the two incident plane waves was achieved in all ten trial cases. From these results, it is apparent that the signal enhanced version of MUSIC has produced superior results relative to unenhanced MUSIC. and the (Yk and z k are, in general, complex valued. Exponential signal models are appropriate in a variety of situations such as in representing: i) the unit-impulse or unitstep response of a linear time-invariant system; or ii) a segment of the correlation sequence of a rational widesense stationary random process. Whatever the case, a rich theory concerning exponential models is available for analyzing experimentally obtained data. The following two theorems summarize salient features of exponential modeling. Their proofs are dependent on the fact that exponential signals satisfy homogeneous difference equations.</p><p>meorem 8: Let the data x ( n ) for 1 I n I N be a segment of a pth-order exponential signal. If p &lt; m , it then follows that there exists a nontrivial ( m + 1 ) x 1 vector a which satisfies the homogeneous matrix equation</p><formula xml:id="formula_36">x f a = 0 (43)</formula><p>where o is the ( Nm ) X 1 zero vector and X f is the ( N m ) X ( m + 1 ) forward data matrix as specified by</p><formula xml:id="formula_37">[ x ( m + 1) x ( m &gt; x(1) 1 x ( m + 2 ) x ( m -t 1) 9 x(2) x, = 1 . . . "</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L x ( N j x ( N 1 1) e -. x ( N -m )</head><p>This data matrix has Toeplitz structure with rank This theorem may be used to identify the data': constituent exponentials by the two step process of: i) making an SVD of the forward data matrix X, and setting p equal to the number of nonzero singular values; and ii) using the singular vectors of this decomposition to identify the exponentials according to a variety of methods (e.g., the near null space method of 131). In more realistic cases, the data under analysis are not perfectly modeled as a sum of a relatively small number of exponentials. In such situations, the standard approach taken is that of finding a vector a which minimizes the size of the exponential modeling error vector e = X u in some sense (usually a least squares solution procedure). The underlying exponential components are then identified from this a vector. An alternative signal enhancement procedure, which uses the properties of the forward data matrix as spelled out in Theorem 8, will be given shortly. This approach has generally proven more effective than traditional LS methods on examples treated to date.</p><formula xml:id="formula_38">[ X f ] = min ( p , m , N -m ) . Moreover, i f p I min ( m , N -m ) ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . Sum of Real Sinusoids Model</head><p>In applications related to array signal processing and other disciplines, it is often desired to model experimentally obtained data as a sum of real valued sinusoids. Since real sinusoids form a subset of exponential signals, it follows that they may possess additional properties which may be useful in signal processing applications. The following theorem gives some of the more important properties, and its proof is found in 121.</p><p>7'heorem 9: Let the real valued data x ( a ) for 1 I n I N be perfectly represented as a sum of p / 2 real valued sinusoids. If p 5 m , it then follows that there exists a nontrivial ( m + 1 ) X 1 vector a which simultaneously satisfies homogeneous matrix equation X , a = 0 <ref type="bibr">(46)</ref> and (43). In this relationship, X,, is the ( Nm ) x ( m + 1 ) backward data matrix as specified by</p><p>x ( m + 1 ) * .</p><p>x ( m + 2 )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4</head><p>. . . where the wk identify the 0 . 5 ~ sinusoid frequencies and B,,, -p is an arbitrary mp degree polynomial in the z-' variable.</p><p>The above characterization of exponential or sinusoid signals is generally useful in theoretically based studies. In most real world applications, however, it is not possible to model exactly the given data as a sum of a relatively small number of exponentials or sinusoids. Nonetheless, it is still often desired to find a model of this nature which provides a suitably accurate approximation to the given data. In order to shorten our development, we shall explicitly treat only the exponential modeling case. Sinusoidal modeling is treated in an almost identical fashion with the primary distinction being that of replacing rank where x ( n ) is an underlying pth-order exponential signal to be determined, and e ( n ) is an error term that measures the inexactness of the exponential model. This signal composition is next used to form the associated ( N -m ) X ( m + 1 ) measurement data matrix which has form Y = X + E .</p><p>( 5 2 )</p><p>Each of the constituent matrices X and E has a Toeplitz structure for our exponential model with entries x ( n ) and e ( n ) , respectively, of the required structure given in (44).</p><p>The task at hand is to then use the measured data matrix Y to form an estimate of the best approximating exponential data matrix X . The singular values and singular vectors associated with Y play key roles in the estimation procedure to be now described. It is well known that the SVD characterization of any matrix Y is equivalent to the eigencharacterization of the matrix product Y*Y. With this in mind, we find that Y*Y = X*X + X*E + E*X + E*E.</p><p>( 5 3 )</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. I .</head><label>I</label><figDesc>Fig. I . Metric space X and property sets S,. S2. and S,.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>V€SL</head><label></label><figDesc>x. A solution to this problem entails finding signals contained in Sk which solve the optimization problem inf d ( x , y ) . The set of signals contained in property set Sk which solve this optimization problem is called the solution set and is denoted by the symbol F k ( x ) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>x_</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Property set S, and solution set F k ( x )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>N o rrn a 1 i z e d 1'1-equ e n c y Fig. 3 .</head><label>y3</label><figDesc>Fig. 3 . Fourier transform of the Hanning window and its positive sequence approximation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Furthermore</head><label></label><figDesc>, mapping F is a norm reducing continuous This theorem is readily proven by first noting that the SVD representation for any matrix X contained in H" "I can be expressed as UCU* where C is the n x 11 diagonal matrix whose h, eigenvalue diagonal elements are positive for 1 I k I p and nonpositive real for p + 1 I k I r , and U is the n x II orthogonal matrix whose columns are the uk eigenvectors. It then follows that for any matrix Xf contained in H' we have / ( X -X c (IF = 11 E -X T llF where X : = U*X+U is another positive matrix in H + .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Dejnition 4 :</head><label>4</label><figDesc>Let a l , ( 6 , , e2, . . . , 6,) for 1 I i I tn and 1 I j I n be a given set of functions which depend on the parameters ( 6 , , 0 2 , . . . . Of,) in which p I mn.Furthermore, let the class Q. consist of all m x n matrices whose components are governed by the functional relationship 6/11 = ~~( 0 ) for 1 I i I m and 1 I j I 17( 2 5 )    for specific choices of the p parameters ( 6 , , d2. * * . , O / ) ) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>A0 = the first row and first column are specified by the paramrespectively, it then follows that the class of Toeplitz matrices are governed by the linear functions u,(e) = a I + , . , + , ( 0 ) = 8 , + , -, for 1 I i I j 5 n a n d u , ( 8 ) = a f + l j + l ( 0 ) = 8 n + l + J -l f o r 1 ~j 5 i I n. Moreover, this matrix class hasp = m + n -1 degrees of freedom. In a similar fashion, it can be established that the classes eters ( O1, 0 2 , . * * o r , ) and (81, 0,, + I , + 2, . . * 9 e n + r n -i ) ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>sponding 6 X 4</head><label>4</label><figDesc>characteristic matrix A are each specified</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Bearing estimates for two incoherent incident plane waves at bearing angles of 85" and 95" at a -12 dB SNR level.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>m ) x ( Nm -1 ) . . * x ( N ) (47) The forward data matrix is Toeplitz and has rank [ X, ] = min ( p , m , Nm ) while the backward data matrix is Hankel with rank [ X f ] = min ( p , m , Nm ) . All solutions to relationship (43) are solutions to relationship (46) and vice versa. This set of solutions is therefore equivalent to solving the enlarged system of equations I f p I min ( m , N -m ) , then any a solution so the set of homogeneous equations (48) also satisfies the homogeneous matrix equation [X, + X,]a = 0 (49) and vice versa. Moreover, the ( Nm ) X ( m + 1 ) matrix Xr + X,, appearing in this expression has a Toeplitz + Hankel structure and the rank [ X f + X,] = min (O.Sp, m , Nm ) . Furthermore, any solution to homogeneous relationships (48) or (49) will have a z-transform of the form Ill A ( z ) = c a,,z-" If = 0 0.Sp = B , ~-, , ( z ) C [ Iexp ( j w k ) z p I ] k = 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>[ Y ] = p by rank [ Y ] = 0 . 5 ~ and Toeplitz by Toeplitz + Hankel in what is to follow. Let us begin our exponential signal modeling development by considering the case in which the measured data are expressible as v(n) = x ( n ) + e ( n ) (51 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Manuscript rcccivcd January 26. 1987. rcvised July 6, 1987. This work was wpported in part by the SDIOilST and managed by the Office of Naval Research under Contract NOOO14-86-K-0540. The author IS with the Department of Electrical Enginecring. Arizona State University. Tempe. A Z 85287.</figDesc><table /><note><p>IEEE Log Nuniher 87 17669.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I HANNINC</head><label>I</label><figDesc>W I N D O W A N D ITS CLOStST POSITIVE APPROXIMATION</figDesc><table><row><cell>n</cell><cell>Hanning</cell><cell>Approximation</cell></row><row><cell>0</cell><cell>I</cell><cell>1.0337</cell></row><row><cell>1</cell><cell>0.9755</cell><cell>0.9943</cell></row><row><cell>2</cell><cell>0.9045</cell><cell>0.9014</cell></row><row><cell>3</cell><cell>0.7939</cell><cell>0.7755</cell></row><row><cell>4</cell><cell>0.6545</cell><cell>0.63 I 1</cell></row><row><cell>5</cell><cell>0.5</cell><cell>0.4822</cell></row><row><cell>6</cell><cell>0.3455</cell><cell>0.3407</cell></row><row><cell>7</cell><cell>0.2061</cell><cell>0.2169</cell></row><row><cell>8</cell><cell>0.0955</cell><cell>0.1179</cell></row><row><cell>9</cell><cell>0.0245</cell><cell>0.0481</cell></row><row><cell>10</cell><cell>0</cell><cell>0.0089</cell></row><row><cell></cell><cell cols="2">VI. MATRIX RANK PROPERTY MAPPINGS</cell></row><row><cell></cell><cell cols="2">One of the more interesting and useful applications of</cell></row><row><cell cols="3">the proposed signal enhancement algorithm is related to</cell></row><row><cell cols="3">signals which take the form of complex valued matrices.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>polynomial in the z-' variable.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>It is now assumed that the error signal e ( n ) is a zero mean white noise process with variance u 2 which is uncorrelated with the exponential signal x ( n ) . It then follows that the expected value of the matrix product Y*Y is given by</p><p>where X*X is taken to be a deterministic but unknown matrix product. Since X*X has rank p , it can thereby be inferred that the SVD of matrix Y will tend to possess p larger singular values and its m + 1 -p smallest singular values are each equal to u 2 .</p><p>The above-described average SVD properties of measured data matrix Y may be used in conjunction with the signal enhancement concept to estimate the exponential data matrix X. This algorithm takes the form</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>x, = F,F(P)(x~-,)</head><p>in which the initial matrix X, = Y. In this expression, F(p) designates the closest rank p property mapping (18), and FA corresponds to the Toeplitz interpretation of linear structure mapping (30). The effect of this enhancement algorithm is that of removing the error term's influence thereby obtaining a rank b Toeplitz structured data matrix which lies closest to X.</p><p>Numerical Example: To test the effectiveness of enhancement algorithm (54), the following data sequence was used:</p><p>x ( n ) = 15 cos (0.25wn) + 10 cos ( 0 . 7 1 ~~) + e(.)</p><p>In this expression, e ( n ) is additive white Gaussian noise of variance 112.5, thereby giving a largest sinusoidal signal-to-noise ratio of 0 dB. The Fourier transform magnitude versus frequency plot for the sinusoidal signal component (i.e., noise free) is shown in Fig. <ref type="figure">5(a)</ref>. Clearly, the two spectral peaks at frequencies 0 . 2 5 ~ and 0 . 7 1 ~ are prominent. A corresponding plot of the noise contaminated data's Fourier transform is shown in Fig. <ref type="figure">5(b)</ref>. The additive noise is seen to moderately obscure the presence of the lower powered sinusoid signal. Next, the signal enhancement algorithm (54) was applied to the noise contaminated data set. In this algorithm, the A matrix of mapping FA corresponds to the block Toeplitz-Hankel structure (48) because of the real sinusoid model here being used. Similarly, the parameterp = 4 since, for a two sinusoid model, the rank of the block Toeplitz-Hankel data matrix appearing in Theorem 9 is two. The signal enhancement algorithm typically converged within 25 iterations. The Fourier transform of the resultant enhanced data is shown in Fig. <ref type="figure">5(c</ref>). This Fourier transform plot provides a close approximation to the noise-free results shown in Fig. <ref type="figure">5(a)</ref>, thereby demonstrating the effectiveness of the signal enhancement algorjthm. XI. CONCLUSION A signal enhancement algorithm has been presented that makes use of signal properties which an underlying signal is postulated as satisfying. Through use of this algorithm, the possibility of achieving significant improvements in signal processing performance is offered. This potential was demonstrated for the positive sequence approximation, the direct-of-arrival, and exponential modeling problems. It has also been applied to a variety of other applications such as rational spectral estimation, data interpolation, and in one-and two-dimensional filter synthesis, with similarly impressive results. The effectiveness of this algorithm is dependent on the user's ability to identify signal properties that properly characterize the underlying signal being identified. More restrictive properties in general lead to more effective removal of the measurement contamination. Selection of these properties is critical, and ingenuity.on the user's part is important in this regard. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Sequences with positive semidefinite Fourier transforms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Cadzow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust., Speech, Signal Processing</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1502" to="1510" />
			<date type="published" when="1986-12">Dec. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Signal enhancement: Detection of multiple sinusoids in white noise</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Cadzow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987-02">Feb. 1987</date>
			<publisher>ASU Rep</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Spectral estimation: An overdetermined rational model equation approach</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Cadzow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1982-09">Sept. 1982</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="907" to="939" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Van Loan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Matrix Computations</title>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>John Hopkins University Press</publisher>
			<pubPlace>Baltimore, MD</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The application of spectral estimation methods to bearing estimation problems</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Is</surname></persName>
		</author>
		<author>
			<persName><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1018" to="1028" />
			<date type="published" when="1982-09">Sept. 1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Introduction to Linear and Nonlinear Programming</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Luenberger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973">1973</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Continuity of closest rank-p approximations to matrices</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Mittelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Cadzow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust. , Speech, Signal Processing</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="121" to="121" />
			<date type="published" when="1987-08">Aug. 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Si</forename><forename type="middle">A W</forename><surname>Naylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Sell</surname></persName>
		</author>
		<title level="m">Linear Operator Theory in Science and Engineering</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">A signal subspace approach to multiple emitter location and spectral estimation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Schmidt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982">1982</date>
			<pubPlace>Stanford, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Stanford Univ.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Error and perturbation bounds for subspaces associated with certain eigenvalue problems</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Stewart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM R e v</title>
		<imprint>
			<biblScope unit="page" from="727" to="764" />
			<date type="published" when="1973-10">Oct. 1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Image restoration by the method of convex projections: Part 1-Theory</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Youla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Webb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Zanywill, NonLinear Programming: A Unified Approach</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="81" to="94" />
			<date type="published" when="1121">Oct. 1982. 1121. 1969</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
	<note>IEEE Trans. Med. Imaging</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
