<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Heron: Automatically Constrained High-Performance Library Generation for Deep Learning Accelerators</title>
				<funder ref="#_bSMDNgB">
					<orgName type="full">Youth Innovation Promotion Association CAS and Beijing Academy of Artificial Intelligence</orgName>
					<orgName type="abbreviated">BAAI</orgName>
				</funder>
				<funder ref="#_GduJTE3 #_wat5tAj #_B4WwCgq #_QwUrHZM #_CscYU3t #_JYzTpHA">
					<orgName type="full">NSF of China</orgName>
				</funder>
				<funder ref="#_uPqApnr">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jun</forename><surname>Bi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Qi</forename><surname>Guo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xiaqing</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yongwei</forename><surname>Zhao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuanbo</forename><surname>Wen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuxuan</forename><surname>Guo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Enshuai</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xing</forename><surname>Hu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zidong</forename><surname>Du</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ling</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tianshi</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Huaping</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">USTC SKL of processors</orgName>
								<orgName type="institution" key="instit2">ICT</orgName>
								<address>
									<country>CAS Cambricon Technologies China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">SKL of processors</orgName>
								<orgName type="institution" key="instit2">ICT</orgName>
								<address>
									<settlement>Beijing</settlement>
									<region>CAS</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">SKL of processors</orgName>
								<orgName type="institution" key="instit2">ICT</orgName>
								<address>
									<settlement>Beijing</settlement>
									<region>CAS</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">SKL of processors</orgName>
								<orgName type="institution" key="instit2">ICT</orgName>
								<address>
									<settlement>Beijing</settlement>
									<region>CAS</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">SKL of processors</orgName>
								<orgName type="institution" key="instit2">ICT</orgName>
								<address>
									<settlement>Beijing</settlement>
									<region>CAS</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution" key="instit1">USTC SKL of processors</orgName>
								<orgName type="institution" key="instit2">ICT</orgName>
								<address>
									<country>CAS Cambricon Technologies China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution" key="instit1">USTC SKL of processors</orgName>
								<orgName type="institution" key="instit2">ICT</orgName>
								<address>
									<country>CAS Cambricon Technologies China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="institution" key="instit1">SKL of processors</orgName>
								<orgName type="institution" key="instit2">ICT</orgName>
								<address>
									<settlement>Beijing</settlement>
									<region>CAS</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="institution" key="instit1">SKL of processors</orgName>
								<orgName type="institution" key="instit2">ICT</orgName>
								<address>
									<settlement>Beijing</settlement>
									<region>CAS</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<orgName type="department">Institute of software</orgName>
								<address>
									<postCode>CAS</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff10">
								<orgName type="department">Huaping Chen USTC</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff11">
								<address>
									<addrLine>25-29, 15 pages</addrLine>
									<postCode>2023</postCode>
									<settlement>Vancouver, New York</settlement>
									<region>BC, NY</region>
									<country>Canada. ACM, USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Heron: Automatically Constrained High-Performance Library Generation for Deep Learning Accelerators</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3582016.3582061</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>code generation</term>
					<term>compiler optimization</term>
					<term>tensor computation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep Learning Accelerators (DLAs) are effective to improve both performance and energy efficiency of compute-intensive deep learning algorithms. A flexible and portable mean to exploit DLAs is using high-performance software libraries with well-established APIs, which are typically either manually implemented or automatically generated by exploration-based compilation approaches. Though exploration-based approaches significantly reduce programming efforts, they fail to find optimal or near-optimal programs from a large but low-quality search space because the massive inherent constraints of DLAs cannot be accurately characterized.</p><p>In this paper, we propose Heron, a novel exploration-based approach, to efficiently generate high-performance libraries of DLAs.</p><p>The key is to automatically (rather than manually) enforce massive sophisticated while accurate constraints through the entire program generation including constrained space generation and constrained space exploration. By conducting static analysis on compute, sophisticated constraints are automatically generated to properly characterize inherent constraints of DLAs, and thus greatly prune</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Deep Learning Accelerators (DLAs), which offer specialized hardware architecture to greatly improve the efficiency of widely-used deep learning algorithms, have received extensive attention in both academia and industry. In academia, started with DianNao series <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28]</ref>, many DLAs targeting different algorithms <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b56">57]</ref> or with new technologies <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b35">36]</ref> emerge. In industry, DLAs including NVIDIA TensorCore <ref type="bibr">[11]</ref>, Google TPU <ref type="bibr" target="#b43">[44]</ref>, and Cambricon MLU [3], are developed for commercial use.</p><p>To embrace the diversity of DLAs, high-performance software libraries with well-established APIs are served as flexible, portable, and efficient solutions for programmers to exploit high computational abilities. For example, NVIDIA offers CUDA Deep Neural Network library (cuDNN) <ref type="bibr" target="#b8">[9]</ref> to utilize TensorCore, and Intel provides oneAPI Deep Neural Network library (oneDNN) <ref type="bibr" target="#b12">[13]</ref> to leverage DL Boost acceleration <ref type="bibr">[7]</ref>. Unfortunately, these libraries are manually implemented and tuned for high performance, which requires a deep understanding of algorithms, compilers, and hardware architectures with intense human efforts. In practice, the development cycle typically takes months or even years for widely-used DL operators, which cannot meet the stringent time-to-market requirement of hardware and also fall behind the fast evolution of algorithms.</p><p>To reduce development costs, exploration-based compilation approaches <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b70">[71]</ref><ref type="bibr" target="#b71">[72]</ref><ref type="bibr" target="#b72">[73]</ref> have recently emerged as one of the most effective solutions for automatic generation of lowlevel programs of DL operators. The key idea is to formulate the program generation as the exploration in a large space consisting of program candidates, which are built either with manually implemented <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b66">67]</ref> or automatically generated <ref type="bibr" target="#b70">[71]</ref><ref type="bibr" target="#b71">[72]</ref><ref type="bibr" target="#b72">[73]</ref> templates along with multiple tunable parameters (e.g., tiling factors). Despite delivering comparable or even better performance against hand-tuned counterparts on CPUs and GPUs (with CUDA core), these approaches cannot perform efficiently on various DLAs because they fail to find optimal or near-optimal programs in the search space. Taking the convolution layers in VGG-16 <ref type="bibr" target="#b63">[64]</ref> as an example, on TensorCore, state-of-the-art exploration-based approaches such as AutoTVM <ref type="bibr" target="#b25">[26]</ref> cannot find the optimal program in the search space, and the performances of generated programs only achieve 46% of that of cuDNN on average.</p><p>The inefficiency of existing exploration-based approaches stems from low-quality search spaces, which are large but nearly all the program candidates are invalid to meet the architectural constraints of DLAs. Taking the matrix multiply operator of size 32?1000?4096 as an example, about 95% of the total programs generated by Au-toTVM are invalid for TensorCore, though they can be executed on general-purpose architectures such as CPUs and GPUs. The reason is that DLAs typically have inherent architectural constraints and thus impose non-trivial requirements on the programs, e.g., the computational unit of TensorCore has strict requirements on the dimensions of computed matrices, while general-purpose architectures do not have such requirements. To improve the quality of search spaces, it is necessary to accurately constrain the search space by eliminating invalid programs as much as possible.</p><p>However, it is quite difficult to accurately constrain the search space because of the diverse and complicated architectural constraints of DLAs. Figure <ref type="figure" target="#fig_0">1(a)</ref> shows that a search space can be easily regular space with a few simple constraints excludes many valid programs, and (b) an irregular space with massive sophisticated constraints includes all valid programs. The irregular space poses a key challenge to the search algorithms in that such constraints should be preserved during the entire exploration process.</p><p>specified with a few simple constraints, represented by the straight lines, while it excludes many valid programs and the optimal one. To include all valid programs, in Figure <ref type="figure" target="#fig_0">1</ref>(b), the search space can be greatly improved by enforcing hundreds of sophisticated constraints, which requires domain knowledge and expertise to accurately characterize architectural constraints of DLAs by imposing appropriate constraints on computation. In addition to accurately constraining the search space, another key challenge is that all such constraints should be strictly satisfied during the entire exploration process to find the optimal programs efficiently. To address the above challenges, in this paper, we propose an automatically constrained exploration-based approach, i.e., Heron, to generate high-performance libraries for DLAs. The key is to automatically (rather than manually) enforce massive sophisticated while accurate constraints through the entire program generation including constrained space generation and constrained space exploration. During constrained space generation, the first challenge of generating accurate constraints is addressed by conducting static analysis on compute. Specifically, we summarize multiple general rules on variables that are mainly related to key architectural constraints such as requirements of functional units and capacity of on-chip memory and then apply such rules during static analysis to automatically produce both optimization schedules and sophisticated constraints on computation description. During constrained space exploration, the second challenge of exploring the irregular space is addressed by a novel constraint-based genetic algorithm (CGA). Concretely, the original space is formulated as a constraint satisfaction problem (CSP) to generate a set of new CSPs. Then the evolutionary operations (e.g., crossover and mutation) are directly enforced on such CSPs instead of concrete solutions in traditional GAs. Thus, all the initial constraints can be strictly preserved during the entire exploration process to find optimal programs.</p><p>To evaluate Heron, we conduct extensive experiments on 3 representative DLAs, i.e., NVIDIA TensorCore, Intel DL Boost, and TVM Versatile Tensor Accelerator (VTA) <ref type="bibr" target="#b54">[55]</ref>, with a large number of benchmarks (including operators and networks). On TensorCore, compared to 4 state-of-the-art automatic generation paradigms including exploration-based approaches (i.e., AutoTVM <ref type="bibr" target="#b25">[26]</ref>, Ansor <ref type="bibr" target="#b70">[71]</ref>, and AMOS <ref type="bibr" target="#b71">[72]</ref>) and a polyhedral compiler (i.e., AKG <ref type="bibr" target="#b69">[70]</ref>), the performance gains of Heron range from 1.52? to 2.85?, with 1.89? on average. Compared to hand-tuned libraries including cuD-NN/cuBLAS and PyTorch kernel, the performance gains of Heron range from 1.10? to 8.89?, with 2.69? on average. On the DL Boost, compared to AutoTVM, Ansor, and AMOS, the performance gains of Heron range from 2.72? to 12.0?, with 4.57? on average. Compared to hand-tuned libraries such as Intel oneDNN, the performance gains of Heron range from 1.02? to 6.94?, with 1.49? on average. On the VTA, compared to AutoTVM, the performance gains of Heron range from 1.03? to 2.95?, with 2.32? on average. This paper makes the following contributions:</p><p>? Automatic generation of sophisticated constraints. We define multiple rules to automatically generate sophisticated while accurate constraints for obtaining a high-quality constrained search space. ? Constraint-based genetic algorithm. We formulate the space exploration as optimizing a constrained optimization problem with a novel constraint-based genetic algorithm.</p><p>To our best knowledge, this is the first work to conduct the evolutionary process directly on CSPs. ? Comprehensive evaluation. We conduct extensive experiments on 3 representative DLAs, where Heron significantly outperforms both state-of-the-art automatic generation approaches without additional compilation costs and vendorprovided hand-tuned libraries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND AND MOTIVATION 2.1 Deep Learning Compilers</head><p>Deep learning compilers emerge as effective techniques to reduce the development efforts for high-performance programs on DLAs. The basic idea is to translate the original models with various operators to native codes on different hardware platforms. Taking the most representative deep learning compiler, i.e., TVM, as an example, original models first undergo graph-level optimizations such as operator fusion and layout transformation. Then, the optimized models (i.e., graphs) are represented by a declarative tensor expression language, where fine-grained optimizations such as loop tiling can be enforced. Finally, the compiler generates native codes for different back-ends, e.g., CUDA for GPU and assembly for CPU. The fine-grained optimizations in TVM are usually performed via a schedule template consisting of a list of schedule primitives, which are program transformations that generate programs from the input compute (i.e., description of the tensor computation consisting of multiple stages such as the load stage) with various optimizations (e.g., loop tiling). As listed in Table <ref type="table" target="#tab_0">1</ref>, a schedule primitive consists of the stage to be transformed, the related loops of the stage, and various schedule parameters. Some of the schedule parameters (e.g., ?????_? ????? , ??????_??????, and ????????) are tunable for better performance. As a result, the combination of possible schedule templates with their tunable parameters can form an extremely large search space of program candidates.</p><p>Apparently, the key factors to the optimization efficiency are the quality of the search space and the effectiveness of the search algorithms. As stated, the space is mainly determined by the schedule templates, which can be generated either manually <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b66">67]</ref> or automatically <ref type="bibr" target="#b70">[71]</ref><ref type="bibr" target="#b71">[72]</ref><ref type="bibr" target="#b72">[73]</ref>. The well-known search algorithms include random search <ref type="bibr" target="#b25">[26]</ref>, simulated annealing <ref type="bibr" target="#b25">[26]</ref>, and genetic algorithm <ref type="bibr" target="#b70">[71]</ref>. Among these algorithms, we observe that the genetic algorithm is most widely used in state-of-the-art deep learning compilers <ref type="bibr" target="#b70">[71,</ref><ref type="bibr" target="#b71">72]</ref>. The background of the schedule template generation and the genetic algorithm will be elaborated later.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Schedule Template Generation</head><p>As stated, there are two main approaches for generating the schedule templates.</p><p>Manual approaches. These approaches rely on domain experts to manually write schedule templates and specify the range of schedule parameters as well for each compute <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b66">67]</ref>. Then, the compiler searches for the best parameter configuration for given input shapes and hardware platforms. These approaches can provide high-performance program implementations and are flexible to support newly emerged DLAs. However, it takes nontrivial efforts for compiler designers to write schedule templates and such manually-implemented templates usually result in limited search spaces.</p><p>Automatic approaches. These approaches automatically generate schedule templates <ref type="bibr" target="#b70">[71]</ref><ref type="bibr" target="#b71">[72]</ref><ref type="bibr" target="#b72">[73]</ref> to overcome the aforementioned drawbacks of the manual approaches. Typically, these approaches rely on predefined rules to generate the schedule templates along with their tunable parameters' ranges. As one of the most representative approaches, Ansor <ref type="bibr" target="#b70">[71]</ref>, first converts the input compute to a naive program and the corresponding compute graph (i.e., directed acyclic graph, DAG) by directly expanding the loop indices. Then, the naive program is recursively transformed by the derivation rules, which are predefined by compiler designers for general-purpose architectures as listed in Table <ref type="table" target="#tab_1">2</ref>, to generate different schedule templates and related programs. Concretely, Ansor traverses the stages (i.e., nodes of the DAG) in reverse topological order and applies the rules if the conditions (e.g., HasDataReuse(S,i) indicates that the node ? in the current state ? has data reuse opportunity such as matrix multiply) are satisfied, so as to generate new schedule templates and related programs (e.g., perform multi-level tiling for data reusable nodes).</p><p>Compared to the manual approaches, the automatic approaches not only remove the programming burden of schedule templates but also generate larger search spaces that contain more highperformance programs. However, they do not consider the diverse architectural constraints of DLAs and thus are not efficient for the code generation of DLAs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Genetic Algorithm</head><p>Genetic algorithm (GA) is a meta-heuristic algorithm for solving optimization problems. GA solves the problem by simulating it as a population's natural evolutionary process where the parameters to be optimized are encoded as a sequence of variables called chromosome. During optimization, GA randomly samples an initial population of chromosomes as the first generation and then iteratively produces new generations by performing selection, crossover, and mutation on the previous generation until given termination conditions (e.g., a time budget) are met. Finally, the chromosome with the highest fitness score, which measures the quality of represented solutions, is decoded as the optimized parameters.</p><p>GA is widely used in existing exploration-based compilation approaches <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b70">71,</ref><ref type="bibr" target="#b71">72]</ref> for program optimization space exploration. The parameters (i.e., tunable parameters) are first encoded as a chromosome whose fitness score is calculated as the measured <ref type="bibr" target="#b25">[26]</ref> or estimated <ref type="bibr" target="#b70">[71,</ref><ref type="bibr" target="#b71">72]</ref> program performance. In each generation, the chromosomes are selected to survive by the Roulette-wheel selection <ref type="bibr" target="#b36">[37]</ref> which selects chromosomes with probability</p><formula xml:id="formula_0">? ? = ? ? ? ?</formula><p>where ? ? is the fitness score. Offspring chromosomes are then generated by performing crossover (e.g., single point crossover in <ref type="bibr" target="#b25">[26]</ref>) and mutation (e.g., tile size or unroll length mutation in <ref type="bibr" target="#b70">[71]</ref>) and form the new generation combined with their parents.</p><p>Although GA can intuitively optimize the parameters in explorationbased compilation, it does not take the constraints into consideration to guide the exploration process because GA is essentially an unconstrained optimization approach <ref type="bibr" target="#b31">[32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Motivation</head><p>To understand the design principle of Heron, we examine the challenges of defining and exploring the search spaces for DLAs and obtain three key observations as follows. Observation #1: There exists a large number of diverse and complicated architectural constraints in DLAs.</p><p>Table <ref type="table" target="#tab_2">3</ref> lists typical architectural constraints of representative DLAs including TensorCore, DL Boost, VTA, TPU <ref type="bibr" target="#b43">[44]</ref>, and Cambricon <ref type="bibr" target="#b48">[49]</ref>. Obviously, the constraints vary significantly. For example, TensorCore has relatively strict constraints on the dimensions of  matrices while Cambricon relaxes the constraints due to more flexible functional units. The constraints of DLAs stem from limitations of on-chip resources (e.g., scratchpad memory and processing elements) and can be grouped into three categories including computation size (e.g., fixed computation sizes for DL Boost), memory capacity (e.g., limited buffer sizes for VTA), and memory access (e.g., aligned load/store vectorization for TensorCore). If constraints are not satisfied, the generated programs result in a compilation or run-time error which significantly degrades the efficiency of the exploration process. Furthermore, there exists a gap between the architectural constraints and tunable parameters, e.g., the constraints of on-chip memory capacity do not directly associate with tunable parameters, which requires enforcing such constraints on various parameters in an indirect and compositional manner. Hence, the diverse and complicated architectural constraints make it challenging for practitioners to accurately describe the parameter search spaces. Observation #2: High-quality search spaces are hard to be accurately described with a small number of intuitive hand-written constraints.</p><p>To describe the relationship between architectural constraints and tunable parameters, it requires to declare massive variables with complicated constraints. Take the GEMM operator (i.e., ? [?, ?] += ?[?, ? ] * ? [?, ?]) as an example, the computation on TensorCore mainly consists of five stages:</p><formula xml:id="formula_1">global ????? 1 -? shared ????? 2 -? register ????? 3 -? TensorCores ????? 4 -? shared ????? 5 -? global (1)</formula><p>where ????? 1 and ????? 2 are for data loading, ????? 3 is for computation, and ????? 4 and ????? 5 are for storing the results. To describe the architectural constraints, 10 dedicated variables are declared (e.g., ?, ?, ? for the fixed computation size) and the related constraints are specified (e.g., ? * ? * ? == 4096 &amp; ? ? {8, 16, 32} &amp;...). Then, these architectural constraints confine the loop lengths, which requires 82 loop lengths related variables (e.g., ????? 3 .? 6 refers to the length of loop ? 6 at ????? 3 ) with constraints (e.g., ? == ????? 3 .? 6 &amp; ????? 3 .? == ????? 3 .? 6 * ... * ????? 3 .? 0 &amp;...). After that, the loop lengths constrain the choice of tunable parameters, which requires 30 tunable parameter-related variables (e.g., ????.????? 3 .? 6 for the tile size of ????? 3 to generate ? 6 ) with constraints (e.g., ????.????? 3 .? 6 == ????? 3 .? 6 ). Finally, 51 other variables are declared to help describe the constraints (e.g., ? ? {8, 16, 32} is expressed as ? == 8 | ? == 16 | ? == 32 where ? == ? is a boolean variable). In this case, there are 173 variables and 372 constraints in total, and Table <ref type="table" target="#tab_3">4</ref> lists the breakdown of such variables.</p><p>In addition to the GEMM operator, Table <ref type="table" target="#tab_4">5</ref> further lists the number of variables and constraints of other operators for accurately describing the irregular search spaces. The numbers of variables and constraints vary for different operators, e.g., the C3D (3D convolution) operator needs more constraints than the C1D (1D convolution) operator since it is more complicated. Even for the same operator, the constraints are different when the shapes of the input tensors vary. Apparently, writing such massive and sophisticated constraints by hand is infeasible even for domain experts. Observation #3: Existing search algorithms fail to explore such high-quality while irregular search space efficiently.</p><p>Although traditional simulated annealing algorithms (SA) and genetic algorithms (GA) work well in previous work <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b70">71]</ref>, they fail to perform better than a random searching algorithm (RAND) in such high-quality while extremely irregular search spaces. Figure <ref type="figure" target="#fig_1">2</ref>(a) illustrates that SA easily gets stuck at the local optimum at the early stage of exploration, because the valid programs can only be obtained by changing values of less-constrained tunable parameters such as unroll. Figure <ref type="figure" target="#fig_1">2(b)</ref> shows that the exploration process of GA is almost random, because GA fails to generate valid programs after crossover and mutation, which incurs frequent random restarts during exploration. All these inefficiencies stem from not taking the massive constraints into consideration when exploring such irregular search spaces.</p><p>In summary, the above observations motivate us to employ an automatic rather than manual approach to enforce sophisticated while accurate constraints to not only search space generation but also space exploration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DESIGN OVERVIEW</head><p>To automatically enforce constraints through program generation, Heron contains two stages, i.e., generation and exploration, and implements four modules (see Figure <ref type="figure" target="#fig_2">3</ref>), including Space Generator, Space Explorer, DLA Measurer, and Cost Model. The first module is responsible for the generation stage and the other three modules are used for the exploration stage.</p><p>Space Generator. To generate the search space, Space Generator takes the compute as the input and outputs a space defined by tunable parameters and their constraints. Specifically, the Space Generator mainly performs two generation steps including Schedule Template Generation and Constraint Generation using Generation in an irregular search space. The points represent measured performances. RAND randomly samples valid parameter configurations under the constraints using a solver <ref type="bibr" target="#b3">[4]</ref>. GA and SA adopt the same setups as <ref type="bibr" target="#b25">[26]</ref> and use RAND to generate initial valid programs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Schedule Template Generation Constraint Generation</head><p>Generation Rules Rules. The Generation Rules contain special rules for generating the schedule templates and the constraints. Based on the compute, the Schedule Template Generation generates a schedule template consisting of schedule primitives whose tunable parameters form an initial search space. By analyzing the generated schedule primitives, the Constraint Generation then generates massive constraints which can be used to limit the range of the tunable parameters and finally transform the search space into a constrained one. More details are provided in Section 4. Space Explorer. It conducts the exploration in the constrained search space with a constraint-based genetic algorithm (i.e., CGA) to obtain the programs with optimal or near-optimal performance. CGA uses predicted performance numbers as the fitness scores and outputs a set of high-performance programs for hardware measurements. More details of CGA are provided in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Exploration</head><p>DLA Measurer. It measures the accurate performances (i.e., the latency) of the generated programs. Concretely, it measures a single program multiple times to obtain the average execution time as the final performance. To obtain stable performance, Heron conducts such measurement by adopting different configurations for different DLAs. Finally, the measured performance is recorded by Heron for later cost model training.</p><p>Cost Model. It estimates the performance of the programs quickly via different designed features <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b70">71]</ref>. Although the employed cost model (i.e., XGBoost <ref type="bibr" target="#b23">[24]</ref>) is similar to AutoTVM's <ref type="bibr" target="#b25">[26]</ref>, Heron uses different features taken from defined variables of the Constraint Generation step. These variables contain different kinds of important information, such as the lengths of loops, the vector length, and the memory usage. More importantly, the values of the defined variables can be obtained without any compilation, which makes the exploration process faster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONSTRAINED SPACE GENERATION</head><p>In Heron, the representation of the constrained search space is formulated as a constraint satisfaction problem called ??? ??????? . Algorithm 1 shows the basic generation process of ??? ??????? , which requires a naive program (i.e., ?) of the given compute and its corresponding computation graph (i.e., DAG) as the inputs. Then two key steps are enabled to generate the schedule template and the constraints respectively. Finally, the algorithm offers ??? ??????? as the output that consists of generated constraints as the constrained search space. ??? ??????? ? ??? ??????? ? ??????????? 24: return ??? ??????? Regarding the schedule template generation (Step-1), Heron traverses the computation stages (i.e., DAG's unscheduled nodes) in reverse topological order and applies predefined schedule generation rules if their conditions are satisfied. For a given node, Heron performs the transformations by iterating over all different types of rules. In each iteration, Heron checks the rule's condition according to the current program and the graph node. Here, if the condition is satisfied, the rule is applied correspondingly based on the program and the node, resulting in four outputs as shown in line 10 of Algorithm primitives for updating the schedule template; and (4) a predicate ???? (e.g., ? ? == ? -1) which is true if the next node should be transformed after the current step. If all the applicable transformations are performed or the ???? is set to be true, the transformation will be terminated and the given node will be inserted into scheduled nodes either. After the transformation of the given node, Heron updates the set of unscheduled nodes according to the current DAG and the set of scheduled nodes. Repeating the above process, Heron generates the schedule template until all nodes are processed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Constrained Search Space Generation</head><p>Regarding the constraints generation (Step-2), Heron scans through the generated schedule primitives and applies predefined constraint generation rules if conditions are satisfied. Concretely, an empty search space is created at first. Then, Heron scans the schedule primitives and iterates all the rules to generate new constraints. In each iteration, Heron analyzes the current schedule primitives to check whether the rule's condition is satisfied. If satisfied, this rule is applied to generate the related variables as well as their constraints. Finally, these generated variables and constraints are fed into the ??? ??????? to update the search space.</p><p>Schedule generation rules. Heron adopts generation rules for DLAs as well as for general-purpose architectures (i.e., rules in Table <ref type="table" target="#tab_1">2</ref>). Generally, the rules of DLAs are designed by considering how to efficiently leverage the hardware intrinsics and dedicated scratchpad memory (SPM). From the perspective of programmers, compared to general-purpose architectures, DLA mainly features coarse-grained hardware intrinsics (e.g., wmma in TensorCore) and user-programmable dedicated SPM (e.g., Unified Buffer in TPU). Thus, we design rules by abstracting such common architectural characteristics of various DLAs. Table <ref type="table" target="#tab_6">6</ref> summarizes three kinds of generation rules, where Rule-S1 corresponds to hardware intrinsics, and Rule-S2 and Rule-S3 correspond to dedicated SPM.</p><p>Concretely, Rule-S1 uses the tensor intrinsics to accelerate computation. Take the mma_sync in TensorCore as an example, to verify the applicability of tensorization for the current node, Heron mainly checks whether the computation matches the matrix multiplication's expression pattern (e.g., ? multiplication) and then checks whether the DLA has multiple levels of SPMs (e.g., TensorCore has two levels of SPMs for wmma fragments and shared memory). When the conditions are satisfied, Heron inserts cache_read primitives for both the node and its producers to perform data movement. Rule-S3 generates multiple nodes for moving data in or out of different SPMs that are used for different types of data. To apply this rule, Heron first checks whether the node has data reuse opportunity and then checks whether the DLA has multiple scopes of SPMs (e.g., Synapse Buffer and Neuron Buffer in DianNao <ref type="bibr" target="#b22">[23]</ref>). When the conditions are satisfied, Heron inserts cache_write primitive for the node and cache_read primitives for its producers. Constraint generation rules. Based on the common characteristics of generated schedule primitives, we group the related constraints into 6 types and propose predefined rules to automatically generate the constraints.</p><p>Table <ref type="table" target="#tab_7">7</ref> summarizes 6 types of constraints, which can well describe the composable relationship of different variables. Concretely, PROD or SUM produce constraints that the variable equals to the product or sum of an array of variables. EQ and LE produce constraints that are used for comparing the values of variables. IN produces a constraint that the variable can only take a value from a list of constants. SELECT produces a constraint that the variable takes value in a list of variables and the index of the selected value is determined by another tunable parameter (e.g., ????? 2 .? == ? ???????? where ? is a list of loop length related variables and ???????? is the computation location when ????? 2 is fused into ????? 1 ).</p><p>Table <ref type="table" target="#tab_8">8</ref> illustrates that the constraint generation rules are abstracted from the common characteristics of generated schedule primitives. Concretely, when there exists a loop that has been split or fused (i.e. HasLoopSplit or HasLoopFused), Rule-C1 and Rule-C2 generate a constraint that the product of two loops' lengths equals to the length of another loop. When there exists a variable whose value is restricted to the candidates (i.e., HasCandidates), Rule-C3 generates the IN constraint to constrain the variable. When there exist two stages where ????? 2 is fused into ????? 1 (i.e., HasStage-Fused), Rule-C4 leverages SELECT to generate constraints that the loop lengths of ????? 2 depend on the compute location. When there exists a schedule primitive that explicitly uses SPMs (i.e., HasSPM), Rule-C5 generates 3 constraints. The first one (i.e., PROD) implies that the memory consumption of each input tensor is determined by the product of loops' lengths. The second one (i.e., SUM) implies that the total memory consumption is determined by the sum of each tensor. The third one (i.e., LE) implies that the total memory consumption is less than the SPM capacity. When DLA has special architectural constraints (i.e., HasSpecialArchConstraints), Rule-C6 generates dedicated constraints for different DLAs. For example, TensorCore limits the vector lengths to {1, 2, 4, 8}, while VTA has constraints on the order of loops.</p><p>An example. Figure <ref type="figure" target="#fig_3">4</ref> illustrates the main generation process of the search space for a GEMM operator, where the process is roughly divided into three parts: the input, generated schedule template, and generated constraints. For the input, the compute is first represented as a tensor expression. Then it is converted to a naive program and a DAG by directly expanding loop indices. For the schedule template, it is generated by applying rules on the stage nodes of the DAG in reverse topological order (i.e., C, A, B). Specifically, the template and the transformed program can be generated by: ), which results in a declaration of tunable parameter-related variables and auxiliary variables with PROD or EQ types of constraints. Finally, the generated variables and their constraints form ??? ??????? which defines the generated constrained search space.</p><p>Customization. Heron is able to support new DLAs by slightly modifying both the schedule and constraint generation rules in order to recognize the architectural constraints. Take TensorCore for example, compiler designers can modify Rule-S1 to properly leverage the hardware intrinsic (i.e., use mma_sync for computation and mma_load_matrix_sync for data loading). Rule-S2 and Rule-S3 also can be modified for proper cache_read or cache_write according to the memory hierarchy of the target DLA (i.e., multiple levels of SPMs including shared memory and wmma fragments, multiple scopes of SPMs including wmma_matrix_a and wmma_matrix_b). For constraint generation rules, Rule-C5 can be modified to set the proper capacity constraint for allocated buffers. To describe the computation size and memory access constraints, designers can declare dedicated variables (e.g., vector_length) with corresponding constraints (e.g., EQ(loop, vector_length) &amp; IN(vector_length, {1,2,4,8})) in Rule-C6. Heron can easily adapt to a new DLA with a small modification of the proposed generation rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONSTRAINED SPACE EXPLORATION</head><p>Constrained space exploration searches for the optimal assignments of tunable parameters that can maximize the performance while satisfying the constraints specified in ??? ??????? . Algorithm 2 shows the detailed workflow of the exploration process. The inputs of the explorer include ??? ??????? , total trials for hardware measurements, and generations of genetic algorithm. The exploration process consists of multiple iterations. In each iteration, four steps are included:</p><p>(1) forming the first generation with randomly sampled assignments as well as the high-performance ones in the previous iteration, (2) evolving the population for several generations to optimize the fitness scores, (3) selecting promising assignments for hardware measurement using ? -?????? strategy <ref type="bibr" target="#b25">[26]</ref>, and ( <ref type="formula">4</ref> Step-1. Forming CGA's first generation of population.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>??? ?????? ? ??????? (??? ??????? , ??? ??? ) 6:</p><p>??? ? ??? + ??? ?????? 7:</p><p>Step-2. Evolving the population for several generations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8:</head><p>for ? ? {0, 1, ..., ??????????? -1} do 9:</p><p>??? ? ?????? ? ? (???, ????? ) ? The Roulette-wheel Selection 10:</p><p>???? ? constraint-based crossover and mutation 11:</p><p>??? ? ??????? (????, ??? ??? ) ? ??? 12:</p><p>Step-3. Selecting assignments for hardware measurements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>13:</head><p>???????? ? ?????? ? -????? ? (???, ????? ) 14:</p><p>??? ? ? ? ??????? (???????? ) 15:</p><p>Step-4. Updating cost model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>16:</head><p>?</p><formula xml:id="formula_2">? ? + {??? ? ? }; ? ? ? + |??? ? ? | 17:</formula><p>? ????? (?????, ? ). 18: return program with highest performance</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Constraint-Based Genetic Algorithm (CGA)</head><p>Heron leverages CGA to search for high-performance assignments that satisfies ??? ??????? . Different from the traditional GA-based exploration process introduced in Section 2.3, CGA encodes the tunable parameters as well as other auxiliary variables declared in ??? ??????? to form the chromosome. Instead of performing crossover and mutation on concrete solutions to generate new chromosomes, CGA performs such transformation (i.e., constraint-based crossover and mutation) on ??? ??????? to generate a set of new ???s. The new ???s are then for generating concrete value assignments to form the new generation of the population with the help of a constraint problem solver.</p><p>CSP solver. For a given ???, Heron searches for valid assignments of the variables by solving the ??? and thus generates chromosomes with concrete solutions for fitness evaluation. This process can be implemented in either grid search or random search. Specifically in Heron, since random search is more efficient than grid search in achieving comparable performance <ref type="bibr" target="#b18">[19]</ref>, we adopt a random constraint satisfaction approach (i.e., ??????? ) which returns multiple chromosomes with valid and concrete value assignments that are randomly generated by the solver.</p><p>Constraint-based crossover and mutation. CGA generates a set of new ???s by specially designed constraint-based crossover and mutation operator as shown in Algorithm 3. The algorithm requires four inputs including: (1) ??? is the population after selection, (2) ????? is the cost model, (3) ? is the size of the offspring population, and (4) ??? ??????? is the generated constrained satisfaction problem. For each new ???, the generation process consists ??????????? ? ? 5:</p><p>Step-1. Key variable extraction 6:</p><p>? ? extract key variables from ????? by feature importance 7:</p><p>Step-2. Constraint-based crossover 8:</p><p>? 1 , ? 2 ? two random chromosomes from ??? 9:</p><p>for ? ? ? do 10:</p><p>??????????? ? ??????????? + {? ? (? ? , [? 1,? , ? 2,? ] ) } 11:</p><p>Step-3. Constraint-based mutation 12:</p><p>??????????? ? remove one constraint from ??????????? randomly.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Initial CSP + new constraints: IN(x, [1,2,3,4,5]) IN(y, [1,2,3,4,5]); IN(z, [0,1]) PROD(t, [x,y]); LE(t, 8)</head><p>1 2 3 4 5 1 2 3 4 5 x y  CGA extracts key variables from the cost model according to predicted importance scores of the input features. In the employed XGBoost model, the importance scores are measured by the improvement of achieved performance (e.g., the gini index). The features are then ranked according to their scores and the Top-k of them are selected as the key variables. The key variables (e.g., memory size) are closely related to the predicted performance. Thus two chromosomes with the same values on key variables share similar predicted performance, which helps crossover to retain good genes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IN(x, [1,2,3,4,5]) IN(y, [1,2,3,4,5]); IN(z, [0,1]) PROD(t, [x,y]); LE(t, 8) IN(x, [1,2]); IN(y, [3,4])</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IN(x, [1,2,3,4,5]) IN(y, [1,2,3,4,5]); IN(z, [0,1]) PROD(t, [x,y]); LE(t, 8) IN(x, [1,2])</head><p>CGA performs the constraint-based crossover and mutation by exerting new constraints on ??? ??????? . For crossover, CGA first chooses two random chromosomes (i.e., ? 1 and ? 2 ) from the population and then creates new constraints for the key variables. For a specific key variable ? and a given chromosome ?, the corresponding value assignments of chromosomes ?, ? 1 , and ? 2 on ? are denoted as ? ? , ? 1,? , and ? 2,? respectively. CGA then creates a constraint ? ? (? ? , [? 1,? , ? 2,? ]) that constrains ? ? to be equal to either ? 1,? or ? 2,? . For mutation, CGA randomly removes one constraint from the ??????????? generated by the crossover operator. The resultant ??????????? are then added to ??? ??????? to form the new ???.</p><p>The proposed constraint-based crossover and mutation not only guarantee the validity of offspring chromosomes but also retain good genes during evolution. Figure <ref type="figure">5</ref> shows an example of the process. The objective function of the constrained optimization problem is 0.4? + 0.6? + 0.01? and the constraints (i.e., ??? ??????? ) are ?? ? 8&amp;? ? {1, 2, 3, 4, 5}&amp;? ? {1, 2, 3, 4, 5}&amp;? ? {0, 1}. In Step-1, variables ? and ? are considered as key variables since they are more related to the value of the objective function. In Step-2, two chromosomes (i.e., ? 1 = [1, 4, ?] and ? 2 = [2, 3, ?]) are randomly selected for crossover which results in two new constraints (i.e., ? ? {1, 2} and ? ? {3, 4}). In Step-3, the mutation operator then removes the ? ? {3, 4} constraint and makes it possible for finding the optimal solution (i.e., ? 4 ). As shown in Figure <ref type="figure">5</ref>(b) and (c), the new ???s consist of both ??? ??????? and new constraints. Thus assignments (e.g., ? 3 and ? 4 ) that satisfy the new ???s also satisfy ??? ??????? , which means that offspring chromosomes by solving the new ???s are guaranteed to be valid. Moreover, the good genes from parents can be retained by crossover when generating offspring chromosomes (e.g., ? from ? 2 and ? from ? 1 are retained to generate ? 3 with higher fitness score). In summary, the proposed approach preserves validity and retains good genes during evolution to make the exploration process efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENTAL METHODOLOGY 6.1 Evaluation Platforms</head><p>We extensively evaluate Heron on 3 representative platforms:</p><p>? NVIDIA TensorCore is integrated into NVIDIA V100 GPUs (Volta architecture) <ref type="bibr" target="#b11">[12]</ref>, which has 640 TensorCores to achieve the peak performance of 112 TFLOPS. We also evaluate Heron on TensorCores of other GPUs including NVIDIA T4 (Turing architecture) <ref type="bibr" target="#b9">[10]</ref> and NVIDIA A100 (Ampere Architecture) <ref type="bibr" target="#b7">[8]</ref>, to demonstrate its generality. ? Intel DL Boost is integrated into Intel's Xeon Gold 6240 CPU with 18 cores, achieving 23 TOPS peak performance. ? TVM Versatile Tensor Accelerator (VTA) is configured with 256 processing elements to perform 8-bit computation on the Xilinx PYNQ-Z2 platform, achieving 51TOPS peak performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Evaluated Benchmarks</head><p>We evaluate Heron with both deep learning (DL) operators and networks. Regarding the operators, we select 9 typical and widely-used operators, including GEMM, 1D convolution (C1D), 2D convolution (C2D), 3D convolution (C3D), transposed 2D convolution (T2D), dilated convolution (DIL), batch matrix multiplication (BMM), GEMV, and scan (SCAN). Specifically, for each operator, we evaluate 6-10 different combinations of shapes and show the geometry average speedups normalized to Heron. The detailed shape configurations are the same as Ansor <ref type="bibr" target="#b70">[71]</ref> and AMOS <ref type="bibr" target="#b71">[72]</ref> for a fair comparison.</p><p>Regarding the networks, we select 4 commonly-used neural networks, including ResNet-50 <ref type="bibr" target="#b37">[38]</ref>, Inception-V3 <ref type="bibr" target="#b64">[65]</ref>, VGG-16 <ref type="bibr" target="#b63">[64]</ref>,</p><p>and BERT <ref type="bibr" target="#b33">[34]</ref> with a batch size of 16.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Comparison Baselines</head><p>Our baselines include 4 state-of-the-art automatic generation approaches (AutoTVM <ref type="bibr" target="#b25">[26]</ref>, Ansor <ref type="bibr" target="#b70">[71]</ref>, AKG <ref type="bibr" target="#b69">[70]</ref>, and AMOS <ref type="bibr" target="#b71">[72]</ref>) and 4 vendor-provided hand-tuned libraries (cuDNN, cuBLAS, Py-Torch, and oneDNN). More specifically, AutoTVM supports all three selected platforms via hand-written templates and shows high performance on the baseline operators. AMOS systematically explores different software mappings of loop iterations onto DLAs and is the state-of-the-art approach on operators with multiple feasible mappings (e.g., C1D and C2D). Ansor is the state-of-the-art approach for code generation of GPU CUDA Core and CPUs, but it cannot utilize DLAs due to its architectural constraints. However, it is still worth comparing Heron with Ansor to show the benefits of using DLAs like TensorCore. AKG is the state-of-the-art polyhedral-based approach for code generation of TensorCore, and we use it as a baseline to show the effectiveness of exploration-based approaches.</p><p>For a fair comparison, we run AutoTVM, Ansor, AMOS, and Heron up to 2, 000 measurement trials per test case and report their best performance. Regarding the hand-tuned libraries, on TensorCore, we use the cuDNN-v8.2.1, cuBLAS-v11.2.1 and kernels in PyTorch-v1.10.2 as baselines, and on DL Boost, we select oneDNN-v2.5.0 as the baseline. Heron uses TVM for code generation and or-tools <ref type="bibr" target="#b3">[4]</ref> for solving CSPs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">EXPERIMENTAL RESULTS</head><p>We compare the operator and network performance of Heron against the baselines on three DLAs, including 3 GPU TensorCores, DL Boost, and VTA. To detail the effectiveness of Heron, we further present generated search spaces' quality and exploration efficiency. Finally, we show that Heron does not introduce additional compilation costs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Operator Performance</head><p>We first evaluate the operator performance on the three DLAs.</p><p>TensorCore. Figure <ref type="figure" target="#fig_8">6</ref> shows that Heron achieves 1.55?, 2.85?, 1.52?, and 2.69? performance improvement over AutoTVM, Ansor, AMOS, and hand-tuned PyTorch (with cuDNN/cuBLAS as backend), respectively <ref type="foot" target="#foot_0">1</ref> . Compared to AutoTVM and AMOS, Heron is able to perform more powerful multi-level loop tiling <ref type="bibr" target="#b70">[71]</ref> by automatically generating accurate constraints for the tiling factors. Besides of tiling, AMOS cannot use the storage_align scheduling primitive to reduce shared memory bank conflicts. The tunable parameters of this primitive are closely related to the lengths of loops and the compute location of shared memory load, which cannot be described by a small number of simple constraints. Compared to Ansor, Heron combines the advantage of the high-performance TensorCore computing units and the efficient auto-scheduling strategies <ref type="bibr" target="#b70">[71,</ref><ref type="bibr" target="#b72">73]</ref> to achieve better program optimization.</p><p>We further compare Heron against baselines on more GPUs including NVIDIA T4 and NVIDIA A100 with the most widely-used GEMM and C2D (i.e., detailed configurations are listed in Table <ref type="table" target="#tab_11">9</ref>). All these configurations are from well-known networks <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b64">65]</ref> or baselines <ref type="bibr" target="#b70">[71]</ref>. We select 5 different shape configurations for each operator and various batch sizes (e.g., 1, 8, 16, and 32) that cover different scenarios aiming at both low latency and high throughput. We also report the absolute performances on these two platforms to show the hardware utilization of different approaches on these workloads. Figure <ref type="figure" target="#fig_9">7</ref> shows that Heron consistently outperforms other generation approaches including AutoTVM, Ansor, AKG, and AMOS. Moreover, compared to hand-tuned libraries (i.e., cuDNN and cuBLAS) and the polyhedral-based approach (i.e., AKG), Heron as well as other exploration-based approaches are more scalable across different platforms since they can adjust their scheduling strategies according to the hardware and software environments.</p><p>DL Boost. Figure <ref type="figure" target="#fig_10">8</ref> shows that Heron achieves 2.93?, 12.0?, 2.71? and 1.49? performance improvement over AutoTVM, Ansor, AMOS, and hand-tuned oneDNN, respectively. For convolution operators, we use the same weight layout as oneDNN (e.g., OhwI64o4i or OhwI32o4i for C2D and OIhw4i16o4i for T2D). Such layouts are cache-friendly and improve the performance by nearly 30% compared to the normal layouts. AutoTVM has fixed tiling structures while Heron explores more complicated tiling structures that are controlled by the tile_factors. AMOS cannot tune different compute locations for fused stages (i.e., cached results), since different compute locations change the inner loops' lengths whose values also need to satisfy the alignment constraints of tensorize. Heron uses automatically generated constraints to describe such dependencies and thus explores this kind of program transformation easily.</p><p>VTA. We evaluate Heron on GEMM, C2D, and BMM with Au-toTVM as the baseline. Figure <ref type="figure" target="#fig_11">9</ref> shows that Heron achieves an average 2.32? performance improvement over AutoTVM on VTA. Regarding the C2D, Heron achieves comparable performance with AutoTVM on all configurations. The main reason is that it is easy to optimize on such a simple architecture with flexible GEMM computation units, where both AutoTVM and Heron can easily reach more than 90% of the peak performance. Regarding the GEMM and BMM, Heron outperforms AutoTVM by exploring more complicated multi-level tiling structures. VTA has special constraints on the tiling structures due to the constraints on the cycles of writing the same address. Multi-level tiling becomes error-prone if such constraints are not considered. Heron handles this challenge by directly applying the constraints on the variables that represent the lengths of loops.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Network Performance</head><p>Figure <ref type="figure" target="#fig_12">10</ref> shows the performance of Heron on 4 evaluated networks. On average, Heron achieves 1.69?, 1.46?, and 1.44? improvement over AutoTVM, AMOS, and PyTorch-cuDNN, respectively. Since ResNet-50 and Inception-V3 use many 1 ? 1 kernels for convolution layers that are well optimized by AutoTVM and AMOS, PyTorch-cuDNN cannot perform better on these two networks. However, both AutoTVM and AMOS perform much worse than     PyTorch-cuDNN on VGG-16 which only uses 3 ? 3 kernels for convolutional layers. Heron overcomes such deficiency by generating accurate search spaces that contain most of the high-performance programs and a highly efficient searching algorithm for finding the optimal or sub-optimal programs. visualized with an obtained performance by considering two key parameters, i.e., the allocated shared memory of output matrix C (X-axis) and input matrix A (Y-axis). The search space of Heron differs from that of AutoTVM in two aspects: 1) either the average or maximal performance of all valid programs in the search space of Heron is much better than that of AutoTVM, and 2) the search space of Heron is much more complicated because the performance of two neighboring programs differs significantly as shown in the marked sub-spaces in Figure <ref type="figure" target="#fig_0">11</ref>, which advances higher challenges on the exploration efficiency of search algorithms. ) and other constraint-handling techniques for GA (i.e., GA-1, GA-2, and GA-3). The y-axis is the performance relative to CGA (the higher the better). The x-axis is the size ? of the GEMM operator with shape (? , ? , ? ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Quality of Search Spaces</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Exploration Efficiency of CGA</head><p>To demonstrate the efficiency of the proposed CGA, we first compare CGA with 3 popular exploration algorithms (i.e., SA, GA, and RAND), and then compare CGA against a modified version of CGA (CGA-1) and 3 state-of-the-art constraint-handling techniques of genetic algorithms (GA-1 <ref type="bibr" target="#b61">[62]</ref>, GA-2 <ref type="bibr" target="#b50">[51]</ref>, and GA-3 <ref type="bibr" target="#b60">[61]</ref>).</p><p>Figure <ref type="figure" target="#fig_1">12</ref> shows that CGA searches faster and finds better programs compared to popular exploration algorithms. Take the GEMM (i.e., Figure <ref type="figure" target="#fig_1">12(b)</ref>) for example, CGA finds better programs in 500 exploration steps compared to the baselines with 1000 exploration steps. The efficiency of CGA mainly stems from the ability to explore more high-performance while valid programs within the given time budget.</p><p>Figure <ref type="figure" target="#fig_2">13</ref> compares CGA against other constraint-handling techniques of GA including: (1) CGA-1 refers to CGA with key variables chosen randomly, (2) GA-1 refers to the GA with stochastic ranking <ref type="bibr" target="#b61">[62]</ref>, (3) GA-2 refers to the GA with a SAT-Decoder <ref type="bibr" target="#b50">[51]</ref>, and (4) GA-3 refers to the GA based on multi-objective optimization <ref type="bibr" target="#b60">[61]</ref>. Experimental results show that CGA outperforms CGA-1 since the key variables predicted by the cost model are more related to the fitness score, which helps retain the good genes of the parent chromosomes. The gap between CGA and CGA-1 becomes smaller as the problem size grows since the accuracy of the cost model trained with a fixed number of samples degrades, which makes both approaches hard to find high-performance programs. GA-1 14: Breakdown of Heron's compilation time.</p><p>and GA-3 cannot guarantee the validity of the offspring chromosomes and thus perform worse than CGA. GA-2 guarantees the validity of offspring chromosomes using a SAT-decoder and thus outperforms GA-1 and GA-3 on smaller problem sizes. However, GA-2 has to generate invalid intermediate chromosomes which are later decoded into valid ones. Thus, GA-2 cannot retain the good genes of parent chromosomes, which results in performance degradation as the problem size grows.</p><p>In general, the efficiency of CGA stems from the ability to explore more high-performance while valid programs since the constraintbased crossover and mutation retain the good genes and guarantee the validity of offspring chromosomes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Compilation Time</head><p>The compilation time is critical for practical usage, and we compare the compilation time of Heron against two exploration-based approaches, i.e., AutoTVM and AMOS. Table <ref type="table" target="#tab_12">10</ref> shows the average compilation time on 5 commonly used operators, and all these approaches perform 2, 000 trials of hardware measurement. The results show that Heron's compilation time is 87% of AutoTVM's and 82% of AMOS's on average because Heron can quickly find optimal programs with lower measurement costs. Figure <ref type="figure" target="#fig_3">14</ref> further shows the breakdown of Heron's compilation time, where we show 3 test cases for each operator. Thanks to the improvement in the efficiency of modern constraint satisfaction problem solvers, the cost of CGA is 23% on average. Most of the compilation time is spent on hardware measurement which ranges from 61% to 79%, with 76% on average. Other costs include training cost model are less than 1% of the total time. Thus Heron does not introduce additional compilation costs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">RELATED WORK</head><p>In addition to reviewing deep learning accelerators, we summarize the related work of manually optimized libraries, automatic code generation for deep learning, and genetic algorithms for constrained optimization.</p><p>Deep learning accelerators. DLAs are customized for different DL applications, aiming at elevating both performance and energy efficiency to the extreme. In academia, by leveraging specialized functional units, memory hierarchy, and interconnect, Dian-Nao family (i.e., DianNao <ref type="bibr" target="#b22">[23]</ref>, DaDianNao <ref type="bibr" target="#b27">[28]</ref>, PuDaianNao <ref type="bibr" target="#b47">[48]</ref>, and ShiDianNao <ref type="bibr" target="#b34">[35]</ref> ) greatly improve the performance of DL computation. Eyeriss <ref type="bibr" target="#b28">[29]</ref> introduces a brand-new dataflow, which minimizes data movement energy consumption on a spatial architecture. Following this trend, many of emerging accelerators that target different algorithms <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b56">57]</ref> or are with new technologies <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b35">36]</ref> are proposed. Meanwhile, spurred by the rapid expansion of DL applications in the industry, hardware vendors (e.g., NIVIDA TensorCore <ref type="bibr" target="#b19">[20]</ref> and Intel NNP <ref type="bibr" target="#b39">[40]</ref>), internet giants (e.g., Google TPU <ref type="bibr" target="#b43">[44]</ref> and Apple Bonic [6]), and even startups (e.g., Cambricon MLU [3] and Graphcore IPU <ref type="bibr" target="#b41">[42]</ref>) have released a number of DLAs. In fact, dedicated DLAs, whether in academia or industry, are essentially domain-specific rather than generalpurpose architecture, thus inevitably incurring complicated and diverse architectural constraints.</p><p>Manually optimized libraries. Manually-optimized libraries are flexible and efficient techniques to improve DL performance. Traditional high-performance libraries in HPC domain such as MKL <ref type="bibr" target="#b0">[1]</ref>, OpenBLAS <ref type="bibr" target="#b13">[14]</ref>, and cuBLAS <ref type="bibr" target="#b1">[2]</ref> are used for accelerating DL computation on general-purpose architecture. Dedicated software libraries have also been developed by DLA vendors. To better exploit TensorCore, cuDNN v7.0 <ref type="bibr" target="#b15">[16]</ref> utilizes TensorCore intrinsics to accelerate various DL operators such as convolution. Intel released a new library oneDNN <ref type="bibr" target="#b12">[13]</ref> for leveraging its DL Boost acceleration mechanism. Other DLA vendors also released libraries along with their hardware products. For example, Graph-Core released PopLIBS <ref type="bibr" target="#b14">[15]</ref> and Habana released SynapseAI <ref type="bibr">[5]</ref> to achieve both programmability and high performance. However, these high-performance libraries are heavily optimized and tuned in a hardware-specific fashion, which requires intense engineering efforts and a deep understanding of algorithms, compilers, and hardware architecture in order to obtain outstanding performance.</p><p>Automatic code generation. Halide <ref type="bibr" target="#b58">[59]</ref> presents a scheduling language for high-performance computing. This language is well suitable for both automatic search and manual optimization, and thus is followed by a number of researches <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b55">56]</ref>. TVM automatically generates low-level optimized code for various hardware, but the users are required to write schedule templates manually. Benefiting by exploring larger search spaces with generated templates, FlexTensor <ref type="bibr" target="#b72">[73]</ref> and Ansor <ref type="bibr" target="#b70">[71]</ref> can identify better-optimized kernels but cannot support typical DLAs such as TensorCore, TPU, and VTA. Although UNIT <ref type="bibr" target="#b66">[67]</ref> can support tensor instructions of DLAs, it still relies on the manual-implemented schedule. Spatial accelerator compilers <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b38">39]</ref> leverage cost models designed by human experts to accelerate space exploration. dMazeRunner <ref type="bibr" target="#b32">[33]</ref> enumerates and evaluates all feasible tile sizes (e.g., 1.75e+07 for a C2D operator), which is not feasible for larger spaces. MindMappings <ref type="bibr" target="#b38">[39]</ref> uses a gradient-based approach to explore unconstrained space, which is hard for spaces with complicated discrete constraints. Recent work <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b69">70]</ref> leverage polyhedral models to solve the code generation problems. Tiramisu <ref type="bibr" target="#b17">[18]</ref> provides finegrained control of optimizations. Tensor Comprehensions <ref type="bibr" target="#b65">[66]</ref> generates high-performance GPU kernel codes for arbitrary mathematical operations on tensors. AKG <ref type="bibr" target="#b69">[70]</ref> is the state-of-the-art that leverages polyhedral schedulers to perform much wider transformations and it can be used for TensorCore. Although automatic code generation techniques evolve very fast, the key deficiency is that they do not carefully consider the pervasive and complicated architectural constraints of DLAs during the program generation process, which might result in low optimization efficiency.</p><p>Genetic algorithms for constrained optimization. Genetic algorithm is an unconstrained optimization approach, therefore, special constraint-handling techniques are introduced to deal with the complicated constraints. Typical constraint-handling techniques mainly consist of four categories including penalty functions, repair algorithms, decoders, and multi-objective optimization <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b52">53]</ref>. Penalty functions <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b68">69]</ref> are used to punish constraint violations by lowering the score on invalid assignments. Repair algorithms <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b67">68]</ref> repair invalid assignments by local search and replace invalid assignments with modified assignments. Decoders <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b50">51]</ref> is designed to map the genotypes (i.e., chromosomes in the original space) to the phenotypes (i.e., chromosomes in a manually designed space) which are guaranteed to be valid. Multiobjective optimization methods <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b60">61]</ref> model the constraints as additional objectives and thus the chromosomes are selected based on the Pareto dominance relationship. All such approaches either fail to guarantee the validity of offspring chromosomes (e.g., penalty functions and multi-objective optimization methods) or may generate invalid intermediate chromosomes (e.g., repair algorithm and decoders) since they perform crossover and mutation on concrete solutions. On contrary, CGA guarantees validity through the entire optimization process by evolving on CSPs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">CONCLUSION</head><p>We propose a novel exploration-based compilation approach, Heron, for efficiently generating high-performance software libraries of various DLAs. Heron automatically enforces massively sophisticated while accurate constraints through the entire program generation including constrained space generation and constrained space exploration. The generated search space is efficiently explored by a novel constraint-based genetic algorithm (CGA) for generating high-performance programs. Experimental results on 3 representative DLAs demonstrate that Heron averagely outperforms stateof-the-art automatic generation approaches and vendor-provided hand-tuned libraries by 2.71? and 2.00?, respectively.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: Comparison of two constrained search spaces: (a) a regular space with a few simple constraints excludes many valid programs, and (b) an irregular space with massive sophisticated constraints includes all valid programs. The irregular space poses a key challenge to the search algorithms in that such constraints should be preserved during the entire exploration process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: Comparison of random search (i.e., RAND) with simulated annealing (i.e., SA) and genetic algorithm (i.e., GA) in an irregular search space. The points represent measured performances. RAND randomly samples valid parameter configurations under the constraints using a solver<ref type="bibr" target="#b3">[4]</ref>. GA and SA adopt the same setups as<ref type="bibr" target="#b25">[26]</ref> and use RAND to generate initial valid programs.</figDesc><graphic url="image-2.png" coords="5,309.69,65.29,249.51,150.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The overview of Heron, which contains two main stages: generation and exploration. The generation stage contains Space Generator, and the exploration stage consists of Space Explorer, DLA Measurer, and Cost Model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: An illustrative example of the constrained space generation for an GEMM operator. Variables that are not tunable are referred as auxiliary variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>) updating the cost model based on measured performances. Finally, Algorithm 2 outputs the program with the highest measured performance as the optimized program. Algorithm 2 CGA-based Exploration 1: Input: ??? ??????? , ? ?????, ??????????? 2: ? ? ?; ??? ? ? 3: while ? ? ? ????? do 4:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>4 cFigure 5 :</head><label>45</label><figDesc>Figure 5: An example of constraint-based crossover and mutation. The points represent valid assignments for ??? ??????? or the new ???s. of three steps including key variable extraction, constraint-based crossover, and constraint-based mutation.CGA extracts key variables from the cost model according to predicted importance scores of the input features. In the employed XGBoost model, the importance scores are measured by the improvement of achieved performance (e.g., the gini index). The features are then ranked according to their scores and the Top-k of them are selected as the key variables. The key variables (e.g., memory size) are closely related to the predicted performance. Thus two chromosomes with the same values on key variables share similar predicted performance, which helps crossover to retain good genes.CGA performs the constraint-based crossover and mutation by exerting new constraints on ??? ??????? . For crossover, CGA first chooses two random chromosomes (i.e., ? 1 and ? 2 ) from the population and then creates new constraints for the key variables. For a specific key variable ? and a given chromosome ?, the corresponding value assignments of chromosomes ?, ? 1 , and ? 2 on ? are denoted as ? ? , ? 1,? , and ? 2,? respectively. CGA then creates a constraint ? ? (? ? , [? 1,? , ? 2,? ]) that constrains ? ? to be equal to either ? 1,? or ? 2,? . For mutation, CGA randomly removes one constraint from the ??????????? generated by the crossover operator. The resultant ??????????? are then added to ??? ??????? to form the new ???.The proposed constraint-based crossover and mutation not only guarantee the validity of offspring chromosomes but also retain good genes during evolution. Figure5shows an example of the process. The objective function of the constrained optimization problem is 0.4? + 0.6? + 0.01? and the constraints (i.e., ??? ??????? ) are ?? ? 8&amp;? ? {1, 2, 3, 4, 5}&amp;? ? {1, 2, 3, 4, 5}&amp;? ? {0, 1}. In Step-1, variables ? and ? are considered as key variables since they are</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Performances relative to Heron on NVIDIA V100 TensorCore.</figDesc><graphic url="image-6.png" coords="10,62.29,80.23,487.10,65.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Performance comparison on other GPU platforms including NVIDIA T4 and NVIDIA A100.</figDesc><graphic url="image-9.png" coords="11,62.31,313.37,484.42,68.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Performances relative to Heron on Intel DL Boost.</figDesc><graphic url="image-13.png" coords="11,326.58,411.38,102.93,83.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Performances relative to Heron on TVM VTA.</figDesc><graphic url="image-10.png" coords="11,60.42,409.32,222.21,62.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Performances of different networks relative to Heron on TensorCore.</figDesc><graphic url="image-11.png" coords="11,62.07,497.95,223.83,63.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 11 Figure 11 :</head><label>1111</label><figDesc>Figure11compares the search space automatically generated by Heron against the manually constrained search space of AutoTVM. More specifically, the search spaces of the GEMM operator G1 are</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 12 : 2 .Figure 13 :</head><label>12213</label><figDesc>Figure 12: Comparison of CGA, SA, and GA on (a) the C2D and (b) the GEMM operator. The setup of baseline is the same as Figure 2.</figDesc><graphic url="image-15.png" coords="12,49.45,71.37,245.25,132.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Examples of schedule primitives in TVM Name Description split split a loop into multiple sub-loops ???? 1 , ???? 2 = ?????.????? (????, ????? _? ????? )</figDesc><table><row><cell>fuse</cell><cell>merge multiple loops into one loop ???? = ?????.? ??? (???? 1 , ???? 2 )</cell></row><row><cell>cache</cell><cell>use shared memory for inputs or outputs ?????_???? (?????, "??????")</cell></row><row><cell>unroll</cell><cell>unroll the loop for several times ?????.?????? (????, ??????_??????)</cell></row></table><note><p>compute_at ????? 2 is fused into ????? 1 at location ????? 2 .???????_?? (????? 1 , ????????) tensorize replace compute to utilize hardware intrinsic ?????.????????? (????, ??????_???? (?, ?, ? ) )</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Examples of rules in Ansor, where the state ? is the current schedule template and related program, ? is the index of current node of the DAG, and ? ? is the updated template and transformed program.</figDesc><table><row><cell>Rule Name</cell><cell>Condition and Application</cell></row><row><cell cols="2">IsStrictInlinable(?, ?) HasDataReuse(?, ?) ? Multi-level-Tiling Always-Inline HaseDataReuse(?, ?)&amp; ? Add-Cache-Stage ? HasFusibleConsumer(?, ?) ? ? ? ????????? ???? (?, ? ); ? ? ? ?</cell></row><row><cell>User-Defined-Rule</cell><cell>user-defined transformations and conditions</cell></row></table><note><p>? ? ?????? (?, ? ); ? ? ? ? -1 ? ? ??????????? ????? (?, ? ); ? ? ? ? -1</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Constraint examples of various DLAs.</figDesc><table><row><cell>Platforms</cell><cell>Constraints</cell><cell>Category</cell></row><row><cell></cell><cell>?  *  ?  *  ? == 4096</cell><cell>computation size</cell></row><row><cell>TensorCore</cell><cell>?, ?, ? ? {8, 16, 32} ??????_??? ? 48?</cell><cell>computation size memory capacity</cell></row><row><cell></cell><cell>?????? _?????? ? {1, 2, 4, 8}</cell><cell>memory access</cell></row><row><cell>DL Boost</cell><cell>?, ?, ? == 1, 16, 4</cell><cell>computation size</cell></row><row><cell></cell><cell>?, ?, ? == 1, 16, 16</cell><cell>computation size</cell></row><row><cell></cell><cell>2 ? ??????_?????</cell><cell>memory access</cell></row><row><cell>VTA</cell><cell>????? _?? ? ? ?? ? 32?</cell><cell>memory capacity</cell></row><row><cell></cell><cell>?????? _?? ? ? ?? ? 256?</cell><cell>memory capacity</cell></row><row><cell></cell><cell>?????? _?? ? ? ?? ? 128?</cell><cell>memory capacity</cell></row><row><cell>TPU</cell><cell>?, ?, ? == 1, 256, 256 ? ? 256 ? 4?</cell><cell>computation size memory capacity</cell></row><row><cell>Cambricon</cell><cell>? ??? ? 3 ? 64? ? ??? + ? ??? ? ? ?? + ? ?? ? 768?</cell><cell>memory capacity memory capacity</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Variables for describing GEMM's constraints on Ten-sorCore.</figDesc><table><row><cell></cell><cell>Architectural</cell><cell>Loop</cell><cell>Tunable</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Others</cell></row><row><cell></cell><cell>Constraint</cell><cell>Length</cell><cell>Parameter</cell><cell></cell></row><row><cell>Numbers</cell><cell>10</cell><cell>82</cell><cell>30</cell><cell>51</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Number of variables and constraints used for space description.</figDesc><table><row><cell></cell><cell cols="5">GEMM BMM C1D C2D C3D</cell></row><row><cell>Variables</cell><cell>173</cell><cell>236</cell><cell>236</cell><cell>304</cell><cell>363</cell></row><row><cell>Constraints</cell><cell>372</cell><cell>529</cell><cell>547</cell><cell>702</cell><cell>861</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Schedule generation rules and the related conditions.</figDesc><table><row><cell cols="2">No. Rule</cell><cell>Condition and Application</cell></row><row><cell cols="3">S1 ? S2 Tensorizable(?, ?) Tensorize HasDataReuse(?, ?) &amp; Add Multi-Level SPM HasMultiLevelCache(?, ?) ? ? ? ?????????????????????? (?, ? ); ? ? ? ?</cell></row><row><cell></cell><cell></cell><cell>HasDataReuse(?) &amp;</cell></row><row><cell>S3</cell><cell>Add Multi-Scope SPM</cell><cell>HasMultiScopeCache(?, ?) ?</cell></row></table><note><p>1: (1) a new program after transformation; (2) a new computation DAG after transformation; (3) new schedule ? ? ? ???????? (?, ? ); ? ? ? ? ? ? ?????????????????? (?, ? ); ? ?? ? ????????? ???? (? ? , ? ); ? ? ? ? -1</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Constraint types and their descriptions</figDesc><table><row><cell cols="2">No. Type</cell><cell>Description</cell></row><row><cell>T1</cell><cell cols="2">PROD(v?</cell></row><row><cell>T3</cell><cell>EQ(v1, v2)</cell><cell>? 1 = ? 2</cell></row><row><cell>T4</cell><cell>LE(v1, v2)</cell><cell>? 1 ? ? 2</cell></row><row><cell>T5</cell><cell>IN(v, [?</cell><cell></cell></row></table><note><p>, [? 1 , ..., ? ? ]) ? = ? 1 * ... * ? ? T2 SUM(v, [? 1 , ..., ? ? ]) ? = ? 1 + ... + ? 1 , ..., ? ? ]) ? = ? 1 or ... or ? = ? ? T6 SELECT(v, u, [? 1 , ..., ? ? ]) ? = ? ?</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 :</head><label>8</label><figDesc>Constraint generation rules, rule conditions and descriptions, where ? is the schedule primitive to be constrained. ? , [? ?+1 , .., ? ? ]) for each k; SELECT (?, ???, [? 1 , ..., ? ? ])</figDesc><table><row><cell cols="3">No. Rule</cell><cell></cell><cell cols="2">Condition</cell><cell>Description</cell></row><row><cell>C1</cell><cell cols="3">AddLoopSplit</cell><cell cols="2">HasLoopSplit(? )</cell><cell>PROD(?, [? ? , ? ? ])</cell></row><row><cell>C2</cell><cell cols="3">AddLoopFuse</cell><cell cols="2">HasLoopsFused(? )</cell><cell>PROD(?, [? 1 , ? 2 ])</cell></row><row><cell>C3</cell><cell cols="3">AddCandidates</cell><cell cols="2">HasCandidates(? )</cell><cell>IN (?, [? 1 , ..., ? ? ])</cell></row><row><cell cols="6">C4 PROD(? C5 AddStageFuse HasStagesFused(? ) AddMemLimit HasSPM(? ) PROD(??? ? , [? 1 , ..., ? ? ]) for each i; SUM(?????, [??? 1 , .., ??? ? ]); LE(?????, ????? )</cell></row><row><cell>C6</cell><cell cols="5">AddDLASpecific HasSpecialArchConstraints(? ) Specialized for each DLA</cell></row><row><cell cols="3">input-?C</cell><cell cols="3">???? -?3 -? C.wmma</cell><cell>???? -?2 -?</cell></row><row><cell cols="2">C.wmma</cell><cell cols="3">-? C.wmma ???? -?1</cell><cell>-? ??????????? ?????</cell><cell>output</cell><cell>(2)</cell></row><row><cell cols="6">According to the given order, node C is firstly transformed by</cell></row><row><cell cols="6">Rule-S3 which generates a new node C.wmma. Then C.wmma is</cell></row><row><cell cols="6">transformed with Rule-S2, Rule-S1, and the MultiLevelTiling Rule</cell></row><row><cell cols="6">in Table 2 to generate the schedule template. The schedule tem-</cell></row><row><cell cols="6">plate covers different program candidates. Take loop ordering as</cell></row><row><cell cols="6">an example, the order of spatial loops, i.e., (?3, ?3, ?4, ?4, ...), can be</cell></row><row><cell cols="4">reordered to (?3, ?4, ?4, ?5, .</cell><cell></cell></row></table><note><p>..) by setting ?3 == 1&amp;?6 == 1. For the constraints, Heron traverses all the schedule primitives to apply constraint generation rules. For example, schedules generated by the MultiLevelTiling satisfy the condition of AddLoopSplit (i.e., Rule-C1</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Algorithm 3 Constraint-based Crossover and Mutation 1: Input: ???, ?????, ? , ??? ??????? 2: ???? ? [] 3: for ? ? {0, 1, ..., ? -1} do 4:</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>13: ??? ? ??? ??????? + ???????????; ????.append(??? ) 14: return ????</figDesc><table><row><cell>Objective:</cell><cell>0</cell><cell>.</cell><cell>4</cell><cell>x</cell><cell>?</cell><cell>0</cell><cell>.</cell><cell>6</cell><cell>y</cell><cell>?</cell><cell>0</cell><cell>.</cell><cell>01</cell><cell cols="2">z</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">, 1 [</cell><cell>, 4</cell><cell>]</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">[</cell><cell>, 3 , 2</cell><cell>]</cell></row><row><cell>Initial CSP:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9 :</head><label>9</label><figDesc>Evaluated configurations for C2D and GEMM on T4 and A100 respectively.</figDesc><table><row><cell cols="4">C2D Names Batch H W</cell><cell>CI</cell><cell cols="6">CO R S Padding Stride GEMM Names</cell><cell>M</cell><cell>N</cell><cell>K</cell></row><row><cell>C1</cell><cell>1</cell><cell cols="2">56 56</cell><cell>64</cell><cell>64</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>1</cell><cell>G1</cell><cell cols="3">1024 1024 1024</cell></row><row><cell>C2</cell><cell>8</cell><cell cols="2">28 28</cell><cell>512</cell><cell>128</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>G2</cell><cell cols="3">4096 4096 4096</cell></row><row><cell>C3</cell><cell>16</cell><cell cols="4">14 14 1024 512</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>2</cell><cell>G3</cell><cell>32</cell><cell cols="2">1000 2048</cell></row><row><cell>C4</cell><cell>32</cell><cell>7</cell><cell>7</cell><cell>512</cell><cell>512</cell><cell>3</cell><cell>3</cell><cell>0</cell><cell>1</cell><cell>G4</cell><cell>32</cell><cell cols="2">4096 4096</cell></row><row><cell>C5</cell><cell>32</cell><cell cols="2">14 14</cell><cell>256</cell><cell>256</cell><cell>3</cell><cell>3</cell><cell>1</cell><cell>1</cell><cell>G5</cell><cell>32</cell><cell cols="2">1000 4096</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 10 :</head><label>10</label><figDesc>Compilation time of different approaches on Ten-sorCore.</figDesc><table><row><cell cols="4">Operator AutoTVM (min) AMOS (min) Heron (min)</cell></row><row><cell>GEMM</cell><cell>91</cell><cell>96</cell><cell>92</cell></row><row><cell>BMM</cell><cell>90</cell><cell>97</cell><cell>90</cell></row><row><cell>Conv1D</cell><cell>98</cell><cell>87</cell><cell>56</cell></row><row><cell>Conv2D</cell><cell>97</cell><cell>91</cell><cell>90</cell></row><row><cell>Conv3D</cell><cell>105</cell><cell>147</cell><cell>97</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The polyhedral-based approach, i.e., AKG, only works for GEMM and C2D, and it is compared in later experiments.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>We would like to thank the reviewers for their valuable suggestions. This work is partially supported by the <rs type="funder">NSF of China</rs> (under Grants <rs type="grantNumber">U22A2028</rs>, <rs type="grantNumber">61925208</rs>, <rs type="grantNumber">62102398</rs>, <rs type="grantNumber">62222214</rs>, <rs type="grantNumber">62002338</rs>, <rs type="grantNumber">U19B2019</rs>, <rs type="grantNumber">U20A20227</rs>), <rs type="projectName">CAS Project for Young Scientists in Basic Research</rs> (<rs type="grantNumber">YSBR-029</rs>), <rs type="funder">Youth Innovation Promotion Association CAS and Beijing Academy of Artificial Intelligence (BAAI)</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_GduJTE3">
					<idno type="grant-number">U22A2028</idno>
				</org>
				<org type="funding" xml:id="_wat5tAj">
					<idno type="grant-number">61925208</idno>
				</org>
				<org type="funding" xml:id="_B4WwCgq">
					<idno type="grant-number">62102398</idno>
				</org>
				<org type="funding" xml:id="_QwUrHZM">
					<idno type="grant-number">62222214</idno>
				</org>
				<org type="funding" xml:id="_CscYU3t">
					<idno type="grant-number">62002338</idno>
				</org>
				<org type="funding" xml:id="_JYzTpHA">
					<idno type="grant-number">U19B2019</idno>
				</org>
				<org type="funded-project" xml:id="_uPqApnr">
					<idno type="grant-number">U20A20227</idno>
					<orgName type="project" subtype="full">CAS Project for Young Scientists in Basic Research</orgName>
				</org>
				<org type="funding" xml:id="_bSMDNgB">
					<idno type="grant-number">YSBR-029</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="http://software.intel.com/en-us/intel-mkl" />
		<title level="m">Accelerate Fast Math with Intel? oneAPI Math Kernel Library</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<ptr target="https://developer.nvidia.com/cublas" />
		<title level="m">Basic Linear Algebra on NVIDIA GPUs</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Mlu</forename><surname>Cambricon</surname></persName>
		</author>
		<ptr target="https://www.cambricon.com/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<ptr target="https://github.com/google/or-tools" />
		<title level="m">Googles Operations Research Tools</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName><surname>Goya</surname></persName>
		</author>
		<author>
			<persName><surname>Products</surname></persName>
		</author>
		<ptr target="https://habana.ai/inference/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Inside Apple&apos;s new A11 Bionic processor</title>
		<ptr target="https://www.zdnet.com/article/inside-apples-new-a11-bionic-processor/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<ptr target="https://www.intel.com/content/www/us/en/artificial-intelligence/deep-learning-boost.html" />
		<title level="m">Intel Deep Learning Boost -Intel AI</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<ptr target="https://www.nvidia.com/en-us/data-center/a100/" />
		<title level="m">NVIDIA A100 TENSOR CORE GPU</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<ptr target="https://developer.nvidia.com/cudnn" />
		<title level="m">NVIDIA cuDNN</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<ptr target="https://www.nvidia.com/en-us/data-center/tesla-t4/" />
		<title level="m">NVIDIA T4 Tensor Core GPU for AI inference</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Core</forename><surname>Nvidia Tensor</surname></persName>
		</author>
		<ptr target="https://www.nvidia.cn/data-center/tensor-cores/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<ptr target="https://www.nvidia.com/en-us/data-center/v100/" />
		<title level="m">NVIDIA V100 TENSOR CORE GPU</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<ptr target="https://github.com/intel/mkl-dnn" />
		<title level="m">oneAPI Deep Neural Network Library (oneDNN)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<ptr target="https://www.openblas.net" />
		<title level="m">OpenBLAS: An optimized BLAS library</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<ptr target="https://www.graphcore.ai/products/poplar" />
		<title level="m">Poplar Graph Framework Software</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<ptr target="https://developer.nvidia.com/blog/programming-tensor-cores-cuda-9/" />
		<title level="m">Programming Tensor Cores in CUDA 9</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning to optimize halide with tree search and random programs</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karima</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Riyadh</forename><surname>Baghdadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tzu-Mao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Micha?l</forename><surname>Gharbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kayvon</forename><surname>Fatahalian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fr?do</forename><surname>Durand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Tiramisu: A polyhedral compiler for expressing fast and portable code</title>
		<author>
			<persName><forename type="first">Riyadh</forename><surname>Baghdadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malek</forename><surname>Ben Romdhane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emanuele</forename><surname>Del Sozzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdurrahman</forename><surname>Akkas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patricia</forename><surname>Suriana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shoaib</forename><surname>Kamil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saman</forename><surname>Amarasinghe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="193" to="205" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Random Search for Hyper-Parameter Optimization</title>
		<author>
			<persName><forename type="first">James</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research (JMLR)</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="281" to="305" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Rtx on-the nvidia turing gpu</title>
		<author>
			<persName><forename type="first">John</forename><surname>Burgess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="36" to="44" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">VIBNN: Hardware Acceleration of Bayesian Neural Networks</title>
		<author>
			<persName><forename type="first">Ruizhe</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ao</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ning</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiwen</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luhao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuehai</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massoud</forename><surname>Pedram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanzhi</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="476" to="488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">Prasanth</forename><surname>Chatarasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyoukjun</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natesh</forename><surname>Raina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vaisakh</forename><surname>Haridas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angshuman</forename><surname>Parashar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Pellauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivek</forename><surname>Sarkar</surname></persName>
		</author>
		<title level="m">Marvel: A Data-centric Compiler for DNN Operators on Spatial Accelerators. arXiv: Distributed, Parallel, and Cluster Computing</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">DianNao: A Small-Footprint High-Throughput Accelerator for Ubiquitous Machine-Learning</title>
		<author>
			<persName><forename type="first">Tianshi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zidong</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ninghui</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengyong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunji</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Temam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="269" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">XGBoost: A Scalable Tree Boosting System</title>
		<author>
			<persName><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">TVM: An Automated End-to-End Optimizing Compiler for Deep Learning</title>
		<author>
			<persName><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thierry</forename><surname>Moreau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziheng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lianmin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eddie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haichen</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meghan</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leyuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuwei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Ceze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th USENIX Symposium on Operating Systems Design and Implementation (OSDI)</title>
		<meeting>the 13th USENIX Symposium on Operating Systems Design and Implementation (OSDI)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="578" to="594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning to optimize tensor programs</title>
		<author>
			<persName><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lianmin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eddie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziheng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thierry</forename><surname>Moreau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Ceze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Krishnamurthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Neural Information Processing Systems (NeurIPS)</title>
		<meeting>the 32nd International Conference on Neural Information Processing Systems (NeurIPS)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3393" to="3404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<author>
			<persName><forename type="first">Yunji</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianshi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiwei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ninghui</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Temam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DianNao Family: Energy-Efficient Hardware Accelerators for Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">DaDianNao: A Machine-Learning Supercomputer</title>
		<author>
			<persName><forename type="first">Yunji</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoli</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shijin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ling</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianshi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiwei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ninghui</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Temam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 47th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="609" to="622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Eyeriss: A Spatial Architecture for Energy-Efficient Dataflow for Convolutional Neural Networks</title>
		<author>
			<persName><forename type="first">Yu-Hsin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Emer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivienne</forename><surname>Sze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd ACM/IEEE Annual International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the 43rd ACM/IEEE Annual International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="367" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">PRIME: A Novel Processing-in-Memory Architecture for Neural Network Computation in ReRAM-Based Main Memory</title>
		<author>
			<persName><forename type="first">Ping</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuangchen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jishen</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongpan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd ACM/IEEE International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the 43rd ACM/IEEE International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="27" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">CONSTRAINT-HANDLING USING AN EVOLU-TIONARY MULTIOBJECTIVE OPTIMIZATION TECHNIQUE</title>
		<author>
			<persName><forename type="first">Carlos</forename><forename type="middle">A Coello</forename><surname>Coello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Civil Engineering and Environmental Systems</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="319" to="346" />
			<date type="published" when="2000">2000. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Constraint-handling techniques used with evolutionary algorithms</title>
		<author>
			<persName><forename type="first">Carlos</forename><forename type="middle">A Coello</forename><surname>Coello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Computation Conference Companion</title>
		<meeting>the Genetic and Evolutionary Computation Conference Companion</meeting>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Shail</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aviral</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youngbin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasikanth</forename><surname>Avancha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyoungwoo</forename><surname>Lee</surname></persName>
		</author>
		<title level="m">Optimizing Convolutions on Dataflow Accelerators. ICASSP 2020 -2020 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="1544" to="1548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter</title>
		<meeting>the Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies (NAACL-HLT</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">ShiDianNao: Shifting Vision Processing Closer to the Sensor</title>
		<author>
			<persName><forename type="first">Zidong</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Fasthuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianshi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Ienne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ling</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaobing</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunji</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Temam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd ACM/IEEE Annual International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the 42nd ACM/IEEE Annual International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="92" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">TETRIS: Scalable and Efficient Neural Network Acceleration with 3D Memory</title>
		<author>
			<persName><forename type="first">Mingyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="751" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Genetic algorithms in search, optimization, and machine learning</title>
		<author>
			<persName><surname>David E Golberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989. 1989. 1989</date>
			<publisher>Addion Wesley</publisher>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Mind mappings: enabling efficient algorithmaccelerator mapping space search</title>
		<author>
			<persName><forename type="first">Kartik</forename><surname>Hegde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Po-An</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sitao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikas</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angshuman</forename><surname>Parashar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">W</forename><surname>Fletcher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<meeting>the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Intel Nervana Neural Network Processor-T (NNP-T) Fused Floating Point Many-Term Dot Product</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Hickmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jieasheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Rotzin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maciej</forename><surname>Urbanski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasikanth</forename><surname>Avancha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE 27th Symposium on Computer Arithmetic</title>
		<imprint>
			<biblScope unit="page" from="133" to="136" />
			<date type="published" when="2020">2020. 2020</date>
			<publisher>ARITH</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Constrained Optimization Via Genetic Algorithms</title>
		<author>
			<persName><forename type="first">Abdollah</forename><surname>Homaifar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charlene</forename><forename type="middle">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">H</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Simulation</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="242" to="253" />
			<date type="published" when="1994">1994. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Blake</forename><surname>Tillman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Maggioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniele</forename><forename type="middle">Paolo</forename><surname>Scarpazza</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.03413</idno>
		<title level="m">Dissecting the graphcore ipu architecture via microbenchmarking</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">On the use of non-stationary penalty functions to solve nonlinear constrained optimization problems with GA&apos;s</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><forename type="middle">A</forename><surname>Joines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">R</forename><surname>Houck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First IEEE Conference on Evolutionary Computation</title>
		<meeting>the First IEEE Conference on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="1994">1994. 1994</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="579" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">In-Datacenter Performance Analysis of a Tensor Processing Unit</title>
		<author>
			<persName><forename type="first">Cliff</forename><surname>Norman P Jouppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nishant</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raminder</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Bajwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suresh</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Al</forename><surname>Boden</surname></persName>
		</author>
		<author>
			<persName><surname>Borchers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th ACM/IEEE Annual International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the 44th ACM/IEEE Annual International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Evolutionary Algorithms, Homomorphous Mappings, and Constrained Parameter Optimization</title>
		<author>
			<persName><forename type="first">Slawomir</forename><surname>Koziel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zbigniew</forename><surname>Michalewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="19" to="44" />
			<date type="published" when="1999">1999. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A Review of Constraint-Handling Techniques for Evolution Strategies</title>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Kramer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Comput. Intell. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">185063</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2010">2010. 2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Differentiable programming for image processing and deep learning in Halide</title>
		<author>
			<persName><forename type="first">Tzu-Mao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Micha?l</forename><surname>Gharbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fr?do</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ragan-Kelley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">PuDianNao : A Polyvalent Machine Learning Accelerator</title>
		<author>
			<persName><forename type="first">Daofu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianshi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoli</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinhong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengyuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Teman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaobing</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuehai</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunji</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="369" to="381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Cambricon: An instruction set architecture for neural networks</title>
		<author>
			<persName><forename type="first">Shaoli</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zidong</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinhua</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunji</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianshi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd ACM/IEEE Annual International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the 43rd ACM/IEEE Annual International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="393" to="405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Optimizing CNN Model Inference on CPUs</title>
		<author>
			<persName><forename type="first">Yizhi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruofei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vin</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yida</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 USENIX Conference on Usenix Annual Technical Conference (ATC)</title>
		<meeting>the 2019 USENIX Conference on Usenix Annual Technical Conference (ATC)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1025" to="1040" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">SAT-decoding in evolutionary algorithms for discrete constrained optimization problems</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Lukasiewycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Gla?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Haubelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J?rgen</forename><surname>Teich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Congress on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="page" from="935" to="942" />
			<date type="published" when="2007">2007. 2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Constrained Optimization via Multiobjective Evolutionary Algorithms</title>
		<author>
			<persName><forename type="first">Efr?n</forename><surname>Mezura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-</forename><surname>Montes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><forename type="middle">A Coello</forename><surname>Coello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multiobjective Problem Solving from Nature</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Constraint-handling in nature-inspired numerical optimization: Past, present and future</title>
		<author>
			<persName><forename type="first">Efr?n</forename><surname>Mezura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-</forename><surname>Montes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><forename type="middle">A Coello</forename><surname>Coello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="173" to="194" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Genocop III: a co-evolutionary algorithm for numerical optimization problems with nonlinear constraints. Proceedings of</title>
		<author>
			<persName><forename type="first">Zbigniew</forename><surname>Michalewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Nazhiyath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Evolutionary Computation</title>
		<imprint>
			<date type="published" when="1995">1995. 1995. 1995</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="647" to="651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A Hardware-Software Blueprint for Flexible Deep Learning Specialization</title>
		<author>
			<persName><forename type="first">Thierry</forename><surname>Moreau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Vega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Roesch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eddie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lianmin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josh</forename><surname>Fromm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziheng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Ceze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Krishnamurthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="8" to="16" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Automatically scheduling halide image processing pipelines</title>
		<author>
			<persName><forename type="first">Ravi</forename><surname>Teja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mullapudi</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dillon</forename><surname>Sharlet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ragan-Kelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kayvon</forename><surname>Fatahalian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">SpinalFlow: An Architecture and Dataflow Tailored for Spiking Neural Networks</title>
		<author>
			<persName><forename type="first">Surya</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Taht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Balasubramonian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Giacomin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre-Emmanuel</forename><surname>Gaillardon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th ACM/IEEE Annual International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the 47th ACM/IEEE Annual International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="349" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Using a genetic algorithm to optimize problems with feasibility constraints</title>
		<author>
			<persName><forename type="first">David</forename><surname>Orvosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First IEEE Conference on Evolutionary Computation</title>
		<meeting>the First IEEE Conference on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="1994">1994. 1994</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="548" to="553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Halide: A Language and Compiler for Optimizing Parallelism, Locality, and Recomputation in Image Processing Pipelines</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ragan-Kelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Connelly</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fr?do</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saman</forename><surname>Amarasinghe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and (PLDI)</title>
		<meeting>the 34th ACM SIGPLAN Conference on Programming Language Design and (PLDI)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="519" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">An Adaptive Penalty Approach for Constrained Genetic-Algorithm Optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Khaled</surname></persName>
		</author>
		<author>
			<persName><surname>Rasheed</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Infeasibility Driven Evolutionary Algorithm for Constrained Optimization</title>
		<author>
			<persName><forename type="first">Tapabrata</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hemant</forename><forename type="middle">Kumar</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amitay</forename><surname>Isaacs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Warren</forename><forename type="middle">F</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Stochastic ranking for constrained evolutionary optimization</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Runarsson</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="284" to="294" />
			<date type="published" when="2000">2000. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Evolution and optimum seeking</title>
		<author>
			<persName><forename type="first">Hans-Paul</forename><surname>Schwefel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth-generation computer technology series</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Very Deep Convolutional Networks for Large-Scale Image Recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Rethinking the Inception Architecture for Computer Vision</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Vasilache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksandr</forename><surname>Zinenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theodoros</forename><surname>Theodoridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">S</forename><surname>Moses</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sven</forename><surname>Verdoolaege</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.04730</idno>
		<title level="m">Tensor comprehensions: Framework-agnostic high-performance machine learning abstractions</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">UNIT: Unifying Tensorized Instruction Compilation</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Animesh</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leyuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yida</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tony</forename><surname>Nowatzki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE/ACM International Symposium on Code Generation and Optimization</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="77" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Adaptive evolutionary planner/navigator for mobile robots</title>
		<author>
			<persName><forename type="first">Jing</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zbigniew</forename><surname>Michalewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lixin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krzysztof</forename><surname>Trojanowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="18" to="28" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Penalty Function Methods for Constrained Optimization with Genetic Algorithms</title>
		<author>
			<persName><forename type="first">Ozgur</forename><surname>Yeniay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical &amp; Computational Applications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="45" to="56" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">AKG: automatic kernel generation for neural processing units using polyhedral transformations</title>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bojie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiong</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuefeng</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation (PLDI)</title>
		<meeting>the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation (PLDI)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1233" to="1248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Ansor: Generating High-performance Tensor Programs for Deep Learning</title>
		<author>
			<persName><forename type="first">Lianmin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengfan</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minmin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cody</forename><surname>Hao Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ameer</forename><surname>Haj-Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yida</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danyang</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koushik</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 14th USENIX Symposium on Operating Systems Design and Implementation (OSDI)</title>
		<meeting>14th USENIX Symposium on Operating Systems Design and Implementation (OSDI)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="863" to="879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">AMOS: Enabling Automatic Mapping for Tensor Computations On Spatial Accelerators with Hardware Abstraction</title>
		<author>
			<persName><forename type="first">Size</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renze</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anjiang</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yicheng</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qin</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bingyang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuhong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengen</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the 49th Annual International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="874" to="887" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Flex-Tensor: An Automatic Schedule Exploration and Optimization Framework for Tensor Computation on Heterogeneous System</title>
		<author>
			<persName><forename type="first">Size</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renze</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiwen</forename><surname>Sheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="859" to="873" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
