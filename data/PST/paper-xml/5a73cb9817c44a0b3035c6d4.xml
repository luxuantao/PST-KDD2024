<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Infrared small-dim target detection based on Markov random field guided noise modeling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2017-11-20">20 November 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chenqiang</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Chongqing Key Laboratory of Signal and Information Processing</orgName>
								<orgName type="institution">Chongqing University of Posts and Telecommunications</orgName>
								<address>
									<addrLine>Chongqing 40 0 065</addrLine>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lan</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Chongqing Key Laboratory of Signal and Information Processing</orgName>
								<orgName type="institution">Chongqing University of Posts and Telecommunications</orgName>
								<address>
									<addrLine>Chongqing 40 0 065</addrLine>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yongxing</forename><surname>Xiao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Chongqing Key Laboratory of Signal and Information Processing</orgName>
								<orgName type="institution">Chongqing University of Posts and Telecommunications</orgName>
								<address>
									<addrLine>Chongqing 40 0 065</addrLine>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qian</forename><surname>Zhao</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute for Information and System Sciences and Ministry of Education Key Lab of Intelligent Networks and Network Security</orgName>
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
								<address>
									<postCode>710049</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Deyu</forename><surname>Meng</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute for Information and System Sciences and Ministry of Education Key Lab of Intelligent Networks and Network Security</orgName>
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
								<address>
									<postCode>710049</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<address>
									<region>C. Gao)</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Infrared small-dim target detection based on Markov random field guided noise modeling</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2017-11-20">20 November 2017</date>
						</imprint>
					</monogr>
					<idno type="MD5">64721D645B0A3144C557EA683FB18E99</idno>
					<idno type="DOI">10.1016/j.patcog.2017.11.016</idno>
					<note type="submission">Received 23 February 2017 Revised 19 October 2017 Accepted 16 November 2017</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Infrared image Small target detection Mixture of Gaussians Markov random field Variational Bayesian</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Small target detection is one of the key techniques in infrared search and tracking applications. When small targets are very dim and of low signal-to-noise ratio, they are very similar to background noise, which usually causes high false alarm rates for conventional methods. To address this problem, we novelly treat the small-dim targets as a special sparse noise component of the complex background noise and adopt Mixture of Gaussians (MoG) with Markov random field (MRF) to model this problem. Firstly, the spatio-temporal patch image is constructed using several consecutive frames to utilize the temporal information of the image sequence. Then, the MRF guided MoG noise model under the Bayesian framework is proposed to model the small target detection problem. After that, by variational Bayesian, the small target component can be effectively separated from complex background noise. Finally, a simple adaptive segmentation method is used to extract small targets. Several series of experiments are done to evaluate the proposed method and the results show that the proposed method is robust for real infrared images with complex background.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Infrared small target detection is a key technique in many areas, including space surveillance systems, early-warning systems, object tracking systems, etc. Its task is to localize targets, e.g., boats in the sea, airplanes in the sky, vehicles in the land, etc., as shown as Fig. <ref type="figure" target="#fig_0">1</ref>  <ref type="bibr" target="#b0">[1]</ref> , in infrared images. Due to the long imaging distance, these targets are usually of very small sizes. Besides, the cloudy clutter, sea clutter or other clutter makes the background very complex and thus the targets are usually of low signal-to-noise ratio (SNR). Although the community has made a good progress on this task in past decades <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref> , it still remains an open problem, due to these challenges.</p><p>Up to now, a large number of approaches have been proposed. Some of them use the spatio-temporal cues to detect small targets. There are two representative categories among these methods: detection before track (DBT) <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref> and track before detection (TBD) <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref> . DBT can exploit the continuity of target's trajectories to reject the false targets in primary detection results obtained by single frame based detection methods. Thus, the performance of this kind of methods greatly depends on detection results from the sin-gle frame. In contrast, TBD can enhance the target signal energy by seeking the potential target trajectory and then accumulating the signal energy of the target along the trajectory before detecting targets. In this way, the enhanced target can be more robustly detected. The classical methods include 3D matched (directional) filters <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref> and other spatio-temporal methods <ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref> . Generally, the methods using spatio-temporal information depend on the assumption of the motion continuity of targets. Whether this assumption is true in practical applications would influence the final detection performance.</p><p>Different from previous methods, many other methods just use spatial information to detect targets. It is usually assumed that an infrared image f F ( x, y ) can be formulated as a combination of three components, which are a background component f B ( x, y ), a target component f T ( x, y ), and a noise component f N ( x, y ), respectively. Some methods attempted to firstly predict the background component f B ( x, y ), and then extract targets from the difference image between f F ( x, y ) and f B ( x, y ). The representative methods include Top-Hat filtering <ref type="bibr" target="#b17">[18]</ref> , Max-Median filtering <ref type="bibr" target="#b18">[19]</ref> and others methods <ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref> . In contrast, other methods directly model the target component f T ( x, y ) based on the infrared small target characteristics, such as GST <ref type="bibr" target="#b2">[3]</ref> , edge directional 2D LMS filter <ref type="bibr" target="#b22">[23]</ref> , sparse ring representation <ref type="bibr" target="#b23">[24]</ref> , modified gaussian function <ref type="bibr" target="#b24">[25]</ref> . Since these methods just focus on one aspect of the infrared image compo-  nents with slightly strong assumptions, they are usually suitable for specific applications while not generalizing well to others.</p><p>Inspired by the recent advances in low-rank matrix analysis <ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref> , the state-of-the-art method <ref type="bibr" target="#b0">[1]</ref> is to jointly consider all three components, namely f B ( x, y ), f T ( x, y ) and f N ( x, y ), in the lowrank framework. With an effective image construction method, the background and target components are approximately transformed into a low-rank matrix and a sparse matrix, respectively, and thus an infrared image can be seen as a combination of a low-rank matrix, a sparse matrix and a noise matrix. By applying the accelerated proximal gradient (APG) approach <ref type="bibr" target="#b29">[30]</ref> , the target and background components can be concurrently and effectively recovered.</p><p>However, for the case of complex background noise, the current assumption for noise is simple, which slightly ignores the influence of noise for the small target detection task. As a result, the model could not well match the practical problem with heavy noise and this would influence the robustness of small target detection.</p><p>In this paper, we focus on the problem of small target detection in the case that targets are not only small, but also dim. These characteristics make their SNRs so low that targets almost approximate to noise, as shown as Fig. <ref type="figure" target="#fig_1">2</ref> . In this situation, it is difficult to model separately the small target and noise components. The conventional methods usually have high false alarm rates on this task since there would be a lot of noise/clutter residual in the target image. To address this challenging problem, we do not explicitly discriminate the target from noise. Instead, we model the target component f T ( x, y ) and noise component f N ( x, y ) together, and as-sume that the target is a component of complex noise. Then we adopt the mixture of Gaussians (MoG) noise model <ref type="bibr" target="#b28">[29]</ref> to model the complex noise. Due to the sparse property of the small target, the corresponding component is generally significant different from the rest components of the MoG. Thus, the small target can be separated from the complex noise. Besides, the adjacent pixels of small targets are usually dependent each other, while the noise pixels are random. Thus, we adopt the Markov random field (MRF) model to guide the separation of small targets from noise, which makes the detected small targets full shapes. In order to tackle the challenge of the low SNR, the spatio-temporal information is utilized and this is different from the state-of-the-art work <ref type="bibr" target="#b0">[1]</ref> which is just based on spatial information in a single image.</p><p>The remainder of this paper is organized as follows. Section 2 describes the proposed method in detail, including the spatio-temporal patch image model, problem formulation, solution and the small target extraction framework. Experiments and comparisons between the proposed method and the baseline methods are provided in Section 3 . Conclusions are given in Section 4 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The proposed method</head><p>In this section, we first introduce the construction and reconstruction method of a spatio-temporal patch image. Then, we describe the formulation of small target detection problem based on MoG and its solution in detail. After that, we present small target extraction and introduce the full framework of the proposed method, including the implementation steps. Finally, we analyze the computational complexity of the proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Spatio-temporal patch image</head><p>Similar to our previous work <ref type="bibr" target="#b0">[1]</ref> , given an image sequence f 1 , f 2 , , f d and a cubic sliding window with a size of w × h × d , we can obtain a series of cubic patches. Then, a 2D matrix can be constructed by orderly vectorizing cubic patches as its columns, as shown in Fig. <ref type="figure">3</ref> . Contrariwise, as shown in Fig. <ref type="figure">4</ref> , after being processed, the constructed 2D matrix can be reconstructed into an image sequence with d frames by the inverse processing with a minor modification. Namely, for the pixel with overlap patches, its value is determined by pooling multiple different values into one. In this paper, we experimentally choose the median pooling method as did in our previous work <ref type="bibr" target="#b0">[1]</ref> . Here, our spatio-temporal patch image is a generalization of the spatial patch image in our previous work <ref type="bibr" target="#b0">[1]</ref> , in order to utilize the temporal information of small targets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Formulation</head><p>Assume that an image sequence ( f 1 , f 2 , , f d ) containing small targets is constructed into a 2D patch image matrix F with a size of m × n by the construction method introduced in Section 2.1 . F can be seen as a combination of background B and a complex noise E as follows:</p><formula xml:id="formula_0">F = B + E. (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>Here the small target component T is integrated into the noise E , since the targets can be seen as a component of noise in our problem discussed previously. We consider the Eq. ( <ref type="formula" target="#formula_0">1</ref>) as a generative model to obtain the B and E . Background component B modeling: According to the infrared imaging mechanism, thermal radiation is affected by the atmospheric scattering and diffraction when transmitting in the atmosphere from a long distance. Therefore, the energy of the thermal radiation captured by the infrared imaging sensor is low and the background image is usually blurred. Though there are heavy local fluctuations in sky and sea-sky backgrounds, the background still changes slowly on the whole and the non-local background blocks are usually similar as discussed in <ref type="bibr" target="#b0">[1]</ref> . Thus, the cubic patches are approximately correlated to each other. As a result, B can be considered as a low rank matrix. We model B as follows <ref type="bibr" target="#b27">[28]</ref> :</p><formula xml:id="formula_2">B = U V T = R r=1 u •r v T •r , (<label>2</label></formula><formula xml:id="formula_3">)</formula><p>where</p><formula xml:id="formula_4">U ∈ R m ×R , V ∈ R n ×R , R is the initial rank value of B , and u • r ( v • r ) is the r th column of U ( V ).</formula><p>To guarantee the low rank nature of B , we need to ensure that U and V are of column sparsity. This goal can be achieved by imposing the following priors on U and V :</p><formula xml:id="formula_5">u •r ∼ N ( u •r | 0 , γ -1 r I m ) , v •r ∼ N ( v •r | 0 , γ -1 r I n ) ,<label>(3)</label></formula><p>where I m denotes a m × m identity matrix. The conjugate priors on each γ r is:</p><formula xml:id="formula_6">γ r ∼ Gam ( γ r | a 0 , b 0 ) , (<label>4</label></formula><formula xml:id="formula_7">)</formula><p>where Gam ( γ r | a 0 , b 0 ) is a gamma distribution parameterized by a 0 and b 0 . It has been validated that such a modeling could lead to large precision values of some γ s, and hence result in a good low-rank estimate of B <ref type="bibr" target="#b27">[28]</ref> .</p><p>Noise component E modeling: As discussed previously, the small-dim targets in infrared images can be regarded as a special kind of noise. Therefore, we can model the small targets and background noise together. This can be achieved by using the mixture of Gaussians, which is a universal approximator to any continuous probability distribution <ref type="bibr" target="#b30">[31]</ref> and has been verified to be effective in modeling the complex noise <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b31">32]</ref> . Thus, the noise E can be modeled as a mixture of K Gaussians:</p><formula xml:id="formula_8">E i j ∼ K k =1 π k N (x | μ k , τ -1 k ) , (<label>5</label></formula><formula xml:id="formula_9">)</formula><p>where E ij is the element of E at the position ( i, j ) and N (x | μ k , τ -1 k ) represents the Gaussian distribution with mean μ k and precision τ k . The precision is normally defined as the reciprocal of the variance. π k is the mixing proportion with π k ≥ 0 and K k =1 π k = 1 . The precision τ k determines the probability distribution shape and thus can constrain the sparsity degree of the noise. For example, when τ k is large, most of the elements of the k th noise component would approach zeros. As a result, this noise component can be considered as a sparse noise matrix.</p><p>For the convenience of inference, Eq. ( <ref type="formula" target="#formula_8">5</ref>) can be equivalently expressed as a two-level generative model by introducing the indicator variables z ijk <ref type="bibr" target="#b28">[29]</ref> :</p><formula xml:id="formula_10">E i j | Z i j ∼ K k =1 N ( E i j | μ k , τ -1 k ) z i jk , Z i j ∼ Multinomial ( Z i j | π ) ,<label>(6)</label></formula><p>where</p><formula xml:id="formula_11">Z i j = z i j1 , . . . , z i jK ∈ { 0 , 1 } K , K k =1 z i jk = 1 and Z ij follows a</formula><p>multinomial distribution parameterized by π . Besides, the priors of the parameters in the MoG are brought in the model to further complete the Bayesian framework:</p><formula xml:id="formula_12">μ k , τ k ∼ N( μ k | μ 0 , ( β 0 τ k ) -1 ) Gam ( τ k | c 0 , d 0 ) , π ∼ Dir ( π | α 0 ) ,<label>(7)</label></formula><p>where</p><formula xml:id="formula_13">Dir ( π | α 0 ) is a dirichlet distribution parameterized by α 0 = ( α 01 , . . . , α 0 K ) .</formula><p>Obviously, compared to current research works, our method has more feasibility since our noise modeling can handle more complex situations. To further match the practical problem, we will embed the spatio-temporal continuity prior into our model in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">MRF guided MoG</head><p>Considering the Markov property of the image pixels, the characteristics of the pixel is mainly affected by the adjacent pixels. If a pixel belongs to a small target, its adjacent pixels will also probably belong to this target. Similarly, if a pixel is noise, its adjacent pixels have higher probability to be noise, too. In order to effectively utilize this property to help separate the small target component from other noise components, we introduce a four-neighborhood Markov Random Field (MRF) <ref type="bibr" target="#b32">[33]</ref> into the MoG model as follows:</p><formula xml:id="formula_14">E i j | Z i j ∼ K k =1 N ( E i j | μ k , τ -1 k ) z i jk , Z i j ∼ Multinomial ( Z i j | π ) 1 C k (p,q ) ∈ N(i, j) exp (λ(2 z i jk -1)(2 z pqk -1)) ,<label>(8)</label></formula><p>where N ( i, j ) denotes the four-neighborhood of the pixel ( i, j ), and C is a normalization constant. λ is the parameter of the MRF, and can be tuned to adjust the influence of the adjacent pixels. If the central pixel and adjacent pixels are generated by the same Gaussian component, the bigger weight will be assigned to the multinomial distribution. This can increase the probability that the central pixel is generated from this Gaussian component. Combining the Eqs. ( <ref type="formula" target="#formula_6">4</ref>) -( <ref type="formula" target="#formula_14">8</ref>) , given F , our goal is to infer the posterior of all involved variables:</p><formula xml:id="formula_15">p ( U, V, Z, μ, τ, π , γ | F ) , (<label>9</label></formula><formula xml:id="formula_16">) where Z = { z i j } , μ = ( μ 1 , . . . , μ K ) , τ = ( τ 1 , . . . , τ K ) and γ = ( γ 1 , . . . , γ R ) .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Solution by variational Bayesian</head><p>As in <ref type="bibr" target="#b28">[29]</ref> , we use the variational Bayesian (VB) method <ref type="bibr" target="#b30">[31]</ref> to infer the posterior of Eq. ( <ref type="formula" target="#formula_15">9</ref>) . Here, we just briefly describe the inference method and the details can be found in <ref type="bibr" target="#b28">[29]</ref> . VB computes the posterior distribution approximation q ( X ) by minimizing the Kullback-Leibler(KL) divergence to p ( X | D ):</p><formula xml:id="formula_17">q * (X ) = min q ∈ KL (q || p) = min q ∈ -q (X ) ln { p(X | D ) q (X ) } d X ,<label>(10)</label></formula><p>where denotes the set of probability densities with certain restrictions to make the minimization tractable. Using mean field approximation, we employ the posterior factorization q (X ) = i q i ( x i ) such that the posterior distribution of each unknown is estimated by holding the others fixed and using their most recent distributions:</p><formula xml:id="formula_18">q * j ( x j ) = exp ln p(X, D ) X\ x j exp ln p(X, D ) X\ x j d x j , (<label>11</label></formula><formula xml:id="formula_19">)</formula><p>where • denotes the expectation and X \ x j denotes the set of X with x j removed. According to the mean field theory, the variational approximation distribution of Eq. ( <ref type="formula" target="#formula_15">9</ref>) can be presented as: <ref type="bibr" target="#b11">(12)</ref> where</p><formula xml:id="formula_20">q ( U, V, Z, μ, τ, π , γ ) = i q ( u i • ) j q ( v j• ) i j q ( z i j ) k q ( μ k , τ k ) q (π ) r q ( γ r ) ,</formula><formula xml:id="formula_21">u i • ( v j • ) denotes i -th ( j -th ) row of U ( V ). Since all distri-</formula><p>butions in MoG noise model are in the conjugate exponential family, the form of each posterior approximation can be found without major difficulties.</p><p>Estimation of noise component: The parameters involved in the noise component are μ, τ , Z and π . Based on the prior imposed in Eq. ( <ref type="formula" target="#formula_12">7</ref>) and its conjugate property, we can get the follow-</p><formula xml:id="formula_22">ing update equation for each μ k , τ k ( k = 1 , . . . , K): q (μ k , τ k ) = N (μ k | m k , (β k τ k ) -1 ) Gam (τ k | c k , d k ) , (<label>13</label></formula><formula xml:id="formula_23">)</formula><p>where</p><formula xml:id="formula_24">β k = β 0 + i j z i jk , m k = 1 β k β 0 μ 0 + i j z i jk ( f i j -u i • v j• T ) , c k = c 0 + 1 2 i j z i jk , d k = d 0 + 1 2 i j z i jk ( f i j -u i • v T j• ) 2 + β 0 μ 2 0 -<label>1</label></formula><formula xml:id="formula_25">β k i j z i jk ( f i j -u i • v j• T ) + β 0 μ 0 2 ⎫ ⎬ ⎭ .</formula><p>Similarly, it is easy to obtain the update equation for mixing proportions π :</p><formula xml:id="formula_26">q (π ) = Dir (π | α) , d<label>(14)</label></formula><p>where</p><formula xml:id="formula_27">α = (α 1 , . . . , α K ) , α k = α 0 k + i j z i jk .</formula><p>The MoG used in this paper is constrained by the MRF, the effect of which is clearly found in the updating of the indicators Z. The variational posterior for Z can be presented as:</p><formula xml:id="formula_28">q (Z i j ) = k r i jk z i jk , (<label>15</label></formula><formula xml:id="formula_29">)</formula><p>where</p><formula xml:id="formula_30">r i jk = ρ i jk k ρ i jk , (<label>16</label></formula><formula xml:id="formula_31">)</formula><formula xml:id="formula_32">ρ i jk = 1 2 ln τ k + ln π k + λ (p,q ) ∈ N(i, j) z pqk - 1 2 τ k f i j -u i • v T j• -μ k 2 - 1 2 ln 2 π . (<label>17</label></formula><formula xml:id="formula_33">)</formula><p>Estimation of background component: The parameters involved in the background component are U, V and γ . For each row u i • of U , using the factorization (12) , we can get</p><formula xml:id="formula_34">q (u i • ) = N (u i • | μ u i • , u i • ) ,<label>(18)</label></formula><p>with mean μ u i • and covariance u i • given by</p><formula xml:id="formula_35">μ T u i • = u i • k τ k j z i jk ( f i j -μ k ) v j• T , u i • = k τ k j z i jk v T j• v j• + -1</formula><p>, where = diag ( γ ) . Similarly, for each row v j • of V , we have</p><formula xml:id="formula_36">q (v j• ) = N (v j• | μ v j• , v j• ) ,<label>(19)</label></formula><p>where</p><formula xml:id="formula_37">μ T v j• = v j• k τ k i z i jk ( f i j -μ k ) u i • T , v j• = k τ k i z i jk u T i • u i • + -1</formula><p>.</p><p>For γ which controls the rank of B , we have where</p><formula xml:id="formula_38">q (γ r ) = Gam (γ r | a r , b r ) , (<label>20</label></formula><formula xml:id="formula_39">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MRF guided MoG noise modeling and inference</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Final result</head><note type="other">ConstrucƟon</note><formula xml:id="formula_40">a r = a 0 + m + n 2 , b r = b 0 + 1 2 u T •r u •r + v T •r v •r .</formula><p>Then, the optimal U, V and r ijk are obtained after alternatively iteration. Through E = F -U V T , we can finally separate noise component from the background.</p><p>In our implementation, we initialize a 0 , b 0 , c 0 , d 0 and α 01 , . . . , α 0 K with 10 -6 , and U and V are initialized through SVD. Besides, a r , b r , c r , d k , γ r , τ k , μ k , z ijk , π k are initialized randomly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Small target extraction</head><p>As r ijk in Eq. ( <ref type="formula" target="#formula_28">15</ref>) presents the probability that the noise components are generated by the k th Gaussian component, the complex noise E can be decomposed into K components E 1 , E 2 , , E m , , E K using the maximum probability criteria as:</p><formula xml:id="formula_41">E m i, j = E i, j , if m = arg max k =1 , 2 , ••• ,K ( r i jk ) , 0 , else .<label>(21)</label></formula><p>As discussed previously, small targets are contained in one of K components. Once we obtain K components, we need to determine which component contains a small targets. As we discussed previously, the spatial distributions of the K components are different and this is an important cue to select the small target component. In this paper, instead of directly selecting the small target component, we first reconstruct K components into their corresponding image sequences E</p><p>1 , E 2 , . . . , E m , . . . , E K using the method in Section 2.1 . Then, for simplicity, we just calculate their variances and the largest one E i is determined as the small target component as follows:</p><formula xml:id="formula_42">i = arg max k =1 , 2 , ••• ,K v ar E k , (<label>22</label></formula><formula xml:id="formula_43">)</formula><p>where var ( • ) means computing variance. Our experimental results show this simple method can work well for different infrared images.</p><p>It is inevitable that the reconstructed small target images still contain some residual noise. In order to extract the small target, a simple segmentation method is applied to each individual image using an adaptive threshold T determined by: T = max (v min , μ + kσ ) , <ref type="bibr" target="#b22">(23)</ref> where μ and σ is the mean value and standard deviation of the small target image. k and v min are constants determined experientially. We set k = 0 . 05 and v min = 0 . 85 for all test sequences. Here, v min is to delete false targets with small values.</p><p>The framework of our method is shown in Fig. <ref type="figure" target="#fig_3">5</ref> and the detailed steps are summarized as follows:</p><p>Step 1 : Construct the spatio-temporal patch image F with the given infrared image sequence using the method in Section 2.1 .</p><p>Step 2 : MoG noise model under the Bayesian framework is built by formulating the low rank component B and complex noise E with Eqs. ( <ref type="formula" target="#formula_2">2</ref>) and ( <ref type="formula" target="#formula_8">5</ref>) , respectively.</p><p>Step 3 : VB is utilized to infer the parameters and variables in the proposed model. Then, F is decomposed into B and E based on the results of the inference.</p><p>Step 4 : Decompose E into K components according to Eq. ( <ref type="formula" target="#formula_41">21</ref>) and reconstruct components into image sequences with the method in Section 2.1 .</p><p>Step 5 : Use Eq. ( <ref type="formula" target="#formula_42">22</ref>) to select the small target images.</p><p>Step 6 : Segment small target images by Eq. ( <ref type="formula">23</ref>) and postprocess the segmented result to obtain the detection results.</p><p>In Step 6 , some post-processing techniques, such as basic region analysis techniques, or morphological techniques, can be used to refine the segmentation results. Generally speaking, the postprocessing is still an important step to achieve good detection results in practice. However, for fair comparison with the baseline methods, we do not perform post-processing and directly use the segmentation results to evaluate the performance in our experiments in Section 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.">Computational complexity</head><p>The computational cost of the proposed model consists of three parts: the inference of the MoG noise model, the reconstruction of the spatio-temporal patch image and the segmentation of target.</p><p>Assuming that the size of F is m × n , it is clear to see that the cost of variational inference of the parameters of the MoG noise </p><formula xml:id="formula_44">((m + n ) R 3 + kmnR ) per iteration, where O ((m + n ) R 3 )</formula><p>is the computational time of inverting a R × R matrix in inferring each u i • and v j • .</p><p>The computational cost of the reconstruction is contributed by the median operation. Assuming that w is the overlapping pixel number during the transformation from the spatio-temporal patch image to the reconstruction image, O ( w ) is needed in the median operation for each pixel. When the size of original image f ( x, y ) is g × h , the computational cost of the reconstruction is O ( ghw ).</p><p>As to the target segmentation, just a simple comparison operation is implemented and the entire cost of this step is O ( gh ). In summary, when the iteration times of the inference of the model is N , the whole computational complexity of the proposed model</p><formula xml:id="formula_45">is around O (ghw + N((m + n ) R 3 + kmnR ) + gh ) .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head><p>In this section, we firstly introduce the evaluation metrics and baseline methods used in this paper. Secondly, we discuss the key parameters of our method. Finally, we compare the performance of our method with the baseline methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Evaluation metrics and baseline methods</head><p>For objective evaluation, the signal to clutter ratio gain (SCRG), background suppression factor (BSF), detection probability P d and false alarm rate F a are adopted <ref type="bibr" target="#b23">[24]</ref> . SCRG and BSF computed on a single frame can describe the ability of target enhancement, as well as the clutter suppression. They are important indictors to final detection performance. The SCRG is defined as:</p><formula xml:id="formula_46">SCRG = SC R out SC R in , (<label>24</label></formula><formula xml:id="formula_47">)</formula><p>where SCR in and SCR out are respectively the signal to clutter ratio of the original and result images. Here, SCR is defined by: SCR</p><formula xml:id="formula_48">= | μ t -μ b | σ b , (<label>25</label></formula><formula xml:id="formula_49">)</formula><p>where μ t is the average pixel value of the target, μ b is the average pixel value of the pixels in neighboring area around the target, and σ b is the standard deviation of the neighboring area. The size of the neighbour is (a</p><formula xml:id="formula_50">+ 2 d) × (b + 2 d)</formula><p>, where the size of small target is a × b as show as in Fig. <ref type="figure" target="#fig_4">6</ref> . We set d = 15 in this paper. BSF is defined as follows:</p><formula xml:id="formula_51">BSF = C in C out , (<label>26</label></formula><formula xml:id="formula_52">)</formula><p>where C in and C out denote the standard deviation of the full image before and after processing, respectively. In Eqs. ( <ref type="formula" target="#formula_46">24</ref>) and ( <ref type="formula" target="#formula_51">26</ref>) , the computation of both metrics includes standard deviation which may be close to zero when the suppressed background is very clean. In this case, these two metrics may approach to infinity. Specifically, this case is prone to happen for SCRG whose standard deviation is calculated based on a local background area. To address this problem, we adopt another metric to evaluate the ability of target enhancement and clutter suppression, namely contrast gain (CG) which is defined as:</p><formula xml:id="formula_53">CG = CO N out CO N in , (<label>27</label></formula><formula xml:id="formula_54">)</formula><p>where CON in and CON out are the contrast (CON) of the original and result images, respectively, and CON is defined as:</p><formula xml:id="formula_55">CON = | μ t -μ b | , (<label>28</label></formula><formula xml:id="formula_56">)</formula><p>where μ t and μ b are the same as those in Eq. ( <ref type="formula" target="#formula_48">25</ref>) .</p><p>Detection probability P d and false alarm rate F a are used to directly evaluate the detection performance and defined as:</p><formula xml:id="formula_57">P d = N a N b , F a = N f N I , (<label>29</label></formula><formula xml:id="formula_58">)</formula><p>where N a is the number of true detections, N b is the number of actual targets, N f is the number of false detections and N I is the number of sequence frames.</p><p>The baseline methods chosen in this paper include the IPI model <ref type="bibr" target="#b0">[1]</ref> , Top-hat <ref type="bibr" target="#b33">[34]</ref> , MaxMean and MaxMedian filtering <ref type="bibr" target="#b18">[19]</ref> . Since the MRF constraint is one of our contributions in our method, we also use the version of our method without MRF constraint as a baseline method, denoted as MoG .</p><p>We use five consecutive real image sequences<ref type="foot" target="#foot_0">1</ref> to test the proposed methods. The sequences were recorded with static infrared camera. The five sequences consist of 108, 123, 134, 10 0, 10 0 frames, respectively. The representative frames of each sequence are shown in the first column of Fig. <ref type="figure" target="#fig_0">14</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Effect of parameters</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Number of frames</head><p>In order to utilize the temporal information, the cubic patch is used. Thus, there are two questions: (1) Is the temporal information helpful? (2) How many frames should be used in a cubic patch? To answer these questions, we test cases of different numbers of frames, including the single frame case, on two real image sequences of sky and sea-sky backgrounds, and the corresponding receiver operating characteristic (ROC) curves are drawn in Fig. <ref type="figure">7</ref> .</p><p>Here, the noise component parameter K in the MoG noise model is set as K = 3 . From Fig. <ref type="figure">7</ref> , we can observe that the cases of multiple frames are obviously better than the single frame case. This means that the temporal information is really helpful for performance improvement. For the cases of multiple frames, when low false alarm rate, the performance seems to increase with the temporal length, especially when false alarm rate is less than around 0.15. However, when the false alarm rate is more than 0.2, this trend is not obvious. Thus, considering the fact that the complexity of the algorithm will increase greatly with the temporal length, in this paper we just use three frames for cubic patches. Actually, a long temporal length may decrease the correlation between cubic patches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Number of components</head><p>The noise component parameter K in the MoG noise model is an important parameter. On the one hand, the target component may contain noise if K is too small. On the other hand, there may be redundant components if K is too large. This can be easily observed through Figs. 8-10 which correspond to the cases of K = 2 , K = 3 , K = 4 , respectively. If we assume two noise components ( K = 2 ), the sparse noise may be mixed with the small target component, as shown as "Component1" in Fig. <ref type="figure">8</ref> . On the contrary, if we assume four noise components ( K = 4 ), there may be a redundant component, as shown as "Component4" in Fig. <ref type="figure" target="#fig_0">10</ref> . When K = 3 , the divided components exactly correspond to small target, sparse noise and dense noise components respectively, as shown as "Component1", "Component2" and "Component3" in Fig. <ref type="figure">9</ref> . To further verify the above discussion, we draw the ROC curves of different values for K on five real image sequences, as shown in Fig. <ref type="figure" target="#fig_0">11</ref> . It can be obviously observed that the performance is best when K = 3 . Specifically, for Sequence 2 to 5, the configuration of K = 3 has considerably higher probabilities of detection ( P d ) than other values. It is worth noting that in Fig. <ref type="figure" target="#fig_0">11</ref> (a) the ROC curve with K = 4 is better than that with K = 3 when F a &lt; 0.5. This is because the separated target components with K = 4 have cleaner backgrounds than those with K = 3 for most of images. However, because the separated target components of some images lose the real small targets when K = 4, the P d of the ROC curve can not reach 1. But this does not happen for K = 3. In following experiments, we always set K = 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Performance evaluation</head><p>In this section, we first evaluate the effect of the MRF constraint in the proposed model and then subjectively and objectively evaluate the performance of small target enhancement of the pro- posed method in comparison with baseline methods. Finally, we use five real infrared image sequences to evaluate the detection performance.</p><note type="other">Original image Component 1 Component 2 Component 3</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">The effect of MRF</head><p>According to the characterises of infrared small targets, we adopt MRF to guide the MoG noise modeling. To verify the effectiveness of the MRF, we also test the version of the proposed method without MRF constraint, namely MoG. The results with/without MRFs for the same images are shown in Figs. 12 and 13 , respectively. We can obviously observe that the MRF constraint can effectively help clean the background clutter in the small target image, as shown as "Component1" in Fig. <ref type="figure" target="#fig_1">12</ref> . In contrast, without MRF constraint the small target image from original MoG noise model <ref type="bibr" target="#b28">[29]</ref> has obvious noise residual, as shown as "Component1" in Fig. <ref type="figure" target="#fig_0">13</ref> . These noise residual could cause a high false alarm rate in the following detection procedure. Our method with MRF constraint can effectively avoid this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">Comparisons to baseline methods</head><p>We compare the abilities of background suppression and target detection of our method and baseline methods. For both IPI model and our method, we set the patch size as 50 × 50, and the step size as 10. And the filter sizes of methods TopHat, MaxMean , and MaxMedian are set as 9 × 9 which is the usual configuration <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b23">24]</ref> . Fig. <ref type="figure" target="#fig_0">14</ref> shows results of different methods without segmentation on five real infrared images with heavy background clutters. Here, these original images are from five infrared image sequences, respectively. We can see that both the IPI model and our method have cleaner backgrounds than other four baseline methods, and   TopHat, MaxMean, MaxMedian and MoG have relatively dense noise residual. Comparing our method to IPI model , we can observe that IPI model still has some sparse noise residual while our method has better results. To objectively evaluate the performance of background suppression of our method, the SCRG and BSF are computed based on Fig. <ref type="figure" target="#fig_0">14</ref> and the results of different methods are listed in Table <ref type="table" target="#tab_0">1</ref> . We can obviously see that the proposed method can get higher performance than baseline methods for both two metrics. Tophat has the smallest values for its failure in suppressing background clutters and reserving the target information. Since MaxMean and MaxMedian can retain parts of the target information, it is a little higher than TopHat , but obviously lower than both the IPI model and the proposed approach for two metrics. the IPI model obtains better BSF performance in images of Seq. 3 and Seq.</p><note type="other">Original image Component 1 Component 2 Component 3</note><p>5. This is because the background intensity of the results is higher in the IPI model , making the standard deviation smaller. MoG has unbalanced performance in different images, for its instability. This further means that the MRF constraint is very important for small target noise modeling.</p><p>As discussed in Section 3.1 , the case that standard deviation may be close to zero prevents us from calculating the average values of above used metrics for all images. Instead, we calculate average contrast gain of all images for each sequence and the results are listed in Table <ref type="table">2</ref> . It is obviously observed that the proposed method totally has the best results among all baseline methods. According to the definition of CG in Eq. ( <ref type="formula" target="#formula_55">28</ref>) , the CG is the gray value difference of background and small targets. The results of Table <ref type="table">2</ref> means that our method has good performance on enlarg-  ing this gray value difference. This will greatly help the following threshold segmentation task for extracting small targets.</p><p>Fig. <ref type="figure" target="#fig_8">15</ref> shows the ROC curves of the methods for five image sequences, respectively. It can be seen that the proposed method has better detection performance than baseline methods. For Sequence 1, 2, 4 and 5, our method has higher probabilities of detection ( P d ) and relatively lower false alarm rates ( F a ). For Sequence 3, the IPI model has a little higher performance than our method when F a ≤ 1.2. However, our method reaches around 0.97 (97%) in a faster speed than the IPI model when F a &gt; 1.2. Fig. <ref type="figure" target="#fig_8">15</ref> also shows that the MoG without MRF constraint has relatively poor detection performance.</p><p>Currently, modern detection algorithms such as Convolutional Neural Networks show astonishing results in visual object detection. For comparison, we test the state-of-the-art object detection method, namely the powerful faster-RCNN method <ref type="bibr" target="#b34">[35]</ref> . We resize the anchor size to 16 2 , 32 2 and 64 2 pixels to adapt to the scales of infrared small targets. We randomly split our dataset to 1.5:1 for training set and test set, and use the ZF model for training. The representative test results are shown in Fig. <ref type="figure" target="#fig_9">16</ref> . It can be observed that there are a number of false detections. The reason could be that the small targets are too small, and thus the feature of small targets is not obvious, with heavy background clutter. This characteristic of small targets makes the powerful ability of CNN weak on feature learning.</p><p>As discussed above, the proposed algorithm mainly handles the case of small-dim targets, similar to noise. However, it is valid for a certain range of small target size. In infrared small target applications, a common problem is that small target sizes in the image could become large during approach, e.g., in missile systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original images</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Result images</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Segmented images</head><p>Fig. <ref type="figure" target="#fig_0">18</ref>. The detection results of the proposed method on different background images without any target.</p><p>Fig. <ref type="figure" target="#fig_10">17</ref> shows the results of this situation. It can be seen that even for infrared targets with a little large size, the proposed method still can get good results. Generally, the small target detection algorithm is applied to the early-warning stage. In this stage, the interested targets are just of a small size. Following this stage is a tracking stage. During the tracking stage, we can switch an appropriate the detection algorithm if we find the size of the target becomes quite large. Furthermore, to evaluate the performance on the case of no target, we test our method on different background images without targets. As can be seen in Fig. <ref type="figure" target="#fig_0">18</ref> , the test results are clean without false alarms. Thus, the proposed method is also robust in infrared images without any target.</p><p>For utilizing temporal information, the proposed method has a delay of several frames. For the case of three consecutive images for the patch image construction, there is a delay of two frames. If the frame rate of one infrared sensor is 30 frames per second, there is just a delay of around 0.067s, assuming that the proposed method can real-timely run on an extremely optimal configuration of the software and hardware. If this delay can not meet the requirement, we can reduce the number of consecutive images for the patch image construction. Especially, our method supports only one image for the patch image construction without temporal information. As discussed in Section 3.2.1 , our method can still achieve good performance even just using one frame.</p><p>Averagely, for one frame with the size of 256 × 200, the real running time of the proposed method is around 93 seconds with Matlab implementation, running on a PC with I7 CPU, 64GB of memory. Actually, the real running time depends on many factors, including the iteration times of VB, the number of frames for the patch image, the patch size and so on. For practical applications, these parameters can be further optimized to reach a good tradeoff between the performance and running time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>A novel method based on MRF guided MoG noise model is presented in this paper, to address the small-dim target detection problem with heavy background noise. Spatio-temporal patch images are constructed using local cubic patches. And then the background, small target and noise components are formulated into a unified model under the Bayesian framework. After that, variational Bayesian is adopted to solve the proposed model and the experiments show that the very small and dim targets can be effectively separated from complex background noise by our methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Representative targets (upper) and the corresponding 3-D surfaces (lower) in different backgrounds (normalized) [1] . (a) A dim small ship target in sea-sky background. (b) A bright ship target in sea-sky background. (c) A dim aeroplane target in sky cloud background. (d) A bright vehicle target in sky-ground background.</figDesc><graphic coords="2,65.03,57.26,456.00,202.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Two representative small-dim target images. (a) A dim small ship target in sea-sky background. (b) A dim aeroplane target in sky cloud background.</figDesc><graphic coords="2,33.54,304.20,249.60,113.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .Fig. 4 .</head><label>34</label><figDesc>Fig. 3. The construction of the spatio-temporal patch image with sequential frames.</figDesc><graphic coords="3,166.82,213.68,126.52,131.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The framework of the proposed method.</figDesc><graphic coords="5,356.84,57.26,71.35,222.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. The neighboring background area of a small target.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .Fig. 8 .</head><label>78</label><figDesc>Fig. 7. ROC curves of different tem poral lengths on two image sequences. (A1) and (B1) are the representative frames of the two image sequences. (A2) and (B2) are the corresponding ROC curves of the proposed method.Original imageBackground image Componet 1 Componet 2</figDesc><graphic coords="7,124.88,454.34,249.22,132.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 9 .Fig. 10 .Fig. 11 .</head><label>91011</label><figDesc>Fig. 9. The results of our method with three Gaussian components. Original image Component 1 Component 2 Component 3 Component 4</figDesc><graphic coords="8,97.58,238.58,284.46,116.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 12 .Fig. 13 .Fig. 14 .</head><label>121314</label><figDesc>Fig. 12. The results of the proposed method (with MRF constraint).</figDesc><graphic coords="9,122.78,73.76,360.07,134.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. The ROC curves of six methods for five real image sequences. (a) Result of Sequence 1. (b) Result of Sequence 2. (c) Result of Sequence 3. (d) Result of Sequence 4. (e) Result of Sequence 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. The representative detection results of the faster-RCNN method [35] on five real infrared images. (a) The result from the sequence 1. (b) The result from the sequence 2. (c) The result from the sequence 3. (d) The result from the sequence 4. (e) The result from the sequence 5.</figDesc><graphic coords="11,45.80,57.92,513.90,80.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17. The representative detection results of the proposed method on real infrared images with different target sizes. (a) The original image and result with a moderate target size. (b) The original image and result with a little large target size.</figDesc><graphic coords="11,43.35,193.49,249.60,213.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>The evaluation results of SCRG and BSF of different methods for images in the first column in Fig.14.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Methods</cell><cell cols="5">image of Seq. 1</cell><cell cols="4">image of Seq. 2</cell><cell cols="4">image of Seq. 3</cell><cell>image of Seq. 4</cell><cell>image of Seq. 5</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">SCRG</cell><cell cols="2">BSF</cell><cell></cell><cell cols="2">SCRG</cell><cell>BSF</cell><cell></cell><cell cols="2">SCRG</cell><cell>BSF</cell><cell></cell><cell>SCRG</cell><cell>BSF</cell><cell>SCRG</cell><cell>BSF</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Max-mean</cell><cell cols="2">3.44</cell><cell cols="2">7.07</cell><cell></cell><cell cols="2">4.68</cell><cell cols="2">1.91</cell><cell cols="2">6.38</cell><cell cols="2">2.92</cell><cell>1.98</cell><cell>1.17</cell><cell>2.52</cell><cell>1.17</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Max-median</cell><cell cols="2">2.17</cell><cell cols="2">9.83</cell><cell></cell><cell cols="2">5.94</cell><cell cols="2">2.06</cell><cell cols="2">3.76</cell><cell cols="2">5.55</cell><cell>1.73</cell><cell>1.51</cell><cell>2.76</cell><cell>1.4</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Top-hat</cell><cell cols="2">2.27</cell><cell cols="2">5.96</cell><cell></cell><cell cols="2">3.04</cell><cell cols="2">0.75</cell><cell cols="2">7.72</cell><cell cols="2">2.48</cell><cell>0.71</cell><cell>0.87</cell><cell>1.91</cell><cell>1.21</cell></row><row><cell></cell><cell></cell><cell></cell><cell>IPI</cell><cell></cell><cell cols="2">7.31</cell><cell cols="2">8.03</cell><cell></cell><cell cols="2">15.38</cell><cell cols="2">5.88</cell><cell cols="2">10.12</cell><cell cols="2">27.86</cell><cell>8.96</cell><cell>12.37</cell><cell>3.81</cell><cell>6.98</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">MoG</cell><cell cols="2">6.21</cell><cell cols="2">9.61</cell><cell></cell><cell cols="2">9.58</cell><cell cols="2">2.95</cell><cell cols="2">2.83</cell><cell cols="2">0.32</cell><cell>5.07</cell><cell>1.69</cell><cell>3.44</cell><cell>0.52</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Ours</cell><cell cols="2">19.41</cell><cell cols="3">26.79</cell><cell cols="2">31.65</cell><cell cols="2">9.76</cell><cell cols="2">14.95</cell><cell cols="2">18.76</cell><cell>17.05</cell><cell>20.88</cell><cell>6.6</cell><cell>3.55</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Table 2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="14">The evaluation results of average CG values of different methods for all image se-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>quences.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Method</cell><cell></cell><cell></cell><cell></cell><cell>Seq. 1</cell><cell></cell><cell cols="2">Seq. 2</cell><cell></cell><cell cols="2">Seq. 3</cell><cell></cell><cell>Seq. 4</cell><cell>Seq. 5</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Max-mean</cell><cell></cell><cell></cell><cell></cell><cell>1.68</cell><cell></cell><cell cols="2">2.97</cell><cell></cell><cell cols="2">22.25</cell><cell></cell><cell>18.48</cell><cell>14.35</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Max-median</cell><cell></cell><cell></cell><cell></cell><cell>1.42</cell><cell></cell><cell cols="2">2.98</cell><cell></cell><cell cols="2">15.49</cell><cell></cell><cell>15.66</cell><cell>9.31</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Top-hat</cell><cell></cell><cell></cell><cell></cell><cell>0.97</cell><cell></cell><cell cols="2">1.46</cell><cell></cell><cell cols="2">17.63</cell><cell></cell><cell>9.34</cell><cell>11.92</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>IPI</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1.26</cell><cell></cell><cell cols="2">2.24</cell><cell></cell><cell cols="2">4.66</cell><cell></cell><cell>8.83</cell><cell>12.14</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>MoG</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>3.37</cell><cell></cell><cell cols="2">3.81</cell><cell></cell><cell cols="2">20.8</cell><cell></cell><cell>20.94</cell><cell>20.14</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Ours</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>2.31</cell><cell></cell><cell cols="2">4.28</cell><cell></cell><cell cols="2">35.2</cell><cell></cell><cell>24.11</cell><cell>29.05</cell></row><row><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell></row><row><cell></cell><cell>0.9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.9</cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.8</cell></row><row><cell>) d P (</cell><cell>0.7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>) d P (</cell><cell cols="2">0.7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>) d P (</cell><cell>0.7</cell></row><row><cell>n o i t c e t e d f o</cell><cell>0.6 0.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>n o i t c e t e d f o</cell><cell cols="2">0.6 0.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>n o i t c e t e d f o</cell><cell>0.5 0.6</cell></row><row><cell>y t i l i b a b o r P</cell><cell>0.3 0.4</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Max-mean Max-median</cell><cell>y t i l i b a b o r P</cell><cell cols="2">0.3 0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Max-mean Max-median</cell><cell>y t i l i b a b o r P</cell><cell>0.3 0.4</cell><cell>Max-mean Max-median</cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell>Top-hat</cell><cell></cell><cell></cell><cell cols="2">0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Top-hat</cell><cell>0.2</cell><cell>Top-hat</cell></row><row><cell></cell><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell>IPI MoG</cell><cell></cell><cell></cell><cell cols="2">0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>IPI MoG</cell><cell>0.1</cell><cell>IPI MoG</cell></row><row><cell></cell><cell cols="6">False-alarm rate (Fa) 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5 0 Ours</cell><cell></cell><cell cols="2">0 0</cell><cell></cell><cell>0.1</cell><cell cols="4">False-alarm rate (Fa) 0.2 0.3</cell><cell></cell><cell>0.4</cell><cell>Ours</cell><cell>0.5</cell><cell>False-alarm rate (Fa) 0 0.10.20.30.40.50.60.70.80.9 1 1.11.21.31.41.51.61.71.81.9 2 2.12.22.32.42.5 0 Ours</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(a)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(b)</cell><cell></cell><cell></cell><cell></cell><cell>(c)</cell></row><row><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>) d P ( n o i t c e t e d f o</cell><cell>0.5 0.6 0.7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>) d P ( n o i t c e t e d f o</cell><cell>0.7 0.6 0.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>y t i l i b a b o r P</cell><cell>0.3 0.4</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Max-mean Max-median</cell><cell>y t i l i b a b o r P</cell><cell>0.4 0.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Max-mean Max-median</cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell>Top-hat</cell><cell></cell><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Top-hat</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>IPI</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">IPI</cell></row><row><cell></cell><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell>MoG</cell><cell></cell><cell></cell><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">MoG</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Ours</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Ours</cell></row><row><cell></cell><cell>0 0</cell><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell><cell>0.4</cell><cell>0.5</cell><cell></cell><cell>0</cell><cell>0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1</cell><cell>1.2</cell><cell>1.4</cell><cell>1.6</cell><cell>1.8</cell><cell>2</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">False-alarm rate (Fa)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">False-alarm rate (Fa)</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>(d)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(e)</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Most of our sequences are from the provider of research projects. We are waiting for their permission for publicly sharing the images. Once we get the authorization, we will share them on our research homepage for research purpose.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>This work is supported by the National Natural Science Foundation of China (No. 61571071 , 61373114 , 61661166011 , 61603292, 11690011, 61721002 ) and the National Grand Fundamental Research 973 Program of China under Grant No. 2013CB329404.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Infrared patch-image model for small target detection in a single image</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Process. IEEE Trans</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4996" to="5009" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Small infrared target detection based on low-rank and sparse representation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>An</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Infrared Phys. Technol</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="98" to="109" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Generalised-structure-tensor-based infrared small target detection</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electron. Lett</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="1349" to="1351" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multiscale patch-based contrast measure for small infrared target detection</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="216" to="226" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Detecting and tracking dim small targets in infrared image sequences under complex backgrounds</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimed. Tools Appl</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1179" to="1199" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multiple target tracking by learning-based hierarchical association of detection responses</title>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Anal. Mach. Intell. IEEE Trans</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="898" to="910" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Scale invariant small target detection by optimizing signal-toclutter ratio in heterogeneous background for infrared search and track, Pattern Recognit</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="393" to="406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mdl approach for multiple low observable track initiation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bar-Shalom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Pattipati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kirubarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Aerospace Electron. Syst. IEEE Trans</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="862" to="882" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sequential along-track integration for early detection of moving targets, Signal Process</title>
		<author>
			<persName><forename type="first">E</forename><surname>Grossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lops</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3969" to="3982" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A novel dynamic programming algorithm for track-before-detect in radar systems, Signal Process</title>
		<author>
			<persName><forename type="first">E</forename><surname>Grossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lops</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Venturino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2608" to="2619" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Melendez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Modestino</surname></persName>
		</author>
		<title level="m">Spatiotemporal multiscan adaptive matched filtering, in: SPIE&apos;s 1995 International Symposium on Optical Science, Engineering, and Instrumentation, International Society for Optics and Photonics</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="51" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Moving weak point target detection and estimation with three-dimensional double directional filter in ir cluttered background</title>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Opt. Eng</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="107007" to="107007" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Temporal profile based small moving target detection algorithm in infrared image sequences</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Infrared. Millimeter Waves</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="373" to="381" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Moving dim point target detection with three-dimensional wide-to-exact search directional filtering</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit. Lett</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="246" to="253" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Small target detection using 3-dimensional bilateral filter</title>
		<author>
			<persName><forename type="first">T.-W</forename><surname>Bae</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Korea Multimed. Soc</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="746" to="755" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Dim Small Infrared Moving Target Detection Algorithm Based on Improved Three-dimensional Directional Filtering</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Image and Graphics Technologies</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="102" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Infrared moving point target detection based on spatial-temporal local contrast filter</title>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Infrared Phys. Technol</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="168" to="173" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Infrared small target enhancement by using sequential top-hat filters</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<idno>93011L-93011L</idno>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Optoelectronic Technology and Application</title>
		<imprint>
			<publisher>International Society for Optics and Photonics</publisher>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Max-mean and maxmedian filters for detection of small targets</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Deshpande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Venkateswarlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE&apos;s International Symposium on Optical Science, Engineering, and Instrumentation, International Society for Optics and Photonics</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="74" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bilateral two-dimensional least mean square filter for infrared small target detection</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Infrared Phys. Technol</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="17" to="23" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Infrared small target detection based on the tensor model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Image and Signal Processing (CISP), 2014 7th International Congress on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="169" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A novel infrared small target detection method based on bemd and local inverse entropy</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Infrared Phys. Technol</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="114" to="124" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Edge directional 2d lms filter for infrared small target detection</title>
		<author>
			<persName><forename type="first">T.-W</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I.-S</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Infrared Phys. Technol</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="137" to="145" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Small infrared target detection using sparse ring representation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Aerosp. Electron. Syst. Mag. IEEE</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="21" to="30" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Small target detection using morphology and modified gaussian distance function</title>
		<author>
			<persName><forename type="first">J.-H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-K</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Secur. Commun. Netw</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="555" to="560" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Robust principal component analysis: Exact recovery of corrupted low-rank matrices via convex optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="2080" to="2088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Bayesian robust principal component analysis, Image Process</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Carin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3419" to="3430" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Sparse bayesian methods for low-rank matrix estimation, Signal Process</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Babacan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Luessi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Katsaggelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3964" to="3977" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Robust principal component analysis with complex noise</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning (ICML-14</title>
		<meeting>the 31st International Conference on Machine Learning (ICML-14</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="55" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Fast convex optimization algorithms for exact recovery of a corrupted low-rank matrix</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Adv. Multi-Sensor Adapt. Process. (CAMSAP)</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">61</biblScope>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<title level="m">Pattern Recognition and Machine Learning</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Robust matrix factorization with unknown noise</title>
		<author>
			<persName><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Torre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1337" to="1344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Robust low-rank matrix factorization under general mixture noise distributions</title>
		<author>
			<persName><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TIP.2016.2593343</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="4677" to="4690" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Morphology-based algorithm for point target detection in infrared backgrounds</title>
		<author>
			<persName><forename type="first">V</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Peli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bondaryk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1954">1954. 1993</date>
			<publisher>SPIE</publisher>
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">he became a Post Doctoral Fellow and continued work on MED and SED until March 2014 when he returned to CQUPT. He is currently a Professor at CQUPT. His research interests include image processing</title>
	</analytic>
	<monogr>
		<title level="m">2004 and the Ph</title>
		<meeting><address><addrLine>Wuhan, China; Wuhan, China; Chongqing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-08">2009. August 2009. September 2012. April 2013</date>
		</imprint>
		<respStmt>
			<orgName>Chenqiang Gao received the B.S. degree in computer science from China University of Geosciences ; Huazhong University of Science and Technology ; Communications and Information Engineering at Chongqing University of Posts and Telecommunications (CQUPT) ; Informedia Group in School of Computer Science at Carnegie Mellon University (CMU)</orgName>
		</respStmt>
	</monogr>
	<note>working on Multimedia Event Detection (MED) and Surveillance Event Detection (SED) as a visiting scholar. infrared target detection, action recognition and event detection</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Lan Wang is currently studying for the M.S degree in information and telecommunication engineering from Chongqing Key Laboratory of Signal and Information Processing</title>
		<imprint>
			<pubPlace>Chongqing, China</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Chongqing University of Posts and Telecommunications</orgName>
		</respStmt>
	</monogr>
	<note>His research interests include infrared target detection, infrared video based action and event detection</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Yongxing Xiao is currently studying for the M.S degree in information and telecommunication engineering from Chongqing Key Laboratory of Signal and Information Processing</title>
	</analytic>
	<monogr>
		<title level="m">Her research interests include computer vision and action recognition</title>
		<meeting><address><addrLine>Chongqing, China</addrLine></address></meeting>
		<imprint/>
		<respStmt>
			<orgName>Chongqing University of Posts and Telecommunications</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">He is currently a lecturer in School of Mathematics and Statistics, Xi&apos;an Jiaotong University. His current research interests include Low-rank matrix/tensor analysis, Bayesian modeling</title>
	</analytic>
	<monogr>
		<title level="m">Ph.D degrees in 2009 and 2015, respectively, from Xi&apos;an Jiaotong University</title>
		<meeting><address><addrLine>Xi&apos;an, China</addrLine></address></meeting>
		<imprint>
			<publisher>Qian Zhao received the B.Sc</publisher>
			<date type="published" when="2013-11">November 2013 to November 2014</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note>he was visiting at Human Sensing Lab and Component Analysis Lab of The Robotics Institute. and Self-pace learning</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">He is currently an associate professor with the institute for information and system sciences, faculty of science, Xi&apos;an Jiaotong University. His current research interests include principal component analysis, nonlinear dimensionality reduction, feature extraction and selection, compressed sensing, and sparse machine learning methods</title>
		<imprint>
			<publisher>Deyu Meng received the B.Sc., M.Sc., and Ph</publisher>
			<pubPlace>Xi&apos;an, China</pubPlace>
		</imprint>
	</monogr>
	<note>D degrees in 20 01, 20 04, and 20 08, respectively, from Xi&apos;an Jiaotong University</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
