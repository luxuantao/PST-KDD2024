<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Differentially Private Event Sequences over Infinite Streams</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Georgios</forename><surname>Kellaris</surname></persName>
							<email>gkellaris@cse.ust.hk</email>
						</author>
						<author>
							<persName><forename type="first">Stavros</forename><surname>Papadopoulos</surname></persName>
							<email>stavrosp@csail.mit.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Intel Labs</orgName>
								<address>
									<country>MIT</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaokui</forename><surname>Xiao</surname></persName>
							<email>xkxiao@ntu.edu.sg</email>
							<affiliation key="aff1">
								<orgName type="institution">Nanyang Technological University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dimitris</forename><surname>Papadias</surname></persName>
							<email>dimitris@cse.ust.hk</email>
						</author>
						<title level="a" type="main">Differentially Private Event Sequences over Infinite Streams</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A48EE6F56BD6AC264003552E7D48B6CE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Numerous applications require continuous publication of statistics for monitoring purposes, such as real-time traffic analysis, timely disease outbreak discovery, and social trends observation. These statistics may be derived from sensitive user data and, hence, necessitate privacy preservation. A notable paradigm for offering strong privacy guarantees in statistics publishing is ϵ-differential privacy. However, there is limited literature that adapts this concept to settings where the statistics are computed over an infinite stream of "events" (i.e., data items generated by the users), and published periodically. These works aim at hiding a single event over the entire stream. We argue that, in most practical scenarios, sensitive information is revealed from multiple events occurring at contiguous time instances. Towards this end, we put forth the novel notion of w-event privacy over infinite streams, which protects any event sequence occurring in w successive time instants. We first formulate our privacy concept, motivate its importance, and introduce a methodology for achieving it. We next design two instantiations, whose utility is independent of the stream length. Finally, we confirm the practicality of our solutions experimenting with real data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>There is a large number of applications that benefit from the continuous monitoring of statistics. For example, traffic services publish the number of cars per area in real-time to allow for optimal route computation <ref type="bibr">[2]</ref>. Moreover, hospitals periodically release the number of patients suffering from certain diseases <ref type="bibr" target="#b1">[1]</ref>, which may help in the timely discovery of disease outbreaks. In addition, social networks constantly report the number of users currently talking about a topic <ref type="bibr" target="#b2">[3]</ref>, which enables listing the hot topics for targeted advertising. However, the inadvertent disclosure of such statistics may compromise the privacy of the individuals, such as the locations a commuter visits, the type of illness a patient suffers from, and the political views a user communicates.</p><p>A popular paradigm for providing privacy in statistics publishing with strong theoretical guarantees is ϵ-differential privacy <ref type="bibr" target="#b9">[10]</ref>. This framework entails perturbing the data prior to their release, in order to hide sensitive information about the individuals that participate in the statistical analysis. Recently, this notion has been applied to streaming scenarios <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b15">16]</ref>, where statistics are continuously published at certain timestamps. These statistics are computed over user events, i.e., "actions" taken by users at specific timestamps that contribute to the published data. For instance, assume that a traffic service periodically publishes the count of commuters per location. Then, the presence of a commuter at a specific location is an event occurring at a certain timestamp.</p><p>There exist two definitions of differential privacy in such settings; event-level and user-level <ref type="bibr" target="#b15">[16]</ref>. The former protects any single event, whereas the latter hides all the events of any user throughout the entire stream. For example, event-level privacy protects a single location visit, whereas user-level privacy protects all the location visits of any commuter. The privacy level affects the amount of perturbation used, which is proportional to the contribution of the sensitive information to the statistics.</p><p>Prior work on differential privacy on streams mainly focuses on event-level privacy on infinite streams <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr">7,</ref><ref type="bibr" target="#b3">4]</ref>, and userlevel privacy on finite streams <ref type="bibr" target="#b16">[17]</ref>. The first category is not useful in realistic scenarios where users cause events in contiguous timestamps, which collectively disclose sensitive information. For example, although event-level privacy protects any single location visit, it does not protect a user path traversed in successive timestamps. The second category has limited applicability in most practical settings, where data must be published indefinitely. For instance, it is restrictive to assume that a traffic reporting service shuts down after an a priori known time interval. On the other hand, offering user-level privacy over infinite streams requires infinite amount of perturbation, which destroys the utility of the data in the long run.</p><p>A novel problem. In this paper we merge the important gap between event-level and user-level privacy in streaming settings. In particular, we propose w-event privacy, which protects any event sequence occurring within any window of w timestamps. This novel privacy definition is useful in numerous applications. For instance, it can protect any temporally constrained movement trajectory in traffic services, patient hospitalization, or succession of related topics discussed by a user.</p><p>w-event privacy captures a superset of the applications of eventlevel privacy, whereas for w = 1 the two definitions become equivalent. However, it is narrower than user-level privacy, since it does not hide multiple event sequences from the same user. Setting w to infinity, w-event privacy converges to user-level privacy, inheriting though the need for infinite perturbation and utility degradation over time. In that sense, our definition strikes a nice balance between practicality and privacy, which expands the machinery for differential privacy in infinite streams. The challenge lies in its rigorous formulation and the design of effective schemes to satisfy it.</p><p>Contributions. We first formulate w-event privacy, and explain that it gives rise to a new class of mechanisms. Next, we present a sliding window methodology that captures a wide range of w-event private mechanisms. A mechanism following our methodology constructs a separate sub mechanism per timestamp, each spending a certain privacy budget that controls the perturbation (the higher the budget, the lower the perturbation). Then, w-event privacy is attained when the sum of budgets of the mechanisms inside any window of w timestamps is at most the total privacy budget ϵ. In the absence of previous work on this problem, we devise three benchmarks adapting ideas from existing schemes. Their main weakness is that they poorly allocate the budget across the event sequences, which results in a low overall utility. This motivates the need for new, flexible, dynamic budget allocation schemes.</p><p>Towards this end, we introduce two novel schemes tailored to our proposed methodology, called Budget Distribution (BD) and Budget Absorption (BA). These mechanisms effectively allocate the budget relying on the fact that the statistics may not change significantly in successive timestamps. Specifically, based on a private sub mechanism that calculates the dissimilarity between statistics, they skip the publications that can be accurately approximated by the last publication. Skipping a publication implies that no budget is spent at that timestamp, which becomes available for a future publication. BD and BA differ in the way they dynamically allocate the available privacy budget over time. BD starts with the entire available budget and distributes it in an exponentially decreasing fashion as publications occur, while reusing the budget used at older timestamps. On the other hand, BA uniformly allocates the initial budget over the timestamps at first, but absorbs budgets that became available from previously skipped publications. We include a utility analysis for our schemes, and propose optimizations. Finally, we experimentally evaluate them on real datasets, and confirm their effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">BACKGROUND</head><p>This section surveys the related work, providing the preliminary definitions and theorems that are necessary for the rest of the presentation. Section 2.1 explains ϵ-differential privacy, whereas Section 2.2 describes this notion in scenarios where statistics are continuously published over time in the form of streams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Differential Privacy</head><p>In the ϵ-differential privacy paradigm, a trusted curator gathers potentially sensitive data from a large number of respondents, creating a database D. The goal is to publish statistics computed on D, without compromising the privacy of the respondents. The curator achieves this goal by randomly perturbing the statistics, such that (i) the presence of any individual in D is hidden, and (ii) the published data have high utility, i.e., the perturbation does not greatly affect their accuracy with respect to the actual statistics. </p><formula xml:id="formula_0">Pr[M(D) ∈ O] ≤ e ϵ • Pr[M(D ′ ) ∈ O]</formula><p>The above definition states that the probability that M produces a transcript o when a user is in D must be roughly the same as in the case where this user is absent from D. Hence, the adversary infers no more information from o about the user than in the case where the individual's data were absent from the database. The smaller the value of ϵ, the stronger the privacy guarantees.</p><p>The first technique to satisfy ϵ-differential privacy is the Laplace Perturbation Algorithm (LPA) <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b11">12]</ref>. Its main idea is to add noise drawn from a Laplace distribution into the statistics to be published. The scale of this distribution must be proportional to the effect that a single user can have on the statistical result. The latter is called sensitivity and formalized as follows. We view the statistics as the result of a query on D. For example, the query may ask for the count of each column of D. We model the query as a function <ref type="bibr" target="#b13">[14]</ref>.</p><formula xml:id="formula_1">Q : D → R d , where d is the number of elements in the output. Let ∥Q(D) -Q(D ′ )∥ 1 denote the L1 norm of Q(D), Q(D ′ ). The sensitivity of Q w.r.t. D is ∆(Q) = max D,D ′ ∈D ∥Q(D) - Q(D ′ )∥1 for all neighboring D, D ′ ∈ D</formula><p>Let Lap(λ) be a random value drawn from a Laplace distribution with mean zero and scale λ. LPA achieves ϵ-differential privacy through the mechanism outlined in the following theorem. </p><formula xml:id="formula_2">= Q(D) + ⟨Lap(∆(Q)/ϵ)⟩ d satisfies ϵ-differential privacy.</formula><p>The higher the ∆(Q) or the smaller the ϵ, the larger the required noise for achieving ϵ-differential privacy. This is justified since (i) the larger the effect of any user on the result, the larger the amount of noise needed to "hide" the user, and (ii) the stronger the privacy guarantees, the more independent the M's output should be with respect to the input, which mandates larger noise.</p><p>Although LPA is a general methodology for ϵ-differential privacy, there are scenarios in which the required noise is prohibitively large, and destroys the utility of the published statistics. Therefore, many approaches have been proposed in order to improve upon the LPA algorithm on specific settings. The Fourier Perturbation Algorithm (FPA) <ref type="bibr" target="#b28">[29]</ref> focuses on time-series data. Roth and Roughgarden <ref type="bibr" target="#b29">[30]</ref> propose the median mechanism for an interactive setting, where the adversary requests statistics about D multiple times in an adaptive fashion. There are also works that focus on other specialized scenarios, such as range-count queries <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b7">8]</ref>, query consistency <ref type="bibr" target="#b18">[19]</ref>, sparse data <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b22">23]</ref>, correlated queries <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b20">21]</ref>, frequent itemsets <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b21">22]</ref>, trajectories <ref type="bibr" target="#b19">[20]</ref>, minimization of relative error <ref type="bibr" target="#b30">[31]</ref>, and non-numerical query answers <ref type="bibr" target="#b25">[26]</ref>. PINQ <ref type="bibr" target="#b24">[25]</ref> is a system implementation that integrates differential privacy with data analysis. Finally, there are several relaxations of ϵ-differential privacy <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b27">28]</ref>.</p><p>We include a composition theorem that is useful for our proofs. It concerns successive executions of differentially private mechanisms on the same input. THEOREM 2. <ref type="bibr" target="#b24">[25]</ref> Let M1, . . . , Mr be a set of mechanisms, where Mi provides ϵi-differential privacy. Let M be another mechanism that executes M1(D), . . . , Mr(D) using independent randomness for each Mi, and returns the vector of the outputs of these mechanisms. Then, M satisfies (∑ r i=1 ϵi</p><p>) -differential privacy.</p><p>The above theorem allows us to view ϵ as a privacy budget that is distributed among the r mechanisms. Moreover, note that the theorem holds even when Mi receives as input the private outputs of M1, . . . , Mi-1 <ref type="bibr" target="#b24">[25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Differential Privacy on Streams</head><p>So far we have focused on statistics that are derived from a static dataset. In this section, we describe how ϵ-differential privacy applies to settings where the dataset is dynamically updated by a stream, and the curator continuously publishes new statistics capturing the updates. In such a streaming scenario, every user is associated with events, i.e., "actions" taken by the user, which are modeled as update items in the stream that contribute to the new statistics. There are typically two different privacy goals in the literature, namely event-level and user-level. The former hides a single event, whereas the latter hides all the events of any user (thus concealing completely the presence of the user in the analysis).</p><p>The two works that initiated the study on this setting are <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b15">16]</ref>. They view a data stream as a sequence of symbols drawn from a domain X, where each symbol represents a user's event (e.g., x ∈ X may refer to event "user u visited location j"). The stream is essentially an array S, where element S <ref type="bibr" target="#b1">[1]</ref> corresponds to the first event that occurred, and new events/symbols are appended at the end of S as time elapses. If the stream S is infinite, we use St to denote the prefix of S after t updates, i.e., St = (S</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>. , S[t]).</head><p>To model privacy, <ref type="bibr" target="#b15">[16]</ref> defines the notion of adjacency between stream prefixes, which is similar to the concept of neighboring databases in the static case. Specifically, stream prefixes St, S ′ t are event-level adjacent, if there exists at most one i such that </p><formula xml:id="formula_3">St[i] ̸ = S ′ t [i], i.e.,</formula><formula xml:id="formula_4">[M(St) ∈ O] ≤ e ϵ • Pr[M(S ′ t ) ∈ O]</formula><p>Most existing schemes focus on event-level privacy in publishing counters, i.e., in reporting at every timestamp the number of event occurrences since the commencement of the system. In such scenarios, the effect of a single event spans over all subsequent publications. The schemes view the data stream as a bitstring, and at each timestamp they publish the number of 1's seen so far. Upon the arrival of an update, Dwork <ref type="bibr" target="#b10">[11]</ref> adds to the counter the update value along with Laplace noise of scale 1/ϵ. The author states that this works well in dense (in terms of 1's) streams, but it may be ineffective in sparse cases. To remedy this, she also proposes to postpone publishing a new counter value, until a predefined number of 1's has been seen. <ref type="bibr" target="#b10">[11]</ref> also deals with other counting problems, such as density estimation, cropped mean, and heavy hitters.</p><p>Dwork et al. <ref type="bibr" target="#b15">[16]</ref> improve upon the counter publishing schemes of <ref type="bibr" target="#b10">[11]</ref>. They focus on a stream of fixed length T , and build a full binary tree over the updates of the stream. Every node stores a noise value with scale logarithmic in T . Then, at the i th update, they identify the subtrees it belongs to, and report the current counter after adding the noise values stored in the roots of these subtrees. A similar result appeared independently in <ref type="bibr" target="#b5">[6]</ref>. The proposed scheme constructs a full binary tree on the updates, where each node contains the sum of the updates in its subtree, plus noise with scale logarithmic in T . At each update i, it identifies the maximal subtrees covering updates 1 to i, and reports the sum of the values stored in their roots. The authors extend their work to infinite streams, by constructing a new binary tree after seeing 2 κ updates, for κ ∈ N.</p><p>Bolot et al. <ref type="bibr" target="#b3">[4]</ref> extend <ref type="bibr" target="#b5">[6]</ref> by proposing decayed sums, which emphasize on recent data more than the data of the past. Moreover, they present the new notion of decayed privacy, where past data are not viewed as private anymore and, thus, they can be used in their raw form. Mir et al. <ref type="bibr" target="#b26">[27]</ref> consider counters that may also decrease. They improve upon the counting schemes of <ref type="bibr" target="#b10">[11]</ref> by utilizing sketches. Chan et al. <ref type="bibr">[7]</ref> report the heavy hitters instead of the counter values in various settings, such as sliding windows and multiple streams with untrusted aggregators.</p><p>There are also two schemes that depart from the counter-based setting. Cao et al. <ref type="bibr" target="#b4">[5]</ref> specify a set of range queries on the time domain before the system starts. Each query requests the sum of the updates therein. The goal is to determine the optimal strategy for answering all the queries, by responding to larger ranges using the noisy answers of smaller subranges. Fan and Xiong <ref type="bibr" target="#b16">[17]</ref> report counts at every timestamp, focusing on user-level privacy. They assume a finite stream, and use sampling to reduce the noise; given a pre-specified number of samples, they choose a subset of timestamps to publish the data, in a way that reduces the total error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">PROBLEM DEFINITION</head><p>We introduce a new privacy definition, motivate its importance, and propose a novel methodology for achieving it. In the absence of direct competitors in the literature, we also devise benchmark schemes by adapting work proposed in different scenarios.</p><p>Setting and privacy goal. The curator receives updates from an infinite data stream S at discrete timestamps. At every timestamp i, the curator collects a database Di with d columns and an arbitrary number of rows, where every row corresponds to a unique user, and every column represents an event. The value in row u and column j is 1 if event j of user u has occurred at i, and 0 otherwise. Every row contains at most one 1. We model the stream as an infinite tuple S = (D1, D2, . . .), where S[i] is the i th element of S. We define a stream prefix of S at t as tuple St = (D1, D2, . . . , Dt). At each timestamp i, the curator wishes to publish the count of every column in Di (i.e., the number of non-zero elements in each column). Let a count query be Q : D → R d , where D is the set of all databases with d columns. Then, Q(S[i]) = Q(Di) = ci is the data to be released at i, where ci[j] is the count of column j of Di. Hence, the curator generates infinite stream (c1, c2, . . .) while collecting S. Note that the sensitivity of</p><formula xml:id="formula_5">Q is ∆(Q) = 1.</formula><p>We justify our model with an example. Suppose that a curator collects at timestamp i a database Di from a traffic reporting service. This database contains one row for every commuter, and a set of columns corresponding to locations in a road network. The value in row u and column j is 1 if commuter u is at location j at timestamp i, and 0 otherwise. Since any commuter can be at a single location at each timestamp, every row can have at most a single 1. The curator publishes at i the count of every column of Di, which represents the number of commuters per location at i. This system runs indefinitely. We next explain our privacy goal.</p><p>We call two databases Di, D ′ i at timestamp i as neighboring if we can obtain D ′ i from Di by removing or adding a row (i.e., we use the term in the same manner as in Section 2.1). We also require a new notion of neighboring stream prefixes, defined below. <ref type="bibr">DEFINITION</ref>  </p><formula xml:id="formula_6">[i1], St[i2], S ′ t [i1], S ′ t [i2] with i1 &lt; i2, St[i1] ̸ = S ′ t [i1] and St[i2] ̸ = S ′ t [i2], it holds that i2 -i1 + 1 ≤ w.</formula><p>In other words, if St, S ′ t are w-neighboring, then (i) their elements are pairwise the same or neighboring, and (ii) all their neighboring databases can fit in a window of up to w timestamps. DEFINITION 4. Let M be a mechanism that takes as input a stream prefix of arbitrary size. Also let O be the set of all possible outputs of M. We say that M satisfies w-event ϵ-differential privacy (or, simply, w-event privacy) if for all sets O ⊆ O, all w-neighboring stream prefixes St, S ′ t , and all t, it holds that</p><formula xml:id="formula_7">Pr[M(St) ∈ O] ≤ e ϵ • Pr[M(S ′ t ) ∈ O]</formula><p>This definition captures settings where sensitive information is disclosed from an event sequence of some finite length w, i.e., from a set of events where (i) each event occurs at a different timestamp, and (ii) all the events occur within w consecutive timestamps. Revisiting our traffic reporting service example, an event sequence of length w may be a trajectory over a set of locations traversed within w consecutive timestamps. In this scenario, w-event privacy protects any such trajectory of any commuter anywhere in the stream.</p><p>w-event privacy expands event-level privacy <ref type="bibr" target="#b15">[16]</ref>. If we set w = 1 and flatten element St[i] so that it corresponds to a sequence of symbols, our w-neighboring definition becomes equivalent to event-level adjacency and, thus, w-event privacy degenerates to event-level privacy. For w &gt; 1, w-event privacy offers stronger guarantees, at the cost of an error increase. However, we shall see that this error depends on w, but not on the stream length, which guarantees that utility does not degrade over time. Setting w = t, w-event privacy converges to user-level privacy. Hence, w-event privacy strikes a nice balance between privacy and utility.</p><p>One may argue that w-event privacy can be satisfied by any userlevel private mechanism as follows. We decompose the stream prefix St into disjoint sub sequences, each of length w. We then break mechanism M into sub mechanisms Mi, each corresponding to a different such sub sequence. Every Mi is any user-level private mechanism for finite streams (e.g., <ref type="bibr" target="#b16">[17]</ref>), since we know a priori the length of its sub sequence. By Definition 3, any w-neighboring prefix S ′ t will differ from St in at most two adjacent sub sequences. If we assign budget ϵ/2 to each Mi, the condition in Definition 4 holds and, thus, w-event privacy is satisfied.</p><p>Nevertheless, this adaptation of user-level privacy to achieve wevent privacy substantially constrains the design and effectiveness of the Mi instantiations. Specifically, every Mi acts independently and allocates budget ϵ/2 to a specific sub sequence of fixed length w. This approach increases the error by a fixed factor of two for any sub sequence of length w in the stream. Furthermore, it hinders budget allocation optimizations for sub sequences that span over two sub mechanisms. In particular, the sub sequences that fall entirely in the scope of a sub mechanism may be more benefited (e.g., from adaptive sampling as in <ref type="bibr" target="#b16">[17]</ref>) than those that are split between two sub mechanisms.</p><p>Ideally, a w-event private mechanism should achieve two goals: for every sub sequence of length w anywhere in stream St, it should (i) allocate up to ϵ budget, and (ii) take budget allocation decisions considering the entirety of the sub sequence. From the above discussion, the adaptation of user-level privacy fails to meet these goals. This suggests that w-event privacy gives rise to novel mechanisms that depart from the user-level privacy literature. Towards this end, we next propose a framework that allows the design of a large class of w-event private mechanisms, achieving the two goals.</p><p>A sliding window methodology. The main idea is to view a mechanism M on a stream prefix St as the composition of t mechanisms M1, . . . , Mt, where every Mi operates on St[i] = Di at timestamp i and uses independent randomness. We analyze the privacy level of every Mi separately. Let Mi be ϵi-differentially private, for some ϵi. In order for M to satisfy w-event privacy, it suffices to ensure the following condition. Let the active window of size w of timestamp i span from i -w + 1 to i. Then, the sum of ϵi-w+1, . . . , ϵi must be smaller than or equal to ϵ. Moreover, this should hold for any timestamp, i.e., as the active window slides over time. We formulate this observation in the theorem below. THEOREM 3. Let M be a mechanism that takes as input stream prefix St, where St[i] = Di ∈ D, and outputs a transcript o = (o1, . . . , ot) ∈ O. Suppose that we can decompose M into t mechanisms M1, . . . , Mt, such that Mi(Di) = oi, each Mi generates independent randomness and achieves ϵi-differential privacy. Then, M satisfies w-event privacy if</p><formula xml:id="formula_8">∀i ∈ [t], i ∑ k=i-w+1 ϵ k ≤ ϵ (1)</formula><p>PROOF. Since all the mechanisms use independent randomness, the following holds for stream prefix St and any mechanism output (o1, . . . , ot) ∈ O ⊆ O:</p><formula xml:id="formula_9">Pr[M(St) = (o1, . . . , ot)] = t ∏ k=1 Pr[M k (D k ) = o k ]</formula><p>Similarly, for any w-neighboring stream prefix S ′ t of St and the same (o1, . . . , ot), it holds:</p><formula xml:id="formula_10">Pr[M(S ′ t ) = (o1, . . . , ot)] = t ∏ k=1 Pr[M k (D ′ k ) = o k ] By Definition 3, there exists i ∈ [t], such that D k = D ′ k for 1 ≤ k ≤ i -w and i + 1 ≤ k ≤ t.</formula><p>Combining this with the above two equations, we get</p><formula xml:id="formula_11">Pr[M(St) = (o1, . . . , ot)] Pr[M(S ′ t ) = (o1, . . . , ot)] = i ∏ k=i-w+1 Pr[M k (D k ) = o k ] Pr[M k (D ′ k ) = o k ] Due to Definition 3, it holds that database pairs D k , D ′ k are neighboring for i -w + 1 ≤ k ≤ i. Since M k is ϵ k -differentially private and due to Definition 1, it holds that Pr[M k (D k )=o k ] Pr[M k (D ′ k )=o k ] ≤ e ϵ k .</formula><p>Thus, we derive that</p><formula xml:id="formula_12">Pr[M(St) = (o1, . . . , ot)] Pr[M(S ′ t ) = (o1, . . . , ot)] ≤ i ∏ k=i-w+1 e ϵ k = exp ( i ∑ k=i-w+1 ϵ k ) Adding probabilities Pr[M(St) = (o1, . . . , ot)] over any O ∈ O, we get Pr[M(St)∈O] Pr[M(S ′ t )∈O] ≤ exp ( ∑ i k=i-w+1 ϵ k )</formula><p>. Hence, if Formula (1) holds, then we get</p><formula xml:id="formula_13">Pr[M(St)∈O]</formula><p>Pr[M(S ′ t )∈O] ≤ e ϵ which, due to Definition 4, concludes our proof.</p><p>Note that our theorem holds even if we provide the previous private outputs o1, . . . , oi-1 as input to Mi for every i <ref type="bibr" target="#b24">[25]</ref>, as well as the previously allocated budgets ϵ1, . . . , ϵi-1 <ref type="bibr" target="#b11">[12]</ref>.</p><p>This theorem enables a w-event private scheme to view ϵ as the total available privacy budget in any sliding window of size w, and appropriately allocate portions of it across the timestamps therein. Observe that, contrary to the user-level privacy adaptation discussed before, this methodology (i) allows any sub sequence of length w in the stream to enjoy up to ϵ budget, and (ii) enables each Mi to decide on budget ϵi considering the budgets allocated to sub sequence St[i -w + 1], . . . , St[i -1], and optimize budget allocation for the entire sub sequence</p><formula xml:id="formula_14">St[i -w + 1], . . . , St[i].</formula><p>The challenge in designing mechanisms that follow this methodology lies in the budget allocation technique, which must respect the condition of the theorem for any sliding window over time. This is because (i) the ϵi values determine the noise scale and, hence, have a direct effect on the accuracy of the outputs, and (ii) in a streaming setting, ϵi may need to be specified on-the-fly as the data arrive at the curator.</p><p>Benchmark methods. No existing scheme is directly applicable to our targeted setting. The works that aim at event-level privacy in infinite streams <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr">7]</ref> capture counter-based scenarios, whereas in our model each event contributes to a single published statistic. Cao et al. <ref type="bibr" target="#b4">[5]</ref> exploit overlapping query ranges, whereas we publish non-overlapping counts at each timestamp. Furthermore, all the schemes in the static scenario (described in Section 2.1) require a priori knowledge of all data, whereas we process the data on-the-fly as they arrive from the stream. The only ideas that can be adapted to our model are from <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b3">4]</ref>, noting though that these target at significantly different settings from ours. Specifically, FAST <ref type="bibr" target="#b16">[17]</ref> supports finite streams, whereas Bolot et al. <ref type="bibr" target="#b3">[4]</ref> study a more relaxed privacy concept called decayed privacy. We next design three competitors based on <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b3">4]</ref>. The first is an instantiation of the user-level privacy adaptation to w-event privacy we discussed above, using FAST, which consists of sub mechanisms, each operating on a disjoint window of w timestamps. On the other hand, the other two, called Uniform and Sample, are tailored to our sliding window methodology, and are comprised of sub mechanisms, each operating at a single timestamp.</p><p>The first competitor, termed as FASTw, instantiates each sub mechanism Mi with FAST, and allocates budget ϵ/2. Mi views its sub sequence as a finite stream of (a priori known) length w, and applies an adaptive sampling technique to each column count separately. Given a pre-specified number of samples, it selects (on-thefly as it receives the stream) only a subset of timestamps to publish, skipping the rest and approximating them with the corresponding lastly published statistics. The budget allocation depends on the number of samples and the length of the stream, which explains why FAST cannot work directly with infinite streams.</p><p>Bolot et al. <ref type="bibr" target="#b3">[4]</ref> utilize LPA independently at every timestamp. In particular, they inject at every published statistic Laplace noise with scale proportional to w instead of the entire stream length. Our Uniform scheme employs a similar approach. Specifically, Uniform is a mechanism M composed of sub mechanisms M1, M2, . . ., such that, at every timestamp i, Mi calculates Q(Di), and injects to the result Laplace noise with scale λi = w • ∆(Q)/ϵ. Recall that, in our setting, the sensitivity ∆(Q) of Q at every timestamp is equal to 1. Hence, due to Theorem 1, Mi satisfies ϵi-differential privacy, where ϵi = 1/λi = ϵ/w. Observe that all the ϵi's are equal, i.e., Uniform distributes privacy budget uniformly across the timestamps. It is easy to see that, for any window of size w, the sum of the ϵi's therein is equal to ϵ, which satisfies the condition of Theorem 3 and, hence, leads to w-event privacy.</p><p>Finally, since the adaptive sampling of FAST cannot be applied to infinite streams, we tailor a simpler sampling technique to our sliding window methodology. Specifically, we design Sample as a mechanism M composed of sub mechanisms M1, M2, . . .. Mechanism Mi publishes Q(Di) with Laplace noise of scale λi = 1/ϵ when (i mod w) = 1, and with infinite scale otherwise. Perceiving each publication with infinite noise as skipped and approximating it with its immediately preceding release, Sample performs a single publication every w timestamps (i.e., it samples the time domain with a fixed rate). Mi is ϵ-differentially private when (i mod w) = 1 and 0-differentially private otherwise. Therefore, Sample satisfies Formula (1) and achieves w-event privacy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">PROPOSED METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Main Idea</head><p>FASTw inherits the budget allocation shortcomings of the general user-level privacy adaptation we discussed in Section 3. On the contrary, Uniform and Sample adhere to our sliding window methodology. The latter requires that the sum of the individual privacy budgets of the sub mechanisms operating in any window of size w is at most equal to the total budget ϵ. Uniform assigns the same budget to every timestamp (equal to ϵ/w). If w is large, this budget becomes very small, which makes the noise scale prohibitively high and destroys the statistics. On the other hand, Sample invests the entire budget ϵ on a single timestamp within the window, which makes that publication very accurate. However, it approximates the next w -1 statistics with the published one. If these statistics greatly differ from the preceding release, the resulting error may become excessive and even exceed that of Uniform.</p><p>Our new solutions follow the sliding window methodology, and are motivated by the shortcomings of Uniform and Sample. Specifically, contrary to Sample, we decide on which publications to skip based on the dissimilarity between statistics. The main idea is to check at every timestamp whether it is more beneficial to approximate the current statistics with the last release, than to publish them with the necessary noise. This check is facilitated by a private dissimilarity calculation sub mechanism. Moreover, in contrast to Uniform, we do not allocate the privacy budget uniformly, but rather invest it on publications that need it the most. At each timestamp, our statistics are either (i) published with low noise, or (ii) accurately approximated by another release.</p><p>Im more detail, each scheme consists of a sequence of sub mechanisms M1, M2, . . ., where Mi operates at timestamp i. Figure <ref type="figure" target="#fig_1">1</ref> illustrates the architecture of Mi. It takes as input all the previous private publications o1, . . . , oi-1 that occurred at timestamps 1, . . . , i -1, respectively, as well as budgets ϵ1, . . . , ϵi-1, and outputs a new transcript oi.</p><formula xml:id="formula_15">M i i D i stream timestamp Private Dissimilarity Calculation M i,1 Private Publication M i,2 o i o 1 , . . . , o i-1 ǫ 1 , . . . , ǫ i-1 dissimilarity Figure 1: Internal mechanics of Mi</formula><p>Mechanism Mi is further decomposed into two sub mechanisms Mi,1 and Mi,2, which operate sequentially with independent randomness. Mi,1 performs a dissimilarity computation algorithm between ci of the incoming database Di and the last private release belonging in o1, . . . , oi-1. The dissimilarity measure is orthogonal to the implementation; any standard measure is applicable. The result of the calculation is forwarded to Mi,2, which uses it to decide whether to publish ci or not. Mi,2 publishes oi, which is either ci with noise (decided based on ϵ1, . . . , ϵi-1), or null . In the latter case, ci is approximated with the last non-null publication.</p><p>Both Mi,1 and Mi,2 must be private, i.e., we must invest privacy budget on them, which will determine the amount of noise injected in their outputs. Note that, although the dissimilarity result of Mi,1 appears only within the internal operation of Mi, we must consider it as being published. This is because the adversary knows that Mi,1 computes the dissimilarity on the sensitive data Di, whose value affects the decision taken by Mi,2. Thus, Mi,1 must add proper noise to the dissimilarity value. Let ϵi,1 and ϵi,2 be the budgets spent in Mi,1 and Mi,2, respectively. Then, due to Theorem 2, the privacy budget of Mi is ϵi = ϵi,1 + ϵi,2.</p><p>We next present two schemes, BD and BA, that follow the architecture described above. They share a common private dissimilarity calculation mechanism (Mi,1), which always spends a fixed budget ϵi,1 for each timestamp. However, they differ in the private publication mechanism (Mi,2); each implements a different dynamic allocation method for budget ϵi,2 over the stream. We refer to ϵi,1 as the dissimilarity budget, and to ϵi,2 as the publication budget.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Budget Distribution (BD)</head><p>The Budget Distribution (BD) scheme starts with the entire budget ϵ and (i) allocates some fixed dissimilarity budget per timestamp, (ii) distributes publication budget in an exponentially decreasing fashion to the timestamps where a publication is decided to occur, and (iii) recycles the budget spent in timestamps falling outside the active window. If the mechanism decides to publish at timestamp i, then the statistics at i are dissimilar from the last release. Thus, it is beneficial to invest a high budget (i.e., inject low noise) to the statistics at i, in order to (i) prevent distorting the dissimilarity of the current statistics to the previous ones, and (ii) retain the accuracy of the current statistics to better approximate future ones if necessary. BD hopes that few publications will take place in the same window. Hence, the first publications receive an exponentially higher portion of the budget than the subsequent ones as the window slides over time. When an old timestamp falls out of the active window, its publication budget is recycled, essentially "resetting" the available budget for future publications.</p><p>Figure <ref type="figure">2</ref> illustrates the pseudocode of Mi (operating at timestamp i) of BD. As explained in Section 4.1, Mi consists of the private dissimilarity calculation sub mechanism Mi,1 (Lines 1-4), and the private publication sub mechanism Mi,2 (Lines 5-8). Mi,1 initially computes the query result on Di (Line 1); this accounts for the vector ci of the d column counts of Di, where d is a public system parameter. Next, it finds the last non-null release o l from (o1, . . . , oi-1) in Line 2. Subsequently, it calculates the dissimilarity dis between ci and o l , employing the Mean Absolute Error (MAE) as the dissimilarity measure (Line 3). We use MAE because this is how we calculate the error in our utility analysis and experiments. Mi,1 invests some fixed dissimilarity budget ϵi,1 = ϵ/(2 • w) to perturb the dis value. The reason behind this choice of ϵi,1 will become clear soon. Next (Lines 3-4), it injects to dis Laplace noise with scale λi,1 = (2 • w)/(ϵ • d) because, as we shall soon prove, this renders Mi,1 as ϵi,1-differentially private.</p><p>Mi,2 calculates the remaining budget ϵrm for the active window [i -w + 1, i] (Line 5), since it must make sure that the total budget spent in the current window does not exceed ϵ, before determining ϵi,2. Note that ϵrm is equal to ϵ minus (i) the dissimilarity budget spent in window [i -w + 1, i], and (ii) the publication budget spent in window</p><formula xml:id="formula_16">[i -w + 1, i -1]. The budget in (i) is equal to ∑ i k=i-w+1 ϵ k,1 = w • (ϵ/(2 • w)) = ϵ/2, i.e.</formula><p>, it is equal to half the maximum budget, which leaves (at most) another half available for Mi,2 in the same window. This justifies our choice to fix ϵi,1 to</p><formula xml:id="formula_17">Input: D i , (o 1 , . . . , o i-1 ), (ϵ 1 , . . . , ϵ i-1 ) Output: o i // Sub mechanism M i,1 1. Calculate c i = Q(D i ) 2. Identify last non-null release o l from (o 1 , . . . , o i-1 ) 3. Set dis = 1 d ∑ d j=1 |o l [j] -c i [j]| and λ i,1 = (2 • w)/(ϵ • d) 4. Set dis = dis + Lap(λ i,1 ) // Sub mechanism M i,2 5. Calculate remaining budget ϵrm = ϵ/2 - ∑ i-1 k=i-w+1 ϵ k,2 6. Set λ i,2 = 2/ϵrm 7. If dis &gt; λ i,2 , Return o i = c i + ⟨Lap(λ i,2 )⟩ d 8. Else Return o i = null Figure 2: Pseudocode of Mi in BD ϵ/(2 • w). On the other hand, the budget in (ii) is ∑ i-1 k=i-w+1 ϵ k,2</formula><p>, where ϵ k,2 is not fixed (it depends on how publications occurred in the past). Observe that ∑ i-1 k=i-w+1 ϵ k,2 encompasses only budgets spent in [i -w + 1, i -1], which implies that any budget used outside this window becomes available again (for technical reasons, for k ≤ 0 we set ϵ k,1 = ϵ/(2 • w) and ϵ k,2 = 0).</p><p>Next, in Lines 6-8, Mi,2 publishes the counts ci if it is more beneficial than approximating them with the last release o l . Specifically, it checks whether the error from the approximation with o l , which is equal to dis, is larger than the error that will be induced if ci is published with Laplace noise of scale λi,2 (which is set to 2/ϵrm in Line 6). The error from this noise, which is expressed as the MAE on pair (ci, oi), is equal to λi,2. If the condition in Line 7 is true, then we publish ci along with noise ⟨Lap(λi,2)⟩ d ; in this case, we will show that the budget spent by Mi,2 is equal to ϵi,2 = 1/λi,2 = ϵrm/2. Otherwise, Mi,2 sets oi to null (Line 8), which is equivalent to approximating ci with o l and, hence, spending no budget for Mi,2, i.e., ϵi,2 = 0.</p><p>We make the following observations about BD. Every time we publish the current statistics ci at some i, the budget allocated for ϵi,2 is half the available budget for the active window. Now consider that m publications occur after i, without recycling any old budget. Then, in the m th publication, the publication sub mechanism will use budget ϵi,2/2 m . This suggests that BD allocates the ϵi,2 budgets in an exponentially decreasing fashion. Moreover, recycling old budget "resets" the available budget and, hence, the latter does not decrease indefinitely, but rather fluctuates over time.</p><p>Figure <ref type="figure">3</ref> illustrates the operation of BD in 6 timestamps for w = 3. Assume that the mechanism decides to publish at timestamps 1, 3, 4, releasing transcripts o1, o3, o4, respectively. At timestamps 2, 5, 6, it outputs null , which implies that the statistics at 2 are approximated with o1, and those of 5, 6 with o4. For every timestamp i, the Mi,1 mechanism of BD enjoys a fixed budget ϵi,1 = ϵ/(2 • w) = ϵ/6. Concerning Mi,2, at timestamp 1, it assigns ϵ1,2 = (ϵ/2 -0)/2 = ϵ/4 according to Lines 5-6 in Figure <ref type="figure">2</ref>. At timestamp 2, ϵ2,2 = 0 since no publication occurs. Then, at timestamp 3, it allocates ϵ3,2 = (ϵ/2 -(ϵ/4 + 0))/2 = ϵ/8, which is half of ϵ1,2. This indicates the exponential decrease in the budgets across subsequent publications within the same window. At timestamp 4, BD assigns ϵ4,2 = (ϵ2 -(0 + ϵ/8))/2 = 3ϵ/16. Observe that, although the mechanism still allocates half of the remaining budget at timestamp 4, ϵ4,2 &gt; ϵ3,2. This is because the budget invested at 1 (ϵ/4) is recycled, i.e., added to the remaining budget. The mechanism continues similarly at timestamps 5 and 6. Finally, notice that, in every window of size w = 3, the sum of the budgets used by BD (which encompasses the budgets for both Mi,1 and Mi,2), is always smaller than or equal to ϵ, which is the requirement for satisfying 3-event privacy. PROOF. We first prove that Mi,1 satisfies ϵi,1-differential privacy for ϵi,1 = ϵ/(2 • w), and Mi,2 is ϵi,2-differentially private for ϵi,2 = (ϵ/2 -∑ i-1 k=i-w+1 ϵ k,2 )/2 if it publishes, and ϵi,2 = 0 otherwise. Mi,1 privately outputs the MAE value</p><formula xml:id="formula_18">Q ′ (Di) = 1 d ∑ d j=1 |o l [j] -ci[j]|.</formula><p>An insertion or deletion of a row from Di results in altering the above result by at most 1/d (recall that, in our setting, every row has a single 1 with all the rest elements being 0). Hence, the sensitivity of</p><formula xml:id="formula_19">Q ′ is ∆(Q ′ ) = 1/d. Mi,1 injects to MAE Laplace noise with scale λi,1 = (2 • w)/(ϵ • d). Due to Theorem 1, Mi,1 is ϵi,1-differential privacy for ϵi,1 = 1/d (2•w)/(ϵ•d) = ϵ/(2 • w).</formula><p>Mi,2 privately publishes Q(Di) = ci or null . In the former case, the sensitivity of Q is ∆(Q) = 1 in our setting, and the mechanism injects Laplace noise with scale 2/(ϵ/2-</p><formula xml:id="formula_20">∑ i-1 k=i-w+1 ϵ k,2 ). Hence, due to Theorem 1, Mi,2 is ϵi,2- differential privacy for ϵi,2 = (ϵ/2 - ∑ i-1 k=i-w+1 ϵ k,2 )/2.</formula><p>In the latter case, ϵi,2 is trivially equal to zero, as no publication occurs.</p><p>According to Theorem 3, we must prove that, for every t and i ∈ [t], it holds that ∑ i k=i-w+1 ϵ k ≤ ϵ. Due to Theorem 2, in BD it holds that ϵ k = ϵ k,1 + ϵ k,2 and, hence,</p><formula xml:id="formula_21">∑ i k=i-w+1 ϵ k = ∑ i k=i-w+1 ϵ k,1 + ∑ i k=i-w+1 ϵ k,2 = ϵ/2+</formula><p>∑ i k=i-w+1 ϵ k,2 , since every ϵ k,1 is fixed to ϵ/(2 • w). Therefore, it suffices to prove that 0 ≤ ∑ i k=i-w+1 ϵ k,2 ≤ ϵ/2, where the comparison with zero is for correctness (differential privacy is not defined for ϵ &lt; 0). We can prove the above by induction, setting the first w timestamps as the base window/case, and sliding an arbitrary window in the stream by one timestamp in the inductive step (we omit the details due to space limitations). Intuitively, this holds because Mi,2 always uses up to half of the available publication budget.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Budget Absorption (BA)</head><p>The Budget Absorption (BA) mechanism follows a similar decision algorithm to BD for publishing at the timestamps based on dissimilarity, but implements a different budget allocation strategy. Specifically, it starts by uniformly distributing publication budget to all timestamps. If it decides not to publish at a timestamp, the corresponding budget becomes available for a future publication. On the other hand, if it decides to publish at a timestamp, it absorbs all the budget that became available from the previous skipped publications, and uses it in order to publish the current statistics with higher accuracy. An important subtlety arises in this case. Whenever the mechanism absorbs budget from previous timestamps, it must nullify the same budget from the immediately succeeding timestamps, forcing their outputs to become null . The nullified budgets cannot be absorbed in the future. This is vital for not exceeding the maximum budget ϵ as the active window slides over time.</p><p>Figure <ref type="figure" target="#fig_2">4</ref> presents the pseudocode of BA. The Mi,1 sub mechanism is identical to that of BD (Lines 1-4 in Figure <ref type="figure">2</ref>). The Mi,2 sub mechanism allocates a fixed budget ϵi,2 = ϵ/(2 • w) to each timestamp i. However, we distinguish two cases at i: (i) if previous publications were skipped, their budgets are added to ϵi,2, and (ii) if a previous publication absorbed budget, ϵi,2 may be nullified, i.e., set to zero, in which case the output is oi = null . The second case is captured first in Lines 5-6, whereas the first case is captured next in Lines 7-11. We explain these two cases in turn below.</p><formula xml:id="formula_22">Input: D i , (o 1 , . . . , o i-1 ), (ϵ 1 , . . . , ϵ i-1 ) Output: o i // Sub mechanism M i,1 // Same as Lines 1-4 in Figure 2 // Sub mechanism M i,2 5. to nullify = ϵ l,2 ϵ/(2•w) -1 6. If i -l ≤ to nullify, Return o i = null 7. Else 8.</formula><p>Set to absorb = i -(l + to nullify) 9.</p><p>Set</p><formula xml:id="formula_23">ϵ i,2 = ϵ/(2 • w) • min(to absorb, w) and λ i,2 = 1/ϵ i,2 10. If dis &gt; λ i,2 , Return o i = c i + ⟨Lap(λ i,2 )⟩ d 11.</formula><p>Else Return o i = null Since we know the last publication o l from Mi,1, we can calculate the amount of budget ϵ l,2 it received. If we divide ϵ l,2 by ϵ/(2 • w) and subtract 1 (Line 5), we get the number of skipped publications whose budgets ϵ l,2 absorbed. This value, called to nullify in our pseudocode, indicates the number of timestamps after l whose budgets we must nullify. Therefore, if i -l ≤ to nullify, then the budget at i is nullified and the mechanism outputs oi = null (Line 6). Otherwise, Mi,2 calculates ϵi,2 after potentially absorbing the budget of skipped publications, and decides on whether to publish the noisy statistics or approximate them with o l (Lines 8-11). In particular, it first computes the number of skipped publications between the last publication timestamp l and i, and stores it in variable to absorb (Line 8). Note that we must not consider the nullified budgets as skipped budgets; the nullified budgets cannot be absorbed. Next (Line 9), the mechanism sets ϵi,2, which is between ϵ/(2 • w) and ϵ/2, since the number of skipped budgets to be absorbed cannot exceed w -1 (otherwise a window will utilize more than ϵ budget and violate w-event privacy). BA proceeds similarly to BD, that is, it sets λi,2 = 1/ϵi,2 (Line 9), compares the dissimilarity dis to the error from injecting Laplace noise with scale λi,2, and outputs the noisy counts if the dissimilarity is larger (Line 10), or null otherwise (Line 11).</p><p>Figure <ref type="figure" target="#fig_5">5</ref> demonstrates the BA mechanism in 6 timestamps with w = 3. At all timestamps, BA allocates ϵ/(2 • w) = ϵ/6 budget for both Mi,1 and Mi,2. At the first timestamp, it publishes the counts using the current budget ϵ1,2 = ϵ/6. Suppose that, at timestamp 2, BA decides not to publish the current counts, i.e., it outputs null and the statistics are approximated by o1. Budget ϵ2,1 is then set to 0, and ϵ/6 becomes available for absorption at a future timestamp. At timestamp 3, the mechanism decides to publish the current counts. It absorbs the ϵ/6 budget that became available at timestamp 2, and adds it to its already allocated budget, yielding ϵ3,2 = ϵ/3. Due to this absorption, the budget at timestamp 4 must be nullified (i.e., ϵ4,2 = 0) and, hence, the mechanism outputs null . At timestamp 5, the mechanism decides to publish, but there is no budget to absorb (recall that the nullified budget at timestamp 4 cannot be absorbed). Thus, M5,2 uses only its own budget ϵ/6 to publish o5. Finally, at timestamp 6, the mechanism decides not to publish, and proceeds similarly. For any window of size 3, the sum of the budgets therein is at most ϵ. Note that, if BA does not nullify the budget at timestamp 4, the sum of the budgets in window <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5]</ref> is 7ϵ/6 &gt; ϵ, which violates w-event privacy. PROOF. Similar to BD, Mi,1 satisfies ϵi,1-differential privacy for ϵi,1 = ϵ/(2 • w), and Mi,2 is ϵi,2-differentially private, where ϵi,2 depends on previous publications, since it may be nullified (Lines 5-6 in Figure <ref type="figure" target="#fig_2">4</ref>), or absorb additional budget (Lines 8-9), or be absorbed (Line 11). Moreover, in any window of size w, the sum of budgets spent by Mi,1 is equal to ϵ/2. Therefore, it suffices to prove that 0 ≤ ∑ i k=i-w+1 ϵ k,2 ≤ ϵ/2. Let i be a timestamp which absorbed budget from α preceding timestamps. According to BA, it holds that (i) ϵi,2</p><formula xml:id="formula_24">1 2 3 4 5 6 ǫ 1,1 = ǫ/6 ǫ 2,1 = ǫ/6 ǫ 3,1 = ǫ/6 ǫ 4,1 = ǫ/6 ǫ 5,1 = ǫ/6 ǫ 6,1 = ǫ/6 w = 3 skipped ǫ 1,2 = ǫ/6 ǫ 2,2 = 0 ǫ 3,2 = ǫ/3 ǫ 4,2 = 0 ǫ 5,2 = ǫ/6 ǫ 6,2 = 0 ǫ 1 = ǫ/3 ǫ 2 = ǫ/6 ǫ 3 = ǫ/2 ǫ 4 = ǫ/6 ǫ 5 = ǫ/3 ǫ 6 = ǫ/6 ǫ 1 + ǫ 2 + ǫ 3 = ǫ ǫ 2 + ǫ 3 + ǫ 4 = 5ǫ/6 ≤ ǫ ǫ 3 + ǫ 4 + ǫ 5 = ǫ ǫ 4 + ǫ 5 + ǫ 6 = 2ǫ/3 ≤ ǫ o 1 o 3 o 5 null null</formula><formula xml:id="formula_25">= (α + 1) • ϵ/(2 • w), (ii) ϵ k,2 = 0 for (i -α ≤ k ≤ i -1) ∧ (i + 1 ≤ k ≤ i + α), and (iii) 0 ≤ α ≤ w -1.</formula><p>Then, any window of size w that contains i also covers n ≥ α timestamps with ϵ k,2 = 0 which were either absorbed or nullified exclusively by i. Therefore, the sum of the budgets of i along with the n zero-budget timestamps is at most (α + 1) • ϵ/(2 • w), i.e., at most equal to the case where each of these n + 1 timestamps receives uniform budget ϵ k,2 = (α+1)•ϵ/(2•w) n+1</p><p>≤ ϵ/(2 • w). The above holds independently also for any timestamp i ′ that absorbed budget from α ′ previous timestamps and lies in the same window as i. Therefore,</p><formula xml:id="formula_26">∑ i k=i-w+1 ϵ k,2 ≤ ∑ i k=i-w+1 ϵ/(2 • w) = ϵ/2.</formula><p>Finally, since α ≥ 0, ϵ k,2 ≥ 0 for every k and, hence, ∑ i k=i-w+1 ϵ k,2 ≥ 0. To sum up, the difference between BA and BD is the following. BD optimistically assumes that few publications will take place in each window and, hence, at each publication it eagerly allocates a large portion of the available budget. On the other hand, BA initially assumes that all publications are likely to occur in the window and, thus, uniformly allocates the budget among them. However, it absorbs the entire budget from the skipped publications, and nullifies the budgets from the immediately succeeding timestamps, because it optimistically assumes that successive statistics may not differ substantially. Therefore, it assigns a large budget to the current publication, hoping that the latter can accurately approximate at least the next few publications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Utility Analysis</head><p>Recall that both BD and BA are data-dependent. The error at any timestamp depends on (i) the budget used in past releases (if a publication occurs), and (ii) how well the statistics at this timestamp are approximated by the previous release (if a publication does not occur). Such data-dependent mechanisms should be evaluated through exhaustive experiments on real datasets, in order to better capture their effectiveness, a task we undertake in Section 5.</p><p>In this section we also include a rigorous utility analysis, which pronounces though the data-dependent aspects. We calculate the error of publication oi as the MAE on pair (oi, ci) if oi ̸ = null , and as the MAE on (o l , ci) otherwise, where o l is the first non-null release preceding i. In the following, we focus in turn on Uniform, Sample, BD and BA.</p><p>Analysis of Uniform and Sample. The expected error of Uniform is equal to the error stemming from the Laplace noise addition. Since its scale is always λ = w/ϵ, the error at each timestamp is w/ϵ. Similarly, Sample results in an error of 1/ϵ at any timestamp i, for (i mod w) = 1, due to the injected Laplace noise with scale λ = 1/ϵ. However, the error at any other timestamp is equal to the error from the approximation with the previous release, which we cannot quantify in Sample.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis of BD.</head><p>To facilitate presentation, we first analyze the error of Mi,2 considering that Mi,1 is not private and returns the dissimilarity value without error. Subsequently, we eliminate this assumption and assess how the error in Mi,1 affects the overall error of BD. We assume that every publication approximates the same number of skipped publications. LEMMA 1. The average error per timestamp for Mi,2 in BD is at most 4 2 m -1 mϵ , if m publications occur in a window and given that Mi,1 is not private. PROOF. At any timestamp i, if Mi,2 publishes, the error is 2/ϵrm since the Laplace scale is λi,2 = 2/ϵrm; otherwise, the approximation provides a better error than 2/ϵrm. In both cases, we can upper bound the error at timestamp i by 2/ϵrm, given that Mi,1 returns the actual dissimilarity value without noise. Consider the worst case, in which m ≤ w publications occur in a window of size w, and no budget is recycled from old timestamps that lie outside the window. Recall that BD distributes the budgets to the m publications in an exponentially decreasing fashion, namely the budget sequence is ϵ/4, ϵ/8, . . . , ϵ/2 m+1 . Since each publication approximates the same number of skipped releases, every publication approximates w/m -1 skipped releases on average. In other words, the error induced by each publication is shared among w/m timestamps. Hence, the average error per timestamp in the window is bounded by</p><formula xml:id="formula_27">1 w • ( w m • 4 ϵ + . . . + w m • 2 m+1 ϵ ) = 4 2 m -1 mϵ .</formula><p>Sub mechanism Mi,1 introduces error to the dissimilarity value. Thus, it contributes an additive factor to the error of Mi,2. This is captured in the theorem below, which states the total error of BD. THEOREM 6. The average error per timestamp in BD is at most</p><formula xml:id="formula_28">4 2 m -1 mϵ + 2•w ϵ•d , if m</formula><p>publications occur in a window. PROOF. Mi,1 induces error when its noisy dissimilarity output guides Mi,2 into making a false publication decision, i.e., when Mi,2 (i) falsely skips a publication, or (ii) falsely performs a publication. When a correct publication occurs, the error of BD is the error induced by Mi,2, which is captured by Lemma 1. When a publication is correctly skipped, the error is the actual dissimilarity between the current statistics ci and the last publication o l , which is bounded by the error of Mi,2 (again captured by Lemma 1). However, when a publication is falsely skipped, the actual dissimilarity is underestimated due to the noise of scale λi,1 added by Mi,1. Conversely, when a false publication occurs, the actual dissimilarity is overestimated due to the noise of scale λi,1 added by Mi,1. The expected under/overestimation of dissimilarity is equal to 2•w ϵ•d due to the noise of Mi,1. Hence, due to Lemma 1, the average error of BD is</p><formula xml:id="formula_29">4 2 m -1 mϵ + 2•w ϵ•d .</formula><p>BD is benefited when the number of publications m per window is small, otherwise its error increases exponentially with m. Moreover, the error from Mi,1 (second term of the total error) rises with w, but diminishes as d increases. This is justified by the fact that the dissimilarity measure is MAE, which averages the attribute differences over d and, hence, reduces the sensitivity.</p><p>Analysis of BA. Contrary to BD, BA distinguishes between skipped and nullified publications. The former are decided based on dissimilarity, whereas the latter are enforced due to budget absorption. We can assess the error of the skipped publications similarly to BD. However, we cannot quantify the error of the nullified publications, as we possess no information about the underlying statistics; nullification is enforced prior to their arrival. Therefore, we will express the error as a function of the average error for a nullified publication, which we denote by err nlf . Moreover, in contrast to BD, the error of BA depends on the average number of absorbed budgets (i.e., skipped releases) per publication, denoted by α, rather than the number of publications per window. THEOREM 7. The average error per timestamp in BA is at most</p><formula xml:id="formula_30">1 2α+1 • ( 2•w ϵ • Hα+1 + α • err nlf ) + 2•w ϵ•d</formula><p>, where α is the number of absorbed budgets per publication, and Hx is the x th harmonic number.</p><p>PROOF. Similar to BD, we first analyze the error of Mi,2, and then add the error contributed by Mi,1, which is the same as in BD (since Mi,1 is identical in BD and BA). Every publication is associated with α skipped publications preceding it (whose budgets it absorbs), and α nullified publications succeeding it. The publication receives budget (α+1)•ϵ 2•w and, hence, its error is 2•w (α+1)•ϵ . The first of the α skipped publications cannot have a larger error than 2•w ϵ because, otherwise, it would not have been skipped. The second skipped publication cannot have a larger error than 2•w 2•ϵ , since it performs the dissimilarity check considering that it absorbs the budget from the first skipped publication. In a similar fashion, we can obtain that the α th skipped publication induces at most error 2•w a•ϵ . Furthermore, each of the α nullified publications introduces error err nlf . Averaging over the above 2α + 1 errors, we derive the average error per timestamp of Mi,2 in BA, which is</p><formula xml:id="formula_31">1 2α+1 • ( 2•w ϵ + . . . + 2•w α•ϵ + 2•w (α+1)•ϵ + α • err nlf ) = 1 2α+1 • ( 2•w ϵ • Hα+1 + α • err nlf ).</formula><p>Adding the error incorporated by Mi,1 (see Theorem 6), we get the average error per timestamp in BA, namely 1 2α+1 •</p><formula xml:id="formula_32">( 2•w ϵ • Hα+1 + α • err nlf ) + 2•w ϵ•d .</formula><p>The error in BA decreases as the number α of skipped publications increases. This is because (i) the skipped publications are approximated with a smaller error than that they would have induced were they published with noise, and (ii) budgets from the skipped publications are utilized by others to increase their accuracy. The average error err nlf of a nullified publication contributes to the total error, but it solely depends on the underlying data. Finally, Mi,1 injects some error as well which, similar to BD, decreases as d becomes larger than w.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Optimizations and Extensions</head><p>In this section we provide optimizations for BD and BA, and explain how to augment our schemes with pan-privacy. Due to space limitations, we only sketch the modifications, delegating the detailed descriptions and proofs to the long version of our paper.</p><p>Column partitioning. When our schemes calculate the dissimilarity (MAE) between counts ci and last release o l , they consider all the elements of ci. Suppose that very few counts from ci change over time, whereas others remain roughly constant. In this case, only a few counts are responsible for increasing MAE and, hence, for potentially causing a publication to occur at timestamp i. When this release occurs, all the counts receive the noise, i.e., even the ones that could have been approximated with the previous release more accurately. Ideally, we should allow column counts to be published with different rates, based on their fluctuation over time.</p><p>Towards this goal, we partition the columns into groups, based on the magnitude of change of their counts over time. We form the groups periodically by observing the private releases. Then, we execute an independent instantiation of BD or BA on every group per timestamp. Note that we do not compromise the privacy of the overall scheme, as we do not access any raw data. The result is that the instantiations of the groups with high magnitude of change will publish more frequently than those of groups with low magnitude.</p><p>Shifting budget from Mi,1 to Mi,2. Both BD and BA assign a fixed budget ϵi,1 = ϵ/(2 • w) to Mi,1, which results in injecting noise with scale λi,1 = (2 • w)/(ϵ • d) due to the sensitivity 1/d of MAE. Over a window of size w, the sum of the budgets for the dissimilarity calculation sub mechanism is ϵ/2, which leaves only half of the maximum budget to Mi,2. We investigate whether we can shift some budget from Mi,1 to Mi,2, in order to improve the accuracy of the publications, without significantly affecting the accuracy of the noisy dissimilarity value returned by Mi,1. Specifically, we observe that, when d ≫ w, λi,1 becomes too small. Motivated by the fact that the typical scale value of 1/ϵ yields high accuracy in other scenarios (e.g., histogram queries <ref type="bibr" target="#b11">[12]</ref>), we set λi,1 = 1/ϵ, which translates to spending budget ϵi,1 = ϵ/d &lt; ϵ/(2 • w). This leaves ϵ -w • (ϵ/d) &gt; ϵ/2 budget for publication in any window.</p><p>Pan-Privacy. A notion relevant to ϵ-differential privacy on streams is pan-privacy <ref type="bibr" target="#b14">[15]</ref>. A mechanism is pan-private if it can preserve ϵ-differential privacy even when an adversary observes snapshots of the mechanism's internal states. These states account for the memory contents during the execution of the mechanism. There are two different intrusion types in the literature; single unannounced intrusion and multiple announced intrusions. The former assumes that the adversary breaches the system only once during its lifetime, without the curator being able to detect the intrusion. The latter considers that the adversary infiltrates the system multiple times, and the curator detects each breach just after it occurs.</p><p>We modify BD and BA so that they satisfy pan-privacy. A crucial point towards this goal is to never store raw data in main memory. Therefore, at every timestamp i, we reset dis and initialize it with noise Lap(λi,1). We do the same for all the elements of ci using noise Lap(λi,2). Then, dis and ci are calculated as Di arrives from the communication channel, without storing any raw item in a variable without pre-assigned noise. Values λi,1 and λi,2 are calculated as follows. For Mi,1, λi,1 remains unaffected because, as mentioned in Section 4.2, we perceive dis as being published at every timestamp. Hence, any intrusion does not disclose any additional information on dis. On the other hand, we must modify λi,2 for BD and BA. The reason is that, although an intrusion at a timestamp where a publication must occur does not help the adversary (since we release what the adversary accessed in main memory anyway), an intrusion at a timestamp where Mi,2 outputs oi = null gives extra information. This case becomes equivalent to publishing the noisy ci, since the adversary accessed it in memory. Consequently, the budget that would have been saved by the approximation is lost and, hence, future budgets (and corresponding noise scales) must be adjusted to retain w-event privacy.</p><p>We first focus on the case of a single unannounced intrusion. In BD, instead of setting ϵi,2 = ϵrm /2, we set it to ϵrm /3, i.e., to a smaller value. For the windows where no intrusion takes place, privacy is not affected; following a similar analysis to Theorem 4, we derive that the sum of budgets spent for publication therein are at most ϵ/3 ≤ ϵ/2 as required for w-event privacy. Consider now any window where the (single) intrusion takes place for a timestamp i where Mi,2 outputs null . In this case, ϵi,2 must be considered twice; once for noisy ci in the intruded main memory, and once as part of ϵrm at the next timestamp a publication occurs. The value of ϵi,2 is ϵrm /3 ≤ (ϵ/2)/3 = ϵ/6. Therefore, the budget spent by the publication sub mechanisms in a window where a single unannounced intrusion occurs is at most ϵ/6 + ϵ/3 = ϵ/2, and Theorem 4 holds. The utility of BD degrades by a factor of 1.5, because every publication uses 1.5 times less budget (ϵrm /3 versus ϵrm /2).</p><p>On the other hand, in BA, we set the initial budget ϵi,2 at timestamp i as ϵ/(4 • w) instead of ϵ/(2 • w). We can prove in the same fashion as Theorem 5 that the sum of budgets per any window where the intrusion did not occur is at most ϵ/4. For any window where the intrusion took place, we must add the maximum budget that can be absorbed by a timestamp, which is (w-1)•(ϵ/(4•w)) &lt; ϵ/4. Hence, the total publication budget in the window becomes at most ϵ/2, and w-event privacy is retained. The utility degrades by a factor of 2, since we halve ϵi,2 as compared to the original scheme. A final remark concerns an intrusion during a nullified publication. This is handled by discarding Di from the communication channel when i corresponds to a nullified publication. In this case, BA constructs no private information on Di and, thus, spends no budget.</p><p>We next turn to the setting of multiple announced intrusions. Similar to the case of a single intrusion, BD and BA keep only noisy versions of dis an ci in main memory, and Mi,1 remains intact. However, here BD and BA do not alter λi,2. The reason is that here the curator always knows when an intrusion takes place, and adjusts the behavior of Mi,2 on-the-fly. Specifically, when it detects an intrusion, it simply forces the publication to occur (i.e., behaves as if the publication had to occur). The schemes never use a timestamp's budget more than once, and the privacy proofs remain identical to those in the original schemes. These intrusions considerably affect the utility of the schemes. The full analysis is rather complex, and we defer it to the long version of this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EXPERIMENTAL EVALUATION</head><p>We compared BD and BA with benchmarks FASTw, Uniform and Sample over real datasets. We implemented FASTw in Java, using the Fan et al. <ref type="bibr" target="#b16">[17]</ref> implementation of FAST<ref type="foot" target="#foot_0">1</ref> , and configured it according to <ref type="bibr" target="#b16">[17]</ref>. We implemented all other methods also in Java, and fine-tuned BD and BA for every experiment according to the optimizations of Section 4.5. We conducted the experiments on a machine with Intel Core i5 CPU 2.53GHz and 4GB RAM, running Windows 7. We ran each experiment 100 times, and reported the average error, expressed as the Mean Absolute Error (MAE) and the Mean Relative Error (MRE). We fixed ϵ = 1.</p><p>We experimented with two real datasets. For the first, we connected our system to an actual online traffic monitoring service in Rome [2], and we periodically retrieved the data real-time as they were generated by the service. We executed our schemes for 10 consecutive days, where every data collection period was 10 minutes (i.e., our time domain consisted of 1442 timestamps). At each timestamp i, we directly retrieved vector ci, where element ci[j] is the number of commuters on road j at i. The total number of roads (and, hence, the size of ci) is d = 25, 936. Note that, in such a scenario, our schemes protect any single trajectory of any user consisting of up to w road segments.</p><p>For the second, we created a stream from a well-known archived dataset, namely World Cup<ref type="foot" target="#foot_1">2</ref> . The latter contains 1,352,804,107 Web server logs from the FIFA 1998 Soccer World Cup website, gathered in 88 consecutive days. Each log entry consists of a client ID, the ID of the requested URL, the size of the response, etc. This dataset does not define a specific period length for each timestamp and, hence, we regard the number of timestamps per day as a variable parameter under investigation. At every timestamp i, we collected from the stream a database Di, where each row is a unique log, every attribute is a URL, and cell (u, j) is 1 if log u accessed URL j, and 0 otherwise. Moreover, at each timestamp i, we calculated vector ci such that ci[j] is the number of logs accessing URL j at i. The number of unique URLs (and, hence, the size of ci) is d = 89, 997. Our schemes protect any single sequence of URL accesses of a user over at most w timestamps (given that each user browses at most a single URL per timestamp).</p><p>Varying parameter w. Figure <ref type="figure" target="#fig_6">6</ref> illustrates (in logarithmic scale) the MAE and MRE of our schemes as a function of w for the Rome dataset. We vary w between 40 and 200. BA is the best method. It outperforms Uniform and FASTw by up to one order of magnitude in both MAE and MRE. It is up to five (four) times better than Sample in MAE (MRE). Moreover, its MAE (MRE) is 46% (35%) smaller than in BD. Finally, its MRE varies in range 5-11%.</p><p>The budget in Uniform is fixed for all timestamps, and linear in w. Hence, its performance deteriorates significantly for large w. FASTw behaves similarly to Uniform, because it uses a fixed number of samples, assigning a uniform budget over all samples. As w is raised, the samples increase and, thus, a smaller budget is available for the publications. FASTw outperforms Uniform in MAE, but features a similar performance in MRE. This is because FASTw approximates well the large counts (which dominate the MAE), but does not equally benefit the small counts, whose collective MRE becomes dominant in the total MRE. Sample performs better than FASTw and Uniform, and is relatively unaffected by w, mainly because (i) it utilizes more budget per publication, and (ii) the statistics do not vary a lot across timestamps and, thus, each sample approximates relatively well the counts in subsequent timestamps. BA and BD are superior due to their data-dependent sampling and approximation (as opposed to Sample), as well as sophisticated budget allocation (as opposed to all benchmarks). For small w, they have a similar performance. However, as w increases, the performance gap between BA and BD increases as well. This is due to the combination of (i) the exponential decay of budget in BD as more publications occur in a larger window, and (ii) the fact that a larger window prevents BD from recycling budget. On the contrary, BA allocates the budget over the multiple publications in the larger window more effectively, via the initial uniform budget distribution and the subsequent dynamic budget absorption. Figure <ref type="figure" target="#fig_7">7</ref> illustrates the MAE and MRE of our mechanisms versus w for the World Cup dataset. We fix the number of publications per day to 15 (which translates to an experiment spanning 1320 timestamps), and vary w between 40 and 200. BA outperforms Uniform by approximately two orders of magnitude in MAE and MRE, Sample by up to three (two) orders of magnitude in MAE (resp. MRE), FASTw by more than one order of magnitude in both MAE and MRE, and BD by up to 51% in MAE and 30% in MRE. Moreover, the MRE in BA is always below 11.8%. Sample is always worse than Uniform in terms of MAE. The reason is that the statistics have great fluctuations in successive timestamps in this dataset, inducing a huge approximation error to Sample, which is higher than that of Uniform even for large values of w. The difference between Sample and Uniform in MRE is marginal. This is because the largest approximation error in Sample occurs in the most popular URLs. This greatly affects the total error in absolute terms, but does not impact it in relative terms to the same extent. Finally, contrary to the case of the Rome dataset, FASTw outperforms Uniform even in MRE. This is because the sampling of FASTw approximates more effectively the highly variable counts of the World Cup dataset across time. The effect of the magnitude of change. The next set of experiments evaluates the effectiveness of our schemes, when the incoming updates change the statistics over time with various magnitudes. We derived datasets of variable magnitude from our two real datasets. In the Rome dataset, we grouped the database columns based on the average Root Mean Square (RMS) of their counts over the entire stream (the RMS is a standard statistical tool for measuring the magnitude of change of a varying quantity). In the World Cup dataset, we varied the number of timestamps per day, as this adjusts the magnitude of change; the larger the number of timestamps, the fewer updates per timestamp and, hence, the smoother the change in the statistics in successive timestamps. Figure <ref type="figure" target="#fig_8">8</ref> presents our results for the Rome dataset. We partitioned the stream into four sub streams. Each sub stream focused on a disjoint subset of roads. The reported counts of the roads in the same sub stream featured a similar RMS. We ran every mechanism on each sub stream independently, and reported its MAE and MRE, setting w = 120. For each sub stream in the x-axis, we also include the average RMS of the counts it generates (smaller RMS values indicate smaller magnitudes of change). BA and BD are always superior to the benchmarks, once again due to their more effective budget allocation. BA is the most robust scheme to RMS, for both MAE (Figure <ref type="figure" target="#fig_8">8</ref>(a)) and MRE (Figure <ref type="figure" target="#fig_8">8</ref>(b)). For small RMS values, BD and BA have comparable performance, featuring excellent utility (about 3% MRE when RMS=5 in Stream 1). The reason is that the small magnitude of change enables the accurate approximation of the current statistics with an older release. They also handle larger magnitude of change better than the benchmarks and continue to be effective even for RMS=29 in Stream 3 (about 11% MRE). For the largest RMS value (114 in Stream 4), BD does not perform well compared to BA (24% vs. 13% MRE) because the large magnitude of change results in numerous publications per window, which greatly impact BD. On the contrary, BA manages to attain excellent performance even for a large RMS, due to its ability to allocate the privacy budget more effectively than BD when many publications occur per window.</p><p>On the other hand, Uniform always performs badly, as it publishes the current statistics with large noise independently of the RMS. FASTw is also relatively unaffected by small RMS values, and only for extreme RMS values does its error increase noticeably. Sample outperforms FASTw in small RMS values. This is because very few samples are needed per window to effectively approximate the skipped statistics, and FASTw unnecessarily allocates budget to a fixed number of samples, which is always larger than that of Sample. However, Sample rapidly deteriorates as RMS increases, since a steep count change over time leads to an excessive approximation error. Figure <ref type="figure" target="#fig_9">9</ref> plots the MAE and MRE of all schemes for the World Cup dataset, where we vary the timestamps per day and set w = 120. Note that every value in the x-axis corresponds to a different dataset. A smaller number of timestamps per day translates to more abrupt changes in consecutive statistics. The performance trends of all mechanisms are similar to those in Figure <ref type="figure" target="#fig_8">8</ref>, i.e., the error increases for larger magnitudes of change. Our schemes outperform the baselines form one to up to three (two) orders of magnitude in MAE (resp. MRE). The errors of BA and BD become marginally close as the number of timestamps increases, whereas their MRE ranges in 10-14% and 10-25%, respectively. when varying the number of groups, and setting w = 120. We decomposed the database columns into disjoint groups, ran our schemes independently on every group, and reported the average MAE over all groups. As the mechanisms received updates from the stream, they periodically modified the groups, such that each group contained columns whose counts feature a similar magnitude of change (measured as the RMS).</p><p>In Figure <ref type="figure" target="#fig_10">10</ref>(a), BD and BA exhibit the best performance when the number of groups is 20. BD improves its MAE by up to 10%, and BA by up to 21%, as compared the case of the single group. Observe that the error increases when the number of groups becomes large after its initial improvement in both schemes. When the number of groups increases, the number of attributes in each group decreases, resulting in higher sensitivity for computing dis in Mi,1. Thus, more budget is assigned to the dissimilarity calculation sub mechanism, leaving less budget for publishing. Hence, a large number of groups results in higher error. In Figure <ref type="figure" target="#fig_10">10</ref>(b), the error curves feature similar trends as in Figure <ref type="figure" target="#fig_10">10</ref>(a), i.e., the number of groups initially improves the performance of both methods, but then adversely impacts it for the same reasons explained for the Rome dataset. BD and BA exhibit the best performance when the number of groups is 150. BD improves its MAE by up to 36%, and BA by up to 71%, as compared the case of the single group. Summary. Our experimental evaluation demonstrated the superiority of BD and BA over the benchmark methods, and their practicality in two real datasets. Specifically, our novel schemes outperformed the baselines approaches by orders of magnitude in the majority of our settings, in both absolute and relative error. Moreover, BA outperformed BD in all experiments, due to its more effective budget allocation when several publications must occur per window. The error in BA was up to about 50% smaller than that of BD in all scenarios. Furthermore, the relative error of BA ranged in 3-14% in all settings and datasets. This renders BA practical for data mining tasks, and confirms the viability of the w-event privacy concept in real-life applications. Finally, we demonstrated the performance boost achieved by our column partitioning optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSION</head><p>We introduced the novel notion of w-event ϵ-differential privacy in privacy-preserving statistics publishing on infinite streams. This concept protects a sequence of w events occurring in successive time instants, and finds practical application in numerous scenarios where sensitive information can be inferred from user activity spanning over a time window. We formulated a sliding window methodology for satisfying this property, and designed three benchmark methods. We then introduced two novel mechanisms that are based on sophisticated sampling and dynamic privacy budget allocation techniques, and outlined several optimizations. We conducted thorough experimentation with real datasets, which demonstrated the superiority of our mechanisms against the benchmarks, and the practicality of our novel privacy notion in real applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Formally, let D denote a set of databases. Each D ∈ D is perceived as a set of rows. Two databases D, D ′ ∈ D are neighboring if we can obtain D ′ from D by removing or adding a single row. Let M be a randomized mechanism, which takes as input a database from D and outputs a transcript in some range O. The curator runs M on D ∈ D, and publishes o ∈ O, i.e., o constitutes the released statistics about D. The ϵ-differential privacy notion is formulated as follows. DEFINITION 1. [10] A mechanism M : D → O satisfies ϵdifferential privacy, where ϵ ≥ 0, if for all sets O ⊆ O, and every pair D, D ′ ∈ D of neighboring databases</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>THEOREM 1 .</head><label>1</label><figDesc><ref type="bibr" target="#b13">[14]</ref> Let Q : D → R d . A mechanism M that adds independently generated noise from a zero-mean Laplace distribution with scale λ = ∆(Q)/ϵ to each of the d output values of Q(D), i.e., which produces o</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Section 4 .</head><label>4</label><figDesc>1 outlines the main idea behind our constructions. Sections 4.2 and 4.3 introduce our BD and BA mechanisms, respectively, and Section 4.4 analyzes their utility. Section 4.5 includes effective optimizations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>6 ǫ 1 , 1 = 6 w = 3 skipped ǫ 1 , 6 ǫ 1 +Figure 3 :</head><label>611631613</label><figDesc>Figure 3: Example of BD THEOREM 4. BD satisfies w-event privacy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Pseudocode of Mi in BA</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Example of BA THEOREM 5. BA satisfies w-event privacy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Error vs. w (Rome dataset)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Error vs. w (World Cup dataset)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Error vs. RMS (Rome dataset)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Error vs. timestamps per day (World Cup dataset)Effect of column partitioning. Figures10(a) and 10(b) assess the effect of the column partitioning optimization for BD and BA (see Section 4.5) on the Rome and World Cup datasets, respectively, when varying the number of groups, and setting w = 120. We decomposed the database columns into disjoint groups, ran our schemes independently on every group, and reported the average MAE over all groups. As the mechanisms received updates from the stream, they periodically modified the groups, such that each</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Error vs. number of groups</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>http://www.mathcs.emory.edu/∼lfan3/FAST/tool/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>http://ita.ee.lbl.gov/html/contrib/WorldCup.html</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>Georgios Kellaris and Dimitris Papadias were supported by grant 618011 from Hong Kong RGC. Xiaokui Xiao was supported by grant ARC19/14 from MOE, Singapore and a gift from MSRA.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<ptr target="http://hcupnet.ahrq.gov/" />
		<title level="m">HCUP net</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">People Talking About This</title>
		<ptr target="www.insidefacebook.com/2012/01/10/people-talking-about-this-defined/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Private decayed predicate sums on streams</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bolot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Fawaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Muthukrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Taft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDT</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Efficient and accurate strategies for differentially private sliding window queries</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ghinita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bertino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EDBT</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Private and continual release of statistics</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TISSEC</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">26</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Differentially private continual monitoring of heavy hitters from distributed streams</title>
		<author>
			<persName><forename type="first">T.-H</forename><forename type="middle">H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PETS</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Differentially private spatial decompositions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Procopiuc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Differentially private publication of sparse data</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Procopiuc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T L</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDT</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<title level="m">Differential privacy. In ICALP</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Differential privacy in new settings</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SODA</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A firm foundation for private data analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CACM</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="86" to="95" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Our data, ourselves: Privacy via distributed noise generation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kenthapadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EUROCRYPT</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Calibrating noise to sensitivity in private data analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TCC</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Pan-private streaming algorithms</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pitassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rothblum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yekhanin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICS</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Differential privacy under continual observation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pitassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Rothblum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Real-time aggregate monitoring with differential privacy</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On the geometry of differential privacy</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Boosting the accuracy of differentially private histograms through consistency</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Miklau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Suciu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="1021" to="1032" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Publishing trajectories with differential privacy guarantees</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bressan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SSDBM</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Optimal error of query sets under the differentially-private matrix mechanism</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Miklau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDT</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">PrivBasis: Frequent itemset mining with differential privacy</title>
		<author>
			<persName><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Qardaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1340" to="1351" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Compressive mechanism: Utilizing sparse representation in differential privacy</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Winslett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<editor>WPES</editor>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Privacy: Theory meets practice on the map</title>
		<author>
			<persName><forename type="first">A</forename><surname>Machanavajjhala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Abowd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vilhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Privacy Integrated Queries: An Extensible Platform for Privacy-preserving Data Analysis</title>
		<author>
			<persName><forename type="first">F</forename><surname>Mcsherry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Mechanism design via differential privacy</title>
		<author>
			<persName><forename type="first">F</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FOCS</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Pan-private algorithms via statistics on sketches</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Muthukrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PODS</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Smooth sensitivity and sampling in private data analysis</title>
		<author>
			<persName><forename type="first">K</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Raskhodnikova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Differentially private aggregation of distributed time-series with transformation and encryption</title>
		<author>
			<persName><forename type="first">V</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Interactive privacy via the median mechanism</title>
		<author>
			<persName><forename type="first">A</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Roughgarden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">iReduct: Differential privacy with reduced relative errors</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Differential privacy via wavelet transforms</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1200" to="1214" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">On differentially private frequent itemset mining</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Naughton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="36" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
