<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dual Correction Strategy for Ranking Distillation in Top-N Recommender System</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Youngjune</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">KAIST</orgName>
								<address>
									<settlement>Daejeon</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Kee-Eung</forename><surname>Kim</surname></persName>
							<email>kekim@kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">KAIST</orgName>
								<address>
									<settlement>Daejeon</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Graduate School of AI</orgName>
								<orgName type="institution" key="instit2">KAIST</orgName>
								<address>
									<settlement>Daejeon</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Dual Correction Strategy for Ranking Distillation in Top-N Recommender System</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3459637.3482093</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS CONCEPTS</term>
					<term>Information systems â†’ Learning to rank</term>
					<term>Collaborative filtering</term>
					<term>Retrieval efficiency Recommender System</term>
					<term>Knowledge Distillation</term>
					<term>Learning to Rank</term>
					<term>Model Compression</term>
					<term>Retrieval efficiency</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Knowledge Distillation (KD), which transfers the knowledge of a well-trained large model (teacher) to a small model (student), has become an important area of research for practical deployment of recommender systems. Recently, Relaxed Ranking Distillation (RRD) has shown that distilling the ranking information in the recommendation list significantly improves the performance. However, the method still has limitations in that 1) it does not fully utilize the prediction errors of the student model, which makes the training not fully efficient, and 2) it only distills the user-side ranking information, which provides an insufficient view under the sparse implicit feedback. This paper presents Dual Correction strategy for Distillation (DCD), which transfers the ranking information from the teacher model to the student model in a more efficient manner. Most importantly, DCD uses the discrepancy between the teacher model and the student model predictions to decide which knowledge to be distilled. By doing so, DCD essentially provides the learning guidance tailored to "correcting" what the student model has failed to accurately predict. This process is applied for transferring the ranking information from the user-side as well as the item-side to address sparse implicit user feedback. Our experiments show that the proposed method outperforms the state-of-the-art baselines, and ablation studies validate the effectiveness of each component.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In this era of information explosion, Recommender Systems (RS) are widely used in various industries to provide personalized user experience <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b17">18]</ref>. For achieving higher recommendation accuracy, the recommendation model has become very large to capture the complexity of personalized recommendations <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30]</ref>. However, large models incur correspondingly large computational cost as well as high latency for inference, which has become one of the major obstacles for real-time service <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>To reduce the inference latency, early methods adopt hash techniques <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b29">30]</ref> or tree-based data structure <ref type="bibr" target="#b0">[1]</ref>. However, they have problems such as easily falling into a local optimum or applicable only to specific models <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b27">28]</ref>. To address the problems, Knowledge Distillation (KD) has been actively studied for RS <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b27">28]</ref>. KD is a model compression technique that improves the performance of a small student model by transferring the knowledge of a pre-trained large teacher model <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b24">25]</ref>. During the distillation, the teacher model provides additional supervision which is not existent in the users' feedback, so the student model can achieve a higher recommendation accuracy compared to the student model trained only on the original feedback.</p><p>The state-of-the-art method, Relaxed Ranking Distillation (RRD) <ref type="bibr" target="#b8">[9]</ref>, formulates the distillation process as a ranking matching problem between the recommendation list of the teacher model and that of the student model. In other words, it utilizes the ranking orders among the items from the teacher model as additional supervision to guide the student model, and trains the student model to preserve the ranking orders of the teacher model. This ranking-distillation approach transfers the relative preference order among the user's preferred items, which is the key knowledge directly affecting top-ğ‘ recommendation accuracy. As a result, it significantly improves performance over the previous methods <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b25">26]</ref> that do not directly utilize the ranking information <ref type="bibr" target="#b8">[9]</ref>.</p><p>Still, there are limitations in RRD. First, it transfers the knowledge without consideration of the prediction errors of the student model. As the student model gets more accurate in matching the prediction of the teacher model, repeatedly distilling the ranking information that the student model already correctly predicts cannot effectively enhance the student model and makes the training inefficient. We argue that the knowledge to be distilled should be dynamically changed based on the student model's prediction error, enabling "correction" for what the student model has not yet predicted accurately. Second, it only transfers user-side ranking information, i.e., ranking orders among the items. Previous studies have pointed out that learning only with the user-side ranking information degrades the quality of user representation <ref type="bibr" target="#b6">[7]</ref> and provides a view insufficient to fully understand the sparse implicit arXiv:2109.03459v1 [cs.IR] 8 Sep 2021 feedback <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b13">14]</ref>. Particularly in KD where the student model's capacity is limited, these problems can be further exacerbated and severely degrade the performance.</p><p>In this work, we propose a novel Dual Correction strategy for Distillation (DCD), which aims to address the aforementioned shortcomings. To this end, DCD first computes discrepancy between the ranking list of the teacher model and that of the student model, then decides what knowledge to be distilled based on the discrepancy. By doing so, DCD provides guidance tailored to correct what the student model has failed to correctly predict, which helps to find an effective path for the student model's training. This process is conducted for dual-side ranking, i.e., for the user-side and the item-side, providing a comprehensive view to better understand both users and items <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14]</ref>. We validate the superiority of the proposed method with extensive experiments on real-world datasets, and provide an ablation study showing the effectiveness of each proposed component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODOLOGY 2.1 Problem formulation and Notations</head><p>We focus on top-ğ‘ recommendation task for implicit feedback <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b17">18]</ref>. Given implicit user-item interactions, a recommender system provides a ranked list of top-ğ‘ unobserved items for each user. The distillation process is conducted as follows: First, we train a large model (teacher) using the implicit feedback. Then, we train a small model (student) with the same feedback data along with the ranking list predicted from the teacher. The ranking information reveals the detailed preference orders among the unobserved items, which helps the training of the student. Our goal is to design a distillation strategy that allows the student to effectively follow the teacher's ranking list.</p><p>We denote the teacher by ğ‘‡ and the student by ğ‘†. ğ‘… ğ‘¢ ğ‘‡ and ğ‘… ğ‘¢ ğ‘† denote the user-side ranking list for user ğ‘¢ (i.e., the list of the unobserved items) predicted by the teacher and the student, respectively. ğ‘… ğ‘¢ * (ğ‘–) denotes the rank of item ğ‘– in the ranking list where a lower value means a higher ranking position, i.e., ğ‘… ğ‘¢ * (ğ‘–) = 0 is the highest ranking. For the item-side ranking list, we simply reverse the notation of the user-side. Concretely, ğ‘… ğ‘– ğ‘‡ and ğ‘… ğ‘– ğ‘† denote the itemside ranking list for item ğ‘– (i.e., the list of the unobserved users) predicted by the teacher and the student, respectively, and ğ‘… ğ‘– * (ğ‘¢) denotes the rank of user ğ‘¢ in the ranking list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Distilling the Ranking Information</head><p>The ranking distillation (RRD) <ref type="bibr" target="#b8">[9]</ref> formulates the distillation as a ranking matching problem between the ranking list of the teacher and that of the student (i.e., ğ‘… ğ‘¢ ğ‘‡ and ğ‘… ğ‘¢ ğ‘† ). Specifically, the method trains the student to preserve the orders of ranking in ğ‘… ğ‘¢ ğ‘‡ by using a variant of ListMLE <ref type="bibr" target="#b28">[29]</ref>. The core idea is to define a permutation probability based on the the student's ranking scores, and train the student to maximize the likelihood of the teacher's ranking ğ‘… ğ‘¢ ğ‘‡ . To make the student better focus on top-ranked items, we also adopt relaxed permutation probability <ref type="bibr" target="#b8">[9]</ref> that ignores the lowranked items' detailed orders. Formally, let ğ‘… ğ‘¢ ğ‘‡ is decomposed to two sub-ranking lists ğ‘… ğ‘¢ ğ‘‡ = [ğœ‹; ğœ‹ â€² ], where ğœ‹ includes a few top-ranked items and ğœ‹ â€² includes the remaining items (ğ‘¢ and ğ‘‡ are omitted for simplicity). The relaxed permutation probability of the ranked list ğœ‹ for the student ğ‘† is defined as follows:</p><formula xml:id="formula_0">ğ‘ (ğœ‹ |ğ‘†) = |ğœ‹ | ğ‘˜=1 exp ğ‘† (ğ‘¢, ğœ‹ ğ‘˜ ) |ğœ‹ | ğ‘–=ğ‘˜ exp ğ‘† (ğ‘¢, ğœ‹ ğ‘– ) + |ğœ‹ â€² | ğ‘—=1 exp ğ‘† (ğ‘¢, ğœ‹ â€² ğ‘— ) ,<label>(1)</label></formula><p>where ğœ‹ ğ‘˜ is the ğ‘˜-th item in ğœ‹, ğ‘† (ğ‘¢, ğœ‹ ğ‘˜ ) is the score of the user-item interaction predicted by the student. By maximizing the probability, the student learns the detailed ranking orders in ğœ‹ while lowering all the ranks of items in ğœ‹ â€² below the lowest rank of items in ğœ‹, which allows the student to focus more on top-ğ‘ ranking orders. The student is trained by the ranking knowledge distillation (RKD) loss as follows:</p><p>min</p><formula xml:id="formula_1">L ğ‘…ğ¾ğ· = L ğ‘…ğ‘† + ğœ† ğ‘…ğ‘…ğ· L ğ‘…ğ‘…ğ· ,<label>(2)</label></formula><p>where L ğ‘…ğ‘† is the loss for training the base model using the implicit feedback data, and</p><formula xml:id="formula_2">L ğ‘…ğ‘…ğ· = âˆ’ 1 |ğµ | ğ‘¢ âˆˆğµ log ğ‘ (ğœ‹ ğ‘¢ |ğ‘†)</formula><p>is the permutation loss defined for the users in mini-batch ğµ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Dual Correction Strategy</head><p>We present Dual Correction strategy for Distillation (DCD) that adaptively assigns more concentrations on training instances that the student fails to predict correctly, unlike the prior methods such as RRD that generate training instances solely based on the teacher's predictions. This correction is used for transferring the ranking information from the user-side as well as the item-side, providing a comprehensive view to understand both users and items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Identifying discrepancy between Teacher model and Student model. DCD first identifies discrepancy between ğ‘… ğ‘¢ ğ‘‡ and ğ‘… ğ‘¢</head><p>ğ‘† to decides what knowledge to be distilled. We define two types of discrepancy: 1) underestimation error and 2) overestimation error. The underestimation error means that the student predicts a low ranking position whereas the teacher predicts a higher ranking position, i.e., ğ‘… ğ‘¢ ğ‘† (ğ‘–) &gt; ğ‘… ğ‘¢ ğ‘‡ (ğ‘–). Thus, the student needs to be corrected to give a lower rank value for (ğ‘¢, ğ‘–). The overestimation error means the opposite, the student predicts a high ranking position whereas the teacher predicts a lower ranking position, i.e., ğ‘… ğ‘¢ ğ‘† (ğ‘–) &lt; ğ‘… ğ‘¢ ğ‘‡ (ğ‘–), which needs to be corrected to give a higher rank value. The userside errors are computed as follows:</p><formula xml:id="formula_3">ğ· ğ‘¢ ğ‘– (ğ‘†,ğ‘‡ ) = ğ‘¡ğ‘ğ‘›â„(ğ‘šğ‘ğ‘¥ (ğœ‡ (ğ‘… ğ‘¢ ğ‘† (ğ‘–) âˆ’ ğ‘… ğ‘¢ ğ‘‡ (ğ‘–)), 0))<label>(3)</label></formula><formula xml:id="formula_4">ğ· ğ‘¢ ğ‘– (ğ‘‡ , ğ‘†) = ğ‘¡ğ‘ğ‘›â„(ğ‘šğ‘ğ‘¥ (ğœ‡ (ğ‘… ğ‘¢ ğ‘‡ (ğ‘–) âˆ’ ğ‘… ğ‘¢ ğ‘† (ğ‘–)), 0))<label>(4)</label></formula><p>We use ğ‘¡ğ‘ğ‘›â„, which is a saturated function, to treat the errors above a certain threshold equally, allowing the student to learn the teacher's knowledge on most of the discrepant predictions. ğœ‡ is a hyperparameter that controls the sharpness of the tanh function. Using the computed errors, we identify the discrepant predictions that need to be corrected. Concretely, we sample ğ‘€ ğ‘¢ ğ‘™ underestimated items and ğ‘€ ğ‘¢ â„ overestimated items. Both sampling probabilities are proportional to the degree of a discrepancy.</p><formula xml:id="formula_5">ğ‘ ğ‘¢ ğ‘™ (ğ‘–) âˆ ğ· ğ‘¢ ğ‘– (ğ‘†,ğ‘‡ ), ğ‘ ğ‘¢ â„ (ğ‘–) âˆ ğ· ğ‘¢ ğ‘– (ğ‘‡ , ğ‘†)<label>(5)</label></formula><p>where ğ‘ ğ‘¢ ğ‘™ (ğ‘–) is the sampling probability of underestimated items and ğ‘ ğ‘¢ â„ (ğ‘–) is the sampling probability of overestimated items for user ğ‘¢. These discrepant items are dynamically changed based on the prediction errors of the student during the training, and will be corrected by the correction loss (Sec. 2.3.2).</p><p>DCD also provides the corrections for discrepancy in terms of the item-side ranking. As pointed out in the previous work <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14]</ref>, learning only the user-side ranking degrades the quality of user representation <ref type="bibr" target="#b6">[7]</ref> and also provides a restricted view insufficient to understand the sparse implicit feedback <ref type="bibr" target="#b13">[14]</ref>. Especially, in KD where the student's capacity is highly limited, these problems can be further exacerbated, which leads to degraded performance.</p><p>Similar to the user-side, we identify the discrepant predictions on the item-side. We sample ğ‘€ ğ‘– ğ‘™ underestimated users and ğ‘€ ğ‘– â„ overestimated users based on the discrepancy between ğ‘… ğ‘– ğ‘‡ and ğ‘… ğ‘– ğ‘† . The sampling probabilities are as follows:</p><formula xml:id="formula_6">ğ‘ ğ‘– ğ‘™ (ğ‘¢) âˆ ğ· ğ‘– ğ‘¢ (ğ‘†,ğ‘‡ ), ğ‘ ğ‘– â„ (ğ‘¢) âˆ ğ· ğ‘– ğ‘¢ (ğ‘‡ , ğ‘†),<label>(6)</label></formula><p>where ğ‘ ğ‘– ğ‘™ (ğ‘¢) is the probability of underestimated users and ğ‘ ğ‘– â„ (ğ‘¢) is the probability of overestimated users for item ğ‘–. Without loss of generality, ğ· ğ‘– ğ‘¢ (ğ´, ğµ) = ğ‘¡ğ‘ğ‘›â„(ğ‘šğ‘ğ‘¥ (ğœ‡ (ğ‘… ğ‘– ğ´ (ğ‘¢) âˆ’ ğ‘… ğ‘– ğµ (ğ‘¢)), 0)). 2.3.2 Dual Correction Distillation Loss. Now, we correct the discrepant predictions in the user-side (summarized by ğ‘€ ğ‘¢ ğ‘™ and ğ‘€ ğ‘¢ â„ ) and the item-side (summarized by ğ‘€ ğ‘– ğ‘™ and ğ‘€ ğ‘– â„ ). From the points of the teacher, the underestimation errors contain the predictions that should be higher-ranked, whereas the overestimation errors contain the predictions that should be relatively lower-ranked compared to the former. As consistently shown in the existing distillation work <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b25">26]</ref>, the student takes a huge benefit by learning the teacher's knowledge with a particular emphasis on the high-ranked items, because it directly affects the top-ğ‘ recommendation accuracy. In this regard, we design the correction loss that corrects the ranks of the underestimation errors in detail and lowers the ranks of the overestimation errors overall.</p><p>Let ğœŒ ğ‘¢ denote the sorted lists of ğ‘€ ğ‘¢ ğ‘™ by the original order in ğ‘… ğ‘¢ ğ‘‡ , and ğœŒ ğ‘– denote the sorted lists of ğ‘€ ğ‘– ğ‘™ by the order in ğ‘… ğ‘– ğ‘‡ . The user-side correction distillation (UCD) for user ğ‘¢ is conducted by maximizing the following relaxed permutation probability:</p><formula xml:id="formula_7">ğ‘ (ğœŒ ğ‘¢ |ğ‘†) = |ğœŒ ğ‘¢ | ğ‘˜=1 exp ğ‘† (ğ‘¢, ğœŒ ğ‘¢ ğ‘˜ ) |ğœŒ ğ‘¢ | ğ‘–=ğ‘˜ exp ğ‘† (ğ‘¢, ğœŒ ğ‘¢ ğ‘– ) + ğ‘— âˆˆğ‘€ ğ‘¢ â„ exp ğ‘† (ğ‘¢, ğ‘—) ,<label>(7)</label></formula><p>where ğœŒ ğ‘¢ ğ‘˜ is the ğ‘˜-th item in ğœŒ ğ‘¢ . UCD is applied for the users in mini-batch ğµ, i.e., L ğ‘ˆ ğ¶ğ· = âˆ’ 1 |ğµ | ğ‘¢ âˆˆğµ log ğ‘ (ğœŒ ğ‘¢ |ğ‘†). Analogously, item-side correction distillation (ICD) for item ğ‘– is conducted by maximizing the following relaxed permutation probability:</p><formula xml:id="formula_8">ğ‘ (ğœŒ ğ‘– |ğ‘†) = |ğœŒ ğ‘– | ğ‘˜=1 exp ğ‘† (ğœŒ ğ‘– ğ‘˜ , ğ‘–) |ğœŒ ğ‘– | ğ‘—=ğ‘˜ exp ğ‘† (ğœŒ ğ‘– ğ‘— , ğ‘–) + ğ‘™ âˆˆğ‘€ ğ‘– â„ exp ğ‘† (ğ‘™, ğ‘–) . (<label>8</label></formula><formula xml:id="formula_9">)</formula><p>ICD is also applied for correcting errors with respect to the items in the batch, i.e., L ğ¼ğ¶ğ· = âˆ’ 1 |ğµ | ğ‘– âˆˆğµ log ğ‘ (ğœŒ ğ‘– |ğ‘†). Finally, the proposed DCD trains the student with the following loss function. min</p><formula xml:id="formula_10">ğœƒ ğ‘  L ğ‘…ğ¾ğ· + ğœ† ğ‘ˆ ğ¶ğ· L ğ‘ˆ ğ¶ğ· + ğœ† ğ¼ğ¶ğ· L ğ¼ğ¶ğ· ,<label>(9)</label></formula><p>where ğœƒ ğ‘  is the learning parameters of the student. ğœ† ğ‘ˆ ğ¶ğ· and ğœ† ğ¼ğ¶ğ· are hyperparameters controlling the user-side and item-side corrections, respectively. Note that L ğ‘…ğ¾ğ· is computed for the same ground-truths regardless of the discrepancy during the training. Finally, our dual correction loss provides dynamically changing guidance to correct the student errors for more effective training. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTS 3.1 Experiment Setup</head><p>We closely follow the setup of the state-of-the-art method, RRD <ref type="bibr" target="#b8">[9]</ref>. Specifically, datasets, base models, evaluation protocol, and the metrics are the same as <ref type="bibr" target="#b8">[9]</ref>. Due to the limited space, we omit the detailed explanations of the setup. Please refer to <ref type="bibr" target="#b8">[9]</ref>. Datasets. We use CiteULike <ref type="bibr" target="#b26">[27]</ref> and Foursquare <ref type="bibr" target="#b21">[22]</ref> which are public real-world datasets. After the preprocessing <ref type="bibr" target="#b8">[9]</ref>, CiteULike has 5,220 users, 25,182 items, and 115,142 interactions. Foursquare has 19,466 users, 28,594 items, and 609,655 interactions. Base models. We use two base models for the top-ğ‘ recommendation: BPR <ref type="bibr" target="#b23">[24]</ref> and NeuMF <ref type="bibr" target="#b4">[5]</ref>, which have different architectures and optimization strategies. For both models, the dimension of user/item representations are set to 200 for the teacher model, and 20 for the student model. Following <ref type="bibr" target="#b8">[9]</ref>, we denote the student model trained without distillation as "Student". Table <ref type="table" target="#tab_0">1</ref> presents the number of parameters and inference time. The inferences are made using PyTorch with CUDA from TITAN Xp GPU and Intel i7-4770 CPU. It shows that the smaller model has lower inference latency.</p><p>Evaluation protocol and metrics. We use the leave-one-out evaluation protocol whereby two interacted items for each user are held out for test/validation, and the rest are used for training <ref type="bibr" target="#b8">[9]</ref>. We adopt two top-ğ‘ ranking evaluation metrics, namely Hit Ratio (H@ğ‘ ) and Mean Reciprocal Rank (M@ğ‘ ). We compute the average score of those two metrics for each user. Finally, we report the average of the five independent runs. Baselines. We compare DCD with the state-of-the-art ranking distillation method, RRD <ref type="bibr" target="#b8">[9]</ref>. Note that we do not include the previous methods distilling point-wise information (e.g., RD <ref type="bibr" target="#b25">[26]</ref>, CD <ref type="bibr" target="#b18">[19]</ref>), because RRD already outperforms them by a huge margin <ref type="bibr" target="#b8">[9]</ref>. Implementation details. We use PyTorch <ref type="bibr" target="#b22">[23]</ref> for implementation and train all models with Adam optimizer <ref type="bibr" target="#b14">[15]</ref>. For each base model and dataset, we tune the hyperparameters by grid search on the validation set. We tune learning rate and L2 regularizer âˆˆ {10 âˆ’1 , 10 âˆ’2 , 10 âˆ’3 , 10 âˆ’4 , 10 âˆ’5 , 10 âˆ’6 }. In the case of RRD-specific hyperparameters, we tune them in the ranges suggested by the original paper. For the dual correction loss, we tune ğœ† ğ‘ˆ ğ¶ğ· , ğœ† ğ¼ğ¶ğ· âˆˆ {1, 10 âˆ’1 , 10 âˆ’2 , 10 âˆ’3 , 10 âˆ’4 , 10 âˆ’5 }, and conduct the sampling process every 5 epochs. The number of discrepant users/items (ğ‘€ * ğ‘™ ,ğ‘€ * â„ ) is set to 40, but it can be further tuned. Lastly, ğœ‡ is set to 10 âˆ’3 . base models. Also, in terms of the number of recommended items (ğ‘ ), DCD shows larger improvements for H@5/M@5 compared to H@10/M@10. Namely, DCD has a better performance at predicting the top-ranked items than RRD, which is practically advantageous for real-world RS, which gives the users the most preferred items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Overall Evaluation.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Ablation Study.</head><p>We provide ablation study of the key components of DCD in Table <ref type="table" target="#tab_2">3</ref>. We compare the following ablations: 1) w/o Correction transfers the user-side and item-side ranking information without the correction strategy, i.e., RRD + item-side RRD. 2) w/o Item-side and w/o User-side ablate ICD and UCD from DCD, respectively. 3) w/o Sampling deterministically selects items/users with the largest underestimation error and overestimation error without the sampling process (Sec. 2.3.1). We observe that each proposed component is indeed effective in distilling the ranking information. This result supports our claim that the supervision from the teacher model should be dynamically changed based on the student's errors (w/o Correction) and distilling the single-side ranking is insufficient (w/o Item-side and w/o User-side). Also, the comparison with "w/o Sampling" shows that a certain degree of flexibility is beneficial in choosing the discrepant predictions for the correction strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Further Analysis.</head><p>We provide further analysis on DCD. For the sake of the space, we report the results of BPR on CiteULike. First, Figure <ref type="figure" target="#fig_0">1a</ref> presents the average ranking-discrepancy of various methods. In specific, we compute the discrepancy as |ğ‘… * ğ‘† (â€¢) âˆ’ Base Model KD Method H@5 M@5 H@10 M@10 ğ‘… * ğ‘‡ (â€¢)| for the user-side (and for the item-side) top-50 recommendation list produced by the teacher model. We compute it for all users (and for all items), then report the average value. We observe that the proposed correction strategy effectively reduces the discrepancy between the teacher model and the student model. All the correction-based methods (i.e., ICD, UCD, and DCD) achieves lower discrepancy than RRD. Also, DCD achieves the lowest discrepancy in both user-side and item-side, which supports its superior recommendation performance. This also again shows the importance of the dual-side ranking correction. Lastly, Figure <ref type="figure" target="#fig_0">1b</ref> shows the effects of ğœ† ğ‘ˆ ğ¶ğ· and ğœ† ğ¼ğ¶ğ· . Note that ğœ† ğ‘ˆ ğ¶ğ· = 0 &amp; ğœ† ğ‘ˆ ğ¶ğ· = 0 corresponds to RRD. We again observe that both user-side and item-side corrections are indeed effective. The best performance is achieved when ğœ† ğ¼ğ¶ğ· is around 10 âˆ’2 -10 âˆ’3 and ğœ† ğ‘ˆ ğ¶ğ· is around 10 âˆ’2 -10 âˆ’3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSION</head><p>We propose DCD, a dual correction strategy for ranking distillation in top-ğ‘ RS. Unlike the existing method based on unilateral distillation, DCD provides guidance designed to correct the errors that the student model has failed to learn. By considering the prediction errors of the student model, DCD helps to find an effective path for the student model's training. DCD also considers the user-side ranking and item-side ranking simultaneously, providing a comprehensive view to understand both users and items. We validate the effectiveness of DCD with extensive experiments on real-world datasets. Also, we provide in-depth ablation study to ascertain the validity of each proposed component. For future work, we will investigate the effects of DCD on various base models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Effects of DCD. (a) The average discrepancy from Teacher, (b) H@5 with varying ğœ† ğ‘ˆ ğ¶ğ· and ğœ† ğ¼ğ¶ğ· .</figDesc><graphic url="image-1.png" coords="4,327.53,218.57,221.10,76.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The number of parameters and inference time for generating recommendation list for every user.</figDesc><table><row><cell>Dataset</cell><cell>Base Model</cell><cell cols="2"># Parameters Time (GPU/CPU)</cell></row><row><cell></cell><cell>BPR (Teacher)</cell><cell>6.08M</cell><cell>5.90s / 59.80s</cell></row><row><cell>CiteULike</cell><cell>BPR (Student)</cell><cell>0.61M</cell><cell>3.67s / 14.90s</cell></row><row><cell></cell><cell>NeuMF (Teacher)</cell><cell>12.24M</cell><cell>17.80s / 261.37s</cell></row><row><cell></cell><cell>NeuMF (Student)</cell><cell>1.22M</cell><cell>7.42s / 33.75s</cell></row><row><cell></cell><cell>BPR (Teacher)</cell><cell>9.61M</cell><cell>25.22s / 252.23s</cell></row><row><cell>Foursquare</cell><cell>BPR (Student)</cell><cell>0.96M</cell><cell>15.22s / 64.22s</cell></row><row><cell></cell><cell>NeuMF (Teacher)</cell><cell>19.30M</cell><cell>75.22s / 1086.44s</cell></row><row><cell></cell><cell>NeuMF (Student)</cell><cell>1.92M</cell><cell>30.54s / 144.05s</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Table2presents top-ğ‘ recommendation accuracy of the methods compared. DCD achieves significantly higher performance than RRD on both datasets and both Performance comparison. improve.r denotes the improvement of DCD over RRD and improve.s denotes the improvement of DCD over Student. * and ** indicate ğ‘ â‰¤ 0.005 and ğ‘ â‰¤ 0.0005 for the paired t-test of DCD vs. RRD on H@5.</figDesc><table><row><cell></cell><cell></cell><cell>CiteULike</cell></row><row><cell cols="3">Base Model KD Method H@5 M@5 H@10 M@10</cell></row><row><cell>BPR</cell><cell>Teacher Student RRD DCD *</cell><cell>0.5282 0.3704 0.6328 0.3844 0.4570 0.3061 0.5673 0.3214 0.4735 0.3200 0.5800 0.3343 0.4989 0.3412 0.6082 0.3560</cell></row><row><cell></cell><cell>improve.r improve.s</cell><cell>5.36% 6.63% 4.86% 6.49% 9.17% 11.47% 7.21% 10.77%</cell></row><row><cell>NeuMF</cell><cell>Teacher Student RRD DCD **</cell><cell>0.4840 0.3346 0.5827 0.3478 0.3805 0.2499 0.4817 0.2634 0.4563 0.2952 0.5647 0.3092 0.4700 0.3101 0.5742 0.3241</cell></row><row><cell></cell><cell>improve.r improve.s</cell><cell>3.00% 5.05% 1.68% 4.82% 23.52% 24.09% 19.20% 23.04%</cell></row><row><cell></cell><cell></cell><cell>Foursquare</cell></row><row><cell cols="3">Base Model KD Method H@5 M@5 H@10 M@10</cell></row><row><cell>BPR</cell><cell>Teacher Student RRD DCD **</cell><cell>0.5623 0.3618 0.7068 0.3812 0.4982 0.3140 0.6498 0.3342 0.5132 0.3259 0.6625 0.3454 0.5468 0.3483 0.6958 0.3683</cell></row><row><cell></cell><cell>improve.r improve.s</cell><cell>6.55% 6.87% 5.03% 6.63% 9.76% 10.92% 7.08% 10.20%</cell></row><row><cell>NeuMF</cell><cell>Teacher Student RRD DCD **</cell><cell>0.5459 0.3499 0.6897 0.3693 0.4793 0.2959 0.6312 0.3162 0.5076 0.3119 0.6615 0.3313 0.5287 0.3303 0.6734 0.3497</cell></row><row><cell></cell><cell>improve.r improve.s</cell><cell>4.16% 5.90% 1.80% 5.55% 10.31% 11.63% 6.69% 10.59%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Ablation analysis on Foursquare dataset.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgement. The authors thank SeongKu Kang for contributing to the implementation and improvement of DCD. This work was supported by IITP grant funded by the MSIT: (No.2019-0-00075, Artificial Intelligence Graduate School Program(KAIST)) and the ETRI: (Contract No. 21ZS1100).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Speeding up the xbox recommender system using a euclidean transformation for inner-product spaces</title>
		<author>
			<persName><forename type="first">Yoram</forename><surname>Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ran</forename><surname>Gilad-Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liran</forename><surname>Katzir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Koenigstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nir</forename><surname>Nice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulrich</forename><surname>Paquet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>In RecSys</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Learning efficient object detection models with knowledge distillation</title>
		<author>
			<persName><forename type="first">Guobin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wongun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tony</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Unsupervised Proxy Selection for Session-based Recommender Systems</title>
		<author>
			<persName><forename type="first">Junsu</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seongku</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongmin</forename><surname>Hyun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Tommaso</forename><surname>Furlanello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Tschannen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Itti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anima</forename><surname>Anandkumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.04770</idno>
		<title level="m">Born again neural networks</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural collaborative filtering</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Collaborative multi-objective ranking</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ping</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Collaborative filtering for implicit feedback datasets</title>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
				<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">DE-RRD: A Knowledge Distillation Framework for Recommender System</title>
		<author>
			<persName><forename type="first">Seongku</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyoung</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wonbin</forename><surname>Kweon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Itemside Ranking Regularized Distillation for Recommender System</title>
		<author>
			<persName><forename type="first">Seongku</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyoung</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wonbin</forename><surname>Kweon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ins.2021.08.060</idno>
		<ptr target="https://doi.org/10.1016/j.ins.2021.08.060" />
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Topology Distillation for Recommender System</title>
		<author>
			<persName><forename type="first">Seongku</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyoung</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wonbin</forename><surname>Kweon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Semisupervised learning for cross-domain recommendation to cold-start users</title>
		<author>
			<persName><forename type="first">Seongku</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyoung</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongha</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Candidate Generation with Binary Codes for Large-Scale Top-N Recommendation</title>
		<author>
			<persName><forename type="first">Wang-Cheng</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Dual neural personalized ranking</title>
		<author>
			<persName><forename type="first">Seunghyeon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jongwuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyunjung</forename><surname>Shim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
				<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep Rating Elicitation for New Users in Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Wonbin</forename><surname>Kweon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seongku</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyoung</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Bidirectional Distillation for Top-K Recommender System</title>
		<author>
			<persName><forename type="first">Wonbin</forename><surname>Kweon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seongku</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Bootstrapping User and Item Representations for One-Class Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Dongha</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seongku</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyunjun</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chanyoung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
			<publisher>SIGIR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Jaewoong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minjin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jongwuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyunjung</forename><surname>Shim</surname></persName>
		</author>
		<title level="m">Collaborative Distillation for Top-N Recommendation. ICDM</title>
				<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Xing Xie, and Longbing Cao. 2017. Discrete Content-Aware Matrix Factorization</title>
		<author>
			<persName><forename type="first">Defu</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Discrete factorization machines for fast feature-based recommendation</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuli</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.02232</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An experimental evaluation of point-of-interest recommendation in location-based social networks</title>
		<author>
			<persName><forename type="first">Yiding</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tuan-Anh Nguyen</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gao</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quan</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
				<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.01703</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">BPR: Bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
				<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Fitnets: Hints for thin deep nets</title>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samira</forename><forename type="middle">Ebrahimi</forename><surname>Kahou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Chassang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlo</forename><surname>Gatta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>arXiv</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Ranking distillation: Learning compact ranking models with high performance for recommender system</title>
		<author>
			<persName><forename type="first">Jiaxi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Collaborative topic regression with social regularization for tag recommendation</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wu-Jun</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Binarized collaborative filtering with distilling graph convolutional networks</title>
		<author>
			<persName><forename type="first">Haoyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Defu</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Ge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Listwise approach to learning to rank: theory and algorithm</title>
		<author>
			<persName><forename type="first">Fen</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wensheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Discrete Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fumin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
