<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Augmented Lagrangian methods under the constant positive linear dependence constraint qualification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2006-12-01">1 December 2006</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">R</forename><surname>Andreani</surname></persName>
							<email>andreani@ime.unicamp.br</email>
						</author>
						<author>
							<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Birgin</surname></persName>
							<email>egbirgin@ime.usp.br</email>
						</author>
						<author>
							<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Martínez</surname></persName>
							<email>martinez@ime.unicamp.br</email>
						</author>
						<author>
							<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Schuverdt</surname></persName>
							<email>schuverd@ime.unicamp.br</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Applied Mathematics</orgName>
								<orgName type="department" key="dep2">IMECC-UNICAMP</orgName>
								<orgName type="institution">University of Campinas</orgName>
								<address>
									<postCode>6065, 13081-970</postCode>
									<settlement>Campinas</settlement>
									<region>CP, SP</region>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science IME-USP</orgName>
								<orgName type="institution">University of São Paulo</orgName>
								<address>
									<addrLine>Rua do Matão 1010, Cidade Universitária</addrLine>
									<postCode>05508-090</postCode>
									<settlement>São Paulo</settlement>
									<region>SP</region>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Augmented Lagrangian methods under the constant positive linear dependence constraint qualification</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2006-12-01">1 December 2006</date>
						</imprint>
					</monogr>
					<idno type="MD5">196D314A281D1A078ED3250BB0D62A5A</idno>
					<idno type="DOI">10.1007/s10107-006-0077-1</idno>
					<note type="submission">Received: 9 August 2004 / Accepted: 21 September 2005 /</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Two Augmented Lagrangian algorithms for solving KKT systems are introduced. The algorithms differ in the way in which penalty parameters are updated. Possibly infeasible accumulation points are characterized. It is proved that feasible limit points that satisfy the Constant Positive Linear Dependence constraint qualification are KKT solutions. Boundedness of the penalty parameters is proved under suitable assumptions. Numerical experiments are presented. Keywords Nonlinear programming • Augmented Lagrangian methods • KKT systems • Numerical experiments Dedicated to Clovis Gonzaga on the occassion of his 60th birthday.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mathematics Subject Classification (2000) 65K05 • 65K10 1 Introduction</head><p>Let F : R n → R n , h : R n → R m and = {x ∈ R n | ≤ x ≤ u}, where , u ∈ R n , &lt; u. Assume that h admits continuous first derivatives on an open set that contains and denote ∇h(x) = (∇h 1 (x), . . . , ∇h m (x)) = h (x) T ∈ R n×m .</p><p>Let P A denote the Euclidian projection operator onto a closed and convex set A. A point x ∈ R n is said to be a KKT point of the problem defined by F, h and if there exists λ ∈ R m such that</p><formula xml:id="formula_0">P [x -F(x) -∇h(x)λ] -x = 0, h(x) = 0, x ∈ . (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>KKT points are connected with the solution of variational inequality problems (VIP). The VIP defined by (F, D) (see, for example <ref type="bibr" target="#b33">[34]</ref>) consists of finding x ∈ D such that F(x) T d ≥ 0 for all d in the tangent cone T D (x) <ref type="bibr">([3]</ref>, p. 343). Defining D = {x ∈ | h(x) = 0}, and under appropriate constraint qualifications, it turns out that the solutions of the VIP are KKT points. In particular, if f : R n → R is differentiable and F = ∇f , the equations (1) represent the KKT optimality conditions of the minimization problem Minimize f (x) subject to h(x) = 0, x ∈ .</p><p>(</p><formula xml:id="formula_2">)<label>2</label></formula><p>The most influential work on practical Augmented Lagrangian algorithms for minimization with equality constraints and bounds (problem (2)) was the paper by Conn et al. <ref type="bibr" target="#b11">[12]</ref>, on which the LANCELOT package <ref type="bibr" target="#b9">[10]</ref> is based. Convergence of the algorithm presented in <ref type="bibr" target="#b11">[12]</ref> was proved under the assumption that the gradients of the general constraints and the active bounds at any limit point are linearly independent. In <ref type="bibr" target="#b10">[11]</ref> the authors extended the method of <ref type="bibr" target="#b11">[12]</ref> to the case where linear inequality constraints are treated separately and also to the case where different penalty parameters are associated with different general constraints.</p><p>In the present paper we introduce two Augmented Lagrangian algorithms for solving <ref type="bibr" target="#b0">(1)</ref>. For proving global convergence, we do not use the linear independence constraint qualification (LICQ) at all. On one hand, we characterize the situations in which infeasible limit points might exist using weaker assumptions than the LICQ. On the other hand, the fact that feasible limit points are KKT points will follow using the constant positive linear dependence (CPLD) condition <ref type="bibr" target="#b28">[29]</ref>, which has been recently proved to be a constraint qualification <ref type="bibr" target="#b1">[2]</ref> and is far more general than the LICQ and other popular constraint qualifications. We use the LICQ only for proving boundedness of the penalty parameters.</p><p>This paper is organized as follows. The two main algorithms are introduced in Sect. 2. In Sect. 3 we characterize the infeasible points that could be limit points of the algorithms. In Sect. <ref type="bibr" target="#b3">4</ref> it is proved that, if the CPLD constraint qualification holds at a feasible limit point, then this point must be KKT. In Sect. 5 we prove boundedness of the penalty parameters. In Sect. <ref type="bibr" target="#b5">6</ref> we present numerical experiments. Conclusions and lines for future research are given in Sect. 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Notation.</head><p>Throughout this work, <ref type="bibr">[v]</ref> i is the i-th component of the vector v. We also denote v i = [v] i if this does not lead to confusion. R + denotes the set of nonnegative real numbers and R ++ denotes the set of positive real numbers.</p><p>If J 1 and J 2 are subsets of {1, . . . , n}, B [J 1 ,J 2 ] is the matrix formed by taking the rows and columns of B indexed by J 1 and J 2 respectively and B [J 1 ] is the matrix formed by taking the columns of B indexed by J 1 . If y ∈ R n , y [J 1 ] is the vector formed by taking the components y i such that i ∈ J 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model algorithms</head><p>From here on we assume that F is continuous. Given</p><formula xml:id="formula_3">x ∈ , λ ∈ R m , ρ ∈ R m ++ we define G(x, λ, ρ) = F(x) + m i=1 λ i ∇h i (x) + m i=1 ρ i h i (x)∇h i (x).</formula><p>If the KKT system is originated in a smooth minimization problem, the mapping F is the gradient of some f : R n → R. In this case we define, for ρ ∈ R m ++ ,</p><formula xml:id="formula_4">L(x, λ, ρ) = f (x) + m i=1 λ i h i (x) + 1 2 m i=1 ρ i h i (x) 2 .</formula><p>This is the definition of the Augmented Lagrangian used in <ref type="bibr" target="#b10">[11]</ref>. In this case we have that ∇L = G. The function L is the Augmented Lagrangian associated with the problem <ref type="bibr" target="#b1">(2)</ref>.</p><p>The mapping G will be used to define one-parameter and many-parameters Augmented Lagrangian algorithms for solving the general KKT problem (1). These two algorithms (A1 and A2) are described below. They are presented as two instances of the general Algorithm A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm A.</head><p>Let</p><formula xml:id="formula_5">x 0 ∈ , τ ∈ [0, 1), γ &gt; 1, -∞ &lt; λmin ≤ 0 ≤ λmax &lt; ∞, ρ 1 ∈ R m ++ (in Algorithm A1 [ρ 1 ] i = ρ 1 ∞ for all i = 1, . . . , m), λ1 ∈ [ λmin , λmax ] m . Let {ε k } k∈N ⊆ R ++</formula><p>be a sequence that converges to zero.</p><p>Step 1. Initialization Set k ← 1.</p><p>Step 2. Solving the subproblem Compute x k ∈ such that</p><formula xml:id="formula_6">P [x k -G(x k , λk , ρ k )] -x k ∞ ≤ ε k . (<label>3</label></formula><formula xml:id="formula_7">)</formula><p>Step 3. Estimate multipliers Define, for all i = 1, . . . , m, </p><formula xml:id="formula_8">[λ k+1 ] i = [ λk ] i + [ρ k ] i h i (x k ). (<label>4</label></formula><formula xml:id="formula_9">) If h(x k ) = 0 and P [x k -G(x k , λk , ρ k )] -x k = 0 terminate</formula><formula xml:id="formula_10">)<label>5</label></formula><p>Step 4. Update the penalty parameters</p><formula xml:id="formula_11">Define k = {i ∈ {1, . . . , m} | |h i (x k )| &gt; τ h(x k-1 ) ∞ }. If k = ∅, define ρ k+1 = ρ k . Else, -In Algorithm A1, define ρ k+1 = γρ k . -In Algorithm A2, define [ρ k+1 ] i = γ [ρ k ] i if i ∈ k and [ρ k+1 ] i = [ρ k ] i if i / ∈ k . Step 5. Begin a new iteration Set k ← k + 1. Go to Step 2.</formula><p>Remark 1 (i) Algorithm A2 only differs from Algorithm A1 in the way in which penalty parameters are updated. In Algorithm A2, as in <ref type="bibr" target="#b10">[11]</ref>, more than one penalty parameter is used per iteration. In the case in which Algorithm A2 updates at least one penalty parameter, Algorithm A1 updates its unique penalty parameter. In such a situation, other penalty parameters may remain unchanged in Algorithm A2. Therefore, the penalty parameters in Algorithm A2 tend to be smaller than the penalty parameter in Algorithm A1. (ii) The global convergence results to be presented in the following sections are independent of the choice of λk+1 in <ref type="bibr" target="#b4">(5)</ref>. Whenever possible, we will choose λk+1 = λ k+1 but, as a matter of fact, the definition (4) is not used at all in the forthcoming Sect. 3 and 4. If one chooses λk+1 = 0 for all k, Algorithms A1 and A2 turn out to be External Penalty methods. (iii) The Augmented Lagrangian algorithms are based on the resolution of the inner problems (3). In the minimization case (F = ∇f ) the most reasonable way for obtaining these conditions is to solve (approximately) the minimization problem</p><formula xml:id="formula_12">Minimize L(x, λk , ρ k ) subject to x ∈ . (<label>6</label></formula><formula xml:id="formula_13">)</formula><p>This is a box-constrained minimization problem. Since is compact, minimizers exist and stationary points can be obtained up to any arbitrary precision using reasonable algorithms. Sufficient conditions under which points that satisfy (3) exist and can be obtained by available algorithms in more general problems have been analyzed in many recent papers. See <ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b25">26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Convergence to feasible points</head><p>At a KKT point we have that h(x) = 0 and x ∈ . Points that satisfy these two conditions are called feasible. It would be nice to have algorithms that find feasible points in every situation, but this is impossible. (In an extreme case, feasible points might not exist at all.) Therefore, it is important to study the behavior of algorithms with respect to infeasibility.</p><p>In this section we show that Algorithm A1 always converges to stationary points of the problem of minimizing h(x) 2  2 subject to ≤ x ≤ u. In the case of Algorithm A2 we will show that the possible limit points must be solutions of a weighted least-squares problem involving the constraints.</p><p>In the proof of both theorems we will use the following well known property:</p><formula xml:id="formula_14">P (u + tv) -u 2 ≤ P (u + v) -u 2 ∀u ∈ , v ∈ R n , t ∈ [0, 1].<label>(7)</label></formula><p>Theorem 1 Assume that the sequence {x k } is generated by Algorithm A1 and that x * is a limit point. Then, x * is a stationary point of the problem</p><formula xml:id="formula_15">Minimize h(x) 2 2 subject to x ∈ . (<label>8</label></formula><formula xml:id="formula_16">) Proof Let K ⊆ N be such that lim k∈K x k = x * . Let us denote ρk = ρ k ∞ for all k ∈ N.</formula><p>Clearly, ρk = [ρ k ] i for all i = 1, . . . , m. By (3) and the equivalence of norms in R n , we have that</p><formula xml:id="formula_17">lim k→∞ P [x k -F(x k ) - m i=1 ([ λk ] i + ρk h i (x k ))∇h i (x k )] -x k 2 = 0. (<label>9</label></formula><formula xml:id="formula_18">)</formula><p>By Step 4 of Algorithm A, if {ρ k } k∈K is bounded we have that h(x * ) = 0, so x * is a stationary point of <ref type="bibr" target="#b7">(8)</ref>.</p><p>Assume that {ρ k } k∈K is unbounded. Since { ρk } is nondecreasing, we have that lim</p><formula xml:id="formula_19">k→∞ ρk = ∞.<label>(10)</label></formula><p>Then, ρk &gt; 1 for k ∈ K large enough. So, using <ref type="bibr" target="#b6">(7)</ref> with</p><formula xml:id="formula_20">u = x k , v = -F(x k ) - m i=1 ([ λk ] i + ρk h i (x k ))∇h i (x k ), t = 1/ ρk ,</formula><p>we have, by <ref type="bibr" target="#b8">(9)</ref>, that</p><formula xml:id="formula_21">lim k→∞ P x k - F(x k ) ρk - m i=1 [ λk ] i ρk + h i (x k ) ∇h i (x k ) -x k 2 = 0.<label>(11)</label></formula><p>By ( <ref type="formula" target="#formula_10">5</ref>), <ref type="bibr" target="#b9">(10)</ref>, <ref type="bibr" target="#b10">(11)</ref> and the continuity of F we obtain:</p><formula xml:id="formula_22">P [x * - m i=1 h i (x * )∇h i (x * )] -x * 2 = 0.</formula><p>This means that x * is a stationary point of ( <ref type="formula" target="#formula_15">8</ref>), as we wanted to prove.</p><p>We say that an infeasible point</p><formula xml:id="formula_23">x * ∈ is degenerate if there exists w ∈ R m + such that x * is a stationary point of the weighted least-squares problem Minimize m i=1 w i h i (x) 2 subject to x ∈ ,<label>(12)</label></formula><p>and w i &gt; 0 for some i such that</p><formula xml:id="formula_24">h i (x * ) = 0. (<label>13</label></formula><formula xml:id="formula_25">)</formula><p>Theorem 2 Let {x k } be a sequence generated by Algorithm A2. Then, at least one of the following possibilities hold:</p><p>1. The sequence admits a feasible limit point.</p><p>2. The sequence admits an infeasible degenerate limit point.</p><p>Proof Assume that all the limit points of the sequence {x k } are infeasible. Therefore, there exists ε &gt; 0 such that</p><formula xml:id="formula_26">h(x k ) ∞ ≥ ε (<label>14</label></formula><formula xml:id="formula_27">)</formula><p>for all k ∈ N. This implies that</p><formula xml:id="formula_28">lim k→∞ ρ k ∞ = ∞.<label>(15)</label></formula><p>Let K be an infinite subset of indices such that</p><formula xml:id="formula_29">ρ k ∞ &gt; ρ k-1 ∞ ∀k ∈ K. (<label>16</label></formula><formula xml:id="formula_30">)</formula><p>Since {1, . . . , m} is a finite set, there exists K 1 , an infinite subset of K, and j ∈ {1, . . . , m} such that</p><formula xml:id="formula_31">ρ k ∞ = [ρ k ] j ∀k ∈ K 1 .<label>(17)</label></formula><p>Then, by <ref type="bibr" target="#b15">(16)</ref> and Step 4 of Algorithm A2,</p><formula xml:id="formula_32">[ρ k ] j = γ [ρ k-1 ] j ∀k ∈ K 1 . (<label>18</label></formula><formula xml:id="formula_33">)</formula><p>By the definition of the algorithm, we have that, for all k ∈ K 1 ,</p><formula xml:id="formula_34">|h j (x k-1 )| &gt; τ h(x k-2 ) ∞ .</formula><p>So, by <ref type="bibr" target="#b13">(14)</ref>,</p><formula xml:id="formula_35">|h j (x k-1 )| &gt; τε ∀k ∈ K 1 .<label>(19)</label></formula><p>Moreover, by ( <ref type="formula" target="#formula_29">16</ref>), ( <ref type="formula" target="#formula_31">17</ref>) and ( <ref type="formula" target="#formula_32">18</ref>), we have:</p><formula xml:id="formula_36">[ρ k-1 ] j ≥ ρ k-1 ∞ γ ∀k ∈ K 1 .<label>(20)</label></formula><p>Let K 2 be an infinite subset of indices of {k -1} k∈K 1 such that</p><formula xml:id="formula_37">lim k∈K 2 x k = x * .</formula><p>By <ref type="bibr" target="#b18">(19)</ref> we have that</p><formula xml:id="formula_38">h j (x * ) = 0. (<label>21</label></formula><formula xml:id="formula_39">)</formula><p>By (3) and the equivalence of norms in R n , we have:</p><formula xml:id="formula_40">lim k→∞ P [x k -F(x k ) - m i=1 ([ λk ] i + [ρ k ] i h i (x k ))∇h i (x k )] -x k 2 = 0.<label>(22)</label></formula><p>By <ref type="bibr" target="#b14">(15)</ref>, ρ k ∞ &gt; 1 for k ∈ K 2 large enough. So, using <ref type="bibr" target="#b6">(7)</ref> with</p><formula xml:id="formula_41">u = x k , v = -F(x k ) - m i=1 ([ λk ] i + [ρ k ] i h i (x k ))∇h i (x k ), t = 1/ ρ k ∞ ,</formula><p>we have, by <ref type="bibr" target="#b21">(22)</ref>, that lim</p><formula xml:id="formula_42">k∈K 2 P x k - F(x k ) ρ k ∞ - m i=1 [ λk ] i ρ k ∞ + [ρ k ] i ρ k ∞ h i (x k ) ∇h i (x k ) -x k 2 = 0. (<label>23</label></formula><formula xml:id="formula_43">) But [ρ k ] i ρ k ∞ ≤ 1 ∀i = 1, . . . , m.</formula><p>Therefore, there exist</p><formula xml:id="formula_44">K 3 ⊆ K 2 and w ∈ R m + such that lim k∈K 3 [ρ k ] i ρ k ∞ = w i ∀i = 1, . . . , m.</formula><p>Moreover, by <ref type="bibr" target="#b19">(20)</ref>,</p><formula xml:id="formula_45">w j &gt; 0. (<label>24</label></formula><formula xml:id="formula_46">)</formula><p>Since { λk } k∈N is bounded, taking limits for k ∈ K 3 in <ref type="bibr" target="#b22">(23)</ref>, by <ref type="bibr" target="#b14">(15)</ref> and the continuity of F, we get:</p><formula xml:id="formula_47">P [x * - m i=1 w i h i (x * )∇h i (x * )] -x * 2 = 0.</formula><p>So, x * is a stationary point of <ref type="bibr" target="#b11">(12)</ref>. By <ref type="bibr" target="#b20">(21)</ref> and <ref type="bibr" target="#b23">(24)</ref>, the condition (13) also takes place. Therefore, x * is a degenerate infeasible point.</p><p>Remark 2 Clearly, any infeasible stationary point of (8) must be degenerate. Moreover, if x is infeasible and degenerate, by <ref type="bibr" target="#b12">(13)</ref> and the KKT conditions of <ref type="bibr" target="#b11">(12)</ref>, the gradients of the equality constraints and the active bound constraints are linearly dependent. The reciprocal is not true. In fact, consider the set of constraints</p><formula xml:id="formula_48">h(x) ≡ x = 0 ∈ R 1 , -1 ≤ x ≤ 1.</formula><p>At the points z = -1 and z = 1 the gradients of equality constraints and active bound constraints are linearly dependent but these points are not degenerate. In <ref type="bibr" target="#b11">[12]</ref> it is assumed that, at all the limit points of the sequence generated by the Augmented Lagrangian algorithm, the gradients of equality constraints and active bound constraints are linearly independent (Assumption AS3 of <ref type="bibr" target="#b11">[12]</ref>). Under this assumption it is proved that all the limit points are feasible. The feasibility of all the limit points generated by Algorithm A1 also holds from our Theorem 1, if we assume that limit points are nondegenerate. For Algorithm A2, the corresponding result comes from Theorem 2: under the weak assumption of nondegeneracy we only obtain the weaker result that there exists at least one feasible limit point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Convergence to optimal points</head><p>In this section we investigate under which conditions a feasible limit point of a sequence generated by the Augmented Lagrangian algorithms is a KKT point.</p><p>The main result is that a feasible limit point is KKT if it satisfies the CPLD. The CPLD condition was introduced by Qi and Wei in <ref type="bibr" target="#b28">[29]</ref>. More recently <ref type="bibr" target="#b1">[2]</ref>, it was proved that this condition is a constraint qualification. Assume that the constraints of a problem are h(x) = 0, g(x) ≤ 0, where h : R n → R m , g : R n → R p and that x is a feasible point such that g i (x) = 0 for all i ∈ I, g i (x) &lt; 0 for all i / ∈ I. We say that x satisfies the CPLD condition if the existence of</p><formula xml:id="formula_49">J 1 ⊆ {1, . . . , m}, J 2 ⊆ I, {λ i } i∈J 1 ⊆ R, {µ i } i∈J 2 ⊆ R + such that i∈J 1 λ i ∇h i (x) + i∈J 2 µ i ∇g i (x) = 0 and i∈J 1 |λ i | + i∈J 2 µ i &gt; 0 implies that the gradients {∇h i (x)} i∈J 1 ∪ {∇g i (x)} i∈J 2 are linearly dependent for all x in a neighborhood of x.</formula><p>Clearly, if the Mangasarian-Fromovitz constraint qualification <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b32">33]</ref> holds, the CPLD condition holds as well, but the reciprocal is not true.</p><p>The AS3 condition of <ref type="bibr" target="#b11">[12]</ref>, when applied only to feasible points, is the classical LICQ assumption (linear independence of the gradients of active constraints). Of course, at points that do not satisfy Mangasarian-Fromovitz the gradients of active constraints are linearly dependent. Therefore, convergence results based on the CPLD condition are stronger than convergence results that assume the classical LICQ.</p><p>In Theorem 3 we prove that, if a feasible limit point of an algorithmic sequence satisfies the CPLD constraint qualification, then this point must be KKT.</p><p>Theorem 3 Assume that {x k } is a sequence generated by Algorithm A and that x * is a feasible limit point that satisfies the CPLD constraint qualification. Then, x * is a KKT point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof Let us write</head><formula xml:id="formula_50">G k = G(x k , λk , ρ k ).</formula><p>Define, for all k ∈ N,</p><formula xml:id="formula_51">v k = P (x k -G k ). Therefore, v k ∈ R n solves Minimize v -(x k -G k ) 2 2 subject to ≤ v ≤ u.</formula><p>By the KKT conditions of this problem, there exist</p><formula xml:id="formula_52">µ u k ∈ R n + , µ k ∈ R n + such that, for all k ∈ N, v k -x k + G k + n i=1 [µ u k ] i e i - n i=1 [µ k ] i e i = 0<label>(25)</label></formula><p>and</p><formula xml:id="formula_53">[µ u k ] i (u i -[x k ] i ) = [µ k ] i ( i -[x k ] i ) = 0 ∀i = 1, . . . , n. (<label>26</label></formula><formula xml:id="formula_54">)</formula><p>By ( <ref type="formula" target="#formula_6">3</ref>),</p><formula xml:id="formula_55">lim k→∞ (v k -x k ) = 0.</formula><p>Then, by <ref type="bibr" target="#b24">(25)</ref>,</p><formula xml:id="formula_56">lim k→∞ G k + n i=1 [µ u k ] i e i - n i=1 [µ k ] i e i = 0.</formula><p>So, defining λ k+1 as in ( <ref type="formula" target="#formula_8">4</ref>),</p><formula xml:id="formula_57">lim k→∞ F(x k ) + ∇h(x k )λ k+1 + n i=1 [µ u k ] i e i - n i=1 [µ k ] i e i = 0.<label>(27)</label></formula><p>Assume now that K is an infinite subset of N such that</p><formula xml:id="formula_58">lim k∈K x k = x * .</formula><p>Since x * is feasible, by the continuity of h we have that</p><formula xml:id="formula_59">lim k∈K h(x k ) = 0.<label>(28)</label></formula><p>By ( <ref type="formula" target="#formula_53">26</ref>), ( <ref type="formula" target="#formula_57">27</ref>) and ( <ref type="formula" target="#formula_59">28</ref>), since ≤ x k ≤ u for all k, the subsequence {x k } k∈K is an approximate KKT sequence in the sense of <ref type="bibr" target="#b28">[29]</ref> (Definition 2.5). (In <ref type="bibr" target="#b28">[29]</ref> one has F = ∇f but the extension of the definition to a general F is straightfoward.) Therefore, as in the proof of Theorem 2.7 of <ref type="bibr" target="#b28">[29]</ref>, we obtain that x * is a KKT point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Boundedness of the penalty parameters</head><p>In this section we assume that the sequence {x k }, generated by Algorithm A1 or by Algorithm A2, converges to a KKT point x * ∈ . To simplify the arguments, as in <ref type="bibr" target="#b11">[12]</ref>, we assume without loss of generality that [x * ] i &lt; u i for all i = 1, . . . , n and that i = 0 for all i = 1, . . . , n. The Lagrange multipliers associated with x * will be denoted λ * ∈ R m . This vector will be unique by future assumptions. We will assume that F (x) and ∇ 2 h i (x) exist and are Lipschitz-continuous for all x ∈ . Many definitions and proofs of this section invoke arguments used in <ref type="bibr" target="#b11">[12]</ref>. We will mention all the cases in which this occurs.</p><formula xml:id="formula_60">Assumption NS Define J 1 = ⎧ ⎨ ⎩ i ∈ {1, . . . , n} | [F(x * ) + m j=1 [λ * ] j ∇h j (x * )] i = 0 and [x * ] i &gt; 0 ⎫ ⎬ ⎭ J 2 = ⎧ ⎨ ⎩ i ∈ {1, . . . , n} | [F(x * ) + m j=1 [λ * ] j ∇h j (x * )] i = 0 and [x * ] i = 0 ⎫ ⎬ ⎭ .</formula><p>Then, the matrix</p><formula xml:id="formula_61">[F (x * ) + m j=1 [λ * ] j ∇ 2 h j (x * )] [J,J] (h (x * ) [J] ) T h (x * ) [J] 0 is nonsingular for all J = J 1 ∪ K such that K ⊆ J 2 .</formula><p>Assumption NS, which corresponds to Assumption AS5 of <ref type="bibr" target="#b11">[12]</ref>, will be supposed to be true all along this section. Clearly, the fulfillment of NS implies that the gradients of active constraints at x * are linearly independent.</p><p>We will also assume that the computation of λk at Step 3 of both algorithms is:</p><formula xml:id="formula_62">[ λk ] i = max{ λmin , min{ λmax , [λ k ] i }}<label>(29)</label></formula><p>for all i = 1, . . . , m. Finally, we will assume that the true Lagrange multipliers</p><formula xml:id="formula_63">[λ * ] i satisfy λmin &lt; [λ * ] i &lt; λmax ∀i = 1, . . . , m. (<label>30</label></formula><formula xml:id="formula_64">)</formula><p>In the case of Algorithm A1 it will be useful to denote, as before, ρk = ρ k ∞ .</p><p>Lemma 1 Assume that the sequence {x k } is generated by Algorithm A1. Then, there exist k 0 ∈ N, ρ, a 1 , a 2 , a 3 , a 4 , a 5 , a 6 &gt; 0 such that, for all k ≥ k 0 ,</p><formula xml:id="formula_65">λ k+1 -λ * ∞ ≤ a 1 ε k + a 2 x k -x * ∞ ,<label>(31)</label></formula><p>and, if ρk 0 ≥ ρ:</p><formula xml:id="formula_66">x k -x * ∞ ≤ a 3 ε k + a 4 λk -λ * ∞ ρk , λ k+1 -λ * ∞ ≤ a 5 ε k + a 6 λk -λ * ∞ ρk (<label>32</label></formula><formula xml:id="formula_67">)</formula><p>and</p><formula xml:id="formula_68">h(x k ) ∞ ≤ a 5 ε k 1 ρk + 1 + a 6 ρk λk -λ * ∞ ρk . (<label>33</label></formula><formula xml:id="formula_69">)</formula><p>Proof The proof is identical to the ones of Lemmas 4.3 and 5.1 of <ref type="bibr" target="#b11">[12]</ref>, using NS, replacing µ k by 1/ ρk and using the equivalence of norms in R n .</p><p>Lemma 2 and Theorem 4 below complete the penalty boundedness proof for Algorithm A1. These proofs are specific for the updating rule of this algorithm, since the proofs of <ref type="bibr" target="#b11">[12]</ref> do not apply to our case.</p><p>Lemma 2 Assume that the sequence {x k } is generated by Algorithm A1. Then, there exists k 0 ∈ N such that for all k ≥ k 0 , λk = λ k .</p><p>Proof By <ref type="bibr" target="#b30">(31)</ref> there exists k 1 ∈ N such that <ref type="bibr" target="#b33">(34)</ref> we obtain that</p><formula xml:id="formula_70">λ k+1 -λ * ∞ ≤ a 1 ε k + a 2 x k -x * ∞ for all k ≥ k 1 . (<label>34</label></formula><formula xml:id="formula_71">) Define = 1 2 min i {[λ * ] i -λmin , λmax -[λ * ] i } &gt; 0. Since x k -x * ∞ → 0 and ε k → 0, by</formula><formula xml:id="formula_72">λ k+1 -λ * ∞ ≤</formula><p>for k large enough.</p><p>By ( <ref type="formula" target="#formula_62">29</ref>), <ref type="bibr" target="#b29">(30)</ref> and the definition of we obtain the desired result.</p><p>In the following theorem we prove that, if a suitable adaptive choice of the convergence criterion of the subproblems is used, Lagrange multipliers are bounded in Algorithm A1.</p><p>Theorem 4 Assume that the sequence {x k } is generated by Algorithm A1 and that ε k is such that</p><formula xml:id="formula_73">ε k = min{ε k , h(x k ) ∞ } (35)</formula><p>where {ε k } is a decreasing sequence that tends to zero. Then, the sequence of penalty parameters {ρ k } is bounded.</p><p>Proof Let k 0 be as in Lemma 2. Then, for all k ≥ k 0 , we have that λk = λ k .</p><p>Assume that ρk → ∞. By ( <ref type="formula" target="#formula_68">33</ref>) and (35) there exists k 1 ≥ k 0 such that a 5 / ρk &lt; 1 and</p><formula xml:id="formula_74">h(x k ) ∞ ≤ 1 + a 6 ρk 1 1 -a 5 ρk λ k -λ * ∞ ρk (36) for all k ≥ k 1 . Since λ k = λ k-1 + ρk-1 h(x k-1 ) we get h(x k-1 ) ∞ = λ k -λ k-1 ∞ ρk-1 ≥ λ k-1 -λ * ∞ ρk-1 - λ k -λ * ∞ ρk-1 .</formula><p>Then, by ( <ref type="formula" target="#formula_66">32</ref>) and ( <ref type="formula">35</ref>), if k is large enough we have that:</p><formula xml:id="formula_75">λ k -λ * ∞ ≤ a 5 ε k-1 + a 6 λ k-1 -λ * ∞ ρk-1 ≤ a 5 h(x k-1 ) ∞ + a 6 h(x k-1 ) ∞ + λ k -λ * ∞ ρk-1 .</formula><p>Therefore, if k is large enough (so that a 6 / ρk-1 &lt; 1) we get:</p><formula xml:id="formula_76">λ k -λ * ∞ ≤ 1 1 a 6 -1 ρk-1 1 + a 5 a 6 h(x k-1 ) ∞ .<label>(37)</label></formula><p>Combining (37) and (36) we obtain:</p><formula xml:id="formula_77">h(x k ) ∞ ≤ π k ρk h(x k-1 ) ∞ with π k = 1 + a 6 ρk 1 1 -a 5 ρk 1 1 a 6 -1 ρk-1 1 + a 5 a 6 .</formula><p>Since lim k→∞</p><formula xml:id="formula_78">π k ρk = 0, there exists k 2 ≥ k 1 such that π k ρk &lt; τ and ρ k+1 = ρ k for all k ≥ k 2 . This is a contradiction.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remark 3</head><p>The choice of the tolerance ε k in (35) deserves some explanation. In this case ε k is given and tends to zero. Therefore, by (35), the sequence ε k tends to zero as required by Algorithm A1. However, when the rule (35) is adopted, ε k is not given before the resolution of each subproblem. In other words, the inner algorithm used to solve each subproblem stops (returning the approximate solution x k ) only when the condition</p><formula xml:id="formula_79">P [x k -G(x k , λk , ρ k )] -x k ∞ ≤ min{ε k , h(x k ) ∞ } is fulfilled.</formula><p>In the rest of this section we consider the Augmented Lagrangian method with several penalty parameters defined by Algorithm A2. Several definitions and proofs will be adapted from the ones given in <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>. This is the case of the definitions that precede Lemma 3.</p><p>From now on, the sequence {x k } is generated by Algorithm A2. Define</p><formula xml:id="formula_80">I ∞ = {i ∈ {1, . . . , m} | [ρ k ] i → ∞}, I a = {i ∈ {1, . . . , m} | [ρ k ] i is bounded}, ρk = min i∈I ∞ {[ρ k ] i }, η k = i∈I a |h i (x k )|.</formula><p>Given the iterate x k ∈ and i ∈ {1, . . . , n}, we have two possibilities for each component</p><formula xml:id="formula_81">[x k ] i : (i) 0 ≤ [x k ] i ≤ [G(x k , λk , ρ k )] i , or (ii) [G(x k , λk , ρ k )] i &lt; [x k ] i . A variable [x k ] i is said to be dominated at the point x k if [x k ] i satisfies (i). If [x k ] i satisfies (ii) the variable [x k ] i is said to be floating. If the variable [x k ] i is dominated, we have that [P [x k -G(x k , λk , ρ k )] -x k ] i = -[x k ] i .<label>(38)</label></formula><p>On the other hand, if the variable [x k ] i is floating, we have:</p><formula xml:id="formula_82">[P [x k -G(x k , λk , ρ k )] -x k ] i = -[G(x k , λk , ρ k )] i . (<label>39</label></formula><formula xml:id="formula_83">)</formula><p>Let us define:</p><formula xml:id="formula_84">I 1 ={i ∈{1, . . . , n} | [x k ] i is floating for all k large enough and [x * ] i &gt; 0}, (<label>40</label></formula><formula xml:id="formula_85">)</formula><formula xml:id="formula_86">I 2 ={i ∈{1, . . . , n} | [x k ] i is dominated for all k large enough}. (<label>41</label></formula><formula xml:id="formula_87">)</formula><p>The following result corresponds to Lemmas 4.3 and 5.1 of <ref type="bibr" target="#b11">[12]</ref>, adapted for several penalty parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 3 Assume that the sequence {x k } is computed by Algorithm A2. There exists k</head><formula xml:id="formula_88">0 ∈ N and positive constants b 1 , b 2 , ρ, α 1 , α 2 , α 3 , α 4 , α 5 such that, for all k ≥ k 0 , λ k+1 -λ * ∞ ≤ b 1 ε k + b 2 x k -x * ∞ , (<label>42</label></formula><formula xml:id="formula_89">)</formula><formula xml:id="formula_90">and, if [ρ k 0 ] i ≥ ρ for all i ∈ I ∞ , x k -x * ∞ ≤ α 1 ε k + α 2 η k + α 3 i∈I ∞ |[ λk ] i -[λ * ] i | [ρ k ] i (<label>43</label></formula><formula xml:id="formula_91">)</formula><formula xml:id="formula_92">and λ k+1 -λ * ∞ ≤ α 4 ε k + α 5 h(x k ) ∞ . (<label>44</label></formula><formula xml:id="formula_93">)</formula><p>Proof The proof of (42) is identical to the one of <ref type="bibr" target="#b30">(31)</ref>. The arguments used below to prove (46)-(51) may be found in <ref type="bibr" target="#b11">[12]</ref> (proof of Lemma 5.1, pp. 558-561).</p><p>Let k be large enough, so that the sets I 1 , I 2 defined in (40) and ( <ref type="formula" target="#formula_86">41</ref> </p><formula xml:id="formula_94">I(I 4 , I 5 ), (<label>45</label></formula><formula xml:id="formula_95">)</formula><p>where the union on the right-hand side of (45) involves a finite number of sets. Therefore, it is sufficient to prove the lemma for each set K = I(I 4 , I 5 ). In this way, the constants α 1 , . . . , α 5 will depend on K. (Say,</p><formula xml:id="formula_96">α i = α i (K), i = 1, . . . ,<label>5.</label></formula><p>) At the end we can take α i = max{α i (K)} and ( <ref type="formula" target="#formula_90">43</ref>), (44) will be true. So, fixing k ∈ K = I(I 4 , I 5 ) we define:</p><formula xml:id="formula_97">I F = I 1 ∪ I 4 and I D = I 2 ∪ I 5 .</formula><p>Thus, the variables in I F are floating whereas the variables in I D are dominated. Define T(x, λ) = F(x) + ∇h(x)λ. By the definition of G and (4) we have that</p><formula xml:id="formula_98">T(x k , λ k+1 ) = G(x k , λk , ρ k ). Define H l (x, λ) = T x (x, λ) = F (x)+ m i=1 λ i ∇ 2 h i (x)</formula><p>, where the derivatives are taken with respect to x. Using Taylor's formula on each term of the expression T(x k , λ k+1 ) in a neighborhood of (x * , λ * ) and on h(x k ) in a neighborhood of x * (see details in <ref type="bibr" target="#b11">[12]</ref>, p. 559), we obtain:</p><formula xml:id="formula_99">H l (x * , λ * ) h (x * ) T h (x * ) 0 x k -x * λ k+1 -λ * = G(x k , λk , ρ k ) -T(x * , λ * ) h(x k ) - r 1 + r 2 r 3 ,<label>(46)</label></formula><p>where</p><formula xml:id="formula_100">r 1 (x k , x * , λ k+1 ) = 1 0 [H l (x k + s(x * -x k ), λ k+1 ) -H l (x * , λ k+1 )](x k -x * )ds, r 2 (x k , x * , λ k+1 , λ * ) = m j=1 ([λ k+1 ] j -[λ * ] j )∇ 2 h j (x * )(x k -x * ) and [r 3 (x k , x * )] i = 1 0 s 1 0 (x k -x * ) T ∇ 2 h i (x * + ts(x k -x * ))(x k -x * )dtds.</formula><p>By (42), lim k→∞ λ k+1 = λ * . So, by the Lipschitz-continuity of F (x) and ∇ 2 h i (x) in a neighborhood of x * , we get:</p><formula xml:id="formula_101">r 1 (x k , x * , λ k+1 ) 2 ≤ a 7 x k -x * 2 2 , r 2 (x k , x * , λ k+1 , λ * ) 2 ≤ a 8 x k -x * 2 λ -λ * 2 and r 3 (x k , x * ) 2 ≤ a 9 x k -x * 2 2 (47)</formula><p>for positive constants a 7 , a 8 and a 9 .</p><p>By (42) we have that λ k+1 tends to λ * and, so, G(x k , λk , ρ k ) tends to T(x * , λ * ). Therefore, as in Lemma 2.1 of <ref type="bibr" target="#b11">[12]</ref>, we obtain that [x * ] i = 0 when i ∈ I D and [T(x * , λ * )] i = 0 when i ∈ I F . Thus, Eq. ( <ref type="formula" target="#formula_99">46</ref>) may be written as</p><formula xml:id="formula_102">⎛ ⎜ ⎝ H l (x * , λ * ) [I F ,I F ] H l (x * , λ * ) [I F ,I D ] h (x * ) T [I F ] H l (x * , λ * ) [I D ,I F ] H l (x * , λ * ) [I D ,I D ] h (x * ) T [I D ] h (x * ) [I F ] h (x * ) [I D ] 0 ⎞ ⎟ ⎠ ⎛ ⎝ (x k -x * ) [I F ] (x k ) [I D ] λ k+1 -λ * ⎞ ⎠ = ⎛ ⎝ G(x k , λk , ρ k ) [I F ] (G(x k , λk , ρ k ) -T(x * , λ * )) [I D ] h(x k ) ⎞ ⎠ - ⎛ ⎝ (r 1 + r 2 ) [I F ] (r 1 + r 2 ) [I D ] r 3 ⎞ ⎠ .</formula><p>Therefore, after some manipulation, we obtain:</p><formula xml:id="formula_103">H l (x * , λ * ) [I F ,I F ] h (x * ) T [I F ] h (x * ) [I F ] 0 (x k -x * ) [I F ] λ k+1 -λ * = G(x k , λk , ρ k ) [I F ] -H l (x * , λ * ) [I F ,I D ] (x k ) [I D ] h(x k ) -h (x * ) [I D ] (x k ) [I D ] - (r 1 + r 2 ) [I F ] r 3 .<label>(48)</label></formula><p>Since [x * ] i = 0 for all i ∈ I D and, by ( <ref type="formula" target="#formula_6">3</ref>) and (38),</p><formula xml:id="formula_104">(x k ) [I D ] 2 ≤ √ |I D |ε k , we get: x k -x * 2 ≤ (x k -x * ) [I F ] 2 + |I D |ε k . (<label>49</label></formula><formula xml:id="formula_105">) Define now x k = (x k -x * ) [I F ] 2 .</formula><p>Combining (42) and (49) we obtain: From here to the end of the proof, the arguments used are not present in <ref type="bibr" target="#b11">[12]</ref>.</p><formula xml:id="formula_106">λ k+1 -λ * 2 ≤ a 10 ε k + a 11 x k ,<label>(50)</label></formula><p>Since</p><formula xml:id="formula_107">(x k ) [I D ] 2 ≤ √ |I D |ε k and, by (3) and (39), G(x k , λk , ρ k ) [I F ] 2 ≤ √ |I F |ε k we obtain: G(x k , λk , ρ k ) [I F ] -H l (x * , λ * ) [I F ,I D ] (x k ) [I D ] h(x k ) -h (x * ) [I D ] (x k ) [I D ] 2 ≤ a 15 ε k + h(x k ) 2 ,</formula><p>with</p><formula xml:id="formula_108">a 15 = √ n 1 + H l (x * , λ * ) [I F ,I D ] h (x * ) [I D ] 2 .</formula><p>By Assumption NS, the left-hand side matrix of (48) is nonsingular. Let M be the norm of its inverse. Multiplying both sides of the equation by this inverse and taking norms, we obtain:</p><formula xml:id="formula_109">(x k -x * ) [I F ] λ k+1 -λ * 2 ≤ M(a 15 ε k + h(x k ) 2 + a 12 ( x k ) 2 + a 13 x k ε k + a 14 ε k 2 ). (<label>52</label></formula><formula xml:id="formula_110">)</formula><p>By ( <ref type="formula" target="#formula_8">4</ref>) and (42),</p><formula xml:id="formula_111">|h i (x k )| = |[λ k+1 ] i -[ λk ] i | [ρ k ] i ≤ |[λ k+1 ] i -[λ * ] i | + |[ λk ] i -[λ * ] i | [ρ k ] i ≤ b 1 ε k + b 2 x k -x * 2 + |[ λk ] i -[λ * ] i | [ρ k ] i . (<label>53</label></formula><formula xml:id="formula_112">) Now, h(x k ) 2 2 = i∈I ∞ |h i (x k )| 2 + i∈I a |h i (x k )| 2 .</formula><p>So, using that n i=1 a 2 i ≤ ( n i=1 a i ) 2 for a i ≥ 0, i = 1, . . . , n, and the inequality (53) for all i ∈ I ∞ , we obtain:</p><formula xml:id="formula_113">h(x k ) 2 ≤ η k + i∈I ∞ |[ λk ] i -[λ * ] i | [ρ k ] i + |I ∞ | (b 1 ε k + b 2 x k -x * 2 ) ρk . (<label>54</label></formula><formula xml:id="formula_114">)</formula><p>By (49), combining (54) and (52), we get</p><formula xml:id="formula_115">(x k -x * ) [I F ] λ k+1 -λ * 2 ≤ M a 15 ε k + η k + i∈I ∞ |[ λk ] i -[λ * ] i | [ρ k ] i + a 16 ε k ρk + b 2 |I ∞ | x k ρk + a 12 ( x k ) 2 + a 13 x k ε k + a 14 ε k 2 , (<label>55</label></formula><formula xml:id="formula_116">)</formula><p>where</p><formula xml:id="formula_117">a 16 = |I ∞ |(b 1 + b 2 √ |I D |). Now, if k is large enough, ε k ≤ min 1, 1 4Ma 13 (<label>56</label></formula><formula xml:id="formula_118">)</formula><p>and</p><formula xml:id="formula_119">x k ≤ 1 4Ma 12 . (<label>57</label></formula><formula xml:id="formula_120">)</formula><p>By ( <ref type="formula" target="#formula_115">55</ref>) and (56), we have that</p><formula xml:id="formula_121">x k = (x k -x * ) [I F ] 2 ≤ M a 15 ε k + η k + i∈I ∞ |[ λk ] i -[λ * ] i | [ρ k ] i + a 16 ε k ρk + b 2 |I ∞ | x k ρk + a 12 ( x k ) 2 + x k 4M + a 14 ε k . (58)</formula><p>Then, by ( <ref type="formula" target="#formula_119">57</ref>) and (58),</p><formula xml:id="formula_122">x k ≤ M a 15 ε k + η k + i∈I ∞ |[ λk ] i -[λ * ] i | [ρ k ] i + a 16 ε k ρk + b 2 |I ∞ | x k ρk + x k 4M + x k 4M + a 14 ε k . (<label>59</label></formula><formula xml:id="formula_123">) Define ρ = max{1, 4|I ∞ |Mb 2 }. If k is large enough, [ρ k ] i ≥ ρ for all i ∈ I ∞ .</formula><p>By (59) we get:</p><formula xml:id="formula_124">x k ≤ 4M (a 15 + a 16 + a 14 )ε k + η k + i∈I ∞ |[ λk ] i -[λ * ] i | [ρ k ] i . (<label>60</label></formula><formula xml:id="formula_125">)</formula><p>So, by ( <ref type="formula" target="#formula_104">49</ref>) and (60), we obtain:</p><formula xml:id="formula_126">x k -x * ∞ ≤ x k -x * 2 ≤ α 1 ε k + α 2 η k + α 3 i∈I ∞ |[ λk ] i -[λ * ] i | [ρ k ] i ,</formula><p>where α 1 = 4M(a 15 + a 16 + a 14 ) + √ |I D | and α 2 = α 3 = 4M. This proves (43). Let us now prove (44). Using ( <ref type="formula" target="#formula_117">56</ref>) and (57) in the inequality (52) we obtain:</p><formula xml:id="formula_127">x k = (x k -x * ) [I F ] 2 ≤ x k 2 + M(a 17 ε k + h(x k ) 2 ),</formula><p>where a 17 = a 14 + a 15 . Therefore,</p><formula xml:id="formula_128">x k ≤ 2M(a 17 ε k + h(x k ) 2 ). (<label>61</label></formula><formula xml:id="formula_129">)</formula><p>By ( <ref type="formula" target="#formula_104">49</ref>) and ( <ref type="formula" target="#formula_128">61</ref>) we obtain:</p><formula xml:id="formula_130">x k -x * ∞ ≤ x k -x * 2 ≤ α 6 ε k + α 7 h(x k ) ∞ , (<label>62</label></formula><formula xml:id="formula_131">)</formula><p>where <ref type="formula" target="#formula_130">62</ref>) and ( <ref type="formula" target="#formula_88">42</ref>) we obtain the inequality</p><formula xml:id="formula_132">α 6 = 2Ma 17 + √ |I D | and α 7 = 2M √ m. Combining (</formula><formula xml:id="formula_133">λ k+1 -λ * ∞ ≤ α 4 ε k + α 5 h(x k ) ∞ ,</formula><p>where α 4 = b 1 + b 2 α 6 and α 5 = b 2 α 7 . Then, (44) is proved.</p><p>Lemma 4 Assume that the sequence {x k } is computed by Algorithm A2. Then, there exists k 0 ∈ N such that, for all k ≥ k 0 , λk = λ k .</p><p>Proof By (42), the proof is the same than that of Lemma 2.</p><p>Theorem 5 is the final result of this section. We will prove that, under a different adaptive choice of the stopping criterion used in the subproblems, the penalty parameters are bounded for Algorithm A2.</p><p>Theorem 5 Assume that the sequence {x k } is computed by Algorithm A2 and that ε k is such that</p><formula xml:id="formula_134">ε k = min{ε k-1 , h(x k ) ∞ , ε k } (63)</formula><p>where {ε k } is a decreasing sequence that converges to zero. Then the sequence</p><formula xml:id="formula_135">{ρ k } is bounded. Proof Suppose that I ∞ = ∅. Let i 0 ∈ I ∞ . For all i ∈ I a there exists k 1 (i) such that for all k ≥ k 1 (i), [ρ k+1 ] i = [ρ k ] i . If k is large enough we have that, for all i ∈ I a , |h i (x k )| ≤ τ h(x k-1 ) ∞ . Then, η k = i∈I a |h i (x k )| ≤ |I a |τ h(x k-1 ) ∞ . (<label>64</label></formula><formula xml:id="formula_136">) Let k ≥ k = max i∈I a {k 0 , k 1 (i)},</formula><p>where k 0 is obtained as in Lemma 4. By (4),</p><formula xml:id="formula_137">|h i 0 (x k )| = |[λ k+1 ] i 0 -[λ k ] i 0 | [ρ k ] i 0 ≤ |[λ k+1 ] i 0 -[λ * ] i 0 | + |[λ k ] i 0 -[λ * ] i 0 | [ρ k ] i 0 .</formula><p>So, by (42),</p><formula xml:id="formula_138">|h i 0 (x k )| ≤ b 1 ε k + b 2 x k -x * ∞ + |[λ k ] i 0 -[λ * ] i 0 | [ρ k ] i 0 .</formula><p>Thus, by (43),</p><formula xml:id="formula_139">|h i 0 (x k )| ≤ 1 [ρ k ] i 0 (b 1 + b 2 α 1 )ε k + b 2 α 2 η k + b 2 α 3 × i∈I ∞ |[λ k ] i -[λ * ] i | [ρ k ] i + |[λ k ] i 0 -[λ * ] i 0 | . (<label>65</label></formula><formula xml:id="formula_140">)</formula><p>Now, by (44) with λ k replacing λ k+1 , (63) implies that <ref type="formula" target="#formula_135">64</ref>), ( <ref type="formula" target="#formula_139">65</ref>) and (66), we obtain:</p><formula xml:id="formula_141">|[λ k ] i -[λ * ] i | ≤ λ k -λ * ∞ ≤ (α 4 + α 5 ) h(x k-1 ) ∞ i = 1, . . . , m. (<label>66</label></formula><formula xml:id="formula_142">) Since ε k ≤ ε k-1 ≤ h(x k-1 ) ∞ , combining (</formula><formula xml:id="formula_143">|h i 0 (x k )| ≤ π k (i 0 ) [ρ k ] i 0 h(x k-1 ) ∞ ,</formula><p>where</p><formula xml:id="formula_144">π k (i 0 ) = (b 1 + b 2 α 2 ) + b 2 α 2 |I a |τ + b 2 α 3 i∈I ∞ 1 [ρ k ] i + 1 (α 4 + α 5 ). Since π k (i 0 ) [ρ k ] i 0 → 0, there exists k(i 0 ) ≥ k such that |h i 0 (x k )| ≤ τ h(x k-1 ) ∞ for all k ≥ k(i 0 ). Therefore, [ρ k+1 ] i 0 = [ρ k ] i 0 .</formula><p>This is a contradiction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remark 4</head><p>As in the case of Theorem 4, the choice of ε k that satisfies (63) is adaptive. In other words, the precision needed for solving each subproblem depends on the level of infeasibility of the approximate solution. The sequence {ε k } is given and the stopping criterion at each subproblem is</p><formula xml:id="formula_145">P [x k -G(x k , λk , ρ k )] -x k ∞ ≤ min{ε k-1 , h(x k ) ∞ , ε k },</formula><p>where ε k-1 is defined by (63). So, as in Theorem 4, the inner algorithm that solves the subproblem returns x k only when this stopping condition is fulfilled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Numerical experiments</head><p>Our main objective regarding this set of experiments is to decide between Algorithm A1 and Algorithm A2. From the theoretical point of view, Algorithm A1 has the advantage that the set of possible infeasible limit points seems to be smaller than the set of possible infeasible limit points of Algorithm A2. Thus, in principle, Algorithm A2 might converge to infeasible points more often than Algorithm A1. On the other hand, Algorithm A2 tends to increase the penalty parameters less frequently than Algorithm A1, a fact that has a positive influence on the conditioning of the subproblems. However, we are also interested in testing several different options for the implementation of the algorithms. Namely: the best values for λmin and λmax (large or small?), the best value for the tolerance τ that determines the increase of penalty parameters and the strategy for choosing ε k .</p><p>Summing up, the practical algorithms to be tested are defined by:</p><p>1. Strategy for updating penalty parameters Option ONE: Algorithm A1. Option TWO: Algorithm A2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Choice of the safeguarded Lagrange multiplier approximations</head><p>Option BIG: λmax = -λmin = 10 20 .</p><p>Option SMALL: λmax = -λmin = 10 6 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Tolerance for improvement of feasibility</head><p>Option TIGHT: τ = 0.1. Option LOOSE: τ = 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Strategy for convergence criterion of subproblems</head><p>Option FIX :</p><formula xml:id="formula_146">ε k = ε min ≥ 0 for all k. Option INEX: ε k = max{0.1 k , ε min } for all k. Option ADPT: ε k = max{0.1 k , ε min } for all k, ε k = max{ε min , min{ε k , h(x k ) ∞ }}</formula><p>for Algorithm A1 and</p><formula xml:id="formula_147">ε k = max{ε min , min{ε k-1 , ε k , h(x k ) ∞ }}</formula><p>for Algorithm A2.</p><p>Therefore, 24 different methods are defined. Observe that, when ε min = 0, the option ADPT corresponds to the theoretical hypotheses used in Section 5 to prove boundedness of the penalty parameters. Obviously, in practical (floating point) computations we must choose some small ε min &gt; 0.</p><p>The implementation decisions that are common to all the options were the following:</p><p>1. For solving the box-constrained minimization subproblems (6) at Step 2 of both algorithms we used GENCAN <ref type="bibr" target="#b4">[5]</ref> with its default parameters.</p><p>The resulting code (Augmented Lagrangian with GENCAN) will be called ALGENCAN. 2. We computed the Lagrange multipliers estimates using ( <ref type="formula" target="#formula_8">4</ref>) and (29). 3. We set [ρ 1 ] i = 10 for all i = 1, . . . , m and γ = 10 for both algorithms. 4. The algorithms were stopped declaring Convergence when</p><formula xml:id="formula_148">P (x k -F(x k ) -∇h(x k )λ k+1 ) -x k ∞ ≤ ε min and h(x k ) ∞ ≤ ε min .</formula><p>We used ε min = 10 -4 . An execution is stopped declaring Time exceeded if the algorithm runs during 10 minutes without achieving Convergence. Other stopping criteria were inhibited in order to ensure an homogeneous comparison. All experiments were done in a Sun Fire 880 with 8,900 Mhz UltraSPARC III Processors, 32 Gb of RAM memory, running SunOS 5.8. The codes were written in FORTRAN 77 and compiled with Forte Developer 7 Fortran 95 7.0 2002/03/09. We used the optimizing option -O. The codes used in this study are available for download in the TANGO webpage (www.ime.usp.br/∼egbirgin/tango).</p><p>We considered all the nonlinear programming problems with equality constraints and bounds of the CUTE collection <ref type="bibr" target="#b8">[9]</ref>. As a whole, we tried to solve 128 problems.</p><p>Consider a fixed problem and let x (M)</p><p>final , M = 1, . . . , 24, be the final point of method M applied to that problem. In this numerical study we say that x (M)  final is feasible if</p><formula xml:id="formula_149">h x (M) final ∞ ≤ ε min .</formula><p>We define</p><formula xml:id="formula_150">f best = min M f x (M) final | x (M) final is feasible .</formula><p>We say that method M found a solution of the problem if x (M) final is feasible and</p><formula xml:id="formula_151">f x (M) final ≤ f best + 10 -3 |f best | + 10 -6 .</formula><p>Let t (M) , M = 1, . . . , 24, be the computer CPU time that method M used to find a solution. If the method did not find a solution we define t (M) = ∞. We define and we say that method M is one of the fastest methods for the problem when</p><formula xml:id="formula_152">t best = min M {t (M) | method M found a solution},</formula><formula xml:id="formula_153">t (M) ≤ t best + 0.01 t best &lt; ∞.</formula><p>These definitions are the same used in <ref type="bibr" target="#b3">[4]</ref> for comparing different Augmented Lagrangian formulae. We are interested in comparing the 24 variants of Augmented Lagrangian algorithms with respect to Robustness, Feasibility and Efficiency. We say that a particular algorithm is robust for solving some problem if it finds the solution of the problem according to the criterion defined above. We say that it is feasible if it finds a feasible point and we say that it is efficient if it is one of the fastest methods for solving the problem. In Table <ref type="table" target="#tab_2">1</ref> we report, for each combination of parameters, the number of problems in which the corresponding algorithm was robust, feasible and efficient, respectively. More precisely, the symbol p(q) under column R indicates that the algorithm found the solution of q problems, according the criterion above and that its rank with respect to robustness was p.</p><p>The symbol p(q) under column F means that the algorithm found a feasible point in q cases and ranked p with respect to feasibility. The same symbol under column E means that the algorithm was one of the fastest in q cases and ranked p with respect to this criterion. Some preliminary conclusions may be drawn by inspection of Table <ref type="table" target="#tab_2">1</ref>.</p><p>-One of the methods (Algorithm A2 with τ = 0.5, λmax = 10 20 , ε k = ε min ) appears to be the best one, considering feasibility, robustness and efficiency. -Algorithm A2 is better than Algorithm A1. This means that using different penalty parameter and increasing separately each of them is better than increasing "all" the penalty parameters when the improvement of just one constraint is not enough, as Algorithm A1 does. -In general, using a fixed small convergence criterion in the subproblems (ε k = ε min ) is better than using different choices of ε k at least in terms of efficiency. With respect to feasibility and robustness the different choices of ε k are equivalent. -The option LOOSE for increasing the penalty parameter is slightly better than the option TIGHT. The choice of λmax between 10 6 and 10 20 is not very relevant. Preliminary experiments showed that smaller values of λmax are not convenient.</p><p>In order to test the consistency of our algorithms we compared our winner Augmented Lagrangian algorithm with the default version of LANCELOT <ref type="bibr" target="#b11">[12]</ref> and with the same version with true Hessians and without preconditioners. The last one is more adequate since the version of GENCAN that we use does not employ preconditioners at all. It must be observed that GENCAN does not use true Hessians either. Matrix-vector products involving Hessians are replaced by incremental gradient quotients in GENCAN. ALGENCAN was more efficient and robust than the version of LANCELOT without preconditioners. It was also more efficient than the preconditioned LANCELOT but not as robust as this method. The corresponding performance profile <ref type="bibr" target="#b14">[15]</ref> is shown in Fig. <ref type="figure" target="#fig_1">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>Augmented Lagrangian methods are useful tools for solving many practical nonconvex minimization problems with equality constraints and bounds. Its extension to KKT systems and, in consequence, to a wide variety of equilibrium problems (see <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref>) is straightforward. We presented two Augmented Lagrangian algorithms for this purpose. They differ only in the way in which penalty parameters are updated. There seems to be an important difference between these two algorithms with respect to convergence properties. According to our feasibility results the set of possible infeasible limit points of Algorithm A1 seems to be strictly contained in the set of possible infeasible limit points of Algorithm A2. This could indicate that Algorithm A2 converges to infeasible points more frequently than Algorithm A1. However, this property was not confirmed by numerical experiments, which indicate that Algorithm A2 is better. So, it seems that maintaining moderate values of the penalty parameters is the more important feature for explaining the practical performance. However, it is still an open problem if stronger results than Theorem 2 can be obtained for Algorithm A2. The question about convergence to optimal (KKT) points is also relevant. Up to our knowledge, convergence to KKT points of algorithms of this type had been obtained only using assumptions on the linear independence of active constraints. Here we proved that a much better constraint qualification (CPLD) can be used with the same purpose. Again, the problem of finding even weaker constraint qualifications under which convergence to KKT points can be guaranteed remains open.</p><p>The superiority of Algorithm A2 over Algorithm A1 in numerical experiments was not a surprise since every optimization practitioner is conscious of the effect of large penalty parameters on the conditioning of the subproblems and, hence, on the overall performance of Augmented Lagrangian and penalty methods. A little bit more surprising was the (slight) superiority of the algorithms based on accurate resolution of the subproblems over the ones based on inexact resolution. Careful inspection of some specific cases lead us to the following explanation for that behavior. On one hand, GENCAN, the algorithm used to solve the subproblems is an inexact-Newton method whose behavior is many times similar to Newton's method especially when the iterate is close to the solution. This implies that, after satisfying a loose convergence criterion, the amount of effort needed for satisfying a strict convergence criterion is usually small. In these cases it is not worthwhile to interrupt the execution for defining a new subproblem. (One would be "abandoning Newton" precisely in the region where it is more efficient!) On the other hand, the formula used for updating the Lagrange multipliers is a first-order formula motivated by the assumption of exact solution of the subproblems. When the resolution is inexact, other updating formulae ( <ref type="bibr" target="#b23">[24]</ref>, p. 291) might be more efficient (although, of course, more costly).</p><p>The conclusion about the relative efficiency of solving accurately or inaccurately the subproblem may change if one uses different box-constrained solvers. The excellent behavior of the spectral gradient method for very large convex constrained minimization <ref type="bibr">[6-8, 13, 30, 31]</ref> is a strong motivation for pursuing the research on inexact stopping criteria for the subproblems, since in this case quadratic or superlinear convergence is not expected.</p><p>Valuable research has been done in the last 10 years in Augmented Lagrangian methods for solving quadratic problems originated from mechanical applications <ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref>. Adaptive criteria that depend on feasibility of the current point (as in the assumptions of our penalty boundedness theorems) have been successfully used and justified from several different points of view. (Antecedents of these practical strategies can be found in <ref type="bibr" target="#b24">[25]</ref>.) More recently <ref type="bibr" target="#b15">[16]</ref>, Dostál showed that, for some convex quadratic programming problems, an updating strategy based on the increase of the Augmented Lagrangian function have interesting theoretical and practical properties. The extension of his philosophy to the general nonquadratic and nonconvex case must be investigated.</p><p>The recent development of efficient sequential quadratic programming, interior-point and restoration methods for nonlinear programming motivates a different line of Augmented Lagrangian research. The "easy" set does not need to be a box and, in fact, it does not need to be "easy" at all if a suitable algorithm for minimizing on it is available. (The case in which is a general polytope was considered in <ref type="bibr" target="#b10">[11]</ref>.) However, many times the intersection of with the general constraints h(x) = 0 is very complicated. In these cases, using the Augmented Lagrangian approach to deal with the general constraints and a different nonlinear programming algorithm to deal with the subproblems is attractive. Certainly, this has been done in practical applications for many years. The convergence properties of these combinations using weak constraint qualifications is considered in a separate report <ref type="bibr" target="#b0">[1]</ref>.</p><p>Inequality constraints in the original problem can be reduced to equality and box constraints by means of the addition of slack variables and bounds. However, it is interesting to consider directly Augmented Lagrangian methods that deal with inequality constraints without that reformulation. The most popular Augmented Lagrangian function for inequality constraints <ref type="bibr" target="#b31">[32]</ref> can be obtained by reducing the inequality constrained problem to an equality constrained one, with the help of squared slack variables, and applying the equality Augmented Lagrangian to the new problem. After some manipulation, squared slack variables are eliminated and an Augmented Lagrangian without auxiliary variables arises <ref type="bibr" target="#b2">[3]</ref>. Many alternative Augmented Lagrangians with better smoothness properties than the classical one have been introduced. It is possible to obtain feasibility and global convergence results for methods based on many inequality Augmented Lagrangians after removing a considerable number of technical difficulties <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4]</ref>. However, results on the boundedness of the penalty parame-ters are harder to obtain. In particular, strict complementarity at the limit point seems to be necessary for obtaining such results. This assumption is not used at all in the present paper.</p><p>We presented our methods and theory considering KKT systems and not merely minimization problems to stress the applicability of the Augmented Lagrangian strategy to the general KKT case. We performed several experiments for general KKT systems, where the algorithm used for solving the subproblems was the well known PATH solver (see <ref type="bibr" target="#b13">[14]</ref>). We compared the resulting algorithm with the PATH method for solving directly the original problem. On one hand, we confirmed the following warning of <ref type="bibr" target="#b22">[23]</ref>: "Typically, singularity [of the Jacobian] does not cause a lot of problems and the algorithm [PATH] can handle the situation appropriately. However, an excessive number of singularities are cause of concern. A further indication of possible singularities at the solution is the lack of quadratic convergence to the solution". In fact, for some tested problems, the effect of singularity of the Jacobian was more serious in the direct application of PATH to the original problem than in the "Augmented Lagrangian with PATH" algorithm. In many other situations the direct application of PATH to the KKT system was more efficient. Clearly, the Augmented Lagrangian framework intensely exploits the minimization structure of the problem when the source of the KKT system is nonlinear programming and loses this advantage when the KKT system is general. However, much research is necessary in order to evaluate the potentiality of the Augmented Lagrangian for equilibrium problems, variational inequalities and related problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>) are well determined. Let I 3 be the set of the remaining indices (dominated or floating). For all k large enough (say, k ≥ k 0 ), define I 4 (k), I 5 (k) such that (i) I 4 (k) ∩ I 5 (k) = ∅ and I 4 (k) ∪ I 5 (k) = I 3 ; (ii) The indices ∈ I 4 (k) correspond to floating variables; (iii) The indices i ∈ I 5 (k) correspond to dominated variables. Let K = k≥k 0 {(I 4 (k), I 5 (k)}. Clearly, K is a finite set. For all (I 4 , I 5 ) ∈ K, consider the set of indices I(I 4 , I 5 ) such that I 4 (k) = I 4 , I 5 (k) = I 5 for all k ∈ I(I 4 , I 5 ). Obviously, {k ∈ N | k ≥ k 0 } = (I 4 ,I 5 )∈K</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 ALGENCAN versus LANCELOT</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>the execution of the algorithm. (In this case, x k is a KKT point and λ k+1 is the associated vector of Lagrange multipliers.) Compute λk+1 ∈ [ λmin , λmax ] m . (</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>≤ a 12 ( x k ) 2 + a 13 x k ε k + a 14 ε k 12 = a 7 + a 9 + a 8 a 11 , a 13 = 2 √ |I D |(a 7 + a 9 ) + a 8 ( √ |I D |a 11 + a 10 ) and a 14 = |I D |(a 7 + a 9 ) + √ |I D |a 8 a 10 .</figDesc><table><row><cell>with a 10 =</cell><cell>√</cell><cell>m(b 1 +</cell><cell>√</cell><cell cols="2">|I D |b 2 ), a 11 =</cell><cell>√ mb 2 . Moreover, by (47), (49) and (50),</cell></row><row><cell></cell><cell></cell><cell cols="3">(r 1 + r 2 ) [I F ] r 3</cell><cell>2</cell><cell>2</cell><cell>(51)</cell></row><row><cell>with a</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1</head><label>1</label><figDesc>Performance of ALGENCAN</figDesc><table><row><cell>Method</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>We are indebted to the Advanced Database Laboratory (LABD) and Bioinfo at the Institute of Mathematics and Statistics of the University of São Paulo for computer facilities and Sergio Ventura for computational insight. Moreover, we are deeply indebted to two anonymous referees whose insightful comments helped us a lot to improve the quality of the paper.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The authors were supported by PRONEX -CNPq / FAPERJ E-26 / 171.164/2003 -APQ1, FAPESP (Grants 2001/04597-4, 2002/00094-0, 2003/09169-6, 2002/00832-1 and 2005/56773-1) and CNPq.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">On Augmented Lagrangian methods with general lower-level constraints</title>
		<author>
			<persName><forename type="first">R</forename><surname>Andreani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Birgin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Schuverdt</surname></persName>
		</author>
		<idno>MCDO-050303</idno>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>UNICAMP, Brazil</publisher>
		</imprint>
		<respStmt>
			<orgName>Department of Applied Mathematics</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On the relation between Constant Positive linear dependence condition and quasinormality constraint qualification</title>
		<author>
			<persName><forename type="first">R</forename><surname>Andreani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Schuverdt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optim. Theory Appl</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="473" to="485" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Nonlinear programming, 2nd edn</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<pubPlace>Athena Scientific, Belmont</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Numerical comparison of Augmented Lagrangian algorithms for nonconvex problems</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Birgin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Martínez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Optim. Appl</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="31" to="56" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Large-scale active-set box-constrained optimization method with spectral projected gradients</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Birgin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Martínez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Optim. Appl</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="101" to="125" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Nonmonotone spectral projected gradient methods on convex sets</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Birgin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Raydan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1196" to="1211" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Algorithm 813: SPG -Software for convex-constrained optimization</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Birgin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Raydan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Math. Softw</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="340" to="349" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Inexact spectral projected gradient methods on convex sets</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Birgin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Raydan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IMA J. Numer. Anal</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="539" to="559" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">CUTE: constrained and unconstrained testing environment</title>
		<author>
			<persName><forename type="first">I</forename><surname>Bongartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Conn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I M</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ph</forename><forename type="middle">L</forename><surname>Toint</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Math. Softw</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="123" to="160" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">LANCELOT: A Fortran Package for Large scale Nonlinear Optimization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Conn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I M</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ph</forename><forename type="middle">L</forename><surname>Toint</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Convergence properties of an Augmented Lagrangian algorithm for optimization with a combination of general equality and linear constraints</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Conn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I M</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sartenaer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ph</forename><forename type="middle">L</forename><surname>Toint</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="674" to="703" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A globally convergent Augmented Lagrangian algorithm for optimization with general constraints and simple bounds</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Conn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I M</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ph</forename><forename type="middle">L</forename><surname>Toint</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Numer. Anal</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="545" to="572" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Augmented Lagrangian algorithms based on the spectral projected gradient for solving nonlinear programming problems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Diniz-Ehrhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Gomes-Ruggiero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Santos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optim. Theory Appl</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page" from="497" to="517" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The PATH solver: A non-monotone stabilization scheme for mixed complementarity problems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Dirkse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Ferris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optim. Methods Softw</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="123" to="156" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Benchmarking optimization software with performance profiles</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Moré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="201" to="213" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Inexact semimonotonic augmented Lagrangians with optimal feasibility convergence for convex bound and equality constrained quadratic programming</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Dostál</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Numer. Anal</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="96" to="115" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Augmented Lagrangian with adaptive precision control for quadratic programming with simple bounds and equality constraints</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Dostál</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Friedlander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Santos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1120" to="1140" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Duality based domain decomposition with natural coarse space for variational inequalities</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Dostál</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A M</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Santos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Appl. Math</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="page" from="397" to="415" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Regularity properties of a semismooth reformulation of variational inequalities</title>
		<author>
			<persName><forename type="first">F</forename><surname>Facchinei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kanzow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="850" to="869" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A semismooth Newton method for variational inequalities: The case of box constraints</title>
		<author>
			<persName><forename type="first">F</forename><surname>Facchinei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kanzow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Ferris</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J.-S</forename><surname>Pang</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page" from="76" to="90" />
			<date type="published" when="1997">1997</date>
			<pubPlace>Philadelphia</pubPlace>
		</imprint>
	</monogr>
	<note>Complementarity and Variational Problems: State of the Art</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A simply constrained reformulation of KKT systems arising from variational inequalities</title>
		<author>
			<persName><forename type="first">F</forename><surname>Facchinei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kanzow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Optim</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="19" to="37" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Finite-Dimensional Variational Inequalities and Complementary Problems</title>
		<author>
			<persName><forename type="first">F</forename><surname>Facchinei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-S</forename><surname>Pang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Springer Series in Operation Research</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Ferris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Munson</surname></persName>
		</author>
		<ptr target="http://www.gams.com/solvers/solv-ers.htm#PATH" />
		<title level="m">PATH 4.6 User Manual</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Practical Methods of Optimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fletcher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Academic</title>
		<imprint>
			<date type="published" when="1987">1987</date>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Analysis and implementation of a dual algorithm for constrained optimization</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Hager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optim. Theory Appl</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="37" to="71" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Finite-dimensional variational inequality and nonlinear complementary problems: a survey of theory, algorithms and applications</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Harker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-S</forename><surname>Pang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="161" to="220" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Mathematical programs with equilibrium constraints</title>
		<author>
			<persName><forename type="first">Z.-Q</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-S</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ralph</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The Fritz-John necessary optimality conditions in presence of equality and inequality constraints</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">L</forename><surname>Mangasarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fromovitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Anal. Appl</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="37" to="47" />
			<date type="published" when="1967">1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On the constant positive linear dependence condition and its application to SQP methods</title>
		<author>
			<persName><forename type="first">L</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="963" to="981" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">On the Barzilai and Borwein choice of steplength for the gradient method</title>
		<author>
			<persName><forename type="first">M</forename><surname>Raydan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IMA J. Numer. Anal</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="321" to="326" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The Barzilai and Borwein gradient method for the large scale unconstrained minimization problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Raydan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="26" to="33" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The multiplier method of Hestenes and Powell applied to convex programming</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Rockafellar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optim. Theory Appl</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="555" to="562" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Lagrange multipliers and optimality</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Rockafellar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Rev</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="183" to="238" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Sensitivity analysis of parameterized variational inequalities</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="109" to="126" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
