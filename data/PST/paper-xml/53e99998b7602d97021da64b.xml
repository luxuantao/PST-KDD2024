<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Taming Hardware Event Samples for Precise and Versatile Feedback Directed Optimizations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Dehao</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Neil</forename><surname>Vachharajani</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Robert</forename><surname>Hundt</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xinliang</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Stephane</forename><surname>Eranian</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wenguang</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Weimin</forename><surname>Zheng</surname></persName>
						</author>
						<title level="a" type="main">Taming Hardware Event Samples for Precise and Versatile Feedback Directed Optimizations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Sample Profile</term>
					<term>Feedback Directed Optimization</term>
					<term>Performance Counter</term>
					<term>Last Branch Record</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Feedback-directed optimization (FDO) is effective in improving application runtime performance, but has not been widely adopted due to the tedious dual-compilation model, the difficulties in generating representative training data sets, and the high runtime overhead of profile collection. The use of hardware-event sampling overcomes these drawbacks by providing a lightweight approach to collect execution profiles in the production environment, which naturally consumes representative input. Yet, hardware event samples are typically not precise at the instruction or basic-block granularity. These inaccuracies lead to missed performance when compared to instrumentation-based FDO. In this paper, we use Performance Monitoring Unit (PMU) based sampling to collect the instruction frequency profiles. By collecting profiles using multiple events, and applying heuristics to predict the accuracy, we improve the accuracy of the profile. We also show how emerging techniques can be used to further improve the accuracy of the sample-based profile. Additionally, these emerging techniques are used to collect value profiles, as well as to assist a lightweight inter-procedural optimizer. All these profiles are represented in a portable form, thus they can be used across different platforms. We demonstrate that sampling-based FDO can achieve an average of 92% of the performance gains obtained using instrumentation-based exact profiles for both SPEC CINT2000 and CINT2006 benchmarks. The overhead of collection is only 0.93% on average, while compiler-based instrumentation incurs 2.0%-351.5% overhead (and 10x overhead on an industrial web search application).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Many compiler optimizations, such as procedure inlining, instruction scheduling, and register allocation benefit from dynamic information e.g. basic block frequency and branch taken / not-taken ratios. This information allows a compiler to optimize for the frequent case, rather than using probabilistically estimated frequencies, or assuming that all code is equally likely to execute. Profiling is used to provide this feedback to a compiler.</p><p>The traditional approach to profile-guided optimization involves three steps. First, we compile the application with special flags to generate an instrumented version of the program (instrumentation build). Next, we run the instrumented application with training data to collect the profile. Finally, we recompile the application using the profile, which can help the compiler make better optimization decisions (feedback-directed optimization (FDO) build).</p><p>Unfortunately, there are four shortcomings in this ap- proach. First, it requires compiling the application twice.</p><p>For applications with long build times, doubling the build time can significantly degrade programmer productivity. Second, the instrumentation and optimization builds are tightly coupled, this prevents flexible use of the profile data. For example, GCC requires that both builds use the same inline decisions and similar optimization flags to ensure that the control-flow graph (CFG) profiled in the instrumentation build matches the CFG annotated with the profile data in the FDO build. During the FDO build, profiles are used for inline decisions. However, the compiler cannot find a callsite specific profile to annotate the inlined callees. Instead, it can only use the scaled callee profile to annotate the cloned instances. In addition, GCC requires that the source files remain unchanged between two builds. However, observations indicate that many of the code changes between releases are in the cold paths, and this does not affect the behavior of the hot code. The tight coupling between the two builds prevents the previous profiles from being reused.</p><p>Third, collecting profiles requires an appropriate execution environment and representative input. For example, profiling a transaction processing application may require an elaborate database setup and a representative set of queries to exercise the application. Creating such an environment and identifying a set of representative input can be very difficult.</p><p>Fourth, the instrumented profile collection run typically incurs significant overhead (reported to range from 9% to 105% <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, but has been observed to be as much as 10x on an industrial web search application) due to the additional instrumentation code executed. While scaling down inputs may ameliorate the problem, for the profiles to be useful, they must accurately reflect the application's real usage. Crafting an input that is sufficiently scaled down to facilitate fast and easy profiling while retaining high fidelity to the real workload is difficult. The problem is exacerbated by constant application changes potentially making old profiling inputs inapplicable to new versions of the application. Furthermore, the high runtime overhead can alter the critical path of time critical routines, e.g., OS kernel codes, for which getting an instrumentation-based profile is not easily possible in the first place.</p><p>These limitations often lead developers to avoid FDO compilation and forgo its associated performance benefits. Several workarounds exist to make instrumentation-based FDO easier to adopt. For example, binary instrumentation can be used to decouple the instrumentation build and the FDO build. However, since its overhead is significantly higher than compiler instrumentation, binary instrumentation is hard to deploy in actual production environments. Synchronous sampling <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b23">[24]</ref> using instrumentation has been proposed to reduce overhead. However, it needs to insert extra code to switch between the normal and the monitoring states. The inserted code still incurs overhead that is not acceptable for production systems.</p><p>To overcome these limitations, we propose skipping the instrumentation step altogether, and rely instead on sampling events generated by the performance monitoring units (PMU) of modern processors to obtain estimated execution profiles. The sample data does not contain any information about the intermediate representation (IR) used by the compiler. Instead, source position information in the debug section of unstripped binaries is used to correlate the samples to the corresponding basic blocks during the FDO build.</p><p>Using sampling to collect profile, together with using source position information to correlate profile has two key benefits.</p><p>1) Since source position information is used to correlate the profile to the program being compiled, this approach eliminates the tight coupling between the instrumentation and FDO builds. Profiles collected on older versions of a program can be used by developers as long as the behavior of the hot code doesn't change and source file haven't been changed too much, thus eliminating the need for dual compilation in the normal work-flow. This benefit can also apply to binary level instrumentation-based FDO.</p><p>2) The overhead of profile collection is significantly lower since no instrumentation code is inserted, and is typically in the range of 2% or less.</p><p>The low overhead of profiling together with a loose coupling between the profiling build and the FDO build offer compelling usage scenarios. For example, in an Internet company, profile collection can occur by infrequently attaching it to standard binaries running on production systems. The data collected can be stored in a profile database for future FDO builds. This usage model further eliminates any potential discrepancy between profile input data and actual usage patterns observed in the deployed application. Since the profile is collected in the production environment, real-world workloads become natural input for the profile collection runs. Thus, the collected profile has a very high fidelity to actual behavior, and programmers do not need to manually forge any training input.</p><p>Using hardware performance monitoring events to estimate execution profiles is, however, not a panacea. To prevent performance monitoring from slowing down the processor's execution, many tradeoffs are made in the design of modern PMUs; these lead to imprecise sample attribution. Specifically, the instruction address that the PMU associates with an event is often not the true address where the event occurred. To complicate matters further, the distance between the instruction that caused an event and the instruction to which event is attributed is typically variable. Our experiments show that even when using advanced PMU features (e.g., Precise Event-Based Sampling (PEBS) mode on Intel Core 2 processors), events aggregate on particular instructions and are missing on others. While these phenomena may not be problematic for performance debugging, they create significant challenges for using sample profiles in FDO. For example, when profiling values of registers, if a target instruction never receives samples, we are unable to collect the value distribution information for that particular instruction.</p><p>In this paper, we present a sampling-based framework for FDO. In traditional compilers, such as GCC and Open64, FDO uses two types of profiles: edge/basic block frequency profiles and value profiles, which are used to drive many feedback directed optimizations. Our framework focuses on both these profiles, and uses several different sampling techniques to collect them. Though researchers have proposed using PMU-based sample profiles to drive other optimizations such as data prefetching <ref type="bibr" target="#b0">[1]</ref>, these techniques are mainly adopted in dynamic optimizers, which are not the focus of this paper. However, our framework enables these optimizations to be easily adopted in FDO.</p><p>We first introduce using sampling approach to collect edge profiles. We show the artifacts observed in samplebased profiles, and propose two approaches to improve its accuracy. Then, we show how sampling can be used to derive value profiles. Finally we evaluates our approach.</p><p>We summarize the primary contributions of this work below:</p><p>1) We build a framework to collect portable profiles in a lightweight manner. We also build infrastructure in the GCC compiler to effectively use these profiles. 2) We identify hardware effects that negatively influence sample distribution. We propose a heuristic approach, based on sampling multiple hardware events, that mitigates the systematic bias introduced by these hardware effects. 3) We propose algorithms that use branch history information to collect an edge/basic block frequency profile. This information is used for indirect call promotion, and to guide module grouping in a lightweight inter-procedural optimizer. 4) We use precise event based sampling to collect value profiles; and use program slicing to extend the sampling scope to allow for more effective sampling-based value profiling. 5) Finally, we present an evaluation of the efficacy of the proposed approach. We present results from an implementation of sampling-based FDO in the GC-C compiler. Overall, we show that PMU samplingbased FDO, combined with the proposed smoothing heuristics, can achieve 92% of the performance gains obtained using instrumentation-based FDO for SPEC2000 benchmarks. However, sampling-based F-DO, on average, incurs only 0.9% to 1.8% profiling overhead as compared to the 90.5% profiling overhead (2x to 10x on an industrial web search application) incurred by compiler-based instrumentation. The rest of the paper is organized as follows: Section 2 describes hardware event sampling and explains how it can be used to generate the profiles for FDO compilation. Section 3 shows the problems in using general sampling approaches to collect frequency profile, and the heuristics used to improve the accuracy. Section 4 describes the algorithm to use branch information to get the frequency profile, and how branch information can be used to assist a lightweight inter-procedural optimizer. Section 5 describes how to use precise event based sampling to collect value profiles. Section 6 then describes the experimental evaluation of PMU sampling-based FDO. Section 7 describes related work in the area. Finally, Section 8 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">USING PMU-BASED SAMPLING FOR F-DO COMPILATION</head><p>This section describes how sampling works with most modern performance monitoring units and how PMU sampling can be used to guide feedback directed optimizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Hardware Event Sampling</head><p>The performance monitoring unit on a modern micro processor is usually organized as a collection of counters that can be configured to increment when certain hardware events occur. For example, counters can be configured to increment on each clock cycle, each time an instruction retires, for every L2 cache miss, etc. The raw contents of these counters can be dumped at program exit to get summary information about how the program executed. Alternatively, the counters can be used for sampling. In this mode, the PMU is configured to generate an interrupt whenever a counter overflows. When the interrupt triggers, performance monitoring software can record the system state (e.g., the program counter (PC), register contents, etc.). This recorded data forms the sample profile for the application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Using the Profile in a Compiler</head><p>In the following parts of this paper, several methods are used to collect the sample profile. Overall, the output of these methods is a mapping from the binary instruction to its corresponding profile, including frequency profile and value profile. Because this mapping is maintained at instruction level, we refer to it as instruction-level profile. For the sample-based profile to be usable by a compiler, the instruction-level profile must be converted into a profile annotated onto the compiler's intermediate representation (IR). To achieve this, the instruction-level samples are first attributed to the corresponding program source line using the source position information present in the debug information. The execution frequency for each source line is stored in the feedback data file.</p><p>During the FDO build, a compiler reads the frequency profile data to annotate the CFG. Each basic block consists of a number of IR statements. The source line information associated with the individual IR statements is used to determine the list of source lines corresponding to a basic block. The basic block sample count is then determined by the frequency of source lines corresponding to it. Theoretically, the frequency of all source lines corresponding to a basic block should be the same. However, as will be discussed in Section 6.2, source correlation can be skewed. A voting algorithm (e.g., average or max) is designed to assign the most reliable frequency as the basic block sample count.</p><p>For the value profiles, if a source line is found to contain possible value profiling optimization opportunities, compiler reads in the corresponding value profile from the instruction profile, and uses it to rebuild the histogram information of the value and optimize the code.</p><p>By using source line information to record profiles, the coupling between the binary used for profile collection and the FDO build is greatly relaxed. This allows effective re-use of the collected profiles. For example, when there are minor source code changes between profile collection and the FDO build, if the source code change does not affect too much of the frequently executed code, the list of source code changes (change-list descriptions) can be used to update the profile recorded to better match the source code being compiled with FDO. One thing to note, this approach is not limited to the sampling-based FDO. The profiles collected using binary instrumentation tools such as PIN can also be represented in the same format to drive a decoupled FDO build. However, because of the excessive overhead incurred by instrumentation, it's not chosen to collect profiles in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Constructing Edge Profile</head><p>Due to errors and noise in sampling, the frequency profile obtained via sampling may not be consistent. That is to say, for a given basic block, its sample count will not always equal the sum of the sample counts of its successor or predecessor edges. To make the counts consistent and to obtain an edge profile from the basic block profile, we translate the problem into an instance of the minimum cost flow (MCF) problem. In our implementation, we use MCF twice. First, before creating the sample feedback file, an MCF prepass is performed on instruction level profile. During the prepass, a binary level CFG is built for each procedure, the instruction level profile is annotated on the CFG, and MCF is used to refine the profile (detailed in Section 3.3). This refined profile is used to create the profile feedback file. Second, after reading the profile feedback file, compiler uses MCF to translate the basic block profile into an edge profile. One thing to note is, if we use the branch information to derive the frequency profile, as described in Section 4, the profile itself is already accurate enough. Thus the first step is omitted in this approach. The details of formulating the basic block to edge profile conversion problem as an MCF problem can be found in the literature <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b21">[22]</ref>. Here, we describe a few salient details.</p><p>An instance of the MCF problem consists of a graph G = (V, E), where each edge has a capacity and a cost function. The objective is to assign a flow to each edge such that for each edge, (a) the flow is less than the edge's capacity, (b) for a given vertex, the sum of the flows on incoming edges equals the sum of the flows on outgoing edges, and (c) that over the whole graph, the sum of the costs is minimized.</p><p>For profile smoothing, the graph used in MCF is known as the residual graph and it is based on a function's CFG. Each basic block is split into two nodes, the incoming edges to the block connect to the first node in the pair, and the outgoing edges originate at the second node in the pair. The two nodes are connected with a forward and reverse edge. Sending flow through the forward edge corresponds to increasing the basic block count, and sending flow through the reverse edge corresponds to decreasing the basic block count. Since a solution to MCF seeks to minimize cost, the solution can be biased in favor of raising a particular block's weight by assigning its forward edge a low cost. Similarly, one can bias in favor of lowering a block's weight by assigning its reverse edge a low cost. Additionally, the solution can be biased towards altering a specific block's weight by giving its forward and reverse edges a lower cost. We exploit this property of MCF in Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">COLLECTING FREQUENCY PROFILE</head><p>Frequency profile is among the most important profiles for FDO compilation because most of the backend optimizations can benefit from it. In this section, we present a general approach to collect frequency profile. Section 3.1 introduces the general approach. Though this approach can be applied to most of the architectures, it suffers from significant inaccuracy problems, which can be summarized as the anomalies described in Section 3.2. Section 3.3 proposes a heuristic to improve the quality of the instruction profile. Another approach is proposed in Section 4, which utilizes an emerging technique, namely LBR, to collect more accurate frequency profile.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">General Approach</head><p>Sampling a counter that increments each time an instruction retires (e.g., INST_RETIRED on x86 processors) provides a natural way to estimate the instruction profile. Each time the counter overflows, the PC is recorded. In the literature, this approach has been called frequency-based sampling <ref type="bibr" target="#b27">[28]</ref>. An alternative to this approach is timebased sampling <ref type="bibr" target="#b27">[28]</ref>, where processor cycles, rather than instructions, are counted. Unfortunately, time-based sampling biases the sample towards basic blocks that take longer to run than others. Thus in this section, PMU-based sampling is adopted to collect the frequency profile.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Problems Observed</head><p>Sampling is a statistical approach and therefore its results are not exact. However, we observe hardware induced problems that go well beyond plain statistical inaccuracies. For example, consider the loop shown in Figure <ref type="figure" target="#fig_0">1</ref>. The loop is comprised of one basic block that iterates 104166667 times.</p><p>If the loop is sampled using a sampling period of 202001, then one would expect each instruction in the loop's body to receive approximately 104166667 202001 = 515.67 samples. The two columns of numbers labeled Fixed Sample Period in the figure show the actual samples collected on an Intel Core 2 machine. The first column shows the raw count for each instruction and the second shows the count normalized by the expected count (i.e., 1.0 is the correct count, &lt; 1.0 means the instruction was undersampled, and &gt; 1.0 means the instruction was oversampled). We can see from this data that the sample counts vary by a factor of 2-3 from what they ought to be. In this section, we describe these artifacts, and posit causes for these anomalies. Section 3.3 will then introduce an approach to achieve more accurate profiles. We observed similar effects on a variety of architectures from Intel and AMD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Synchronization</head><p>If one selects a period that is synchronized with a piece of the application, a few instructions will receive all of the samples. For example, if a loop contains k dynamic instructions per iteration, and the sampling period is selected as a multiple k, then only one instruction in the loop will be sampled.</p><p>Randomization can avoid synchronization. Instead of using a constant sampling period, the PMU is configured so the number of events between samples is the user provided sampling period plus a randomly chosen delta. After each sample, a new random delta is selected. Since the number of events between each sample is not constant, periodic properties in the program being measured do not skew the sample.</p><p>Additionally, our empirical results show that random sampling improves the uniformity of samples even in the absence of synchronization. In the example in Figure <ref type="figure" target="#fig_0">1</ref>, there are 19 instructions in the loop and the sampling period used was 202001 which is not a multiple of 19. Consequently, the unexpected results should not be due to synchronization. However, when random sampling is used, one obtains the results shown in the two columns labeled Random Sample Period in the figure. With randomization, the samples are more uniformly distributed. The average number of samples per instruction changed because the average sampling period was 204080 (rather than 202001) due to randomization. However, notice that random sampling reduced the standard deviation by a factor of almost 2.5.</p><p>Further experiments reveal that non-random sampling leads to a form of pseudo-synchronization. Although a particular sampling period is requested, due to skid (described in the next section) that is variable, yet systematic, the actual sampling period is ultimately partially synchronized with the loop. While this can be mitigated through careful non-random adjustment of the sampling period for the particular code in the example, random sampling proves more effective when dealing with code with complex control flow and with varying amounts instruction-level parallelism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Sample Skid</head><p>Ideally the PC reported when a counter overflows would be the PC associated with the instruction that triggered the overflow. Unfortunately, the reported PC is often for an instruction that executes many cycles later. This phenomenon is referred to as skid. For example, previous work shows that on an Alpha 21064, the recorded PC corresponds to the instruction that is at the head of the instruction queue 6cycles after the one that triggered the overflow <ref type="bibr" target="#b11">[12]</ref>. On an Intel Core 2 machine, we observed a similar phenomenon. The reported PC corresponds to the instruction that is at the head of the instruction queue some number of cycles (often approximately 30-cycles) after the one that overflows the counter.</p><p>When sampling the CPU_CLK_UNHALTED event, which is distributed evenly among every cycle, the skid merely shifts the profile by a certain amount of cycles. The sample count attributed to each instruction is still proportional to  the total amount of cycles it consumes. As a result, this phenomenon does not affect the precision of the collected profile <ref type="bibr" target="#b2">[3]</ref>. However, for INST_RETIRED event sampling, the effects of skid are important. Figure <ref type="figure" target="#fig_1">2</ref> shows how this effect interacts with a long latency instruction. Because long latency instructions sit at the head of the instruction queue for long periods of time, they are sampled disproportionately more than other instructions. Consequently, instructions that trigger long stalls such as cache or TLB misses will have abnormally higher sample counts compared to other instructions in the same basic block. We refer to this as the aggregation effect. These additional samples should have been attributed to instructions after the stalled instruction, however since they accumulate on the stalled instruction, instructions in the shadow of the stalled instruction frequently have unusually low sample counts. We refer to this as the shadow effect. Previous work suggests accounting for this phenomenon by approximating the amount of time that an instruction spends at the head of the instruction queue <ref type="bibr" target="#b2">[3]</ref>. Unfortunately, estimating this quantity on a modern out-oforder, superscalar processor with a deep cache hierarchy is difficult. In the next section, we show how measuring other performance counters can be used to help correct for this bias.</p><p>Modern Intel x86 processors provide precise event based sampling (PEBS) which guarantees that the address reported for a counter overflow corresponds to a dynamic instruction that caused the counter to increment. Provided sufficient delay between two back-to-back events, the address reported corresponds to the instruction immediately after the one that overflowed the counter <ref type="bibr" target="#b10">[11]</ref>. Unfortunately, when measuring instruction retirement, as the two columns labeled PEBS in Figure <ref type="figure" target="#fig_0">1</ref> show, sampling with PEBS actually yields lower accuracy than sampling without PEBS. This occurs due to bursts of instruction retirement events near the counter overflow. These instructions will not be sampled, once again leading to asymmetric sampling. Since PEBS does not support randomized sampling periods, non-PEBS sampling with randomized sampling periods appears to be a more promising approach.</p><p>AMD processors, on the other hand, provide instructionbased sampling (IBS) which is similar to the ProfileMe approach <ref type="bibr" target="#b11">[12]</ref>. Unfortunately, this facility only allows sam-pling instructions fetched (which include instructions on mispredicted paths) or ?ops retired (which are at a finer granularity than ISA instructions). Since the number of ?ops per instruction is unknown, using IBS also proves problematic <ref type="bibr" target="#b12">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Multi-Instruction Retirement</head><p>On most modern superscalar processors, more than one instruction can retire in a given cycle. For example, on Intel's Core 2 processor, up to four instructions can retire each cycle. Unfortunately, the interrupt signaling the overflow of a performance counter happens immediately before or after a group of committed instructions, and the performance monitoring software records only one PC associated with the group. Consequently, if a set of instructions always retire together, only one instruction in the group will have samples attributed to it, and these samples will be the aggregation of all the samples for the instructions it retired with. For example, in Figure <ref type="figure" target="#fig_0">1</ref>, observe that the cmp instruction receives no samples. While the precise cause cannot be known, it is likely because it commits with the instruction immediately following it (due to fused compare and branch in the processor backend). Further, since the other instructions are data-dependent, the instruction with address 0x30 will execute approximately 30-cycles later, and the data shows that it has accumulated additional samples. We find similar effects on other x86 architectures such as AMD.</p><p>Fortunately, as Figure <ref type="figure" target="#fig_0">1</ref> shows, this aggregation is frequently contained within a single basic block due to the serialization caused by branches. Consequently, while the sample counts for individual instructions may show significant variation due to this effect, the basic block profiles derived by averaging these samples across each block's instructions exhibit significantly less variability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Improving Profile Precision</head><p>From the previous section, it may seem that profiles derived from PMU sampling will be fraught with inaccuracies. However, as Levin et al. show <ref type="bibr" target="#b16">[17]</ref>, MCF is an effective algorithm to derive completely consistent basic block and edge profiles from potentially inaccurate basic block profiles. However, as they also demonstrate, the quality of the derived profiles heavily depend on the specific cost functions used in MCF. In general, if the sample counts for a particular basic block are accurate, the corresponding edges in the residual graph used during MCF should be assigned a high cost. Conversely, if the sample count is inaccurate, depending on whether the sample count is too high or too low, the corresponding forward or reverse edge in the residual graph should have a lower cost. Based on the observation that basic blocks are often missed during profiling (and therefore have a profile that is too small), prior work uses a fixed cost for all edges, with forward edges having a significantly lower cost than reverse edges. This section details an alternate approach for assigning edge costs. By sampling multiple performance counters, one can compute a confidence in the accuracy of the profile for a basic block, and estimate if the sample count is too high or too low. As our results indicate, adjusting the cost functions used in MCF according to these predictions significantly improves the quality of the derived profiles.</p><p>In our approach, we use heuristics to predict the confidence level of the instruction retired profile for a specific basic block. High confidence means that the basic block sample count is predicted to be close to the real execution count. Basic blocks with low confidence are further divided into two categories, blocks where the sample count is predicted to be larger(smaller) than the true execution count. The basic block classification information is used by the edge cost functions in the MCF algorithm to help make better smoothing decisions.</p><p>As was described earlier, there are two principal biasing effects in the INST RETIRED based profile: the aggregation effect and the shadow effect. Recall that the aggregation effect leads to larger sample counts, and the shadow effect leads to smaller sample counts. However, both these effects usually coexist for a single basic block. Consequently, the goal of the heuristic is to determine which effect, if any, is dominant for a particular basic block.</p><p>Recall that aggregation occurs for long-latency instructions. For a fixed skid, D, a unit-latency instruction will be sampled if the instruction that retired D cycles earlier overflowed the performance counter. However, since an instruction with latency L remains at the head of the instruction window between times t and t + L -1, it will be sampled if the counter overflowed anywhere between D and max(D -L -1, 1) cycles before the instruction issued. Consequently, an instruction's chance of getting sampled increases proportionally to its latency. To model this aggregation, a compiler must estimate the latency of each instruction. However, it is hard to measure latency since stall events are not attributed to the correct instruction due to skid. However, our observations show that most aggregation is caused by instructions that stall for significant amounts of time (e.g., stalling due to a DTLB miss). Events measuring these long stalls are generally unaffected by skid and therefore are attributed to the instruction that caused the overflow of the performance counter. Consequently, the heuristic to model aggregation is restricted to events that lead to significant stalls. The set of such events is selected once when a compiler is being tuned for a specific architecture.</p><p>For each such event e, the average stall duration (obtained from processor manuals), stall duration e , multiplied by the sample count for the event, count e,i , gives the total number of cycles that a particular instruction i stalled due to event e. Summing over all such stall events for all instructions in a basic block gives us an aggregation factor, A.</p><formula xml:id="formula_0">A = ? e stall duration e ? ( ? i?BB count e,i )</formula><p>The shadow effect can be modeled by comparing the total number of cycles spent in a basic block (as measured by sampling CPU CLK UNHALTED) to the number of instruction retired events attributed to the block. The difference between these two sample counts is the shadow factor, S. Recall, that in the CPU CLK UNHALTED event based profile, sample count should have proper attribution. Consequently, if S is large, two possibilities exist. First, the basic block could legitimately have experienced high CPI. Alternatively, its instruction retirement samples could have been shadowed. In the first case, A should also be large. Consequently if S ? A then it is likely that the block's samples have been shadowed. In our implementation, if S -A is greater than twice the raw basic block count, the block is classified as under-sampled. Conversely, if A &gt; S and A is a significant fraction of the total number of cycles spent in the block, then it is likely that the block has aggregated too many instruction retirement samples <ref type="foot" target="#foot_0">1</ref> . In our implementation, if A &gt; S and A accounts for more than 50% of the cycles spent in the block, it is classified as over-sampled.</p><p>Based on this classification, an MCF prepass is performed on the profile at the instruction level, with adjusted cost function for basic blocks that are predicted to be over-/under-sampled. For over-sampled block, its corresponding forward edge in the residual graph is set as the maximum cost in the CFG, while its reverse edge is set to 0 (and vice-versa for under-sampled basic blocks).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SAMPLING THE LAST BRANCH RECORD</head><p>In recent Intel micro-processors, a series of registers are designated to record the last few branches taken, namely Last Branch Record (LBR). This is an extension of the Branch Trace Buffer (BTB), which exists on almost all modern processors. In the Intel Core 2 processor, these registers record the last 4 taken branches, while in the Intel Core i7 (code named Nehalem), the last 16 taken branches are recorded.</p><p>In PMU-based sampling, these registers can also be recorded in the interrupt handler. To prevent branches inside the interrupt handler from being recorded, the hardware freezes LBR registers whenever overflow is triggered. In this section, we describe how LBR samples can help derive more accurate instruction frequency profile. We also show how this approach can be used to assist a lightweight interprocedural optimizer and indirect call promotion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Using LBR to Collect Edge Profiles</head><p>In our approach, each time an overflow triggers an interrupt, we record all the branches in the LBR buffer. Ideally, each taken branch would be sampled in proportion to its frequency. On Intel Core 2 processors, there is an event called BR_INST_RETIRED taken that can serve this purpose. Unfortunately, on the Intel Nehalem processors, this event is not available. However, there is an alternative event called BR_INST_EXEC taken , which counts in all taken branches including those mis-predicted branches. By subtracting the profile derived from the event BR_MISP_EXEC taken , which takes effect when a nontaken branch is mis-predicted, we can approximate the original branch retired taken event.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Using Edge Profiles to Calculate Instruction Profiles</head><p>Each taken branch recorded by the LBR corresponds to an edge in the control flow graph (CFG) of the program, and consequently an edge profile can be derived from the LBR samples. However, this profile will only contain frequency information for taken branch edges. We use Algorithm 1 to derive the unknown frequency information for fall through edges. We use the same algorithm to calculate the frequency of each basic block, which is then used to derive the instruction frequency profile.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Deriving the basic block frequency from the taken branch frequency</head><p>Require: Basic block are labeled according to their topological order 1. for i = 1 to BB Count do 2. BB i .succs(f all through).F req = BB i .F req</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7.</head><p>for all edge in BB i .succs do 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BB i .succs(f all through).F req -= edge.F req</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9.</head><p>end for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">end for</head><p>In this algorithm, the basic blocks are initially labeled by their topological order. The frequencies of the incoming edges are summed to derive the frequency of the basic block. Then the frequency of the basic block, after subtracting the frequencies of all taken out-going edges, is used to find the frequency of the fall-through edge. This algorithm propagates samples of each basic block along the topological order, and finally derives the frequencies of all basic blocks and edges.</p><p>The proof of correctness of this algorithm is as follows: note that for each basic block, there should be at most one incoming fall-through edge and at most one out-going fall-through edge, which have unknown frequency in the original profile. First, the basic blocks are labeled in the order they appear in the binary. Assume that for BB i , all the incoming edges have known frequency. The frequency of BB i can be easily calculated by summing up frequencies of all its incoming edges. Once the frequency of BB i is known, the frequency of its only out-going fall-through edge can be calculated because the frequencies of all outgoing taken edges can be derived from the LBR profile. So far we can infer that all the incoming edges of BB i+1 should have known frequency because the only possible unknown incoming edge is the fall-through edge from BB i to BB i+1 , for which the frequency has already been calculated. In addition, the frequencies of all incoming edges of the first basic block (entry block) should be known in the LBR data because they're all function calls. As a result, Algorithm 1 gives the frequency of all edges and basic blocks in one pass of the control flow graph. The time complexity can be represented as O(N + E), where N represents the total number of basic blocks, and E is the total number of edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Using the LBR Profile to Directly Collect an Instruction Profile</head><p>In the LBR profile, whenever the counter triggers an overflow, N back-to-back taken branches are recorded. Algorithm 2 can be used to derive an instruction profile directly (without first constructing an edge profile). The idea here is to increment the sample count for instructions between the destination of one taken branch and the source of the subsequent taken branch.</p><p>Algorithm 2 Using back-to-back taken branch pair to derive the instruction profile 1. for all entry in Sample file do 2.</p><p>for i = 1 to T otal record per entry -1 do</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head><p>for all inst between entry.record <ref type="bibr">[i]</ref>.target and entry.record[i + 1].source do</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>inst.count + +</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.</head><p>end for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.</head><p>end for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">end for</head><p>In this algorithm, all consecutive taken branch pairs in the LBR are examined. The frequency of all instructions between the destination of the first branch and the source of the second branch are incremented. In the end, the total count of each instruction represents the frequency of the instruction.</p><p>To prove the correctness of this algorithm, we first label the basic blocks in the binary according to their topological order. We define a path from instruction I i to I j as maximum non-taken path P ij , if and only if I i is the target of a taken branch, and no branch is taken along this path except I j . Since all the branches in P ij are fall-through branches, we can easily describe P ij as I i , I i+1 , . . . , I j . In the LBR profile, all instructions between each back to back taken branch pair can be considered a maximum non-taken path.</p><p>The total execution count of an instruction is equal to the sum of all maximum non-taken paths that spans it. Following the algorithm, the total sample count of an instruction is equal to the total number of sampled backto-back edges that span the instruction. Since each taken branch will have an equal opportunity to trigger the counter overflow, each maximum non-taken path will have an equal probability of being sampled. Thus the sample count of a maximum non-taken path (the instructions between a backto-back branch pair) is proportional to the actual invocation count of that maximum non-taken path. This proves that algorithm 2 can derive the correct instruction profile.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Accuracy of the LBR-based Instruction Profiles</head><p>The LBR profile is also collected using PMU-based sampling, which could potentially suffer from the problems described in Section 3.2. We use random sampling to mitigate the synchronization problem. Current processors can only retire at most 1 branch instruction each cycle, therefore, an LBR-based profile won't have the multiretirement issue. For the sample skid problem, the LBRbased profile is affected much less than the traditional method because of the following reasons:</p><p>1) The skid for LBR sampling is only 10 cycles, which is one third that of the traditional sampling approach. 2) BR_INST_RETIRED taken events are far less frequent than INST_RETIRED events. Also, most often the intervals between two events are greater than the skid itself. 3) Since the LBR contains multiple entries, the sampling naturally occurs in a burst. This produces more accurate profiles. As a result, LBR-based sampling can derive much more accurate profiles than the traditional sampling-based approach. This is further verified by the accuracy evaluations in Section 6.1.</p><p>The approaches described in Section 4.2 and Section 4.3 are two orthogonal techniques to collect instruction profiles. The accuracy of these two approaches is similar. Thus for later evaluations, we'll only use the approach described in Section 4.3 to demonstrate the quality of LBR-based approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Sampling-based LIPO</head><p>When writing a program, programmers usually divide it into several modules. In C/C++, each .c/.cc file is considered to be one module. Generally, the compiler compiles the program module by module, and the linker links the compiled modules to produce an executable file. In traditional inter-procedural optimization (IPO), a compiler reads in all the modules to carry out a whole-program analysis, which is usually extremely expensive and not scalable.</p><p>LIPO <ref type="bibr" target="#b17">[18]</ref> is a technique aimed at using a lightweight approach to perform IPO. The basic idea is to identify modules that have large degree of affinity. When compiling inter-procedurally, instead of compiling the whole program, LIPO still compiles the original modules one by one. During compilation of each module, a compiler only reads in the relevant modules as auxiliary modules to assist in compilation of the main module. This method is lightweight in the sense that the compilation model is the same as the traditional intra-module compilation, and it uses the traditional linker, which does not require significant linking time. In addition, whenever a file is modified, only the relevant modules need to be rebuilt. Unfortunately, this lightweight approach is built on top of heavy-weighted instrumentation. Thus a significant amount of overhead is incurred in collecting the profile.</p><p>The most important task for LIPO is to build the module grouping policy, i.e. identifying auxiliary modules for each compilation module. This is done by instrumenting each call instruction to get the frequency of the call-edge. If function A frequently calls B, and they're in different modules, LIPO adds the module of B as the auxiliary module of A. This auxiliary module relationship is transitive. As a result, modules along a hot call path will all be included to form an auxiliary module set. In our approach, instead of using instrumentation to collect the edge frequency, we use the LBR profile collected in the previous steps to derive the call-edge frequency. Then we apply the same heuristics that LIPO used to derive the module grouping policy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Using LBR-based Sampling to Collect Indirect Call Profiles</head><p>LBR can record the frequency of each taken branch including function calls. We use this information to guide an indirect call promotion optimization. First, the binary is disassembled to find all indirect call instructions. For each indirect call instruction, all possible targets are recorded by reading the LBR entries. By looking up the target address in the symbol table, one can easily find the potential targets of an indirect call. A histogram is constructed to identify the most frequent targets of an indirect call, and these are stored as the indirect call profile.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">SAMPLING-BASED VALUE PROFILING</head><p>Value profile-based optimizations attempt to compute the distributions of the values for some specific computations. If some values dominate the whole distribution, a compiler will generate multiple versions of the code to handle the special values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Value Profiling in GCC</head><p>In GCC, there are 3 different types of value profiles:</p><p>1) Indirect Call Promotion If GCC finds that the indirect call is directing to some functions most of the time, the callsites are cloned, and the expected callees are promoted to direct calls. In this way, these functions have an opportunity to be inlined into the caller. As was mentioned in Section 4.6, by sampling LBR registers, one can collect indirect call profiles. 2) Stringop Optimization If the size of the string operations (e.g. memcpy, memset) is constant most of the time, GCC tries to generate multiple versions of the call according to the frequently occurring values. In this way, later compiler optimizations can choose the most efficient way to expand these stringops. For example, if the size is small most of the time, GCC may use inlined assembly code to reduce the call overhead. 3) Div/Mod Optimizations The divide and mod operations are expensive. If the dividend is frequently found to be some constant, GCC can use shift operations to reduce the complexity of the computation.</p><p>One thing to note is that the current implementation of value profiling in GCC only records the one most frequent value, and may cause the wrong information to be recorded. This is designed to reduce the overhead. One can choose to use more sophisticated algorithms to get more accurate profiles, but this approach could incur significant overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Using PEBS to Collect Value Profiles</head><p>In recent Intel processors, a Precise Event Based Sampling (PEBS) mode is provided. In this mode, when an event triggers an overflow, the system enters a special state; the next time the event occurs, the system captures the current state immediately, and records it in the memory buffer. This buffer is flushed to the disk once it is full or when the program terminates. PEBS guarantees that the state recorded is strictly concurrent with the instruction that triggers the event. In AMD micro-processors, a technique called Instruction Based Sampling (IBS) can perform similar tasks as PEBS sampling.</p><p>In PEBS mode, all values within one sample are strictly correlated to the instruction pointer recorded in it. This is important for value profiling since the values need to be mapped back to the source code through the debug information of the recorded instruction address. For non-PEBSbased sampling, only the instruction pointer is recorded by hardware, and thus other register values might be modified by instructions inside the interrupt handler. Using PEBS, we can record the value profiles for stringop optimization and div/mod optimization.</p><p>During the sample collection phase, the INST_RETIRED event is used to sample the PEBS profile, and thus each instruction should have an equal opportunity to be sampled. We record all register values for each sample. When the collection finishes, the offline analysis tool is used to collect the value profiles. This happens in two steps:</p><p>First, the tool disassembles the binary to find potential target instructions and registers. For the stringop operations, we check if it is a call instruction to a stringop functions. Following the x86 64 calling convention, we record the register that saves the actual parameter to represent the size of the stringop. For div/mod operations, we record the dividend register.</p><p>Next, the tool clusters all samples by the value of the PC register. A histogram is constructed to compute the few most frequent few values for each instruction found in the previous step. The ratios of the most frequent values are recorded as the value profile of the instruction.</p><p>Since the sampling period is controllable, and is usually kept below a threshold, the overhead of recording the system state is negligible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Program Slicing to Extend the Value Profiles</head><p>Unfortunately, in PEBS sampling, some target instructions are not sampled, even though they are in a hot path. This can be explained by the shadowing and multi-retiring effects as discussed in Section 3.2.</p><p>To overcome this problem, we propose the use of program slicing to extend the value profiles beyond the target instruction itself. After looking at the instructions that dominate or post-dominate the target instruction, we can utilize extra samples to assist the target instruction. Since instructions after the target instruction could be the destination of other branches, slicing is only performed in the backward direction. The slicing algorithm traverses backwards from the target instruction until the value of the target register is killed. The samples associated with these instructions are used to derive the value profiles of the target instruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EVALUATION</head><p>To evaluate the sample profile, we need to compare it to a correct profile. As was described in Section 1, instrumentation incurs a large overhead which may affect program behavior. However, when the program has deterministic behavior, one can use instrumentation to derive correct edge/basic block frequency profiles and value profiles. For this section, we chose to use the deterministic SPECCPU benchmarks for evaluation. The sample profile is compared to the instrumented profile, which is deemed correct for all SPECCPU benchmarks.</p><p>We first evaluate the precision of the sample profiles by comparing the overlap measures, and then show how improved source correlation can be used to improve precision. Additionally, we evaluated the effectiveness of samplingbased FDO by comparing the runtime performance of sample-FDO builds with instrumented-FDO builds. Finally we evaluate the overheads of different profiling mechanisms, and discuss the pros and cons of our approach.</p><p>In this section, all binaries were produced using GCC version 4.4.3 targeting x86 64. Our sampling-based FDO framework was also built on top of this compiler. The sample profiles were collected using perfmon2 on an Intel Core2 i7 920 2.67GHz machine with a sampling period of 1 million. Random sampling, with a randomization mask of 0xFFF, was used to improve the quality of the samples. With these parameters, a sample was taken after every 1,000,000 + (rand() &amp; 0xFFF) instructions retired. All runtime performance measurements were performed on the same machine that was used to collect profiles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Precision of the profile</head><p>We used the degree of overlap metric <ref type="bibr" target="#b16">[17]</ref> to evaluate the quality of the profiles independent of the FDO optimizations with which they will be used. The degree of overlap metric compares the similarity of two edge profiles annotated onto a common CFG. The definition is as follows:</p><formula xml:id="formula_1">PW (e, W ) = W (e) ? e ? ?E W (e ? ) overlap (W 1 , W 2 ) = ? e?E min (PW (e, W 1 ) , PW (e, W 2 ))</formula><p>where W is a map from edges to weights, E is the set of edges in the CFG, and PW computes the normalized weight of an edge. If two profiles agree exactly, the overlap is equal to 1 (or 100%), the sum of the normalized edge weights over the CFG. Conversely, if the profile weights differ for some edge, since the minimum of the two is selected the overlap will decrease. Consequently, the overlap can vary between 0% and 100%.</p><p>Figure <ref type="figure" target="#fig_2">3</ref> shows the overlap between the sample profiles and the instrumented profiles for the SPEC CINT2000. The overlap is measured at the binary level, derived by comparing sampled profiles to edge profiles that are derived using Pin <ref type="bibr" target="#b18">[19]</ref>. We evaluate binary level overlap to isolate the PMU sampling precision problem from source correlation problems (see Section 6.2), and show how refinements can improve the precision incrementally. The first bar shows the quality of the raw profiles (converted to an edge profile using static profile heuristics <ref type="bibr" target="#b26">[27]</ref>). On comparing the first and second bars, we see that, on average, the MCF algorithm (as presented in the literature <ref type="bibr" target="#b16">[17]</ref>) improves the overlap by 8.46% compared to static estimation. Comparing the second and third bars, we see that by classifying basic blocks as over-/under-sampled using multiple PMU profiles, precision can be further improved by 7.67%. The fourth bar shows the potential of our refinement approach of classifying blocks as over-/under-sampled using perfect profiles (obtained from Pin) rather than using additional hardware events. Comparing the third and fourth bars shows that our approach performs only 1.21% worse (82.3% vs 83.5%) than using perfect profiles for basic block classification. The LBR-based profile, as shown in the last bar, achieves much better accuracy, achieving an average of 96.95% overlap.</p><p>To estimate the potential for further improvement of the non-LBR based approach, we computed the functionlevel overlap of the sampled profile and the true function profiles obtained using Pin. Function-level overlap is defined identically to edge overlap except that W is a mapping from a procedure to its weight. Since the heuristics used to infer edge profiles from the sample profiles are intra-procedural, the function-level overlap is an upper bound to the edge overlap. The function-level overlap was measured to be 88.03%, thus the smoothed edge profile obtained using our algorithms is within 10% of optimal. The imprecision in the function-level profile can be explained by aggregation/shadow effects crossing procedure boundaries. The overlap when using a more aggressive compiler inline heuristic (which reduces the chances of aggregation/shadowing across procedure boundaries) increases the function-level overlap to 92.37%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Issues with Source Position Information</head><p>In addition to the challenges imposed by issues inherent to hardware-event sampling, there are other challenges that arise due to inaccuracies in the source position information used to correlate samples to the GCC IR. These challenges, along with our enhancements to the GCC source information, are outlined in this section. Fig. <ref type="figure">4</ref>. Edge overlap measures of LBR-based profile at both source and binary level for SPEC CINT2000 benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Insufficient Source Position Information</head><p>One line of source code can embody multiple basic blocks (e.g., consider any use of the ternary ?: operator). In our current implementation, a patch in GCC and the GNU binutils is applied to distinguish different basic blocks that are mapped to the same line of code. If instructions in different basic blocks are mapped to the same source line, the source information of an instruction is represented by a triplet (f ilename, lineno, discriminator). The discriminator is a distinct number used to denote the residing basic block of an instruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Over/Under Sampling Due to Optimization</head><p>Optimizations such as loop unrolling etc., cause some statements to be duplicated in different basic blocks in the optimized binary used for profile collection. Because multiple basic blocks in the binary correspond to one basic block in the GCC IR, the profile normalization strategy will cause the profile for these basic blocks to be too low. Conversely, optimizations like if-conversion promote conditionally executed code to unconditionally executed code. This increases the likelihood that it will be sampled thus causing its profile count to be too high. In our implementation, we have special bookkeeping for optimizations that duplicate code. Additionally, when optimizations move an instruction out of its original basic block, we abandon the profile of that instruction to ensure the correctness of the recorded profiles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3">Quantitative Comparison</head><p>Figure <ref type="figure">4</ref> shows a quantitative comparison between the source level profile and binary level profile. The profiles were all collected using LBR-based sampling. The source level overlap decreased to 84.13%, whereas the same profile shows an overlap of 96.95% at binary level. However, with our enhancements to the source position information, the overlap measure improves to 92.93%, which is only 4.72% worse than the binary level profile.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Effectiveness of the framework</head><p>Figure <ref type="figure">5</ref> shows the speedup obtained by using FDO over a baseline binary compiled without FDO. The baseline and FDO binaries were all compiled using GCC with the -O2 flag. In this figure, the instrumented FDO has incorporated both value profile and LIPO, and thus represents the peak performance that GCC can achieve. On average, using profiles collected on an Intel Core2 i7 processor, sampling-based FDO with our refinements provides an absolute speedup of 14.24%. This speedup is due to a series of components in the framework. Initially, using traditional PMU-based sampling to collect frequency profile, as described in <ref type="bibr" target="#b8">[9]</ref>, approximately 4.35% speedup can be achieved. If we use LBR to collect the profile, the speedup increases to 7.38%. After enabling the lightweight inter-procedural optimizer, the speedup reaches 11.85%. And finally, enabling the value profile-based optimizations boosts the speedup to 14.24%, which is 91.8% of the peak speedup of GCC using instrumentation-based FDO.</p><p>Detailed investigation into several benchmarks revealed that most of the performance gap between sampling-based FDO and instrumentation-based FDO can be attributed to the following major causes:</p><p>1) Source correlation issues. For the 252.eon, the gap between the sample FDO and the instrumented FDO lies in the missing inline information for some frequently invoked call-sites. This Sample FDO is a statistical approach, which means that sample count for each instruction is scaled down proportionally to avoid the overhead. This will sometimes cause problems when the frequency is too low to get any samples. For example, in 254.gap, a callsite is only invoked for around 1, 000 times. Though not very frequent, it is still beneficial to inline it because the is hot, and inlining this callsite can enable other backend optimizations to further optimize the callee. GCC has a heuristic to inline these infrequent but beneficial callsites. However, this heuristic is only effective when the callsite is executed at least once. For the sample FDO, using a sampling period of 1 million, this callsite is too infrequent to get any samples, and thus it is deemed "not executed". As a result, the heuristic fails to inline this callsite, causing performance loss of the 254.gap benchmark. 3) Errors in the profile.</p><p>As shown in Section 6.1, the LBR-based approach can already obtain very accurate profiles, but this approach still has an error ratio of less than 5%. This could cause problems when accurate information is vital for compiler optimizations. Further study of an industrial application shows that loop unrolling is one such optimization. The instrumentation-based profile can derive exact loop trip counts, while the trip counts derived using the sample-based profile are sometimes off by a small amount. As a result, with instrumented FDO, a loop may be fully-unrolled for most frequent situations, while in sampled FDO it may have some "left-over" iterations that degrade the performance.</p><p>Tuning the compiler's unrolling heuristics for the sample-based behavior could potentially ameliorate this problem.</p><p>One thing to note is that the above evaluations are not cross-validated. However, they are good indicators of the effectiveness of our approach because FDO (both instrumented and sample-based) performs best when the input data used for profile collection is also used for performance evaluation. To make the evaluation complete, we cross-validated the performance improvements on SPEC CINT2006 benchmarks. "Train" data sets are used to collect both sampled and instrumented profiles. These profiles are used in the FDO builds and performance is measured using the "Ref" data sets. As a comparison, the non-crossvalidated setup is also performed on SPEC CINT2006 benchmarks, in which "Ref" data sets are used to collect both sampled and instrumented profiles, and the performance is measured using "Ref" data sets. As shown in Figure <ref type="figure">6</ref>, for the non-cross-validated version, samplingbased FDO can achieve 91.9% speedup of instrumentationbased FDO. In the cross-validation, sampling-based FDO can achieve 85.2% speedup of instrumentation-based FDO, which is less than the non-cross-validated version because "Train" data sets run for a much shorter period of time than "ref" data sets; this introduces more statistical errors for less sampled instructions. However, as soon as the program is sampled for enough time, the sampling-based approach can always derive representative profile for FDO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Profiling Overhead</head><p>We also evaluated the overhead incurred by profile collection. As shown in Table <ref type="table" target="#tab_5">1</ref>, on the SPEC benchmark- Fig. <ref type="figure">6</ref>. Cross-validation of the speedup for SPEC CINT2006 benchmarks. The sample profile collected using "Ref" input data can obtain an average speedup of 6.42%, which is 91.9% of the instrumentation-based approach. The sample profile collected using "Train" input data can obtain an average speedup of 4.69%, which is 85.2% of the instrumentation-based approach.</p><p>s, using a sampling rate of 1 million, the overhead of PMU-based sampling never exceeds 1.8% and averages 0.9%. Compiler-based instrumentation incurs an overhead between 2.0% and 351.5%, and dynamic instrumentation tools, such as Pin <ref type="bibr" target="#b18">[19]</ref>, incur an overhead between 14x and 150x. On an industrial web search application, the compiler-based instrumentation suffered a 10x overhead, compared to just over 2% overhead when profiled using hardware PMU sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Discussion</head><p>As was demonstrated in the performance evaluation, sample FDO shows speedup that is competitive with the instrumentation-based approach. However, these two approaches of collecting profiles are not equivalent. First, instrumentation may insert extra code to collect flexible profiles that is hard to archive by the sampling-based approach. For example, path profiling can be collected using instrumentation. Though LBR can also be used to collect a partial path profile, because of the limited branch entries, it cannot collect the full path profile. Second, sampling the PMU can provide some information that instrumentation cannot get. For example, by sampling cache miss events, sample FDO can derive the locality information and perform aggressive locality optimizations. In this paper, we focus on traditional profiles that have been adopted by instrumented FDO. The evaluation is also intentionally biased in favor of instrumented FDO by choosing deterministic benchmarks. We leave the study of profiles that sample FDO can use to out-perform instrumented FDO for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">RELATED WORK</head><p>In a recent paper, Levin, Newman, and Haber <ref type="bibr" target="#b16">[17]</ref> use sampled profiles of the instruction retirement hardware event to construct edge profiles for feedback-directed optimization in IBM's FDPR-Pro, post-link time optimizer. The samples can be directly correlated to the corresponding basic blocks without using source position information, as this is done post-link time. As is done in this paper, the problem of constructing a full edge profile from basic block sample counts is formalized as a Minimum Cost Circulation problem. In this paper, we extend their work by applying sampling to higher level compilation (as opposed to post-link optimization) and show how sampling additional performance counters can improve the quality of sample profiles.</p><p>Others have proposed sampling approaches without relying on performance counters. For example, the Morph system <ref type="bibr" target="#b27">[28]</ref> collects profiles via statistical sampling of the program counter on clock interrupts. Alternatively, Conte et al. proposed sampling the contents of the branch-prediction hardware using kernel-mode instructions to infer an edge profile <ref type="bibr" target="#b9">[10]</ref>. In particular, the tags and target addresses stored in the branch target buffer (BTB) serve to identify an arc in an application, and the branch history stored by the branch predictor can be used to estimate each edge's weight. Both of these works require additional information to be encoded in the binary to correlate instructionlevel samples back to a compiler's IR rather than using source position information present in unstripped binaries. Additionally, neither work investigates the intrinsic bias of the sampling approach nor attempts to correct the collected profiles heuristically.</p><p>Other profiling methods build on ideas from both program instrumentation and statistical sampling. For example, Traub, Schechter, and Smith propose periodically inserting instrumentation code to capture a small and fixed number of the branch's executions <ref type="bibr" target="#b24">[25]</ref>. A post-processing step is used to derive traditional edge profiles from the sampled branch biases collected. Their experiments show that the derived profiles show competitive performance gains when compared with using complete edge profiles to drive a superblock scheduler. Rather than dynamically modifying the binary, others have proposed a similar framework that performs code duplication and uses compiler-inserted counterbased sampling to switch between instrumented and noninstrumented code in a controlled, fine-grained manner <ref type="bibr" target="#b15">[16]</ref>. Finally, stack sampling has been used, without the use of any instrumentation, to implement a low-overhead call profiler <ref type="bibr" target="#b13">[14]</ref>.</p><p>Similarly, there have been proposals that combine instrumentation and hardware performance counters. Ammons, Ball, and Larus proposed instrumenting programs to read hardware performance counters <ref type="bibr" target="#b1">[2]</ref>. By selecting where to reset and sample the counters, the authors are able to extract flow and context sensitive profiles. These profiles are not limited to simple frequency profiles. The authors show, for example, how to collect flow sensitive cache miss profiles from an application.</p><p>Besides the frequency profiling, instrumentation based value profiling has been proven to be useful <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b14">[15]</ref>, and has been adopted in some compilers such as GCC. However, the instrumentation based approach suffers from excessive overhead and potential inaccuracy introduced by replacement policy. Sampling based value profiling is proposed to pursue better efficiency and flexibility <ref type="bibr" target="#b6">[7]</ref>. However, it still incurs an average overhead of around 10%.</p><p>Not surprisingly, performance counter sampling has also been used in the context of just-in-time (JIT) compilation. For example, Schneider, Payer, and Gross sample cache miss performance counters to optimize locality in a garbage collected environment <ref type="bibr" target="#b22">[23]</ref>. Like our work, the addresses collected during sampling have to be mapped back to the source code (in their case, Java bytecode). However, since their optimizations were implemented in a JIT, they simply augmented the information stored during dynamic compilation to perform the mapping.</p><p>Specialized hardware has also been proposed to facilitate PMU-based profiling. ProfileMe was proposed hardware support to allow accurate instruction-level sampling <ref type="bibr" target="#b11">[12]</ref> for Alpha processors. AMD adopts the ProfileMe approach in the Opteron processors. As discussed in Section 3.2, it cannot produce profiles accurate enough for compiler use. Merten et al. also propose specialized hardware support for identifying program hot spots <ref type="bibr" target="#b19">[20]</ref>. Unfortunately, the hardware they propose is not available in today's commercial processors.</p><p>Orthogonal to collecting profiles, recent work has studied the stability and accuracy of hardware performance counters <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b25">[26]</ref>. In that work, the authors measured the total number of instructions retired across a range of benchmarks on various x86 machines running identical binaries. Their results show that subtle changes to the heap layout, the number of context switches and page faults, and differences in the definition of one instruction can lead to substantial variability in even the total number of instructions retired as reported by the performance counters. Unfortunately, the authors do not study the artifacts in sampling the performance counters, and the results on the aggregate data do not explain the anomalous behavior observed in our experiments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The sample counts measured on an Intel Core 2 for a loop consisting of one basic block.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Aggregation Effect due to long latency instructions measured on an Intel Core 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>BB i .F req = 0 3 .</head><label>3</label><figDesc>for all edge in BB i .preds do 4.BB i .F req += edge.F req</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>is because in the current GCC implementation, only filename and lineno information is embeded in each level of the inline stack. The discriminator is only available at the top of the stack, but not at other levels. As a result, it cannot distinguish between two inlined callsites that reside in the same source line. The performance would no doubt improve once the discriminator is better supported in GCC.2) Statistical sampling issues.</figDesc><table><row><cell>70%</cell><cell></cell><cell>non-LBR</cell><cell>LBR</cell><cell></cell><cell>LIPO</cell><cell>VPT</cell><cell cols="2">InstrFDO</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>60%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>50%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>40%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>30%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>20%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>10%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-10%</cell><cell>164</cell><cell>175</cell><cell>176</cell><cell>181</cell><cell>186</cell><cell>197</cell><cell>252</cell><cell>253</cell><cell>254</cell><cell>255</cell><cell>256</cell><cell>300</cell><cell>Mean</cell></row><row><cell cols="14">Fig. 5. Speedup of SPEC CINT2000. SampleFDO achieves an average speedup of 14.24%, which is 91.8% of</cell></row><row><cell cols="4">the speedup of instrumented FDO.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 1</head><label>1</label><figDesc>Overhead of profile collection using different approaches, with sampling rate at 1 million.</figDesc><table><row><cell>Benchmark</cell><cell>Our Approach</cell><cell>GCC -fprofile-generate</cell><cell>PIN</cell></row><row><cell>164.gzip</cell><cell>1.7%</cell><cell>40.1%</cell><cell>51x</cell></row><row><cell>175.vpr</cell><cell>0.9%</cell><cell>15.6%</cell><cell>44x</cell></row><row><cell>176.gcc</cell><cell>1.1%</cell><cell>66.2%</cell><cell>87x</cell></row><row><cell>181.mcf</cell><cell>0.6%</cell><cell>2.0%</cell><cell>14x</cell></row><row><cell>186.crafty</cell><cell>1.8%</cell><cell>103.9%</cell><cell>95x</cell></row><row><cell>197.parser</cell><cell>0.8%</cell><cell>52.2%</cell><cell>62x</cell></row><row><cell>252.eon</cell><cell>1.0%</cell><cell>240.6%</cell><cell>71x</cell></row><row><cell>253.perlbmk</cell><cell>-0.5%</cell><cell>165.6%</cell><cell>128x</cell></row><row><cell>254.gap</cell><cell>1.0%</cell><cell>351.5%</cell><cell>101x</cell></row><row><cell>255.vortex</cell><cell>1.6%</cell><cell>208.8%</cell><cell>150x</cell></row><row><cell>256.bzip2</cell><cell>0.6%</cell><cell>41.3%</cell><cell>45x</cell></row><row><cell>300.twolf</cell><cell>1.4%</cell><cell>50.7%</cell><cell>31x</cell></row><row><cell>Geomean</cell><cell>0.9%</cell><cell>90.5%</cell><cell>62x</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The aggregation factor A may over-estimate the number of cycles spent in a basic block due to stalls if some of the stalls are overlapped. In such cases, our heuristic may assert that a block has aggregated too many samples when in fact it has not. Our experience has shown that this mischaracterization occurs rarely.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="8">CONCLUSION</head><p>We designed and implemented a framework to use hardware event sampling and source position information to drive feedback-directed optimizations. Both frequency profile and value profile are implemented, making samplingbased FDO achieving good overlap with the true execution frequencies and competitive speedups when compared with the instrumentation-based approach. Moreover, samplingbased FDO provides better portability and usability while incurring negligible overhead. Our experiments show that the proposed techniques are feasible for production use on out-of-order platforms.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Neil Vachharajani Neil Vachharajani is a Software for Pure Storage where he is working on next generation high performance storage systems. Previously, he was a compiler engineer at Google investigating application performance for warehouse scale computers. His research interests include I/O performance, compiles, computer architecture, and programming languages focused on concurrency and multi-core architectures. Neil received his Ph.D. from Princeton University where he was an NSF graduate fellow. Neil also holds a BSE in Electrical Engineering and an MA in Computer Science from Princeton University.</p><p>Robert Hundt Robert is a Tech Lead at Google. He is working on GMail and datacenter performance, building fleet-wide indepth analysis tools and infrastructure. He is heavily involved in compiler and research. Robert has a Diplom in comscience the Technical in Munich.</p><p>Xinliang Li David Li leads the compiler optimizer group in Google. He is working on advanced Profile Directed Optimizations and highly scalable cross module optimizations that can be deployed in Google's build environment. He received the B.S and M.S degrees (both in EE) from Wuhan University and University respectively.</p><p>Stephane Eranian Stephane Eranian is a software engineer in the Linux kernel team at Google. For several years now, he has been working on improving the Linux kernel support for hardware-based performance monitoring. He is the author of the perfmon2 subsystem. Nowadays, he is a contributor to the event subsystem. Prior to joining Google, Stephane was at HPLabs where he worked on the port of Linux to the Intel Itanium processors. He is the co-author of the book entitled "IA-64 linux kernel design and implementation". </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Wenguang Chen</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Prefetch injection based on hardware monitoring and object metadata</title>
		<author>
			<persName><forename type="first">Ali-Reza</forename><surname>Adl-Tabatabai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">L</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mauricio</forename><forename type="middle">J</forename><surname>Serrano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sreenivas</forename><surname>Subramoney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN 2004 conference on Programming language design and implementation, PLDI &apos;04</title>
		<meeting>the ACM SIGPLAN 2004 conference on Programming language design and implementation, PLDI &apos;04<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="267" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Exploiting hardware performance counters with flow and context sensitive profiling</title>
		<author>
			<persName><forename type="first">Glenn</forename><surname>Ammons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">R</forename><surname>Larus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI &apos;97: Proceedings of the ACM SIGPLAN 1997 conference on Programming language design and implementation</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="85" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Continuous profiling: Where have all the cycles gone?</title>
		<author>
			<persName><forename type="first">Jennifer</forename><forename type="middle">M</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lance</forename><forename type="middle">M</forename><surname>Berc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monika</forename><forename type="middle">R</forename><surname>Henzinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shun-Tak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">L</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">T</forename><surname>Sites</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><forename type="middle">A</forename><surname>Vandevoorde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">E</forename><surname>Waldspurger</surname></persName>
		</author>
		<author>
			<persName><surname>Weihl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="357" to="390" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A framework for reducing the cost of instrumented code</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barbara</forename><forename type="middle">G</forename><surname>Ryder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN 2001 conference on Programming language design and implementation, PLDI &apos;01</title>
		<meeting>the ACM SIGPLAN 2001 conference on Programming language design and implementation, PLDI &apos;01<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="168" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Optimally profiling and tracing programs</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">R</forename><surname>Larus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Program. Lang. Syst</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1319" to="1360" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Efficient path profiling</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">R</forename><surname>Larus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO 29: Proceedings of the 29th annual ACM/IEEE international symposium on Microarchitecture</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="46" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Efficient and flexible value sampling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Burrows</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Erlingsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S-T</forename><forename type="middle">A</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Vandevoorde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Waldspurger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Weihl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASPLOS-IX: Proceedings of the ninth international conference on Architectural support for programming languages and operating systems</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Value profiling</title>
		<author>
			<persName><forename type="first">Brad</forename><surname>Calder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Feller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Eustace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO 30: Proceedings of the 30th annual ACM/IEEE international symposium on Microarchitecture</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="259" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Taming hardware event samples for fdo compilation</title>
		<author>
			<persName><forename type="first">Dehao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Vachharajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Hundt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shih-Wei</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinodha</forename><surname>Ramasamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenguang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weimin</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CGO &apos;10: Proceedings of the 8th annual IEEE/ACM international symposium on Code generation and optimization</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="42" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Hardware-based profiling: An effective technique for profiledriven optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Burzin</forename><forename type="middle">A</forename><surname>Conte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kishore</forename><forename type="middle">N</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Menezes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stan</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Parallel Processing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="187" to="206" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">System Programming Guide</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
		<respStmt>
			<orgName>Intel Corporation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Profileme: hardware support for instruction-level profiling on out-of-order processors</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">E</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><forename type="middle">A</forename><surname>Waldspurger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">E</forename><surname>Weihl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Chrysos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO 30: Proceedings of the 30th annual ACM/IEEE international symposium on Microarchitecture</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="292" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Instruction-based sampling: A new performance analysis technique for amd family 10h processors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><surname>Drongowski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007-11">November 2007</date>
			<publisher>Advanced Micro Devices, Inc</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Lowoverhead call path profiling of unmodified, optimized code</title>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Froyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Mellor-Crummey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Fowler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICS &apos;05: Proceedings of the 19th annual international conference on Supercomputing</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="81" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Can program profiling support value prediction?</title>
		<author>
			<persName><forename type="first">Freddy</forename><surname>Gabbay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avi</forename><surname>Mendelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th annual ACM/IEEE international symposium on Microarchitecture</title>
		<meeting>the 30th annual ACM/IEEE international symposium on Microarchitecture<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="270" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Profile-based optimization with statistical profiles</title>
		<author>
			<persName><forename type="first">Nick</forename><surname>Gloy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bradley Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">D</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997-04">April 1997</date>
		</imprint>
		<respStmt>
			<orgName>Harvard University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Complementing missing and inaccurate profiling using a minimum cost circulation algorithm</title>
		<author>
			<persName><forename type="first">Roy</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilan</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gadi</forename><surname>Haber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HiPEAC&apos;08: Proceedings of the 3rd international conference on High performance embedded architectures and compilers</title>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="291" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Lightweight feedback-directed cross-module optimization</title>
		<author>
			<persName><forename type="first">David</forename><surname>Xinliang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Raksit</forename><surname>Ashok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Hundt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CGO &apos;10: Proceedings of the 8th annual IEEE/ACM international symposium on Code generation and optimization</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="53" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Pin: building customized program analysis tools with dynamic instrumentation</title>
		<author>
			<persName><forename type="first">Chi-Keung</forename><surname>Luk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Muth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harish</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artur</forename><surname>Klauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoff</forename><surname>Lowney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><forename type="middle">Janapa</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Hazelwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI &apos;05: Proceedings of the 2005 ACM SIGPLAN conference on Programming language design and implementation</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="190" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A hardware-driven profiling scheme for identifying program hot spots to support runtime optimization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">R</forename><surname>Merten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">N</forename><surname>Trick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">C</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Mei</forename><forename type="middle">W</forename><surname>Gyllenhaal</surname></persName>
		</author>
		<author>
			<persName><surname>Hwu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA &apos;99: Proceedings of the 26th annual international symposium on Computer architecture</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="136" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Evaluating the accuracy of java profilers</title>
		<author>
			<persName><forename type="first">Todd</forename><surname>Mytkowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amer</forename><surname>Diwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hauswirth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">F</forename><surname>Sweeney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 ACM SIGPLAN conference on Programming language design and implementation, PLDI &apos;10</title>
		<meeting>the 2010 ACM SIGPLAN conference on Programming language design and implementation, PLDI &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="187" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Feedback-directed optimization in gcc with estimated edge profiles from hardware event sampling</title>
		<author>
			<persName><forename type="first">Vinodha</forename><surname>Ramasamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dehao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Hundt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GCC Developers&apos; Summit</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Online optimizations driven by hardware performance monitoring</title>
		<author>
			<persName><forename type="first">Florian</forename><forename type="middle">T</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Payer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">R</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI &apos;07: Proceedings of the 2007 ACM SIGPLAN conference on Programming language design and implementation</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="373" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Analyzing lock contention in multithreaded applications</title>
		<author>
			<persName><forename type="first">Nathan</forename><forename type="middle">R</forename><surname>Tallent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">M</forename><surname>Mellor-Crummey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allan</forename><surname>Porterfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM SIGPLAN symposium on Principles and practice of parallel programming, PPoPP &apos;10</title>
		<meeting>the 15th ACM SIGPLAN symposium on Principles and practice of parallel programming, PPoPP &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="269" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Ephemeral instrumentation for lightweight program profiling</title>
		<author>
			<persName><forename type="first">Omri</forename><surname>Traub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Schechter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">D</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000-06">June 2000</date>
		</imprint>
		<respStmt>
			<orgName>Harvard University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Can hardware performance counters be trusted</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sally</forename><forename type="middle">A</forename><surname>Weaver</surname></persName>
		</author>
		<author>
			<persName><surname>Mckee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Workload Characterization</title>
		<imprint>
			<date type="published" when="2008-09">September 2008</date>
			<biblScope unit="page" from="141" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Static branch frequency and program profile analysis</title>
		<author>
			<persName><forename type="first">Youfeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">R</forename><surname>Larus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO 27: Proceedings of the 27th annual international symposium on Microarchitecture</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dehao Chen Dehao is a software engineer at Google. He is working on performance of Google applications, developing scalable mechanisms to make feedback directed optimizations useful in the production environment</title>
		<author>
			<persName><forename type="first">Xiaolan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Gloy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bradley Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">D</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">He received the Huazhong Uniof Science and Technology, M.S and Ph</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="15" to="26" />
		</imprint>
		<respStmt>
			<orgName>D in Tsinghua University</orgName>
		</respStmt>
	</monogr>
	<note>System support for automatic profiling and optimization</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
