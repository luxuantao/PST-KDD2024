<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Geomatics</orgName>
								<orgName type="institution">National Cheng Kung University</orgName>
								<address>
									<postCode>701</postCode>
									<settlement>Tainan</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">77438803D44B5B879F5B6F9B76CBCABF</idno>
					<idno type="DOI">10.1109/TGRS.2012.2197682</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cloud Removal From Multitemporal Satellite</head><p>Images Using Information Cloning Chao-Hung Lin, Member, IEEE, Po-Hung Tsai, Kang-Hua Lai, and Jyun-Yuan Chen</p><p>Abstract-A cloud removal approach based on information cloning is introduced. The approach removes cloud-contaminated portions of a satellite image and then reconstructs the information of missing data utilizing temporal correlation of multitemporal images. The basic idea is to clone information from cloud-free patches to their corresponding cloud-contaminated patches under the assumption that land covers change insignificantly over a short period of time. The patch-based information reconstruction is mathematically formulated as a Poisson equation and solved using a global optimization process. Thus, the proposed approach can potentially yield better results in terms of radiometric accuracy and consistency compared with related approaches. Some experimental analyses on sequences of images acquired by the Landsat-7 Enhanced Thematic Mapper Plus sensor are conducted. The experimental results show that the proposed approach can process large clouds in a heterogeneous landscape, which is difficult for cloud removal approaches. In addition, quantitative and qualitative analyses on simulated data with different cloud contamination conditions are conducted using quality index and visual inspection, respectively, to evaluate the performance of the proposed approach.</p><p>Index Terms-Cloud removal, information cloning, Poisson equation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>G LOBALLY, the Enhanced Thematic Mapper Plus (ETM+) land scenes are, on average, about 35% cloud covered, as reported by Ju and Roy <ref type="bibr" target="#b0">[1]</ref>, indicating that cloud covers are generally present in optical satellite images. This phenomenon limits the usage of optical images and increases the difficulty of image analysis. Thus, considerable research efforts have been devoted to the topic of cloud removal to ease the difficulties caused by cloud covers <ref type="bibr" target="#b1">[2]</ref>- <ref type="bibr" target="#b6">[7]</ref>. If multitemporal images are acquired, the cloud-cover problem has a chance to be eased by reconstructing the information of cloudcontaminated pixels under the assumption that the land covers change insignificantly over a short period of time.</p><p>The aim of this study is to remove clouds and reconstruct information of missing data by taking advantage of the temporal correlation of multitemporal images. An information cloning algorithm is introduced to consistently reconstruct the information of cloud-contaminated region using several highsimilarity and cloud-free patches acquired at different times. Instead of reconstructing information pixel by pixel <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, which may have the problem of radiometric inconsistency, we propose a patch-based approach that mathematically formulates the reconstruction problem as a Poisson equation and then solve this equation using a global optimization process. In the optimization, the selected cloud-free patches are globally and consistently cloned in the corresponding cloud-contaminated region. This process potentially results in good cloud removal results in terms of radiometric accuracy and consistency.</p><p>In the past decade, a number of cloud removal approaches have been proposed. These approaches can be classified into three categories: inpainting-based, multispectral-based, and multitemporal-based. In the first category, without the aid of multispectral and multitemporal data, the cloud-contaminated regions are synthesized using image synthesis and inpainting techniques <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b5">[6]</ref>. The information inside the cloudcontaminated region is synthesized by propagating the geometrical flow inside that region. The synthesis approaches can yield a visually plausible result, which is suitable for cloudfree visualization. However, the lack of restoring information of cloud-contaminated pixels makes them unsuitable for further applications. In multispectral-based approaches, multispectral data are utilized in cloud detection and removal <ref type="bibr" target="#b6">[7]</ref>- <ref type="bibr" target="#b10">[11]</ref>. Rakwatin et al. <ref type="bibr" target="#b6">[7]</ref> proposed a reconstruction algorithm to restore missing data of Aqua Moderate Resolution Imaging Spectroradiometer (MODIS) band 6 using histogram matching and least squares fitting. Histogram matching corrects detectorto-detector striping of the functional detectors, and least squares fitting reconstructs the missing parts based on a cubic polynomial derived from the relation between Aqua MODIS bands 6 and 7. Chun et al. <ref type="bibr" target="#b7">[8]</ref> regarded cloud removal as a denoising problem. Based on statistical characteristics of images, an improved homomorphism filtering is applied to filter out low-frequency components that potentially represent clouds. Similarly, Wang et al. <ref type="bibr" target="#b8">[9]</ref> filtered out clouds in the infrared band using wavelet frequency analysis and then reconstructed information of cloud-contaminated regions for the other bands by a B-spline-based surface repairing approach. Zhang et al. <ref type="bibr" target="#b9">[10]</ref> proposed a geostatistical approach to interpolate intensities of cloud-contaminated pixels using kriging or cokriging interpolation techniques. Although the aforementioned methods based on the ideas of denoising and intensity interpolation can restore cloud-contaminated pixels sometimes with very good results, such methods tend to have difficulty with large clouds. Recently, Roy et al. <ref type="bibr" target="#b10">[11]</ref> have proposed to use information observed by MODIS to predict Landsat ETM+ images. In general, fusing information from different sensors is constrained by spectral compatibility and spatial resolution. Although MODIS has comparable spectral bands with ETM+, this sensor has a much coarser spatial resolution.</p><p>Compared with the multispectral-based approaches, the multitemporal-based approaches <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b17">[18]</ref> which rely on both temporal coherence and spatial coherence have a better ability to cope with large clouds. Melgani and Benabdelkader <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref> proposed a contextual prediction process to determine spectrotemporal relationships between the acquired images. The spectrotemporal relationships are inferred from cloud-free areas in the neighborhood of cloud-contaminated regions over the available temporal images. Li et al. <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref> adopted a thresholding-based approach to identify the best cloud-free and nonshadow pixels in a given region. A cloud-free image is then generated by stitching or mosaicking the selected cloudfree pixels. Gabarda and Crist√≥bal <ref type="bibr" target="#b13">[14]</ref> introduced a cloud removal method based on image fusion that involves a 1-D pseudo-Wigner distribution transformation and a pixelwise cloud model. Both features can be interpreted as a denoising method centered on pixel-level measurement. Denoising enables selection of noise-free pixels from input images. Helmer and Ruefenacht <ref type="bibr" target="#b14">[15]</ref> utilized regression tree to detect and predict pixel values underneath clouds and cloud shadows from other image data captured at different times. An improved histogram matching was then adopted to match adjacent scenes with only spectral data and maximum likelihood classification. Similarly, Jiao et al. <ref type="bibr" target="#b15">[16]</ref>, Wang et al. <ref type="bibr" target="#b16">[17]</ref>, and Tseng et al. <ref type="bibr" target="#b17">[18]</ref> corrected the radiometric inconsistency of cloud-contaminated images and their corresponding temporal images using means and standard deviations of pixel intensities first. Wavelet-based fusion method was then used to fuse boundaries of cloudcontaminated regions. While the aforementioned methods <ref type="bibr" target="#b14">[15]</ref>- <ref type="bibr" target="#b17">[18]</ref> can yield good results for homogeneous regions, it should be noted that the approaches based on histogram matching and data fusion tend to have difficulty with heterogeneous landscapes. Based on the shortcomings in the related works, the aim and the main contribution of this study are to reconstruct information of cloud-contaminated regions using patch-based information cloning with global optimization, which can yield better results in terms of radiometric accuracy and consistency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. CLOUD REMOVAL ALGORITHM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overview</head><p>The workflow of the proposed cloud removal method is schematically shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Our method consists of three main processing steps: cloud detection, image quality assessment, and information reconstruction. In the first step, a semiautomatic cloud detection approach is adopted to detect clouds and cloud shadows for the input images. A quality assessment based on structural similarity (SSIM) index <ref type="bibr" target="#b18">[19]</ref> is then applied to sort the input images according to image similarity. In the last step, the proposed information cloning algorithm is performed to fill in the missing data after removing the cloud-contaminated pixels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Cloud and Cloud-Shadow Detection</head><p>Given a cloud-contaminated image, called target image and denoted as I T , and a set of its corresponding images captured at the same position but different times, called reference images and denoted as {I R 1 , . . . , I R n }, the aim is to remove clouds and cloud shadows and to reconstruct the information of missing data in the target image I T using the reference images {I R 1 , . . . , I R n }. In the first step, a semiautomatic approach is adopted to detect clouds and cloud shadows in both the target and reference images. The approach presented by Huang et al. <ref type="bibr" target="#b19">[20]</ref> is applied, and then, a simple user interface is provided to manually refine the detection results. In the automatic detection phase, relying on the physical fact that clouds are bright and cold in the thermal band, a thresholding-based approach is adopted to define the cloud boundaries in the spectraltemperature space. Once the cloud pixels are identified, their shadows are roughly predicted according to the cloud location and the solar illumination direction. The dark and connected components within the neighborhood of the predicted shadows are identified as the shadow components. This approach is simple and can detect most clouds and cloud shadows. To robustly generate a cloud-free and cloud-shadow-free image, a manual refinement is further performed to accurately determine the clouds and cloud shadows. In the proposed system, users are allowed to refine the cloud detection results through an interface with simple selection and erasion operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Image Quality Assessment</head><p>Once the cloud-contaminated pixels in the target and reference images are identified, several cloud-free patches are selected from the reference images {I R 1 , . . . , I R n } to reconstruct the information of cloud-contaminated regions in the target image I T . Taking radiometric accuracy into account, the cloud-free patches are selected based on image similarity. The simplest and most widely used similarity metric is the mean square error (MSE), which is computed by averaging the squared intensity differences of pixels in the target and reference images. The MSE can be simply calculated and has a clear physical meaning. However, this metric does not fully take structure similarity into account. To generate a satisfactory cloud-free image, the SSIM index introduced by Wang et al. <ref type="bibr" target="#b18">[19]</ref> is used to estimate the quality of working regions in the reference images. The SSIM index is briefly described in the following formulas, wherein this similarity measurement has three components, namely, illumination L(I T , I R ), contrast C(I T , I R ), and structure S(I T , I R ):</p><formula xml:id="formula_0">L(I T , I R ) = 2Œº I T Œº I R + C 1 Œº 2 I T + Œº 2 I R + C 1 C(I T , I R ) = 2œÉ I T œÉ I R + C 2 œÉ 2 I T + œÉ 2 I R + C 2 S(I T , I R ) = œÉ I T I R + C 3 œÉ I T œÉ I R + C 3 (1)</formula><p>where Œº I and œÉ I represent the mean intensity and the standard deviation of image I, respectively, and œÉ I T I R represents the covariance coefficient between images I T and I R . The constants C 1 , C 2 , and C 3 are used to avoid instability when the denominators are nearly zero. By combining these three similarity components, the SSIM index is formulated as follows:</p><formula xml:id="formula_1">SSIM (I T , I R )=[L(I T , I R )] Œ± [C(I T , I R )] Œ≤ [S(I T , I R )] Œ≥ (2)</formula><p>where Œ±, Œ≤, and Œ≥ are the weighting factors for the similarity components. Following the parameter setting given in <ref type="bibr" target="#b18">[19]</ref>, the weighting factors are all set to 1.0, and</p><formula xml:id="formula_2">C 3 = C 2 /2.</formula><p>This results in the following simplified form of SSIM index:</p><formula xml:id="formula_3">SSIM (I T , I R ) = (2Œº I T Œº I R +C 1 )(2œÉ I T I R +C 2 ) Œº 2 I T +Œº 2 I R +C 1 œÉ 2 I T +œÉ 2 I R +C 2 . (<label>3</label></formula><formula xml:id="formula_4">)</formula><p>In the experiments, the constants C 1 and C 2 are set to (K 1 L) 2 and (K 2 L) 2 , respectively, where L is the dynamic range of pixels (i.e., 255 for an 8-bit channel) and K 1 = K 2 = 0.01. The SSIM index ranges from 1.0 (the most similar) to -1.0 (the most dissimilar). To accurately estimate image similarity and to select suitable cloning patches, the SSIM index between the target and reference images is calculated for the cloud-free regions only. Moreover, to cope with large clouds in heterogeneous landscape, the information of a cloudcontaminated region is reconstructed using several patches in the reference images instead of using only one patch. In this manner, many reference images may be selected, and many patches may be embedded into the cloud-contaminated regions, which tends to have the problem of radiometric inconsistency. To solve this problem, the cloud amount is considered in the patch selection. For a reference image, if the amount of cloud in a patch is greater than a defined threshold (set to 80% for all experiments), then the patches will not be selected as candidates. For example, in Fig. <ref type="figure" target="#fig_1">2</ref>, the working area (the cloudcontaminated area) is marked by a red circle. For this working area, the SSIM index of the reference image captured on June 29, 2002, is 0.9, and the cloud amount in the working area is greater than the defined threshold. Thus, this patch will not be selected as a candidate. A comparison of the patch selection with (right figure) and without (middle figure) the constraint of cloud amount is shown in Fig. <ref type="figure" target="#fig_2">3</ref>. The number of selected reference images is reduced from six to four with the cloud amount constraint. The number of selected patches is reduced, resulting in better reconstruction quality in terms of radiometric consistency.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Information Reconstruction</head><p>Inspired by the concept of image editing presented by Perez et al. <ref type="bibr" target="#b20">[21]</ref>, the details of selected patches are used to reconstruct the information of corresponding cloud-contaminated regions. Instead of correcting radiance and locally smoothing boundaries of cloud-contaminated regions or reconstructing information pixel by pixel, the problem is mathematically formulated as a Poisson equation and solved using a global optimization process. The idea is shown in Fig. <ref type="figure" target="#fig_3">4</ref>. The cloudcontaminated region in the target image I T is denoted as Œì, and its boundary is denoted as ‚àÇŒì. Let f be an unknown image intensity function defined over the cloud-contaminated region Œì (i.e., the unknown that is to be calculated). Let f * be the image intensity function defined over the target image I T minus the cloud-contaminated region Œì, and let V be a guidance vector field defined over the cloud-contaminated region Œì. The vector field V is defined as the gradient of the selected patches and is used to guide the reconstruction process to optimize the pixel intensities in the cloud-contaminated regions. To find an accurate and optimized reconstruction result (i.e., the solution of the unknown function f ), the problem is formulated as an optimization equation with the boundary condition f</p><formula xml:id="formula_5">| ‚àÇŒì = f * | ‚àÇŒì : min f Œì |‚àáf -V| 2 , with f | ‚àÇŒì = f * | ‚àÇŒì (<label>4</label></formula><formula xml:id="formula_6">)</formula><p>where ‚àá = ((‚àÇ/‚àÇx), (‚àÇ/‚àÇy)) is the gradient operator and can be calculated by the following finite difference method:</p><formula xml:id="formula_7">‚àÇf (x, y) ‚àÇx = f (x + 1, y) -f (x, y) ‚àÇf (x, y) ‚àÇy = f (x, y + 1) -f (x, y). (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>Equation ( <ref type="formula" target="#formula_5">4</ref>) aims to derive result f with a gradient that is as close to the guidance vector field V (i.e., the details of selected patches) as possible. The solution to (4) is the unique solution of the following Poisson equation with Dirichlet boundary conditions:</p><formula xml:id="formula_9">Œîf = div V over Œì, with f | ‚àÇŒì = f * | ‚àÇŒì (<label>6</label></formula><formula xml:id="formula_10">)</formula><p>where Œî = (‚àÇ 2 /‚àÇx 2 ) + (‚àÇ 2 /‚àÇy 2 ) is the Laplacian operator and divV = (‚àÇv 1 /‚àÇx) + (‚àÇv 2 /‚àÇy) is the divergence of the vector field V = (v 1 , v 2 ). Similarly, the second derivatives ‚àÇ 2 /‚àÇx 2 and ‚àÇ 2 /‚àÇy 2 can be calculated using the finite difference method as follows:</p><formula xml:id="formula_11">‚àÇ 2 f (x, y) ‚àÇx 2 = f (x + 1, y) + f (x -1, y) -2f (x, y) ‚àÇ 2 f (x, y) ‚àÇy 2 = f (x, y + 1) + f (x, y -1) -2f (x, y). (<label>7</label></formula><formula xml:id="formula_12">)</formula><p>Equations ( <ref type="formula" target="#formula_5">4</ref>) and ( <ref type="formula" target="#formula_9">6</ref>) are the fundamental formulations of information reconstruction. In these equations, the boundary condition f | ‚àÇŒì = f * | ‚àÇŒì is used to enforce boundary consistency between the scalar functions f and f * . The equation minimization indicates that the gradient of the unknown function f * is close, in L 2 -norm, to the gradient field V of the selected patches. The physical meaning is to interpolate inward while enforcing the spatial variations of the unknown function f * to the guidance field V as close as possible. Therefore, the minimization has a good probability of inconsistently cloning the details of selected patches to the cloud-contaminated regions, thereby resulting in a satisfactory cloud-free image with consistent and accurate radiance.</p><p>Equations ( <ref type="formula" target="#formula_5">4</ref>) and ( <ref type="formula" target="#formula_9">6</ref>) can be discretized by a pixel grid. Let N p be the pixel set of the four connected neighbors of pixel p in the target image I T , and denote p, q as a pixel pair such that pixel q is one of the four connected neighbors of pixel p (i.e., q ‚àà N p ). Let f (p) be the value of image function f at position/pixel p. The task is to compute the pixel intensities in the cloud-contaminated region Œì. The discretization of (4) yields the following discrete optimization equation: where v pq = I R (p) -I R (q), which is the directional gradient (i.e., the -‚Üí pq direction) of the reference image at position p.</p><formula xml:id="formula_13">min f p,q ‚à©Œì =0 (f (p) -f (q) -v pq ) 2 , with f (s) = f * (s) for all s ‚àà ‚àÇŒì (8)</formula><p>According to <ref type="bibr" target="#b7">(8)</ref>, the following equation can be generalized:</p><formula xml:id="formula_14">|N p |f (p)- q‚ààN p ‚à©Œì f (q) = q‚ààN p ‚à©‚àÇŒì f * (q)+ q‚ààN v pq for all p ‚àà Œì (9)</formula><p>where |N p | is the number of neighbors in N p . Equation ( <ref type="formula">9</ref>) is iteratively solved until the unknown function f is converged. As previously mentioned, the patches are selected based on image quality/similarity. Thus, the information of cloud-contaminated region is reconstructed by several different patches in the reference images. To generate a smooth guidance field, the guidance vectors on the patch boundary are calculated by averaging the gradients of neighboring patches as follows:</p><formula xml:id="formula_15">v pq = (P R i (p) -P R i (q)) + P R j (p) -P R j (q) 2<label>(10)</label></formula><p>where P R i and P R j represent the neighboring patches in reference images I R i and I R j . When the cloud-contaminated region Œì contains pixels on the border of the target image (as shown in Fig. <ref type="figure">5</ref>, right), the effect of the reconstruction process will be similar to that of extrapolation. In the implementation, due to the lack of neighbor information on the border pixels, these  pixels are calculated using <ref type="bibr" target="#b10">(11)</ref>, which removes the boundary terms in the right-hand side of ( <ref type="formula">9</ref>)</p><formula xml:id="formula_16">|N p |f p - q‚ààN f q = q‚ààN v pq . (<label>11</label></formula><formula xml:id="formula_17">)</formula><p>The cases of interpolation and extrapolation are shown in Fig. <ref type="figure">6</ref>. The working areas are encircled in red circles. In the top panels of Fig. <ref type="figure">6</ref> (the interpolation case), ( <ref type="formula">9</ref>) is used to reconstruct information. In the bottom panels of Fig. <ref type="figure">6</ref> (the extrapolation case), the border pixels are calculated using <ref type="bibr" target="#b10">(11)</ref>, and the other pixels are calculated using <ref type="bibr" target="#b8">(9)</ref>. If the working area is replaced by a selected patch, a significant discontinuity on the brightness occurs. In contrast, the proposed approach that uses global optimization can potentially yield satisfactory results for either the interpolation case or the extrapolation case. Note that a number of works are proposed for improving or extending the gradient-based information cloning/reconstruction technique to achieve better visualization <ref type="bibr" target="#b21">[22]</ref>- <ref type="bibr" target="#b24">[25]</ref>. However, these approaches are unsuitable to be applied to the cloud removal because of the lack of consideration for radiometric accuracy.   To demonstrate the robustness of our approach, we experimented on images with a large amount of cloud cover. The results are shown in Fig. <ref type="figure" target="#fig_8">10</ref>. The images with 36%, 46%, 53%, 63%, and 70% of cloud covers were tested. With the aid of patch-based reconstruction and global optimization, satisfactory cloud-free results can be obtained even though the amount of cloud cover is large. Note that the generated results in Fig. <ref type="figure" target="#fig_8">10</ref> are misty because some misty patches are selected as reconstruction candidates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EXPERIMENTAL RESULTS</head><p>An experiment of removing simulated cloud-contaminated data and reconstructing the missing data was conducted to quantify the reconstruction accuracy and to compare with the related cloud removal approaches. The experimental procedure was as follows. Select a sequence of images that contains several different landscapes, simulate clouds by partly obscuring a cloud-free image of the sequence, and then compare the reconstructed image with the original cloud-free image. A simulation image containing four simulated cloud-contaminated regions shown in Fig. <ref type="figure" target="#fig_9">11</ref> was tested. The experimental results and statistical analyses are shown in Fig. <ref type="figure" target="#fig_10">12</ref> and<ref type="figure">Table I</ref>, respectively. The patch replacement approach, the radiometric correction with wavelet-based color blending on boundaries suggested by Jiao et al. <ref type="bibr" target="#b15">[16]</ref>, Wang et al. <ref type="bibr" target="#b16">[17]</ref>, and Tseng et al. <ref type="bibr" target="#b17">[18]</ref>, and the proposed approach are evaluated. In <ref type="bibr" target="#b15">[16]</ref>- <ref type="bibr" target="#b17">[18]</ref>, the process of radiometric correction is performed to correct the radiance of the cloud-contaminated image and the corresponding temporal images by the means and standard deviations of image intensities. The wavelet-based color blending/fusion is then performed to smooth the boundaries of cloud-contaminated regions. The results generated by these approaches may have a slight discontinuity at the cloud boundaries even though the smoothing operation is applied (see Fig. <ref type="figure" target="#fig_10">12</ref>). In contrast, we formulate the reconstruction problem as a Poisson equation and solve the equation by an optimization process, yielding a better  result in terms of radiometric consistency. To quantitatively compare the approaches, the standard and commonly used measurements, root-mean-square error (RMSE), peak signalto-noise ratio (PSNR), and SSIM index, are used to evaluate the results shown in Fig. <ref type="figure" target="#fig_10">12</ref>. In this experiment, two reference images were tested for data reconstruction. Reference image B has better similarity/quality than reference image A. From the statistical table, it is apparent that the approaches using reference image B (RI_B) have better reconstruction accuracy than those using reference image A (RI_A). Moreover, our approach generally has better reconstruction accuracy compared with the related approaches. This result is particularly apparent for the case of large cloud in a heterogeneous landscape. For example, compared with the approach of radiometric correction and local color blending (i.e., approach C), our approach has a larger improvement in area 1 that contains urban areas and croplands [the RMSE is improved from 6.99 to 6.28 (11.3%)] than in area 4 that contains mountains [the RMSE is improved from 2.60 to 2.54 (2.3%)]. Note that the reconstruction quality can be greatly improved using our approach when a higher quality reference image is used or more reference images are used. In Fig. <ref type="figure" target="#fig_11">13</ref>, the accuracy assessment for the vegetation growth area (change area) and the mountain area (nonchange area) was conducted. The target image is captured on May 27, 2003, and the images captured between July 3, 1999, and May 11, 2003, are selected as reference images. Using our approach, the reconstruction of change area and nonchange area has average RMSE of 8.75 and 5.51, respectively. This indicates that nonharmonic changes of land cover decrease reconstruction quality. However, if the reference images captured on <ref type="bibr">May 11, 2003, and</ref><ref type="bibr">April 9, 2003</ref>, are used, the reconstruction has RMSE of 7.5 and 7.43, respectively, which are close to the worst case of nonchange-area reconstruction. Therefore, our approach cannot accurately reconstruct information when land covers change significantly over a short period of time. It is a limitation of multitemporal-based approaches. For the case that land covers change nonharmonically, our approach has a chance to efficiently reconstruct information if the images captured in the period of harmonic change of land covers are selected as reference images.</p><p>To demonstrate the advantage of utilizing multitemporal images, we conducted an experiment of information reconstruction using a single reference image and multiple reference images, respectively. The results are shown in Fig. <ref type="figure" target="#fig_12">14</ref> and Table <ref type="table" target="#tab_1">II</ref>. It is apparent that using multiple reference images has better reconstruction accuracy and has comparable visual quality compared with using a single reference image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONCLUSION AND FUTURE WORK</head><p>In this paper, a novel cloud removal algorithm has been introduced. The cloud-contaminated portions of a satellite image are removed, and then the information of missing data is reconstructed using the correlation of multitemporal images. Our approach is based on the patch-based information reconstruction strategy with the global optimization process. The major improvement is that our approach makes better use of appropriate temporal information to reconstruct the information. Thus, our approach can potentially yield better results in terms of radiometric accuracy and consistency, compared with the related approaches. Experimental analyses on sequences of images acquired by the Landsat-7 ETM+ sensor demonstrate the feasibility of our approach to process clouds in a heterogeneous landscape, and demonstrate the robustness of our approach to process images with a large amount of cloud. Moreover, the quantitative and qualitative analyses on the simulated data with different cloud contamination conditions show a clear superiority of our approach over the related approaches. In the future, an automatic cloud (including thin cloud) detection approach and a reconstruction approach for thin cloud are planned to be developed. Dr. Lin is a member of the Association for Computing Machinery. He served as a member of the international program committees of Pacific Graphics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Workflow of the proposed cloud removal method which consists of three main processing steps: cloud detection, image quality assessment, and information reconstruction.</figDesc><graphic coords="2,303.24,69.98,244.20,159.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Reference images sorted by SSIM index and cloud amount. The images captured on June 29, 2002, November 14, 2000, and May 28, 2002, are filtered out because of the constraint of cloud amount.</figDesc><graphic coords="3,307.95,70.50,246.12,136.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Cloning patch selection. (Left) Target image. (Middle) There are six reference images selected by SSIM index. Each image is represented by a color. (Right) There are four reference images selected by SSIM index with the constraint of cloud amount.</figDesc><graphic coords="3,307.95,254.57,246.12,116.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Illustration of information reconstruction. The information of cloudcontaminated region Œì in target image I T is reconstructed by the selected patch in the reference image I R with the aid of the gradient field V of the selected patch.</figDesc><graphic coords="3,317.95,427.61,225.96,84.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .Fig. 6 .</head><label>56</label><figDesc>Fig. 5. Illustration of two interpolation cases. (Left) Interpolation. (Right) Extrapolation.</figDesc><graphic coords="4,311.75,186.80,228.12,233.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .Fig. 8 .</head><label>78</label><figDesc>Fig. 7. Cloud removal result. (Top) (Marked by red) Target and reference images and the quality assessment of the selected patches. The reference images are sorted by SSIM index. The target image is captured near eastern Taiwan on August 8, 1999. (Bottom) (a) Result of patch replacement, (b) our result, and (c) the enhancement of (b).</figDesc><graphic coords="5,107.45,70.54,384.12,275.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Cloud removal results. (a) Target image visualized using bands 2-4. (b) Result generated by our approach. (c) Quality of the embedded patches.</figDesc><graphic coords="6,102.23,69.98,384.12,447.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>AND DISCUSSION Landsat-7 ETM+ images with different types of landscapes were used to test the feasibility of the proposed approach. The images captured near the east of Taiwan, Los Angeles, and Taipei in August 1999, July 2000, and November 2000 were used as inputs. The cloud removal results are shown in Figs. 7-9. In Figs. 7 and 8, the visible bands [band 1 (0.45-0.52 Œºm), band 2 (0.52-0.60 Œºm), and band 3 (0.63-0.69 Œºm)] of ETM+ images are used, and there are seven images selected as reference images. The cloud-free patches in the reference images with the highest rank are utilized to reconstruct the information of cloud-contaminated regions. The path quality measured by the SSIM index is normalized, and the values range from 0 (the worst quality) to 100 (the best quality). The results of patch replacement are shown in Figs. 7(a) and 8(a),</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. (Top) Test data. The percentages of cloud amount in the test data are 36%, 46%, 53%, 63%, and 70%, respectively. (Bottom) Cloud removal results.</figDesc><graphic coords="7,97.94,268.25,402.84,115.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Simulation data. (Left) Target image containing four simulated cloud-contaminated regions: Area 1 (urban area and cropland), area 2 (large cropland), area 3 (small cropland), and area 4 (small mountain area). (Middle) Reference image with low dynamic range. (Right) Reference image with high dynamic range. The target image is captured near Chiayi on October 26, 2002, and the reference images are captured on January 14, 2003, and March 3, 2003. and our results are shown in Figs. 7(b) and 8(b). The cloud-free results are enhanced by a linear enhancement transformation to provide a clear visual comparison. The enhanced results are shown in Figs. 7(c) and 8(c). In Fig. 9, bands 1-3, band 4 (0.78-0.90 Œºm), band 5 (1.55-1.75 Œºm), and band 7 (2.09-2.35 Œºm) of ETM+ images are used. The cloud removal result for each band and the pseudocolor image formed by bands 2-4 are shown in this figure. These results on the multitemporal images demonstrate the feasibility of our approach.To demonstrate the robustness of our approach, we experimented on images with a large amount of cloud cover. The results are shown in Fig.10. The images with 36%, 46%, 53%, 63%, and 70% of cloud covers were tested. With the aid of patch-based reconstruction and global optimization, satisfactory cloud-free results can be obtained even though the amount of cloud cover is large. Note that the generated results in Fig.10are misty because some misty patches are selected as reconstruction candidates.An experiment of removing simulated cloud-contaminated data and reconstructing the missing data was conducted to quantify the reconstruction accuracy and to compare with the related cloud removal approaches. The experimental procedure was as follows. Select a sequence of images that contains several different landscapes, simulate clouds by partly obscuring a cloud-free image of the sequence, and then compare the reconstructed image with the original cloud-free image. A simulation image containing four simulated cloud-contaminated regions shown in Fig.11was tested. The experimental results and statistical analyses are shown in Fig.12and TableI,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Results of cloud removal for the simulation data shown in Fig. 11. (From left to right) Results generated by patch replacement, radiometric correction, radiometric correction and boundary blending, and our approach, respectively. The results of using reference images A and B are shown at the top and bottom, respectively.</figDesc><graphic coords="7,307.95,430.07,246.12,102.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Accuracy assessment for (change area) the vegetation growth area and (nonchange area) the mountain area. (Top) Target image containing two simulated cloud-contaminated areas.(Bottom) RMSE of the reconstruction results using (red curve) the patch replacement approach and (black curve) our approach with the reference images captured between July 3, 1999, andMay 11, 2003.    </figDesc><graphic coords="8,39.71,257.33,246.14,187.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Results of cloud removal using a single reference image and multiple reference images. (a) Result of using multiple reference images (RI_A, RI_B, and RI_C). (b) Result of using a single reference image (RI_C).</figDesc><graphic coords="8,302.75,257.21,246.14,196.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>Chao-Hung Lin (M'12) received the M.S. and Ph.D. degrees in computer science and information engineering from National Cheng Kung University, Tainan, Taiwan, in 1998 and 2004, respectively. Since 2006, he has been a Faculty Member with the Department of Geomatics, National Cheng Kung University, where he is currently an Associate Professor, leads the Digital Geometry Processing Laboratory, and coleads the Computer Graphics Laboratory. He served as an Editorial Board Member of the International Journal of Computer Science and Artificial Intelligence. His current research interests include remote sensing, point cloud processing, digital map generation, information visualization, and computer graphics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I RECONSTRUCTION</head><label>I</label><figDesc>ACCURACY OF CLOUD REMOVAL RESULTS GENERATED BY THE APPROACHES OF (APPROACH A) PATCH REPLACEMENT, (APPROACH B) RADIOMETRIC CORRECTION, (APPROACH C) RADIOMETRIC CORRECTION AND LOCAL COLOR BLENDING, AND OUR APPROACH. THE SIMULATION DATA AND THE REFERENCE IMAGES A AND B (DENOTED BY RI_A AND RI_B) SHOWN IN FIG. 11 ARE USED</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II RECONSTRUCTION</head><label>II</label><figDesc>ACCURACY OF CLOUD REMOVAL RESULTS GENERATED USING A SINGLE REFERENCE IMAGE AND MULTIPLE REFERENCE IMAGES</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank the anonymous reviewers for their valuable comments and suggestions. The authors would also like to thank the U.S. Geological Survey Center for providing the images.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the National Science Council, Taiwan, under Contracts NSC 100-2119-M-006-008 and NSC 100-2119-M-006 -025 and in part by the Central Geological Survey, Ministry of Economic Affairs, Taiwan.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Po-Hung Tsai received the B.S. and M.S. degrees in geomatics from National Cheng Kung University, Tainan, Taiwan, in 2008 and 2010, respectively.</p><p>He is currently a member of the Digital Geometry Processing Laboratory, National Cheng Kung University. His research interests include remote sensing and image processing.</p><p>Kang-Hua Lai received the B.S. degree in civil engineering from National Chung Hsing University, Taichung, Taiwan, in 2010 and the M.S. degree in geomatics from National Cheng Kung University, Tainan, Taiwan, in 2012.</p><p>He is currently a member of the Digital Geometry Processing Laboratory, National Cheng Kung University. His research interests include remote sensing and image processing.</p><p>Jyun-Yuan Chen received the B.S. and M.S. degrees in geomatics from National Cheng Kung University, Tainan, Taiwan, in 2005 and 2007, respectively, where he is currently working toward the Ph.D. degree.</p><p>He is currently a member of the Digital Geometry Processing Laboratory, National Cheng Kung University. His research interests include point cloud processing, information visualization, computer graphics, remote sensing, and image processing.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The availability of cloud-free Landsat ETM Plus data over the conterminous United States and globally</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Environ</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1196" to="1211" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Contextual reconstruction of cloud-contaminated multitemporal multispectral images</title>
		<author>
			<persName><forename type="first">F</forename><surname>Melgani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="442" to="455" />
			<date type="published" when="2006-02">Feb. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Contextual spatiospectral postreconstruction of cloud-contaminated images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Benabdelkader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Melgani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="204" to="208" />
			<date type="published" when="2008-04">Apr. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Clouds and cloud shadows removal from high-resolution remote sensing images</title>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE IGRASS</title>
		<meeting>IEEE IGRASS</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="4256" to="4259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A bandelet-based inpainting technique for clouds removal from remotely sensed images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Maalouf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Carre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Augereau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fernandez-Maloigne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2363" to="2371" />
			<date type="published" when="2009-07">Jul. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Inpainting strategies for reconstruction of missing data in VHR images</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lorenzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Melgani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mercier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="914" to="918" />
			<date type="published" when="2011-09">Sep. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Restoration of Aqua MODIS band 6 using histogram matching and local least squares fitting</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rakwatin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Takeuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yasuoka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="613" to="627" />
			<date type="published" when="2009-02">Feb. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An improved method for cloud removal in ASTER data change detection</title>
		<author>
			<persName><forename type="first">F</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jian-Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE IGRASS</title>
		<meeting>IEEE IGRASS</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="3387" to="3389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A new cloud removal algorithm for multi-spectral images</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SAR MIPPR</title>
		<meeting>SAR MIPPR</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="230" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Restoration of clouded pixels in multispectral remotely sensed imagery with cokriging</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Travis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2173" to="2195" />
			<date type="published" when="2009-01">Jan. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multi-temporal MODIS-Landsat data fusion for relative radiometric normalization, gap filling, prediction of Landsat data</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schaaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lindquist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Remote Sens. Environ</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3112" to="3130" />
			<date type="published" when="2008-06">Jun. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Producing cloud free and cloudshadow free mosaic from cloudy Ikonos images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Liew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Kwoh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE IGARSS</title>
		<meeting>IEEE IGARSS</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="3946" to="3948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automated production of cloudfree and cloud shadow-free image mosaics from cloudy satellite imagery</title>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kwoh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 20th Congr</title>
		<meeting>20th Congr</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="15" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Cloud covering denoising through image fusion</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gabarda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vis. Comput</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="523" to="530" />
			<date type="published" when="2007-05">May 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Cloud-free satellite image mosaics with regression trees and histogram matching</title>
		<author>
			<persName><forename type="first">E</forename><surname>Helmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ruefenacht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Photogramm. Eng. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1079" to="1089" />
			<date type="published" when="2005-09">Sep. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Information reconstruction in the cloud removing area based on multi-temporal Chris images</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="679" to="708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Automated detection and removal of clouds and their shadows from Landsat TM images</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Muramatsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Fujiwara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEICE Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="453" to="460" />
			<date type="published" when="1999-02">Feb. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automatic cloud removal from multi-temporal spot images</title>
		<author>
			<persName><forename type="first">D.-C</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-T</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-L</forename><surname>Chien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Comput</title>
		<imprint>
			<biblScope unit="volume">205</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="584" to="600" />
			<date type="published" when="2008-11">Nov. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Image quality assessment: From error visibility to structural similarity</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004-04">Apr. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automated masking of cloud and cloud shadow for forest change analysis using Landsat images</title>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Goward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Masek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R G</forename><surname>Townshend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Vogelmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="5449" to="5464" />
			<date type="published" when="2010-06">Jun. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Poisson image editing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gangnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="313" to="318" />
			<date type="published" when="2003-07">Jul. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Scene completion using millions of photographs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="87" to="94" />
			<date type="published" when="2007-07">Jul. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Photosketcher: Interactive sketch-based image synthesis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Eitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hildebrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Boubekeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alexa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Graph. Appl</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="56" to="66" />
			<date type="published" when="2011-12">Dec. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A comprehensive framework for image inpainting</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bugeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bertalmio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Caselles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2634" to="2645" />
			<date type="published" when="2010-10">Oct. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Distributed gradient-domain processing of planar and spherical images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kazhdan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Surendran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">article</biblScope>
			<date type="published" when="2010-03">Mar. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
