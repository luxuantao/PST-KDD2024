<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">RNN Models for Dynamic Matrix Inversion: A Control-Theoretical Perspective</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Long</forename><surname>Jin</surname></persName>
							<email>jinlong@lzu.edu.cn</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Shuai</forename><surname>Li</surname></persName>
							<email>shuaili@polyu.edu.hk</email>
						</author>
						<author>
							<persName><forename type="first">Bin</forename><surname>Hu</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science and Engi-neering</orgName>
								<orgName type="institution">Lanzhou University</orgName>
								<address>
									<settlement>Lanzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
								<address>
									<addrLine>Hung Hom</addrLine>
									<settlement>Kowloon, Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Transactions on Industrial Informatics IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Transactions on Industrial Informatics IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">RNN Models for Dynamic Matrix Inversion: A Control-Theoretical Perspective</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">47BEB9212CA824485C011EA5A8B6B089</idno>
					<idno type="DOI">10.1109/TII.2017.2717079</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Recurrent neural network</term>
					<term>control-theoretic approach</term>
					<term>dynamic problems with time-varying parameters</term>
					<term>zerofinding methods</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, the existing recurrent neural network (RNN) models for solving zero-finding (e.g., matrix inversion) with time-varying parameters are revisited from the perspective of control and unified into a control-theoretical framework. Then, limitations on the activated functions of existing RNN models are pointed out and remedied with the aid of control-theoretical techniques. In addition, gradient-based RNNs, as the classical method for zero-finding, have been remoulded to solve dynamic problems in manners free of errors and matrix inversions. Finally, computer simulations are conducted and analyzed to illustrate the efficacy and superiority of the modified RNN models designed from the perspective of control. The main contribution of this paper lies in the removal of the convex restriction and the elimination of the matrix inversion in existing RNN models for dynamic matrix inversion. This work provides a systematic approach on exploiting control techniques to design RNN models for robustly and accurately solving algebraic equations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>R ECURRENT neural network (RNN) solutions for zero- finding are often designed as an ordinary differential equation (ODE) system, of which the equilibrium points are identical to the theoretical solution of the problems <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b8">[9]</ref>. Then, starting with a given initial state, an RNN model evolves along a desired direction to recurrently generate the estimates on equilibrium points until a predefined accuracy is achieved. Therefore, a fundamental requirement for a computational method is to output the correct evolution direction based on the input states such that the corresponding residual error would decrease as time evolves. It is found in <ref type="bibr" target="#b9">[10]</ref> that there exists an essential similarity between the solving of a zerofinding problem and the regulation control of a system: their corresponding residual errors should be enforced to zero as timely, accurately, and stably as possible.</p><p>Up to now, limited studies have been conducted by exploiting such a similarity, which enriches tools to design and analyze new computational models and provides a new viewpoint to revisit and remould the existing ones <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b12">[13]</ref>. The design and analysis of the most existing methods for solving equations and optimizations are often constructed and developed in the computational framework, which are revisited from the perspective of control in what follows. Direct methods, e.g., Cramer's rule for solving a system of linear equations, converging to the desired theoretical solution in finite steps, play a fundamental role in problems of simple calculations <ref type="bibr" target="#b13">[14]</ref>. With the rapid development of science and technology, many scientific computation problems have become more and more complicated and cannot be handled by these direct methods, thereby inspiring the exploiting of recursive methods. Bisection method, which recursively bisects a potential solution interval and then selects a subinterval in which the theoretical solution must lie for further processing, can be deemed as a seminal iterative algorithm different from direct methods. From the perspective of control, at each iteration, bisection method exploits the residual error generated via the last iteration to find the evolution direction for an estimated value on the theoretical solution. Even with the simple structure, bisection method suffers from the unsatisfactory convergent speed, which severely restricts its applications to the industrial and scientific fields.</p><p>Much effort has been devoted to the design and analysis of recurrent methods for the online solution of zero-finding problems. An intuitional approach is to take steps proportional to the negative of the gradient, which is termed gradientbased or gradient-related computational models <ref type="bibr" target="#b14">[15]</ref>. For example, to solve the inverse of matrix A, a simple continuoustime gradient-based RNN (GNN) model can be designed as Ẋ = -γA T (AX -I), where X is the unknown matrix to be obtained, I is the identity matrix and γ is the parameter for scaling the convergent speed. In addition, as a typical numerical algorithm for solving equations in a discrete-time manner, Newton iteration can be formulated as X k+1 = X k -X k (A k X k -I), where subscript k denotes the iteration index. From the viewpoint of control, the GNN model is a kind of proportional feedback controller, of which the feedback gain is γ with the residual error being AX -I. Newton iteration can be interpreted as a proportional feedback controller in a similar way. In the literatures, many computational models, as variants of classical gradient descent method or Newton iteration, are presented to solve different equations and optimizations with different emphases, e.g., conjugate gradient methods <ref type="bibr" target="#b15">[16]</ref>. Although these models express in different formation and have different computational complexity, they share the same errorfeedback mechanism in finding the evolution direction, and thus can be deemed as proportional feedback controllers in control terminology.</p><p>It is evident that, for a controller that only exploits the proportional feedback, it cannot control a plant with timevarying parameters in a predict way, thereby resulting in time-delay errors. In addition, these gradient-based models or Newton iteration related numerical algorithms cannot solve a dynamic zero-finding problem with time-varying parameters effectively due to the similar reasons. To eliminate lagging errors, Zhang et al. present a new type of RNN (i.e., zeroing neural network, ZNN) by exploiting the time-derivative information of the dynamic parameters, which is the first systematic work on the dynamic problems solving <ref type="bibr" target="#b16">[17]</ref>. Such a methodology is further extended to the design of high accuracy discrete-time numerical algorithms <ref type="bibr" target="#b17">[18]</ref>, and modified to be of finite-time convergence <ref type="bibr" target="#b18">[19]</ref>- <ref type="bibr" target="#b20">[21]</ref>, and so on <ref type="bibr" target="#b21">[22]</ref>- <ref type="bibr" target="#b23">[24]</ref>. It is worth pointing out that these finite-time convergent RNN models may have limited significance due to the existence of the truncation errors as well as round-off errors. In short, these models for solving dynamic problems may differ with each other in structures from the perspective of computation, but can be unified into a proportional-derivative controller in control.</p><p>In recent years, researchers have devoted their effort to design a general framework based on control-theoretic approaches directly. Bhaya et al. employ systems and control ideas to systemize a swarm of continuous-time RNN models and discrete-time numerical algorithms, in which the zerofinding problem in computation is formulated into regulation problem in control <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b12">[13]</ref>. Designing a suitable controller based on a Lyapunov function leads to the convergence of the residual error, and consequently, the zero-finding problem is solved. Motivated by the achievements gained by <ref type="bibr">Bhaya et al.</ref> in the design and analysis of computational model based on control-theoretic approaches, Jin et al. present a modified ZNN model to tolerate noise existing in the solving process of dynamic zero-finding problems in a similar way.</p><p>Although some successes have been achieved for the design and analysis of RNN model for the online solution of dynamic problems, the existing research is far from upto-date <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>. For example, in addition to be not of saturation, the existing activation function for ZNN should be odd and monotonically increasing. Considering that bang-bang control only exploits maximum input action, minus maximum input action, and zero input action, a saturated activation function is desired for RNN models specially designed for solving dynamic problems (i.e., ZNN models). Moreover, the matrix involved in dynamic matrix inversion problems (or optimization problems) solved by ZNN models are required to be nonsingular at every time instant, which may exclude many possible applications. For example, for the motion generation of a redundant manipulator, we could not foresee the existence of Jacobian matrix singularity during the task execution. However, a crash may happen due to the inversion in ZNN models.</p><p>To remedy these weaknesses of existing solutions, a gradientbased GNN model with adaptive coefficient is presented in this paper and is depicted in an inverse-free manner.</p><p>The remainder of this paper is organized into six sections. Problem formulation and existing results are provided in Section II. Then, Section III proposes new nonconvex-allowed activation functions to remedy the weaknesses of existing ZNN models from the perspective of control. Section IV further releases the requirements on matrix inversion by proposing a GNN model with adaptive coefficient. Sections V and VI provide illustrative simulation examples to substantiate the efficacy and superiority of the proposed models. Section VII concludes the paper with final remarks. Before ending this introductory section, we highlight the main contributions of this paper in the following facts.</p><p>• This is the first work relaxing the convex restriction in existing ZNN models computing the inverse of dynamic matrices. The corresponding RNN model, being of saturation, is accelerated to finite-time convergence. • With the aid of Lyapunov function, for the first time, a gradient-based GNN model with adaptive coefficient is constructed for computing the inverse of dynamic matrices. The derived model is free of theoretical errors and matrix inversions. • This paper extends the establishment of RNN models from an optimization perspective to a control perspective and revisits the existing computational models from the perspective of control. • The designs and analyses of RNN models presented in this paper, by their very nature, have provided a unique perspective for showing how to leverage control techniques to robustly and accurately solve zero-finding problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PROBLEM FORMULATION AND EXISTING RESULTS</head><p>In this paper, without loss of generality, we take the dynamic matrix inversion problem as an example and the corresponding ZNN model is revisited from the control perspective. The ZNN models for solving other dynamic problems (e.g., dynamic optimization problem) can be derived similarly. The following dynamic matrix inversion problem should be solved in realtime <ref type="bibr" target="#b16">[17]</ref>:</p><formula xml:id="formula_0">A(t)X(t) = I,<label>(1)</label></formula><p>where time-varying matrix A(t) ∈ R n×n is assumed to be smoothly and nonsingular; I ∈ R n×n is the identity matrix.</p><p>By defining an error function as ǫ(t) = A(t)X(t) -I, such a problem is formulated as a zero-finding problem, and the theoretical solution X * (t) zeros out it. Then, the design formula is used to force residual error ǫ(t) to converge to zero:</p><formula xml:id="formula_1">ǫ(t) = -γΦ(ǫ(t)),<label>(2)</label></formula><p>where γ &gt; 0; Φ(•) : R n×n → R n×n denotes a vector array of activation function with its element denoted by φ(•).</p><p>According to the reported results, only the monotonically increasing and odd activation function φ(•) can be used to construct the corresponding ZNN models. For example, the following three activation functions are frequently used to construct the ZNN models: linear (li) activation function:</p><formula xml:id="formula_2">φ li (ǫ ij ) = ǫ ij ;</formula><p>power-sigmoid (ps) activation function :</p><formula xml:id="formula_3">φ ps (ǫ ij ) = 1+exp(-4) 1-exp(-4) 1-exp(-4ǫij ) 1+exp(-4ǫij) , if |ǫ ij | &lt; 1, ǫ 3 ij , if |ǫ ij | ≥ 1;</formula><p>hyperbolic sine (hs) activation function:</p><formula xml:id="formula_4">φ hs (ǫ ij ) = exp(3ǫ ij ) 2 - exp(-3ǫ ij ) 2 .</formula><p>Note that, design formula ( <ref type="formula" target="#formula_1">2</ref>) is a decoupled system, and its ijth subsystem activated by the linear function can be rewritten as</p><formula xml:id="formula_5">ǫij (t) + γǫ ij (t) = 0,</formula><p>which is exactly the first-order dynamic system. Starting from any initial state ǫ(0), such a system is stable in view of γ &gt; 0.</p><p>Expanding (2) with ǫ(t) = A(t)X(t) -I, we further have</p><formula xml:id="formula_6">A(t) Ẋ(t) = -Ȧ(t)X(t) -γΦ(A(t)X(t) -I).<label>(3)</label></formula><p>With A(t) being nonsingular at every time instant, the above equation is simulated in MATLAB in the form of</p><formula xml:id="formula_7">Ẋ(t) = -A -1 (t)[ Ȧ(t)X(t) + γΦ(A(t)X(t) -I)].<label>(4)</label></formula><p>Even if ZNN model (3) (or (4)) may have complex dynamic behavior during the transient state, its residual error globally converges to zero in view of the fact that ZNN model (3) (or (4)) is an equivalent expansion of (2).</p><p>One of the latest research on solving dynamic problems is the integration-enhanced ZNN design formula, which is presented to tolerant noise online <ref type="bibr" target="#b26">[27]</ref>, and shown as:</p><formula xml:id="formula_8">ǫ(t) = -γǫ(t) -λ t 0 ǫ(τ )dτ,<label>(5)</label></formula><p>where λ &gt; 0. Then, the corresponding ZNN can be derived similarly. Based on the control theory, it can be readily concluded that, starting from any initial state ǫ(0), the error ǫ(t) of ZNN models generalized from (5) globally converges to zero even if perturbed by a constant noise. So far, we have revisited the research results on solving dynamic problems, which, from the viewpoint of control, can be deemed as simple dynamic systems. In the ensuing section, new projection activation functions are designed with link to bang-bang control.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. NONCONVEX PROJECTION ACTIVATED ZNN</head><p>We define P Γ (U ) = arg min Y ∈Γ Y -U F with 0 ∈ Γ, where U and Γ are two sets. That is to say, P Γ (U ) is the projection from the set U to the set Γ. Taking (2) as an example and exploiting P Γ (U ), we have</p><formula xml:id="formula_9">ǫ(t) = -P Γ (γǫ(t)).<label>(6)</label></formula><p>Then, we similarly have</p><formula xml:id="formula_10">A(t) Ẋ(t) = -Ȧ(t)X(t) -P Γ (γ(A(t)X(t) -I)). (<label>7</label></formula><formula xml:id="formula_11">)</formula><p>To investigate the convergence performance of the proposed ZNN model ( <ref type="formula" target="#formula_10">7</ref>), we have the following theorem.</p><p>Theorem 1: ZNN model ( <ref type="formula" target="#formula_10">7</ref>) globally converges to the theoretical solution of dynamic matrix inversion problem <ref type="bibr" target="#b0">(1)</ref>.</p><p>Proof: To prove the convergence performance of ZNN model <ref type="bibr" target="#b6">(7)</ref>, a Lyapunov function candidate is firstly defined as</p><formula xml:id="formula_12">V 1 (t) = ǫ T (t)ǫ(t)/2.</formula><p>In view of the facts that V 1 (t) &gt; 0 for any ǫ(t) = 0, and that V 1 (t) = 0 only for ǫ(t) = 0, one can readily draw the conclusion that the above Lyapunov function candidate is positive definite. Then, the time derivative of V 1 (t) is calculated as:</p><formula xml:id="formula_13">V1 (t) = -ǫ T (t)P Γ (ǫ(t)).</formula><p>Based on the definition of P Γ (ǫ(t)), for all Y ∈ Γ, we have</p><formula xml:id="formula_14">P Γ (ǫ(t)) -2 F ≤ Y -ǫ(t) 2 F .</formula><p>Letting Y = 0 generates</p><formula xml:id="formula_15">P Γ (ǫ(t)) -ǫ(t) 2 F ≤ ǫ(t) 2 F ,</formula><p>which can be written equivalently as</p><formula xml:id="formula_16">P T Γ (ǫ(t))P Γ (ǫ(t)) -2P T Γ (ǫ(t))ǫ(t) ≤ 0.</formula><p>Rearranging the above inequality leads to</p><formula xml:id="formula_17">2P T Γ (ǫ(t))ǫ(t) ≥ P T Γ (ǫ(t))P Γ (ǫ(t)) ≥ 0.</formula><p>Therefore, one can readily deduce the following results:</p><formula xml:id="formula_18">V1 (t) ≤ -P T Γ (ǫ(t))P Γ (ǫ(t))/2 ≤ 0.</formula><p>It can be summarized that ǫ(t) globally converges to zero based on the Lyapunov theory. That is to say, ZNN model <ref type="bibr" target="#b6">(7)</ref> globally converges to the theoretical solution of dynamic matrix inversion problem (1). The proof is thus complete. Theorem 1 indicates that the projection P Γ (•) incorporates the existing activation functions for accelerating ZNN as special cases. Additionally, different from those existing results, we have the following special sets to construct new activation functions to meet extra requirements.</p><p>• Bound situation with saturation. Γ = {U ∈ R n×n , ω -≤ U ≤ ω + }, where ω -&lt; 0 and ω + &gt; 0. For this case,</p><formula xml:id="formula_19">P Γ (U ij ) =    ω + ij , U ij &gt; ω + ij , U ij , ω - ij ≤ U ij ≤ ω + ij , ω - ij , U ij &lt; ω - ij .</formula><p>• Ball situation with saturation. Γ = {U ∈ R n×n , U F ≤ η}, where η &gt; 0. For this case,</p><formula xml:id="formula_20">P Γ (U ) = U, Bu F ≤ η, η U U F , U F &gt; η.</formula><p>• Nonconvex situation with saturation.</p><formula xml:id="formula_21">Γ = {U ∈ R n×n , -c 1 ≤ U ij ≤ c 1 or U ij = c 2 or U ij = c 3 },</formula><p>where c 1 , c 2 , and c 3 are constants and 0 &lt; c 1 &lt; c 2 , and</p><formula xml:id="formula_22">c 3 &lt; -c 1 &lt; 0.</formula><p>Remark 1: Liu and Wang present a hard-limiting activation function for accelerating RNN models to finite-time convergence for solving constrained static optimization problems in <ref type="bibr" target="#b27">[28]</ref>, which can be deemed as a degraded case of the new activation function with nonconvex situation. For c 1 → 0, the new activation function can be rewritten as</p><formula xml:id="formula_23">P Γ (U ij ) =    c 2 , U ij &gt; 0, 0, U ij = 0, c 3 , U ij &lt; 0.</formula><p>Then, the design formula (6) reduces to</p><formula xml:id="formula_24">ǫij (t) =    -c 2 , ǫ ij (t) &gt; 0, 0, ǫ ij (t) = 0, -c 3 , ǫ ij (t) &lt; 0.<label>(8)</label></formula><p>Theorem 1 proves that the design formula (6) possesses the global convergence property, which indicates that each element of ǫ(t) (i.e., ǫ ij (t)) globally approaches to zero with randomlygenerated initial state ǫ ij (0). Therefore, for a given initial value</p><formula xml:id="formula_25">ǫ ij (0), ǫ ij (t) falls in interval [ǫ ij (0), 0] [corresponding to ǫ ij (0) &lt; 0] or [0, ǫ ij (0)] [corresponding to ǫ ij (0) &gt; 0]</formula><p>. Letting ǫ max (t) denote the element in ǫ(t) with the largest absolute initial value, by solving (8) directly, we could compute the finite-time convergent time t f as</p><formula xml:id="formula_26">t f =    ǫ max (0)/c 2 , ǫ max (0) &gt; 0, 0, ǫ max (0) = 0, ǫ max (0)/c 3 , ǫ max (0) &lt; 0.</formula><p>Note that the bang-bang control in industrial areas often involves three types of inputs: the maximum input c 2 , the minus maximum input c 3 , and zero input 0. Therefore, the hard-limiting activation function can be deemed as an application of the widely used strategies in bang-bang control. In addition, the zero input action can be expanded into [-c 1 , c 1 ] for preventing oscillation phenomena, which leads to the definition of Γ in the new activation function with nonconvex situation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. GNN WITH ADAPTIVE COEFFICIENT</head><p>As stated previously, ZNN is an effective method for solving dynamic matrix inversion problems with time-varying parameters. However, with the existence of singularities at which the problem fails to have a theoretical solution, the ZNN method fails to solve the corresponding problem.</p><p>As reviewed in the Introduction part, the gradient-based RNN (GNN) model can be classified into the type of proportional feedback controller, which cannot solve a dynamic problem with time-varying parameters in a predictive and accurate way and formulated as</p><formula xml:id="formula_27">Ẋ(t) = -γA T (t)(A(t)X(t) -I).<label>(9)</label></formula><p>However, the gradient-based approach has many advantages in handling complex problems, thereby enabling it a widely used method. For example, it is evident that such a model avoids the matrix inversion operation naturally. Therefore, taking the advantages of the conventional GNN model, a new GNN model with adaptive coefficient is given as</p><formula xml:id="formula_28">Ẋ(t) = -κ(t)A T (t)(A(t)X(t) -I),<label>(10)</label></formula><p>where</p><formula xml:id="formula_29">κ(t) = c 4 |vec T (A(t)X(t) -I)vec( Ȧ(t)X(t))| I n ⊗ A(t)vec(A(t)X(t) -I) 2 2</formula><p>, with I n ∈ R n×n being a unit matrix; ⊗ denoting the Kronecker product operation; vec(•) denoting the vectorization of a matrix and c 4 &gt; 1 denoting a constant. In addition, motivated by the activation function used in ZNN, we exploit these function to accelerate the proposed GNN model <ref type="bibr" target="#b9">(10)</ref> with adaptive coefficient:</p><formula xml:id="formula_30">Ẋ(t) = -κ(t)A T (t)Φ(A(t)X(t) -I),<label>(11)</label></formula><p>where Φ is defined the same as that in <ref type="bibr" target="#b1">(2)</ref>.</p><p>For convenience, we define f (x(t)) = vec(A(t)X(t) -I), where x(t) is the vectorization of matrix X(t). Then, the solving of dynamic matrix inversion problem is transformed into a vector-formed zero-finding problem. Similarly, GNN model <ref type="bibr" target="#b9">(10)</ref> with adaptive coefficient can be rewritten in the vector-formed formation as</p><formula xml:id="formula_31">ẋ(t) = -κ(t) ∂f (x(t)) ∂x T (t) T f (x(t),<label>(12)</label></formula><p>where</p><formula xml:id="formula_32">κ(t) = c 4 |f T (x(t)) ∂f (x(t)) ∂t | ∂f (x(t)) ∂x T (t) f (x(t)) 2 2 .</formula><p>To investigate the convergence performance of the proposed GNN model (10) (or its vector-formed model ( <ref type="formula" target="#formula_31">12</ref>)) with adaptive coefficient, we have the following theorem.</p><p>Theorem 2: GNN model <ref type="bibr" target="#b9">(10)</ref> with adaptive coefficient globally converges to the theoretical solution of dynamic matrix inversion problem <ref type="bibr" target="#b0">(1)</ref>.</p><p>Proof: To prove the convergence performance of GNN model with adaptive coefficient, a Lyapunov function candidate is firstly defined as</p><formula xml:id="formula_33">V 2 (t) = f T (x(t))f (x(t))/2.</formula><p>In view of the facts that V 2 (t) &gt; 0 for any f (x(t)) = 0, and that V 2 (t) = 0 only for f (x(t)) = 0, one can readily draw the conclusion that the above Lyapunov function candidate is positive definite. Then, the time derivative of V 2 (t) is calculated as:</p><formula xml:id="formula_34">V2 (t) = f T (x(t)) ∂f (x(t)) ∂x T (t) ẋ(t) + ∂f (x(t)) ∂t</formula><p>Substituting vector-formed GNN model <ref type="bibr" target="#b11">(12)</ref> with adaptive parameter into the above equation leads to</p><formula xml:id="formula_35">V2 (t) = -κ(t)f T (x(t)) ∂f (x(t)) ∂x T (t) ∂f (x(t)) ∂x T (t) T f (x(t)) +f T (x(t)) ∂f (x(t))</formula><p>∂t .</p><p>We further have</p><formula xml:id="formula_36">V2 (t) = -κ(t) f T (x(t)) ∂f (x(t)) ∂x T (t) 2 2 + f T (x(t)) ∂f (x(t)) ∂t .</formula><p>From the definition of κ(t), we have</p><formula xml:id="formula_37">V2 (t) = -c 4 |f T (x(t)) ∂f (x(t)) ∂t | + f T (x(t)) ∂f (x(t)) ∂t .</formula><p>In view of the condition that c 4 &gt; 1, one can readily draw the conclusion that V2 (t) &lt; 0. It can be summarized that f (x(t)) globally converges to zero based on the Lyapunov theory. That is to say, GNN model <ref type="bibr" target="#b9">(10)</ref> with adaptive coefficient globally converges to the theoretical solution of time-varying matrix inversion problem (1). The proof is thus complete. Additionally, for the nonlinear activation function aided GNN model <ref type="bibr" target="#b10">(11)</ref> with adaptive coefficient, we have the following theorem.</p><p>Theorem 3: If the power-sigmoid (or hyperbolic sine) activation function is used, superior convergence is achieved for GNN model <ref type="bibr" target="#b10">(11)</ref> with adaptive coefficient, compared with the convergence obtained using the linear activation function presented in Theorem 2.</p><p>Proof We focus on the convergence properties of GNN model <ref type="bibr" target="#b10">(11)</ref> with adaptive coefficient by using the aforementioned two types of nonlinear activation function Φ(•). We discuss the power-sigmoid activation function firstly, which is divided into two sub-cases. a) For |ǫ ij | ≥ 1, φ ps degrades into a power function, which is expressed as φ(ǫ ij (t)) = ǫ 3 ij (t). Reviewing V 2 (t) defined in Theorem 2, we have</p><formula xml:id="formula_38">V2 (t) ps = -κ(t) n 2 i=1, j=1 ǫ ij (t)φ ps ǫ ij (t) = -κ(t) n 2 i=1, j=1 ǫ 4 ij (t) ≤ -κ(t) n 2 i=1, j=1 ǫ 2 ij (t) = -κ(t) n 2 i=1, j=1 ǫ ij φ li ǫ ij = V2 (t) li ,</formula><p>where V2 (t) ps and V2 (t) li denote V (t) activated by Φ ps and by Φ li , respectively. Therefore, for error range |ǫ ij | ≥ 1, superior convergence is achieved for GNN model <ref type="bibr" target="#b10">(11)</ref> with adaptive coefficient aided with Φ ps , compared with the convergence obtained using Φ li . b) For |ǫ ij | &lt; 1, φ ps degrades into a bipolar-sigmoid function. Reviewing V 2 (t) defined in Theorem 2, we have</p><formula xml:id="formula_39">V2 (t) ps = -κ(t) n 2 i=1, j=1 ǫ ij (t)φ ps ǫ ij (t) &lt; -κ(t) n 2 i=1, j=1 ǫ 2 ij (t) = -κ(t) n 2 i=1, j=1 ǫ ij φ li ǫ ij = V2 (t) li ,</formula><p>which implies that, for error range |ǫ ij | &lt; 1, superior convergence is achieved for GNN model <ref type="bibr" target="#b10">(11)</ref> with adaptive coefficient aided with Φ ps , compared with the convergence obtained using Φ li .</p><p>The above analyses of the two sub-cases illustrate that, if Φ ps is used, superior convergence is achieved (to the convergence speed of using Φ li ).</p><p>Then, we present the discussion on Φ hs . Applying Taylor expansion to Φ hs leads to</p><formula xml:id="formula_40">φ hs (ǫ ij (t)) = exp(3ǫ ij (t)) 2 - exp(-3ǫ ij (t)) 2 = 1 2 +∞ l=0 (3ǫ ij (t)) l l! - +∞ l=0 (-3ǫ ij (t)) l l! = +∞ l=1 (3ǫ ij (t)) 2l-1 (2l -1)! &gt; 3ǫ ij (t).<label>(13)</label></formula><p>For any |ǫ ij (t)| = 0, the following inequalities hold</p><formula xml:id="formula_41">V2 (t) hs = -κ(t) n 2 i=1, j=1 ǫ ij (t)φ hs (ǫ ij ) &lt; -κ(t) n 2 i=1, j=1 3ǫ 2 ij (t) = 3 V2 (t) li , V2 (t) hs = -κ(t) n 2 i=1, j=1 ǫ ij (t)φ hs (ǫ ij ) &lt; -κ(t) n 2 i=1, j=1 ǫ ij (t)φ ps (ǫ ij (t)) = V2 (t) ps ,</formula><p>which implies that, superior convergence is achieved for GNN model <ref type="bibr" target="#b10">(11)</ref> with adaptive coefficient aided with Φ hs , compared with the convergence obtained using Φ ps or Φ li . The proof is thus complete. Remark 2: It is worth interpreting the proposed GNN model (10) (or <ref type="bibr" target="#b10">(11)</ref>) with adaptive coefficient from the perspective of control. On one hand, the term A(t)X(t) -I is used to feed back the error information on the current solution to obtain a robust solution, which can be deemed as a measure of the distance between computed X(t) and the theoretical solution X * (t); On the other hand, the scaling parameter κ(t) is adaptive with related to Ȧ(t)X(t), thereby exploiting the time derivative of the dynamic parameter A(t) during the real-time solution process. Therefore, from the viewpoint of control, GNN model <ref type="bibr" target="#b9">(10)</ref> (or <ref type="bibr" target="#b10">(11)</ref>) adapts to the change of coefficients in a predictive manner and exploits the error feedback information, and thus can solve dynamic problems in an accurate and robust way.</p><p>Remark 3: To impose restrictions on Ẋ(t), a saturation function can be employed:</p><formula xml:id="formula_42">S( Ẋij ) =      Ẋ+ ij , if Ẋij &gt; Ẋ+ ij Ẋij , if Ẋ- ij ≤ Ẋij ≤ Ẋij Ẋ- ij , if Ẋij &lt; Ẋ- ij .</formula><p>where Ẋ+ ij and Ẋij denote the upper and lower limits of Ẋij , respectively.</p><p>1551-3203 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.  <ref type="formula" target="#formula_10">7</ref>). (c) ǫ(t) of ( <ref type="formula" target="#formula_10">7</ref>). (d) ǫ(t) of ( <ref type="formula" target="#formula_10">7</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. ILLUSTRATIVE EXAMPLES</head><p>In this section, a dynamic matrix inversion problem with time-varying parameters investigated in <ref type="bibr" target="#b16">[17]</ref> is provided as a benchmark:</p><formula xml:id="formula_43">A(t) = sin(t) cos(t) -cos(t) sin(t) ∈ R 2×2 .<label>(14)</label></formula><p>In addition, the theoretical inverse of matrix ( <ref type="formula" target="#formula_43">14</ref>) is given to check the correctness of solution generated by these models:</p><formula xml:id="formula_44">A -1 (t) = sin(t) -cos(t) cos(t) sin(t) ∈ R 2×2 .<label>(15)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. ZNN with Nonconvex Constraints on Activation Function</head><p>It is revealed in Theorem 1 that the nonconvex projection operation can be used to construct the activation functions of ZNN, which satisfies saturation constraint. In the ensuing simulations, the following set Γ is chosen as an example:</p><formula xml:id="formula_45">Γ = {ϕ = [ϕ ij ] ∈ R 2×2 , -0.05 ≤ σ ij ≤ 0.05,<label>(16)</label></formula><p>or</p><formula xml:id="formula_46">σ ij = 2, or σ ij = -2}.</formula><p>Considering that 0 ∈ Γ and 2 ∈ Γ but (0 + 2)/2 / ∈ Γ, we can draw the conclusion that this choice of Γ is nonconvex. As stated in previous part, Γ defined in ( <ref type="formula" target="#formula_45">16</ref>) can be deemed as a 3.81 ‡ †AF and MSSRE denote activation function and maximal steady-state residual error, respectively ‡The difference between the initial state and the theoretical solution should be sufficiently small. Otherwise, a crash may generate. ⋆ Quantitative data are generated by computing the inverse of Toeplitz matrix A(t) ∈ R 20×20 in Subsection V-C, where c 1 = 10, c 2 = 20, c 3 = -20, c 4 = 50, γ = 10, the step-size of model in <ref type="bibr" target="#b17">[18]</ref> and <ref type="bibr" target="#b29">[30]</ref> is set as h = 0.5, and the sampling gap is set as 0.1.</p><p>generalized form of commonly used strategies in industrial bang-bang control. The simulation results synthesized by nonconvex function activated ZNN model <ref type="bibr" target="#b6">(7)</ref> are illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>. Starting from randomly-given initial state, the neural state of nonconvex function activated ZNN model <ref type="bibr" target="#b6">(7)</ref> (denoted by solid lines in blue) shown in Fig. <ref type="figure" target="#fig_0">1</ref>(a) rapidly converges to the theoretical inverse of A(t) (denoted by dashed lines in red). The corresponding residual error ||ǫ(t)|| F is shown in Fig. <ref type="figure" target="#fig_0">1(b)</ref>, from which, we can observe that it approaches to zero at t ≈ 2.2 s. In addition, Remark 1 indicates an approximative approach to compute the convergence time of nonconvex function activated ZNN model <ref type="bibr" target="#b6">(7)</ref>. It can be seen from Fig. <ref type="figure" target="#fig_0">1(c</ref>) that the ǫ max (0) ≈ -4.5, and thus, t f = ǫ max (0)/(-2) ≈ (-4.5)/(-2) ≈ 2.25 s. Evidently, the analysis presented in Remark 1 is verified effectively. Moreover, the change rate of the model for the perspective of control, i.e., ǫ(t), is illustrated in Fig. <ref type="figure" target="#fig_0">1(d)</ref>, of which the values are either ±2 or within the small range [-0.05, 0.05], which shows the compliance of the activation functions with the nonconvex set Γ in <ref type="bibr" target="#b15">(16)</ref>. Due to the relative large residual error at the beginning, the elements of ǫ(t) are as large as ±2. With time elapsing, their values reduce to the range [-0.05, 0.05] and remain inside after 2 s. The convergence of the residual error in Fig. <ref type="figure" target="#fig_0">1</ref> validates the effectiveness of Theorem 1 for the nonconvex constraint on activation function. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. GNN Model with Adaptive Coefficient</head><p>Computer simulation results synthesized by GNN model <ref type="bibr" target="#b9">(10)</ref> with adaptive coefficient are illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>. Starting from randomly-given initial state, the corresponding residual error ||ǫ(t)|| F with c 4 = 5 is shown in Fig. <ref type="figure" target="#fig_1">2(b)</ref>, from which, we can observe that it approaches to zero at t ≈ 0.8 s. In addition, for c 4 = 50, the residual error converges to near zero at t ≈ 0.08 s, which means that the convergence speed of GNN model <ref type="bibr" target="#b9">(10)</ref> with adaptive coefficient can be expedited by increasing c 4 . Moreover, computer simulations synthesized by nonlinear function activated GNN model <ref type="bibr" target="#b9">(10)</ref> with adaptive coefficient are shown in Fig. <ref type="figure" target="#fig_2">3</ref>. From Figs. <ref type="figure" target="#fig_1">2</ref> and<ref type="figure" target="#fig_2">3</ref>, we can observe that (10) activated by Φ hs has the best performance among three activated functions (Φ li , Φ ps , and Φ hs ). These results demonstrate the correctness of Theorems 2 and 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Dynamic Toeplitz Matrix Inversion</head><p>For further investigation, the proposed nonconvex function activated ZNN model <ref type="bibr" target="#b6">(7)</ref> and GNN model <ref type="bibr" target="#b9">(10)</ref> with adaptive coefficient are simulated for computing the inverse of a dynamic Toeplitz matrix. We consider the dynamic Toeplitz matrix A(t) ∈ R n×n with the ijth element a ij (t) defined as:</p><formula xml:id="formula_47">a ij (t) =    n + sin(5t), i = j, cos<label>(</label></formula><p>5t)/(i -j), i &gt; j, sin(5t)/(j -i), i &lt; j.</p><p>In the simulations, n = 20 and thus Toeplitz matrix A(t) is constituted of 400 elements. The residual errors synthesized by these two models are plotted in Fig. <ref type="figure" target="#fig_3">4</ref>, which converge to zero rapidly. In summary, these results completely verify effectiveness of the two RNN models for computing the inverse of dynamic matrices once again.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Comparisons</head><p>In this part, we compare the performance of the proposed nonconvex function activated ZNN model <ref type="bibr" target="#b6">(7)</ref> and GNN model <ref type="bibr" target="#b9">(10)</ref> with adaptive coefficient with existing solutions <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>, all of which are exploited for solving dynamic matrix inversion with time-varying parameter. As summarized in Table <ref type="table">I</ref>, model ( <ref type="formula" target="#formula_10">7</ref>) is able to deal with nonconvex projection set Γ, while existing ones require the projection set to be convex. In addition, from the perspective of control, GNN model ( <ref type="formula" target="#formula_27">9</ref>) can be deemed as a proportional feedback control due to the lack of time derivative information, which cannot perfectly solve such a problem in an error-free manner. Moreover, the proposed GNN model <ref type="bibr" target="#b9">(10)</ref> with adaptive coefficient is able to solve such a problem in the manners of inversionfree and error-free with global convergence, with theoretical analysis and simulation verifications provided. In addition, as indicated in Table <ref type="table">I</ref>, for the situations of nonconvex, saturation or nondifferentiable requirements, existing neural network solutions cannot handle them while the proposed ZNN model <ref type="bibr" target="#b6">(7)</ref> satisfies the set constraint, benefitting form the theoretical analysis presented in Theorem 1. Besides, the maximal steady-state residual errors (MSSRE) synthesized by the proposed RNN models are of order 10 -5 , which is numerically near zero but nonzero and, as shown in the table, theoretical errors of the proposed RNN models should be zero. Such an inconsistent phenomenon is due to the fact that the simulation is conducted on a finite-arithmetic digital computer. Therefore, the computational errors resulting from round-off errors and truncation errors may be inevitable. That is to say, the residual error remains nonzero. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. APPLICATION TO INVERSE KINEMATIC MOTION GENERATION</head><p>Robotics has been widely investigated in recent years <ref type="bibr" target="#b30">[31]</ref>- <ref type="bibr" target="#b37">[38]</ref>, and the proposed models are employed to the motion generation of robot in this part. The motion generation of a two-link planar robot manipulator shown in <ref type="bibr" target="#b17">[18]</ref> using the proposed models is provided in this section to illustrate their potential in real applications. We denote its joint-angle vector as θ = [θ 1 , θ 2 ] T ∈ R 2 . Then, the following relation between the desired velocity ṙd (t) and θ is derived:</p><formula xml:id="formula_48">ṙd (t) = J(t) θ(t),<label>(17)</label></formula><p>where J(t) is the Jacobian matrix. For <ref type="bibr" target="#b16">(17)</ref>, we can compute the solution via θ(t) = J -1 (t) ṙd (t). We can exploit nonconvex function activated ZNN model ( <ref type="formula" target="#formula_10">7</ref>) to solve J -1 (t) online: θ(t) = X(t) ṙd (t), J(t) Ẋ(t) = -J(t)X(t) -P Γ (γ(J(t)X(t) -I)).</p><p>The corresponding simulation results are illustrated in Fig. <ref type="figure" target="#fig_4">5</ref>. It can be observed from this figure that the actual trajectory is very close to the desired path and the tracking task is fulfilled well. The maximal position error visualized in Fig. <ref type="figure" target="#fig_4">5(c</ref>) is 6 × 10 -6 m, which is very tiny. This application verifies the efficacy and superiority of the proposed ZNN model for solving the dynamic matrix inversion problem of robot manipulators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSIONS</head><p>In this paper, we have revisited the existing recurrent neural network (RNN) models for zero-finding (e.g., matrix inversion) with parameters varying with time from the perspective of control. Then, we have proposed new ZNN model to remedy limitations of the activated functions. In addition, from the perspective of control, we have designed a gradientbased RNN to solve dynamic matrix inversion problems in manner free of errors and matrix inversions. Finally, computer simulations have been conducted and analyzed to illustrate the efficacy and superiority of the modified RNN models designed from the perspective of control.</p><p>The advantages of the proposed models over other existing methods can be interpreted from two layers: the superficial layer and the deep layer. Without getting too deeply into detail, the superficial layer mainly reflects in two aspects: the removal of the convex restriction on activation functions and the elimination of matrix inversion. As to the deep layer, the designs and analyses of RNN models presented in this paper, by their very nature, have further provided a unique perspective for exploiting control techniques to robustly and accurately solve algebraic equation with time-varying parameters. For example, inspired by the bang-bang control, we have removed the convex restriction in RNN models. Note that the shift from traditional computation perspective to control perspective provides powerful techniques for performance improvement in the online solution of algebraic equations with time-varying parameters and external perturbations. In the future works, based on the control perspective approach presented in this paper, techniques in control, such as distributed control or internal model principle <ref type="bibr" target="#b38">[39]</ref>, can be utilized to construct RNN models for solving dynamic zero-finding problems with distributed topologies or with the ability to eliminate noises with known dynamics. In addition, various numerical algorithms can be generated by discretizing the proposed continuous RNN models with the aid of different numerical differential formulas and control techniques can be used to analyze their convergence, stability and robustness. These RNN models may open a door to the performance improvement of the related applications, e.g., robot control <ref type="bibr" target="#b39">[40]</ref> and path planning <ref type="bibr" target="#b40">[41]</ref>, with great capacity in tolerating noises and computing accuracy.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Performance of ||ǫ(t)|| F of nonconvex function activated ZNN model (7) with c 1 = 0.05, c 2 = 2, and c 3 = -2, where the initial state is randomly generated, for computing time-varying inverse of dynamic matrix<ref type="bibr" target="#b13">(14)</ref>. (a) Neural states of nonconvex function activated ZNN model<ref type="bibr" target="#b6">(7)</ref>, where the theoretical solution and computed solution are denoted by red dashed-dotted curves and blue solid curves, respectively. (b) ||ǫ(t)|| F of<ref type="bibr" target="#b6">(7)</ref>. (c) ǫ(t) of (7). (d) ǫ(t) of<ref type="bibr" target="#b6">(7)</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Residual errors ||ǫ(t)|| F of GNN model (10) with adaptive coefficient, where the initial state is randomly generated, with different value of c 4 , for computing time-varying inverse of dynamic matrix (14) in an inverse-free manner. (a) Neural states of GNN model (10) with adaptive coefficient, where the theoretical solution and computed solution are denoted by red dashed-dotted curves and blue solid curves, respectively. (b) ||ǫ(t)|| F of (10) with c 4 = 5. (c) ||ǫ(t)|| F of (10) with c 4 = 50.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Residual errors ||ǫ(t)|| F of nonlinear function activated GNN model<ref type="bibr" target="#b9">(10)</ref> with adaptive coefficient, where the initial state is set the same as that in Fig.2, with different value of c 4 , for computing time-varying inverse of dynamic matrix (14) in an inverse-free manner. (a) ||ǫ(t)|| F of (10) with c 4 = 5. (b) ||ǫ(t)|| F of (10) with c 4 = 50.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Residual errors synthesized by nonconvex function activated ZNN model (7) and GNN model (10) with adaptive coefficient for computing the inverse of Toeplitz matrix A(t) ∈ R 20×20 in Subsection V-C, where c 1 = 10, c 2 = 20, c 3 = -20, and c 4 = 50.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Application of nonconvex function activated ZNN model (7) to kinematic control of a two-link planar robot manipulator, where the nonconvex function is set the same as that in Fig. 1. (a) Profiles of θ. (b) Profiles of θ. (c) Position errors ε(t). (d) Simulated motion trajectory of the robot manipulator.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>1551-3203 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TII.2017.2717079, IEEE Transactions on Industrial Informatics</figDesc><table><row><cell>IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS</cell><cell>9</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>USA in 2014. He is currently a research assistant professor with Department of Computing, The Hong Kong Polytechnic University, Hong Kong. His current research interests include dynamic neural networks, robotic networks, and other dynamic problems defined on a graph. Bin Hu received Ph.D. degree in computer science from Institute of Computing Technology, Chinese Academy of Science, China in 1998. Since 2008, He has been a professor and the Dean of School of Information Science and Engineering, Lanzhou University, China. He had been also guest professorship in ETH Zurich, Switzerland till 2011. His research interests include Ubiquitous Intelligence, Computational Psychophysiology, and Data Modeling.</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work is supported by the National Natural Science Foundation of China (with number 61401385), by the Hunan Natural Science Foundation of China (No. 2017JJ3257 and No. 2017JJ3258), by the National Basic Research Program of China (973 Program) (No.2014CB744600), by the National Natural Science Foundation of China (No.61632014, and No.61210010), by the Program of Beijing Municipal Science &amp; Technology Commission (No.Z171100000117005), by the Program of International S&amp;T Cooperation of MOST (No.2013DFA11140), by Hong Kong Research Grants Council Early Career Scheme (with number 25214015), by Hong Kong Polytechnic University (with numbers G-YBMU, G-UA7L, 4-ZZHD, F-PP2C, 4-BCCS), and also by the Research Foundation of Education Bureau of Hunan Province, China (No. 17B215 and No. 17C1299). , IEEE Transactions on Industrial Informatics IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS 4</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Optimal control-based adaptive NN design for a class of nonlinear discrete-time block-triangular systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2670" to="2680" />
			<date type="published" when="2016-11">Nov. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Manipulability optimization of redundant manipulators using dynamic neural networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>La</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="4710" to="4720" />
			<date type="published" when="2017-06">Jun. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Time-scale expansion-based approximated optimal control for underactuated systems using projection neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1109/TSMC.2017.2703140</idno>
	</analytic>
	<monogr>
		<title level="m">Press with</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Neural network controlbased adaptive learning design for nonlinear systems with full state constraints</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L P</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learning Syst</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1562" to="1571" />
			<date type="published" when="2016-07">Jul. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">G2-type SRMPC scheme for synchronous manipulation of two redundant robot arms</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="153" to="164" />
			<date type="published" when="2015-02">Feb. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Distributed winner-take-all in dynamic networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>You</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Control</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="577" to="589" />
			<date type="published" when="2017-02">Feb. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Robust adaptive neural tracking control for a class of stochastic nonlinear interconnected systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learning Syst</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="510" to="523" />
			<date type="published" when="2016-03">Mar. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Neural-based adaptive output-feedback control for a class of nonstrict-feedback stochastic nonlinear systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1977" to="1987" />
			<date type="published" when="2015-09">Sep. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Understanding subtitles by characterlevel sequence-to-sequence learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yue</surname></persName>
		</author>
		<idno type="DOI">10.1109/TII.2016.2601521</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Informat</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Noise-tolerant ZNN models for solving time-varying zero-finding problems: A Control-Theoretic Approach</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Control</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="992" to="997" />
			<date type="published" when="2017-02">Feb. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Control Perspectives on Numerical Algorithms and Matrix Problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bhaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kaszkurewicz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>SIAM</publisher>
			<pubPlace>Philadelphia, PA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A control-theoretic approach to the design of zero finding numerical methods</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bhaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kaszkurewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Control</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1014" to="1026" />
			<date type="published" when="2007-06">Jun. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Control Liapunov function design of neural networks that solve convex optimization and variational inequality problems</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Pazos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">16-18</biblScope>
			<biblScope unit="page" from="3863" to="3872" />
			<date type="published" when="2009-10">Oct. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Iterative solution of linear systems in the 20th century</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Saad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Van Der</surname></persName>
		</author>
		<author>
			<persName><surname>Vorst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Computational Appl. Math</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="1" to="33" />
			<date type="published" when="2000-11">Nov. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improved neural solution for the Lyapunov matrix equation based on gradient search</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Process. Lett</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="876" to="881" />
			<date type="published" when="2013-11">Nov. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Electromagnetic compatibility estimator using scaled conjugate gradient backpropagation based artificial neural network</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Khadse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">B</forename><surname>Borghate</surname></persName>
		</author>
		<idno type="DOI">10.1109/TII.2016.2605623</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Informat</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Integration-enhanced Zhang neural network for real-time-varying matrix inversion in the presence of various kinds of noises</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learning Syst</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2615" to="2627" />
			<date type="published" when="2016-12">Dec. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Novel discrete-time Zhang neural network for time-varying matrix inversion</title>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yan</surname></persName>
		</author>
		<idno type="DOI">10.1109/TSMC.2017.2656941</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern., Syst</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Accelerating a recurrent neural network to finite-time convergence for solving time-varying Sylvester equation by using a sign-bi-power activation function</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Process. Lett</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="189" to="205" />
			<date type="published" when="2013-04">Apr. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Solving time-varying quadratic programs based on finite-time Zhang neural networks and their application to robot tracking</title>
		<author>
			<persName><forename type="first">P</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="693" to="703" />
			<date type="published" when="2015-04">Apr. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Design and analysis of FTZNN applied to real-time solution of nonstationary lyapunov equation and tracking control of wheeled mobile manipulator</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Informat</title>
		<imprint/>
	</monogr>
	<note>In press</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Complex neural network models for time-varying drazin inverse</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Stanimirović</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2790" to="2824" />
			<date type="published" when="2016-12">Dec. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Neural-Dynamic-Method-Based Dual-Arm CMG Scheme With Time-Varying Constraints Applied to Humanoid Robots</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learning Syst</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3251" to="3262" />
			<date type="published" when="2015-03">Mar. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Three recurrent neural networks and three numerical methods for solving repetitive motion planning scheme of redundant robot manipulators</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ASME Trans. Mechatro</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2017-03">Mar. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Recurrent neural network for computing the Drazin inverse</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Stanimirović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Živković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learning Syst</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2830" to="2843" />
			<date type="published" when="2015-11">Nov. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Recurrent neural network approach based on the integral representation of the Drazin inverse</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Stanimirović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Živković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2107" to="2131" />
			<date type="published" when="2015-10">Oct. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A robust algorithm for state-of-charge estimation with gain optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Muhammad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rafique</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Guan</surname></persName>
		</author>
		<idno type="DOI">10.1109/TII.2017.2699219</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Informat</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Finite-time convergent recurrent neural network with a hard-limiting activation function for constrained optimization with piecewise-linear objective functions</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="601" to="613" />
			<date type="published" when="2011-04">Apr. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Dynamical methods for polar decomposition and inversion of matrices</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Getz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Marsden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linear Algebra Appl</title>
		<imprint>
			<biblScope unit="volume">258</biblScope>
			<biblScope unit="page" from="311" to="343" />
			<date type="published" when="1997-06">Jun. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Taylor-type 1-step-ahead numerical differentiation rule for first-order derivative approximation and ZNN discretization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Appl. Math</title>
		<imprint>
			<biblScope unit="volume">273</biblScope>
			<biblScope unit="page" from="29" to="40" />
			<date type="published" when="2015-01">Jan. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Vibration control of a flexible robotic manipulator in the presence of input deadzone</title>
		<author>
			<persName><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Informat</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="48" to="59" />
			<date type="published" when="2017-11">Nov. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Adaptive neural network control of an uncertain robot with full-state constraints</title>
		<author>
			<persName><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="620" to="629" />
			<date type="published" when="2016-03">Mar. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Tricriteria optimization-coordination motion of dual-redundant-robot manipulators for complex path planning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<idno type="DOI">10.1109/TCST.2017.2709276</idno>
	</analytic>
	<monogr>
		<title level="m">Press with</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Recurrent neural network for computing the Drazin inverse</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rafique</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learning Syst</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2830" to="2843" />
			<date type="published" when="2015-11">Nov. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A novel recurrent neural network for manipulator control with improved noise tolerance</title>
		<author>
			<persName><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1109/TNNLS.2017.2672989</idno>
	</analytic>
	<monogr>
		<title level="m">Press with</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Adaptive neural network control of a marine vessel with constraints using the asymmetric barrier lyapunov function</title>
		<author>
			<persName><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yin</surname></persName>
		</author>
		<idno type="DOI">10.1109/TCYB.2016.2554621</idno>
	</analytic>
	<monogr>
		<title level="m">Press with</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Formation control of leader-follower mobile robots&apos; systems using model predictive control based on neuraldynamic optimization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L P</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="5752" to="5762" />
			<date type="published" when="2016-09">Sep. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Adaptive impedance control for an upper limb robotic exoskeleton using biological signals</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1664" to="1674" />
			<date type="published" when="2017-02">Feb. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Distributed task allocation of multiple robots: A control perspective</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1109/TSMC.2016.2627579</idno>
	</analytic>
	<monogr>
		<title level="m">Press with</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Cooperative motion generation in a distributed network of redundant robot manipulators with noises</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liao</surname></persName>
		</author>
		<idno type="DOI">10.1109/TSMC.2017.2693400</idno>
	</analytic>
	<monogr>
		<title level="m">Press with</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Long Jin received the B.E. degree and the PhD degree from Sun Yat-sen University</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<ptr target=".1109/TAC.2017.2694547" />
	</analytic>
	<monogr>
		<title level="m">His main research interests include neural networks, robotics, and intelligent information processing</title>
		<meeting><address><addrLine>Guangzhou, China; Kowloon, Hong Kong</addrLine></address></meeting>
		<imprint>
			<publisher>The Hong Kong Polytechnic University, Hung Hom</publisher>
			<date type="published" when="2011">2011 and 2016</date>
		</imprint>
	</monogr>
	<note>Press with DOI 10</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">M&apos;14) received the B.E. degree in Precision Mechanical Engineering from Hefei University of Technology</title>
		<author>
			<persName><forename type="first">Shuai</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">China in 2005, the M.E. degree in Automatic Control Engineering from University of Science and Technology of China, China in 2008, and the Ph.D. degree in</title>
		<imprint/>
		<respStmt>
			<orgName>Electrical and Computer Engineering from Stevens Institute of Technology,</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
