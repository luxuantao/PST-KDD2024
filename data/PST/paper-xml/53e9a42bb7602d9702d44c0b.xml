<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Temporal Streams in Commercial Server Applications</title>
				<funder>
					<orgName type="full">IBM</orgName>
				</funder>
				<funder ref="#_RknV3uP">
					<orgName type="full">NSERC</orgName>
				</funder>
				<funder>
					<orgName type="full">Intel</orgName>
				</funder>
				<funder ref="#_X83aYRS">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Advanced Computer Architecture Lab (ACAL)</orgName>
								<orgName type="institution">University of Michigan</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Computer Architecture Lab (CALCM)</orgName>
								<orgName type="institution">Ecole Polytechnique F?d?rale</orgName>
								<address>
									<addrLine>Carnegie Mellon University 3 I&amp;C School</addrLine>
									<settlement>Lausanne</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Ferdman</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Computer Architecture Lab (CALCM)</orgName>
								<orgName type="institution">Ecole Polytechnique F?d?rale</orgName>
								<address>
									<addrLine>Carnegie Mellon University 3 I&amp;C School</addrLine>
									<settlement>Lausanne</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anastasia</forename><surname>Ailamaki</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Computer Architecture Lab (CALCM)</orgName>
								<orgName type="institution">Ecole Polytechnique F?d?rale</orgName>
								<address>
									<addrLine>Carnegie Mellon University 3 I&amp;C School</addrLine>
									<settlement>Lausanne</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Babak</forename><surname>Falsafi</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Computer Architecture Lab (CALCM)</orgName>
								<orgName type="institution">Ecole Polytechnique F?d?rale</orgName>
								<address>
									<addrLine>Carnegie Mellon University 3 I&amp;C School</addrLine>
									<settlement>Lausanne</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andreas</forename><surname>Moshovos</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Dept. of ECE</orgName>
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Temporal Streams in Commercial Server Applications</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Commercial server applications remain memory bound on modern multiprocessor systems because of their large data footprints, frequent sharing, complex non-strided access patterns, and long chains of dependant misses. To improve memory system performance despite these challenging access patterns, researchers have proposed prefetchers that exploit temporal streams-recurring sequences of memory accesses. Although prior studies show substantial performance improvement from such schemes, they fail to explain why temporal streams arise; that is, they treat commercial applications as a black box and do not identify the specific behaviors that lead to recurring miss sequences. In this paper, we perform an information-theoretic analysis of miss traces from single-chip and multi-chip multiprocessors to identify recurring temporal streams in web serving, online transaction processing, and decision support workloads. Then, using function names embedded in the application binaries and Solaris kernel, we identify the code modules and behaviors that give rise to temporal streams.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Off-chip memory accesses continue to pose a critical performance bottleneck in commercial server applications <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b24">25]</ref>. Extensive research has shown that widely-deployed stride-based prefetchers provide only limited benefit for many server applications, such as online transaction processing and web serving, because these applications are dominated by pointer-based data structures with complex, non-strided access patterns <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b24">25]</ref>.</p><p>To improve performance for these access patterns, over a decade of research has lead to the development of address-correlating prefetchers, which exploit correlation between consecutive memory accesses and are highly-effective for pointerbased structures <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b24">25]</ref>. Building on this line of research, the latest proposals prefetch extended sequences of memory accesses that recur over the course of program execution <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b24">25]</ref>. We adopt the terminology of <ref type="bibr" target="#b24">[25]</ref> and refer to these recurring memory access sequences as temporal streams.</p><p>Although prior studies present a variety of hardware designs and demonstrate substantial performance gains from temporal streams, they fail to explain the specific application behaviors that result in the underlying phenomenon of miss sequence repetition. Because of the difficulty in analyzing the behavior of large-scale closed-source applications, these studies have taken a "black-box" approach to all but the simplest of scientific applications.</p><p>Furthermore, prior studies have considered only a single system organization, focusing either on uniprocessors <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b20">21]</ref> or multi-chip distributed-shared-memory systems <ref type="bibr" target="#b24">[25]</ref>. As we will show, server applications' off-chip miss behavior changes drastically when all cores are located on a single chip, because coherence activity and contention are captured entirely within that chip. As multi-core system size and diversity increase, users will expect scalable performance whether or not all cores are collocated. Hence, it is critical to understand the impact of multiprocessor organization on memory access behavior.</p><p>In this paper, we present a hardware-independent study of temporal streams across single-chip and multi-chip multiprocessors. We identify temporal streams using a previouslyproposed information-theoretic analysis that locates repetitive access sequences of arbitrary length without any assumptions about specific prefetching implementation <ref type="bibr" target="#b6">[7]</ref>. Furthermore, by inspecting the call stack at each access, we build a profile of specific code modules within our commercial applications and the Solaris kernel that lead to cache misses and temporal streams. Through analysis of user and operating system cache miss traces generated through full-system simulation, we demonstrate:</p><p>? Miss classification across system organizations. We classify miss behavior using categories similar to the "4 C's" model <ref type="bibr" target="#b11">[12]</ref>. Our results confirm prior observations that up to 80% of off-chip misses are coherence-induced in multi-chip multiprocessors <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b24">25]</ref>; however, a single-chip multiprocessor captures this communication traffic on chip, and off-chip behavior is instead dominated by capacity and I/O-induced misses.</p><p>? Information-theoretic analysis of temporal streams. Our hardware-independent stream analysis reveals that 40-80% of off-chip misses are part of temporal streams; that streams are typically long, with a median length of eight misses; and that the reuse distance between consecutive occurrences of a stream varies drastically across coherence-induced (100's of intervening misses) and capacityinduced (10,000's of misses) streams.</p><p>? Application-level origins of temporal streams. Our analysis of the specific functions and modules that give rise to temporal streams reveals a great diversity of application and OS functionality that results in miss repetition. With the exception of frequent bulk memory copies in decision support workloads, no single source accounts for more than 25% of temporal streams. This result demonstrates the success of years of optimization and tuning effort expended on these commercial applications: no obvious, dominant memory bottlenecks remain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Temporal Streams</head><p>A temporal stream is a sequence of two or more cache misses that occurs at least twice during program execution <ref type="bibr" target="#b24">[25]</ref>. Temporal streams extend the notion of address correlation to sequences rather than pairs of misses. Although the term "temporal stream" was introduced in <ref type="bibr" target="#b24">[25]</ref>, a wide variety of recent prefetchers rely on the same underlying phenomenon, including hot data stream prefetching <ref type="bibr" target="#b6">[7]</ref>, the global history buffer <ref type="bibr" target="#b18">[19]</ref>, the user-level memory thread <ref type="bibr" target="#b20">[21]</ref>, epoch-based correlation prefetching <ref type="bibr" target="#b7">[8]</ref>, and last-touch correlated data streaming <ref type="bibr" target="#b8">[9]</ref>.</p><p>Prefetching mechanisms exploit temporal streams by recording miss-address sequences in tables or circular buffers, locating a previously-seen sequence upon a subsequent miss, and then prefetching the recorded addresses. In this study, we analyze temporal streams directly, ignoring the details of individual prefetching mechanisms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Motivating Examples</head><p>To illustrate why memory accesses in commercial applications often occur in temporal streams, we present two motivating examples taken from actual behaviors observed in our commercial application suite. These examples demonstrate a variety of the characteristics we observe in temporal streams-that streams are long, repeat across cores, evolve over time, and are generally distinguishable based on their initial "head" address.</p><p>Although these examples are real, we have chosen them for their usefulness in illustrating stream characteristics; they are not the largest sources of miss repetition (see <ref type="bibr">Section 5)</ref>.</p><p>Example one: B+-tree range scans. The B+-tree, one of the critical data structures used in database applications, enables the efficient insertion, removal, and search for database records <ref type="bibr" target="#b3">[4]</ref>. A B+-tree maintains a sorted index of records according to a key constructed from one or more fields in the record. Each B+-tree node contains a sorted key list with pointers to children, such that the range of keys within a child's subtree is bounded by two adjacent keys in the parent.</p><p>The leaves of the B+-tree point to tuple identifiers that indicate the location of a corresponding database record. The record(s) for a particular key can be located rapidly through a combination of binary search within each node and traversal from the root to the child containing the key.</p><p>A distinguishing feature of the B+-tree is the horizontal pointers that connect sibling leaves of the tree. These horizontal links enable fast in-order tree traversals, and are used to implement range scans. To scan over a set of records from some lower to some upper key, the database engine first locates the lower key. Then, it traverses horizontally along sibling links until it reaches the upper key.</p><p>Overlapping range scans result in temporal streams following these sibling links. The first range scan results in a miss sequence for leaves along the bottom of the tree. A second, overlapping range scan will access the same leaves in the same order. As leaves are typically not contiguous in memory, the leaf access sequence cannot be captured by stride prefetchers. Since the B+tree is a shared data structure, the temporal streams arising from scans recur across processors in a multiprocessor system.</p><p>Example two: Solaris thread scheduler. One of the key innovations of Solaris 2.3-introduced nearly 15 years ago, but still used in current Solaris releases-is per-processor dispatch queues <ref type="bibr" target="#b17">[18]</ref>. In the earliest versions of Solaris, and older UNIX implementations, a single queue maintained pointers to all runnable threads waiting to be scheduled on a processor. To improve Solaris's multiprocessor scalability, this single dispatch queue was split into a real time queue and per-processor dispatch queues, each protected by separate locks, allowing multiple dispatch queues to be accessed or modified concurrently. A complicated set of thread prioritization and affinity algorithms determines to which queue and at which location a thread should be inserted when it becomes runnable.</p><p>In most cases, when the thread currently running on a processor blocks or exhausts its time quantum, the processor simply scans its own dispatch queue to identify which thread to run next. However, if its dispatch queue is empty, the processor tries to steal a runnable thread off another processor's queue. It scans other queues looking for the highest priority available thread (in the kernel functions disp_getwork() and disp_getbest()), removes the thread from the queue (via dispdeq()), and finally confirms that no higher priority thread has since become runnable (via disp_ratify()). These functions account for an astounding number of misses in commercial applications, as much as 12% of all off-chip misses.</p><p>These functions incur many coherence misses to the locks that protect each dispatch queue and the linked lists that comprise the queues. These miss sequences are highly repetitive because all processors scan the dispatch queues in the same order, starting with the real-time priority queue and then advancing through the linked list that connects the dispatch queues. Because the locks remain at fixed addresses, and the queues themselves change little between scans, the misses form temporal streams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Analysis Methodology</head><p>We apply an information-theoretic approach to quantify the prevalence and characteristics of temporal streams. Like similar studies of repetition in L1 data accesses <ref type="bibr" target="#b6">[7]</ref> and program paths <ref type="bibr" target="#b15">[16]</ref>, we use the SEQUITUR hierarchical data compression algorithm <ref type="bibr" target="#b9">[10]</ref> to identify repetitive sub-sequences within the miss traces.</p><p>The SEQUITUR compression algorithm. SEQUITUR constructs a grammar whose production rules correspond to repetitions in its input. Each production rule maps a label to a sequence of symbols and other rule labels. SEQUITUR operates by incrementally extending the grammar's root production rule by one symbol at a time. As each symbol is appended, the grammar is modified to create new production rules that capture any new repetition the appended symbol creates. SEQUITUR maintains two invariants as the grammar grows. First, no pair of symbols are adjacent more than once in the grammar. Second, every production rule in the grammar (except the root rule) is used more than once. As a result of these invariants, the grammar's rules correspond to distinct repetitive sequences (a.k.a. temporal streams).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System contexts.</head><p>We analyze read miss traces from three system contexts: (1) off-chip misses in multi-chip multiprocessor (referred to as "multi-chip" in the results), (2) off-chip misses in single-chip multi-core system ("single-chip"), and (3) intrachip misses in the single-chip system; that is, hits in shared onchip caches ("intra-chip"). Our traces include all user and OS read misses.</p><p>Our multi-chip model is a 16-node distributed-shared-memory multiprocessor based on the system in <ref type="bibr" target="#b24">[25]</ref>. Each node comprises a single processor with split 2-way 64KB L1 I and D caches and a unified 16-way 8MB L2 cache. We chose a 64KB L1 size because this is roughly the upper bound seen in recent commercial systems for one-to two-cycle access times. We chose an 8MB L2 because investigation of miss rates across cache sizes in our database workloads indicate that 8MB is sufficient to capture first-order temporal locality in the applications' data footprints <ref type="bibr" target="#b10">[11]</ref>. We model an MSI coherence protocol.</p><p>Our single-chip model is a 4-core system with split 64KB L1 I and D caches and a shared 16-way 8MB L2 cache, chosen to approximate a contemporary multi-core. The L1s and shared L2 implement a MOSI coherence protocol based closely on Piranha <ref type="bibr" target="#b1">[2]</ref>. The hierarchy is non-inclusive. Other system details do not materially affect traces.</p><p>Applications. Our analysis covers three commercial application classes. Table <ref type="table" target="#tab_0">1</ref> enumerates their configuration details. We run all applications on top of Solaris 8.</p><p>We include OLTP and DSS workloads running on IBM DB2 v8 ESE. Our OLTP workload is an optimized TPC-C 3.0 toolkit provided by IBM. We select three queries from the TPC-H DSS workload based on the categorization in <ref type="bibr" target="#b19">[20]</ref>: one scandominated query, one join-dominated query, and one query exhibiting mixed behavior. We evaluate web server behavior with the SPECweb99 benchmark on Apache HTTP Server v2.0 and Zeus Web Server v4.3. We simulate a separate client system and collect memory traces only on the server.</p><p>Trace collection. We collect cache miss traces with the FLEXUS full-system simulation infrastructure <ref type="bibr" target="#b25">[26]</ref>. FLEXUS builds on Virtutech Simics <ref type="bibr" target="#b16">[17]</ref> and supports both rapid tracebased and detailed cycle-accurate simulation of a variety of uni-and multiprocessor system organizations.</p><p>We collect read miss traces in FLEXUS with in-order execution and no memory system stalls. For OLTP and web workloads, we warm main memory for at least 5000 transactions or requests prior to starting traces, and then trace at least 1000 transactions. For DSS queries, we analyze queries 2 and 17 in their entirety, and a trace of over three billion instructions taken from query 1 at steady-state. We have verified that varying trace start location has minimal impact on results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Code module analysis.</head><p>With the exception of Apache, we do not have access to the source code of any of the commercial applications in this study. Instead, we exploit the function names embedded in the commercial software and Solaris to tie misses to specific function invocations. By analyzing the call stack at each miss, we can identify an enclosing function with a recognizable purpose. We then group functions into larger categories based on module naming conventions adorning the function names. Fortunately, both Solaris and DB2 frequently prefix function names with an identifier of the module to which it belongs.</p><p>Our results are based on a best-effort categorization by iterative refinement of the assignment of functions to categories. In most cases, the purpose of a particular module is apparent from its function names. For Solaris, several public resources document the kernel implementation details (e.g., <ref type="bibr" target="#b17">[18]</ref>). Furthermore, with the release of OpenSolaris in 2006, we can examine much of the kernel source code, with the caveat that the code may have changed since the Solaris release we study (Solaris 8). Our categorizations have not been reviewed or endorsed by the organizations that produced these products.</p><p>Our FLEXUS tracing infrastructure collects a descriptor for the currently-running thread and a call stack at each miss. We obtain an index of threads, symbol names, and corresponding virtual address ranges using the Solaris kernel debugger, mdb, and the nm utility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Temporal Stream Characterization</head><p>We first report on the quantitative characteristics of temporal streams in our application suite. Like prior studies, these results take a "black box" analysis approach. We "open the box" to report on our code analysis in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Miss Classification</head><p>We begin by classifying misses using a categorization based on the "four C's model" <ref type="bibr" target="#b11">[12]</ref>. These high-level breakdowns demonstrate the substantial differences in miss behavior across single-chip and multi-chip contexts. Furthermore, the breakdown allows us to immediately identify miss subsets that are not repetitive, and gives insight into later results.</p><p>We Replacement for all remaining misses, which may be capacity or conflict misses (as our L2 caches are 16-way associative, most are capacity misses). We report the results in Figure <ref type="figure">1</ref> (left). The vertical axis shows the number of misses per thousand instructions.</p><p>In Figure <ref type="figure">1</ref> (right), we classify intra-chip misses based on their cause and the hierarchy level that supplied the response. Because of the allocation policies of the Piranha intra-chip coherence protocol, coherence misses may be satisfied by a peer L1 or the shared L2. All other L2 hits are the result of L1 replacement misses. We aggregate L2 misses into a single Offchip category, which corresponds to the single-chip breakdown in Figure <ref type="figure">1</ref> (left).</p><p>Discussion. Our measurements corroborate prior conclusions that coherence misses tend to dominate in multi-chip systems with large L2 caches <ref type="bibr" target="#b2">[3]</ref>. In the intra-chip context, we also observe a substantial fraction of misses from coherence activity between cores despite the small capacity of the L1 caches-roughly one third to one half of all L2 and peer-L1 accesses result from coherence. There is no (non-I/O) off-chip coherence activity in single-chip. In the DSS workloads, compulsory misses dominate across contexts, as many data are visited only once.</p><p>Coherence misses form temporal streams when locks and read-write shared data structures with repetitive traversal patterns are transferred among cores. Replacement misses comprise streams when a repetitive traversal accesses a data structure that exceeds the cache's capacity or traversals are separated by many intervening accesses. Unlike these two categories, compulsory misses, by definition, do not repeat a prior miss sequence and cannot form temporal streams. A key shortcoming of temporal-stream prefetching is that it cannot address compulsory misses (unlike stride-based prefetchers, which can eliminate compulsory misses).</p><p>I/O coherence misses arise from two sources, blocks invalidated by DMA transfers, and blocks written by bulk kernel-touser buffer copies (the Solaris default_copyout family of functions; these functions use special store instructions that do not allocate in the cache hierarchy). About half of the misses arise from each source. In principle, misses in either category could form temporal streams if I/O buffers are reused. In practice, we find that DMA transfers rarely reuse buffers over the time-scales covered by our traces (seconds of execution), whereas kernel-to-user copies aggressively reuse buffers. Nonetheless, we expect that temporal streams provide no advantage over existing prefetching schemes as these accesses are typically strided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Fraction of misses in temporal streams</head><p>Using the SEQUITUR algorithm, we identify temporal streams in our miss traces. In Figure <ref type="figure">2</ref>, we show the fraction of misses that are part of the first occurrence of a temporal stream (New stream), the second or subsequent occurrence of a stream (Recurring stream), or not part of any stream (Non-repetitive).</p><p>Discussion. Our results confirm prior studies <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b24">25]</ref>: a substantial miss fraction, 35%-90%, occurs in temporal streams. In the web applications, temporal streams account for 75-80% of off-chip misses. In the multi-chip context, these applications are dominated by coherence activity, nearly all of which is repetitive. In the single-chip context, as much as 20% of offchip accesses arise as a result of I/O coherence. Unlike database workloads, the I/O activity in web applications is repetitive, as it involves many kernel-to-user copies from reused buffers.</p><p>In contrast to the web workloads, OLTP exhibits a stark difference in miss repetition across contexts. Coherence activity dominates in the multi-chip and intra-chip contexts. Past studies attribute the high proportion of coherence activity in OLTP to locking and read-write meta-data structures (e.g., active transaction tables, cursors, log management) <ref type="bibr" target="#b2">[3]</ref>. Our code module analysis (see Section 5) finds that OS scheduling and synchronization primitives also contribute substantially. OLTP coherence activity is remarkably repetitive. In the single-chip context, there is much less repetition: half are either compulsory or non-repetitive I/O coherence misses, leaving only limited opportunity in the remaining replacement misses for temporal streaming.</p><p>The DSS queries show an even larger fraction of non-repetitive compulsory misses. These queries all scan tables that exceed the database's buffer pool capacity. Tuples from the largest table are visited only once. Hence, we observe a substantial proportion of non-repetitive I/O coherence as data is scanned and discarded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Strided patterns and temporal streams</head><p>Whether a sequence of accesses forms a temporal stream is orthogonal to whether it follows a constant stride. We present a joint breakdown of strided and repetitive miss sequences in Figure <ref type="figure" target="#fig_0">3</ref>. The solid segments of the bar correspond to temporal streams (Repetitive), while the upper-most and lower-most segments correspond to stride-predictable accesses (Strided).</p><p>Discussion. In the case of DSS queries, many accesses, both within and outside of temporal streams, follow strided patterns, particularly within the single-chip context. Temporal streams are unlikely to provide much benefit for single-chip DSS workloads. Coherence misses in the multi-chip and intrachip context are not strided, but still tend to be repetitive, offering some opportunity for synergy between stride and temporal stream prefetching. In the remaining applications, only a small fraction of misses are strided. Moreover, strided patterns and temporal streams are largely disjoint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Temporal stream length</head><p>Stream length is a critical factor affecting the usefulness of temporal streams. Long streams amortize prefetch costs (e.g., off-chip lookup latency <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b24">25]</ref>). However, long streams may also imply the need to throttle stream retrieval-a long stream cannot be buffered entirely on chip without displacing other potentially-useful data.</p><p>For each application and context, we construct a cumulative distribution of stream lengths weighted by their total contribution to temporal streams. Hence, the cumulative distribution shows the relative importance of long and short streams, and the 50th percentile corresponds to the median stream length.</p><p>The cumulative distributions appear in Figure <ref type="figure">4</ref> (left). Stream length is plotted logarithmically on the horizontal axis.</p><p>Discussion. The most critical observation we draw from these results is that streams are generally quite long-in all cases the median stream length exceeds the fixed prefetch depths of many prior proposals <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21]</ref>. Overall, the median stream length is eight to ten cache blocks, and thousand-block streams are not unusual.</p><p>Furthermore, we observe that there is enormous variation in stream length, from as few as two to many thousands of blocks. The variation in stream length argues against fixeddepth fetch policies-there is no one size that fits all temporal streams, within or across applications.</p><p>Stream length variability also complicates stream storage. Assuming a fixed length for streams allows a simple set-associative table to map stream heads to their bodies <ref type="bibr" target="#b20">[21]</ref>. Supporting streams with lengths that vary over three orders of magnitude precludes such a simple design.</p><p>The DSS applications tend to exhibit longer streams than the other applications, a trend that is particularly apparent in the single-chip context. The large step at the right edge arises from streams that access approximately 4KB, which corresponds to the OS page size. Nearly all of the DSS streams longer than 512 bytes arise from bulk memory copies and are easily captured by simple stride predictors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Stream reuse distance</head><p>The distance between two occurrences of a temporal stream provides insight into the time-scale over which data structure traversals repeat and is a critical indicator of the storage requirements for streams.</p><p>To divorce the notion of stream reuse distance from time or performance, we measure reuse distance as the number of misses between two stream occurrences. As we study multiprocessors, the two occurrences may not be on the same processor. We count the number of intervening misses on the first processor, as this measure corresponds directly to the storage  required to remember the stream in a log of all misses at the first processor <ref type="bibr" target="#b24">[25]</ref>.</p><p>We report the probability density function of reuse distance in Figure <ref type="figure">4</ref> (right). We truncate the distribution at ten million misses as such distances correspond to substantial real execution time (approaching one second of wall-clock time) and are unlikely to be exploited by prefetching.</p><p>Discussion. Coherence misses typically have far shorter reuse distances than replacement misses. A replacement miss implies that the corresponding block has been displaced by other cache allocations. As L2 capacities are large, typically thousands of L2 misses occur between a block's allocation and eviction. Blocks accessed more frequently than every ten thousand misses will not be evicted from L2, which places a soft lower bound on replacement miss reuse distance. In contrast, coherence-miss reuse distances are determined by the distance between production and consumption of shared data, and can be arbitrarily short (near zero in cases of contention).</p><p>The critical difference between the reuse behavior of these two miss classes results in the substantial difference in the center of mass of the reuse distributions across contexts. As the multi-chip context is dominated by coherence activity, reuse distances tend to be short, and nearly all stream reuse distances are below ~200,000 misses. Intra-chip temporal streams also frequently exhibit low reuse distances: in addition to coherence activity, intra-chip replacement streams may recur frequently because L1 capacity is limited (1000 lines).</p><p>In contrast, in the single-chip context, reuse distances tend to be much longer, with the longest distances approaching ten million misses. In single-chip, replacement misses dominate. Replacement misses have high reuse distances because of the substantial L2 capacity. The key implication of this result is that single-chip systems will require larger storage to track the same fraction of temporal streams as multi-chip systems.</p><p>Several peaks in the DSS reuse distance distribution arise from specific query behaviors, and are not representative of average </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>multi-chip</head><p>behavior. Query one exhibits a reuse distance peak below ten misses. These misses are the result of the lock contention. All three queries exhibit peaks just under 10,000 misses in all contexts. These peaks arise from the bulk kernel-to-user copies of data arriving from disk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Code Module Analysis</head><p>Our previous results have demonstrated that the vast majority of misses in commercial applications are repetitive. However, the black-box approach of our trace analyses does not tell us why temporal streams arise. In this section, we provide quantitative evidence that ties temporal streams to specific application behaviors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Miss categories.</head><p>We briefly describe each miss category in Table <ref type="table" target="#tab_5">2</ref>. For easier comparison across applications, we divide categories into those that apply to all three application classes and those specific to each. In the following tables, we report each category's contribution to the overall miss breakdown, and the fraction of misses within a category that are part of temporal streams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Web applications</head><p>One of the most surprising results of our web server analysis is that the http server software itself accounts for only a tiny fraction of memory activity-about 3% of off-chip misses and 5% of L1 misses. Instead, activity is dominated by the communication between perl scripts that generate dynamic page content, the web server software, and kernel interfaces that send http replies to the network. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cross-application categories</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bulk memory copies</head><p>Kernel and user memory copy functions, such as memcpy, bcopy, __align_cpy_1, and default_copyout. This last function is particularly notable as it copies the results of I/O arriving via DMA from kernel to user buffers, and figures prominently in the overall contribution of memory copies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System call implementation</head><p>Kernel functionality invoked on behalf of user threads within system call interfaces. The most frequent system calls all involve I/O, with poll, open, read, write, and stat dominating.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Kernel task scheduler</head><p>Functions that perform kernel thread prioritization and dispatching, as briefly described in Section 2.1. Extensive discussion of the operation of the Solaris scheduler appears in <ref type="bibr" target="#b17">[18]</ref>.</p><p>Kernel MMU and trap handlers Functions (other than system calls) that are entered via the kernel's trap vector table. The most frequent traps are the instruction_access_MMU_miss and data_access_MMU_miss traps, which fill virtual-to-physical translations into the on-chip MMU from software caches and page tables. Register window management traps, where a window of eight integer registers are read from or written to a software stack, also contribute substantially. SPARC trap handling is described in detail in <ref type="bibr" target="#b23">[24]</ref>.</p><p>Kernel synchronization primitives Solaris-supplied mutex and condition variable primitives. This category also includes functions that manage the linked lists of threads waiting on a mutex or condition variable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Kernel -other activity</head><p>All remaining functionality that can be definitively tied to the Solaris kernel but is not part of a category that stands out as a major contributor to memory access behavior in any application or context. Many of the functions in this category deal with various forms of kernel memory and resource management.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Web-specific categories</head><p>Kernel STREAMS Implementation of stream based I/O, such as stdin and stdout. Consists largely of functions that move pointers to strings or portions of strings among thread-safe queues.</p><p>Kernel IP packet assembly Functions that divide data written to sockets into individual IP packets.</p><p>Web server worker threads All activity within either Apache or Zeus-perhaps surprisingly, relatively little of the overall SpecWeb activity occurs in web server code: most operations are performed by the OS on behalf of the web server.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CGI -perl input processing</head><p>A single function, Perl_sv_gets, which parses the requests passed from the web server to perl.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CGI -perl execution engine</head><p>The Perl_pp_* functions, which implement the primitive operations that make up perl's control flow graph. Examples include Perl_pp_const, Perl_pp_print, and Perl_pp_return.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CGI -perl other</head><p>Other functionality of perl that is not readily identifiable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DB2-specific categories</head><p>Kernel block device driver A small number of functions that manage I/O to block devices, such as disks.</p><p>DB2 index, page, and tuple accesses Functions in the sqli, sqld, and sqlpg modules of DB2. The sqli module accounts for most of this category, and includes functions which manipulate and traverse indices. The example we describe in Section 2.1 arises in this category. The sqld module includes functions that access individual database rows, such as sqldRowUpdate or sqldRowFetch. The sqlpg module includes functions that manipulate entire buffer pool pages, such as flushing pages to disk or calculating page checksums.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DB2 SQL request control</head><p>The DB2 modules sqlrr and sqlra which manipulate context information for a particular database transaction/ request (e.g., state of database cursors).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DB2 interprocess communication</head><p>Functions which pass data between the DB2 server and client processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DB2 SQL runtime interpreter</head><p>The sqlri module. The functions in this module implement primitive operations that appear in a parsed database execution plan, analogous to the Perl_pp_* functions of the perl interpreter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DB2 -other activity</head><p>Any other DB2 functionality whose overall contribution to misses is small or where function names do not allow us to determine their functionality.</p><p>SPECWeb specifies that some client web requests be satisfied by static pages served by the web server, and some by dynamic pages that are generated via the web server's Common Gateway Interface (CGI). The majority of web server activity arises from the creation and delivery of these dynamic pages. Much of the tuning of a SPECWeb implementation centers on careful orchestration of the CGI interaction. Our workloads employ the FastCGI interface, where a pool of perl processes await client requests, and the web server dispatches requests to an available process as requests arrive <ref type="bibr" target="#b4">[5]</ref>. FastCGI drastically improves performance over traditional CGI by avoiding process creation overheads on each request. The web server and perl communicate using the standard I/O streams, which are implemented in Solaris's STREAMS sub-system.</p><p>The interprocess communication implemented in STREAMS results in many temporal streams. The STREAMS code breaks data passed via read and write system calls into individual messages, which pass through a series of modules that may perform various processing steps, such as packetization or header assembly <ref type="bibr" target="#b22">[23]</ref>. The kernel STREAMS code manages synchronization and message passing among modules. Both the locks and the manipulation of message pointers within these queues result in highly-repetitive access sequencesabout 80% occur in temporal streams.</p><p>The perl processes that generate the dynamic web content also exhibit many temporal streams, albeit somewhat less repetitive than kernel activities. The function that parses the input to the dynamic content generation scripts, Perl_sv_gets, is the single most repetitive function we have identified, with just under 99% of its misses repeating a prior temporal stream. The implementations of individual perl statements and expressions also result in about 75% repetitive miss behavior. We conjecture that misses in the perl execution engine repeat because each of the thousands of requests invoke the same script, and hence traverse the same control flow graph. Thus, accesses to control flow graph representation within the execution engine are likely to repeat.</p><p>Within OS activity, the largest miss contributor is system calls, in particular, poll. This system call is used by the web server to accept incoming connections and pass them to a worker thread for processing.</p><p>Because of the many http and perl threads created to keep up with incoming requests, the OS scheduler and synchronization primitives result in many temporal streams (see example two in Section 2.1). The repetitive synchronization activity arises mostly from Solaris condition variables, where manipulation of queues of sleeping threads are the likely source of temporal streams.</p><p>Finally, we note that bulk memory copies account for a substantial fraction of misses, particularly in the single-chip context. More than half of these copies are repetitive. We have found that the repetitive copies arise because of reused I/O buffers for incoming network data.</p><p>Although perl's behavior may be an artifact of SPECWeb, many of the other temporal streams we observe are inherent in web serving. For example, the STREAMS and IP packet assembly code must be exercised by any web server on Solaris. Scheduling and synchronization activity will also occur in any busy web server, as current web servers maintain hundreds to thousands of threads for servicing incoming connections. Hence, we believe our results broadly represent web serving beyond the specific workloads studied here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Online transaction processing</head><p>The most significant miss sources in OLTP are the index, tuple, and page accesses issued to the database buffer pool, accounting for between one sixth and one fifth of all misses. Within this category, index accesses are the largest contributor (see example one in Section 2.1).  The higher layers of the DB2 execution engine, which build transaction and query processing capabilities on top of the storage manager interface, are more repetitive than the buffer pool management functionality. The transaction management, execution plan interpreter, and interprocess communication components all exhibit 90% repetition. These observations support prior conjecture that the coherence activity in databases comes from meta-data-data structures that do not reside on disk or within the buffer pool, such as locks, transaction tables, or the query plans manipulated by the optimizer and runtime interpreter <ref type="bibr" target="#b2">[3]</ref>. We expect these repetitive activities to arise in any transaction-oriented database workload, even if accesses to the data managed within the database are not repetitive.</p><p>The Solaris scheduler and synchronization primitives contribute substantially to the miss profiles where coherence activity plays a significant role (multi-chip, intra-chip), but are absent in the single-chip system. This profile is characteristic of coherence activity to a relatively small number of addressescache lines migrate between processors, but are never evicted due to capacity constraints.</p><p>Within the Solaris kernel, we see that trap handlers, and in particular traps filling translations into the SPARC MMU, result in a large number of temporal streams. A single page table lookup can require several main memory accesses, and, since many mappings are loaded repetitively into the MMU, the misses incurred during the translation process repeat.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Decision support</head><p>The obvious characteristic of DSS miss breakdowns is the prominence of bulk memory copies. Half or more of all memory access activity arises from these copies. The copies tend to be of power-of-two sizes, with page-sized 4KB copies most frequent. Unlike in the web applications, where bulk copies are often repetitive, copies in DSS do not reuse buffers and are generally non-repetitive. It is the prevalence of these copies that renders temporal streams all but useless for DSS workloads-bulk copies are either bandwidth bound, or already addressed by far simpler stride prefetchers.</p><p>The second most important miss contributors in DSS are index and tuple accesses, as in OLTP workloads. However, unlike OLTP, off-chip misses in these functions are not repetitivethe DSS workloads typically scan over data only once. We do observe some intra-chip repetition. We attribute this to the nested-loop joins in queries 2 and 17, which loop over portions of a database table that exceed L1, but do not exceed L2 capacity. In general, we conclude that DSS workloads exhibit few temporal streams because most data are visited only once.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>To our knowledge, our study is the first to identify specific application/OS behaviors that lead to the recurring temporal streams underlying a variety of prefetching techniques. Temporal streams are inherent in many programming idioms; onehalf to three-quarters of misses occur in streams. Streams are frequently tens, hundreds, and even thousands of misses long. Furthermore, we observe drastic differences between the offchip access patterns of single-and multi-chip multiprocessors, which have critical implications on the design and storage requirements of prefetching in general, and temporal streams in particular.</p><p>The memory access activity in commercial server applications is spread over a wide variety of functionality, with no particular activity standing out. We believe this flat distribution is a testament to the years of investment in optimizing these applications-any code that produced disproportionate misses has been stamped out. Furthermore, the lack of outlying "bad" behavior illustrates why it is so challenging to optimize these applications further, and why we must resort to mechanisms as   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIGURE 3 :</head><label>3</label><figDesc>FIGURE 3: Strides and temporal streams.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 : Application parameters.</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell>Online Transaction Processing (TPC-C on DB2)</cell></row><row><cell>OLTP</cell><cell>100 warehouses (10 GB), 64 clients, 450 MB buffer pool</cell></row><row><cell></cell><cell>Decision Support (TPC-H on DB2)</cell></row><row><cell>Qry 1</cell><cell>Scan-dominated, 450 MB buffer pool</cell></row><row><cell>Qry 2</cell><cell>Join-dominated, 450 MB buffer pool</cell></row><row><cell>Qry 17</cell><cell>Balanced scan-join, 450 MB buffer pool</cell></row><row><cell></cell><cell>Web Server</cell></row><row><cell>Apache</cell><cell>16K connections, FastCGI, worker threading model</cell></row><row><cell>Zeus</cell><cell>16K connections, FastCGI</cell></row></table><note><p>classify off-chip misses as: Coherence if the cache block was written by another processor since last read at this processor; I/O Coherence if the block was written by a DMA transfer or OS-to-user bulk memory copy; Compulsory if the corresponding cache block has never previously been accessed; and</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Miss classification for off-chip misses (left) and intra-chip misses (right).</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell cols="2">Compulsory</cell><cell cols="4">I/O Coherence</cell><cell></cell><cell cols="2">Replacement</cell><cell></cell><cell cols="3">Coherence</cell><cell></cell><cell></cell><cell></cell><cell>Off chip Off-chip</cell><cell>Replacement:L2 Replacement:L2</cell></row><row><cell></cell><cell></cell><cell>14 14</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>25</cell><cell>Coherence:L2</cell><cell>Coherence:Peer-L1</cell></row><row><cell></cell><cell></cell><cell>12</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ff-chip read misses Of</cell><cell>r 1000 instructions per</cell><cell>2 4 6 8 10 -</cell><cell>multi-chip</cell><cell>single-chip</cell><cell>multi-chip</cell><cell>single-chip</cell><cell>multi-chip</cell><cell>single-chip</cell><cell>multi-chip</cell><cell>single-chip</cell><cell>multi-chip</cell><cell>single-chip</cell><cell>multi-chip</cell><cell>single-chip</cell><cell>) read misses Intra-chip (L1)</cell><cell>nstructions per 1000 in</cell><cell>-10 15 20 5 10</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Apache Zeus</cell><cell>DB2</cell><cell>Qry1</cell><cell>Qry2 Qry17</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Apache</cell><cell cols="2">Zeus</cell><cell cols="2">DB2</cell><cell cols="2">Qry1</cell><cell cols="2">Qry2</cell><cell cols="2">Qry17</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Web Web</cell><cell>OLTP OLTP</cell><cell>DSS DB2 DSS DB2</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Web</cell><cell></cell><cell></cell><cell cols="2">OLTP</cell><cell></cell><cell cols="3">DSS DB2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="18">FIGURE 1: Non repetitive Non-repetitive</cell><cell>New Stream New Stream</cell><cell>Recurring Stream Recurring Stream</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">100%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>80%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">read misses %</cell><cell>20% 40% 60% 0%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>multi-chip</cell><cell>single-chip</cell><cell>intra-chip</cell><cell>multi-chip</cell><cell>single-chip</cell><cell>intra-chip</cell><cell>multi-chip</cell><cell>single-chip</cell><cell>intra-chip</cell><cell>multi-chip</cell><cell>single-chip</cell><cell>intra-chip</cell><cell>multi-chip</cell><cell>single-chip</cell><cell>intra-chip</cell><cell>multi-chip</cell><cell>single-chip</cell><cell>intra-chip</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Apache</cell><cell>Zeus</cell><cell>DB2</cell><cell>Qry1</cell><cell>Qry2</cell><cell>Qry17</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Web Web</cell><cell>OLTP OLTP</cell><cell>DSS DB2 DSS DB2</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">FIGURE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>2: Fraction of misses in temporal streams.</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>misses in streams 0% % Distance (misses) FIGURE 4: Temporal stream length (left) and reuse distance (right).</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>100% 100%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>25%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>% misses in streams Cum. %</cell><cell>20% 40% 60% 80% 0%</cell><cell>1</cell><cell>10</cell><cell>100</cell><cell>1000</cell><cell>10000</cell><cell>% misses in streams</cell><cell>5% 10% 15% 20% 0%</cell><cell>1</cell><cell>1 0 multi-chip</cell><cell>1 0 2</cell><cell>10 3</cell><cell>10 4</cell><cell>10 5</cell><cell>10 6</cell><cell>10 7</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Stream length</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Distance (misses)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>100%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>25% 25%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>% misses in streams Cum. % Cum. % misses in streams</cell><cell cols="7">misses in streams % % 40% 60% 80% single-chip 0% 20% 1 10 100 1000 10000 Stream length 0% 20% 40% 60% 80% 100% 20% intra-chip</cell><cell>5% 10% 15% 20% 0% 5% 25% 5% 10% 15% 20%</cell><cell>1</cell><cell cols="2">single-chip 1 0 1 0 2 intra-chip</cell><cell cols="3">Distance (misses) 10 3 10 4 10 5</cell><cell cols="2">10 6 Web Apache 10 7 Web Apache Web Zeus DSS Qry1 DSS Qry2 DSS Qry17 OLTP DB2</cell></row><row><cell></cell><cell></cell><cell>1</cell><cell>10</cell><cell>100 Stream length</cell><cell>1000</cell><cell cols="2">10000</cell><cell></cell><cell>1</cell><cell>1 0</cell><cell>1 0 2</cell><cell>10 3</cell><cell>10 4</cell><cell>10 5</cell><cell>10 6</cell><cell>10 7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 : Miss Categories.</head><label>2</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 : Temporal stream origins in Web applications.</head><label>3</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4 : Temporal stream origins in OLTP (DB2).</head><label>4</label><figDesc></figDesc><table><row><cell>complex as temporal stream prefetching to achieve perfor-</cell></row><row><cell>mance gains.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 5 : Temporal stream origins in DSS (DB2).</head><label>5</label><figDesc></figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The authors would like to thank the anonymous reviewers for their feedback on drafts of this paper. This work was partially supported by grants and equipment from <rs type="funder">Intel</rs>, two Sloan research fellowships, an <rs type="funder">NSERC</rs> <rs type="grantName">Discovery Grant</rs>, an <rs type="funder">IBM</rs> faculty partnership award, and <rs type="funder">NSF</rs> grant <rs type="grantNumber">CCR-0509356</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_RknV3uP">
					<orgName type="grant-name">Discovery Grant</orgName>
				</org>
				<org type="funding" xml:id="_X83aYRS">
					<idno type="grant-number">CCR-0509356</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">DBMSs on a modern processor: Where does time go?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Dewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The VLDB Journal</title>
		<imprint>
			<date type="published" when="1999-09">Sept. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Piranha: A scalable architecture base on single-chip multiprocessing</title>
		<author>
			<persName><forename type="first">L</forename><surname>Barroso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nowatzyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Qadeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stets</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Verghese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 27th Intn&apos;l Symp. on Computer Architecture</title>
		<meeting>of the 27th Intn&apos;l Symp. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2000-06">June 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Memory system characterization of commercial workloads</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Barroso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bugnion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 25th Intn&apos;l Symp. on Computer Architecture</title>
		<meeting>of the 25th Intn&apos;l Symp. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1998-06">June 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Organization and maintenance of large ordered indices</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mccreight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Informatica</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1972-09">Sep. 1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">FastCGI: A high-performance web server interface</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<ptr target="http://its.mak.ac.ug/fastcgi/doc/fastcgi-whitepaper/fastcgi.htm" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Generalized correlation-based hardware prefetching</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Charney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Reeves</surname></persName>
		</author>
		<idno>EE-CEG-95-1</idno>
		<imprint>
			<date type="published" when="1995-02">Feb. 1995</date>
		</imprint>
		<respStmt>
			<orgName>School of Electrical Engineering, Cornell University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dynamic hot data stream prefetching for general-purpose programs</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Chilimbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hirzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conf. on Programming Language Design and Implementation (PLDI)</title>
		<meeting>of the Conf. on Programming Language Design and Implementation (PLDI)</meeting>
		<imprint>
			<date type="published" when="2002-06">June 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Low-cost epoch-based correlation prefetching for commercial applications</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 40th Intn&apos;l Symp. on Microarchitecture</title>
		<meeting>of the 40th Intn&apos;l Symp. on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2007-12">Dec. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Last-touch correlated data streaming</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intn&apos;l Symp. on Performance Analysis of Systems and Software (ISPASS)</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Identifying hierarchical structure in sequences: A linear-time algorithm</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Nevill-Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Database servers on chip multiprocessors: Limitations and opportunities</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hardavellas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Pandis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mancheril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd Biennial Conf. on Innovative Data Systems Research (CIDR)</title>
		<imprint>
			<date type="published" when="2007-01">Jan. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Evaluating associativity in CPU caches</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Computers</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="1989-12">Dec. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">TCP: Tag correlating prefetchers</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaxiras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 9th Symp. on High-Performance Computer Architecture</title>
		<meeting>of the 9th Symp. on High-Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Prefetching using Markov Predictors</title>
		<author>
			<persName><forename type="first">D</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grunwald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In 24th Intn&apos;l Symp. on Computer Architecture</title>
		<imprint>
			<date type="published" when="1997-06">Jun. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dead-block prediction &amp; dead-block correlating prefetchers</title>
		<author>
			<persName><forename type="first">A.-C</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 28th Intn&apos;l Symp. on Computer Architecture</title>
		<meeting>of the 28th Intn&apos;l Symp. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2001-07">July 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Whole program paths</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Larus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conf. on Programming Language Design and Implementation (PLDI)</title>
		<meeting>of the Conf. on Programming Language Design and Implementation (PLDI)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Simics: A full system simulation platform</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Magnusson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Christensson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eskilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Forsgren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hallberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hogberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moestedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Werner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="50" to="58" />
			<date type="published" when="2002-02">Feb. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Mauro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mcdougall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Solaris Internals. Sun Microsystems Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Data cache prefetching using a global history buffer</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Nesbit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 10th Symp. on High-Performance Computer Architecture</title>
		<meeting>of the 10th Symp. on High-Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2004-02">Feb. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">DBmbench: Fast and accurate database workload representation on modern microarchitecture</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 15th IBM Center for Advanced Studies Conference</title>
		<meeting>of the 15th IBM Center for Advanced Studies Conference</meeting>
		<imprint>
			<date type="published" when="2005-10">Oct. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Using a user-level memory thread for correlation prefetching</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Solihin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Torrellas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 29th Annual Intn&apos;l Symp. on Computer Architecture</title>
		<meeting>of the 29th Annual Intn&apos;l Symp. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2002-05">May 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Spatial memory streaming</title>
		<author>
			<persName><forename type="first">S</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 33rd Annual Intn&apos;l Symp. on Computer Architecture</title>
		<meeting>of the 33rd Annual Intn&apos;l Symp. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2006-06">June 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">STREAMS Programming Guide</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Sun Microsystems Press</publisher>
		</imprint>
		<respStmt>
			<orgName>Sun Microsystems</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">The SPARC Architecture Manual, Version 9</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Weaver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Germond</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>SPARC International</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Temporal streaming of shared memory</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hardavellas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 32nd Annual Intn&apos;l Symp. on Computer Architecture</title>
		<meeting>of the 32nd Annual Intn&apos;l Symp. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2005-06">June 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">SimFlex: statistical sampling of computer system simulation</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Wunderlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Hoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2006-08">Jul.-Aug. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
