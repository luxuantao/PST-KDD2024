<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Spatial-Aware Hierarchical Collaborative Deep Learning for POI Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hongzhi</forename><surname>Yin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Weiqing</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ling</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xiaofang</forename><surname>Zhou</surname></persName>
						</author>
						<title level="a" type="main">Spatial-Aware Hierarchical Collaborative Deep Learning for POI Recommendation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">27ABBBFD1BEF828620EFCD296305E66E</idno>
					<idno type="DOI">10.1109/TKDE.2017.2741484</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TKDE.2017.2741484, IEEE Transactions on Knowledge and Data Engineering</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>POI recommendation</term>
					<term>Spatial-Aware User Modeling</term>
					<term>Deep Learning</term>
					<term>DBN</term>
					<term>Collaborative Filtering</term>
					<term>Cold Start</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Point-of-interest (POI) recommendation has become an important way to help people discover attractive and interesting places, especially when they travel out of town. However, the extreme sparsity of user-POI matrix and cold-start issues severely hinder the performance of collaborative filtering-based methods. Moreover, user preferences may vary dramatically with respect to the geographical regions due to different urban compositions and cultures. To address these challenges, we stand on recent advances in deep learning and propose a Spatial-Aware Hierarchical Collaborative Deep Learning model (SH-CDL). The model jointly performs deep representation learning for POIs from heterogeneous features and hierarchically additive representation learning for spatial-aware personal preferences. To combat data sparsity in spatial-aware user preference modeling, both the collective preferences of the public in a given target region and the personal preferences of the user in adjacent regions are exploited in the form of social regularization and spatial smoothing. To deal with the multimodal heterogeneous features of the POIs, we introduce a late feature fusion strategy into our SH-CDL model. The extensive experimental analysis shows that our proposed model outperforms the state-of-the-art recommendation models, especially in out-of-town and cold-start recommendation scenarios.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recent years have witnessed the fast development and popularity of location-based social networks (LBSNs), such as Yelp, Foursquare and Facebook Places. In LBSNs, users can post their physical locations in the form of a "check-in", and share their life experiences in the physical world. Using user check-in data to make personalized POI recommendation in LBSNs is crucial for helping users to explore new POIs and regions (e.g., cities), and for facilitating location-based services (e.g., launching personalized mobile advertisments). Personalized POI recommendation is especially important and useful when a user travels to an unfamiliar area, where she has little knowledge about the neighbourhood. In this scenario, the recommendation task is referred to as recommendations for out-of-town users <ref type="bibr" target="#b9">[10]</ref>. Correspondingly, the problem of making recommendations to users in their local area is called recommendations for home-town users. In this paper, we aim to offer high quality recommendations for both home-town and outof-town users by effectively leveraging their check-in data. This problem is highly challenging for three main reasons:</p><p>Spatial Dynamic of Users' Preferences. Users tend to have different preferences when they travel in regions with different urban compositions and cultures, as noted in <ref type="bibr" target="#b35">[35]</ref>. For example, a person who never gambles in her home city may be quite interested in visiting a casino when she travels to Macao or Las Vegas. Thus, users' preferences learned from their check-in history in one region (e.g., home town) may not always be effective for making recommendations in another region.</p><p>Data Sparsity. While LBSNs expand rapidly, the number of POIs visited by an individual user is rather small compared to the • H. Yin, W. Wang and X. Zhou are with the School of ITEE, The University of Queensland, Australia. E-mails:db.hongzhi@gmail.com, weiqingwang@uq.edu.au and zxf@itee.uq.edu.au. • L. <ref type="bibr">Chen</ref>  total number of POIs in an LBSN, which results in a very sparse user-POI matrix. Moreover, the travel locality indicates that most of the users' check-ins happen in their local regions (e.g., home cities) <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b41">[41]</ref>. This observation aggravates the data sparsity problem further for out-of-town POI recommendations.</p><p>Cold Start Problem. Cold start is a critical problem in the domain of POI recommendation, and consists of the cold-start POI problem and the cold-start user problem. POIs that have not received any check-ins are called cold-start POIs. Similarly, users who have not rated any POIs are called cold-start users. Besides new users, out-of-town users may encounter the same problem as cold-start users, even though they have historical check-in data in other regions. This is because, as discussed in the issue of spatial dynamic of user preferences, users' preferences learned from their check-ins in their home towns can seldom be taken as references to produce recommendations in out-of-town regions, especially when the two regions are far away from each other.</p><p>Several methods <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b35">[35]</ref>, <ref type="bibr" target="#b36">[36]</ref>, <ref type="bibr" target="#b41">[41]</ref>, <ref type="bibr" target="#b42">[42]</ref>, <ref type="bibr" target="#b49">[49]</ref> have recently been developed to make POI recommendations for both home-town and out-of-town users. However, these approaches either do not address all the aforementioned challenges, or they do not address these challenges effectively. For example, most existing user behavior modeling research <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b45">[45]</ref> focuses on the temporal dynamics of user interests in the online world, yet ignores the spatial dynamics of user preferences in the physical world. To handle the spatial dynamics of user preferences, the state-ofthe-art POI recommender models, such as LCA-LDA <ref type="bibr" target="#b41">[41]</ref>, Geo-SAGE <ref type="bibr" target="#b35">[35]</ref> and ST-SAGE <ref type="bibr" target="#b36">[36]</ref> exploit the general public's preferences in the target region as a proxy for personal preferences. However, this strategy fails to identify the different preferences of different users to provide personalized recommendations. In our recent work <ref type="bibr" target="#b42">[42]</ref>, we develop the model, ST-LDA, to leverage the textual content of visited POIs to learn region-dependent personal interests that are modeled as a topic distribution. Although the method addresses the spatial dynamics of user preferences to some extent, it is ineffective in incorporating the collaborative filtering information that is essential for POI recommendation.</p><p>A widely adopted approach to alleviate the issues of data sparsity and cold start, especially in the out-of-town recommendation scenario, is to exploit and integrate the auxiliary information of POIs. Some recent studies <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b35">[35]</ref>, <ref type="bibr" target="#b36">[36]</ref>, <ref type="bibr" target="#b41">[41]</ref>, <ref type="bibr" target="#b42">[42]</ref> have leverage the content information of POIs to infer user interests for POI recommendations. However, existing methods extract the semantic features from the textual content in a unsupervised and generalpurpose way that is independent of the recommendation task, thus they are not sufficiently effective to improve the recommendation. In this paper, we exploit four types of POI features with different modalities in a task-guided and supervised way.</p><p>Recently, deep learning models have demonstrated great potential for learning effective representations and delivered the state-of-the-art performance in traditional recommendation tasks. For instance, Wang et al. <ref type="bibr" target="#b34">[34]</ref> integrated stacked denoising autoencoders (SDA) into a matrix factorization model. In their method, denoising auto-encoders are used to extract the items' latent factors from their content information. Li et al. <ref type="bibr" target="#b17">[17]</ref> extended the work <ref type="bibr" target="#b34">[34]</ref> to unify the marginalized denoising auto-encoders (mDA) with a matrix factorization model. Kim et al. <ref type="bibr" target="#b15">[15]</ref> combined convolutional neural network model (CNN) with matrix factorization. Although these methods use deep learning techniques to learn the item representation, only one type of item feature is considered as auxiliary information. We note that there are multiple types of POI features with diverse input modalities, such as textual content, geographical features and neighborhood features, which may contribute rich information to improve POI recommendation. How to extract a unified POI representation from the heterogeneous features for POI recommendation is more challenging and has not been studied. Besides, these methods assume that personal preferences are stable and ignore their spatial dynamics over geographical regions.</p><p>To address these challenges of POI recommendation in an effective and unified way, we propose a novel POI recommendation framework to jointly perform spatial-aware personal preference modeling and POI semantic representation learning from versatile POI auxiliary information.</p><p>Specifically, to address the spatial dynamics of user preferences, we model spatial-aware user preferences by allowing a user to have different preference vectors for different regions. Given the check-in records generated by an individual user in an outof-town region are extremely sparse, the preferences of a crowd sharing the same role as the user in that region (i.e., the wisdom of the crowd) <ref type="bibr" target="#b35">[35]</ref> are employed to enhance the inference of spatialaware personal preferences in the form of social regularization. To further alleviate the issue of data sparsity, we exploit geographical correlation to smooth spatial-aware personal preferences over a spatial index structure -spatial pyramid, inspired by <ref type="bibr" target="#b35">[35]</ref>. To handle the cold start issue, we adopt Deep Belief Networks (DBN) <ref type="bibr" target="#b13">[13]</ref> to learn the POIs' semantic representations from a set of heterogeneous features, inspired by the better performance of DBN than SDA in the classification task and its robustness to noise <ref type="bibr" target="#b8">[9]</ref>. To fuse multiple types of POI features and learn a unified semantic representation of individual POIs, we extend the conventional DBN into a multi-modal DBN (MDBN) by introducing a late feature fusion strategy. Finally, to integrate the learned spatialaware personal preferences and POIs' semantic representation, we propose a probabilistic model framework, called Spatial-Aware Hierarchical Collaborative Deep Learning (SH-CDL), to jointly perform matrix factorization and automatic extraction of the POIs' semantic representation. Our SH-CDL enables the extraction of POIs' semantic representation to be guided by user feedback information (e.g., check-in) in a supervised way.</p><p>The main contributions of this paper are summarized below:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>We propose a spatial-aware user preference modeling method based on latent factor models to overcome the challenge of spatial dynamics of personal preferences. To alleviate data sparsity in inferring spatial-aware personal preferences, we leverage the spatial-aware crowd's preferences in the form of social regularization and exploit the geographical autocorrelation of personal preferences based on their geographically hierarchical additive representations. Besides, we systematically illustrate how to design a matrix factorization objective function with social regularization and geographically hierarchical smoothing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>To address the cold start and data sparsity issues, we explore multiple types of POI features and propose a supervised and task-guided method to learn the semantic representation of POIs from their associated heterogeneous features. To address the multi-modality issue, we proposed a late non-linear fusion method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>We conduct extensive experiments on two datasets. Our experimental results show SH-CDL significantly outperforms the state-of-the-art recommendation methods, especially in out-of-town and cold-start scenarios.</p><p>Roadmap of this paper. Section 2 provides the preliminaries of our SH-CDL model. Section 3 details the model structure and inference. We present a hierarchically additive representation for spatial-aware personal preferences in Section 4. We extend the DBN to learn a unified POI representation from heterogeneous features in Section 5. We report our experimental study in Section 6. Section 7 reviews the related works and Section 8 closes the paper with some concluding remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARIES</head><p>In this section, we introduce the necessary preliminaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Probabilistic Matrix Factorization</head><p>POI recommendation is commonly studied on a user-POI matrix C ∈ R M ×N , where there are M users and N POIs. Each entry c u,v in C records the feedback or the rating score of user u to POI v. Hereafter, following the common symbolic notation, we will use upper case bold letters to denote matrices, lower case bold letters to denote column vectors and non-bold letters to represent scalars.</p><p>Given a check-in matrix C, one possible approach to POI recommendation is the collaborative filtering (CF). The state-ofthe-art CF-based methods are probabilistic matrix factorization (PMF) <ref type="bibr" target="#b25">[25]</ref>, since PMF's principled probabilistic interpretation enables it to easily incorporate auxiliary information such as POIs' content and geographical information. PMF assumes that each user u ∈ U and POI v ∈ V can be represented as latent factor vectors p u and q v , respectively. The rating or feedback that u gives v is the inner product of p u and q v . The training data is usually very sparse, and without regularization the model is crippled by severe over-fitting. Therefore, Gaussian priors are used for both p u and q v as regularization. Formally, the probabilistic generative process of the model is listed as follows: where function g(x) is the Sigmoid function g(x) = 1/(1 + exp(-x)), which bounds p T u q v within the range [0, 1]. The negative log-likelihood of the PMF model is:</p><formula xml:id="formula_0">1) Sample p u |ρ U ∼ N (0, ρ 2 U I) 2) Sample q v |ρ V ∼ N (0, ρ 2 V I) 3) Sample c u,v |p u , q v , ρ C ∼ N (g(p T u q v ), ρ 2 C I)</formula><formula xml:id="formula_1">LMF = ∑ u∈U ∑ v∈V Iu,v(cu,v -g(p T u qv)) 2 + λ U 2 ∑ u∈U ∥pu∥ 2 + λ V 2 ∑ v∈V ∥qv∥ 2 , (<label>1</label></formula><formula xml:id="formula_2">)</formula><p>where I u,v is a binary value indicating whether u visits v, i.e., I u,v = I(c u,v &gt; 0). λ U and λ V are regularization parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">RBMs and Their Generalizations</head><p>Restricted Boltzmann Machines (RBMs) <ref type="bibr" target="#b14">[14]</ref>, <ref type="bibr" target="#b31">[31]</ref> have been widely used in modeling distributions over binary-valued data. Recent work on Boltzmann machine models and their generalizations to exponential family distributions have allowed these models to be successfully used in many application domains. In particular, the Replicated Softmax model <ref type="bibr" target="#b14">[14]</ref>, <ref type="bibr" target="#b31">[31]</ref> has been shown to be effective in modeling sparse word count vectors, whereas Gaussian RBMs have been used to model real-valued inputs for speech and vision tasks. In this subsection we briefly review these models following <ref type="bibr" target="#b31">[31]</ref>, as they serve as building blocks for our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Restricted Boltzmann Machines (RBM).</head><p>A RBM is a particular type of Markov random field that has a two-layer architecture. The visible binary stochastic units x ∈ {0, 1} D are connected to hidden binary stochastic units h ∈ {0, 1} F , as shown in Figure <ref type="figure" target="#fig_0">1</ref> (a). The energy of the state {x, h} is:</p><formula xml:id="formula_3">E(x, h; Ψ) = -x T W h -b T x -a T h = - D ∑ i=1 F ∑ j=1 Wi,j xihj - D ∑ i=1 bixi - F ∑ j=1 aj hj (2)</formula><p>where Ψ = {W , b, a} are the model parameters; W i,j represents the symmetric interaction term between visible unit i and hidden unit j; b i and a j are bias terms. The joint distribution over the visible and hidden units is defined as:</p><formula xml:id="formula_4">P (x, h; Ψ) = 1 Z(Ψ) exp (-E(x, h; Ψ))<label>(3)</label></formula><formula xml:id="formula_5">Z(Ψ) = ∑ x ∑ h exp (-E(x, h; Ψ))</formula><p>where Z(Ψ) is known as the normalizing constant. Gaussian RBM. Given the visible real-valued units x ∈ R D and binary stochastic hidden units h ∈ {0, 1} F , the energy of the state {x, h} of the Gaussian RBM is defined as follows:</p><formula xml:id="formula_6">E(x, h; Ψ) = D ∑ i=1 (xi -bi) 2 2ρ 2 i - D ∑ i=1 F ∑ j=1 Wi,j hj xi ρi - F ∑ j=1 aj hj (<label>4</label></formula><formula xml:id="formula_7">)</formula><p>where Ψ = {W , a, b, ρ 2 } are the model parameters. Replicated Softmax Model. The Replicated Softmax Model is useful for modeling sparse count data, such as word count vectors in a document. Let x ∈ N K be a vector of visible units where x i is the number of times word i occurs in the document with the vocabulary of size K. Let h ∈ {0, 1} F be binary stochastic hidden units. The energy of the state {x, h} is defined as follows: <ref type="bibr" target="#b4">(5)</ref> where Ψ = {W , a, b} are the model parameters and ξ = ∑ i x i is the total number of words in a document.</p><formula xml:id="formula_8">E(x, h; Ψ) = - K ∑ i=1 F ∑ j=1 Wi,j xihj - K ∑ i=1 bixi -ξ F ∑ j=1 aj hj</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Deep Belief Network</head><p>RBMs can be stacked and trained in a greedy manner to form Deep Belief Networks (DBN) <ref type="bibr" target="#b13">[13]</ref>. A deep belief network is a probabilistic generative graph model with many layers of hidden nodes at the top and one layer of observations at the bottom. DBN models the joint distribution between observed vector x and the L hidden layers h m as follows:</p><formula xml:id="formula_9">P (x, h 1 , . . . , h L ; Ψ) = ( L-2 ∏ m=0 P (h m |h m+1 ) ) P (h L , h L-1 )<label>(6)</label></formula><p>where h 0 = x, P (h m |h m+1 ) is a conditional distribution for the visible units conditioned on the hidden units of the RBM at level m, and P (h L , h L-1 ) is the visible-hidden joint distribution in the top-level RBM. This is illustrated in Figure <ref type="figure" target="#fig_0">1</ref> (b).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">GEOGRAPHICAL DEEP LEARNING</head><p>In this section, we first formulate the POI recommendation problem, and then present our proposed SH-CDL model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Definition</head><p>Below we first introduce some closely related concepts, and then define the POI Recommendation problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 1. (POI)</head><p>A POI is defined as a uniquely identified geographical site (e.g., a restaurant or a cinema). In our work, we exploit four types of features for a POI: content features, geo-location features, popularity features and neighborhood features (with the details discussed in Section 5.1). Given a POI v, we use x c v to denote the content features of v (e.g., its category, description and comments), x g v to denote its geolocation features (e.g., its geographical position), x p v to denote the popularity features of v (e.g., its check-in number), and x n v to represent the neighborhood related features. x v is used to represent the whole feature vector of POI v, and X denotes the feature matrix formed by all x v . Definition 2. (User Home Location) Following the recent work of <ref type="bibr" target="#b16">[16]</ref>, given a user u, we define the user's home location as the place where the user lives, denoted as l u . Due to privacy concerns, users' home locations are not always available. For a user u whose home location is not explicitly given, we adopt the method developed by <ref type="bibr" target="#b30">[30]</ref> to infer her home location based on her check-in history. to the range [0, 1] using the function f (x) = x/C max where C max is the maximum possible value. Given a check-in Cuboid C and a POI feature matrix X, we aim to provide POI recommendation for both home-town and out-oftown users. Following <ref type="bibr" target="#b42">[42]</ref>, we formulate our problem below. Problem 1. (POI Recommendation) Given a querying user u q with her target region r q , we first compute the user role s q according to the distance between her target region and her home location. Then, a query q = (u q , r q , s q ) is formed. Our goal is to find top-k POIs from V that match the preferences of query q. The problem becomes an outof-town recommendation if the distance is greater than a predefined threshold ζ. Otherwise, the problem is a hometown recommendation. Following the related studies <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b26">[26]</ref>, we set ζ = 100km.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Model Structure of SH-CDL</head><p>The graphical representation of SH-CDL is shown in Figure <ref type="figure">2</ref>, where different colors represent different components.</p><p>To capture the spatial dynamic of personal preferences, we assume user's preferences are region-dependent in SH-CDL and use p u,r to denote u's preferences when traveling to region r. To overcome the cold-start problem, SH-CDL incorporates versatile auxiliary information of POIs (i.e., POI features). Given a POI v at region r, we use x v to denote its raw feature vector directly extracted from the auxiliary information, and DBN (x v ; Ψ) to denote its hidden feature vector modeled from raw features by DBN <ref type="bibr" target="#b13">[13]</ref>. We use q v to denote its latent factor vector, and assume that the dimension of q v is the same as that of the hidden feature vector. Similar to the probabilistic matrix factorization (PMF), the probabilistic generative process of SH-CDL for each checkin record c u,v,s is formulated as follows:</p><formula xml:id="formula_10">cu,v,s ∼ N (g(p T u,r qv), ρ 2 C ), pu,r ∼ N (θs,r, ρ 2 U I) θs,r ∼ N (0, ρ 2 R I), qv ∼ N (DBN (xv; Ψ), ρ 2 V I)</formula><p>where we assume that c u,v,s follows a normal distribution to account for the noise in the user ratings/feedbacks. In SH-CDL, θ s,r denotes the collective preferences of the general public visiting region r with role s (i.e., the wisdom of the crowd). Since the user's check-in records generated in a single region r are sparse, especially when r is an out-of-town region, it is very challenging to infer the user's preferences in the region without over-fitting. Therefore, we exploit the wisdom of the crowd. Following <ref type="bibr" target="#b34">[34]</ref>, <ref type="bibr" target="#b42">[42]</ref>, SH-CDL recognizes two roles of an individual user in a geographical region: a local or a tourist. Given a region, check-in records from local users will be mined to learn native preferences (s = 1). Similarly, check-in records from tourists will be used to learn tourist preferences (s = 0). Users with the same role at a region are more likely to have similar preferences. Taking the collective preferences θ s,r as the Gaussian prior for region-aware personal preferences p u,r alleviates the issue of data sparsity to some extent. In practice, the collective preference θ s,r plays the role of social regularization (i.e., it serves as a regularization term in the objective function in Equation <ref type="formula">8</ref>). ρ U indicates the variance of personal preferences. The smaller the ρ U , the more similar the personal preferences p u,r are to the collective preferences θ s,r at region r, and the more strongly p u,r is regularized.</p><p>Automatic learning of hidden feature vector from POI auxiliary information x v is achieved by Deep Belief Network (DBN) <ref type="bibr" target="#b13">[13]</ref>, considering its excellent performance in recent applications and its robustness to noise <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b31">[31]</ref>, <ref type="bibr" target="#b37">[37]</ref>. DBNs are graphical models which learn to extract a deep hierarchical representation of the input features, and can be treated as a very flexible deterministic function that maps x v to DBN (x v ; Ψ). To overcome the cold-start problem, our SH-CDL unifies the probabilistic matrix factorization (PMF) and the deep representation learning by linking the latent factor vector q v and the hidden feature vector DBN (x v ; Ψ). Rather than simply defining the two vectors to be equal as in <ref type="bibr" target="#b32">[32]</ref>, <ref type="bibr" target="#b37">[37]</ref>, we assume that q v follows a normal distribution with the mean DBN (x v ; Ψ), to learn a more robust mapping from the POI features, since users' check-in behaviors may be influenced by other unknown factors beyond our collected POI features.</p><p>Based on the probabilistic generative process of SH-CDL, through a simple Bayesian inference, the posterior distribution of the personal preferences, the collective preferences of crowds and the POIs' latent factor vectors is formulated in Equation <ref type="bibr" target="#b6">(7)</ref>, where P , Θ, Q are two hyper-matrices and one matrix formed by p u,r , θ s,r and q v , respectively. Both I u,v,s and I u,r,s are indicator functions and defined as: I u,v,s = I(c u,v,s &gt; 0), and I u,r,s = I(l u ∈ r) ⊙ s where ⊙ is the XOR operation. If u's home location l u is within region r, we assume that u is local at r. I u,v,s indicates whether u has visited a POI v with the role s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Model Inference of SH-CDL</head><p>We adopt the Maximum Likelihood Estimation to infer the model. The negative log-likelihood of Equation ( <ref type="formula">7</ref>) is shown in Equation <ref type="bibr" target="#b7">(8)</ref>, where irrelevant constants are omitted. The hyperparameters λ U , λ R and λ V are the ratios</p><formula xml:id="formula_11">ρ 2 C /ρ 2 U , ρ 2 C /ρ 2 R and ρ 2 C /ρ 2</formula><p>V , respectively, and a larger value indicates a stronger regularization. r v denotes the region where POI v is located. The model parameters consist of two parts: the weight parameters Ψ in DBN and the latent vectors p u,r , θ s,r and q v . Below, we introduce how to estimate them using the gradient descent method.</p><p>Since Ψ consists of a large amount of parameters, directly optimizing L SH-CDL using gradient descent could easily lead to overfitting. Following the DBN training process established in <ref type="bibr" target="#b13">[13]</ref>, we first pre-train the DBN as stacked layers of Restricted Boltzmann Machines in an unsupervised fashion, i.e., the principle of greedy layer-wise unsupervised training is applied to DBNs with RBMs as the building blocks for each layer. We then optimize L SH-CDL using gradient descent, and the gradient descent part of DBN is implemented as back-propagation. The whole DBN training process is shown as follows: 1) Train the first layer of DBN as an RBM that models the raw input h 0 = x v as its visible layer, using CD1 algorithm <ref type="bibr" target="#b13">[13]</ref>.</p><p>1041-4347 (c) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p><p>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TKDE.2017.2741484, IEEE Transactions on Knowledge and Data Engineering 5</p><formula xml:id="formula_12">P (P , Θ, Q|C, X, ρ 2 C , ρ 2 U , ρ 2 V , ρ 2 R , Ψ) ∝ P (C|P , Q, ρ 2 C )P (P |Θ, ρ 2 U )P (Θ|0, ρ 2 R )P (Q|X, Ψ) = ∏ u∈U ∏ v∈V ∏ s∈{0,1} [ N (cu,v,s|g(p T u,r qv), ρ 2 C ) ] Iu,v,s × ∏ u∈U ∏ r∈R ∏ s∈{0,1} [ N (pu,r|θs,r, ρ 2 U ) ] Iu,r,s × ∏ s∈{0,1} ∏ r∈R N (θs,r|0, ρ 2 R ) × ∏ v∈V N (qv|DBN (xv, Ψ), ρ 2 V ) (7) LSH-CDL = ∑ u∈U ∑ v∈V ∑ s∈{0,1} Iu,v,s(cu,v,s -g(p T u,rv qv)) 2 + λU 2 ∑ u∈U ∑ r∈R ∑ s∈{0,1}</formula><p>Iu,r,s∥pu,r -θs,r∥</p><formula xml:id="formula_13">2 + λR 2 ∑ s∈{0,1} ∑ r∈R ∥θs,r∥ 2 + λV 2 ∑ v∈V ∥qv -DBN (xv, Ψ)∥ 2 (8)</formula><p>2) Use that first layer to obtain a representation of the input that will be used as data for the second layer. This representation is chosen as being the mean activations, i.e., p(h 1 j = 1|h 0 ). 3) Train the second layer as an RBM, taking the transformed data (mean activations) as training examples. 4) Iterate steps 2 and 3 for the desired number of layers, each time propagating upward the mean activation values. 5) Fine-tune all the parameters of DBN via supervised gradient descent of the objective function L SH-CDL .</p><p>Steps 1-4 are an unsupervised training process, called pretraining. The DBN is then converted into a multi-layer perception (MLP) for supervised learning (Step 5). This stage is called finetuning and implemented as a standard back-propagation. To finetune the parameters Ψ in the DBN, their gradients are updated as follows (a special case of the chain-rule of derivation):</p><formula xml:id="formula_14">∂LSH-CDL ∂Ψ = ∂LSH-CDL ∂DBN (xv, Ψ) ∂DBN (xv, Ψ) ∂Ψ . (<label>9</label></formula><formula xml:id="formula_15">)</formula><p>For the latent vectors p u,r , θ s,r and q v , their gradients are computed as follows:</p><formula xml:id="formula_16">∂L SH-CDL ∂pu,r =2 ∑ v∈Vr ∑ s∈{0,1} Iu,v,sg ′ (p T u,r qv)(g(p T u,r qv) -cu,v,s) + λ U ∑ s∈{0,1}</formula><p>Iu,r,s(pu,r -θs,r), <ref type="bibr">(</ref></p><formula xml:id="formula_17">) ∂L SH-CDL ∂θs,r = λ U ∑ u∈U Iu,r,s(θs,r -pu,r) + λ R θs,r, (<label>10</label></formula><formula xml:id="formula_18">)<label>11</label></formula><formula xml:id="formula_19">∂L SH-CDL ∂qv =2 ∑ u∈U ∑ s∈{0,1} Iu,v,sg ′ (p T u,rv qv)(g(p T u,rv qv) -cu,v,s) + λ V (qv -DBN (xv, Ψ)),<label>(12)</label></formula><p>where g ′ (x) is the derivation of g(x), i.e., g</p><formula xml:id="formula_20">′ (x) = g(x)(1 - g(x)</formula><p>), and V r denotes the set of POIs located in region r.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Complexity Analysis</head><p>In addition to the DBN, the main computation in the model inference is evaluating the object function L SH-CDL and its gradients against variables. Because of the sparsity of cuboid C, the computation complexity of evaluating the objective function</p><formula xml:id="formula_21">L SH-CDL is O(C)</formula><p>where C denotes the number of non-zero entries in the check-in cuboid C, i.e., the number of check-ins. The computation complexities for updating gradients in Equations <ref type="bibr" target="#b9">(10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12)</ref> are</p><formula xml:id="formula_22">O(M × R), O(C) and O(C) respectively,</formula><p>where M is the number of users, and R is the number of regions. Therefore, the total computational complexity for one iteration is O(C), which indicates that the computational time of our method is linear with respect to the number of observations in the checkin cuboid. As for fine-tuning the DBN with back-propagation, its computation complexity is O(N × |Ψ|), where N is the number of POIs and |Ψ| is the number of parameters in the DBN. We implemented our SH-CDL using Theano 1 , because it supports convenient GPU programming and automatic symbolic differentiation. GPUs with large video memory enable the training of our SH-CDL to be efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">POI Recommendation Using SH-CDL</head><p>Once we have trained the model SH-CDL, given a querying user u q with the target region r q , we first compute the indicator s q (i.e., the role of user u q ). Thus, a query q = (u q , r q , s q ) is formed. Then, we compute the ranking score of each unvisited POI v in region r q w.r.t. the query q, as in Equation ( <ref type="formula">13</ref>), and then select the top-k with highest ranking scores as recommendations.</p><p>S(q, v) = g(p T uq ,rq qv) <ref type="bibr" target="#b13">(13)</ref> As the latent factor vector q v is approximate to the hidden feature vector DBN (x v , Ψ), the ranking score for the cold-start POIs (e.g., new POIs) can be approximately computed as follows:</p><formula xml:id="formula_23">S(q, v) = g(p T uq ,rq DBN (xv, Ψ)).<label>(14)</label></formula><p>As for cold-start users, SH-CDL can make accurate recommendation according to the collective preferences of the crowd with the same role s q at target region r q , as follows:</p><formula xml:id="formula_24">S(q, v) = g(θ T sq ,rq qv). (<label>15</label></formula><formula xml:id="formula_25">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">HIERARCHICAL USER PREFERENCE MODELING</head><p>To capture the spatial dynamics of personal preferences, we assume that personal preferences are spatial-aware in our SH-CDL model. However, the user's check-in records at a single region r are sparse, especially when r is an out-of-town region. To alleviate the data sparsity, we exploit the geographical autocorrelation of personal preferences. Given close regions have similar urban compositions and cultures, personal preferences in these regions should be similar. Thus, we can "borrow" the user's check-in records from nearby regions to smooth her preferences at r. To encode the spatial autocorrelation and enable the learned personal preferences to be smoothed over spatial regions, we adopt a hierarchical spatial index structure -spatial pyramid, to partition and index the entire geographic area, inspired by <ref type="bibr" target="#b35">[35]</ref>. The spatial pyramid is constructed by partitioning POI locations into spatial regions of varying sizes at different levels. More specifically, the spatial pyramid decomposes the space into h levels. The first/top level has only one grid cell. For a given level j ≥ 1, the space is partitioned into 4 j-1 equal area grid cells. Thus, the space is divided recursively into finer cells at deeper levels. An example of a spatial pyramid with h = 4 is illustrated in Figure <ref type="figure">3</ref>.</p><p>Based on the spatial pyramid structure, we propose a novel path-based region representation approach. That is, each region r can be represented by a path from the root cell to its corresponding  cell. We use a vector to describe the path. For example, given a region r h which corresponds to a cell at level h, the region can be represented by the vector (r 1 , r 2 ,. . . , r j , . . . , r h ) where cell r j is the father node of cell r j+1 . Based on the pathbased region representation, we propose a hierarchically additive framework <ref type="bibr" target="#b35">[35]</ref> to represent personal preferences, as follows:</p><formula xml:id="formula_26">pu,r h = h ∑ j=1 ϕu,r j (16)</formula><p>Similarly, the collective preferences of the general public with role s at region r can be represented as follows:</p><formula xml:id="formula_27">θs,r h = h ∑ j=1 ϑs,r j (17)</formula><p>where region r h is assumed to correspond to a cell at level h; if r j is an ancestor node of r h , that means region r h belongs to region r j , denoted as r h ∈ r j . ϕ u,rj and ϑ s,rj represent the amortized personal preferences and collective preferences at level j, respectively. Since p u,r h and θ s,r h are respectively represented as the sum of ϕ u,rj and ϑ s,rj at each level j, we need to calculate the gradients of ϕ u,rj and ϑ s,rj . Thus, we extend Equations <ref type="bibr" target="#b9">(10,</ref><ref type="bibr" target="#b10">11)</ref> to infer the gradients of ϕ u,rj and ϑ s,rj at each level j, as shown in Equations <ref type="bibr" target="#b18">(18,</ref><ref type="bibr" target="#b19">19)</ref> where p u,r h and θ s,r h are computed as in Equations <ref type="bibr" target="#b16">(16,</ref><ref type="bibr" target="#b17">17)</ref>.</p><p>Based on the hierarchically additive representation for spatialaware personal preferences, if there are few or no check-in records for a user u at region r, we can still infer u's personal preferences guided by her check-in data generated at r's ancestor regions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPLOITING HETEROGENEOUS POI FEATURES</head><p>In this section, we first present the four types of heterogeneous features extracted for POIs, and then develop a multimodal learning technique to fuse these features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Feature Extraction</head><p>In this subsection, we introduce four types of features we have extracted for POIs.</p><p>Content Features. Given a POI v, we first extract textual content features x c v from POIs' categories, description and comments. The formation of the feature vector and its size are discussed in the experiments in Section 6.</p><p>Geo-Location Features. Given a POI, its geo-location refers to its geographical position in terms of latitude and longitude.</p><p>Popularity Features. As analyzed in <ref type="bibr" target="#b43">[43]</ref>, the probability of a user visiting a POI is largely affected by local word-ofmouth about the POI (i.e., the popularity of the POI), especially when users travel in unfamiliar regions. In our SH-CDL model, we exploit three kinds of popularity features: overall popularity, role-aware popularity and temporal popularity. Given a POI, the overall popularity features refer to the total number of checkins and the total number of unique visitors. According to user roles, the overall popularity can be refined into its popularity among local people and tourists, respectively. As different users have different working schedules and life styles, the compatibility between time-varying popularity of POIs and regular availability of users can influence user decision-making <ref type="bibr" target="#b39">[39]</ref>. Thus, we further consider the temporal distributions of its check-ins and its unique users over the course of a week (i.e., Monday to Sunday) and in a 24-hour scale as well as on weekdays and weekends, respectively. In total, there are 66 temporal popularity features that consist of 7 × 2 weekly popularity features, 24 × 2 daily popularity features and 2 × 2 weekday-weekend popularity features. In a short, we generate 2 overall popularity features, 4 role-aware popularity features and 66 temporal popularity features for each POI.</p><p>Neighborhood Features. Given a POI v, the neighborhood features refer to the ones that describe the environment around v. The geographical influence <ref type="bibr" target="#b40">[40]</ref> suggests that people tend to explore the POIs near the ones they favor. More specifically, we measure the density, heterogeneity, competitiveness and popularity of the surrounding area, the transition density and transition quality, and the transportation by analyzing the set {v ′ ∈ V : dist(v, v ′ ) &lt; d} of POIs that lie in a disk of radius d around POI v. The function dist denotes the geographical distance between two POIs, and V is the whole set of POIs.</p><p>1) Density: The density feature refers to the number of neighbors around the POI within a circle of radius d. Formally, it is defined as follows:</p><formula xml:id="formula_28">F n1 (v) = |{v ′ ∈ V : dist(v, v ′ ) &lt; d}|</formula><p>Given that the radius d is the same for all POIs, the density of neighboring POIs depends only on the number of POIs in the neighborhood. We use the notation N (v, d) to denote the number of v's neighbors within a radius d. Intuitively, a denser area could imply a higher likelihood of an opportunistic visit to a target POI.</p><p>2) Heterogeneity: To incorporate the influence of the spatial heterogeneity of the neighborhood on the users' check-in behaviors, we apply an entropy measure from information theory to the frequency of the POI types (i.e., categories) in the area. We denote the number of POI neighbors of type γ with N γ (v, d). The neighborhood entropy is formally defined as follows:</p><formula xml:id="formula_29">F n2 (v) = - ∑ γ∈Γ N γ (v, d) N (v, d) × log N γ (v, d) N (v, d)</formula><p>where Γ is the set of all POI types.</p><p>3) Competitiveness: We devise a feature to describe the competitiveness of the surrounding area. Given the type of POI v (e.g., Chinese Restaurant), we measure the proportion of neighboring POIs of the same type γ v as follows.</p><formula xml:id="formula_30">F n3 (v) = N γv (v, d) N (v, d)</formula><p>Competition can have either positive or negative effects. One would expect that, for instance, a bar in an area populated with nightlife spots would be more attractive to users as there is already an ecosystem of related services. However, being surrounded by competitors may also mean that users have more choices, and the probability of visiting v might be reduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Area Popularity:</head><p>To assess the influence of the overall popularity of the area, we measure the total number of checkins, empirically observed among the neighboring POIs in the area: </p><formula xml:id="formula_31">F n4 (v) = |{(u, v ′ , s) ∈ C : dist(v, v ′ ) &lt; d}|.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) Transition Density:</head><p>Assuming that increased mobility from neighboring POIs to v can increase the probability of a user visiting v, we measure the density of transitions between v and its neighboring POIs as follows:</p><formula xml:id="formula_32">F n5 (v) = |{(v ′ , v) ∈ T v : dist(v ′ , v) &lt; d}|</formula><p>where T v is the set of consecutive check-in transitions from other POIs v ′ ∈ V to v. 6) Potential Transition Density: Another aspect of POI attractiveness comes from the potential number of local users that the POI might attract from the area. We thus measure the probability of transitions from POIs of all other types to POIs of type γ v . The resulting probabilities allow us to take into account the nearby POIs as potential sources of users to the POI v. More formally:</p><formula xml:id="formula_33">F n6 (v) = ∑ {v ′ ∈V:dist(v ′ ,v)&lt;d} κ γ v ′ →γv × N v ′</formula><p>where N v ′ is the number of check-ins at POI v ′ , and κ γ v ′ →γv is a probability of transitions between categories γ v ′ and γ v , defined as the average percentage of all check-ins to POI v ′ that are followed by POIs with type γ v :</p><formula xml:id="formula_34">κ γ v ′ →γv = E[ |{(m, n) ∈ T : m = v ′ ∧ γ n = γ v }| N v ′ ]</formula><p>where T is the total set of consecutive check-in transitions between POIs and as a tuple, (m, n) ∈ T , the POIs m ∈ V and n ∈ V involved in two consecutive check-ins.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7) Transportation:</head><p>The transportation features refer to the numbers of bus stops and subway stations in the surrounding area, which are defined as follows:</p><formula xml:id="formula_35">F n7 (v) = |{v ′ ∈ V : dist(v ′ , v) &lt; d ∧ γ v ′ = bus stop}| F n8 (v) = |{v ′ ∈ V : dist(v ′ , v) &lt; d ∧ γ v ′ = subway station}|</formula><p>As for the radius d in the neighborhood features, we have experimented with different values and have selected it to be equal to 200 meters because this yielded the best experimental results, and is also consistent with the optimal neighborhood size in <ref type="bibr" target="#b23">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Multimodal Learning</head><p>The POI features described above are heterogeneous and multimodal. Specifically, the content features are represented as sparse word count vectors, whereas the geo-location, popularity and neighborhood features are real-valued and dense. There is a great deal of structure in the POI features but it is difficult to discover highly non-linear relationships that exist between features across different modalities. Moreover, these features are noisy and may have missing values. Traditional DBNs adopt an early fusion strategy to directly concatenate all types of features as the joint input for the first layer RBM, as shown in the left panel of Figure <ref type="figure" target="#fig_2">4</ref>. The joint input is then abstracted by other high-level RBMs. Although the classic early fusion mechanism achieves good performance with homogenous features, it does not apply to multimodal heterogeneous features because the correlations across different modalities are highly non-linear, and it is difficult for the first RBM to represent their relations properly. In light of this, we extend the traditional DBN to a multimodal DBN (MDBN) and adopt a late fusion strategy, inspired by <ref type="bibr" target="#b31">[31]</ref>, <ref type="bibr" target="#b48">[48]</ref>. As shown in the right panel of Figure <ref type="figure" target="#fig_2">4</ref>, the key idea of the MDBN is to first use separate modality-friendly latent variable models to learn latent representations of each data modality independently. Then, the latent representations (instead of the raw features) for different modalities are concatenated to form a multimodal input. Higher-order latent variables can subsequently be used to model the distribution over this input. Similar to the DBN, the parameters of this MDBN can be learned approximately by greedy layer-wise training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Late Fusion Early Fusion</head><p>Note that the MDBN can be described as a composition of multiple unimodal pathways. Each pathway is learned separately in a completely unsupervised fashion, which enables the MDBN to be more flexible and powerful than the conventional DBN with the early fusion strategy. Any number of pathways each with any number of layers could potentially be used. The type of lower RBMs in each layer could be different, accounting for different kinds of input distributions, as long as the final hidden representations at the end of each pathway are of the same type. Since input features for our SH-CDL model consists of both dense realvalue features and sparse word count features, we use the Gaussian RBM to model the distribution over real-valued features (i.e., its geo-location features, popularity and neighborhood features) while a Replicated Softmax model is employed to model its distribution over the word count vectors (i.e., the content features). As for the rest of the layers, binary RBMs are adopted <ref type="bibr" target="#b11">[12]</ref>.</p><p>Zhang et al. <ref type="bibr" target="#b46">[46]</ref> also proposed a late fusion strategy for the multi-modal features, but they assumed that the learnt hidden features of different modalities are in the same semantic space and simply add them together to represent the latent factors of an item. In our fusion approach, the learnt hidden features of different modalities are in different spaces. We first project them to the same semantic space by multiplying a modality-specific matrix and then adopt a non-linear method to fuse them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENTS</head><p>In this section, we first describe the settings for the experiments and then demonstrate the experimental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Datasets</head><p>Our experiments are conducted on two large real-life datasets:</p><p>Yelp. Yelp's Challenge Dataset 2 contains 552,000 users and 77,000 POIs from 10 cities across 4 countries. There are 2.2 </p><formula xml:id="formula_36">• • • • DL-PMF • • HLDBN • • CDL • • DCF • • ST-LDA • • • ST-GLDA • • •</formula><p>million rating records, and each rating record consists of a user-ID, a POI-ID, a rating score (1-5 star) and a time-stamp. For each POI, we also collected its four types of features.</p><p>Foursquare. Foursquare is one of the most popular LBSNs. We collected its public check-in data from Sep 2010 to Jan 2011 through Twitter with the same crawling strategy as proposed in <ref type="bibr" target="#b3">[4]</ref>. This dataset contains 62,462 POIs and 1,434,668 check-ins generated by 114,508 users who live in the USA. Each check-in is stored as user-ID, POI-ID, time-stamp. For each POI, we crawled its auxiliary information through Foursquare's API and extracted four types of features. As there is no explicit rating information in this datset, we assigned a rating of 1 to each observed checkin and used them as the positive samples. To generate negative samples, we used the well-established User-Oriented Sampling method proposed in <ref type="bibr" target="#b27">[27]</ref>, i.e., for user u who visits V u , we randomly sampled |V u | POIs from V \ V u and assigned a rating of 0 to each generated negative check-in.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Comparative Approaches</head><p>We compare our SH-CDL with the following four deep learningbased recommenders and two state-of-the-art POI recommenders. Table <ref type="table">1</ref> lists the characteristics of these methods. For fair comparison, all deep learning based models take the same input features.</p><p>DL-PMF. DL-PMF is a two-stage deep deep learning powered probabilistic matrix factorization model <ref type="bibr" target="#b32">[32]</ref>. This model first uses PMF to learn latent factor vectors p u and q v for all users and items, and then trains a DBN to map from the item feature vector x v to the latent factor vector q v .</p><p>HLDBN. The hierarchical linear model combined with DBN was developed for music recommendation in <ref type="bibr" target="#b37">[37]</ref>. It unifies the deep belief network and probabilistic matrix factorization model. They try to minimize the following objective function:</p><formula xml:id="formula_37">LHLDBN = ∑ u∈U ∑ v∈V (cu,v -p T u DBN (xv, Ψ)) 2 + λ ∑ u∈U ∥pu -µ∥ 2</formula><p>where µ represents the common preferences of all users. CDL. Collaborative Deep Learning <ref type="bibr" target="#b34">[34]</ref> unifies the stacked denoising auto-encoders (SDA) and matrix factorization model. In CDL, the denoising auto-encoders is used to learn the hidden feature vectors from the auxiliary information of items.</p><p>DCF. Deep Collaborative Filtering model was developed in <ref type="bibr" target="#b17">[17]</ref>, which unifies the marginalized denoising auto-encoders (mDA) and matrix factorization model following CDL.</p><p>ST-LDA. ST-LDA <ref type="bibr" target="#b42">[42]</ref> is the state-of-the-art POI recommender model that can adapt to the spatial dynamics of user interests. It extends the topic model LDA to model region-aware personal interests by a topic distribution.</p><p>ST-GLDA. Inspired by the success of the recent word2vector techniques, we further extend ST-LDA to generate continuous word embeddings and use a multivariate Gaussian distribution to represent a topic following the Gaussian LDA model <ref type="bibr" target="#b7">[8]</ref>.</p><p>Note that we do not directly compare our SH-CDL with other powerful POI recommendation methods such as GT-BNMF <ref type="bibr" target="#b21">[21]</ref>, Geo-SAGE <ref type="bibr" target="#b35">[35]</ref>, Rank-GeoFM <ref type="bibr" target="#b18">[18]</ref> and LTSCR <ref type="bibr" target="#b47">[47]</ref>, because ST-LDA has been validated to outperform these methods in the same experimental settings and datasets in <ref type="bibr" target="#b42">[42]</ref>.</p><p>To further validate the benefits brought by each new technology developed in our SH-CDL, including spatial-aware personal preference modeling (T1), leveraging collective preferences to perform social regularization(T2), exploiting geographical correlation to smooth region-aware personal preferences (T3) and the late feature fusion strategy developed in MDBN (T4), we design four variant versions of SH-CDL. SH-CDL-T1 is the first variant version of SH-CDL where personal preferences are region-independent, i.e., p u is stable over different regions. Correspondingly, the social regularization and spatial smoothing techniques are not applicable to SH-CDL-T1. SH-CDL-T2 does not consider the collective preferences, and simply adopts zero as the Gaussian prior for the personal preference vector p u,r . SH-CDL-T3 does not exploit the geographical correlation to smooth personal preferences in the spatial pyramid. SH-CDL-T4 directly employs the conventional DBN with the early fusion strategy to model the heterogeneous features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Implementation Notes</head><p>Training deep learning models (e.g., DBN, SDA and mDA) on CPUs is extremely slow. GPUs with large memory are indispensable in deep learning experiments. Training the SH-CDL model on our two datasets takes two to three days using a single GPU with 4GB video memory. Hence, we developed a scalable parallel implementation of the SH-CDL by harnessing the powers of GPUs and clusters. Specifically, we deployed our SH-CDL model on an Amazon EC2 Multi-GPU cluster with 10 computing nodes (g2.2xlarge 3 ), each equipped with four high-performance NVIDIA GPUs. Each has 1536 CUDA cores and 4GB video memory. Stochastic gradient descent (SGD) is a popular technique for largescale optimization problems and has been widely adopted for the inference of deep learning models. However, traditional SGD processes one example per iteration, and this sequential nature makes SGD challenging for distributed inference. To parallelize the inference of our SH-CDL, we employed the efficient minibatch training which processes multiple examples at each iteration.</p><p>There are more than 20,000 distinct non-stop words in our datasets. To keep the text representation manageable, the content features are represented using a vocabulary of the 2000 most frequent words. Even so, x c v is still a sparse word count vector (i.e., the content features), and we employed a Replicate Softmax Model with 2000 visible and 200 hidden units followed by another layer of 50 hidden units. For the dense real-value features (i.e., the concatenation of the geo-location, popularity and neighborhood features), we employed a Gaussian RBM with 80 visible units followed by 30 hidden units. The joint layer for the two pathways contains 80 hidden units for the POI representation. Obviously, there are four layers in the pathway towards content features, while there are only three layers in the pathway towards the real-value features, because the predicative abilities of content features and the other three types of features are not in the same level. The three types of real-value features are closer to the learned latent features in the joint layer, since they are more powerful than the content features in predicting user check-in behaviors, as will be analyzed in Section 6.6. We actually tried different configurations of hyperparameters such as the number of layers and the number of units for each layer by referring to <ref type="bibr" target="#b11">[12]</ref>. With the above configuration, SH-CDL achieved the best recommendation performance. The pre-training was conducted for each pathway of the MDBN with the greedy layer-wise CD1 algorithm for 200 iterations, and then all the parameters were fine-tuned via the supervised gradient descent of the negative log-likelihood L SH-CDL . The mini-batch size for both pre-training and fine-tuning was 5000. The learning rate for the Gaussian RBM was 5 × 10 -5 and other RBMs 10 -2 . The fine-tune learning rate at the supervised training stage was 0.5, and the regularization parameters λ V =100, λ R =0.01. We use the cross-validation method to obtain the above configuration of hyperparameters with which our model achieved the optimal performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Evaluation methods</head><p>Our SH-CDL is designed to support both home-town and outof-town recommendation, we evaluate the recommendation effectiveness of our model in both scenarios. Given a collection of check-in records C u generated by each user u, we first divide C u into home-town check-ins C home u and out-of-town checkins C out u . To decide whether a check-in occurred in the home town or out of town, we measure the distance between the user's home location and the POI (i.e., |l u -l v |). If the distance is greater than ζ, then we assume the check-in occurred out of town. Otherwise, it occurred in the hometown. The check-in records in both C home u and C out u are first ranked according to their check-in timestamps. Then, we use the 80-th percentile as the cut-off point so that check-ins before this point are used for training, and the rest are for testing. In the training dataset, we choose the last 10% of the check-ins as the validation data to tune the model's hyperparameters such as the numbers of layers and the number of units in each layer. Note that C home u (or C out u ) is also included in the training set for the evaluation of the out-of-town recommendation (or the home-town recommendation).</p><p>According to the above dividing strategies, we split the dataset C into the training set C training and the test set C test . To evaluate the recommendation methods in top-k recommendation, we use the Accuracy@k measurement and evaluation methodology which has been widely adopted by <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b35">[35]</ref>, <ref type="bibr" target="#b41">[41]</ref>. Specifically, for each non-zero entry c u,v,s ∈ C test :</p><p>(1) We compute the ranking score for the ground-truth POI v as well as all others within the circle with center v and radius ζ and unvisited by u, instead of all POIs, since only those being geographically close to v are real competitors.</p><p>(2) We form a ranked list by ordering these POIs according to their scores. Let p denote the position of POI v in the ranking list.</p><p>(3) We form a top-k recommendation list by picking the k top ranked POIs from the list. If p ≤ k, we have a hit (i.e., the ground truth v is recommended to the user). Otherwise, we have a miss.</p><p>The computation of Accuracy@k is as follows.</p><formula xml:id="formula_38">Accuracy@k = #hit@k |C test |</formula><p>where #hit@k denotes the number of hits in the test set, and |C test | is the total number of all test cases. For models that can predict ratings, another evaluation metric -Mean Absolute Error (MAE) is also used to measure the deviation of the predicted ratings from their true values on the Yelp dataset. For each non-zero entry c u,v,s ∈ C test and a predicted rating ĉu,v,s , the absolute difference |c u,v,s -ĉu,v,s | is calculated between them as the error for that pair. Then M AE is computed as the average error over all test cases.</p><formula xml:id="formula_39">M AE = ∑ cu,v,s∈Ctest |c u,v,s -ĉu,v,s |/|C test |</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Recommendation Effectiveness</head><p>In this section, we report the comparison results between our proposed SH-CDL and other competitor methods with well-tuned parameters in Figures <ref type="figure" target="#fig_3">5</ref> and<ref type="figure" target="#fig_4">6</ref>. All differences between our model and the other comparison methods are statistically significant (p &lt; 0.01). We only show the performance where k is set to 1, 5, 10, 15, 20, as a greater value of k is usually ignored.</p><p>Out-of-Town Recommendation On Foursquare. Figure <ref type="figure" target="#fig_3">5</ref>(a) presents the recommendation accuracy in the out-of-town recommendation scenario, where the accuracy of SH-CDL is about 0.194 when k = 10 (i.e., the model has a probability of 19.4% of placing an appealing POI in the top-10). Clearly, our proposed SH-CDL significantly outperforms other models, and the relative improvements, in terms of Accuracy@10, are 20.13%, 24.61%, 115.06%, 119.75%, 130.42% and 205.54% compared with ST-GLDA, ST-LDA, DCF, CDL, HLDBN and DL-PFM, respectively.</p><p>Several observations are made from the results. First, SH-CDL achieves much higher recommendation accuracy than the stateof-the-art models ST-LDA and ST-GLDA. This demonstrates the effectiveness of SH-CDL by extracting and incorporating multiple types of POI features in a supervised and deep manner, while ST-LDA and ST-GLDA only integrate the textual and temporal information in an unsupervised and shallow way. Second, ST-GLDA performs slightly better than ST-LDA, showing the small benefit brought by the word embedding technique. Third, although all SH-CDL, DCF, CDL, HLDBN and DL-PMF are deep learningbased recommender models that integrate the same POI features, our SH-CDL outperforms others significantly due to the new techniques developed in the SH-CDL, including spatial-aware personal preference modeling, leveraging the collective preferences to perform social regularization, exploiting the geographical correlation to smooth personal preferences and multimodal learning from heterogeneous features. SH-CDL also learns a more robust POI representation from the raw features than DCF, CDL and HLDBN, because: 1) The DBN adopted by our SH-CDL is more robust to noise than the denoising auto-encoders <ref type="bibr" target="#b8">[9]</ref> used by CDL and DCF; and 2) HLDBN directly takes the learnt latent feature vectors as the latent factors in the matrix factorization, while our SH-CDL introduces the Gaussian noise. Fourth, among all the deep learningbased recommender models, DL-PMF lags far behind others. This is because DL-PMF adopts a pipeline approach to perform matrix factorization and hidden feature extraction in sequence and fails to capture their interaction and interdependence.</p><p>1041-4347 (c) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.  Home-Town Recommendation On Foursquare. Figure <ref type="figure" target="#fig_3">5</ref> (b) reports the experimental results in the home-town scenario, and our SH-CDL still achieves the best performance. From the results, we observe that the recommendation accuracies of all methods are higher in Figure <ref type="figure" target="#fig_3">5</ref>(b) than that in Figure <ref type="figure" target="#fig_3">5(a)</ref>. Another observation is that the relative improvements of our SH-CDL over other deep learning-based recommender models are smaller in the hometown scenario than in the out-of-town scenario. The comparison between Figure <ref type="figure" target="#fig_3">5</ref>(a) and Figure <ref type="figure" target="#fig_3">5</ref>(b) reveals that it is more difficult to produce accurate out-of-town recommendations.</p><p>Recommendation on Yelp. Figure <ref type="figure" target="#fig_4">6</ref> reports the performance of the recommendation models on the Yelp dataset. From the figure, we observe that the trend of comparison result is similar to that presented in Figure <ref type="figure" target="#fig_3">5</ref>, and the main difference is that all recommendation methods achieve lower accuracy. This may be because users' check-in data on this dataset is more sparse than on the Foursquare dataset (99.995% v.s. 99.98%). As explicit ratings are available in the Yelp dataset, we also evaluate the rating prediction performance of SH-CDL, DCF, CDL, HLDBN and DL-PMF in terms of MAE and present the results in Table <ref type="table" target="#tab_6">2</ref>. Obviously, our SH-CDL model achieves the least rating prediction error in both out-of-town and home-town recommendation scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Impact of Different Factors</head><p>As both recommendation techniques and POI features are essential to improving the recommendation effectiveness, we study their impacts in this experiment.</p><p>To explore the benefits brought by each new technique developed in SH-CDL, we compare our SH-CDL with its four variant versions discussed in Section 6.2. The comparison results on the two datasets are shown in Tables <ref type="table" target="#tab_7">3</ref> and<ref type="table" target="#tab_8">4</ref>, respectively. From the results, we first observe that SH-CDL consistently outperforms the four variant versions in both out-of-town and home-town recommendation scenarios, demonstrating the benefits brought by each new technique, respectively. For instance, the performance gap between SH-CDL and SH-CDL-T1 validates the benefit of region-aware dynamic personal preference modeling. Second, we find that the contribution of each new technique to improving recommendation accuracy is different. Another observation is that the contributions of the same technique are different in the two different recommendation scenarios. Specifically, according to the importance of the four techniques in the out-of-town recommendation scenario, they can be ranked as follows: T 1 &gt; T 2 &gt; T 3 &gt; T 4, while in the home-town recommendation scenario they can be ranked as T 4 &gt; T 1 &gt; T 3 &gt; T 2. This is because   the two recommendation scenarios have different characteristics: 1) most of users have enough check-in records in their home towns while few check-in activities are generated in out-of-town regions; and 2) people are very familiar with their home towns, and thus their visiting behaviors at home towns are mainly influenced by their personal preferences, while their visiting behaviors are significantly affected by the public's preferences when they travel out of town. Obviously, the region-aware user modeling technique enhanced by social regularization and spatial smoothing plays a dominant role in improving out-of-town recommendation, while the multimodal learning technique with late feature fusion strategy is most important for home-town recommendation.</p><p>To study the impact of each type of POI features, including the content features (F1), geo-location features (F2), popularity features (F3) and neighborhood features (F4), we design another four variant versions of SH-CDL, as shown in Table <ref type="table">5</ref>. We compare our SH-CDL with its four variant versions, respectively, and present the comparison results in Tables <ref type="table">6</ref> and<ref type="table" target="#tab_12">7</ref>. As expected, SH-CDL consistently outperforms the four variant versions in both out-of-town and home-town recommendation scenarios, demonstrating the benefits brought by each type of POI feature. We also observe that the contribution of each type of feature to improving recommendation accuracy is different. Obviously, the neighborhood features that are novelly exploited in this paper play a dominant role in both out-of-town and home-town recommendation scenarios. Another observation is that the contributions of F1, F2 and F3 are different in the two different recommendation scenarios. Specifically, according to the importance of the four types of features in the out-of-town recommendation scenario,  </p><formula xml:id="formula_40">• • SH-CDL-F2 • • • SH-CDL-F3 • • • SH-CDL-F4 • • • SH-CDL • • • • TABLE 6</formula><p>Recommendation Accuracy on Foursquare Dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Out-of-Town Scenario Home-Town Scenario Ac@1 Ac@10 Ac@20 Ac@1 Ac@10 Ac@20  they can be ranked as follows: F 4 &gt; F 3 &gt; F 1 &gt; F 2, while in the home-town recommendation scenario they can be ranked as</p><formula xml:id="formula_41">F 4 &gt; F 2 &gt; F 3 &gt; F 1.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7">Parameter Sensitivity Analysis</head><p>In this experiment, we study the impact of the spatial pyramid's height and the regularization parameter for personal preference vectors on the Foursquare dataset. The height of the spatial pyramid is an important parameter, since it determines the space partition granularity (i.e., the region size). To study its impact, we test the performance of the SH-CDL model by varying the height of spatial pyramid from 1 to 7. The results are presented in Table <ref type="table" target="#tab_13">8</ref>. When the height is set to 1, it means that there is no space partition, and our SH-CDL degrades to SH-CDL-T1 where personal preferences are assumed to be stable. From the results, we observe that the recommendation accuracy of SH-CDL first increases with increasing height, and then begins to slightly decrease when the height is larger than 5. One possible reason for the early increase is that increasing the height increases the exploitation of spatial dynamic of personal preferences makes the region-aware personal preferences precise. Later on, the recommendation accuracy begins to slightly decrease as the height continues to increase, because increasing the height makes personal check-in data in a region cell sparser and also means there are more parameters to be learnt. SH-CDL achieves its best performance when the height of spatial pyramid is 5, which could be a tradeoff between the aforementioned two factors. The size of a cell in level 5 is about 100km × 100km. Another observation is that the performance of SH-CDL is more sensitive to the height of the spatial pyramid in the out-of-town recommendation scenario than in the home-town scenario. λ U is another important hyper-parameter in SH-CDL. The larger the λ U , the more similar the personal preferences p u,r are to the collective preferences of the crowd with the same role θ s,r , and the more strongly p u,r is regularized. When λ U becomes extremely small, our SH-CDL would degenerate to SH-CDL-T2 where the collective preferences are not exploited. To study its impact, we test the performance of SH-CDL model by varying the value of λ U from 0.01 to 100, and the results are presented in Table <ref type="table" target="#tab_14">9</ref>. From the results, we observe that the recommendation accuracy of SH-CDL first increases with the increasing λ U , and then begins to decrease. Our SH-CDL achieves its best performances with different λ U values in the two different recommendation scenarios: Home-Town λ U =0.1 Vs. Out-of-Town λ U =10. There are two possible reasons: 1) users tend to follow the public's collective preferences when they travel in out-of-town regions, while they tend to follow their own preferences in their home town; and 2) users' generated check-ins in out-of-town regions are too sparse to enable the inference of their preferences for these regions without social regularization, while most of users have enough check-in data in their home towns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.8">Test for Cold-Start Recommendation</head><p>This experiment studies the effectiveness of the different recommender models for the cold start problem. We first test their performance in recommending cold-start POIs.</p><p>We first choose POIs with less than 10 check-ins as cold-start POIs, and then select users with at least one cold-start check-in as test users. For each test user, we first choose her check-ins associated with cold-start POIs as the test set, and the remaining check-ins as the training set. Our aim is to measure whether the marked-off cold-start POIs in the test set can be accurately recommended to the right users in the top-k results. As SH-CDL, ST-GLDA, ST-LDA, DCF, CDL, HLDBN and DL-PMF exploit the auxiliary information of POIs (i.e., POI features), all of them have the potential to recommend cold-start POIs to users. We test their recommendation effectiveness for cold-start POIs on the Foursquare dataset and present the results in Figure <ref type="figure" target="#fig_5">7</ref>. From the results, we observe that: 1) our SH-CDL model consistently outperforms the other models in recommending cold-start POIs, and its advantage is more obvious; 2) compared with the results in Figure <ref type="figure" target="#fig_3">5</ref>, the recommendation accuracies of all models for cold-start POIs decrease to different degrees, e.g., the degree of decrease of ST-LDA and ST-GLDA is much larger than that of our SH-CDL, as our SH-CDL deeply exploits multiple types of POI features in a supervised way while ST-LDA and ST-GLDA only leverage the textual and temporal information in an unsupervised and shallow manner; and 3) the top-k recommendation performances of all models show a more significant drop in the out-of-town setting than in the home-town scenario.</p><p>1041-4347 (c) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.  To test the recommendation performance for cold-start users, we choose users with less than 10 check-ins as cold-start users. For those cold-start users, we mark off their check-ins as the test set, and use the check-in records generated by the other users as the training set. Among all comparison methods, only ST-LDA and ST-GLDA are able to recommend POIs for cold-start users according to the collective preferences of the crowd with the same role in the target region. Thus, we compare our SH-CDL with ST-LDA, ST-GLDA and a strong baseline recommendation algorithm called Top-Pop that recommends the top-k POIs with highest popularity in the target region, and present the results in Figure <ref type="figure">8</ref>. By comparing the Figures <ref type="figure" target="#fig_3">5</ref> and<ref type="figure">8</ref>, we observe that, although the performances of ST-GLDA, ST-LDA and SH-CDL decrease to various degrees, for cold-start users, our proposed SH-CDL still achieves the best performance. As all SH-CDL, ST-LDA and ST-GLDA consider the role-aware crowd's preferences, they are more accurate than Top-Pop. Additionally, ST-LDA and ST-GLDA can only capture the popularity of POIs among the users with the same roles, while our SH-CDL can capture the collective preferences towards the POI features. Thus, the POIs with not so many check-ins but with popular features can still be recommended to the cold-start users by our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.9">Model Training Efficiency</head><p>In this experiment, we evaluate the efficiency of our SH-CDL model training in 4 different computational hardware environments: Single-CPU, Singe-GPU, Multi-GPUs and Multi-GPUs cluster, and also compare the training time of ST-LDA model. We conduct this experiment on an Amazon EC2 Multi-GPUs cluster with maximum of 10 computing nodes, each equipped with 4 high-performance NVIDIA GPUs. The Gibbs EM algorithm is used for the inference of ST-LDA <ref type="bibr" target="#b42">[42]</ref>, and Gibbs sampling is performed in the E-step. Because the Gibbs sampling procedure does not involve any matrix operation, it cannot take advantage of the power of GPUs. To speed up the training of ST-LDA, we implemented the ST-LDA on the distributed GraphLab system with 10 nodes. Figure <ref type="figure" target="#fig_7">9</ref> shows the training time of our SH-CDL model and ST-LDA model. We can conclude that the modern computational hardware environment (GPUs clusters) can effectively guarantee the scalability of our SH-CDL. Obviously, the training of our SH-CDL based on the GPUs cluster is much more efficient than ST-LDA with parallelization. Additionally, we make the following observations: 1) Single-GPU is 6.3x faster than Single-CPU, showing the advantage of GPU in training deep learning models; 2) as expected, Multi-GPU-4 is nearly 4x faster than the Single-GPU; and 3) as the number of computing nodes increases from 1 to 10, there is only a 7.0x increase in speed for the Multi-GPU-Cluster due to the synchronization cost of minibatch training. In a cluster environment, computing nodes need to communicate with each other for every mini-batch in order to synchronize the shared variables, such as gradients. Given that both bandwidth and latency of networks are at least 10x worse than physical memory, this overhead cannot be ignored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">RELATED WORK</head><p>In general, our work is closely related to content-aware collaborative filtering and POI recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Content-aware Collaborative Filtering</head><p>To address the issues surrounding the data sparsity and cold start, the matrix factorization models have been widely extended to content-aware factorization models by incorporating the content features, such as regression-based latent factor model <ref type="bibr" target="#b0">[1]</ref>, LibFM <ref type="bibr" target="#b28">[28]</ref>, SVD <ref type="bibr" target="#b2">[3]</ref> and ICCF <ref type="bibr" target="#b19">[19]</ref>. These models are almost equivalent in model representation, but adopt different optimization algorithms. A latent factor vector is learned for each feature besides users and items. Inspired by the success of word2vec <ref type="bibr" target="#b24">[24]</ref>, some embedding techniques were developed to embed features, users and items in the same latent space, such as Meta-Prod2Vec <ref type="bibr" target="#b33">[33]</ref>. However, these methods exploited the content features in a shallow way and assumed the interactions between features are linear. Recently, some deep learning models have been integrated to learn a deep item representation from its associated content information for recommendation <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b17">[17]</ref>, <ref type="bibr" target="#b32">[32]</ref>, <ref type="bibr" target="#b34">[34]</ref>, <ref type="bibr" target="#b37">[37]</ref>, <ref type="bibr" target="#b44">[44]</ref>, <ref type="bibr" target="#b51">[51]</ref>. For example, Oord et al. <ref type="bibr" target="#b32">[32]</ref>, Tim et al. <ref type="bibr" target="#b15">[15]</ref> and Zheng et al. <ref type="bibr" target="#b51">[51]</ref> applied a convolutional neural network (CNN) to process the content features. Wang et al. <ref type="bibr" target="#b37">[37]</ref> utilized deep belief nets (DBN) to process the music content. They assumed that a user has a latent factor vector drawn from a Gaussian prior, and a song has a latent factor vector learned by a deep belief network. Then, the matrix factorization was used to compute the preference score. Wang et al. <ref type="bibr" target="#b34">[34]</ref> proposed a hierarchical Bayesian model called collaborative deep learning (CDL) which used the stacked denoising auto-encoders (SDA) to process the item content and 1041-4347 (c) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TKDE.2017.2741484, IEEE Transactions on Knowledge and Data Engineering extended the collaborative topic regression (CTR) to compute user preferences. Li et al. <ref type="bibr" target="#b17">[17]</ref> extended CDL by replacing the SDA with the marginalized denoising stacked auto-encoders. Although these existing works have combined deep learning models with collaborative filtering to improve the recommendation, our work in this paper is distinct from theirs in several points. First, compared to our SH-CDL, existing models ignore the spatial dynamic of personal preferences. Second, they do not consider the heterogeneity and multi-modality of item content features. Third, they do not exploit the social and spatial correlations to alleviate the data sparsity issue in learning user preferences.</p><p>Our proposed SH-CDL is a generalized deep learning-based framework for POI recommendation and can be easily extended by other deep learning techniques to process the rich POI features. For example, the ReLU architecture <ref type="bibr" target="#b5">[6]</ref> can be adopted to process the content features of POIs and deals with the sparse textual features by the word2vector technique. The embedded sparse features are directly concatenated with the raw dense features to form a wide input layer. However, it is difficult for this architecture to discover highly non-linear relationships that exist between POI features across different modalities. The deep learning matcher in <ref type="bibr" target="#b44">[44]</ref> can be modified to process the textual content of POIs and then join with Gaussian restricted Boltzmann machine to obtain a unified POI representation. Similarly, the convolutional neural networks (CNN) in <ref type="bibr" target="#b51">[51]</ref> can also be used to replace the replicated softmax model to process the textual features of POIs. The stacked denoising autoencoder in <ref type="bibr" target="#b34">[34]</ref> can replace the Gaussian restricted Boltzmann machine to process the dense real-value features. We will compare the performance of these alternative components based on our SH-CDL framework in our future work.</p><p>Our SH-CDL is also related with GH-BDBN <ref type="bibr" target="#b48">[48]</ref>, since both of them used a late fusion strategy to learn a joint representation of an object from its associated heterogenous features. But GH-BDBN is designed for location estimation for a given image and does not consider the user-side information (e.g., user-item interaction history), thus it cannot apply to recommendation tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">POI Recommendation</head><p>Many recent studies <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b20">[20]</ref>, <ref type="bibr" target="#b40">[40]</ref> have shown that there is a strong correlation between user check-in activities and geographical distance as well as social connections, so most of current POI recommendation work mainly focuses on leveraging the geographical and social influences to improve recommendation accuracy. For example, Ye et al. <ref type="bibr" target="#b40">[40]</ref> delved into POI recommendation by investigating the geographical influences among locations and proposed a framework that combines user preferences, social influence and geographical influence. The temporal effect of user check-ins in LBSNs has also attracted much attention from researchers. POI recommendation with temporal effect mainly leverage temporal cyclic patterns <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b45">[45]</ref>, temporal sequential patterns <ref type="bibr" target="#b22">[22]</ref>, <ref type="bibr" target="#b50">[50]</ref> and temporal matching between POI popularity and user availability <ref type="bibr" target="#b39">[39]</ref>. Recently, researchers explored the content information of POIs to alleviate the issues surrounding data sparsity and cold start. Yin et al. <ref type="bibr" target="#b35">[35]</ref>, <ref type="bibr" target="#b36">[36]</ref>, <ref type="bibr" target="#b41">[41]</ref>, <ref type="bibr" target="#b42">[42]</ref> exploited both personal interests and local preferences based on the contents of POIs. Zhao et al. <ref type="bibr" target="#b49">[49]</ref> integrated both POI-associated contents and user sentiment information into POI recommendation. Lian et al. <ref type="bibr" target="#b19">[19]</ref> proposed an implicit-feedback based content-aware collaborative filtering framework to incorporate the semantic content for POI recommendation.</p><p>Compared with the above methods such as Geo-SAGE <ref type="bibr" target="#b35">[35]</ref>, ST-LDA <ref type="bibr" target="#b42">[42]</ref> and ST-SAGE <ref type="bibr" target="#b36">[36]</ref>, our work distinguishes from them in the following aspects. First, we proposed a spatial-aware user preference modeling method based on matrix factorization models. To overcome the challenge of data sparsity in inferring spatial-aware personal preferences, we proposed to regularize them with the spatial-aware crowd's preferences and spatially smooth them based on their geographically hierarchical additive representations. Second, we incorporated multiple types of heterogenous POI features in a generic way and developed a taskguided method to learn the unified deep representation of POIs from their associated heterogeneous features. To address the multimodality issue, we proposed a late non-linear fusion method. Third, we studied the contribution of each type of features to improve the recommendation accuracy and our proposed neighborhood features demonstrate the most superior predictive ability.</p><p>There are also some neural networks that can be straightforwardly applied to POI recommendation in the form of itembased collaborative filtering, such as collaborative denoising autoencoders <ref type="bibr" target="#b38">[38]</ref> and RBM <ref type="bibr" target="#b29">[29]</ref>. They take the POI IDs of each user as the input features and output the top-k recommendations. But they cannot address any challenge from the spatial dynamics of personal preferences, data sparsity and cold start.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSIONS</head><p>In this paper, we developed a novel POI recommendation model SH-CDL to jointly perform deep representation learning for POIs from heterogeneous features and hierarchically additive representation learning for spatial-aware personal preferences to overcome the challenges of the spatial dynamics of user preferences, cold start and data sparsity. Social regularization and spatial smoothing technologies were developed to overcome data sparsity in the spatial-aware dynamic user preference modeling. To deal with the multimodal heterogeneous features, we extended the DBN to MDBN by introducing a late feature fusion strategy. Extensive experiments were conducted, and the experimental results showed that our SH-CDL model significantly outperforms the state-of-theart recommendation methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Restricted Boltzmann Machine and Deep Belief Networks with Two Latent Layers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>6 EntireFig. 3 .</head><label>63</label><figDesc>Fig. 3. The Spatial Pyramid with Four Layers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Two Feature Fusion Strategies in DBN. Different colors represent different modalities of features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Top-k Performance on Foursquare Dataset</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Top-k Performance on Yelp Dataset</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Top-k Performance for Cold-start POIs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Fig. 8. Top-k Performance for Cold-start Users.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Model Training Time On Yelp Dataset. SH-CDL-Multi-GPUs (4) means that there are 4 GPUs. SH-CDL-GPUs-Cluster (10) means there are 10 computing nodes, each with 4 GPUs.</figDesc><graphic coords="12,393.45,45.30,153.16,121.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TKDE.2017.2741484, IEEE Transactions on Knowledge and Data Engineering</figDesc><table><row><cell>… … … Fig. 2. The Geographical Representation of SH-CDL DBN</cell><cell>Definition 3. (Check-in) A check-in is a triplet (u, v, s) that means user u visits POI v with the role of s. If s = 1, the user is recognized as a local and the check-in activity occurs in u's home town. If s = 0, u is a tourist when visiting v. Definition 4. (Check-in Cuboid) A check-in cuboid C is a M × N × 2 cuboid, where M is the number of users, N is the number of POIs, and 2 is the number of roles. A cell indexed by (u, 4</cell></row></table><note><p>v, s) (i.e., c u,v,s ) stores the feedback/rating of u to v with the role s. Without loss of generality, c u,v,s is normalized 1041-4347 (c) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TKDE.2017.2741484, IEEE Transactions on Knowledge and Data Engineering</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>7</cell></row><row><cell>∂LSH-CDL ∂ϕu,r j</cell><cell>= 2</cell><cell>r h ∈r j ∑</cell><cell>v∈Vr h ∑</cell><cell>s∈{0,1} ∑</cell><cell cols="2">Iu,v,sg</cell><cell cols="2">′ (p T u,r h</cell><cell cols="2">qv)(g(p T u,r h</cell><cell>qv) -cu,v,s) + λ U</cell><cell>r h ∈r j ∑</cell><cell>s∈{0,1} ∑</cell><cell>Iu,r h ,s (pu,r h -θs,r h ),</cell><cell>(18)</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">∂ϑs,r j ∂LSH-CDL</cell><cell cols="2">= λU</cell><cell cols="2">r h ∈r j ∑</cell><cell>∑</cell><cell></cell><cell></cell></row></table><note><p><p>1041-4347 (c) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. u∈U Iu,r h ,s (θs,r h -pu,r h ) + λRϑs,r j ,</p><ref type="bibr" target="#b19">(19)</ref> </p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TKDE.2017.2741484, IEEE Transactions on Knowledge and Data Engineering</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>TABLE 1</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">Features of Different Methods.</cell><cell></cell><cell></cell></row><row><cell>Features</cell><cell>Spatial-aware</cell><cell>Spatial-Aware</cell><cell cols="2">Supervised Hidden Unsupervised Hidden</cell><cell>Late</cell><cell>Early</cell></row><row><cell>Methods</cell><cell cols="2">User Preferences Crowd's Preferences</cell><cell>Feature Extraction</cell><cell>Feature Extraction</cell><cell cols="2">Feature Fusion Feature Fusion</cell></row><row><cell>SH-CDL</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>2. https://www.yelp.com/dataset challenge 1041-4347 (c) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TKDE.2017.2741484, IEEE Transactions on Knowledge and Data Engineering</figDesc><table /><note><p>3. https://aws.amazon.com/ec2/instance-types/ 1041-4347 (c) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 2 Rating</head><label>2</label><figDesc>Citation information: DOI 10.1109/TKDE.2017.2741484, IEEE Transactions on Knowledge and Data Engineering Prediction on the Yelp Dataset.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">Out-of-Town Recommendation Scenario</cell><cell cols="2">Home-Town Recommendation Scenario</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>SH-CDL</cell><cell>DCF</cell><cell>CDL</cell><cell>HLDBN</cell><cell>DL-PMF</cell><cell>SH-CDL</cell><cell>DCF</cell><cell>CDL</cell><cell>HLDBN</cell><cell>DL-PMF</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.976</cell><cell>1.192</cell><cell>1.234</cell><cell>1.316</cell><cell>1.451</cell><cell>0.891</cell><cell>1.036</cell><cell>1.064</cell><cell>1.147</cell><cell>1.263</cell></row><row><cell>1</cell><cell>5</cell><cell>10</cell><cell>15</cell><cell>20</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE 3 Recommendation</head><label>3</label><figDesc>Accuracy on Foursquare Dataset.</figDesc><table><row><cell>Methods</cell><cell cols="3">Out-of-Town Scenario Ac@1 Ac@10 Ac@20</cell><cell cols="3">Home-Town Scenario Ac@1 Ac@10 Ac@20</cell></row><row><cell>SH-CDL-T1</cell><cell>0.078</cell><cell>0.142</cell><cell>0.173</cell><cell>0.144</cell><cell>0.252</cell><cell>0.305</cell></row><row><cell>SH-CDL-T2</cell><cell>0.090</cell><cell>0.164</cell><cell>0.194</cell><cell>0.149</cell><cell>0.261</cell><cell>0.317</cell></row><row><cell>SH-CDL-T3</cell><cell>0.092</cell><cell>0.168</cell><cell>0.200</cell><cell>0.146</cell><cell>0.255</cell><cell>0.310</cell></row><row><cell>SH-CDL-T4</cell><cell>0.095</cell><cell>0.173</cell><cell>0.206</cell><cell>0.139</cell><cell>0.244</cell><cell>0.296</cell></row><row><cell>SH-CDL</cell><cell>0.103</cell><cell>0.194</cell><cell>0.229</cell><cell>0.155</cell><cell>0.272</cell><cell>0.329</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE 4 Recommendation</head><label>4</label><figDesc>Accuracy on Yelp Dataset.</figDesc><table><row><cell>Methods</cell><cell cols="3">Out-of-Town Scenario Ac@1 Ac@10 Ac@20</cell><cell cols="3">Home-Town Scenario Ac@1 Ac@10 Ac@20</cell></row><row><cell>SH-CDL-T1</cell><cell>0.045</cell><cell>0.108</cell><cell>0.143</cell><cell>0.102</cell><cell>0.201</cell><cell>0.243</cell></row><row><cell>SH-CDL-T2</cell><cell>0.062</cell><cell>0.118</cell><cell>0.150</cell><cell>0.106</cell><cell>0.209</cell><cell>0.252</cell></row><row><cell>SH-CDL-T3</cell><cell>0.063</cell><cell>0.120</cell><cell>0.153</cell><cell>0.104</cell><cell>0.205</cell><cell>0.247</cell></row><row><cell>SH-CDL-T4</cell><cell>0.066</cell><cell>0.125</cell><cell>0.159</cell><cell>0.097</cell><cell>0.191</cell><cell>0.232</cell></row><row><cell>SH-CDL</cell><cell>0.071</cell><cell>0.136</cell><cell>0.173</cell><cell>0.119</cell><cell>0.228</cell><cell>0.278</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>1041-4347 (c) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TKDE.2017.2741484, IEEE Transactions on Knowledge and Data Engineering TABLE 5 Features of Different Variants of SH-CDL.</figDesc><table><row><cell>Methods</cell><cell>Features</cell><cell>F1</cell><cell>F2</cell><cell>F3</cell><cell>F4</cell></row><row><cell cols="2">SH-CDL-F1</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>TABLE 7 Recommendation</head><label>7</label><figDesc>Accuracy on Yelp Dataset.</figDesc><table><row><cell>Methods</cell><cell cols="3">Out-of-Town Scenario Ac@1 Ac@10 Ac@20</cell><cell cols="3">Home-Town Scenario Ac@1 Ac@10 Ac@20</cell></row><row><cell>SH-CDL-F1</cell><cell>0.059</cell><cell>0.119</cell><cell>0.154</cell><cell>0.103</cell><cell>0.211</cell><cell>0.250</cell></row><row><cell>SH-CDL-F2</cell><cell>0.062</cell><cell>0.121</cell><cell>0.160</cell><cell>0.098</cell><cell>0.201</cell><cell>0.239</cell></row><row><cell>SH-CDL-F3</cell><cell>0.054</cell><cell>0.114</cell><cell>0.149</cell><cell>0.101</cell><cell>0.207</cell><cell>0.245</cell></row><row><cell>SH-CDL-F4</cell><cell>0.051</cell><cell>0.109</cell><cell>0.141</cell><cell>0.092</cell><cell>0.195</cell><cell>0.232</cell></row><row><cell>SH-CDL</cell><cell>0.071</cell><cell>0.136</cell><cell>0.173</cell><cell>0.119</cell><cell>0.228</cell><cell>0.278</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>TABLE 8</head><label>8</label><figDesc>Study of The Impact of Spatial Pyramid Height.</figDesc><table><row><cell>Height</cell><cell cols="3">Out-of-Town Scenario Ac@1 Ac@10 Ac@20</cell><cell cols="3">Home-Town Scenario Ac@1 Ac@10 Ac@20</cell></row><row><cell>1</cell><cell>0.078</cell><cell>0.142</cell><cell>0.173</cell><cell>0.144</cell><cell>0.252</cell><cell>0.305</cell></row><row><cell>2</cell><cell>0.082</cell><cell>0.161</cell><cell>0.188</cell><cell>0.146</cell><cell>0.256</cell><cell>0.309</cell></row><row><cell>3</cell><cell>0.087</cell><cell>0.172</cell><cell>0.195</cell><cell>0.147</cell><cell>0.258</cell><cell>0.313</cell></row><row><cell>4</cell><cell>0.096</cell><cell>0.183</cell><cell>0.217</cell><cell>0.151</cell><cell>0.264</cell><cell>0.320</cell></row><row><cell>5</cell><cell>0.103</cell><cell>0.194</cell><cell>0.229</cell><cell>0.155</cell><cell>0.272</cell><cell>0.329</cell></row><row><cell>6</cell><cell>0.102</cell><cell>0.188</cell><cell>0.215</cell><cell>0.152</cell><cell>0.267</cell><cell>0.323</cell></row><row><cell>7</cell><cell>0.098</cell><cell>0.182</cell><cell>0.207</cell><cell>0.149</cell><cell>0.262</cell><cell>0.317</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>TABLE 9</head><label>9</label><figDesc>Study of The Impact of Regularization Parameter λ U .</figDesc><table><row><cell>λU</cell><cell cols="3">Out-of-Town Scenario Ac@1 Ac@10 Ac@20</cell><cell cols="3">Home-Town Scenario Ac@1 Ac@10 Ac@20</cell></row><row><cell>0.01</cell><cell>0.092</cell><cell>0.166</cell><cell>0.196</cell><cell>0.150</cell><cell>0.263</cell><cell>0.318</cell></row><row><cell>0.1</cell><cell>0.097</cell><cell>0.170</cell><cell>0.201</cell><cell>0.155</cell><cell>0.272</cell><cell>0.329</cell></row><row><cell>1</cell><cell>0.100</cell><cell>0.179</cell><cell>0.212</cell><cell>0.152</cell><cell>0.267</cell><cell>0.323</cell></row><row><cell>10</cell><cell>0.103</cell><cell>0.194</cell><cell>0.229</cell><cell>0.149</cell><cell>0.262</cell><cell>0.316</cell></row><row><cell>50</cell><cell>0.101</cell><cell>0.177</cell><cell>0.210</cell><cell>0.143</cell><cell>0.251</cell><cell>0.304</cell></row><row><cell>100</cell><cell>0.097</cell><cell>0.171</cell><cell>0.201</cell><cell>0.138</cell><cell>0.242</cell><cell>0.293</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Regression-based latent factor models</title>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<author>
			<persName><forename type="first">B.-C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="19" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Location-based and preferenceaware recommendation using sparse geo-social networking data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Mokbel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGSPATIAL</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="199" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Svdfeature: A toolkit for feature-based collaborative filtering</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3619" to="3622" />
			<date type="published" when="2012-12">Dec. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Exploring millions of footprints in location sharing services</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Caverlee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Z</forename><surname>Sui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICWSM</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Friendship and mobility: user movement in location-based social networks</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1082" to="1090" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep neural networks for youtube recommendations</title>
		<author>
			<persName><forename type="first">P</forename><surname>Covington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sargin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="191" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Performance of recommender algorithms on top-n recommendation tasks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cremonesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Turrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="39" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Gaussian lda for topic models with word embeddings</title>
		<author>
			<persName><forename type="first">R</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="795" to="804" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A study on the similarities of deep belief networks and stacked autoencoders</title>
		<author>
			<persName><forename type="first">A</forename><surname>De Giorgio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Thesis</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Location recommendation for out-oftown users in location-based social networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ference</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="721" to="726" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Exploring temporal effects for location recommendation on location-based social networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="93" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A practical guide to training restricted boltzmann machines</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks: Tricks of the Trade</title>
		<imprint>
			<biblScope unit="page" from="599" to="619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Personal use is permitted, but republication/redistribution requires IEEE permission</title>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<ptr target="http://www.ieee.org/publications_standards/publications/rights/index.html" />
	</analytic>
	<monogr>
		<title level="m">for more information</title>
		<imprint>
			<date type="published" when="2012">2012. 2017</date>
			<biblScope unit="page" from="1041" to="4347" />
		</imprint>
	</monogr>
	<note>IEEE</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Replicated softmax: an undirected topic model</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1607" to="1614" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Convolutional matrix factorization for document context-aware recommendation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Towards social user profiling: unified and discriminative influence model for inferring home locations</title>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-C</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1023" to="1031" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep collaborative filtering via marginalized denoising auto-encoder</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kawale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="811" to="820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Rankgeofm: A ranking based geographical factorization method for point of interest recommendation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-A</forename><forename type="middle">N</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Krishnaswamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="433" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Content-aware collaborative filtering for location recommendation based on human mobility data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="261" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Geomf: Joint geographical modeling and matrix factorization for point-of-interest recommendation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="831" to="840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning geographical preferences for point-of-interest recommendation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1043" to="1051" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unified point-of-interest recommendation with temporal interval assessment</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1015" to="1024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Urban nuclei and the geometry of streets: the &apos;emergent neighborhoods&apos; model</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mehaffy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Porta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Salingaros</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Urban Design International</publisher>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="22" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Probabilistic matrix factorization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1257" to="1264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Does distance matter in the age of the internet?</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wellman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carrasco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Urban Studies</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="2747" to="2783" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">One-class collaborative filtering</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lukose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Scholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="502" to="511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Factorization machines with libFM</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Intell. Syst. Technol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">22</biblScope>
			<date type="published" when="2012-05">May 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Restricted boltzmann machines for collaborative filtering</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="791" to="798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Socio-spatial properties of online location-based social networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Scellato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Noulas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lambiotte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mascolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICWSM</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Multimodal learning with deep boltzmann machines</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2222" to="2230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep content-based music recommendation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schrauwen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2643" to="2651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Meta-prod2vec: Product embeddings using side-information for recommendation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Vasile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Smirnova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="225" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Collaborative deep learning for recommender systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-Y</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1235" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Geosage: A geographical sparse additive generative model for spatial item recommendation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sadiq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1255" to="1264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">St-sage: A spatial-temporal sparse additive generative model for spatial item recommendation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sadiq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Intell. Syst. Technol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="48" />
			<date type="published" when="2017-04">Apr. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Improving content-based and hybrid music recommendation using deep learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MM</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="627" to="636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Collaborative denoising auto-encoders for top-n recommender systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="153" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Poi recommendation: A temporal matching between poi popularity and user regularity</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="549" to="558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Exploiting geographical influence for collaborative point-of-interest recommendation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-L</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="325" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Lcars: A location-contentaware recommender system</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="221" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Adapting to user interest drift for poi recommendation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V H</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2566" to="2581" />
			<date type="published" when="2016-10">Oct 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Joint modeling of user check-in behaviors for point-of-interest recommendation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sadiq</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1631" to="1640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Solving cold-start problem in large-scale recommendation engines: A deep learning approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shalaby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Korayem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Aljadda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Big Data</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1901" to="1910" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Time-aware point-of-interest recommendation</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Thalmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="363" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Collaborative knowledge base embedding for recommender systems</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="353" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Location and time aware social collaborative retrieval for new successive point-of-interest recommendation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1221" to="1230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning geographical hierarchy features for social image location prediction</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2401" to="2407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Sar: A sentiment-aspect-region model for user preference analysis in geo-tagged reviews</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Stellar: Spatialtemporal latent ranking for successive point-of-interest recommendation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="315" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Joint deep modeling of users and items using reviews for recommendation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="425" to="434" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
