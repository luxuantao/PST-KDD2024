<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Practical Guide to Select Quality Indicators for Assessing Pareto-Based Search Algorithms in Search-Based Software Engineering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shuai</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Simula Research Laboratory</orgName>
								<address>
									<settlement>Oslo</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shaukat</forename><surname>Ali</surname></persName>
							<email>shaukat@simula.no</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Simula Research Laboratory</orgName>
								<address>
									<settlement>Oslo</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tao</forename><surname>Yue</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Simula Research Laboratory</orgName>
								<address>
									<settlement>Oslo</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">University of Oslo</orgName>
								<address>
									<settlement>Oslo</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yan</forename><surname>Li</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Beihang University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marius</forename><surname>Liaaen</surname></persName>
							<email>marliaae@cisco.com</email>
							<affiliation key="aff3">
								<orgName type="institution">Cisco Systems</orgName>
								<address>
									<settlement>Oslo</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Practical Guide to Select Quality Indicators for Assessing Pareto-Based Search Algorithms in Search-Based Software Engineering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7E1A083A60D65FD7563A0BFE8CF0DB69</idno>
					<idno type="DOI">10.1145/2884781.2884880</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Quality Indicators</term>
					<term>Multi-objective Software Engineering Problems</term>
					<term>Pareto-based Search Algorithms</term>
					<term>Practical Guide</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Many software engineering problems are multi-objective in nature, which has been largely recognized by the Search-based Software Engineering (SBSE) community. In this regard, Paretobased search algorithms, e.g., Non-dominated Sorting Genetic Algorithm II, have already shown good performance for solving multi-objective optimization problems. These algorithms produce Pareto fronts, where each Pareto front consists of a set of nondominated solutions. Eventually, a user selects one or more of the solutions from a Pareto front for their specific problems. A key challenge of applying Pareto-based search algorithms is to select appropriate quality indicators, e.g., hypervolume, to assess the quality of Pareto fronts. Based on the results of an extended literature review, we found that the current literature and practice in SBSE lacks a practical guide for selecting quality indicators despite a large number of published SBSE works. In this direction, the paper presents a practical guide for the SBSE community to select quality indicators for assessing Pareto-based search algorithms in different software engineering contexts. The practical guide is derived from the following complementary theoretical and empirical methods: 1) key theoretical foundations of quality indicators; 2) evidence from an extended literature review; and 3) evidence collected from an extensive experiment that was conducted to evaluate eight quality indicators from four different categories with six Pareto-based search algorithms using three real industrial problems from two diverse domains.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Many software engineering problems are multi-objective in nature and can be formulated as multi-objective optimization problems (MOPs) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b7">8]</ref>. A substantial number of works in Search-Based Software Engineering (SBSE) has shown the capability to solve MOPs using Pareto-based search algorithms that are based on Pareto optimality theory <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref>. A Pareto-based search algorithm produces a Pareto front consisting of a set of non-dominated solutions (i.e., solutions with equivalent quality) from which users can select one or more solutions for their specific needs. It is therefore important to assess the quality of Pareto fronts produced by these algorithms to determine the applicability of SBSE for solving MOPs <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b27">28]</ref>.</p><p>To evaluate the quality of Pareto fronts, the existing works in SBSE have applied several quality indicators, e.g., hypervolume (HV), Epsilon ( ùúñ ), Generalized Spread (GS), Generational Distance (GD), and Pareto Front Size (PFS). These quality indicators are further classified into different categories, e.g., ùúñ and GD are defined to measure the Convergence between solutions produced by search algorithms and optimal solutions, and GS is defined to measure the Diversity of solutions in a Pareto front <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b64">65]</ref>. However, based on the improved literature review that we conducted by extending the one reported in <ref type="bibr" target="#b12">[13]</ref>, we discovered that the current literature of SBSE lacks a practical guide to select quality indicators for different software engineering applications. More specifically, the current literature lacks the evidence for selecting quality indicators for the following three cases. First, there is no evidence to show whether it matters to select a particular quality indicator within the same category (e.g., Convergence). For example, if the Pareto front produced by Non-dominated Sorting Genetic Algorithm II (NSGA-II) has a better value of GD (Convergence) than the one produced by Improved Strength Pareto Evolutionary Algorithm (SPEA2), there is no evidence that we can observe the same phenomenon for ùúñ (Convergence). Second, there is no evidence whether it matters to select a particular quality indicator from different categories. For example, using GD from Convergence and GS from Diversity, there is no evidence to show that the same trend of performance can be observed for NSGA-II and SPEA2. Finally, there is no evidence whether computation time can be used as a criterion for selecting quality indicators. It is important to note that the existing works usually chose a subset of the existing quality indicators without proper justification and in most cases, HV was selected because of its popularity <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b50">[51]</ref><ref type="bibr" target="#b51">[52]</ref><ref type="bibr" target="#b52">[53]</ref><ref type="bibr" target="#b53">[54]</ref><ref type="bibr" target="#b54">[55]</ref><ref type="bibr" target="#b55">[56]</ref>.</p><p>In this paper, we propose a practical guide to select quality indicators for assessing Pareto-based search algorithms in SBSE using the following theoretical and empirical methods: 1) Theoretical foundations of quality indicators, 2) The extended literature review, and 3) An extensive experiment. An overview of the approach that we used to derive the guide is shown in Figure <ref type="figure">1</ref>.</p><p>As shown in Figure <ref type="figure">1</ref>, first, we studied the theoretical foundations of the quality indicators and conducted an extended literature review based on <ref type="bibr" target="#b12">[13]</ref> from the existing literature (Step 1). In the second step (Step 2 in Figure <ref type="figure">1</ref>), we conducted an extensive experiment with eight quality indicators that have been applied in the existing works <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b11">12,</ref>. These quality indicators are classified into four different categories, i.e., Convergence: GD, Euclidean Distance (ED), ùúñ; Diversity: PFS and GS; Combination of convergence and diversity (Combination): Inverted Generational Distance (IGD), HV and Coverage: Coverage (C) <ref type="bibr" target="#b8">[9]</ref>. We evaluate these quality indicators together with six commonly-used Pareto-based search algorithms (e.g., NSGA-II) by employing three industrial software engineering MOPs based on our long-term collaboration from communication and subsea oil&amp;gas domains. From the communication domain, we selected two problems on testing Video Conferencing Systems (VCSs) <ref type="bibr" target="#b9">[10]</ref> including: test suite minimization problem (TM) with four objectives and test case prioritization problem (TP) with four objectives. From the subsea oil&amp;gas domain, we selected one requirements allocation problem (RA) with three objectives <ref type="bibr" target="#b10">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1 Approach for developing the practical guide</head><p>The remainder of the paper is organized as: Section 2 provides theoretical foundations of Pareto optimality, Pareto-based search algorithms, and quality indicators followed by presenting the extended literature review (Section 3). Section 4 presents the extensive experiment and Section 5 provides the practical guide. Last, Section 6 concludes the paper and sketches the future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">THEORETICAL FOUNDATIONS</head><p>This section presents theoretical foundations for Pareto optimality theory (Section 2.1), six Pareto-based search algorithms (Section 2.2) and eight quality indicators (Section 2.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Pareto Optimality Theory</head><p>Multi-objective optimization is usually based on the Pareto optimality theory <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b25">26]</ref>, which aims to balance several trade-off objectives and produces a number of solutions with equal quality. Pareto optimality defines dominance to compare solutions, i.e., a solution A is said to dominate another solution B, if for all objectives, A is no worse than B at the same time at least one objective exists that A is better than B.</p><p>Formally speaking, suppose there are ùëö objectives ùëÇ = {ùëú ! , ùëú ! , ‚Ä¶ , ùëú ! } to be optimized (let's say minimization), which can be defined as a set of objective functions</p><formula xml:id="formula_0">ùêπ = {ùëì ! , ùëì ! , ‚Ä¶ , ùëì ! }. Solution A dominates solution B (i.e., ùê¥ ‚âª ùêµ ) if and only if ‚àÄùëñ ‚àà 1,2, ‚Ä¶ , ùëö , ùëì ! ùê¥ ‚â§ ùëì ! ùêµ ùëéùëõùëë ‚àÉùëó ‚àà 1,2, ‚Ä¶ , ùëö , ùëì ! ùê¥ &lt; ùëì ! ùêµ .</formula><p>The set of solutions that cannot be dominated by others are considered as equally viable, which is named as Pareto front. An optimal Pareto front (also called true Pareto front) includes all non-dominated solutions that exist in a given search space for a problem, while a Pareto front obtained by a particular search algorithm is usually named as a computed Pareto Front <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b25">26]</ref>.</p><p>Thus, multi-objective search algorithms based on the Pareto optimality theory aim at exploring a given search space and outputs a Pareto front with the aim to provide users with a number of alternative solutions, from which, users can choose the most appropriate solution based on their specific requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Six Pareto-based Search Algorithms</head><p>Search algorithms aim at mimicking natural phenomenon (e.g., bird flocking) to search optimal solutions for optimization problems <ref type="bibr" target="#b16">[17]</ref>. To apply search algorithms, fitness functions should be defined to assess the quality of obtained solutions. This paper selects six Pareto-based search algorithms, which are classified into three categories (Table <ref type="table" target="#tab_0">1</ref>) <ref type="bibr" target="#b16">[17]</ref>. Notice that our goal is to cover a representative set of existing search algorithms rather than limiting to commonly used ones (e.g., NSGA-II and SPEA2). To achieve this, the six algorithms were chosen systematically for covering at least one algorithm per category <ref type="bibr" target="#b16">[17]</ref>. NSGA-II sorts the population into several non-dominated fronts using a ranking algorithm followed by selecting individuals from these non-dominated fronts and generates new population by applying selection, crossover and mutation operators <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b17">18]</ref>. Moreover, NSGA-II defines a metric called crowding distance to measure the distance between an individual solution and the others. If two individual solutions are in the same non-dominated front, the solution with a higher value of the crowding distance is selected. The aim for crowding distance indicator is to maximize the diversity of the outputted non-dominated solutions.</p><p>Multi-objective Cellular (MOCell) is based on the cellular model of GAs (cGAs) with an assumption that an individual only interacts with its neighbours during the search process <ref type="bibr" target="#b18">[19]</ref>. Moreover, MOCell stores a set of obtained non-dominated individual solutions in an external archive. After each generation, MOCell replaces a fixed number of solutions randomly chosen from the population by selecting the same number of solutions from the archive until the termination conditions are met. Such replacement only takes place when newly generated solutions from the population are worse than the ones in the archive.</p><p>Improved Strength Pareto Evolutionary Algorithm (SPEA2) calculates the fitness value for each solution by summing up a strength raw fitness based on the objective functions and density estimation <ref type="bibr" target="#b19">[20]</ref>. The density estimation measures the distance between a solution and its nearest neighbours for maximizing the diversity. SPEA2 stores a fixed number of best solutions into an archive by applying selection, crossover and mutation operators. Then, a new population is created by combining solutions from the archive and the non-dominated solutions of the original population. If the combined non-dominated solutions are greater than the maximum size of the population, the solution with the minimum distance to any other solution is selected by applying a truncation operator to calculate the distances to its neighbourhood.</p><p>Pareto Archived Evolution Strategy (PAES) applies the dynamic mutation operator for exploring the search space and manages to find optimal solutions <ref type="bibr" target="#b20">[21]</ref>. PAES also stores the obtained non-dominated solutions into an archive and newly generated solutions can be added into the archive if they are better than existing solutions by calculating objective functions.</p><p>The Speed-constrained Multi-objective Particle Swarm Optimization (SMPSO) is a biological metaheuristic inspired by the social foraging behaviour of animals such as bird flocking <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b21">22]</ref>. SMPSO selects the best solutions by calculating the crowding distance and stores the selected individual solutions in an archive. SMPSO takes advantage of mutation operators to accelerate the input input speed of convergence and adapts the velocity constriction mechanism to avoid the explosion of swarms <ref type="bibr" target="#b21">[22]</ref>.</p><p>The Differential Evolution (DE) algorithm is considered as another kind of EA, which generates solutions by applying recombination, mutation and selection operators <ref type="bibr" target="#b16">[17]</ref>. DE calculates the weighted difference between two randomly selected parent solutions and integrates obtained weighted different parts into a third parent solution for generating an offspring. CellDE is a hybrid metaheuristic algorithm using MOCell as a search engine and replacing the typical selection, crossover and mutation operators for GAs with the recombination mechanism of DE <ref type="bibr" target="#b22">[23]</ref>. CellDE takes the advantage of cellular GA and DE with good diversity and convergence <ref type="bibr" target="#b22">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Quality Indicators</head><p>To assess the quality of Pareto fronts produced by algorithms, a certain number of quality indicators has been proposed and applied by the existing works, e.g., Generational Distance (GD) <ref type="bibr" target="#b28">[29]</ref>, Inverted Generation Distance (IGD) <ref type="bibr" target="#b8">[9]</ref>, Hypervolume (HV) <ref type="bibr" target="#b27">[28]</ref>, Epsilon (ùúñ) <ref type="bibr" target="#b25">[26]</ref>, Generalized Spread (GS) <ref type="bibr" target="#b26">[27]</ref>. Based on the existing literature <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b25">26]</ref>, we selected the most commonly used eight quality indicators and classified them into four categories based on their definitions, convergence, diversity, combination of convergence and diversity (combination), and coverage (shown in Table <ref type="table" target="#tab_1">2</ref>).</p><p>As discussed in Section 2.1, the optimal Pareto front and a computed Pareto front obtained by an algorithm are referred as ùëÉùêπ ! and ùëÉùêπ ! , respectively. It is worth mentioning that obtaining ùëÉùêπ ! for an optimization problem is infeasible in practice due to the limited time or resources <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b26">27]</ref>. Thus, when applying quality indicators to evaluate Pareto-based search algorithms, a reference Pareto front (ùëÉùêπ !"# ) is often computed to represent the optimal Pareto front (ùëÉùêπ ! ). Suppose ùëõ number of search algorithms produce ùëõ computed Pareto fronts: ùëÉùêπ !! , ùëÉùêπ !! ,‚Ä¶, ùëÉùêπ !" , ùëÉùêπ !"# is then a union of all the non-dominated solutions from these ùëõ computed Pareto fronts, which can be calculated as: Convergence. 1) Generational Distance (GD) is defined to measure how far are the solutions that exist in ùëÉùêπ ! from the nearest solutions in ùëÉùêπ ! <ref type="bibr" target="#b28">[29]</ref>, which can be calculated using the formula:</p><formula xml:id="formula_1">ùëÉùêπ !"! = (‚àÑ ! ! ‚àà !" !" ! !!! ùë† ! ‚àà ùëÉùêπ !" ! !!! )(ùë† ! ‚âª ùë† ! ) .</formula><formula xml:id="formula_2">ùê∫ùê∑ = !(! ! ,!" ! ) ! |!"!| !!! |!" ! |</formula><p>, where |ùëÉùêπ ! | is the cardinality of ùëÉùêπ ! (i.e., the number of solutions included in ùëÉùêπ ! ) and ùëë(ùë† ! , ùëÉùêπ ! ) refers to the minimum Euclidean distance from the solution ùë† ! in ùëÉùêπ ! to ùëÉùêπ ! , i.e., the Euclidean distance between ùë† ! in ùëÉùêπ ! and the nearest solution in ùëÉùêπ ! . A value of 0 for GD indicates that ùëÉùêπ ! and ùëÉùêπ ! are the same, i.e., all the obtained solutions by a search algorithm are optimal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Euclidean Distance from the Ideal Solution (ED) measures the</head><p>Euclidean distance between the ideal solution and the closest solution in ùëÉùêπ ! <ref type="bibr" target="#b31">[32]</ref>. The ideal solution ùë† !"#$% is created by including all the optimal values for each objective (e.g., minimum values for a minimization problem) obtained from all the non-dominated solutions in ùëÉùêπ ! . ED can be calculated as ùê∏ùê∑ = ùëë(ùë† !"#$% , ùëÉùêπ ! ) (i.e., the shortest Euclidean Distance from ùë† !"#$% to ùëÉùêπ ! ) and a value of 0 for ED indicates that the computed Pareto front includes the ideal solution.</p><p>Notice that the main difference between ED and GD is that ED focuses on the shortest Euclidean distance between the computed Pareto front and the ideal solution, while GD aims at measuring the average Euclidean distance between solutions in the computed Pareto front and the optimal Pareto front.</p><p>3) Epsilon (ùùê) measures the shortest distance used to transform every solution in ùëÉùêπ ! to dominate ùëÉùêπ ! <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b33">34]</ref>. Suppose a solution ùë† can be represented as ùë† = (ùëì ! , ùëì ! , ‚Ä¶ , ùëì ! ) where ùëö is the number of objectives and ùëì ! is the function value for the objective ùëñ. Thus, ùúñ can be calculated as:</p><formula xml:id="formula_3">ùúñ ùëÉùêπ ! = ùëñùëõùëì !‚àà‚Ñù ‚àÄ(ùë† ! ‚àà ùëÉùêπ ! ‚àÉùë† ‚àà ùëÉùêπ ! : ùë† ‚â∫ ! ùë† ! }</formula><p>where ùëñùëõùëì !‚àà‚Ñù refers to the infimum for ùúñ and ùë† ‚â∫ ! ùë† ! means the solution ùë† ! in ùëÉùêπ ! dominates the solution ùë† in ùëÉùêπ ! with a distance of ùúñ, i.e., ùë† ‚â∫ ! ùë† ! if and only if ‚àÄ 1 ‚â§ ùëñ ‚â§ ùëö : ùëì ! ! ‚â∫ ùúñ + ùëì ! ! ! . Notice that a lower value of ùúñ denotes that the computed Pareto front is closer to the optimal Pareto front.</p><p>Diversity. 4) Generated Spread (GS) is defined to extend the quality indicator Spread (which only works for two-objective problems) and measure the extent of spread for the solutions in ùëÉùêπ ! <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36]</ref>. GS can be computed using the formula:</p><formula xml:id="formula_4">ùê∫ùëÜ = ! ! ! ,!" ! ! |! !,!" ! !!| !‚àà!"! ! !!! ! ! ! ,!" ! ! !!! ! !" ! * !</formula><p>, where (ùëí ! , ùëí ! , ‚Ä¶ , ùëí ! ) refers to ùëö extreme solutions for each objective in ùëÉùêπ ! (ùëö is the number of objectives). An extreme solution for a particular objective means a solution from ùëÉùêπ ! that achieves the optimal value for the objective on the basis of sacrificing other objectives. ùëë ùëí ! , ùëÉùêπ ! refers to the shortest Euclidean distance between the extreme solution ùëí ! and ùëÉùêπ ! . ùëë ùë†, ùëÉùêπ ! means the shortest Euclidean distance between the solution ùë† in ùëÉùêπ ! and the other solutions in ùëÉùêπ ! , while ùëë is the mean value of ùëë ùë†, ùëÉùêπ ! for all the solutions in ùëÉùêπ ! . A lower value of GS shows that the solutions have a better distribution in ùëÉùêπ ! .</p><p>5) Pareto front size (PFS) measures the number of solutions that are included in ùëÉùêπ ! , i.e., |ùëÉùêπ ! | <ref type="bibr" target="#b6">[7]</ref>. It is used to reflect diversity on the basis that users can have more options to choose and thus a higher value of PFS shows a more diverse computed Pareto front.</p><p>Combination. 6) Inverted Generational Distance (IGD) measures the shortest Euclidean distance from each solution in ùëÉùêπ ! to the closest solution in ùëÉùêπ ! <ref type="bibr" target="#b28">[29]</ref>. IGD can be calculated as:</p><formula xml:id="formula_5">ùêºùê∫ùê∑ = !(! ! ,!" ! ) ! |!"!| !!! |!" ! |</formula><p>, where |ùëÉùêπ ! | refers to the number of solutions in the optimal Pareto front and ùëë(ùë† ! , ùëÉùêπ ! ) refers to the minimum Euclidean distance from the solution ùë† ! in ùëÉùêπ ! to the computed Pareto front. Notice a lower value of IGD means the computed Pareto front is closer to the optimal Pareto front.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7) Hypervolume (HV)</head><p>is defined to measure the volume in the objective space that is covered by ùëÉùêπ ! <ref type="bibr" target="#b8">[9]</ref>. HV can be calculated by ùêªùëâ = ùë£ùëúùëôùë¢ùëöùëí ( ùë£ ! ùëÉùêπ ùëê !!! ) and for each solution ùë† ! ‚àà ùëÉùêπ ! , ùë£ ! means the diagonal corners of the hypercube between the solution ùë† ! and a reference point that is a vector of worst objective function values. The reference point is created by including all the worst values for each objective, which can be obtained from all the nondominated solutions in ùëÉùêπ ! (e.g., maximum value for a minimization problem). Notice that a higher value of HV demonstrates a better performance of the computed Pareto front.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Coverage. 8) Coverage (C) measures the dominance between ùëÉùêπ !</head><p>and ùëÉùêπ ! <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38]</ref>, i.e., the number of solutions in ùëÉùêπ ! that are covered by ùëÉùêπ ! . It can be calculated using ùê∂ =</p><formula xml:id="formula_6">| !‚àà!" ! !‚àà!"! | |!" ! |</formula><p>. Notice that C ranges from 0 to 1 and a higher value of C is preferable, as it signifies that the computed Pareto front consists of more optimal solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXTENDED LITERATURE REVIEW</head><p>Search algorithms are increasingly becoming an efficient means for solving complex optimization problems in all phases of software development life cycle. This area of research is termed as Search-Based Software Engineering (SBSE) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b43">44]</ref>. In the last two decades, research in SBSE has been significantly increased, e.g., the SBSE repository hosted by the CREST centre <ref type="bibr" target="#b13">[14]</ref> contains 1389 published papers as of August 18th, 2015.</p><p>Initially, SBSE was mainly focused on solving single-objective optimization problems (SOPs) using search algorithms, e.g., Genetic Algorithms. However, many SE problems are multiobjective by nature <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b12">13]</ref> and thus it is becoming critical for SBSE to deal with multi-objective optimization problems (MOPs), e.g., selecting a subset of test cases from a large number of test cases without significantly decreasing fault detection capability and at the same time achieving high coverage (threeobjective test case selection problem) <ref type="bibr" target="#b3">[4]</ref>. One approach in SBSE try to solve MOPs by converting them into SOPs by assigning weights to each objective <ref type="bibr" target="#b15">[16]</ref>. Such an approach has two key problems: 1) it is not possible to select precise and accurate weights for each objective; 2) several solutions with equivalent quality may be lost due to the conversion. To overcome these problems, Pareto-based search algorithms (e.g., NSGA-II) are increasingly being used to solve MOPs. These algorithms produce Pareto fronts, where each Pareto front contains a set of nondominated solutions and eventually a user can select one or more solutions <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b12">13]</ref> for their problems based on their specific requirements. To evaluate the performance of various Paretobased search algorithms, a number of quality indicators have been proposed, e.g., Hypervolume (HV) for assessing the quality of Pareto fronts produced by search algorithms <ref type="bibr" target="#b25">[26]</ref>.</p><p>A literature review has been conducted in <ref type="bibr" target="#b12">[13]</ref> to review the existing works on applying Pareto-based search algorithms for solving SE problems coined as Pareto-optimal SBSE (POSBSE) from the following perspectives: 1) algorithms used; 2) number of objectives to optimize; 3) framework to implement algorithms, and 4) quality indicators for evaluating Pareto fronts. The results show that only 51 out of 1101 papers (as of April 2013) have focused on MOPs suggesting that it is still a new area of research in SBSE. In addition, we also observed that only 15 out of these 51 papers have applied standard quality indicators (e.g., HV) to assess the quality of Pareto fronts, which is commonly used in the optimization community <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b64">65]</ref>. Even for these 15 papers, there is no clear justification for selecting quality indicators. For most of these works, HV was selected as a quality indicator because it was commonly used and it combines convergence and diversity as discussed in Section 2.3 <ref type="bibr" target="#b12">[13]</ref>.</p><p>Since this work focuses on providing a practical guide on how to choose quality indicators, we have followed the same template and extended the review work in <ref type="bibr" target="#b12">[13]</ref> by selecting and reviewing the papers from the SBSE repository related with POSBSE from April 2013 to August 2015. The goal for this extended literature review is to study which quality indicators have been used and how the quality indicators were chosen in the recent SBSE works. In addition, we also report the number of objectives for optimization, which can be used for proposing the practical guide. Notice that we do not report the applied multi-objective algorithms and the tool for algorithm implementation (as reported in <ref type="bibr" target="#b12">[13]</ref>) since they are out of scope of this paper.</p><p>From our extended literature review, we observe papers on POSBSE have increased from 51 to 73 until August 2015 and Table <ref type="table">3</ref> lists all these incremental works (in total 22). We can see that the works applying the standard quality indicators has increased from 15 reported in <ref type="bibr" target="#b12">[13]</ref> (by April 2013) to 28 (August 2015). However, similarly as discussed in <ref type="bibr" target="#b12">[13]</ref>, our extended literature review also shows that there is still no clear justification or explanation on the selection criteria for choosing quality indicators in various SE applications. For instance, all the works applying HV <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b50">[51]</ref><ref type="bibr" target="#b51">[52]</ref><ref type="bibr" target="#b52">[53]</ref> simply justified that HV was selected either because of its definition based on convergence and diversity or just because of its popularity. Furthermore, since quality indicators can be classified into different categories (Section 2.3), there is no evidence to show whether applying a subset of quality indicators (e.g., ED and HV were used in <ref type="bibr" target="#b42">[43]</ref> while HV and GD were applied in <ref type="bibr" target="#b47">[48]</ref>) is sufficient to evaluate Pareto fronts produced by search algorithms. There are also no practical guides in the existing SBSE literature for choosing quality indicators in different SE applications.</p><p>Based on the extended literature review, this paper is the first work in the SBSE community that aims at providing a practical guide for selecting quality indicators when assessing Pareto-based search algorithms. Notice that the eight quality indicators chosen in this paper cover all the quality indicators that have been applied in the recent SBSE works (Table <ref type="table">3</ref>).</p><p>Table <ref type="table">3</ref>. Extended POSBSE works in SBSE Reference Quality Indicators # of Objectives <ref type="bibr" target="#b5">[6]</ref> Not Applied 5 <ref type="bibr" target="#b6">[7]</ref> HV, PFS, Spread, IGD, Epsilon 5 <ref type="bibr" target="#b39">[40]</ref> PFS, HV, Spread 2 <ref type="bibr" target="#b40">[41]</ref> Not Applied 2 <ref type="bibr" target="#b41">[42]</ref> C, GD, IGD, ED 2, 4 <ref type="bibr" target="#b42">[43]</ref> ED, HV 2 <ref type="bibr" target="#b44">[45]</ref> Not Applied 4 <ref type="bibr" target="#b45">[46]</ref> Not Applied 2 <ref type="bibr" target="#b46">[47]</ref> Not Applied 3 <ref type="bibr" target="#b47">[48]</ref> HV, GD 2 <ref type="bibr" target="#b48">[49]</ref> HV 2 <ref type="bibr" target="#b49">[50]</ref> IGD 15 <ref type="bibr" target="#b50">[51]</ref> HV, IGD, C 2 <ref type="bibr" target="#b51">[52]</ref> HV, Spread 2 <ref type="bibr" target="#b52">[53]</ref> HV 2, 4, 6 <ref type="bibr" target="#b53">[54]</ref> HV, GD, IGD, C 2 <ref type="bibr" target="#b54">[55]</ref> HV, GD, IGD, Epsilon 2 <ref type="bibr" target="#b55">[56]</ref> HV, C, ED 5 <ref type="bibr" target="#b56">[57]</ref> Not Applied 2 <ref type="bibr" target="#b57">[58]</ref> Not Applied 4 <ref type="bibr" target="#b58">[59]</ref> Not Applied 2 <ref type="bibr" target="#b59">[60]</ref> Not Applied 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENT</head><p>This section presents the extensive experiment we conducted for empirically evaluating the eight quality indicators together with the six Pareto-based search algorithms, which includes: 1) description of the industrial problems (Section 4.1); 2) experiment design (Section 4.2); 3) experiment results (Section 4.3); 4) discussion based on the results (Section 4.4); and 5) discussion related with threats to validity (Section 4.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Description of the Industrial Problems</head><p>This section presents three industrial problems from two distinct domains: communication (Section 4.1.1) and subsea oil&amp;gas (Section 4.1.2), as shown in Table <ref type="table" target="#tab_3">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Communication Case Studies</head><p>Since 2007, we have established a close collaboration with Cisco, Norway, focusing on improving the cost and effectiveness of testing a variety of Videoconferencing Systems (VCSs) developed by Cisco <ref type="bibr" target="#b9">[10]</ref>. The core functionality of a VCS is to establish a videoconference among participants at various physical locations. There is also a possibility of transmitting presentations in parallel to a videoconference using VCSs. Generally speaking, VCSs aim at offering efficient means to organize high-quality, face-to-face meetings, without requiring physically gathering of participants from different geographic locations. Each VCS has on average three million lines of embedded C code. Notice that for testing Saturn (a product line of VCSs focused in this paper), a test case repository has been constructed by Cisco's test engineers with more than 2000 test cases. New test cases are continuously added to this repository. For testing a new VCS, we learned that two industrial problems are required to be addressed, i.e., 1) Cost-effective Test Suite Minimization: eliminating redundant test cases without significantly reducing the effectiveness (e.g., feature pairwise coverage) at the same time minimizing the cost (execution time) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b15">16]</ref>; 2) Cost-effective Test Case Prioritization: prioritizing test cases into an optimal order within a limited test resource budget with the aim to maximize the effectiveness (e.g., fault detection capability) and minimize the cost (e.g., execution time) <ref type="bibr" target="#b14">[15]</ref>. Considering the number of test cases is large (i.e., search space is huge) for both industrial problems, each of the two problems can be formulated as a multi-objective optimization problem and applying search algorithms shows promising results as we previously studied <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.1">Test Suite Minimization Problem</head><p>Test suite minimization aims at eliminating redundant test cases, while maximizing the effectiveness and minimizing the cost. To deal with this problem, four cost/effectiveness objectives (Table <ref type="table" target="#tab_3">4</ref>) were defined together with test engineers at Cisco. a) Test Minimization Percentage (TMP) measures the number of test cases that can be minimized as compared with the original test suite; TMP can be measured as ùëáùëÄùëÉ = 1 -!" !"#"!"$%&amp; !" !"#$#%&amp;' * 100%), where ùëõùë° !"#"!"$%&amp; is the number of minimized test cases and ùëõùë° !"#$#%&amp;' is the number of original test cases; b) Feature Pairwise Coverage (FPC) measures how many pairs of features (testing functionalities) can be covered by the minimized test cases; FPC is measured as</p><formula xml:id="formula_7">ùêπùëÉùê∂ = !"!"# !"#"!"$%&amp; !"#$% ! !</formula><p>, where ùëÅùë¢ùëöùêπùëÉ !"#"!"$%&amp; refers to the number of feature pairs covered by the minimized test cases, while ùëÅùë¢ùëöùêπùëÉ ! ! is the number of feature pairs that should be covered by VCS product ùëù ! ; c) Fault Detection Capability (FDC) measures how many test cases can manage to find faults within a specified time period (e.g., one week in the past); FDC can be measured as ùêπùê∑ùê∂ =</p><formula xml:id="formula_8">!"#$ !" ! !" !"#"!"$%&amp; !!! !" !"#"!"$%&amp;</formula><p>, where ùëÜùë¢ùëêùëÖ !" ! refers to the success rate that a test case ùë°ùëê ! can manage to detect faults in a given time; d) Overall Execution Time (OET) measures how long it takes for executing the minimized test cases. OET can be measured as</p><formula xml:id="formula_9">ùëÇùê∏ùëá = ùê¥ùê∏ùëá !" ! !" !"#"!"$%&amp; !!!</formula><p>, where ùê¥ùê∏ùëá !" ! refers to the average historical execution time for test case ùë°ùëê ! .</p><p>More details about the objective functions can be found in <ref type="bibr" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.2">Test Case Prioritization Problem</head><p>Test case prioritization aims to cost-effectively prioritize a set of test cases within a limited budget of available test resources <ref type="bibr" target="#b14">[15]</ref>. In our case, test resources refer to correct software versions deployed on hardware since test cases aim at testing different software versions. Notice that it may take different time to allocate particular test resources for a specific test case. Similarly, to address such a test prioritization problem, we defined four costeffectiveness measures as below (shown in Table <ref type="table" target="#tab_3">4</ref>).</p><p>a) Prioritized Extent (PE) measures the number of test cases that can be prioritized within the test resource budget; PE can be measured as ùëÉùê∏ =</p><formula xml:id="formula_10">!" !"#$"#%#&amp;'( !"</formula><p>, where ùëõùë° !"#$"#%#&amp;'( refers to the number of prioritized test cases within available test resources while ùëõùë° is the total number of test cases to be prioritized; b) Feature Pairwise Coverage (FPC) measures how many pairs of features can be covered by the prioritized test cases; FPC can be measured as</p><formula xml:id="formula_11">ùêπùëÉùê∂ ! ! = !"!"# !"#$"#%#&amp;'( !"#$%</formula><p>, where ùëÅùë¢ùëöùêπùëÉ !"#$"#%#&amp;'( is the number of feature pairs covered by the prioritized test cases and ùëÅùë¢ùëöùêπùëÉ refers to the total number of feature pairs that should be tested; c) Fault Detection Capability (FDC) measures the fault detection capability of the prioritized test cases. It is measured as</p><formula xml:id="formula_12">ùêπùê∑ùê∂ = !"#$ !" ! !" !"#$"#%#&amp;'( !!! !" !"#$"#%#&amp;'(</formula><p>, where ùëÜùë¢ùëêùëÖ !" ! refers to the success rate that a test case ùë°ùëê ! can manage to find faults in a given time; d) Overall Execution Cost (OEC) measures how long it takes to setup the required test resources and execute the prioritized test cases. It can be calculated as ùëÇùê∏ùê∂ =</p><formula xml:id="formula_13">(ùê¥ùê∏ùëá !" ! + !" !"#$"#%#&amp;'( !!! ùëáùëáùëÖ !" ! )</formula><p>, where ùê¥ùê∏ùëá !" ! refers to the average historical execution time for test case ùë°ùëê ! and ùëáùëáùëÖ !" ! is the total time for allocating relevant test resources for ùë°ùëê ! . More details can be found in <ref type="bibr" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Subsea Oil&amp;Gas Case Study</head><p>Subsea production systems (SPSs) are large-scale, heterogeneous and highly-hierarchical Cyber-Physical Systems (CPSs) that control and monitor physical processes such as oil and gas production platforms <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31]</ref>. SPSs manage the exploitation of oil and gas production fields by integrating hundreds of hardware components and software.</p><p>At the early phase of developing such a large scale CPS, a large number of requirements are required to be inspected by different stakeholders from different organizations or departments of the same organization. These requirements have different characteristics such as various extents of importance to an organization, complexity, and dependencies between each other, thereby requiring different effort (workload) to inspect <ref type="bibr" target="#b24">[25]</ref>. Therefore, one practical challenge has been identified, i.e., requirements allocation that aims to maximize stakeholders' familiarities to the assigned requirements and at the same time balance the overall workload of each stakeholder. The problem has been formulated as a multi-objective optimization problem in our previous works <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b24">25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.1">Requirements Allocation Problem</head><p>To address this problem, three cost-effectiveness measures have been defined in <ref type="bibr" target="#b24">[25]</ref>.</p><p>a) ASSIGN represents the extent of assigning all the requirements to stakeholders. It can be measured as ASSIGN</p><formula xml:id="formula_14">= ! !" ! ! !" !!! ! !</formula><p>, where ùëõ !" ! returns the number of requirements assigned to the ùëñ !! stakeholder, ùëõ ! is the total number of requirements and ùëõ !" is the total number of stakeholders; b) FAM denotes the overall familiarity of the stakeholders to requirements allocated to them. It can be measured as FAM =</p><formula xml:id="formula_15">!" !" !!" !"# (!" !"# !!" !"# ) ! !" ! !!! ! !" !!! ! !" ! ! !" !!!</formula><p>, where ùêπùëÄ !" represents the familiarity value of stakeholder ùëÜ ! for requirement ùëÖ ! and all familiarity values range from ùêπùëÄ !"# to ùêπùëÄ !"# ; c) OWL represents the overall differences of workloads of the stakeholders and it can be measured as OWL =</p><formula xml:id="formula_16">!"# !" ! !!" ! ! !" !!!!! ! !" !! !!! ! !" * (! !" !!)</formula><p>, where ùëäùêø ! computes the workload for all the requirements assigned to ùëñ !! stakeholder based on their complexity, dependency index, and importance:</p><formula xml:id="formula_17">ùëäùêø ! = (( !" ! !!" !"# (!" !"# !!" !"# ) ! !" ! !!" !"# (!" !"# !!" !"# ) ! !" ! !!" !"# (!" !"# !!" !"# ) ) ! !" ! !!! /!) ! !" !</formula><p>, in which, ùê∂ùëÄ ! , ùê∑ùëÉ ! and ùêºùëÄ ! represent the complexity, dependency and importance of the requirement ùëó !! respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiment Design</head><p>In this section, we present the experiment design from 1) Research (Section 4.2.1); 2) studies of the three industrial problems (Section 4.2.2); 3) Experiment tasks performed and statistical tests (Section 4.2.3); 4) Evaluation metric and algorithm parameter settings (Section 4.2.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Research Questions</head><p>Our goal is to provide a practical guide for the SBSE community to select quality indicators for SE applications. To meet our objective, we define the following research questions:</p><p>RQ1: Does it matter to select a particular quality indicator within each category?</p><p>Answering this research question helps us to define a guide for selecting quality indicators within the same category for assessing Pareto-based search algorithms in different SE contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RQ2: Does it matter to select quality indicators from different categories?</head><p>Answering this research question helps to define a guide for selecting quality indicators from different categories for assessing Pareto-based search algorithms in different SE contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RQ3: Does it matter to take calculation time into account when selecting quality indicators?</head><p>Answering this research question helps us to study whether calculation time can be an additional layer to define a guide for selecting quality indicators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Case Studies</head><p>In Section 4.1, we introduced three industrial problems: 1) test suite minimization problem (TM), 2) test case prioritization problem (TP), and 3) requirements allocation problem (RA). We detail the case studies used for each problem as below.</p><p>TM: We chose four VCSs from Saturn: C20, C40, C60 and C90 (Table <ref type="table" target="#tab_4">5</ref>). There are 169 features (testing functionalities) in Saturn and each VCS includes a subset of these features. Moreover, C20, C40, C60 and C90 include 17, 25, 32 and 43 features respectively and 138, 167, 192 and 230 test cases relevant for testing these VCSs, respectively <ref type="bibr" target="#b5">[6]</ref>. Notice that each feature can be tested by at least one test case and each test case can be used to test at least one feature. Each test case ùë°ùëê ! has a success rate for execution (ùëÜùë¢ùëêùëÖ !" ! ) for calculating FDC, an average execution time ( ùê¥ùê∏ùëá !" ! ) for measuring OET. In general, for Saturn, each feature is associated with 5-10 test cases and each test case ùë°ùëê ! is associated with 1-5 features with ùëÜùë¢ùëêùëÖ !" ! ranging from 50% to 100%, and ùê¥ùê∏ùëá !" ! ranging from 2 to 60 minutes.</p><p>TP: We chose a testing cycle that includes 257 test cases for testing 53 functionalities (features) (Table <ref type="table" target="#tab_4">5</ref>). Each feature can be tested by at least one test case and one test case can be executed for testing one or more features. Each test case ùë°ùëê ! has a success rate for execution (ùëÜùë¢ùëêùëÖ !" ! ) ranging from 50% to 100%, an average execution time ùê¥ùê∏ùëá !" ! ranging from 2 to 60 minutes, and time for allocating relevant test resources (ùëáùëáùëÖ !" ! ) ranging from 1 to 30 minutes. Moreover, there are 59 available test resources used to setup the test environment (e.g., correct software) for executing such 257 test cases. Notice that each test resource can be allocated for executing one or more test cases and execution of each test case requires one or more test resources.</p><p>RA: We selected a real-world case study (i.e., a large-scale CPS) including 287 requirements and identified 10 stakeholders who are responsible for reviewing and checking these requirements (Table <ref type="table" target="#tab_4">5</ref>). Each requirement ùëÖ ! has three attributes that include: complexity ùê∂ùëÄ ranging from 0 to 9, dependency index ùê∑ùëÉ from 0 to ùëõ ! -1 (ùëõ ! is the number of requirements) and importance ùêºùëÄ ranging from 0 to 9. Each stakeholder ùëÜ ! has one attribute, i.e., familiarity for a specific requirement ùëÖ ! (ùêπùëÄ !" ) ranging from 0 to 9 in our case.</p><p>It is worth mentioning that all the three industrial problems are complex based on our previous works <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b24">25]</ref> since random search (a baseline) has been compared with search algorithms and results consistently show that search algorithms significantly outperform random search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Experiment Tasks and Statistical Tests</head><p>Experiment Tasks: We first perform a task by running the six algorithms for the case studies in each industrial problem (as shown in Figure <ref type="figure">2</ref>). Thus, for each case study in an industrial problem, 100 values are obtained for each quality indicator in terms of each search algorithm.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2 Pseudo code for obtaining quality indicator values</head><p>We defined a corresponding task as shown in Table <ref type="table" target="#tab_4">5</ref> to answer each research question based on the obtained quality indicator values. The ùëá ! task is divided into ùëá !! and ùëá !" , where ùëá !! compares each pair of the search algorithms using each quality indicator within the same category for each case study. The ùëá !" task answers RQ1 from another perspective, where we study the correlations of two quality indicators within category by ignoring the differences of the search algorithms. ùëá ! is also divided into two tasks. ùëá !" compares each pair of the algorithms by analyzing the values of quality indicators across categories. ùëá !! studies the correlations between the quality indicators across categories. Last, in ùëá ! , we compare the quality indicators based on their calculation time to answer RQ3. Statistical Tests: For ùëá !! and ùëá !" , the Vargha and Delaney statistics and Mann-Whitney U test are used by following the guides reported in <ref type="bibr" target="#b60">[61]</ref> to compare the results of the search algorithms based on the quality indicators within or across categories (Table <ref type="table" target="#tab_4">5</ref>). The Vargha and Delaney statistics is used to calculate ùê¥ !" , which is a non-parametric effect size measure. In our context, ùê¥ !" is used to compare the probability of yielding higher values of each quality indicator for two algorithms A and B. Each pair of algorithms is further compared using the Mann-Whitney U test (p-value) to determine the significance of the results with the significance level of 0.05, i.e., there is a significant difference if p-value is less than 0.05. For the quality indicators HV, PFS, C (higher value, better performance), A significantly outperforms B if ùê¥ !" is greater than 0.5 and the pvalue is less than 0.05 while A performs significantly worse than B if ùê¥ !" is less than 0.5 and the p-value is less than 0.05. There is no significant difference between A and B if the p-value is greater than 0.05. For the other quality indicators (i.e., GD, ED, epsilon, IGD and GS), vice versa.</p><p>To study the correlation between each pair of quality indicators (ùëá !" and ùëá !! ), we choose the Kendall rank correlation coefficient (ùúè) as shown in Table 5 <ref type="bibr" target="#b63">[64]</ref>. The ùúè value ranges from -1 to 1, i.e., there is a positive correlation if ùúè is equal to 1 and a negative correlation when ùúè is -1. A ùúè close to 0 shows that there is no correlation between two sets of data. Moreover, we also report significance of correlation using Prob&gt;|ùúè |; a value lower than 0.05 means that the correlation is statistically significant. Notice that the test does not require the monotonicity of two data sets, which suits our case. In addition, the Mann-Whitney U test is applied to determine whether there are significant differences for the time to calculate each quality indicator (ùëá ! ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Metric and Parameter Settings</head><p>Evaluation Metric: To address RQ1 and RQ2, we define a metric ùëÄùëéùë°ùë°ùëíùëüùë† to measure whether two quality indicators can demonstrate the same trend of performance when evaluating the algorithms:</p><formula xml:id="formula_18">ùëÄùëéùë°ùë°ùëíùëüùë† (ùëÑùêº ! , ùëÑùêº ! ) = ùëöùëéùë°ùë°ùëíùëü ! (ùëÑùêº ! , ùëÑùêº ! ) !(!,!) !!!</formula><p>, where ùëõ is the number of the algorithms and ùê∂(ùëõ, 2) refers to the number of the algorithm pairs. For instance, there are ùê∂ 6, 2 = 15 pairs for the selected six Pareto-based search algorithms in our case. The ùëöùëéùë°ùë°ùëíùëü ! ùëÑùêº ! , ùëÑùêº ! function denotes whether it matters to choose one of the quality indicators ùëÑùêº ! and ùëÑùêº ! when comparing the ùëñ !! algorithm pair. In other words, ùëöùëéùë°ùë°ùëíùëü ! ùëÑùêº ! , ùëÑùêº ! is 1 if both ùëÑùêº ! and ùëÑùêº ! reveal the same trend of performance for the ùëñ !! algorithm pair, i.e., it doesn't matter which quality indicator to choose; otherwise, ùëöùëéùë°ùë°ùëíùëü ! ùëÑùêº ! , ùëÑùêº ! is 0. For example, suppose that HV and IGD are used to compare NSGA-II and SPEA2. If both HV and IGD consistently indicate one of the three cases: 1) NSGA-II performs significantly better than SPEA2; 2) NSGA-II performs significantly worse than SPEA2; and 3) there is no significant difference between NSGA-II and SPEA2, ùëöùëéùë°ùë°ùëíùëü ! ùêªùëâ, ùêºùê∫ùê∑ will be 1. Otherwise, if HV and IGD demonstrate different trends of performance for NGSA-II and SPEA2, ùëöùëéùë°ùë°ùëíùëü ! ùêªùëâ, ùêºùê∫ùê∑ will be 0. Using ùëÄùëéùë°ùë°ùëíùëüùë†, RQ1 and RQ2 can be answered in a precise and compact manner. In conclusion, we can say that it does not matter if we choose ùëÑùêº ! or ùëÑùêº ! for assessing the algorithms if ùëÄùëéùë°ùë°ùëíùëüùë† ùëÑùêº ! , ùëÑùêº ! = 1 for all pairs of the search algorithms (e.g., 15 pairs for the six search algorithms in our case); otherwise it matters and therefore both ùëÑùêº ! and ùëÑùêº ! should be applied together if ùëÄùëéùë°ùë°ùëíùëüùë† ùëÑùêº ! , ùëÑùêº ! = 0 since there is at least one algorithm pair that the two quality indicators show the different trends of performance.</p><p>Parameter Settings: We employ jMetal <ref type="bibr" target="#b8">[9]</ref> to encode the three industrial problems together with the implementation of the six selected Pareto-based search algorithms. All the parameters that are used for configuring these algorithms are shown in Table <ref type="table">6</ref>, which are suggested as default parameters from the jMetal library <ref type="bibr" target="#b8">[9]</ref>. In addition, we set the maximum number of fitness evaluations as 25000, i.e., the search is terminated if the fitness function has been evaluated for 25000 times. Notice that tuning parameters may lead to different performance of search algorithms, but standard parameter settings are usually recommended <ref type="bibr" target="#b60">[61]</ref>. Furthermore, all the eight quality indicators mentioned in Section 2.3 are implemented based on jMetal <ref type="bibr" target="#b8">[9]</ref>. As suggested in <ref type="bibr" target="#b60">[61]</ref>, each algorithm was run 100 times to account for random variations. Table <ref type="table">6</ref>. Recombination: differential evolution, crossover rate = 0.9; Archive Size: 100</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experiment Results</head><p>This section presents the results for each research question <ref type="foot" target="#foot_0">1</ref> . RQ1: RQ1 focuses on empirically evaluating the quality indicators within the same category. Table <ref type="table" target="#tab_5">7</ref> lists the values of <ref type="figure">-----------------------------------------------------------</ref>ùëÄùëéùë°ùë°ùëíùëüùë† for the quality indicators within each category by applying the six Pareto-based search algorithms in the four VCS products (case studies) for solving the TM and TP problems and one CPS for solving the RA problem. From Table <ref type="table" target="#tab_5">7</ref>, we can observe that the three quality indicators within Convergence (i.e., GD, ED and ùúñ ) show the same trend of performance when comparing the 15 pairs of the six algorithms in the three industrial problems since all the values for ùëÄùëéùë°ùë°ùëíùëüùë† are equal to 1. Similarly, the two quality indicators (i.e., IGD and HV) within Combination also demonstrate the same trend of performance when comparing the 15 pairs of the six algorithms. However, we observe that in Diversity, GS and PFS show different trends of performance since all the values of ùëÄùëéùë°ùë°ùëíùëüùë† are 0. This observation shows that when using GS and PFS for measuring diversity, we may observe different performance of search algorithms for the same problem. Notice that we only have one quality indicator in Coverage (Table <ref type="table" target="#tab_4">5</ref>) and thus we cannot calculate ùëÄùëéùë°ùë°ùëíùëüùë† within Coverage. Moreover, we apply the Kendall rank correlation coefficient test (ùúè) for studying the correlations between quality indicators within the same category. Table <ref type="table" target="#tab_6">8</ref> summaries the key results for pairs of quality indicators using the ùúè test. From Table <ref type="table" target="#tab_6">8</ref>, one can observe that the three quality indicators (ED, GD and ùúñ ) of Convergence have significantly positive correlations for all the case studies of the three industrial problems since all the values of œÑ are greater than 0 (close to 1) and the p-values for Prob&gt;|ùúè| are all less than 0.05 (due to the limited space, we do not report the individual values for ùúè and Prob&gt;|ùúè|). Therefore, we can conclude that for Convergence, all the three quality indicators show the same trend of performance when comparing different algorithms and it therefore does not matter which one to choose. </p><formula xml:id="formula_19">œÑ &lt; 0 ùëù &lt; 0.05 œÑ &lt; 0 ùëù &lt; 0.05 œÑ &lt; 0 ùëù &lt; 0.05</formula><p>As for Diversity, the results in Table <ref type="table" target="#tab_6">8</ref> show that there is no significant correlation between GS and PFS since the p-values for Prob&gt;| ùúè | are greater than 0.05 and thus GS and PFS have to be selected together when evaluating the diversity of a Pareto front. For Combination (i.e., HV and IGD), Table <ref type="table" target="#tab_6">8</ref> shows that a significantly negative correlation exists between HV and IGD. The correlation is negative since a higher value of HV shows a better Pareto front, which is represented by a lower value of IGD. Thus, for this category, it also does not matter which indicator to choose when assessing the performance of the search algorithms.</p><p>Based on the above results, RQ1 can be answered as follows. For Convergence and Combination, it doesn't matter which quality indicator within the same category to choose; however, it does matter for Diversity, i.e., both GS and PFS should be used together when assessing Pareto fronts.</p><p>RQ2: RQ2 aims at empirically evaluating the quality indicators across categories. Based on the results of RQ1 (i.e., GD, ED and ùúñ have significant correlations, and IGD and HV also have a significant correlation), we chose ùúñ and HV for representing the categories of Convergence and Combination, respectively since the results of GD and ED are consistent with ùúñ for Convergence and the results of IGD are consistent with HV for Combination. Therefore, the five quality indicators from the four different categories (i.e., ùúñ, HV, PFS, GS and C) are compared in the three industrial problems (i.e., TM, TP and RA). Table <ref type="table" target="#tab_7">9</ref> summarizes the key results of ùëÄùëéùë°ùë°ùëíùëüùë† when comparing each pair of the five quality indicators in the three industrial problems. Table <ref type="table" target="#tab_9">10</ref> summarizes the key findings by studying correlations between each pair of quality indicators across categories using the Kendall rank correlation coefficient test (ùúè). We can see that there is no significant correlation for all the pairs of the quality indicators except for ùúñ and C since the p-values for Prob&gt;| ùúè | are greater than 0.05. As for ùúñ and C, there is a significantly negative correlation since all the values for ùúè are less than 0 (close to -1) and the p-values for Prob&gt;| ùúè | are all less than 0.05. Such a significant correlation is negative since a lower value of ùúñ denotes a better Pareto front, which is represented by a higher value of C. RQ3: This research question is designed to compare time to calculate each indicator. Notice that each algorithm is run for 100 times in our case and each run provides a data point for the time. Since six algorithms are selected and three industrial problems are involved including 9 case studies (Table <ref type="table" target="#tab_4">5</ref>), 5400 data points of time can be obtained in total for calculating each quality indicator. We report the average value of these 5400 time data points for each quality indicator (Table <ref type="table" target="#tab_10">11</ref>) and perform the Mann-Whitney U test to determine whether there are significant differences in terms of calculation time for each pair of quality indicators.</p><p>Results show that for all the eight quality indicators, PFS takes significantly less time than all the others since all the p-values are less than 0.05, which are not reported to save space. Within Convergence and Coverage, calculating C takes significantly less time than the others (i.e., GD, ED and ùúñ). Within Combination, there is no significant difference for calculating HV and IGD. Thus, we can answer RQ3 as follows: there are significant differences in terms of time for calculating quality indicators and thus calculation time can be used as additional criterion in our guide for selecting quality indicators. However, the practical differences for calculating these quality indicators may not be huge since all of them are in a few seconds (Table <ref type="table" target="#tab_10">11</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Discussion on Results</head><p>For RQ1, we observe that within Convergence, all the three quality indicators (i.e., GD, ED and ùúñ) show the same trend of performance when comparing Pareto-based search algorithms at the same time there are significantly positive correlations among them. This can be explained from the fact that GD, ED and ùúñ are defined to measure the distance of solutions in a computed Pareto front to the optimal solutions (in the optimal Pareto front) though different mathematical formulas are applied (Section 2.3). It is worth mentioning that calculating ED only requires an ideal set of objective values, i.e., the optimal value that each objective can achieve (Section 2.3), while GD and ùúñ require obtaining a reference Pareto front (simulating the optimal Pareto front) <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b64">65]</ref>. In the context of our case studies, we were not aware of ideal objective set beforehand (which is obtained from the reference Pareto front) and the results show that GD, ED and ùúñ are equivalent in terms of Convergence. However, for certain SE problems, if the ideal set of objective values is known beforehand (e.g., for testing, the maximum value of feature pairwise coverage is 1), ED should be a more accurate quality indicator as compared with GD and ùúñ, since these two indicators require a reference Pareto front for representing the optimal Pareto front <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b64">65]</ref>.</p><p>As for Combination, both HV and IGD are defined to measure: 1) how obtained solutions are close and 2) how obtained solutions are distributed in a computed front. Based on the results of the experiment, HV and IGD indicate the same trend of performance when comparing the algorithms. Furthermore, calculating HV requires a reference point (the worst objective set) instead of a reference Pareto front required by IGD (Section 2.3). Therefore, HV is considered as a more accurate quality indicator when such a reference point is known beforehand for certain SE problems, e.g., the minimum number of test cases to be eliminated is 0 for test suite minimization.</p><p>However, within Diversity, the two quality indicators (i.e., GS and PFS) do not demonstrate the same trend of performance when comparing the search algorithms and the correlation between them is not significant. This can be explained based on the fact that PFS is defined based on the assumption that more solutions included into a Pareto front, more options a user can choose from and thus it reflects a more diverse Pareto front. However, when all the solutions are close to each other in the front, even higher values of PFS cannot necessarily demonstrate a Pareto front with a higher diversity. As compared with PFS, GS is defined to measure how well solutions are distributed in a computed Pareto front (Section 2.3). Thus, GS and PFS provide two different perspectives of measuring diversity, which should be applied together. When calculating GS, it requires calculating a reference Pareto front (Section 2.3) while PFS does not require anything.</p><p>As for RQ2, the results show that the quality indicators of Convergence show the same trend of performance as the quality indicator of Coverage. Such interesting finding can be explained that when a computed Pareto front shares more common solutions with the optimal Pareto front (i.e., the value of C is higher), the computed Pareto front and the optimal solutions should be closer (i.e., the values for GD, ED and ùúñ are lower). Meanwhile, significant correlations were observed among these four quality indicators, which provide further evidence for the observation. As for other quality indicators across categories, no such phenomenon were found that denotes that quality indicators can not replace others that belongs to different categories except for the above-mentioned ones (i.e., GD, ED, ùúñ and C).</p><p>In terms of computation effort (RQ3), the results demonstrate that calculating quality indicators can take significantly time, e.g., the calculation time for PFS is significantly less than the others (Section 4.3). Based on the theoretical foundations <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b64">65]</ref>, we observe that the computation effort for PFS is linear, whereas the others except HV are in quadratic. As for HV, the calculation time will be increased exponentially with the increase in the number of objectives. When the number of objectives is less (e.g., three and four objectives in our cases), the practical differences are not very huge when looking into the average calculation time for each indicator, e.g., 0.35 seconds for PFS and 4.86 seconds for ùúñ (Table <ref type="table" target="#tab_10">11</ref>). Notice that when the number of objectives is greater than 10 (15 as reported in <ref type="bibr" target="#b49">[50]</ref>), HV is not applicable since it becomes very expensive to calculate. Based on these observations, calculation time can be an additional criterion for selecting quality indicators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Threats to Validity</head><p>A threat to internal validity is that we have experimented with only one-default configuration setting for algorithm parameters. However, these settings are in accordance with the common guides in the literature <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b62">63]</ref>. The conclusion validity threat in experiments involving algorithms is due to random variations. To address it, we repeated experiments 100 times to reduce the possibility that the results were obtained by chance. We also reported the results using the Vargha and Delaney statistics (to measure the effect size), Mann-Whitney U test (to determine the statistical significance) and the Kendall rank correlation coefficient (to measure the correlations among the indicators).</p><p>The observed construct validity threat is that the measures used are not comparable across the algorithms. In our context, we used the same stopping criteria for all the algorithms, i.e., the number of fitness evaluations (i.e., 25000). As for external validity threat related with generalization of results, three industrial problems were chosen from two different domains (i.e., communication and subsea oil&amp;gas), which cover two different phases of software lifecycle, i.e., requirements and testing. For the test suite minimization problem and test case prioritization problem, four different VCS products with varying complexity were selected for the experiment. For the requirements allocation problem, one large-scale CPS was chosen. Notice that such threat to external validity is common to all empirical studies <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b61">62]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">PRACTICAL GUIDE</head><p>This section provides a practical guide (Figure <ref type="figure" target="#fig_3">3</ref>) for selecting quality indicators, when assessing Pareto-based search algorithms. As mentioned before, the guide is derived based on: a) the theoretical foundations (TF); b) the extended literature review (LR); and c) the extensive experiment (EE). In Figure <ref type="figure" target="#fig_3">3</ref>, we explicitly show this information inside the brackets when recommending a quality indicator to apply.</p><p>As shown in Figure <ref type="figure" target="#fig_3">3</ref>, a category of quality indicators should be first selected (A1):</p><p>1) Select Convergence or Coverage if a user only cares whether obtained solutions are optimal or not. In particular, for some SE problems (e.g., RA in our case), only one optimal solution is required regardless of the diversity of solutions. In this case, a dedicated quality indicator for Convergence is recommended. Moreover, if an ideal set of objective values (i.e., optimal objective values) is unknown for a specific SE problem (e.g., RA in our case), any of GD, ED, ùúñ and C can be selected (A3) based on EE, i.e., the results showed that all of them indicate the same trend of performance when comparing algorithms. Otherwise, if an ideal objective set is known before, ED should be selected (A2) since it only requires an ideal objective set instead of a whole reference Pareto front based on TF.</p><p>2) Select Combination if a user prefers more diverse solutions to choose from in addition to Convergence. For example, a user can choose solutions based on the preference of objectives. In this case, the first selection criterion is based on the number of objectives to be optimized since the computation effort of HV increases exponentially with the number of objectives <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b64">65]</ref>. From our experiment with three and four objectives (TM, TP and RA problems), there is no significant time difference for calculating HV and IGD, and from the extended literature review (Section 3), we observed that the number of objectives is always less than or equal to six for all the existing works that applied HV. Thus, according to LR, we set the threshold of the number of objectives as six for the guide, i.e., when the number of objectives for a problem are more than six, IGD should be selected (A4) since the computation effort of IGD is only in quadratic based on TF. When the number of objectives is less than or equal to six, HV should be selected (A5) if an accurate reference point is known, i.e., the worst values for all the objectives. That is because calculating HV only requires a reference point rather than an entire reference Pareto front (TF). Otherwise, if a reference point is not known before (e.g., the RA problem in our case), either HV or IGD can be chosen (A6) based on EE since HV and IGD indicates the same trend of performance for comparing algorithms. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND FUTURE WORK</head><p>This paper provides a practical guide for the Search-based Software Engineering (SBSE) community to select proper quality indicators when assessing Pareto-based search algorithms in different software engineering applications. The guide is derived from: 1) theoretical foundations of quality indicators; 2) an extended literature review; and 3) an extensive experiment to evaluate eight quality indicators along with six Pareto-based search algorithms using three industrial problems.</p><p>In the future, we plan to involve more quality indicators into the guide, which have not been investigated by the SBSE community, e.g., purity <ref type="bibr" target="#b25">[26]</ref>, dominance ranking <ref type="bibr" target="#b38">[39]</ref>. We also plan to employ more industrial problems from other domains with the aim to further improve the proposed practical guide.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 4 :</head><label>14</label><figDesc>ùëá ! ùëá !! : Compare each pair of the algorithms by analyzing the values of the quality indicators within category !" : Compare each pair of the algorithms by analyzing the values of the quality indicators across categories Vargha and Delaney statistics Mann-Whitney U test PFS TP C20 Combination IGD C40 ùëá !! : Analyze the correlations for each pair of the quality indicators across categories Kendall Rank Test HV C60 Coverage C C90 3 ùëá ! : Compare the quality indicators in terms of computation time Average Value Mann-Whitney U test RA CPS For each industrial problem: For each case study: 1: Run the six Pareto-based search algorithms with certain number of times (100 in our case); For each time of run: 2: Obtain a reference Pareto front by combining Pareto fronts produced by the six algorithms; 3: Calculate the values for the eight quality indicator so that each algorithm has eight values associated with each quality indicator; End; Obtain the 100 values for each quality indicator for each algorithm; End; End.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>100; Selection of Parents: binary tournament + binary tournament; Recombination: simulated binary, crossover rate = 0.9; Mutation: polynomial, mutation rate = 1.0/n MOCell Population Size: 100; Neighbourhood: 1-hop neighbours (8 surrounding solutions); Selection of Parents: binary tournament + binary tournament; Recombination: simulated binary, crossover rate = 0.9: Mutation: polynomial, mutation rate = 1.0/n; Archive Size: 100 PAES Mutation: polynomial, mutation rate = 1.0/n; Archive Size: 100 SMPSO Population Size: 100; Mutation: polynomial, mutation rate = 1.0/n; Archive Size: 100 CellDE Population Size: 100; Neighbourhood: 1-hop neighbours (8 surrounding solutions); Selection of Parents: binary tournament + binary tournament;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>3 )</head><label>3</label><figDesc>Select Convergence or Coverage together with Diversity. .g., HV)<ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b64">65]</ref>. Notice that quality indicators of Diversity cannot be applied separately since it does not make sense in realistic situations that users only care about the diversity of solutions without considering they are optimal or not. In this case, we need to learn whether the ideal objective set is known for a SE problem. If the ideal objective set is known, ED from Convergence should be applied together with PFS and GS (Diversity) (A7) based on TF and EE, i.e., PFS and GS indicate different trends of performance when comparing algorithms. Otherwise, any quality indicator from Convergence or Coverage can be chosen together with PFS and GS (A8) based on EE. Notice that PFS and GS should be selected together since they reflect the diversity from two different perspectives, i.e., the number of obtained solutions and distribution of solutions. It is worth mentioning that the quality indicators from Convergence and Diversity may demonstrate completely different performance of algorithms and thus making it impossible to obtain a definite answer which algorithm is better. In this case, we recommend selecting the quality indicators from Combination (A9) since applying HV or IGD can tell us which algorithm is better by combining both Convergence and Diversity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 . Classification of search algorithms Algorithm Category Algorithm</head><label>1</label><figDesc></figDesc><table><row><cell>Evolutionary Algorithms</cell><cell>GAs</cell><cell>Sorting-Based Cellular-Based</cell><cell>NSGA-II MOCell</cell></row><row><cell>(EAs)</cell><cell cols="2">Strength Pareto EA</cell><cell>SPEA2</cell></row><row><cell></cell><cell cols="2">Evolution Strategies</cell><cell>PAES</cell></row><row><cell>Swarm Algorithm</cell><cell cols="2">Particle Swarm Theory</cell><cell>SMPSO</cell></row><row><cell>Hybrid Algorithm</cell><cell cols="2">Cellular GA + differential evolution</cell><cell>CellDE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>also</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Require column). We detail each quality indicator as follows. Table 2. Categories of quality indicators Category Name Brief Description Require</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>GD</cell><cell>The Euclidean distance between solutions</cell><cell>Reference</cell></row><row><cell></cell><cell></cell><cell>in  ùëÉùêπ ! and the nearest solutions in  ùëÉùêπ !</cell><cell>Pareto front</cell></row><row><cell>Convergence</cell><cell>ED</cell><cell>Euclidean distance between the ideal solution and the closest solution in  ùëÉùêπ !</cell><cell>Ideal Solution</cell></row><row><cell></cell><cell>ùúñ</cell><cell>Smallest distance for transferring every solution in  ùëÉùêπ ! to dominate  ùëÉùêπ !</cell><cell>Reference Pareto front</cell></row><row><cell>Diversity</cell><cell>GS</cell><cell>The extent of spread for ùëÉùêπ !</cell><cell>Reference Pareto front</cell></row><row><cell></cell><cell>PFS</cell><cell>Number of solutions included in ùëÉùêπ !</cell><cell>None</cell></row><row><cell>Combination</cell><cell>IGD HV</cell><cell>Euclidean distance between solutions in  ùëÉùêπ ! and the nearest solutions in  ùëÉùêπ ! The volume covered by solutions in  ùëÉùêπ !</cell><cell>Reference Pareto front Reference Point</cell></row><row><cell>Coverage</cell><cell>C</cell><cell>The dominance between  ùëÉùêπ ! and  ùëÉùêπ !</cell><cell>Reference Pareto front</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 . An overview of the industrial problems</head><label>4</label><figDesc></figDesc><table><row><cell>Domain</cell><cell>Problem</cell><cell>Objective</cell></row><row><cell></cell><cell></cell><cell>Test Minimization Percentage (TMP)</cell></row><row><cell></cell><cell>Test Suite</cell><cell>Feature Pairwise Coverage (FPC)</cell></row><row><cell></cell><cell>Minimization</cell><cell>Fault Detection Capability (FDC)</cell></row><row><cell>Communication</cell><cell></cell><cell>Overall Execution Time (OET) Prioritized Extent (PE)</cell></row><row><cell></cell><cell>Test Case</cell><cell>Feature Pairwise Coverage (FPC)</cell></row><row><cell></cell><cell>Prioritization</cell><cell>Fault Detection Capability (FDC)</cell></row><row><cell></cell><cell></cell><cell>Overall Execution Cost (OEC)</cell></row><row><cell>Subsea oil&amp;gas</cell><cell>Requirements Allocation</cell><cell>Extent of Assigned Requirements (ASSIGN) Familiarity of Stakeholders (FAW) Overall Differences of Workloads (OWL)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 An overview of the experiment design</head><label>5</label><figDesc></figDesc><table><row><cell>RQs</cell><cell>Experiment Tasks</cell><cell>Statistical Tests</cell><cell>Algorithms</cell><cell>Quality Indicators</cell><cell>Problems</cell><cell>Case Studies</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 7 . Matters of the quality indicators within each category</head><label>7</label><figDesc></figDesc><table><row><cell>Category</cell><cell>Quality Indicators</cell><cell>TM</cell><cell>TP</cell><cell>RA</cell></row><row><cell></cell><cell>GD and ED</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Convergence</cell><cell>GD and ùúñ</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell></cell><cell>ED and ùúñ</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Diversity</cell><cell>GS and PFS</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Combination</cell><cell>IGD and HV</cell><cell>1</cell><cell>1</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8 . Key results for the correlation analysis using the ùùâ test for the quality indicators within category</head><label>8</label><figDesc></figDesc><table><row><cell>Category</cell><cell>Quality Indicators</cell><cell>TM</cell><cell>TP</cell><cell>RA</cell></row><row><cell>Convergence</cell><cell>GD and ED GD and ùúñ ED and ùúñ</cell><cell>œÑ &gt; 0 ùëù &lt; 0.05</cell><cell>œÑ &gt; 0 ùëù &lt; 0.05</cell><cell>œÑ &gt; 0 ùëù &lt; 0.05</cell></row><row><cell>Diversity</cell><cell>GS and PFS</cell><cell>ùëù &gt; 0.05</cell><cell>ùëù &gt; 0.05</cell><cell>ùëù &gt; 0.05</cell></row><row><cell>Combination</cell><cell>IGD and HV</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 9 . Matters of the quality indicators across categories</head><label>9</label><figDesc></figDesc><table><row><cell>Category Across</cell><cell>Pair</cell><cell>TM</cell><cell>TP</cell><cell>RA</cell></row><row><cell>Convergence and Diversity</cell><cell>ùúñ and GS ùúñ and PFS</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Convergence and Combination</cell><cell>ùúñ and HV</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Convergence and Coverage</cell><cell>ùúñ and C</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Diversity and Combination</cell><cell>GS and HV PFS and HV</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Diversity and Coverage</cell><cell>GS and C PFS and C</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Combination and Coverage</cell><cell>HV and C</cell><cell></cell><cell></cell><cell></cell></row><row><cell>From</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 9 ,</head><label>9</label><figDesc>we observe that two quality indicators from different categories can result in different trends of performance of the search algorithms except for ùúñ and C. In other words, it does not matter which quality indicators to choose in terms of Convergence and Coverage, but it does matter for the quality indicators from other categories since all values for ùëÄùëéùë°ùë°ùëíùëüùë† = 0.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 10 . Key results for the correlation analysis using the ùùâ test for the quality indicators across categories</head><label>10</label><figDesc>Based on the above results, RQ2 can be answered as follows. It does matter to choose quality indicators across categories except for Convergence and Coverage when assessing Pareto-based search algorithms in different SE contexts.</figDesc><table><row><cell>Category Across</cell><cell>Pair</cell><cell>TM</cell><cell>TP</cell><cell>RA</cell></row><row><cell>Convergence and Diversity</cell><cell>ùúñ and GS ùúñ and PFS</cell><cell>ùëù &gt; 0.05</cell><cell>ùëù &gt; 0.05</cell><cell>ùëù &gt; 0.05</cell></row><row><cell>Convergence and Combination</cell><cell>ùúñ and HV</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Convergence and Coverage</cell><cell>ùúñ and C</cell><cell>œÑ &lt; 0 ùëù &lt; 0.05</cell><cell>œÑ &lt; 0 ùëù &lt; 0.05</cell><cell>œÑ &lt; 0 ùëù &lt; 0.05</cell></row><row><cell>Diversity and Combination</cell><cell>GS and HV PFS and HV</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Diversity and Coverage</cell><cell>GS and C PFS and C</cell><cell>ùëù &gt; 0.05</cell><cell>ùëù &gt; 0.05</cell><cell>ùëù &gt; 0.05</cell></row><row><cell>Combination and Coverage</cell><cell>HV and C</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 11 . Average time to calculate each quality indicator</head><label>11</label><figDesc></figDesc><table><row><cell>Category</cell><cell>Quality Indicators</cell><cell>Average Time (Seconds)</cell></row><row><cell></cell><cell>GD</cell><cell>3.57</cell></row><row><cell>Convergence</cell><cell>ED</cell><cell>1.84</cell></row><row><cell></cell><cell>ùúñ</cell><cell>4.86</cell></row><row><cell>Diversity</cell><cell>GS PFS</cell><cell>5.41 0.35</cell></row><row><cell>Combination</cell><cell>IGD HV</cell><cell>3.76 3.02</cell></row><row><cell>Coverage</cell><cell>C</cell><cell>1.03</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>For reproducibility, we make all the data related with the experiment publicly available at: http://zen-tools.com/ICSE2015.html</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>This research was supported by the Research Council of Norway (RCN) funded Certus SFI. Shuai Wang is also supported by RFF Hovedstaden funded MBE-CR project. Tao Yue and Shaukat Ali are also supported by RCN funded Zen-Configurator project, the EU Horizon 2020 project funded U-Test, RFF Hovedstaden funded MBE-CR project and RCN funded MBT4CPS project.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Search Based Software Engineering: A Comprehensive Analysis and Review of Trends Techniques and Applications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Mansouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno>TR-09-03</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
			<pubPlace>King College London</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Making the Case for MORTO: Multi Objective Regression Test Optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Fourth International Conference on Software Testing, Verification and Validation Workshops</title>
		<meeting>of the IEEE Fourth International Conference on Software Testing, Verification and Validation Workshops</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="111" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A Systematic Review of the Application and Empirical Investigation of Search-Based Test Case Generation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Briand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hemmati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Panesar-Walawege</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="742" to="762" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Pareto Efficient Multi-Objective Test Case Selection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of International Symposium on Software testing and analysis (ISSTA)</title>
		<meeting>of International Symposium on Software testing and analysis (ISSTA)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="140" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Search Based Requirements Optimization: Existing Work and Challenges</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Requirements Engineering: Foundation for Software Quality</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="88" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cost-effective test suite minimization in lines using search techniques</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gotlieb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Systems and Software</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="370" to="391" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Combining Multi-Objective Search and Constraint Solving for Configuring Large Software Product Lines</title>
		<author>
			<persName><forename type="first">C</forename><surname>Henard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Papadakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">L</forename><surname>Traon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 37th International Conference on Software Engineering (ICSE)</title>
		<meeting>of the 37th International Conference on Software Engineering (ICSE)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">UPMOA: An improved search algorithm to support user-preference multi-objective optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liaaen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of International Symposium on Software Reliability Engineering</title>
		<meeting>of International Symposium on Software Reliability Engineering</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="393" to="404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">jMetal: A Java framework for multiobjective optimization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Durillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Nebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Engineering Software</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="760" to="771" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A Systematic Test Case Selection Methodology for Product Lines: Results and Insights From an Industrial Case Study</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gotlieb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liaaen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Empirical Software Engineering Journal</title>
		<imprint>
			<biblScope unit="page" from="1" to="37" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Zen-ReqOptimizer: A Search-based Approach for Requirements Assignment Optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Empirical Software Engineering Journal</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On the value of user preferences in search-based software engineering: a case study in software product lines</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Sayyad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Menzies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ammar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference of Software Engineering (ICSE)</title>
		<meeting>of the International Conference of Software Engineering (ICSE)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="492" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Pareto-Optimal Search-Based Software Engineering (POSBSE): A literature Survey</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Sayyad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ammar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 2nd International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering</title>
		<meeting>of 2nd International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="21" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mansouri</surname></persName>
		</author>
		<title level="m">The SBSE Repository: A repository and analysis of authors and research articles on Search Based Software Engineering</title>
		<meeting><address><addrLine>CREST Centre, UCL</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multi-objective test prioritization in software product line testing: an industrial case study</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Buchmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gotlieb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liaaen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 18th International Software Product Line Conference</title>
		<meeting>of the 18th International Software Product Line Conference</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="32" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Minimizing Test Suites in Software Product Lines Using Weighted-based Genetic Algorithms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gotlieb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Genetic and Evolutionary Computation Conference</title>
		<meeting>of the Genetic and Evolutionary Computation Conference</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1493" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Clever Algorithms: Nature-Inspired Programming Recipes</title>
		<author>
			<persName><forename type="first">J</forename><surname>Brownlee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A Fast and Elitist Multiobjective Genetic Algorithm: NSGA-II</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pratap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Meyarivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="182" to="197" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Design Issues in a Multiobjective Cellular Genetic Algorithm</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Nebro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Durillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Luna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dorronsoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Alba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary Multi-Criterion Optimization</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="126" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Optimization and Control with Applications to Industrial Problems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laumanns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the EUROGEN 2001-Evolutionary Methods for Design</title>
		<meeting>of the EUROGEN 2001-Evolutionary Methods for Design</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="95" to="100" />
		</imprint>
	</monogr>
	<note>SPEA2: Improving the Strength Pareto Evolutionary Algorithm</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Approximating the Nondominated Front Using the Pareto Archived Evolution Strategy</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Corne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="149" to="172" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">SMPSO: A new PSO-based Metaheuristic for Multi-objective Optimization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Nebro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Durillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Garcia-Nieto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Coello Coello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Luna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Alba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Symposium on Computational Intelligence in Multicriteria Decision-Making (MCDM)</title>
		<meeting>of the Symposium on Computational Intelligence in Multicriteria Decision-Making (MCDM)</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="66" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Solving Threeobjective Optimization Problems using a New Hybrid Cellular Genetic Algorithm</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Durillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Nebro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Luna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Alba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="661" to="670" />
		</imprint>
	</monogr>
	<note>Parallel Problem solving from nature-PPSN X. Lecture notes in computer science</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Enhancing Test Case Prioritization in an Industrial Setting with Resource Awareness and Multi-Objective Search</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">√ò</forename><surname>Bakkeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liaaen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 38 th International Conference on Software Engineering</title>
		<meeting>of the 38 th International Conference on Software Engineering</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Applying Search Algorithms for Optimizing Stakeholders Familiarity and Balancing Workload in Requirements Assignment</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM Genetic and Evolutionary Computation Conference</title>
		<meeting>of ACM Genetic and Evolutionary Computation Conference</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1295" to="1302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A Tutorial on the Performance Assessment of Stochastic Multiobjective Optimizers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">)</forename><surname>Tik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eth</forename><surname>Zurich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Engineering and Networks Laboratory</title>
		<imprint>
			<biblScope unit="volume">214</biblScope>
			<date type="published" when="2006-02">Feb. 2006</date>
		</imprint>
	</monogr>
	<note>TIK Report</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Multi-objective optimization using evolutionary algorithms</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multiobjective evolutionary algorithms: a comparative case study and the strength pareto approach</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Evol Comput</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="257" to="271" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Multiobjective evolutionary algorithm research: A history and analysis</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Van Veldhuizen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Lamont</surname></persName>
		</author>
		<idno>TR-98-03</idno>
	</analytic>
	<monogr>
		<title level="j">Dept. Elec. Comput. Eng., Graduate School of Eng., Air Force Inst.Technol</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<pubPlace>Wright-Patterson, AFB, OH</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Cyber-physical system product line engineering: comprehensive domain analysis and experience report</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Selic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of International Conference on Software Product Line</title>
		<meeting>of International Conference on Software Product Line</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="338" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Research-based innovation: A tale of three projects in model-driven engineering</title>
		<author>
			<persName><forename type="first">L</forename><surname>Briand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Falessi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nejati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sabetzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM/IEEE 15th International Conference on Model Driven Engineering Languages and Systems (MODELS)</title>
		<meeting>of ACM/IEEE 15th International Conference on Model Driven Engineering Languages and Systems (MODELS)</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="793" to="809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Multiple Criteria Decision Making</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Cochrane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zeleny</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973">1973</date>
			<publisher>University of South Carolina Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Multiobjective optimization and multiple constraint handling with evolutionary algorithms-part ii: application example</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Flemming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans System, Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="38" to="47" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">GA-based decision support system for multicriteria optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Furukawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tanino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE international conference on systems, man, and cybernetics</title>
		<meeting>of the IEEE international conference on systems, man, and cybernetics</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1556" to="1561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">AbYSS: Adapting Scatter Search to Multiobjective Optimization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Nebro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Luna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Alba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dorronsoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Durillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Evol Comput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="439" to="457" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Combining model-based and genetics-based offspring generation for multiobjective optimization using a convergence criterion</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sendhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tsang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Congress on evolutionary computation (CEC)</title>
		<meeting>of IEEE Congress on evolutionary computation (CEC)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="3234" to="3241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Establishing Integration Test Orders of Classes with Several Coupling Measures</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K G</forename><surname>Assun√ß√£o</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Colanzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T R</forename><surname>Pozo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Vergilio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of GECCO</title>
		<meeting>of GECCO<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1867" to="1874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The human competitiveness of search based software engineering</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>De Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Maia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">G</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Coutinho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SSBSE</title>
		<meeting>of SSBSE</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="143" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Diversity comparison of Pareto front approximations in many-objective optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Cybern</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2568" to="2584" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Differential Evolution with Pareto Tournament for the Multi-objective Next Release Problem</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Chaves-Gonz√°lez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>P√©rez-Toledano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">252</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">An Empirical Study of the Sensitivity of Quality Indicator for Software Module Clustering</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Amarjeet</surname></persName>
		</author>
		<author>
			<persName><surname>Chhabra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 7th International Conference on Contemporary Computing (IC3 &apos;14)</title>
		<meeting>of 7th International Conference on Contemporary Computing (IC3 &apos;14)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="206" to="211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A multi-objective optimization approach for the integration and test order problem</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K G</forename><surname>Assun√ß√£o</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Colanzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Vergilio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pozo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">267</biblScope>
			<biblScope unit="page" from="119" to="139" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A Pattern-Driven Mutation Operator for Search-Based Product Line Architecture Design</title>
		<author>
			<persName><forename type="first">G</forename><surname>Guizzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Colanzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Vergilio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 6th International Symposium on Search-Based Software Engineering (SSBSE)</title>
		<meeting>of the 6th International Symposium on Search-Based Software Engineering (SSBSE)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="77" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Search Based Software Engineering for Software Product Line Engineering: A Survey and Directions for Future Work</title>
		<author>
			<persName><forename type="first">M</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Krinke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Langdon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Petke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 18th International Software Product Line Conference (SPLC)</title>
		<meeting>of the 18th International Software Product Line Conference (SPLC)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="5" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Multiobjective Genetic Optimization for Noise-Based Testing of Concurrent Software</title>
		<author>
			<persName><forename type="first">V</forename><surname>Hrub√°</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>K≈ôena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Letko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pluh√°ƒçkov√°</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Vojnar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 6th International Symposium on Search-Based Software Engineering (SSBSE)</title>
		<meeting>of the 6th International Symposium on Search-Based Software Engineering (SSBSE)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="107" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Bi-Objective Genetic Search for Release Planning in Support of Themes</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Karim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ruhe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 6th International Symposium on Search-Based Software Engineering (SSBSE)</title>
		<meeting>of the 6th International Symposium on Search-Based Software Engineering (SSBSE)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="123" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Robust Next Release Problem: Handling Uncertainty During Optimization</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Letier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Genetic and Evolutionary Computation</title>
		<meeting>of the Conference on Genetic and Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1247" to="1254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Comparative Analysis of Classical Multi-Objective Evolutionary Algorithms and Seeding Strategies for Pairwise Testing of Software Product Lines</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Lopez-Herrejon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ferrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chicano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Egyed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Alba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Congress on Evolutionary Computation (CEC)</title>
		<meeting>of IEEE Congress on Evolutionary Computation (CEC)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="387" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The Software Project Scheduling Problem: A Scalability Analysis of Multi-objective Metaheuristics</title>
		<author>
			<persName><forename type="first">F</forename><surname>Luna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Gonz√°lez-√Ålvarez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chicano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Vega-Rodr√≠guez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="136" to="148" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">High Dimensional Search-based Software Engineering: Finding Tradeoffs among 15 Objectives for Automating Software Refactoring using NSGA-III</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Mkaouer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kessentini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bechikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">√ì</forename><surname>Cinn√©ide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Genetic and Evolutionary Computation</title>
		<meeting>of the Conference on Genetic and Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1263" to="1270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A Robust Multi-objective Approach for Software Refactoring under Uncertainty</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Mkaouer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kessentini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bechikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">√ì</forename><surname>Cinn√©ide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 6th International Symposium on Search-Based Software Engineering (SSBSE)</title>
		<meeting>of the 6th International Symposium on Search-Based Software Engineering (SSBSE)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="168" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Identifying Optimal Trade-offs between CPU Time Usage and Temporal Constraints using Search</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nejati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Briand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Symposium on Software Testing and Analysis (ISSTA)</title>
		<meeting>of the International Symposium on Software Testing and Analysis (ISSTA)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="251" to="261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">On the Performance of Multiple Objective Evolutionary Algorithms for Software Architecture Discovery</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ramrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ventura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Conference on Genetic and Evolutionary Computation (GECCO)</title>
		<meeting>of Conference on Genetic and Evolutionary Computation (GECCO)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1287" to="1294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A Comparison Study of Binary Multi-Objective Particle Swarm Optimization Approaches for Test Case Selection</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>De Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B C</forename><surname>Prudencio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Barros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Congress on Evolutionary Computation (CEC)</title>
		<meeting>of the IEEE Congress on Evolutionary Computation (CEC)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2164" to="2171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Requirements Prioritization and Next-Release Problem under Non-Additive Value Conditions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sureka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 23rd Australian Software Engineering Conference (ASWEC)</title>
		<meeting>of the 23rd Australian Software Engineering Conference (ASWEC)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="120" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">On the Application of the Multi-Evolutionary and Coupling-Based Approach with Different Aspect-Class Integration Testing Strategies</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K G</forename><surname>Assun√ß√£o</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Colanzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Vergilio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pozo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 5th International Symposium on Search-Based Software Engineering (SSBSE)</title>
		<meeting>of the 5th International Symposium on Search-Based Software Engineering (SSBSE)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="19" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Cost-aware Pareto Optimal Test Suite Minimisation for Service-centric Systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bozkurt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Genetic and Evolutionary Computation (GECCO)</title>
		<meeting>of the Conference on Genetic and Evolutionary Computation (GECCO)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1429" to="1436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A Multi-Objective Genetic Algorithm to Rank State-Based Test Cases</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Briand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Labiche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 5th International Symposium on Search-Based Software Engineering (SSBSE)</title>
		<meeting>of the 5th International Symposium on Search-Based Software Engineering (SSBSE)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="66" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Preference-based Multi-Objective Software Modelling</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Mkaouer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kessentini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bechikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Tauritz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 1st International Workshop on Combining Modelling and Search-Based Software Engineering (CMSBSE &apos;13)</title>
		<meeting>of 1st International Workshop on Combining Modelling and Search-Based Software Engineering (CMSBSE &apos;13)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="61" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">The Use of Development History in Software Refactoring using A Multiobjective Evolutionary Algorithm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ouni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kessentini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sahraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Hamdi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Conference on Genetic and Evolutionary Computation</title>
		<meeting>of Conference on Genetic and Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1461" to="1468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A Practical Guide for Using Statistical Tests to Assess Randomized Algorithms in Software Engineering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Arcuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Briand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of International Conference on Software Engineering (ICSE)</title>
		<meeting>of International Conference on Software Engineering (ICSE)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="21" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Barros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Dias-Neto</surname></persName>
		</author>
		<title level="m">Threats to Validity in Searchbased Software Engineering Empirical Studies</title>
		<imprint>
			<publisher>UNIRIO -Universidade Federal do Estado do Rio de Janeiro0006/2011</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Handbook of Parametric and Nonparametric Statistical Procedures</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Sheskin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">A New Measure of Rank Correlation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kendall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="81" to="89" />
			<date type="published" when="1938">1938</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Quality Assessment of Pareto Set Approximations</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zizler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Multiobjective Optimization Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="page" from="373" to="404" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
