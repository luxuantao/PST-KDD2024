<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!</title>
				<funder ref="#_HkzN9kB">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yubo</forename><surname>Ma</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">S-Lab</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yixin</forename><surname>Cao</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Singapore Management University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yongching</forename><surname>Hong</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">S-Lab</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aixin</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">S-Lab</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Identify the entities expressed by each sentence</term>
					<term>then locate each entity to words in sentence. The possible entity types are location-GPE</term>
					<term>organizationcompany</term>
					<term>person-politician?? Sentence: DSC and Traction Control on all Speed3 models is also standard. Entities: (type: product-other</term>
					<term>identified_entity: DSC)</term>
					<term>(type: product-car</term>
					<term>identified_entity: Speed3) Peterson</term>
					<term>Object: pianist</term>
					<term>Relation: No defined relation)</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large Language Models (LLMs) have made remarkable strides in various tasks. However, whether they are competitive few-shot solvers for information extraction (IE) tasks and surpass fine-tuned small Pre-trained Language Models (SLMs) remains an open problem. This paper aims to provide a thorough answer to this problem, and moreover, to explore an approach towards effective and economical IE systems that combine the strengths of LLMs and SLMs. Through extensive experiments on eight datasets across three IE tasks, we show that LLMs are not effective few-shot information extractors in general, given their unsatisfactory performance in most settings and the high latency and budget requirements. However, we demonstrate that LLMs can well complement SLMs and effectively solve hard samples that SLMs struggle with. Building on these findings, we propose an adaptive filterthen-rerank paradigm, in which SLMs act as filters and LLMs act as rerankers. By utilizing LLMs to rerank a small portion of difficult samples identified by SLMs, our preliminary system consistently achieves promising improvements (2.1% F1-gain on average) on various IE tasks, with acceptable cost of time and money.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Large Language Models <ref type="bibr">(LLMs, Brown et al. 2020;</ref><ref type="bibr" target="#b4">Chowdhery et al. 2022;</ref><ref type="bibr" target="#b8">Hoffmann et al. 2022)</ref> are becoming a fundamental tool for general task solver. They have shown amazing emergent (e.g., memorization and reasoning) abilities through incontext learning (ICL) on various applications, including arithmetic reasoning, commonsense reasoning, and open-domain question answering <ref type="bibr">(Wei et al., 2022c;</ref><ref type="bibr" target="#b31">Yu et al., 2023;</ref><ref type="bibr" target="#b23">Sun et al., 2023)</ref>.</p><p>Recent studies have compared the performance between LLMs with ICL<ref type="foot" target="#foot_0">1</ref> and Small Language Models (SLMs) with conventional fine-tuning techniques<ref type="foot" target="#foot_1">2</ref> across many tasks. Focusing on information extraction (IE), some claim that LLMs are good few-shot extractors <ref type="bibr" target="#b26">(Wang et al., 2022;</ref><ref type="bibr" target="#b0">Agrawal et al., 2022)</ref>, while some others hold opposite opinions <ref type="bibr" target="#b9">(Jimenez Gutierrez et al., 2022)</ref>. We attribute the disagreement to the different IE subtasks, datasets, and settings in experiments. Given the disagreement, we claim a systematic evaluation on whether LLMs perform competitively on various few-shot IE tasks is non-trivial for further research.</p><p>In this paper, we target such a thorough evaluation on the advantages and disadvantages of LLMs and SLMs on various IE tasks. We aim to answer the following questions: 1) Do LLMs really outperform SLMs in few-shot IE tasks? 2) Can more annotations improve LLMs and SLMs? 3) In terms of financial and time cost, which is preferable? 4) Are LLMs and SLMs respectively adept at handling different types of samples?</p><p>To answer the first three questions, we conduct an extensive empirical study on eight datasets across three common IE tasks: Named Entity Recognition (NER), Relation Extraction (RE), and Event Detection (ED). The results show that 1) LLMs outperform SLMs only when the overall number of annotations is limited, i.e., both label types 3 and the samples 4 per label are extremely scarce. However, 2) when we increase the number of samples (e.g., a few hundreds), SLMs outperform LLMs by a large margin. We speculate it is caused by the natural limitations of ICL in two main ways. First, only a small subset of available samples can be used as demonstrations (demos) to prompt LLMs due to the maximum input length of ICL. Moreover, more samples in demos might not bring extra performance gains. Second, as the schema (or number of label types) grows, the number of samples per label in prompts decreases. It is thus difficult to well understand tens (even hundreds) of label types and their semantic interactions via instruction. Besides, 3) calling LLMs API suffers from much higher inference latency and financial cost than finetuning SLMs locally, especially when there are excessively long demos in ICL. Therefore, we claim that LLM is not a good few-shot information extractor in general.</p><p>We next investigate whether LLMs and SLMs exhibit different abilities to handle various types of samples, hoping LLMs could complement SLMs. We partition the testing samples into different groups according to their difficulty (measured by the confidence score of SLMs-based models) and compare the results of LLMs and SLMs on each group. We find that 4) LLMs are good at hard samples, though bad at easy samples. We speculate the hard samples (i.e., low confidence scores) require external knowledge or complex reasoning, which go beyond the abilities of SLMs but could be well solved by LLMs. For relatively easy samples, however, SLMs learn them well by fine-tuning parameters and perform much better than LLMs.</p><p>Building on these findings, we propose a novel adaptive filter-then-rerank framework to combine SLMs and LLMs considering both performance and cost in practice. The basic idea is that SLMs serve as a filter and LLMs as a reranker. In specific, SLMs make the first round of prediction, and if the sample is a hard one, we further pass the top-N candidate labels with highest prediction scores by SLMs to LLMs for reranking. The reranking mechanism leverages both LLMs and SLMs to deal with samples on which they are more proficient and thus combines their strengths. Moreover, it reranks only a small subset of test samples and minimizes the extra latency and budgets for calling LLM APIs. We outline our main contributions as follows:</p><p>? We conduct an extensive empirical study comparing LLMs and SLMs on IE tasks. Our findings suggest that LLMs are generally not wellsuited for IE tasks, especially when dealing with many samples and complicated schema.</p><p>? We propose a filter-then-rerank paradigm that combines the strengths of both LLMs and SLMs. We note that LLMs can be effective rerankers for challenging samples.</p><p>? With only 0.5%-13.2% of the samples being reranked, our adaptive filter-then-rerank system surpasses the previous state-of-the-art methods by an average 2.1% F1-score gain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Large Language Models (LLMs) We are fortunate to witness the emergent abilities <ref type="bibr">(Wei et al., 2022b)</ref> of Large Language Models <ref type="bibr">(LLMs, Brown et al. 2020;</ref><ref type="bibr" target="#b4">Chowdhery et al. 2022;</ref><ref type="bibr" target="#b8">Hoffmann et al. 2022)</ref> very recently. With qualitative progress on model scales <ref type="bibr">(parameters, training corpus, training compute, etc. Brown et al. 2020;</ref><ref type="bibr" target="#b4">Chowdhery et al. 2022)</ref> and training strategies (code tuning, instruction tuning, human feedback, chain-of-thought tuning, etc. <ref type="bibr">Chen et al. 2021;</ref><ref type="bibr">Wei et al. 2022a;</ref><ref type="bibr" target="#b18">Ouyang et al. 2022;</ref><ref type="bibr" target="#b4">Chung et al. 2022)</ref>, LLMs show unprecedented reasoning and/or memorization abilities and benefit diverse NLP tasks.</p><p>In-context Learning (ICL) In our work, we use LLMs via ICL since fine-tuning LLMs for every downstream task is not practical. ICL enables LLMs to learn tasks through instructions and/or a few exemplars at inference stage without the need for model parameter updating. There are various approaches to improve the ICL ability of LLMs:</p><p>(1) Chain-of-Thought Reasoning (CoT) <ref type="bibr">(Wei et al., 2022c;</ref><ref type="bibr" target="#b11">Kojima et al., 2022;</ref><ref type="bibr" target="#b33">Zhang et al., 2023)</ref> leverages manual or auto-generated rationales to elicit the power of LLMs.</p><p>(2) Demonstration Selection (DS) <ref type="bibr" target="#b12">(Liu et al., 2022;</ref><ref type="bibr" target="#b20">Rubin et al., 2022;</ref><ref type="bibr" target="#b22">Su et al., 2022)</ref> retrieves appropriate samples as demos via unsupervised sentence similarity or supervised neural retriever. (3) Self-consistency <ref type="bibr" target="#b26">(Wang et al., 2023)</ref> or Self-ensemble (SE) runs LLMs multiple times and determines the final results from different results by majority voting. We explore all three variants in Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ICL in Information Extraction Tasks</head><p>There have been two branches exploring the use of LLMs in few-shot IE tasks with the aid of ICL. The first branch <ref type="bibr" target="#b5">(Ding et al., 2022;</ref><ref type="bibr" target="#b10">Josifoski et al., 2023)</ref> views LLMs as an annotator and generates abundant samples with (pseudo) labels via ICL approaches. They then train SLMs using augmented data to achieve superior performance. Another branch, which includes our work, directly employs LLMs for inference. We contend that our approach differs from theirs in at least two ways. Firstly, previous work has been constrained to a single task type or a limited number of label types, and  <ref type="bibr" target="#b24">(Tjong Kim Sang and De Meulder, 2003)</ref>, OntoNotes 5.0 <ref type="bibr" target="#b30">(Weischedel et al., 2013)</ref> and FewNERD <ref type="bibr" target="#b5">(Ding et al., 2021)</ref>.</p><p>(2) Relation Extraction (RE): TA-CRED <ref type="bibr" target="#b32">(Zhang et al., 2017)</ref> and TACREV <ref type="bibr" target="#b1">(Alt et al., 2020)</ref>. (3) Event Detection (ED): ACE05 <ref type="bibr" target="#b6">(Doddington et al., 2004)</ref>, MAVEN <ref type="bibr" target="#b26">(Wang et al., 2020)</ref> and ERE <ref type="bibr" target="#b21">(Song et al., 2015)</ref>. We list the statistics of these eight datasets in Appendix A.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setup</head><p>We construct few-shot datasets from the original eight datasets mentioned above. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Small Language Models</head><p>We adopt four representative supervised methods to evaluate the ability of SLMs on few-shot IE tasks. We choose RoBERTa-large <ref type="bibr" target="#b13">(Liu et al., 2019)</ref> as the backbone of extractive-based methods and T5-large <ref type="bibr">(Raffel et al., 2020)</ref> as the backbone of generation-based methods, respectively. Next, we brief these methods and leave their implementation details in Appendix B.1.</p><p>(1). Fine-tuning (FT): Add a classifier head on SLMs to predict the labels of each sentence/word.</p><p>(2). FSLS <ref type="bibr" target="#b17">(Ma et al., 2022)</ref>: The state-of-the-art extractive-based method for few-shot NER task. Anonymous (2022) also validate its competitive performance on few-shot ED tasks.</p><p>(3). KnowPrompt <ref type="bibr" target="#b3">(Chen et al., 2022)</ref>: The best extractive-based method for few-shot RE task.</p><p>(4). UIE <ref type="bibr">(Lu et al., 2022b)</ref>: A competitive unified generation-based method for few-shot IE tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Large Language Models</head><p>We adopt the current 5 strongest CODEX 6 <ref type="bibr">(Chen et al., 2021)</ref> rather than InstructGPT 7 <ref type="bibr" target="#b18">(Ouyang et al., 2022)</ref> in our experiments out of two primary reasons: (1) They share similar scales (~175B) and functionality. Previous study <ref type="bibr" target="#b26">(Wang et al., 2022)</ref> showed CODEX has comparable, if not better, ICL capability. Our pivot experiments in Appendix C.1 further validates it. (2) Calling InstructGPT via API 8 is very costly. 9 In contrast, CODEX is currently available for free, allowing us to reduce cost and improve the reproducibility of our experiments.</p><p>We adopt several ICL approaches to evaluate the LLM ability on IE tasks. We introduce them in 5 2023-03-03 6 code-davinci-002 7 text-davinci-003 8 https://openai.com/ 9 The estimated cost of using InstructGPT is about 40K dollars to reproduce all the experiments in this section.</p><p>brief here and leave their details in Appendix B.2.</p><p>(1). Vanilla ICL utilizes the common prompts consisting of instruction, demonstrations (demos) and question. We show such format in Figure <ref type="figure">1</ref>.</p><p>(2). ICL w. Automatic Chain-of-thought (Auto-CoT, <ref type="bibr" target="#b33">Zhang et al. 2023</ref>) first bootstrap rationales from original examples. These generated rationales then act as intermediate reasoning steps in demos.</p><p>(3). ICL w. Demonstration Selection (DS, <ref type="bibr" target="#b12">Liu et al. 2022</ref>) retrieves similar training examples as demos for each test example. We adopt a heuristic unsupervised approach here measuring the similarity of each sentence by their embeddings. (4). ICL w. Self-ensemble (SE) predicts each test example by multiple times. Each time the examples (and/or their orders) are different in the demos. These predicted outputs are ensemebled by majorvoting to determine the final prediction. 10 We first overview the performance of the remaining seven methods in Figure <ref type="figure" target="#fig_0">2</ref>. Comparison among ICL Approaches We observe that vanilla ICL achieves the worst results among three remaining ICL approaches. Since the number of examples in demos is bounded by LLMs' maximum input length, the increase of sample number brings no benefit and the performance of ICL is at a standstill once the sample number exceeds some threshold. Both DS and SE slightly alleviate such problem to some extent. Overall speaking, SE is better than DS with fewer shots, while DS outperforms the other two methods with more samples, i.e., more retrieval candidates. LLMs are not good few-shot Information Extractor. Even compared with the best LLM-based methods, SLMs mostly outperform by a large margin . (1) For most of the NER and RE datasets (except CONLL'03 with only 4 defined entities), the best LLM-based methods merely present significantly superior performance than SLMs unconsistency <ref type="bibr" target="#b26">(Wang et al., 2023)</ref>. The randomness in selfconsistency lies in output rationales (and answers) generated from nucleus sampling <ref type="bibr" target="#b9">(Holtzman et al., 2020)</ref>. The randomness in self-ensemble, however, comes from the different examples in input demos. We find setting the samping temperature coefficient t = 0, i.e., greedy decoding, achieves the optimal result according to pivot experiments in Appendix C.3. Therefore we use self-ensemble rather than self-consistency (which requires a non-zero t) in this work.</p><p>der extremely low-resource settings (1-shot). The most competitive SLMs usually achieve comparable results with LLMs under 5-10 shot settings. With more samples, LLM-based methods perform worse than almost all SLM-based methods. (2) For three ED datasets, SLMs consistently beat all LLM-based methods even under 1-shot settings. LLMs show limited inference speed We additionally compare the inference speed of different methods and show their results in Table <ref type="table" target="#tab_2">1</ref>. Expectedly we observe that the most efficient LLM-based method, i.e., vanilla ICL, is still much slower than SLMs since they have much more parameters and longer input context length. We speculate it is partly due to their task formats. Both of these two tasks require structured outputs, i.e., the (label, span) tuples as shown in Figure <ref type="figure">1</ref>. Moreover, the number of outputs and the extracted span within each output are not fixed. Standing with <ref type="bibr" target="#b10">Josifoski et al. (2023)</ref>, we believe ICL approaches are not experienced on such task formats.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract Event Understanding</head><p>We observe that ED achieves the worst performance among three tasks. In addition to its task format, (1) the definition of events is more abstract than that of entity and relations, (2) and the rules for labeling events are more complicated<ref type="foot" target="#foot_4">11</ref> . Therfore we speculate the abilities required to solve ED task are unlikely to be learned during the pre-training of LLMs or be generalized through instructions during ICL.</p><p>4 LLMs are Good Few-shot Reranker</p><p>Despite their unsatisfactory performance and their significant time and monetary costs, we believe that LLMs' abilities in memorization and reasoning remain crucial strengths for solving IE tasks. Consequently, we aim to identify more effective methods to harness the strengths of LLMs while minimizing their limitations in this section.</p><p>We propose a novel filter-then-rerank paradigm. Based on such paradigm, we observe the complementary results of LLMs and SLMs on samples with varying levels of difficulty. We would detail them in the following two subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Filter-then-rerank Paradigm</head><p>Our filter-then-rerank paradigm combines SLMs and LLMs, as its name implies, by utilizing both as a filter and a reranker within it. SLMs act as a filter which eliminates unlikely labels and retains only the top-N candidates. LLMs then rerank these N labels and output the final answer.</p><p>Within our filter-then-rerank paradigm, we dynamically obtain N candidate labels for each test sample to be reranked by LLMs. We argue the prompts used in Section 3.3, which contain the whole schema in their instructions, are no longer needed. Instead, we reformulate the reranking procedure as a multiple-choice question. We show the format of our new multiple-choice question prompt as below, and leave real examples in Appendix F. As shown above, the instruction asks LLMs to determine the relation between entities in the sentence followed by. Then N candidate labels filtered from SLMs are provided. Each label is rephrased as a piece of choice text using the template T(&lt;label&gt;, &lt;h ent&gt;, &lt;t ent&gt;). The template describes that the head entity &lt;h ent&gt; and the tail entity &lt;e ent&gt; have &lt;label&gt; relation. For example, T(cities_of_residence, Charles, Abidjan) = Charles lives in the city Abidjan. Then LLMs are expected to answer this multiple-choice question (optionally associated with rationales) as colored in red. We believe the format of multiplechoice question has various advantages: (1) It narrows the label scope significantly. (2) It lowers the difficulty of IE tasks since LLMs are more familiar with this format.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">LLMs are and only are Hard Sample Solver</head><p>Unfortunately, we find such a filter-then-rerank system still performs far from satisfactory. Moreover, it leads to longer latency since LLMs rerank candidates per sample, rather than per sentence. We intuitively speculate LLMs are more proficient than SLMs on hard samples. The hard samples here refer to those requiring external knowledge or complex reasoning beyond the capability of SLMs, see examples in Appendix E. SLMs could not solve them well with limited model capacity and data amount, while LLMs could solve them better. In contrast, SLMs could learn easy samples well from more samples by updating their parameters and exceed the performance of LLMs.</p><p>We design experiments to validate our conjecture. We group the samples by their difficulty and evaluate their performance before and after reranking within each group. To measure the difficulty of a sample x for SLMs, we adopt the maximum probability among all labels as the confidence score,</p><formula xml:id="formula_0">s(x) = max y?Y p(y|x)<label>(1)</label></formula><p>where p(y|x) represents the probability of x having label y computed by SLMs. We call samples with low confidence scores as hard samples.</p><p>We conduct experiments on various datasets with SLM-based methods (i.e., the filter). We select FewNERD, TACREV and ACE05 as the datasets, fine-tuning and the best baseline in Section 3.4 (FSLS for FewNERD and ACE05 datasets, Know-Prompt for TACREV dataset) as two SLM-based methods. The results illustrated in Figure <ref type="figure" target="#fig_2">3</ref> validate our assumption. (1) There exists a consistent trend among different tasks and SLM-based methods that the performance of low-confidence samples improves after reranking while the highconfidence ones get degraded from reranking (see the red curves are usually higher than the purple curves when the confidence being less than a threshold, but lower after exceeding such threshold). In other word, LLMs are more proficient than SLMs on hard samples, but often make mistake on easy samples.</p><p>(2) The hit@3 scores of SLMs usually achieve more than 95%<ref type="foot" target="#foot_5">12</ref> even under low-confidence scenarios. It ensures almost all true answers are included in candidate options for LLMs to rerank, making our reranking feasible.</p><p>(3) The performance of LLMs might collapse under samples with very high-confidence. It is likely due to that LLMs sometimes tend to give false-positive predictions for negative samples, most of which are easy for SLMs and lie in high-confidence interval. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Method</head><p>We call our method as adaptive filter-then-rerank and illustrate it in Figure <ref type="figure" target="#fig_3">4</ref>. We first train SLMs with supervised approach and use it to predict each test sample. For samples with confidence score higher than a threshold, we retain their predictions from SLMs as final results. Otherwise we</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Filter</head><p>The sentence implies that Charles Ble Goude is a supporter of Ouattara and was present in Abidjan for a rally.</p><p>However, there is no indication in the sentence that Charles Ble Goude has any specific relationship with Abidjan.</p><p>Answer: (b)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Demonstration</head><p>The lawyer denied Italian news reports that she wept while addressing the court, but said Knox was upset as she recounted the pressure, the aggressiveness of the police who called her a liar . select their top-N predictions and rerank them via LLMs. Here the threshold is adaptively determined by maximizing F1-score of the validation set.</p><p>As shown in right part of Figure <ref type="figure" target="#fig_3">4</ref>, the prompt used in our adaptive reranker is composed of demos and an unanswered question. The demos (green part) contain several exemplars and each of them is an answered multiple-choice question as shown in Section 4.1. The unanswered question (pink part) is exactly a hard sample with N candidate labels to be reranked. The LLMs would rerank the candidates by answering this question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental Setup</head><p>We conduct experiments on FewNERD for NER task, TACREV for RE task and ACE05 for ED task. We set K as <ref type="bibr">(5,</ref><ref type="bibr">10,</ref><ref type="bibr">20)</ref> for NER/ED tasks, and (20, 50, 100) for RE task. We use the competitive SLM-based methods shown in previous experiments (FSLS for NER and ED tasks, Know-Prompt for RE task. Both use RoBERTa-large as backbones) as the filter, and a 175B InstructGPT (text-davinci-003) as the reranker.</p><p>We select the top-3 candidate labels for NER/RE tasks, and top-2 candidate labels for ED task from SLMs' predictions and feed them to LLMs. We also add No-label choice if it is not in the top-N predictions of each sample. We select 20 samples from validation set and write their rationales manually for each dataset. We randomly choose 4 example from them as demos each time. See some demo examples in Appendix F. We follow template in <ref type="bibr">Lu et al. (2022a)</ref> as our choice-template for TACREV dataset, and write templates used in FewNERD and ACE05 dataset by ourselves. We list all these templates in Appendix G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Main Results</head><p>We compare 5 methods in this section to validate the effectiveness of our filter-then-rerank method.</p><p>(1) LLM-based ICL approach: We select the most competitive LLM-based variant shown in Section 3.4, ICL with DS, as a baseline.</p><p>(2) FSLS/KnowPrompt: The most competitive SLM-based methods (FSLS for NER and ED tasks, KnowPrompt for RE task) shown in Section 3.4.</p><p>(3) FSLS/KnowPrompt + Ensemble: We ensemble two SLMs (trained with the same dataset but different seeds), to validate the score gains from reranking is not only due to the ensemble effect. (4) FSLS/KnowPrompt + Rerank: Our adaptive reranker with one SLM model as the filter.</p><p>(5) FSLS/KnowPrompt + Ensemble+ Rerank: Our adaptive reranker with ensemble of two SLMs as the filter, to further validate the gains from ensemble and reranking are complementary.</p><p>We overview the results listed in Table <ref type="table" target="#tab_5">2</ref> and observe that our filter-then-rerank method achieves consistent and significant improvement on nine different settings across three datasets. The reranker brings a 2.4% average F1-gains without ensemble (line 3 v.s 5) and 2.1% F1-gains with ensemble (line 4 v.s 6). Thus we conclude that (1) the reranking approach is effective, and (2) the gains it brings are different and complementary to the ensemble.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Ablation Study</head><p>We investigate the effectiveness of modules in LLM-reranker by removing each of them in turn.</p><p>(1) Manual CoT: We remove the rationales of examples in demos.</p><p>(2) Demonstrations: We further remove all demos, making the reranking procedure as a zero-shot QA (question answering) problem.</p><p>(3) Candidate Filter: We keep all samples rather than only top-N labels for reranking. We show their results in Table <ref type="table" target="#tab_6">3</ref> and observe that (1) Demos with manual CoT achieves consistent improvement on all three datasets. It indicates that the rationales on correct choices further elicit the reranking ability of LLMs. (2) Even the demos without rationales improve the performance to some extent, see the comparison line 2 v.s. 3 and line 4 v.s. 5. (3) The filtering of candidate labels usually brings gains, especially on TACREV dataset. Furthermore, it significantly reduces the input length of LLMs and thus the inference cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Analysis</head><p>Few makes big difference We know from Figure <ref type="figure" target="#fig_2">3</ref> that most of samples are easy for SLMs (with high Few makes small cost We compare the inference cost between direct ICL via InstructGPT and filterthen-rerank method from two aspects, financial and time, in Figure <ref type="figure" target="#fig_4">5</ref>. It shows that filter-then-rerank achieves a reduction of ~80%-90% on budgets and latency compared with the direct ICL methods. We point out that it is much more efficient due to three main reasons: (1) It calls LLMs API for only a small portion of samples. (2) It reranks only a small set of labels.</p><p>(3) It requires less demos. 13 An exception occurs at FewNERD dataset, on which the performance of reranked samples seems to degrade slightly. We dive deep into the result and observe that LLM-rerankers correct (eliminate, in other word) many false-positive samples. Therefore the overall performance actually improves even though the metric values on reranked samples decrease. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have conducted an extensive empirical study comparing LLMs and SLMs on eight datasets across three tasks. We show that LLMs are still not good few-shot information extractor due to the task format, limited sample capacity and oversized schema. Meanwhile, compared to SLMs, LLMs incur significant time and monetary costs. We discover, however, LLMs could largely help SLMs to rerank and correct hard samples. Building on these findings, we propose an adaptive "filter-thenrerank" paradigm that leverages the strengths of both LLMs and SLMs while avoiding their limitations. This approach consistently yields promising results, with 2.1% F1-gain on average on several few-shot IE tasks, while minimizing the cost of latency and budgets caused by calling LLM APIs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Datasets</head><p>A.1 Full Datasets</p><p>We construct few-shot IE datasets and conduct an empirical study on eight datasets spanning three tasks, with varying schema complexities. We show their statistics in Table <ref type="table" target="#tab_9">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Details of Few-shot IE Datasets</head><p>Sampling Algorithm for Train/Valid Datasets.</p><p>We downsample sentences from original training dataset to construct few-shot training and valid datasets. We adopt K-shot sampling strategy that each label has (at least) K samples. For RE task, each sentence has exactly one relation and we simply select K sentences for each label. For NER and ED tasks, each sentences is possible to contain more than one entities/events. Since our sampling is at sentence-level, the algorithm of accurate sampling , i.e., finding exactly K samples for each label, is NP-complete<ref type="foot" target="#foot_6">14</ref> and unlikely to find a practical solution. Therefore we follow Yang and Katiyar (2020); <ref type="bibr" target="#b17">Ma et al. (2022)</ref> adopting a greedy sampling algorithm to select sentences for NER and ED tasks, as shown in Algorithm 1. Note that the actual sample number of each label can be larger than K under this sampling strategy. For all three tasks, we additionally sample negative sentences (without any defined labels) and make the ratio of positive sentences (with at least one label) and negative sentences as 1:1. The statistics of the curated datasets are listed in Table <ref type="table" target="#tab_10">6</ref>.</p><p>Based on the subsets constructed above, we optionally further split them into training and valid sets. For few-shot datasets with more than 300 sentences, we additionally split 10% sentences as the valid set and the remaining sentences as training set. Otherwise, we do not construct valid set and conduct 5-fold cross validation to avoid overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Models B.1 Implementations Details on SLMs</head><p>We introduce the implementation details of 4 methods based on Small Language Models (SLMs). Fine-tuning/FSLS. We implement these two methods by ourselves. We use RoBERTa-base and RoBERTa-large <ref type="bibr" target="#b13">(Liu et al., 2019)</ref>   <ref type="foot" target="#foot_7">15</ref> to save memory. We run each experiment on a single NVIDIA V100 GPU. We train each model with the AdamW <ref type="bibr" target="#b14">(Loshchilov and Hutter, 2019)</ref> optimizer with linear scheduler and 0.1 warm-up steps. We set the weight-decay coefficient as 1e-5 and maximum graidient norms as 1.0. We set the batch size as 64, the maximum input sequence length as 192, the training step as 500 and the learning rate as 5e-5. KnowPrompt We implement this method based on original source code<ref type="foot" target="#foot_8">16</ref> , and use RoBERTa-base and RoBERTa-large as our backbones. We set 10 maximum epochs for 50-and 100-shot datasets, and as 50 epochs for other datasets. We keep all other hyperparameters as default, and run each experiment on a single NVIDIA V100 GPU. UIE We implement this method based on original source code<ref type="foot" target="#foot_9">17</ref> , and use T5-base and T5-large (Raffel et al., 2020) as the backbones. We run each experiment on a single NVIDIA Quadro RTX8000 GPU. We set the batch size as 16 with 1000 training steps for base model, and the batch size as 4 with 4000 training steps for large model. We set the maximum input sequence length as 800 and the learning rate as 1e-4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Implementations Details on LLMs</head><p>We mainly use CODEX <ref type="bibr">(Chen et al., 2021)</ref> as backbones of our ICL approaches. We also use Instruct-GPT <ref type="bibr" target="#b18">(Ouyang et al., 2022)</ref> in pivot experiments (as shown in Appendix C) and our adaptive filterthen-rerank system. We set the maximum input length as 3600 for all tasks and models. The only exception occurs when we use CODEX to solve RE tasks: here we set the maximum input length as 7000. We unify the maximum output length as 96 for NER and ED tasks, and as 32 for RE task. We set the sampling temperature coefficient t = 0, i.e., greedy decoding. We would detail the special design for each variant below.</p><p>Vanilla ICL Our prompts are composed of three parts: (1) Instruction: a short piece of natural language description about the task. ( <ref type="formula">2</ref> DSC and Traction Control on all Speed3 models is also standard.</p><p>A renewed effort to build a children 's theme park emerged ??.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Read the following sentence: DSC and Traction</head><p>Control on all Speed3 models is also standard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Could you explain why DSC is a kind of product that does not?? Read the following sentence: DSC and Traction Control on all Speed3 models is also standard. Could you explain why Speed3 is a kind of car?</head><p>The mention of 'Speed3 models' indicates that this is a vehicle-related context?? for each samples, and insert them between the sentences and answers (see blue box in left part of the figure). If a sentence has no positive labels, however, we do not ask LLMs and keep the original format as the vanilla ICL approach. ICL w. Demonstration Selection (DS, <ref type="bibr" target="#b12">Liu et al. 2022;</ref><ref type="bibr" target="#b22">Su et al. 2022)</ref> The format of prompts is the same as that of vanilla ICL approach. The difference from vanilla ICL lies in that we retrieve similar samples as demo examples for each instance rather than sample randomly. We adopt the cosine similarity of two sentence embeddings to measure their similarity. We compute sentence embeddings by SimCSE-RoBERTa large <ref type="bibr" target="#b7">(Gao et al., 2021)</ref>. (4). ICL w. Self Ensemble (SE) We repeatedly test each sample 5 times with different demos and count the results. We select the winners with more than 1 votes as our final results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Yes</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>No</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>No Rationale</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Pivot Experiments</head><p>LLMs require enormous financial and time cost during inference. Therefore we conduct several pivot experiments to prune some experimental settings with (1) potential unaffordable cost and (2) significant unsatisfactory performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 CODEX v.s. InstructGPT</head><p>We tend to use CODEX rather than InstructGPT as much as possible in our empirical study since CODEX is now free access to the public. Therefore we choose one representative setting from each dataset and test the performance difference between CODEX and InstructGPT. We show their results in Table <ref type="table" target="#tab_13">8</ref> and observe that there is no significant difference between these two LLMs. Based on this finding, we determine to only use CODEX for empirical study in Section 3.4. We also find out, however, InstructGPT achieves much better results than CODEX in our adaptive filter-then-rerank system. Therefor we use Instruct-GPT in Section 4 and Section 5. Including this pivot experiments, we pay about 1000 dollars to call InsturctGPT API for this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 ICL w. Auto-CoT</head><p>This section we explore whether ICL with Auto-CoT approach achieves competitive performance as we expected. Though CODEX achieves similar performance with InstructGPT on IE tasks, we do observe that InstructGPT is able to generate more fluent and reasonable explanations. Therefore we generate rationales using InstructGPT with tem- perature t = 0.7. We select several representative settings and compare the performance with and without Auto-CoT as shown in Table <ref type="table" target="#tab_12">7</ref>.</p><p>We are frustrated to find Auto-CoT degrades the performance with a large margin. We speculate this degration could be attributed to 3 main reasons. (1) The rationale increase the length of each sample and thus decrease the overall example number in demos. (2) There exists an obvious discrepancy between sentences with and without positive labels. As shown in Figure <ref type="figure" target="#fig_5">6</ref>, the rationales are only provided for sentences with positive labels because it is hard to explain why a sentence dose not contain any label. (3) Some auto-generated rationales are low-quality, especially for RE tasks. We would explore better strategy to exploit auto-genertaed rationales in the future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Random Sampling for LLM Outputs</head><p>Previous work 18 tells us that it is better to set the sampling temperature t = 0 for tasks with structured outputs, including IE tasks. We validate this conclusion in Table <ref type="table">9</ref>, from which we could see the generated quality when t = 0 is much higher than the quality when t = 0. Therefore we set t = 0 in all main experiments, and do not take self-consistency <ref type="bibr" target="#b26">(Wang et al., 2023)</ref> into account. Instead we adopt self-ensemble since it does not require the generation randomness.</p><p>Table <ref type="table">9</ref>: The F1-score difference between with and without non-zero t value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>10-shot train set</head><p>FewNERD TACREV ACE05 t = 0 48.5(1.9) 53.7(2.3) 42.9(2.2) + self-ensemble 53.5(1.3) 58.6(1.5) 46.3(0.8) t = 0.7 40.9(2.3) 39.9(1.2) 35.6(1.0) + self-consistency 52.1(0.9) 53.4(1.3) 45.6(3.0)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 Do More Samples in Demos help?</head><p>We wonder whether longer demos bring more performance gains. Thus we gradually increase the 18 https://help.openai.com/en/articles/6654000-bestpractices-for-prompt-engineering-with-openai-api number of demos, and observe the changes of performance as the input length increases. We show the results in Figure <ref type="figure">7</ref> and observe that (1) The performance of RE task increase consistently. Thus RE task shows potential benefiting from more demos.</p><p>(2) The performance of NER and ED gradually become stable even degrade with the increase of demos. It frustratingly implies these two tasks have been bounded even before achieving the maximum input length of LLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Terms</head><p>We summarize all terms used in our work and their abbreviations in Table <ref type="table" target="#tab_14">10</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Case Study</head><p>Table <ref type="table" target="#tab_7">14</ref> shows some hard examples which benefits from our adaptive filter-then-rerank paradigm. We could see that external knowledge (e.g., Triptolemus is a figure in Greek mythology) and complex reasoning (e.g., The coach of a Finland's football team may not be the residence of Finland) from LLMs do help to correct the errors made by SLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Demonstration examples</head><p>We convert few-shot IE tasks to multiple-choice questions in our filter-then-rerank paradigm. We show 4 examples used in demonstrations for FewN-ERD dataset in Table <ref type="table" target="#tab_15">15</ref>, for TACREV dataset in Table <ref type="table" target="#tab_16">16</ref>, and for ACE05 datasets in Table <ref type="table" target="#tab_17">17</ref>.</p><p>Table <ref type="table" target="#tab_7">14</ref>: Examples of the samples corrected by LLM reranking. We sample 3 examples from NER, RE and ED tasks, respectively. Sentences: The sentences in which samples locate. We color the samples (entities or trigger words) to be identified. before: The prediction before LLM reranking. Based on SLM-based methods. after:</p><p>The reranked prediction using LLMs. Rationales: Auto-generated rationales by LLMs. Could be viewed as the explanation of the reranked results.</p><p>Sentences (entity/event) Before After Rationales</p><p>According to it, King Eleusis and Cothonea (Cyntinia), parents of Triptolemus, are visited by Demeter, who rears their son, feeding him divine milk by day and placing him into the fire at night, which makes Triptolemus grow faster than mortal children normally do.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>person-other other-god</head><p>According to the context, Triptolemus is a figure in Greek mythology, the son of King Eleusis and Cothonea (Cyntinia). He was a demigod who was sent by Demeter to teach mankind the art of agriculture. So Triptolemus is a god in some legend/religious story.</p><p>Miettinen coaches Helsinki's PK-35, which shares the lead in Finland's top women's football league, and becomes the third Sky Blue coach in two months.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>countries of residence</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>None</head><p>The sentence states that 'Miettinen coaches Helsinki's PK-35, which shares the lead in Finland's top women's football league.' This implies that Miettinen is a coach in Finland's top women's football league, but does not suggest any other specific relationship between Miettinen and Finland. So Miettinen has no known relations to Finland.</p><p>We have fought every institution, every law firm ... it 's cost us a fortune but now we 're going on a massive expansion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflict.Attack</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>None</head><p>In the given sentence, the word fought is used to describe the action of the speaker fighting against various institutions and law firms. This does not involve any physical violence or court proceedings, so the word fought does not trigger any known event.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Template</head><p>In our filter-then-rerank paradigm, we utilize templates converting candidate labels to question options. We list the template for FewNERD dataset in Table <ref type="table" target="#tab_18">18</ref>, for TACREV dataset in Table <ref type="table" target="#tab_19">19</ref>, and for ACE05 datasets in Table <ref type="table" target="#tab_20">20</ref>.      </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Movement.Transport</head><p>The word {evt} triggers a TRANSPORT event: an ARTIFACT (WEAPON or VEHICLE) or a PERSON is moved from one PLACE (GEOPOLITICAL ENTITY, FACILITY, LOCATION) to another.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Personnel.Elect</head><p>The word {evt} triggers an ELECT event which implies an election.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Personnel.Start-Position</head><p>The word {evt} triggers a START-POSITION event: a PERSON elected or appointed begins working for (or changes offices within) an ORGANIZATION or GOVERNMENT.</p><p>The word {evt} triggers a NOMINATE event: a PERSON is proposed for a position through official channels.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Overall results of 4 supervised SLM-based methods (dashed lines) and 3 LLM-based ICL methods (solid lines) on eight datasets. FT: Fine-tuning. ICL: In-context Learning. DS: Demonstration Selection. SE: Self-ensemble. The results are averaged over 5 repeated experiments. See detailed values in Tables 11, 12 and 13.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Instruction:</head><label></label><figDesc>Read the sentence and determine the relation between &lt;h ent&gt; and &lt;t ent&gt;. Sentence: &lt;Sentence&gt; (a) T(&lt;Label 1&gt;, &lt;h ent&gt;, &lt;t ent&gt;) (b) T(&lt;Label 2&gt;, &lt;h ent&gt;, &lt;t ent&gt;) (c) T(&lt;Label 3&gt;, &lt;h ent&gt;, &lt;t ent&gt;) [Optional] Analysis: &lt;Rationale&gt; Answer: &lt;Correct choice&gt;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: Relationship between confidence score and F1-score of samples, before (colored in purple) and after (colored in red) LLM reranking. The x-axis shows 9 sample groups divided by their confidence scores. The left y-axis corresponds to the F1-score curves depicting the performance of samples within each group. The right y-axis (log scale) corresponds to the bars indicating the sample number in each group. Each subfigure is titled as[X]-[Y], where [X] represents the dataset and [Y] represents the filter (SLM-based) methods. Among various datasets and the filter methods, we observe the similar trend between F1-scores before and after reranking.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure4: The overall architecture of our adaptive filter-then-rerank paradigm. We color easy samples in orange and hard samples in pink. For easy samples, the final predictions are exactly from the SLM-based methods. For hard samples, the top-N predictions from SLMs are fed into LLMs as the format of multiple-choice questions (pink box). The question is paired with demos (green box, we only provide 1 demo for convenience of visualization). LLMs rerank these N candidates and generate the final prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure5: The financial and time cost over 500 sentences among three kinds of methods. Note that we do not take the financial cost of SLMs into account since they could run locally, and the financial cost of LLMs are estimated.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: The diagram of ICL approach with Auto-CoT.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Prompts used in Vanilla ICL approach. We box out the instruction in green and demonstrations in blue. Actually the instruction lists all labels and demos usually contain tens of examples. Here we show only three labels and two examples for convenience of visualization. The outputs generated by LLMs are colored in red.</figDesc><table><row><cell></cell><cell></cell><cell>Instruction</cell></row><row><cell></cell><cell cols="2">Demonstrations</cell></row><row><cell></cell><cell>Sentence: Fuller, 37, has been here before.</cell></row><row><cell></cell><cell>Triple:(Subject: Fuller, Object: 37, Relation: per:age)</cell><cell>Output</cell></row><row><cell>Named Entity Recognition</cell><cell>Relation Extraction</cell></row><row><cell>Figure 1:</cell><cell></cell></row></table><note><p><p><p><p><p><p><p><p>conducted on different experimental settings. For example,</p><ref type="bibr" target="#b26">Wang et al. (2022)</ref> </p>concentrated on the Event Argument Extraction (EAE) task, while</p><ref type="bibr" target="#b19">Qin et al. (2023)</ref> </p>focused solely on the NER task. Although Jimenez Gutierrez et al. (</p>2022</p>) studied both NER and RE tasks, they chose datasets with simple schemas (no more than 2 entity types and 5 relation types). These inconsistencies in experimental setups have led to inconclusive findings on whether LLMs outperform SLMs. To address the issue, our work concurrently tackles multiple tasks and conducts experiments on widely-used datasets with varying schema complexities ranging from 4 to 168 label types. Secondly, previous work solely relied on LLMs, while we have developed an adaptive filter-then-rerank approach based on comprehensive empirical research, which combines the strengths of both SLMs and LLMs.</p>3 Large LMs v.s. Small LMs We wonder whether LLMs can outperform supervised SLMs in few-shot IE scenarios purely through ICL. To this end, we evaluate SLMs and LLMs on eight commonly used datasets spanning three representative IE tasks. (1) Named Entity Recognition (NER): CONLL'03</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Training and Validation Set We adopt K-shot sampling strategy to construct few-shot datasets,</figDesc><table /><note><p><p><p><p><p>i.e., sampling K samples for each label type. We set 4 different</p>K-values (1, 5, 10, 20)  </p>for</p>NER and  ED tasks, 5, 10, 20,  50, 100)  </p>for RE tasks. For each constructed dataset with more than 300 sentences, we split 10% sentences as validation set and the remaining sentences as training set. See Appendix A.2 for details and the statistics of the sampled few-shot IE datasets. Test Set To reduce the inference time and cost of LLMs, we randomly sample 250 sentences from the original test sets for NER and ED tasks, and 500 sentences for RE task, as our test benchmark. Evaluation Metric We adopt micro-F1 score as evaluation metric. The reported value of each setting is the averaged score w.r.t 5 sampled train/validation sets to reduce random fluctuation.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>The inference seconds over 500 sentences. B: RoBERTa/T5-base. L: RoBERTa/T5-large. C: code-davinci-002. T: text-davinci-003.</figDesc><table><row><cell></cell><cell>Task</cell><cell cols="3">FT (Roberta) UIE (T5) ICL (GPT-3) B L B L C T</cell></row><row><cell cols="3">CONLL03 0.6 OntoNotes 1.6 NER FewNERD 1.1</cell><cell>1.6 4.1 2.8</cell><cell>3.0 10.3 128.8 113.8 9.3 22.9 134.1 114.6 14.6 39.4 179.4 166.5</cell></row><row><cell>RE</cell><cell cols="2">TACRED 0.4 TACREV 0.4</cell><cell>1.4 1.4</cell><cell>14.1 43.8 164.4 132.4 14.5 45.6 151.6 127.1</cell></row><row><cell>ED</cell><cell cols="2">ACE05 0.8 ERE 0.9 MAVEN 2.6</cell><cell>2.4 1.9 6.6</cell><cell>3.0 8.9 135.2 112.1 5.2 15.8 136.6 102.2 31.5 62.5 171.7 156.2</cell></row><row><cell cols="4">3.4 Comparison Result</cell></row><row><cell cols="5">We evaluate eight approaches, four SLM-based su-</cell></row><row><cell cols="5">pervised methods and four LLM-based ICL meth-</cell></row><row><cell cols="5">ods introduced above, on eight datasets across three</cell></row><row><cell cols="5">IE tasks. We first conduct pivot experiments and</cell></row><row><cell cols="5">observe ICL with Auto-CoT delivers much poorer</cell></row><row><cell cols="5">results than we expected (see results and analysis</cell></row><row><cell cols="5">in Appendix C.2). Therefore we do not include</cell></row><row><cell cols="5">ICL with Auto-CoT in main experiments.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Overall results of LLM-based ICL methods, SLM-based supervised methods, and our proposed filterthen-rerank (S+L) methods. The best results are in bold face and the second best are underlined. All results except InstructGPT are averaged over 5 repeated experiments, and sample standard deviations are in the round bracket (the same below). The standard deviations are derived from different sampling few-shot datasets instead of random seeds. Thus high standard deviation values do not mean that no significant difference among these methods. (2.1) 62.7 (0.8) 63.3 (0.6) 66.8 (2.6) 72.3 (1.4) 75.4 (1.5) 57.8 (4.6) 65.3 (1.7) 67.3 (2.2) + Ensemble + LLM Rerank 61.3 (1.9) 63.2 (0.9) 63.7 (1.8) 68.9 (1.3) 74.8 (1.3) 76.8 (1.2) 59.5 (3.7) 65.3 (1.9) 67.8 (2.1)</figDesc><table><row><cell></cell><cell>Method</cell><cell>FewNERD</cell><cell>TACREV</cell><cell>ACE</cell></row><row><cell></cell><cell></cell><cell cols="3">5-shot 10-shot 20-shot 20-shot 50-shot 100-shot 5-shot 10-shot 20-shot</cell></row><row><cell>LLM</cell><cell>CODEX InstructGPT</cell><cell cols="3">53.8 (0.5) 54.0 (1.4) 55.9 (0.5) 59.1 (1.4) 60.3 (2.4) 62.4 (2.6) 47.1 (1.2) 47.7 (2.8) 47.9 (0.5) 53.6 (-) 54.6 (-) 57.2 (-) 60.1 (-) 58.3 (-) 62.7 (-) 52.9 (-) 52.1 (-) 49.3 (-)</cell></row><row><cell>SLM</cell><cell>FSLS / KnowPrompt + Ensemble</cell><cell cols="3">59.4 (1.5) 61.4 (0.8) 60.7 (1.9) 62.4 (3.8) 68.5 (1.6) 72.6 (1.5) 55.1 (4.6) 63.9 (0.8) 65.8 (2.0) 59.6 (1.7) 61.8 (1.2) 62.6 (1.0) 64.9 (1.5) 71.9 (2.2) 74.1 (1.7) 56.9 (4.7) 64.2 (2.1) 66.5 (1.7)</cell></row><row><cell>S+L</cell><cell>+ LLM Rerank</cell><cell>60.6</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Ablation study on three datasets. 20-shot settings for FewNERD and ACE05. 100-shot setting for TACREV. The filter is two ensembled SLMs.</figDesc><table><row><cell>Manual</cell><cell>Demo</cell><cell>Cand</cell></row><row><cell>CoT</cell><cell>Selection</cell><cell cols="2">Filter FewNERD TACREV ACE05</cell></row><row><cell></cell><cell></cell><cell></cell><cell>63.7 (1.8) 76.8 (1.2) 67.8 (2.1)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>63.4 (1.2) 74.9 (1.7) 66.7 (2.2)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>63.1 (1.3) 74.6 (2.7) 66.8 (2.5)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>62.7 (1.3) 73.9 (1.1) 66.9 (2.4)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>62.7 (0.9) 72.8 (3.2) 66.2 (1.7)</cell></row><row><cell cols="3">FSLS/KnowPrompt</cell><cell>62.6 (1.0) 74.1 (1.7) 66.5 (1.7)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>The F1-score differences of all samples (the left three columns), reranked samples (the middle three columns), and the ratio of reranked samples (the last column) over three datasets. 20-shot settings for FewN-ERD and ACE05. 100-shot setting for TACREV. The filter is two ensembled SLMs.</figDesc><table><row><cell></cell><cell>Overall</cell><cell>Reranked</cell><cell>Reranked</cell></row><row><cell></cell><cell>before after</cell><cell>before after</cell><cell>Ratio</cell></row><row><cell cols="3">FewNERD 62.6 63.7 1.1 31.4 28.3 -3.1</cell><cell>3.3%</cell></row><row><cell cols="3">TACREV 74.1 76.8 2.7 33.8 43.4 9.6</cell><cell>13.2%</cell></row><row><cell>ACE05</cell><cell cols="2">66.5 67.8 1.3 35.6 55.7 20.1</cell><cell>0.5%</cell></row><row><cell cols="4">confidence score). Therefore only a tiny minority</cell></row><row><cell cols="4">of samples are fed to LLMs for reranking, as shown</cell></row><row><cell cols="4">in Table 4 (the last column). However, we figure</cell></row><row><cell cols="4">out from Table 4 that the reranking brings impres-</cell></row><row><cell cols="4">sive improvement on them, see ~10% for TACREV</cell></row><row><cell cols="4">and ~20% for ACE05 dataset. Such upheaval on</cell></row><row><cell cols="4">small amount of samples leads to an overall signifi-</cell></row><row><cell cols="2">cant improvement. 13</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Statistics of three full ED datasets.</figDesc><table><row><cell></cell><cell></cell><cell cols="3">Named Entity Recognition</cell><cell cols="2">Relation Extraction</cell><cell cols="2">Event Detection</cell><cell></cell></row><row><cell>Dataset</cell><cell></cell><cell cols="7">CONLL OntoNotes FewNERD TACREV TACRED ACE05 MAVEN</cell><cell>ERE</cell></row><row><cell cols="2">#Label Type</cell><cell>4</cell><cell>18</cell><cell>66</cell><cell>41</cell><cell>41</cell><cell>33</cell><cell>168</cell><cell>38</cell></row><row><cell>#Sents</cell><cell>Train Test</cell><cell>14,041 3,453</cell><cell>49,706 10,348</cell><cell>131,965 37,648</cell><cell>68,124 15,509</cell><cell>68,124 15,509</cell><cell>14,024 728</cell><cell cols="2">32,360 14,736 8,035 1,163</cell></row><row><cell>#Mentions</cell><cell>Train Test</cell><cell>23,499 5,648</cell><cell>128,738 12,586</cell><cell>340,247 96,902</cell><cell>13,012 3,123</cell><cell>13,012 3,123</cell><cell>5,349 424</cell><cell>77,993 18,904</cell><cell>6,208 551</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>The statistics of few-shot training sets. We set different random seeds and generate 5 training sets for each setting. We report their average statistics.</figDesc><table><row><cell cols="6">Dataset Settings # Labels # Sent # Sample # Avg shot</cell></row><row><cell></cell><cell>1-shot</cell><cell></cell><cell>4.8</cell><cell>5.8</cell><cell>1.4</cell></row><row><cell>CONLL'03</cell><cell>5-shot 10-shot</cell><cell>4</cell><cell>16.2 29.2</cell><cell>21.8 42.6</cell><cell>5.5 10.7</cell></row><row><cell></cell><cell>20-shot</cell><cell></cell><cell>65.6</cell><cell>82.0</cell><cell>20.5</cell></row><row><cell></cell><cell>1-shot</cell><cell></cell><cell>20.0</cell><cell>33.4</cell><cell>1.9</cell></row><row><cell>OntoNotes</cell><cell>5-shot 10-shot</cell><cell>18</cell><cell>84.8 158.6</cell><cell>148.0 281.0</cell><cell>8.2 15.6</cell></row><row><cell></cell><cell>20-shot</cell><cell></cell><cell>332.8</cell><cell>547.2</cell><cell>30.4</cell></row><row><cell></cell><cell>1-shot</cell><cell></cell><cell>89.8</cell><cell>147.0</cell><cell>2.2</cell></row><row><cell>FewNERD</cell><cell>5-shot 10-shot</cell><cell>66</cell><cell>286.2 538.0</cell><cell>494.8 962.0</cell><cell>7.5 14.6</cell></row><row><cell></cell><cell>20-shot</cell><cell></cell><cell>1027.2</cell><cell>1851.4</cell><cell>28.1</cell></row><row><cell></cell><cell>1-shot</cell><cell></cell><cell>81.6</cell><cell>41.0</cell><cell>1.0</cell></row><row><cell></cell><cell>5-shot</cell><cell></cell><cell>387.6</cell><cell>205.0</cell><cell>5.0</cell></row><row><cell>TACREV</cell><cell>10-shot 20-shot</cell><cell>41</cell><cell>741.2 1367.2</cell><cell>406.0 806.0</cell><cell>9.9 19.7</cell></row><row><cell></cell><cell>50-shot</cell><cell></cell><cell>2872.0</cell><cell>1944.0</cell><cell>47.4</cell></row><row><cell></cell><cell>100-shot</cell><cell></cell><cell>4561.0</cell><cell>3520.0</cell><cell>85.9</cell></row><row><cell></cell><cell>1-shot</cell><cell></cell><cell>81.6</cell><cell>41.0</cell><cell>1.0</cell></row><row><cell></cell><cell>5-shot</cell><cell></cell><cell>387.6</cell><cell>205.0</cell><cell>5.0</cell></row><row><cell>TACRED</cell><cell>10-shot 20-shot</cell><cell>41</cell><cell>741.2 1367.2</cell><cell>406.0 806.0</cell><cell>9.9 19.7</cell></row><row><cell></cell><cell>50-shot</cell><cell></cell><cell>2871.2</cell><cell>1944.0</cell><cell>47.4</cell></row><row><cell></cell><cell>100-shot</cell><cell></cell><cell>4575.2</cell><cell>3520.0</cell><cell>85.9</cell></row><row><cell></cell><cell>1-shot</cell><cell></cell><cell>47.4</cell><cell>41.0</cell><cell>1.2</cell></row><row><cell>ACE05</cell><cell>5-shot 10-shot</cell><cell>33</cell><cell>192.8 334.6</cell><cell>165.0 319.4</cell><cell>5.0 9.7</cell></row><row><cell></cell><cell>20-shot</cell><cell></cell><cell>579.4</cell><cell>598.2</cell><cell>18.1</cell></row><row><cell></cell><cell>1-shot</cell><cell></cell><cell>157.6</cell><cell>298.0</cell><cell>1.8</cell></row><row><cell>MAVEN</cell><cell>5-shot 10-shot</cell><cell>168</cell><cell>540.4 891.2</cell><cell>1262.2 2413.8</cell><cell>7.5 14.4</cell></row><row><cell></cell><cell>20-shot</cell><cell></cell><cell>1286.4</cell><cell>4611.4</cell><cell>27.4</cell></row><row><cell></cell><cell>1-shot</cell><cell></cell><cell>48.4</cell><cell>54.6</cell><cell>1.4</cell></row><row><cell>ERE</cell><cell>5-shot 10-shot</cell><cell>38</cell><cell>175.0 304.8</cell><cell>219.2 432.4</cell><cell>5.8 11.4</cell></row><row><cell></cell><cell>20-shot</cell><cell></cell><cell>521.6</cell><cell>806.6</cell><cell>21.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>CoT Identify the entities expressed by each sentence, then locate each entity to words in sentence. The possible entity types are location-GPE, organization-company, person-politician??</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>Has entities ?</cell></row><row><cell></cell><cell>Instruct</cell></row><row><cell cols="2">Sentence: DSC and Traction Control on all Speed3</cell></row><row><cell>models is also standard.</cell><cell></cell></row><row><cell cols="2">Rationale 1: The mention of 'Speed3 models'??</cell></row><row><cell cols="2">Entity 1: (type: product-car, identified_entity: Speed3)</cell></row><row><cell cols="2">Rationale 2: The mention of 'DSC'??</cell></row><row><cell cols="2">Entity 2: (type: product-other, identified_entity: DSC)</cell></row><row><cell cols="2">Sentence: A renewed effort to build a children 's theme</cell></row><row><cell cols="2">park emerged during this period as well .</cell></row><row><cell>Entities: No defined entities.</cell><cell>Demonstrations</cell></row><row><cell cols="2">Sentence: Princess Tomato makes an appearance in</cell></row><row><cell cols="2">Super Bomberman R as a playable DLC character named</cell></row><row><cell>Princess Tomato Bomber.</cell><cell></cell></row><row><cell cols="2">Rationale 1: The mention of 'Super Bomberman R' as</cell></row><row><cell cols="2">well as 'playable DLC character' indicates that it is an</cell></row><row><cell>electronic game product.</cell><cell></cell></row><row><cell cols="2">Answer 1: (type: product-game, identified_entity: Super</cell></row><row><cell>Bomberman R)</cell><cell>Output</cell></row><row><cell></cell><cell>)</cell></row><row><cell></cell><cell>Demonstrations: some (input, output) pairs as</cell></row><row><cell></cell><cell>train examples for LLMs. (3) Question: the in-</cell></row><row><cell></cell><cell>put as test example. Most time the training sample</cell></row><row><cell></cell><cell>number exceeds the limitation of examples in de-</cell></row><row><cell></cell><cell>mos. Under this case, we would randomly sample</cell></row><row><cell></cell><cell>a subset as demo examples for each test instance.</cell></row><row><cell></cell><cell>ICL w. Automatic Chain-of-thought (Auto-</cell></row><row><cell></cell><cell>CoT, Zhang et al. 2023) If a sentence has posi-</cell></row><row><cell></cell><cell>tive labels, we would query LLMs According to</cell></row><row><cell></cell><cell>[sentence], Why [span] is a [label]. For exam-</cell></row><row><cell></cell><cell>ple, given the sentence "DSC and Traction Control</cell></row><row><cell></cell><cell>on all Speed3 models is also standard." in which</cell></row><row><cell></cell><cell>Speed3 is a car-product entity and DSC is an other-</cell></row><row><cell></cell><cell>product entity, it is to auto-generate rationales for</cell></row><row><cell></cell><cell>these two entities. By asking "Could you explain</cell></row><row><cell></cell><cell>why Speed3 is a kind of car", the LLMs would</cell></row></table><note><p><p><p>answer "the term Speed3 refers to a specific car model produced by Mazda. Mazda is an automobile manufacturer, and as such, Speed3 is likely a car product from their lineup" . As shown in Figure</p>6</p>, we collect these auto-generated rationales Auto-</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 7 :</head><label>7</label><figDesc>The F1-score difference between with and without Auto-CoT. We generate rationales by Instruct-GPT, then adopt ICL w. Auto-CoT approach and use CODEX as our backbone for inference.</figDesc><table><row><cell cols="2">10-shot train set FewNERD TACREV ACE05</cell></row><row><cell>wo. Auto-CoT</cell><cell>54.0(1.4) 57.3(1.8) 47.7(2.8)</cell></row><row><cell>w. Auto-CoT</cell><cell>36.6(1.7) 22.0(1.2) 43.1(3.4)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 8 :</head><label>8</label><figDesc>The F1-score difference between CODEX and InstructGPT. We adopt ICL w. DS approach for two LLMs.</figDesc><table><row><cell></cell><cell></cell><cell>NER (20-shot)</cell><cell></cell><cell cols="2">RE (20-shot)</cell><cell></cell><cell>ED (20-shot)</cell><cell></cell></row><row><cell></cell><cell cols="8">CONLL OntoNotes FewNERD TACREV TACRED ACE05 MAVEN ERE</cell></row><row><cell>InstructGPT</cell><cell>77.2</cell><cell>47.7</cell><cell>57.2</cell><cell>60.1</cell><cell>52.1</cell><cell>49.3</cell><cell>25.4</cell><cell>40.8</cell></row><row><cell>CODEX</cell><cell>81.1</cell><cell>55.6</cell><cell>55.9</cell><cell>59.1</cell><cell>53.6</cell><cell>47.9</cell><cell>22.8</cell><cell>39.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 10 :</head><label>10</label><figDesc>Term Table (with their abbreviations)</figDesc><table><row><cell>Abbreviation</cell><cell>Full Name</cell></row><row><cell>IE</cell><cell>Information Extraction</cell></row><row><cell>NER</cell><cell>Named Entity Recognition</cell></row><row><cell>RE</cell><cell>Relation Extraction</cell></row><row><cell>ED</cell><cell>Event Detection</cell></row><row><cell>LLMs</cell><cell>Large Language Models</cell></row><row><cell>SLMs</cell><cell>Small Pre-trained Langauge Models</cell></row><row><cell>ICL</cell><cell>In-context Learning</cell></row><row><cell>FT</cell><cell>Fine-tuning</cell></row><row><cell>Auto-CoT</cell><cell>Automatic Chain-of-thought</cell></row><row><cell>DS</cell><cell>Demonstration Selection</cell></row><row><cell>SE</cell><cell>Self-ensemble</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 15 :</head><label>15</label><figDesc>Demo examples used in FewNERD dataset. We color the entity in blue and the analysis in red. Read following sentences and identify what is the entity type of 392 quoted by &lt;t&gt;. Sentence: Powell v . Texas , &lt;t&gt; 392 &lt;t&gt; U.S. 514 ( 1968 ) , was a United States Supreme Court case that ruled that a Texas statute criminalizing public intoxication did not violate the Eighth Amendment protection against cruel and unusual punishment. In the context you provided, 392 refers to the volume number in the United States Reports where the Supreme Court's decision in Powell v. Texas can be found. However, 392 itself does not refer to a legal document. So 392 do/does not belong to any known entities. Read following sentences and identify what is the entity type of The New Yorker quoted by &lt;t&gt;. Sentence: In 2004 Gourevitch was assigned to cover the 2004 U.S. presidential election for " &lt;t&gt; The New Yorker &lt;t&gt; ". (a) The New Yorker does not belong to any known entities. (b) The New Yorker is a broadcast program. (c) The New Yorker is a kind of written art. (d) The New Yorker is a media/newspaper organization. Analysis: The New Yorker is a well-known American magazine that has been published since 1925, and is primarily known for its long-form journalism, commentary, and satire. It has a reputation for publishing high-quality writing on a wide variety of topics, including politics, culture, and the arts. So The New Yorker is a media/newspaper organization. According to the context, St. is an abbreviation of Saint, used in the name of Mount St. Helens, which is an active volcano in the state of Washington. However, St. itself does not refer to anything. So St. do/does not belong to any known entities. Read following sentence and identify what is the entity type of Ridzuan quoted by &lt;t&gt;. Sentence: &lt;t&gt; Ridzuan &lt;t&gt; was promoted to Harimau Muda A for 2014 season . (a) Ridzuan does not belong to any known entities. (b) Ridzuan is a person, but not affiliated with following professions: actor, artist, author, director, politician, scholar, soldier. (c) Ridzuan is an athlete. Analysis: The mention of 'Harimau Muda A' indicates that it is a sports-related context, and 'promoted' implies a progression or advancement within the sports team. So Ridzuan is an athlete.</figDesc><table><row><cell>(a) 392 is a legal document, a term or a convention in legal sense.</cell></row><row><cell>(b) 392 does not belong to any known entities.</cell></row><row><cell>(c) 392 refers to a protest, uprising or revolution event</cell></row><row><cell>(d) 392 refers to a government or governmental agency</cell></row><row><cell>Analysis: Answer: (b)</cell></row><row><cell>Instruct: Answer: (d)</cell></row><row><cell>Instruct: Read following sentence and identify what is the entity type of St. quoted by &lt;t&gt;.</cell></row><row><cell>Sentence: The May 1980 eruption of Mount &lt;t&gt; St. &lt;t&gt; Helens in the state of Washington seriously affected both 47th Air</cell></row><row><cell>Division and 92d Bombardment Wing operations at Fairchild AFB , resulting in dispersal of Fairchild 's B-52 and KC-135</cell></row><row><cell>aircraft to various bases while around-the-clock shifts removed the volcanic ash from facilities within the base perimeter. "</cell></row><row><cell>(a) St. does not belong to any known entities.</cell></row><row><cell>(b) St. is a natural disaster event.</cell></row><row><cell>(c) St. is a geographic position about mountain.</cell></row><row><cell>Analysis: Answer: (a)</cell></row><row><cell>Instruct: Answer: (c)</cell></row></table><note><p>Instruct:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 16 :</head><label>16</label><figDesc>Demo examples used in TACREV dataset. We color the subject and object entities in blue and the analysis in red. Read the sentence and determine the relation between she and lawyer quoted by &lt;t&gt;.Sentence: The &lt;t&gt; lawyer &lt;t&gt; denied Italian news reports that she wept while addressing the court, but said Knox was upset as &lt;t&gt; she &lt;t&gt; recounted " the pressure, the aggressiveness of the police who called her a liar . " (a) she is the other family member of lawyer (b) she is a lawyer (c) she has no known relations to lawyer Analysis: In the sentence, the word 'she' refers to someone who was upset while recounting certain events in court. The word 'lawyer' refers to someone who denied a news report about that same person weeping in court. There is no information in the sentence to indicate that the two individuals are related in any way. So she has no known relations to lawyer. Read the sentence and determine the relation between MEF and Myanmar Equestrian Federation quoted by &lt;t&gt;. Sentence: YANGON , Dec. 27 -LRB-Xinhua -RRB--Myanmar will hold a horse race in Yangon to commemorate the country 's 63rd Anniversary Independence Day , the &lt;t&gt; Myanmar Equestrian Federation &lt;t&gt; -LRB-&lt;t&gt; MEF &lt;t&gt; -RRBconfirmed to Xinhua on Monday. (a) MEF is also known as Myanmar Equestrian Federation (b) MEF has political affiliation with Myanmar Equestrian Federation (c) MEF has no known relations to Myanmar Equestrian Federation Analysis: The symbols -LRB-and -RRB-in the sentence stand for left and right round brackets and are used to enclose the abbreviation 'MEF' to indicate that it is a replacement for the longer name 'Myanmar Equestrian Federation. So MEF is also known as Myanmar Equestrian Federation. Read the sentence and determine the relation between FAA and U.S. quoted by &lt;t&gt;.Sentence: On its Web site , the &lt;t&gt; U.S. &lt;t&gt; &lt;t&gt; FAA &lt;t&gt; says the Category 2 rating means the country lacks the laws or regulations that are needed for the certification and oversight of air carriers , according to minimum international standards. The sentence states that the FAA says the Category 2 rating means the country lacks the laws or regulations needed for the certification and oversight of air carriers, indicating that the FAA is responsible for overseeing aviation regulations in the country. Actually the FAA (Federal Aviation Administration) is a U.S. government agency responsible for regulating and overseeing civil aviation in the United States, and it has its headquarters in Washington, D.C.. So FAA has a headquarter in the country U.S..</figDesc><table><row><cell>Answer: (c)</cell></row><row><cell>Instruct: Answer: (a)</cell></row><row><cell>Instruct: Read the sentence and determine the relation between Douglas Flint and chairman quoted by &lt;t&gt;.</cell></row><row><cell>Sentence: At the same time , Chief Financial Officer &lt;t&gt; Douglas Flint &lt;t&gt; will become &lt;t&gt; chairman &lt;t&gt; , succeeding</cell></row><row><cell>Stephen Green who is leaving to take a government job.</cell></row><row><cell>(a) Douglas Flint has no known relations to chairman</cell></row><row><cell>(b) Douglas Flint is a chairman</cell></row><row><cell>(c) Douglas Flint is the employee of chairman</cell></row><row><cell>Analysis: The sentence states that Chief Financial Officer Douglas Flint Douglas Flint will succeed Stephen Green as a</cell></row><row><cell>chairman. So Douglas Flint is a chairman.</cell></row><row><cell>Answer: (b)</cell></row><row><cell>Instruct: (a) FAA is also known as U.S.</cell></row><row><cell>(b) FAA has no known relations to U.S.</cell></row><row><cell>(c) FAA has a headquarter in the country U.S.</cell></row><row><cell>Analysis: Answer: (c)</cell></row></table><note><p>Instruct:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 17 :</head><label>17</label><figDesc>Demo examples used in ACE05 dataset. We color the trigger word in blue and the analysis in red. Read following sentences and identify what event is triggered by the word loan quoted by &lt;t&gt;. Sentence: Separately , former WorldCom CEO Bernard Ebbers failed on April 29 to make a first repayment of 25 million dollars, plus interest, on a 400-million -dollar &lt;t&gt; loan &lt;t&gt; from MCI, the Journal said, citing SEC documents. (a) The word loan does not trigger any known event.(b) The word loan triggers a TRANSFER-MONEY event: giving, receiving, borrowing, or lending money when it is NOT in the context of purchasing something. (c) The word loan triggers a DECLARE-BANKRUPTCY event: an Entity officially requests legal protection from debt collection due to an extremely negative balance sheet. Analysis: In the given sentence, the word loan is used to describe the 400-million-dollar loan from MCI to former WorldCom CEO Bernard Ebbers, which he failed to repay on time. This situation clearly involves a transfer of money without the context of purchasing something, which falls under the TRANSFER-MONEY event. So the word loan triggers a TRANSFER-MONEY event: giving, receiving, borrowing, or lending money when it is NOT in the context of purchasing something. Read following sentences and identify what event is triggered by the words treated quoted by &lt;t&gt;. Sentence: When she 's in Germany , Lynch will be &lt;t&gt; treated &lt;t&gt; for bullet wounds and broken bones . (a) The word treated triggers an INJURE event: a PERSON gets/got injured whether it occurs accidentally, intentionally or even self-inflicted. Read following sentences and identify what event is triggered by the words buy quoted by &lt;t&gt;. Sentence: And I won't dwell on the irony of an Oracle employee being driven out of Oracle , starting his own company , and forcing Ellison to spend $ 10.3 billion to get his company -but not him -back ( though it does rather delightfully remind me of Coca -Cola basically giving away the bottling franchise and then spending billions to &lt;t&gt; buy &lt;t&gt; it back ) . (a) The word buy triggers a DECLARE-BANKRUPTCY event: an Entity officially requests legal protection from debt collection due to an extremely negative balance sheet. (b) The word buy triggers a TRANSFER-OWNERSHIP event: The buying, selling, loaning, borrowing, giving, or receiving of artifacts or organizations by an individual or organization. (c) The word buy does not trigger any known event. Analysis: In the given sentence, the word buy is used to describe the action of Oracle spending $10.3 billion to get a company back. This clearly involves the transfer of ownership of the company from one entity to another. So the word buy triggers a TRANSFER-OWNERSHIP event: The buying, selling, loaning, borrowing, giving, or receiving of artifacts or organizations by an individual or organization. Read following sentences and identify what event is triggered by the words set quoted by &lt;t&gt;. Sentence: British forces also began establishing the country's first postwar administration Tuesday, granting a local sheik power to &lt;t&gt; set &lt;t&gt; up an administrative committee representing the groups in the region. (a) The word set triggers a START-POSITION event: a PERSON elected or appointed begins working for (or changes offices within) an ORGANIZATION or GOVERNMENT. (b) The word set triggers a START-ORG event: a new ORGANIZATION is created. (c) The word set does not trigger any known event. Analysis: The phrase 'set up' specifically implies the creation or establishment of a new organization or entity, rather than simply the word 'set'. So the word set does not trigger any known event.</figDesc><table><row><cell>Answer: (b)</cell></row><row><cell>Instruct: Answer: (c)</cell></row></table><note><p>Instruct: Answer: (b) Instruct: (b) The word treated does not trigger any known event. (c) The word treated triggers a TRANSPORT event: an ARTIFACT (WEAPON or VEHICLE) or a PERSON is moved from one PLACE (GEOPOLITICAL ENTITY, FACILITY, LOCATION) to another. Analysis: The sentence suggests that Lynch has already been injured and will receive medical treatment in Germany for her injuries. The word 'treated' simply describes the medical care she will receive and does not indicate a new event or action taking place. So the word treated does not trigger any known event. Answer: (b) Instruct:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 18 :</head><label>18</label><figDesc>Templates for FewNERD dataset, where {ent} is the placeholder for event type. work of art, but not belong to the categories of music, film, written art, broadcast or painting.</figDesc><table><row><cell>Entity</cell><cell>Template</cell></row><row><cell>no-entity</cell><cell>{ent} do/does not belong to any known entities.</cell></row><row><cell>person-artist/author</cell><cell>{ent} is an artist or author.</cell></row><row><cell>person-actor</cell><cell>{ent} is an actor.</cell></row><row><cell>art-writtenart</cell><cell>{ent} is a kind of writtenart.</cell></row><row><cell>person-director</cell><cell>{ent} is a director.</cell></row><row><cell>person-other</cell><cell>{ent} is a person, but not affiliated with following professions: actor, artist, athlete,</cell></row><row><cell></cell><cell>author, director, politician, scholar, soldier.</cell></row><row><cell>organization-other</cell><cell>{ent} pertains to an organization that does not fall under the categories of company,</cell></row><row><cell></cell><cell>educational institution, government, media, political party, religion, sports league, sports</cell></row><row><cell></cell><cell>team, band or musical group.</cell></row><row><cell>organization-company</cell><cell>{ent} is a company</cell></row><row><cell>organization-sportsteam</cell><cell>{ent} is a sports team</cell></row><row><cell>organization-sportsleague</cell><cell>{ent} is a sports league</cell></row><row><cell>product-car</cell><cell>{ent} is a kind of car</cell></row><row><cell>event-protest</cell><cell>{ent} refers to a protest, uprising or revolution event</cell></row><row><cell>organization-</cell><cell>{ent} refers to a government or governmental agency</cell></row><row><cell>government/governmentagency</cell><cell></cell></row><row><cell>other-biologything</cell><cell>{ent} is a special term about biology / life science.</cell></row><row><cell>location-GPE</cell><cell>{ent} is a kind of geopolitical entity</cell></row><row><cell>location-other</cell><cell>{ent} is a geographic locaton that does not fall under the categories of geopolitical entity,</cell></row><row><cell></cell><cell>body of water, island, mountain, park, road, railway and transit.</cell></row><row><cell>person-athlete</cell><cell>{ent} is an athlete or coach.</cell></row><row><cell>art-broadcastprogram</cell><cell>{ent} is a broadcast program.</cell></row><row><cell>product-other</cell><cell>{ent} is a kind of product that does not fall under the categories of airplane, train, ship,</cell></row><row><cell></cell><cell>car, weapon, food, electronic game and software.</cell></row><row><cell>building-other</cell><cell>{ent} is a kind of building that does not fall under the categories of airport, hospital,</cell></row><row><cell></cell><cell>hotel, library, restaurant, sports facility and theater</cell></row><row><cell>product-weapon</cell><cell>{ent} is a kind of weapon.</cell></row><row><cell>building-airport</cell><cell>{ent} is an airport.</cell></row><row><cell>building-sportsfacility</cell><cell>{ent} is a sports facility building.</cell></row><row><cell>person-scholar</cell><cell>{ent} is a scholar.</cell></row><row><cell>art-music</cell><cell>{ent} is a music.</cell></row><row><cell>event-other</cell><cell>{ent} refers to some event except attack, election, natural disaster, protest, revolution</cell></row><row><cell></cell><cell>and sports</cell></row><row><cell>other-language</cell><cell>{ent} is a kind of human language.</cell></row><row><cell>other-chemicalthing</cell><cell>{ent} is some special term about chemical science.</cell></row><row><cell>art-film</cell><cell>{ent} is a film.</cell></row><row><cell>building-hospital</cell><cell>{ent} is a hospital.</cell></row><row><cell>other-law</cell><cell>{ent} is a legal document, a term or a convention in legal sense.</cell></row><row><cell>product-airplane</cell><cell>{ent} is kind of airplane product.</cell></row><row><cell>location-</cell><cell>{ent} is a geographic position about roadways, railways, highways or public transit</cell></row><row><cell>road/railway/highway/transit</cell><cell>systems.</cell></row><row><cell>person-soldier</cell><cell>{ent} is a soldier</cell></row><row><cell>location-mountain</cell><cell>{ent} is geographic position about mountain.</cell></row><row><cell>organization-education</cell><cell>{ent} is an educational institute/organization.</cell></row><row><cell>organization-media/newspaper</cell><cell>{ent} is a media/newspaper organization.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 19 :</head><label>19</label><figDesc>Templates for TACREV dataset, where {subj} and {obj} are the placeholders for subject and object entities. Copied from(Lu et al., 2022a)    </figDesc><table><row><cell>Relation</cell><cell>Template</cell></row><row><cell>no_relation</cell><cell>{subj} has no known relations to {obj}</cell></row><row><cell>per:stateorprovince_of_death</cell><cell>{subj} died in the state or province {obj}</cell></row><row><cell>per:title</cell><cell>{subj} is a {obj}</cell></row><row><cell>org:member_of</cell><cell>{subj} is the member of {obj}</cell></row><row><cell>per:other_family</cell><cell>{subj} is the other family member of {obj}</cell></row><row><cell>org:country_of_headquarters</cell><cell>{subj} has a headquarter in the country {obj}</cell></row><row><cell>org:parents</cell><cell>{subj} has the parent company {obj}</cell></row><row><cell>per:stateorprovince_of_birth</cell><cell>{subj} was born in the state or province {obj}</cell></row><row><cell>per:spouse</cell><cell>{subj} is the spouse of {obj}</cell></row><row><cell>per:origin</cell><cell>{subj} has the nationality {obj}</cell></row><row><cell>per:date_of_birth</cell><cell>{subj} has birthday on {obj}</cell></row><row><cell>per:schools_attended</cell><cell>{subj} studied in {obj}</cell></row><row><cell>org:members</cell><cell>{subj} has the member {obj}</cell></row><row><cell>org:founded</cell><cell>{subj} was founded in {obj}</cell></row><row><cell>per:stateorprovinces_of_residence</cell><cell>{subj} lives in the state or province {obj}</cell></row><row><cell>per:date_of_death</cell><cell>{subj} died in the date {obj}</cell></row><row><cell>org:shareholders</cell><cell>{subj} has shares hold in {obj}</cell></row><row><cell>org:website</cell><cell>{subj} has the website {obj}</cell></row><row><cell>org:subsidiaries</cell><cell>{subj} owns {obj}</cell></row><row><cell>per:charges</cell><cell>{subj} is convicted of {obj}</cell></row><row><cell>org:dissolved</cell><cell>{subj} dissolved in {obj}</cell></row><row><cell>org:stateorprovince_of_headquarters</cell><cell>{subj} has a headquarter in the state or province {obj}</cell></row><row><cell>per:country_of_birth</cell><cell>{subj} was born in the country {obj}</cell></row><row><cell>per:siblings</cell><cell>{subj} is the siblings of {obj}</cell></row><row><cell>org:top_members/employees</cell><cell>{subj} has the high level member {obj}</cell></row><row><cell>per:cause_of_death</cell><cell>{subj} died because of {obj}</cell></row><row><cell>per:alternate_names</cell><cell>{subj} has the alternate name {obj}</cell></row><row><cell>org:number_of_employees/members</cell><cell>{subj} has the number of employees {obj}</cell></row><row><cell>per:cities_of_residence</cell><cell>{subj} lives in the city {obj}</cell></row><row><cell>org:city_of_headquarters</cell><cell>{subj} has a headquarter in the city {obj}</cell></row><row><cell>per:children</cell><cell>{subj} is the parent of {obj}</cell></row><row><cell>per:employee_of</cell><cell>{subj} is the employee of {obj}</cell></row><row><cell>org:political/religious_affiliation</cell><cell>{subj} has political affiliation with {obj}</cell></row><row><cell>per:parents</cell><cell>{subj} has the parent {obj}</cell></row><row><cell>per:city_of_birth</cell><cell>{subj} was born in the city {obj}</cell></row><row><cell>per:age</cell><cell>{subj} has the age {obj}</cell></row><row><cell>per:countries_of_residence</cell><cell>{subj} lives in the country {obj}</cell></row><row><cell>org:alternate_names</cell><cell>{subj} is also known as {obj}</cell></row><row><cell>per:religion</cell><cell>{subj} has the religion {obj}</cell></row><row><cell>per:city_of_death</cell><cell>{subj} died in the city {obj}</cell></row><row><cell>per:country_of_death</cell><cell>{subj} died in the country {obj}</cell></row><row><cell>org:founded_by</cell><cell>{subj} was founded by {obj}</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 20 :</head><label>20</label><figDesc>Templates for ACE05 dataset, where {evt} is the placeholder for event type.</figDesc><table><row><cell>Event</cell><cell>Template</cell></row><row><cell>no-event</cell><cell>The word {evt} does not trigger any known event.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>All LLMs discussed in this paper are not fine-tuned, and results for LLMs are based on ICL through APIs.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>We define SLMs as relatively small pre-trained language models (PLMs) that can be easily fine-tuned locally, such as BERT, RoBERTa, BART and T5.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Label types denote entity/relations/event types in different tasks. We use them interchangeably there-in-after.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>Samples refer to (i) demonstrations in ICL of LLMs, or (ii) training samples for SLMs' fine-tuning.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_4"><p>e.g., when a word triggers event and when does not, which word to annotate if more than one words trigger the event within the single sentence, and so on.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_5"><p>Note that the proportions of unhit samples, i.e., the orange bar, are distorted Figure3due to the log scale.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_6"><p>The Subset Sum Problem, a classical NP-complete problem, can be reduced to this sampling problem.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_7"><p>https://pytorch.org/docs/stable/amp.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16" xml:id="foot_8"><p>https://github.com/zjunlp/KnowPrompt</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17" xml:id="foot_9"><p>https://github.com/universal-ie/UIE</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>The <rs type="projectName">reason you buy the Insurance and Today's Royal Caribbean International (RCL) Stock Price. Triple: (Subject: Royal Caribbean International</rs>, Object: RCL, Relation: org:alternate_names. Sentence: <rs type="person">"Peterson</rs> was the reason I became a jazz pianist", the 43-yearold singer-pianist told the <rs type="institution">Los Angeles Times</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_HkzN9kB">
					<orgName type="project" subtype="full">reason you buy the Insurance and Today&apos;s Royal Caribbean International (RCL) Stock Price. Triple: (Subject: Royal Caribbean International</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACE05 F1 score</head><p>Figure <ref type="figure">7</ref>: The F1-score difference with different demo number among three datasets: FewNERD for NER task, TACREV for RE task and ACE05 for ED task. We adopt ICL w. DS approach and use CODEX as the LLM in this experiment. The x-axis in each subfigure represents the number of demos (not the shot value K) during ICL. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflict.Attack</head><p>The word {evt} triggers an ATTACK event: a violent physical act causing harm or damage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Personnel.End-Position</head><p>The word {evt} triggers an END-POSITION event: a PERSON stops working for (or changes offices within) an ORGANIZATION or GOVERNMENT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contact.Meet</head><p>The word {evt} triggers a MEET event: two or more entities come together at a single location and interact with one another face-to-face.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Life.Marry</head><p>The word {evt} triggers a MARRY event: two people are married under the legal definition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contact.Phone-Write</head><p>The word {evt} triggers a PHONE-WRITE event: two or more people directly engage in discussion which does not take place 'face-to-face'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transaction.Transfer-Money</head><p>The word {evt} triggers a TRANSFER-MONEY event: giving, receiving, borrowing, or lending money when it is NOT in the context of purchasing something.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Justice.Sue</head><p>The word {evt} triggers a SUE event: a court proceeding has been initiated for the purposes of determining the liability of a PERSON, ORGANIZATION or GEOPOLITICAL ENTITY accused of committing a crime or neglecting a commitment</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflict.Demonstrate</head><p>The word {evt} triggers a DEMONSTRATE event: a large number of people come together in a public area to protest or demand some sort of official action. For eample: protests, sit-ins, strikes and riots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Business.End-Org</head><p>The word {evt} triggers an END-ORG event: an ORGANIZATION ceases to exist (in other words, goes out of business).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Life.Injure</head><p>The word {evt} triggers an INJURE event: a PERSON gets/got injured whether it occurs accidentally, intentionally or even self-inflicted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Life.Die</head><p>The word {evt} triggers a DIE event: a PERSON dies/died whether it occurs accidentally, intentionally or even self-inflicted.</p><p>Justice.Arrest-Jail The word {evt} triggers a ARREST-JAIL event: a PERSON is sent to prison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transaction.Transfer-Ownership</head><p>The word {evt} triggers a TRANSFER-OWNERSHIP event: The buying, selling, loaning, borrowing, giving, or receiving of artifacts or organizations by an individual or organization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Justice.Execute</head><p>The word {evt} triggers an EXECUTE event: a PERSON is/was executed Justice.Trial-Hearing The word {evt} triggers a TRIAL-HEARING event: a court proceeding has been initiated for the purposes of determining the guilt or innocence of a PERSON, ORGANIZATION or GEOPOLITICAL ENTITY accused of committing a crime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Justice.Sentence</head><p>The word {evt} triggers a SENTENCE event: the punishment for the DEFENDANT is issued</p><p>Life.Be-Born The word {evt} triggers a BE-BORN event: a PERSON is given birth to.</p><p>Justice.Charge-Indict The word {evt} triggers a CHARGE-INDICT event: a PERSON, ORGANIZATION or GEOPOLIT-ICAL ENTITY is accused of a crime</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Business.Start-Org</head><p>The word {evt} triggers a START-ORG event: a new ORGANIZATION is created.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Justice.Convict</head><p>The word {evt} trigges a CONVICT event: a PERSON, ORGANIZATION or GEOPOLITICAL ENTITY is convicted whenever it has been found guilty of a CRIME.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Business.Declare-Bankruptcy</head><p>The word {evt} triggers a DECLARE-BANKRUPTCY event: an Entity officially requests legal protection from debt collection due to an extremely negative balance sheet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Justice.Release-Parole</head><p>The word {evt} triggers a RELEASE-PAROLE event.</p><p>Justice.Fine</p><p>The word {evt} triggers a FINE event: a GEOPOLITICAL ENTITY, PERSON or ORGANIZATION get financial punishment typically as a result of court proceedings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Justice.Pardon</head><p>The word {evt} triggers a PARDON event: a head-of-state or their appointed representative lifts a sentence imposed by the judiciary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Justice.Appeal</head><p>The word {evt} triggers a APPEAL event: the decision of a court is taken to a higher court for review Business.Merge-Org The word {evt} triggers a MERGE-ORG event: two or more ORGANIZATION Entities come together to form a new ORGANIZATION Entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Justice.Extradite</head><p>The word {evt} triggers a EXTRADITE event.</p><p>Life.Divorce The word {evt} triggers a DIVORCE event: two people are officially divorced under the legal definition of divorce.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Justice.Acquit</head><p>The word {evt} triggers a ACQUIT event: a trial ends but fails to produce a conviction.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Large language models are few-shot clinical information extractors</title>
		<author>
			<persName><forename type="first">Monica</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Hegselmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hunter</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Sontag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2022 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Abu Dhabi, United Arab Emirates</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1998" to="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Association for Computational Linguistics. Anonymous. 2022. Few-shot event detection: An empirical study and a unified view</title>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Alt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Gabryszak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonhard</forename><surname>Hennig</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.142</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020-10">2020. October</date>
			<biblScope unit="page" from="1558" to="1569" />
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Mc-Candlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Mark Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heewoo</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiming</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henrique</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Pond? De Oliveira Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harrison</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuri</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Brockman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raul</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Puri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heidy</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Khlaaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brooke</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alethea</forename><surname>Pavlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Power</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><surname>Bavarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Neural Information Processing Systems, NIPS&apos;20</title>
		<editor>
			<persName><forename type="first">Joshua</forename><surname>Achiam</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Vedant</forename><surname>Misra</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Evan</forename><surname>Morikawa</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Matthew</forename><surname>Knight</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Miles</forename><surname>Brundage</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mira</forename><surname>Murati</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Katie</forename><surname>Mayer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</editor>
		<meeting>the 34th International Conference on Neural Information Processing Systems, NIPS&apos;20<address><addrLine>Red Hook, NY, USA; William Saunders, Christopher Hesse, Andrew N. Carr; Bob McGrew</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2020-01">2020. Jan Leike</date>
		</imprint>
	</monogr>
	<note>Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings. Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. 2021. Evaluating large language models trained on code. CoRR, abs/2107.03374</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Knowprompt: Knowledgeaware prompt-tuning with synergistic optimization for relation extraction</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ningyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shumin</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunzhi</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luo</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huajun</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1145/3485447.3511998</idno>
	</analytic>
	<monogr>
		<title level="m">WWW &apos;22: The ACM Web Conference 2022, Virtual Event</title>
		<meeting><address><addrLine>Lyon, France</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2022-04-25">2022. April 25 -29, 2022</date>
			<biblScope unit="page" from="2778" to="2788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Palm: Scaling language modeling with pathways</title>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parker</forename><surname>Schuh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kensen</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasha</forename><surname>Tsvyashchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Maynez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parker</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Vinodkumar Prabhakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Reif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reiner</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>Gur-Ari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toju</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anselm</forename><surname>Duke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Levskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunipa</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henryk</forename><surname>Dev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vedant</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liam</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyeontaek</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Spiridonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Sepassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shivani</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Omernick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thanumalayan</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie</forename><surname>Sankaranarayana Pillai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Pellat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erica</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Moreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksandr</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zongwei</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brennan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Saeta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Catasta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathy</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douglas</forename><surname>Meier-Hellstern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Eck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Slav</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dasha</forename><surname>Fiedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Valter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adams</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanping</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongkun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Slav</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><surname>Wei</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2210.11416</idno>
	</analytic>
	<monogr>
		<title level="m">Hyung Won Chung</title>
		<editor>
			<persName><forename type="first">Le</forename><surname>Hou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Shayne</forename><surname>Longpre</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yunxuan</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Siddhartha</forename><surname>Brahma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Albert</forename><surname>Webson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Shane</forename><surname>Shixiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Zhuyun</forename><surname>Gu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mirac</forename><surname>Dai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xinyun</forename><surname>Suzgun</surname></persName>
		</editor>
		<editor>
			<persName><surname>Chen</surname></persName>
		</editor>
		<meeting><address><addrLine>Alex Castro-Ros, Marie Pellat, Kevin Robinson</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note>Scaling instructionfinetuned language models</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Few-NERD: A few-shot named entity recognition dataset</title>
		<author>
			<persName><forename type="first">Bosheng</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengwei</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linlin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boyang</forename><surname>Li ; Ning Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangwei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaobin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengjun</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haitao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.248</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2021">2022. 2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3198" to="3213" />
		</imprint>
	</monogr>
	<note>Is gpt-3 a good data annotator?. Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The automatic content extraction (ACE) program -tasks, data, and evaluation</title>
		<author>
			<persName><forename type="first">George</forename><surname>Doddington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Przybocki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lance</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC&apos;04)</title>
		<meeting>the Fourth International Conference on Language Resources and Evaluation (LREC&apos;04)<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">SimCSE: Simple contrastive learning of sentence embeddings</title>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingcheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.552</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Dominican Republic. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="6894" to="6910" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eliza</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>De Las</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><forename type="middle">Anne</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hennigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katie</forename><surname>Noland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bogdan</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelia</forename><surname>Damoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Guy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erich</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><forename type="middle">W</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><surname>Sifre</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2203.15556</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Training compute-optimal large language models</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Thinking about GPT-3 in-context learning for biomedical IE? think again</title>
		<author>
			<persName><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Bernal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimenez</forename><surname>Gutierrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolas</forename><surname>Mcneal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clayton</forename><surname>Washington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">You</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Su</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1904.09751</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2022</title>
		<meeting><address><addrLine>Abu Dhabi</addrLine></address></meeting>
		<imprint>
			<publisher>United Arab Emirates. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020. 2022</date>
			<biblScope unit="page" from="4497" to="4512" />
		</imprint>
	</monogr>
	<note>The curious case of neural text degeneration</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Exploiting asymmetry for synthetic training data generation: Synthie and the case of information extraction</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Josifoski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marija</forename><surname>Sakota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxime</forename><surname>Peyrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>West</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2303.04132</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Large language models are zero-shot reasoners</title>
		<author>
			<persName><forename type="first">Takeshi</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shane</forename><surname>Shixiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Machel</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutaka</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusuke</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><surname>Iwasawa</surname></persName>
		</author>
		<idno>abs/2205.11916</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Neural Information Processing Systems</title>
		<meeting>the 36th International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures</title>
		<author>
			<persName><forename type="first">Jiachang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dinghan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Carin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.deelio-1.10</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Deep Learning Inside Out</title>
		<meeting>Deep Learning Inside Out<address><addrLine>Dublin, Ireland and Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022. DeeLIO 2022</date>
			<biblScope unit="page" from="100" to="114" />
		</imprint>
	</monogr>
	<note>What makes good in-context examples for GPT-3?</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1907.11692</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Roberta: A robustly optimized bert pretraining approach</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">2022a. Summarization as indirect supervision for relation extraction</title>
		<author>
			<persName><forename type="first">Keming</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I-Hung</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenxuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyu</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhao</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2022</title>
		<meeting><address><addrLine>Abu Dhabi</addrLine></address></meeting>
		<imprint>
			<publisher>United Arab Emirates. Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="6575" to="6594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">2022b. Unified structure generation for universal information extraction</title>
		<author>
			<persName><forename type="first">Yaojie</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dai</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyan</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianpei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.395</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5755" to="5772" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Label semantics for few shot named entity recognition</title>
		<author>
			<persName><forename type="first">Jie</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srikanth</forename><surname>Doss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishita</forename><surname>Anubhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunil</forename><surname>Mallya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaser</forename><surname>Al-Onaizan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.findings-acl.155</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2022</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1956" to="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carroll</forename><forename type="middle">L</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarina</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fraser</forename><surname>Kelton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maddie</forename><surname>Simens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2203.02155</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Training language models to follow instructions with human feedback</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Is chatgpt a general-purpose natural language processing task solver? Colin Raffel</title>
		<author>
			<persName><forename type="first">Chengwei</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aston</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">; Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2302.06476</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2020">2023. 2020</date>
		</imprint>
	</monogr>
	<note>Exploring the limits of transfer learning with a unified text-to-text transformer</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning to retrieve prompts for in-context learning</title>
		<author>
			<persName><forename type="first">Ohad</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.naacl-main.191</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Seattle, United States. Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2655" to="2671" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">From light to rich ERE: Annotation of entities, relations, and events</title>
		<author>
			<persName><forename type="first">Zhiyi</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ann</forename><surname>Bies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Riese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Mott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename><surname>Kulick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neville</forename><surname>Ryant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyi</forename><surname>Ma</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/W15-0812</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the The 3rd Workshop on EVENTS: Definition, Detection, Coreference, and Representation</title>
		<meeting>the The 3rd Workshop on EVENTS: Definition, Detection, Coreference, and Representation<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="89" to="98" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Selective annotation makes language models better few-shot learners</title>
		<author>
			<persName><forename type="first">Hongjin</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jungo</forename><surname>Kasai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><forename type="middle">Henry</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijia</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianlu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiayi</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2209.01975</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Recitation-augmented language models</title>
		<author>
			<persName><forename type="first">Zhiqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition</title>
		<author>
			<persName><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fien</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meulder</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003</title>
		<meeting>the Seventh Conference on Natural Language Learning at HLT-NAACL 2003</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="142" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Large language models still can&apos;t plan (a benchmark for llms on planning and reasoning about change)</title>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Valmeekam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Olmo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarath</forename><surname>Sreedharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subbarao</forename><surname>Kambhampati</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2206.10498</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Code4struct: Code generation for few-shot structured prediction from natural language</title>
		<author>
			<persName><forename type="first">Xiaozhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wangyi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sha</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2210.12810</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<editor>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</editor>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020. 2022. 2023</date>
			<biblScope unit="page" from="1652" to="1671" />
		</imprint>
	</monogr>
	<note>The Eleventh International Conference on Learning Representations. ICLR 2023</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Finetuned language models are zero-shot learners</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>International Conference on Learning Representations</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<title level="m">Emergent abilities of large language models. Transactions on Machine Learning Research</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Survey Certification</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Chain of thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Huai Hsin Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Neural Information Processing Systems</title>
		<meeting>the 36th International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Linguistic Data Consortium, Philadelphia, PA. Yi Yang and Arzoo Katiyar. 2020. Simple and effective few-shot named entity recognition with structured nearest neighbor learning</title>
		<author>
			<persName><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitchell</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lance</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ann</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michelle</forename><surname>Franchini</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.516</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2013">2013. 2013t19</date>
			<biblScope unit="page" from="6365" to="6375" />
		</imprint>
	</monogr>
	<note>Ontonotes release 5.0 ldc</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Generate rather than retrieve: Large language models are strong context generators</title>
		<author>
			<persName><forename type="first">Wenhao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Iter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxuan</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumya</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenguang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Jiang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>In International Conference for Learning Representation (ICLR 2023</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Positionaware attention and supervised data improve slot filling</title>
		<author>
			<persName><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1004</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="35" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Automatic chain of thought prompting in large language models</title>
		<author>
			<persName><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aston</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>ICLR 2023</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Method FewNERD OntoNotes Conll 1-shot 5-shot 10-shot 20-shot 1-shot 5-shot 10-shot 20-shot 1-shot 5-shot 10-shot 20-shot Small LMs Fine-tune Roberta-b</title>
		<imprint/>
	</monogr>
	<note>110M) 20.1(2.2) 33.7(3.4) 37.4(1.8) 48.6(1.5) 17.2(4.3) 50.2(3.1) 56.3(5.0) 64.5(3.6) 21.9(10.3) 50.1(7.0) 57.7(7.0) 64.8(4.9</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Table 12: Performance with different methods on RE tasks. Averaged F1-scores with sample standard deviations on 5 repeated experiments are shown. The best results are in bold face and the second best are underlined. Method TARCREV TARCRED 1-shot 5-shot 10-shot 20-shot 50-shot 100-shot 1-shot 5-shot 10-shot 20-shot 50-shot 100-shot Small LMs Fine-tune Roberta-b</title>
		<idno>1.0) 69.6(3.6) 75.8(3.3) 79.1(1.3) 81.1(2.4</idno>
		<imprint/>
	</monogr>
	<note>110M) 10.3(3.2) 35.0(3.1) 44.6(2.5) 54.1(1.3) 61.1(2.3) 66.4(2.1) 8.4(3.2) 25.7(4.1) 37.5(2.6) 47.2(1.0) 53.3(4.0) 59.7(1.4)</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Performance with different methods on ED tasks. Averaged F1-scores with sample standard deviations on 5 repeated experiments are shown. The best results are in bold face and the second best are underlined. Method ACE05 ERE MAVEN 1-shot 5-shot 10-shot 20-shot 1-shot 5-shot 10-shot 20-shot 1-shot 5-shot 10-shot 20-shot Small LMs Fine-tune Roberta-b</title>
		<idno>ICL+SE CODEX (175B) 56.0(1.1) 57.8(3.6) 58.6(1.9) 58.6(1.5) 59.6(0.3) 59.5(1.2) 52.4</idno>
		<imprint>
			<biblScope unit="volume">13</biblScope>
		</imprint>
	</monogr>
	<note>2.1) 54.6(2.7) 53.2(0.7) 52.8(2.7) 54.0(1.3) 54.6(1.3) Table. 110M) 20.1(4.9) 45.1(6.6) 55.9(2.4) 60.3(1.9) 17.2(4.9) 35.5(2.1) 46.5(3.4) 47.3(2.5) 15.5(3.2) 36.1(1.9) 45.2(1.3) 52.4(1.4)</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName><surname>Icl+se Codex</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>175B) 42.0(3.3) 45.4(1.5) 46.3(0.8) 46.3(1.3) 31.9(2.6) 39.4(4.2) 40.4(3.2) 40.1(2.4) 26.7(1.7) 28.0(0.3) 29.2(1.2) 28.2(1</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
