<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Service-Oriented Architectures Testing: A Survey</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Gerardo</forename><surname>Canfora</surname></persName>
							<email>canfora@unisannio.it</email>
							<affiliation key="aff0">
								<orgName type="department">RCOST -Research Centre on Software Technology</orgName>
								<orgName type="institution">University of Sannio Palazzo ex Poste</orgName>
								<address>
									<addrLine>Via Traiano</addrLine>
									<postCode>82100</postCode>
									<settlement>Benevento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Massimiliano</forename><forename type="middle">Di</forename><surname>Penta</surname></persName>
							<email>dipenta@unisannio.it</email>
							<affiliation key="aff0">
								<orgName type="department">RCOST -Research Centre on Software Technology</orgName>
								<orgName type="institution">University of Sannio Palazzo ex Poste</orgName>
								<address>
									<addrLine>Via Traiano</addrLine>
									<postCode>82100</postCode>
									<settlement>Benevento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Service-Oriented Architectures Testing: A Survey</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">96E8163D81CE1F402A829904FFFEEB7D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Testing of Service Oriented Architectures (SOA) plays a critical role in ensuring a successful deployment in any enterprise. SOA testing must span several levels, from individual services to inter-enterprise federations of systems, and must cover functional and non-functional aspects.</p><p>SOA unique combination of features, such as run-time discovery of services, ultra-late binding, QoS aware composition, and SLA automated negotiation, challenge many existing testing techniques. As an example, run-time discovery and ultra-late binding entail that the actual configuration of a system is known only during the execution, and this makes many existing integration testing techniques inadequate. Similarly, QoS aware composition and SLA automated negotiation means that a service may deliver with different performances in different contexts, thus making most existing performance testing techniques to fail.</p><p>Whilst SOA testing is a recent area of investigation, the literature presents a number of approaches and techniques that either extend traditional testing or develop novel ideas with the aim of addressing the specific problems of testing service-centric systems. This chapter reports a survey of recent research achievements related to SOA testing. Challenges are analyzed from the viewpoints of different stakeholders and solutions are presented for different levels of testing, including unit, integration, and regression testing. The chapter covers both functional and non-functional testing, and explores ways to improve the testability of SOA.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Service Oriented Architectures (SOA) are rapidly changing the landscape of today and tomorrow software engineering. SOA allows for flexible and highly dynamic systems through service discovery and composition <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">2,</ref><ref type="bibr" target="#b3">3]</ref>, ultra-late binding, Service Level Agreement (SLA) management and automated negotiation <ref type="bibr" target="#b4">[4]</ref>, and autonomic system reconfiguration <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b6">6,</ref><ref type="bibr" target="#b7">7]</ref>. More important, SOA is radically changing the development perspective, promoting the separation of the ownership of software (software as a product) from its use (software as a service) <ref type="bibr" target="#b8">[8]</ref>.</p><p>The increasing adoption of SOA for mission critical systems calls for effective approaches to ensure high reliability. Different strategies can be pursued to increase confidence in SOA: one possibility is to realize fault tolerant SOA by redundancy. For example, Walkerdine et al. <ref type="bibr" target="#b9">[9]</ref> suggest that each service invoked by a system could be replaced by a container that invokes multiple, equivalent, services, and acts as a voter.</p><p>Another possibility is to continuously monitor a service-centric system during its execution <ref type="bibr" target="#b5">[5]</ref> and apply corrective actions when needed: whenever an exceptional event is detected (e.g., a failure of a post condition or a violation of a Quality of Service-QoS-constraint), a recovery action is triggered. For example, if a temperature service, part of a whether forecasting system, is not available, an alternative one is located and invoked.</p><p>Whilst monitoring is an effective tool to build self-healing and self-repairing servicecentric systems <ref type="bibr" target="#b10">[10]</ref>, it requires that adequate recovery actions be implemented for all possible exceptional events. Thus, testing remains a key process to reduce at a minimum the number of such exceptional events.</p><p>Several consolidated testing approaches, applied for years to traditional systems, apply to service-centric systems as well. Primarily, the idea that a combination of unit, integration, system, and regression testing is needed to gain confidence that a system will deliver the expected functionality. Nevertheless, the dynamic and adaptive nature of SOA makes most of the existing testing techniques not directly applicable to test services and service-centric systems. As an example, most traditional testing approaches assume that one is always able to precisely identify the actual piece of code that is invoked at a given call-site. Or, as in the case of object-centric programming languages, that all the possible (finite) bindings of a polymorphic component be known. These assumptions may not be true anymore for SOA, which exhibits run-time discovery in an open marketplace of services and ultra-late binding.</p><p>Examples of SOA unique features that add complexity to the testing burden include:</p><p>-systems based on services are intrinsically distributed, and this requires that QoS be ensured for different deployment configurations; -services in a system change independently from each other, and this has impacts on regression testing; -systems implement adaptive behaviors, either by replacing individual services or adding new ones, and thus integration testing has to deal with changing configurations; -the limited trust service integrators and users have about the information service providers use to advertise and describe the service makes it complex the task of designing test cases; -ownership over the system parts is shared among different stakeholders, and thus system testing requires the coordination of these stakeholders.</p><p>The adoption of SOA, in addition to changing the architecture of a system, brings changes in the process of building the system and using it, and this has effects on testing too. Services are used, not owned: they are not physically integrated into the systems that use them and run in a provider's infrastructure. This has several implications for testing: code is not available to system integrators; the evolution strategy of a service (that is, of the software that sits behind the service) is not under the control of the system owner; and, system managers cannot use capacity planning to prevent SLA failures.</p><p>This chapter overviews SOA testing, discussing issues and possible solutions for different testing levels and perspectives, introducing ways to improve service testability, and outlining open issues as an agenda for future research.</p><p>The chapter is organized as follows. Section 2 identifies key challenges of SOA testing, while Section 3 discusses testing needs, problems, and advantages from the perspectives of different stakeholders. Section 4 focuses on testing levels, namely unit, integration, regression, and non-functional testing, identifying problems and reviewing solutions in the literature. Section 5 discusses ways to increase testability in SOA. Finally, Section 6 concludes the chapter, highlighting open issues and future research directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Testing Challenges</head><p>When a new technology emerges and new software engineering approaches/processes have to be developed for such technology, a typical question is whether it is possible to reuse/adapt existing approaches, previously developed for other kinds of systems. In the context of this chapter, the question is whether testing approaches and techniques developed for traditional monolithic systems, distributed systems, component-based systems, and Web applications, can be reused or adapted to test service-centric systems. Answering this question requires an analysis of the peculiarities that make service-centric systems different from other systems as far as the testing process is concerned.</p><p>Key issues that limit the testability of service-centric systems include <ref type="bibr" target="#b11">[11]</ref>:</p><p>-lack of observability of the service code and structure: for users and system integrators services are just interfaces, and this prevents white-box testing approaches that require knowledge of the structure of code and flow of data. When further knowledge is needed for testing purpose-e.g., a description of the dependencies between service operations, or a complete behavioral model of the service-either the service provider should provide such information, or the tester has to infer it by observing the service from the outside. -dynamicity and adaptiveness: for traditional systems one is always able to determine the component invoked in a given call-site, or, at least, the set of possible targets, as it happens in (OO) systems in presence of polymorphism <ref type="bibr" target="#b12">[12]</ref>. This is not true for SOA, where a system can be described by means of a workflow of abstract services that are automatically bound to concrete services retrieved from one or more registries during the execution of a workflow instance. -lack of control: while components/libraries are physically integrated in a software system, this is not the case for services, which run on an independent infrastructure and evolve under the sole control of the provider. The combination of these two characteristics implies that system integrators cannot decide the strategy to migrate to a new version of a service and, consequently, to regression testing the system <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b14">14]</ref>. In other words, a service may evolve, however this is not notified to integrators/users accessing it. As a consequence, systems making use of the service can unexpectedly change their behavior or, although the functional behavior is preserved, might not meet SLAs anymore. -lack of trust: a service might provide descriptions of its characteristics, for instance a behavioral model, information about the QoS levels ensured, etc. Such information can, in theory, be used by integrators to discover the service, to comprehend its characteristics, and to select it. However, it is not possible to guarantee that any piece of information a service provides corresponds to the truth. In general, a service provider may lie, providing incorrect/inaccurate description of a service's functional and non-functional behavior, thus influencing decisions integrators may take on the use of the service. -cost of testing: invoking actual services on the provider's machine has effects on the cost of testing, too, if services are charged on a per-use basis. Also, service providers could experience denial-of-service phenomena in case of massive testing, and repeated invocation of a service for testing may not be applicable whenever the service produces side effects, other than a response, as in the case of a hotel booking service <ref type="bibr" target="#b11">[11]</ref>.</p><p>Any level of SOA testing needs to develop new strategies, or to adapt existing ones, to deal with these issues. For example, SOA testing has similarities to commercial offthe-shelf (COTS) testing. The provider can test a component only independently of the applications in which it will be used, and the system integrator is not able to access the source code to analyze and retest it. However, COTS are integrated into the user's system deployment infrastructure, while services live in a foreign infrastructure. Thus, the QoS of services can vary over time more sensibly and unpredictably than COTS. This QoS issue calls for specific testing to guarantee the SLAs stipulated with consumers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Testing Perspectives</head><p>SOA introduces different needs and challenges for different stakeholders involved in testing activities, i.e. developers, providers, integrators, certifiers, and end-users. Table <ref type="table" target="#tab_0">1</ref> provides a summary of pros and cons stakeholders experience in different testing levels.</p><p>Service Developer. Aiming to release a highly reliable service, the service developer tests the service to detect the maximum possible number of failures. The developer owns the service implementation, thus s/he is able to perform white-box testing. Among the other things, the developer also tries to assess the service's non-functional properties and its ability to properly handle exceptions. Although testing costs are limited in this case (the developer does not have to pay when testing his own service), non-functional testing is not realistic because it does not account for the provider and consumer infrastructure, and the network configuration or load. In general, test cases devised by the developer may not reflect a real usage scenario.</p><p>Service Provider. The service provider tests the service to ensure it guarantees the requirements stipulated in the SLA with the consumer. Testing costs are limited. However, the provider might not use white-box techniques, since s/he may be an organization/person different from who developed the service. Finally, non-functional testing does not reflect the consumer infrastructure and network configuration or load and, once again, test cases do not reflect the service real usage scenario.</p><p>Service Integrator. The service integrator tests to gain confidence that any service to be bound to her own composition fits the functional and non-functional assumptions made at design time. Runtime discovery and ultra-late binding can make this more challenging because the bound service is one of many possible, or even unknown, services.  <ref type="bibr" target="#b11">[11]</ref>. Roles/responsibilities are reported in italic, advantages with a (+), issues with a(-). Furthermore, the integrator has no control over the service in use, which is subject to changes during its lifetime. Testing from this perspective requires service invocations and results in costs for the integrator and wasted resources for the provider.</p><p>Third-Party Certifier. The service integrator can use a third-party certifier to assess a service's fault-proneness. From a provider perspective, this reduces the number of stakeholders-and thus resources-involved in testing activities. To ensure fault tolerance, the certifier can test the service on behalf of someone else, from the same perspective of a service integrator. However, the certifier does not test a service within any specific composition (as the integrator does), neither s/he performs testing from the same network configuration as the service integrator.</p><p>End-User. The user has no clue about service testing. His only concern is that the application s/he is using works while s/he is using it. For the user, SOA dynamicity represents both a potential advantage-for example, better performance, additional features, or reduced costs-and a potential threat. Making a service-centric system capable of self-retesting certainly helps reducing such a threat. Once again, however, testing from this perspective entails costs and wastes resources. Imagine if a service-centric application installed on a smart-phone and connected to the network through a wireless network suddenly starts a self-test by invoking several services, while the network usage is charged based on the bandwidth usage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Testing Levels</head><p>This section details problems and existing solutions for different levels of testing, namely (i) unit testing of atomic services and service compositions, (ii) integration/interoperability testing, (iii) regression testing, and (iv) testing of non-functional properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Unit Testing</head><p>Testing a single atomic services might, in principle, be considered equivalent to component testing. As a matter of fact, there are similarities, but also differences:</p><p>-observability: unless when the service is tested by its developer, source code is not available. This prevents the possibility of using white-box testing techniques (e.g., code coverage based approaches). For stateful services, it would be useful to have models-e.g., state machines-describing how the state evolves. Such models could support, in addition to testing, service discovery <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">2]</ref>, and composition <ref type="bibr" target="#b3">[3]</ref>.</p><p>Unfortunately, these models are rarely made available by service developers and providers, due to the lack of proper skills to produce them, or simply to the lack of time and resources. Nevertheless, approaches for a black-box reverse engineering of service specifications-for example inspired by likely invariant detection approaches <ref type="bibr" target="#b16">[15]</ref>-are being developed <ref type="bibr" target="#b17">[16,</ref><ref type="bibr" target="#b18">17]</ref>. -testing cost and side effects: as explained in Section 2, this is a crosscutting problem for all testing activities concerning services. Unit testing should either be designed to limit the number of service invocations-making test suite minimization issues fundamental-or services should provide a "testing mode" interface to allow testers to invoke a service without being charged a fee, without occupying resources allocated for the service production version, and above all without producing side effects in the real world.</p><formula xml:id="formula_0">-</formula><p>Bertolino et al. <ref type="bibr" target="#b22">[21]</ref> propose an approach and a tool, named TAXI (Testing by Automatically generated XML Instances) <ref type="bibr" target="#b23">[22]</ref>, for the generation of test cases from XML schema. Although not specifically designed for web services, this tool is well-suited for performing service black-box testing. The tool partitions domains into sub-domains and generates test cases using category-partition <ref type="bibr" target="#b24">[23]</ref>.</p><p>Bai et al. <ref type="bibr" target="#b25">[24]</ref> proposes a framework to deal with the generation of test data for operations of both simple and composite services, and with the test of operation sequences. The framework analyzes services WSDLs (Web Service Description Language) interfaces to produce test data. As known, service operation parameters can be simple XSD types, aggregate types (e.g., arrays) or user defined types. For simple types the framework foresees a database where, for each type and for each testing strategy a tester might want to adopt, a facet defines default values, minimum and maximum length (e.g., for strings), minimum and maximum values (e.g. numeric types), lists of admissible values (strings) etc. This information is used to generate test data for simple parameter types, while for complex and user defined types the structure is recursively analyzed until leaves defined in terms of simple types are encountered.</p><p>Other than generating test data, the approach of Bai et al. <ref type="bibr" target="#b25">[24]</ref> also generates operation sequences to be tested, based on dependencies existing between operations. Bai et al. infer operation dependencies from the WSDL, based on the following assumptions:</p><p>1. two operations are input dependent if they have common input parameters; 2. two operations are output dependent if they have common output parameters; 3. two operations are input/output dependent if there exist at least one output produced by an operation that is input for the other.</p><p>Conroy et al. <ref type="bibr" target="#b26">[25]</ref> exploit user interfaces of legacy applications-hereby referred as Reference APplications (RAP)-to generate test data for web services-hereby referred as Target APplications (TAP). Their approach is based on the following key ideas: 1. GUI element may be (i) input data acceptors (e.g., input fields), (ii) action producers (e.g., buttons), (iii) output data retrievers (e.g., combo-boxes, tables), or (iv) state checkpoints (i.e., any GUI element that appear in a particular state in order to make the application to work correctly). 2. Data can be captured from the GUI using technologies conceived for accessibility purposes, e.g., to support screen reading for visually impaired. 3. Once data has been captured, the tester can map such data to inputs of the target application/service, and then enact the replay.</p><p>Unit Testing of Service Compositions. Other than atomic services, WS-BPEL processes also need unit testing. In this section, we analyze WS-BPEL testing issues from the perspective of a developer, who has access to the WS-BPEL process itself, and thus can test it using white-box testing strategies. We recall that black-box testing of a WS-BPEL process is equivalent to service testing, discussed in the previous section, since a WS-BPEL process is viewed, from an external point of view, as a service exposing a WSDL interface. It is very unlikely that WS-BPEL processes are tested in isolation, since it would require to produce stubs for all the process partners. On the other hand, the possibility of testing a WS-BPEL process without requiring the availability of partners would allows for testing it even before partners have been developed, or in general without involving partners in the testing phase. Li et al. <ref type="bibr" target="#b27">[26]</ref> define a framework for WS-BPEL Unit Testing. Such a framework is, to some extent, similar to other unit testing frameworks, such as JUnit. The framework comprises four components:</p><p>1. the WS-BPEL process composition model (Fig. <ref type="figure" target="#fig_0">1-a</ref>), which includes the WS-BPEL Process Under Testing (PUT) and its Partner Processes (PPs). 2. the test architecture (Fig. <ref type="figure" target="#fig_0">1-b</ref>), where PP are replaced by stubs, named test processes (TPs), coordinated by a Control Process (CP). Thus, TPs simulate PP, plus they contain testing control structure and behavior (e.g., error-detecting logic). 3. lifecycle management, that starts-up or stops CPs and TPs by means of a User Interface (UI). To this aim, the CP provides a beginTest and endTest interface, and the TPs have startTest and stopTest interface. When the tester starts the testing activity by invoking beginTest through the CP interface, the CP on its own is responsible to start the TP it is coordinating. When all TPs complete their activity, the CP terminates as well.</p><p>A constraint-solver based approach for test case generation for WS-BPEL processes has been proposed by Yuan et al. <ref type="bibr" target="#b28">[27]</ref>. Test case generation is performed in four steps:</p><p>1. WS-BPEL processes are represented as BPEL-Flow-Graphs (BFG), a variation of Control Flow Graphs (CFG) with fork, merge (the outgoing edge is activated by any incoming edge) and join (the outgoing edge is activated after all the incoming edges have been activated) nodes. Tsai et al. <ref type="bibr" target="#b29">[28]</ref> proposes a shift of perspective in service testing, moving from Individual Verification &amp; Validation to Collaborative Verification &amp; Validation. They propose a technique, inspired from blood testing, that overcomes the need for manually defining oracles. Testing is performed by invoking multiple, equivalent services and then using a voter to detect whether a service exhibited a failure; in other words, if voting is performed upon three equivalent services, and one out of the three provides a different output, then it is assumed to contain a fault.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Integration Testing</head><p>SOA shifts the development perspective from monolithical applications to applications composed of services, distributed over the network, developed and hosted by different organizations, and cooperating together according to a centralized orchestration (e.g., described using WS-BPEL) or in a totally-distributed way (as it happens in a peer-topeer architectures). Moreover, service compositions can dynamically change to fulfill varying conditions, e.g., a service unavailability, or the publication of a new service with better QoS. In such a scenario, it becomes crucial to test services for interoperability, i.e., to perform service integration testing. This need is also coped by industrial initiative such as WS-Interoperability<ref type="foot" target="#foot_0">1</ref> , aimed at suggesting best practices to ensure high service interoperability.</p><p>The problem of integration testing for service compositions is discussed by Bucchiarone et al. <ref type="bibr" target="#b30">[29]</ref>. With respect to traditional integration testing, the following issues have to be handled:</p><p>-The lack of information about the integrated components, which makes the production of stubs very difficult. -The impossibility of executing the integrated components in testing mode: this requires to limit the involvement of services in testing activities, since it may cause costs, resource consumption, and even undesired side effects, as discussed earlier in this chapter.</p><p>As highlighted in our previous work <ref type="bibr" target="#b11">[11]</ref>, dynamic binding between service composition and partners make integration testing of service composition even more difficult. An invocation (hereby referred as "abstract service") in a service composition (e.g., in a WS-BPEL process) can be dynamically bound to different end points.</p><p>Dynamic binding can be based on QoS constraints and objectives <ref type="bibr" target="#b31">[30,</ref><ref type="bibr" target="#b32">31]</ref> or else on constraints defined upon service functional and non-functional properties (e.g., one might want to avoid services from a specific provider). This requires to perform integration testing with all possible bindings, as it happens when performing integration testing of OO systems <ref type="bibr" target="#b33">[32]</ref>. For example, in Fig. <ref type="figure">2</ref>-a the invocation from method mc() of class A to method m() of class B can be bound to B::m(), C::m() or D::m(). Regarding data-flow, for OO systems there is a call coupling between a method mA and a method mB when mA invokes mB, and a parameter coupling when mB has an input parameter that mA defines or an output parameter that mA uses. For such couplings, it can be possible to define:</p><p>-call coupling paths, beginning from the call site where (mA invokes mB) and finishing with a return site. -parameter coupling paths: (see Fig. <ref type="figure">2-b</ref>) for input parameters, it starts from the last definition of the parameter before the call, continues through the call site, and ends with the first use of the parameter in the callee. Similarly, for output parameters, it starts from the last definition of output parameter in the callee before the return, and ands with the first use after call in the caller.</p><p>Given the above paths, coverage criteria for OO systems include:</p><p>1. all call sites: test cases must cover all call-sites in the caller; 2. all coupling definitions: test cases must cover, for each coupling definition, at least one coupling path to at least one reachable coupling use; 3. all coupling uses: test cases must cover, for each coupling definition, at least one coupling path to each reachable coupling use; 4. all coupling paths: test cases must cover all coupling paths from the coupling definition to all coupling uses.</p><p>Ideally, such criteria could apply to test service compositions in the presence of dynamic binding. However:</p><p>-parameter coupling criteria cannot be applied as they are above defined, since the partners are invoked on providers' servers and thus viewed as black box entities. In other words, for parameters defined in the caller, the only visible use is the partner invocation, while definitions in the callee are only visible from return points (see Fig. <ref type="figure">2-d</ref>).</p><p>-the set of all possible concrete services for a given abstract service might not be known a-priori. In fact, some services available at design time might not be available at run-time, or else, if dynamic discovery in an open marketplace is used, new services can be made available at runtime (see Fig. <ref type="figure">2-c</ref>). -achieving the above coverage criteria for all possible bindings can be overly expensive and, in general, not possible when, as highlighted by Bucchiarone et al. <ref type="bibr" target="#b30">[29]</ref>, services cannot be invoked in testing mode.</p><p>Tsai et al. defines a framework for service integration testing, named Coyote <ref type="bibr" target="#b34">[33]</ref>, supporting both test execution and test scenario management. The Coyote tool consists of two parts: a test master and a test engine. The test master produces testing scenarios from the WSDL specifications, while the test engine interacts with the web service being tested and provides tracing information to the test master.</p><p>Bertolino and Polini <ref type="bibr" target="#b35">[34]</ref> propose an approach to ensure the interoperability between a service being registered in a Universal Description, Discovery and Integration (UDDI) registry and any other service, already registered, that can potentially cooperate with the service under registration. As Bertolino and Polini suggest, an UDDI registry should change its role from a passive service directory towards the role of an active "audition" authority.</p><p>SOA calls for integration testing aimed at SLA, too. Since each abstract service in a workflow can be bound to a set of possible concrete services (equivalent from functional point-of-view, but with different QoS), there might be particular combinations of bindings that can cause SLA violations. This point is further discussed in Section 4.4.</p><p>An important issue, dicussed by Mei et al. <ref type="bibr" target="#b36">[35]</ref>, concerns the use WS-BPEL makes of XPath to integrate workflow steps. Services take as input, and produces as output, XML documents. Thus problems can arise when information is extracted from an XML document using an XPath expression and then used as input for a service. The authors indicate the case where a service looks for the availability of DSL lines in a given city. If the city is provided using a XML document like such as:</p><formula xml:id="formula_1">&lt;address&gt; &lt;state&gt; &lt;name&gt;Beijing&lt;/name&gt; &lt;city&gt;Beijing&lt;/city&gt; &lt;/state&gt; &lt;/address&gt; or &lt;address&gt; &lt;state /&gt; &lt;city&gt;Beijing&lt;/city&gt; &lt;/address&gt;</formula><p>Different XPaths can return different values in the two cases. For example, both /city/ and /state/city/ return Beijing for the first document, while for the second /state/city/ returns an empty document. To perform BPEL data-flow testing, Mei et al. rewrite XPaths using graphs, named XPath Rewriting Graphs (XRG), that make explicit different paths through a XML schema. For example, the XPath expression //city/ can be considered as * //city/ * or just * //city/. An XRG is composed of rewriting nodes, containing the original expression (//city/ in our case), having edges directed to rewritten nodes, representing the different forms of an XPath ( * //city/ * and * //city/ in our case). Then, Mei et al. build models named X-WSBPEL, that combine CFG extracted from WS-BPEL with the XRG. To perform data-flow testing on the X-WSBPEL models, Mei et al. define a set of data-flow testing def-use criteria, based on variable definition and usages over XPaths.</p><p>An approach for data-flow testing of service compositions is proposed by Bartolini et al. <ref type="bibr" target="#b37">[36]</ref>, who essentially adapts data-flow criteria conceived for traditional CFGs to WS-BPEL processes to build, from a WS-BPEL process, an annotated CFG, and then generate test cases achieving different data-flow coverage criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Regression Testing</head><p>An issue that makes service-centric systems very different from traditional applications is the lack of control a system integrator has over the services s/he is using. System integrators select services to be integrated in their systems and assume that such services will maintain their functional and non-functional characteristics while being used. However, this is not the case: a system exposed as a service undergoes-as any other system-maintenance and evolution activities. Maintenance and evolution strategies are out of the system integrators control, and any changes to a service may impact all the systems using it. This makes service-centric systems different from component-based systems: when a component evolves, this does not affect systems that use previous versions of the component itself. Component-based systems physically integrate a copy of the component and, despite the improvements or bug fixing performed in the new component release, systems can continue to use an old version. In such a context, several evolution scenarios may arise:</p><p>-Changes that do not require modifying the service interface and/or specification, e.g., because the provider believes this is a minor update, As a consequence, the changes remain hidden from whoever is using the service. -Changes that do not affect the service functional behavior, but affect its QoS. Once again, these are not always documented by the service provider and, as a consequence, the QoS of the system/composition using such a service can be affected. -A service can be, on its own, a composition of other services. As a matter of fact, changes are propagated between different system integrators, and it happens that the distance between the change and the actor affected by the change makes unlikely that, even if the change is advertised, the integrator will be able to get it and react accordingly. The above scenarios raises the need for an integrator to periodically re-test the service she/he is using, to ensure that they still meet functional and non functional expectations. To this aim, Di Penta et al. <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b14">14]</ref> propose to complement service descriptions with a facet providing test cases, in the form of XML-based functional and non functional assertions. A facet is a (XML) document describing a particular property of a service, such as its interface (in this case the facet can correspond to the WSDL interface), its QoS, a SLA template that can be negotiated with the potential service users <ref type="bibr" target="#b4">[4]</ref>. A faceted approach to describe services <ref type="bibr" target="#b38">[37]</ref>, extends the UDDI registry with an XMLbased registry containing different kinds of facets. However, additional facets could simply be linked to the service WSDL without the need for requiring a customized, proprietary registry. Fig. <ref type="figure">3</ref> shows an excerpt of the SOA conceptual model <ref type="bibr" target="#b39">[38]</ref> related to facets describing properties of a service. A facet is specified by means of a facet specification expressed using a language, e.g., WSDL for interfaces, or WS-Agreement for SLA. As shown in the figure, a service can be described by a number of facets related to signature, operational semantics, QoS, test cases, etc. When a service integrator discovers a service and wants to use it, s/he downloads the testing facet and uses it to check whether the service exhibits the functional and nonfunctional properties s/he expects. As a matter of fact, a test suite can be used to support developers' comprehension of software artifacts: this has been investigated by Ricca et al. <ref type="bibr" target="#b40">[39]</ref>, who empirically assessed the usefulness of acceptance test cases expressed as Fit (Framework for Integrated Testing) <ref type="bibr" target="#b41">[40]</ref> tables in requirement comprehension tasks. Then, the test suite is used to periodically re-test the service to check whether it still meets the integrator functional and non-functional needs. Fig. <ref type="figure">4</ref> describes a possible scenario for the test case publication and regression testing process taken from <ref type="bibr" target="#b14">[14]</ref>. The scenario involves both a service provider (Jim) and two system integrators (Alice and Jane), and explains the capabilities of the proposed regression testing approach.</p><p>1. At time t 0 Jim deploys a service, e.g., a RestaurantService that allows an user to search for restaurants, gets restaurants info and check for availability. The service is deployed together with its test suite (facet). 2. At time t 1 Alice discovers the service, negotiates the SLA and downloads the test suite; she can complement the test suite with her own test cases, performs a preexecution of the test suite, and measures the service non-functional behavior. A SLA is agreed with the provider, and Alice stores both the test suite and the QoS assertions generated during the pre-execution. 3. Then, Alice regularly uses the service, until, 4. after a while, Jim updates the service. In the new version the ID return value for getRestaurantID is composed of five digits instead of four. Also, because of some changes in its configuration, the modified service is not able to answer in less than two seconds. 5. Jane regularly uses the new service with no problems. In fact, she uses a field that is large enough for visualizing a restaurant ID composed of five digits. Meanwhile, Jane's interactions are monitored. 6. Since the service has changed, Alice decides to test it: data monitored from Jane's executions can be used to reduce the number of service invocations during testing.</p><p>A test log containing successes and failures for both functional test cases and QoS assertions is reported.</p><p>According to Di Penta et al. <ref type="bibr" target="#b14">[14]</ref>, facets to support service regression testing can either be produced manually by the service provider or by the tester, or can be generated from unit test cases of the system exposed as a service, as described in Section 5.</p><p>The idea of using test cases as a form of contract between service providers and service consumers <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b14">14]</ref> also inspired the work of Dai et al. <ref type="bibr" target="#b42">[41]</ref>. They foresee a contract-based testing of web services. Service contracts are produced, in a Design by Contract <ref type="bibr" target="#b43">[42]</ref> scenario, using OWL-S models. Then, Petri nets are used for test data generation. As for Di Penta et al., test cases are then used to check whether during the time a service preserves the behavior specified in the contract.</p><p>Regression test suite reduction is particularly relevant in SOA, given the high cost of repeated invocations to services. Ruth and Tu <ref type="bibr" target="#b44">[43,</ref><ref type="bibr" target="#b45">44]</ref> defines a safe regression test suite selection technique largely based on the algorithm defined by Rothermel and Harrold <ref type="bibr" target="#b46">[45]</ref> for monolithic application. The proposed technique requires the availability of CFGs (rather than source code) for service involved in the regression testing activity. The idea is that CFGs should be able to highlight the changes that can trigger regression testing, while shielding the source code. Unfortunately, such assumption is, in most cases, pretty stronger in that service providers are unlikely to expose service CFGs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Non-functional Testing</head><p>Testing non-functional properties is crucial in SOA, for a number of reasons:</p><p>-service providers and consumers stipulate a SLA, in which the provider guarantees to consumers certain pieces of functionality with a given level of QoS. However, under certain execution conditions, caused by unexpected consumer inputs or unanticipated service load, such QoS level could not be met; -the lack of service robustness, or the lack of proper recovery actions for unexpected behaviors can cause undesired side effects even on the service side or on the integrator side; -services are often exposed over the Internet, thus they can be subject to security attacks, for instance by means of SQL injection.</p><p>Robustness Testing. Different approaches have been proposed in the literature to deal with different aspects of service non-functional testing. Martin et al. <ref type="bibr" target="#b47">[46,</ref><ref type="bibr" target="#b48">47]</ref> presents a tool for automatic service robustness testing. First, the tool automatically generates a service client from the WSDL. Then, any test generation tool for OO programs could be used to perform service robustness testing. In particular, the authors use JCrasher<ref type="foot" target="#foot_1">2</ref>  <ref type="bibr" target="#b49">[48]</ref>, a tool that generates JUnit tests. The authors applied their tool on services such as Google search and Amazon; although no major failures were detected, the authors indicated that, sometimes, services hanged up, suggesting a possible presence of bugs.</p><p>Ensuring robustness also means ensuring that exceptional behavior is properly handled and that the service reacts properly to such behavior. However, very often the error recovery code is not properly tested. Fu et al. <ref type="bibr" target="#b50">[49]</ref> proposes an approach for exception code data-flow testing, suited to web services developed in Java, but that can be applied to any Java program. In particular, they define the concept of exception-catch (e-c) link, i.e., the link between a fault-sensitive operation and a catch block in the program to be tested, and define coverage criteria for such links. SLA Testing. SLA testing deals with the need for identifying conditions for which a service cannot be able to provide its functionality with a desired level of SLA. Before offering a SLA to a service consumer, the service provider would limit the possibility that it can be violated during service usage. Di Penta et al. <ref type="bibr" target="#b21">[20]</ref> proposes an approach for SLA testing of atomic and composite services using Genetic Algorithms (GA). For a service-centric system such violations can be due to the combination of different factors, i.e., (i) inputs, (ii) bindings between abstract and concrete services, and (iii) network configuration and server load. In the proposed approach, GAs generate combinations of inputs and bindings for the service-centric system causing SLA violations. For atomic services, the approach generates test data as inputs for the service, and monitors the QoS exhibited by the service during test invocations. At minimum, the approach is able to monitor properties such as response time, throughput, and reliability. However, also domain specific QoS attributes <ref type="bibr" target="#b51">[50]</ref> can be monitored. Monitored QoS properties are used as fitness function to drive the test data generation (the fitness is used to select the individuals, i.e., test cases, that should "reproduce" by means of GA crossover and mutation operators). In other words, the closer a test case is to produce a QoS constraint violation, the better it is. To allow for test data generation using GA, test inputs are represented as a forest, where each tree represents a service input parameter according to its XML schema definition. Proper crossover and mutation operators are defined to generate new test data from existing one, i.e., evolving the population of GA solutions.  For service compositions, in particular where dynamic binding between abstract services in the workflow and concrete services is possible, GA aims at generating combinations of bindings and inputs that cause SLA violations. In fact, for the same inputs, different bindings might result in a different QoS. Fig. <ref type="figure" target="#fig_2">5</ref> shows an image processing workflow. Let us make the following assumptions:</p><p>-the service provider guarantees to consumers a response time less than 30 ms and a resolution greater or equal to 300 dots per inches (dpi); -a user provides as inputs an image having a size smaller than 20 Mb (which constitutes a precondition for our SLA), posterize = true, dim1 = dim2, and nsharpen = 2; -the abstract services are bound to ScaleC, PosterizeC, SharpenB, and GrayA, respectively.</p><p>In this case, while the response time will be lower-bounded by 24 ms, and therefore the constraint would be met, the resolution of the image produced by the composite service would be of 200 dpi, corresponding to the minimum resolution guaranteed by the invoked services. In other cases, the scenario can be much more complex, in particular when combinations of inputs for each service invoked in the workflow can, on its own, contribute to the overall SLA violation.</p><p>Testing for Dependability. The approach above described has a specific purpose, i.e., generating service inputs (and bindings) that violate the SLA. More generally, for services used in a business-critical scenario, it would be useful to generate service inputs that cause:</p><p>-security problems, e.g., allowing unauthorized access to sensible data; -service hang up; -unexpected, unhandled exceptions; -a behavior not observable in the service response.</p><p>Many of the existing approaches rely on SOAP message perturbation. According to Voas <ref type="bibr" target="#b52">[51]</ref>, perturbation allows for altering an application internal state without modifying its source code.</p><p>To this aim, Offutt and Xu <ref type="bibr" target="#b53">[52]</ref> foresee an approach to generate web service test cases through Data Perturbation (DP). Basically, the process consists in modifying the request messages, resending them to the web service and analyzing how the response message changed with respect to the original message. Specifically, the mechanism foresees two types of perturbation: Data Value Perturbation (DVP), Remote Procedure Call (RPC) Communication Perturbation (RCP), and Data Communication Perturbation (DCP). DVP produces data input modifications according to the types described in the service parameter XML schema, and is largely inspired to the concepts of boundary value testing <ref type="bibr" target="#b54">[53]</ref>. For example, for numeric values minimum, maximum and zero are considered, while for strings the perturbation consists of generating minimum length or maximum length strings, and upper-casing or lower-casing the string. RCP modifies message in RPC and data communication, in particular considering data used within programs and data used as inputs to database queries. For data used within programs, mutation mechanisms are defined for different data types; for example a numeric datum n can be changed to to 1/n (Divide), n × n (Multiply), -n (Negative), |n| (Absolute). Another perturbation exchanges the order of arguments. When data is used to query a database, perturbation aims at SQL injection, which occurs when an user input, incorrectly filtered for string literal, escapes characters embedded in SQL statements, causing the execution of unauthorized queries.</p><p>Offutt and Xu provide the following example: if a service expects 2 input parameters, username and password, and then checks for the presence of username and password in a database table using the query:</p><p>SELECT username FROM adminuser WHERE username='turing' AND password='enigma'</p><p>then, the Unhautorized perturbation mechanism appends to both username and password the string ' OR '1'='1. As a result, the query becomes:</p><p>SELECT username FROM adminuser WHERE username='turing' OR '1'='1' AND password ='enigma' OR '1'='1' always providing authentication/access. They also provide an example of data perturbation: given a SOAP message containing a data structure describing, for instance, a book: &lt;book&gt; &lt;ISBN&gt;0-781-44371-2&lt;/ISBN&gt; &lt;price&gt;69.99&lt;/price&gt; &lt;year&gt;2003&lt;/year&gt; &lt;/book&gt; Data perturbation entails sending (i) empty instances of the data structure, (ii) an allowable number of instances, (iii) duplicating instances from the message and (iv) removing an instance from the message. For example, the above message can be mutated by means of a duplication, as follows: &lt;book&gt; &lt;ISBN&gt;0-781-44371-2&lt;/ISBN&gt; &lt;price&gt;69.99&lt;/price&gt; &lt;year&gt;2003&lt;/year&gt; &lt;/book&gt; &lt;book&gt; &lt;ISBN&gt;0-781-44371-2&lt;/ISBN&gt; &lt;price&gt;69.99&lt;/price&gt; &lt;year&gt;2003&lt;/year&gt; &lt;/book&gt; Such a perturbation test would be useful, for instance, to check whether the different behavior the service exhibits in presence of such a duplicate record is observable from the response message. A response like "true" or "false"-just indicating whether the insertion was successful or not-is not sufficient to see how many records have been inserted.</p><p>Looker et al. <ref type="bibr" target="#b55">[54]</ref> propose to assess service dependability by means of fault injection techniques. They propose an approach and a tool named WS-FIT (Web Service Fault Injection Technology) inspired from network fault injection. Basically, they decode network messages based on SOAP and inject errors in these messages. They define a fault model for web services, considering different kinds of faults, namely (i) physical faults, (ii) software faults (programming or design errors), (iii) resource management faults (e.g., memory leakage), and (iv) communication faults. In particular, Looker et al. provide a detailed fault model for communication, considering message duplication, message omission, the presence of extra (attack) messages, change of message ordering, or the presence of delays in messages.</p><p>When injecting a fault, the service may react in different ways: (i) the service may crash, (ii) the web server may crash, (iii) the service may hang, (iv) the service may produce corrupted data, or (v) the response can be characterized message omission, duplication, or delay. Thus, the aim of the fault injection is to determine to what extent the service is able to properly react to faults seed in input messages, with proper exception handling and recovery actions, without exhibiting any of the above failures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Summary Table</head><p>Table <ref type="table" target="#tab_6">2</ref> briefly summarizes the approaches described in this section, providing, for each work, the reference, the testing level, and a short description.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Improving Testability</head><p>The intrinsic characteristics of SOA are a strong limit for service testability. According to Tsai et al. <ref type="bibr" target="#b56">[55]</ref>, service testability should account for several factors, such as: -the service accessibility, i.e., source code accessibility, binary accessibility, model accessibility, signature accessibility; -the "pedigree" of data describing a service. The origin of such information can constitute a crucial aspect since integrators might not trust it; -the level of dynamicity of the SOA.</p><p>Below, we describe some approaches, summarized in Table <ref type="table">3</ref>, that deal with service testability.</p><p>Tsai et al. <ref type="bibr" target="#b57">[56]</ref> propose that information to enhance service testability should be provided by extending WSDL. Specifically, the following information is proposed:</p><p>1. Input-Output-Dependency: they introduce a new complex type in the WSDL schema, named WSInputOutputDependenceType, to account for dependencies between service operation inputs and outputs; 2. Invocation Sequences: this represents a crucial issue when testing services, since a service might delegate to another service the execution of a particular task. The tester might want to be aware of such dependencies. A WSDL schema type WSInvocation-DependenceType is defined to represent caller-callee relationships between services; Bertolino et al. <ref type="bibr" target="#b22">[21,</ref><ref type="bibr" target="#b23">22]</ref> Test data generation from XML schema using the category partition strategy Bai et al. <ref type="bibr" target="#b25">[24]</ref> WSDL test data generation from XSD types Conroy et al. <ref type="bibr" target="#b26">[25]</ref> Exploit user interfaces of legacy systems to perform capture-replay over web services Li et al. <ref type="bibr" target="#b27">[26]</ref> Define a framework for BPEL unit testing Yuan et al. <ref type="bibr" target="#b28">[27]</ref> Constraint-solver based approach for WS-BPEL test case generation Tsai et al. <ref type="bibr" target="#b29">[28]</ref> Builds automatic oracles by invoking multiple equivalent services and comparing results through a voter Integration Tsai et al. <ref type="bibr" target="#b34">[33]</ref> Coyote: a framework for service test integration testing Bertolino and Polini <ref type="bibr" target="#b35">[34]</ref> The UDDI registry plays the role of audition authority to ensure service interoperability Bucchiarone et al. <ref type="bibr" target="#b30">[29]</ref> Discusses problems related to service integration testing Mei et al. <ref type="bibr" target="#b36">[35]</ref> Data-flow testing of WS-BPEL process with focus on XPath expressions Bartolini et al. <ref type="bibr" target="#b37">[36]</ref> Data-flow testing of service composition Regression Di Penta et al. <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b14">14]</ref> Generation of service testing facet from system JUnit test suite. Regression testing of service from the integrator side Dai et al. <ref type="bibr" target="#b42">[41]</ref> Services accompanied with a contract; Petri nets for generating test cases Ruth and Tu <ref type="bibr" target="#b44">[43,</ref><ref type="bibr" target="#b45">44]</ref> Applies the safe regression technique of <ref type="bibr">Rothermel and</ref> Harrold <ref type="bibr" target="#b46">[45]</ref> to web services where source code is unavailable. Non-functional Martin et al. <ref type="bibr" target="#b47">[46,</ref><ref type="bibr" target="#b48">47]</ref> Service robustness testing based on Axis and JCrasher Fu et al. <ref type="bibr" target="#b50">[49]</ref> Framework and criteria to perform exception code coverage Di Penta et al. <ref type="bibr" target="#b21">[20]</ref> Search-based SLA testing of service compositions Offutt and Xu <ref type="bibr" target="#b53">[52]</ref> Perturbation of SOAP messages Looker et al. <ref type="bibr" target="#b55">[54]</ref> WS-FIT: Service fault injection approach and tool Table <ref type="table">3</ref>. Approaches for improving service testability Reference Description Tsai et al. <ref type="bibr" target="#b57">[56]</ref> Complement WSDL with I/O dependencies, external dependencies, admissible invocation sequences, functional descriptions Tsai et al. <ref type="bibr" target="#b58">[57]</ref> Extension of UDDI registry with testing features to test service I/O behavior Heckel and Mariani <ref type="bibr" target="#b59">[58]</ref> Extension of UDDI registry with testing information; use of graph transformation systems to test single web services Heckel and Lohmann <ref type="bibr" target="#b60">[59]</ref> Complement services with contracts at different (model, XML, and implementation) levels Di Penta et al. <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b14">14]</ref> Generate service test cases ("facet") to be used as contracts for regression testing purposed from system test cases Bai et al. <ref type="bibr" target="#b61">[60]</ref> Framework for testing highly dynamic service-centric environments Bertolino et al. <ref type="bibr" target="#b62">[61]</ref> Puppet: QoS test-bed generator for evaluating the QoS properties of a service under development Bertolino et al <ref type="bibr" target="#b64">[62]</ref> Test-bed generator from extra-functional contracts (SLA) and functional contracts (modeled as state machines)</p><p>3. Functional Description: a service functional description can also be included as a form of hierarchy, to enhance black-box testing. To this aim Tsai et al. define two sub elements, WSFParents and WSFChildren, that permit the definition of functional structures. However, other than defining a hierarchical form for functional descriptions, the authors did not indicate which information such description must contain; 4. Sequence Specification: licit operation calling sequences are described using regular expressions, e.g., OpenF ile • (ReadLine|W riteLine) * • Close indicates that a file opening must be followed by zero or more read or write, then followed by a file closing.</p><p>Tsai et al. <ref type="bibr" target="#b58">[57]</ref> also propose to extend the UDDI registry with testing features: the UDDI server stores test scripts in addition to WSDL specifications.</p><p>Heckel and Mariani <ref type="bibr" target="#b59">[58]</ref> use graph transformation systems to test individual web services. Like Tsai et al., their method assumes that the registry stores additional information about the service. Service providers describe their services with an interface descriptor (i.e., WSDL) and some graph transformation rules that specify the behavior.</p><p>Heckel and Lohmann <ref type="bibr" target="#b60">[59]</ref> propose to enable web service testing by using Design by Contract <ref type="bibr" target="#b43">[42]</ref>. In a scenario where a service provider offers a piece of functionality through a service and a service consumer requests it, provider-consumer contracts describe the offered and required functionality. Heckel and Lohmann foresee service contract at different levels: (i) at model level, understandable by humans, (ii) at XML level, to be integrated into existing service standards like WSDL, and (iii) at implementation level, realized for example using JContract, and used by tools such as Parasoft Jtest<ref type="foot" target="#foot_2">3</ref> to generate test cases. Clearly, a mapping among different levels is required.</p><p>As described in Section 4.3, it would be useful to complement a service with facets containing test cases that can be used as a "contract" to ensure that the service, during the time, preserves its functional and non-functional behavior. To this aim, Di Penta et al. <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b14">14]</ref> propose to generate service test cases from test suites developed for the software system implementing the features exposed by the service. This is useful since, in most cases, developers are reluctant to put effort in producing a service test suite. On the other hand, legacy system unit test suites, such as Junit, are very often in use. Many software development methodologies, e.g., test-driven development, strongly encourage developers to produce unit test suites even before implementing the system itself. However, although these test suites are available, they cannot be directly used by a service integrator to test the service. This because assertions contained in the JUnit test cases can involve expressions composed of variables containing references to local objects and, in general, access to resources that are only visible outside the service interface. Instead, a test suite to be executed by a system integrator can only interact with the service operations. This requires that any expression part of a JUnit assertion, except invocations to service operations and Java static methods (e.g., methods of the Math class), needs to be evaluated and translated into a literal, by executing an instrumented version of the JUnit test class from the server-side. Such a translation is supported by the tester, that selectively specifies the operation invocation within the JUnit test suite that should be left in the testing facet and those that should be evaluated and translated in literals, since it regards operations not accessible from the service interface or operations not involved in the testing activity.</p><p>Testing activities in highly-dynamic environments, such as SOA with run-time discovery binding, require the presence of a test broker able to decouple test case definition from their implementation, and the testing environment from the system under test <ref type="bibr" target="#b61">[60]</ref>. This allows for a run-time binding and reconfiguration of test agents in case the service under test change (i) interface operations, (ii) its bindings, or (iii) steps of its underlying process.</p><p>An important issue when testing service-centric systems is the need for test-beds that can be used to evaluate QoS properties of a service under development, but also, for instance, to evaluate/test the QoS of a service composition-as described in Section 4.4-without having component services available and, even if they are available, avoiding to invoke them to limit side-effects and reduce the testing costs. Bertolino et al. <ref type="bibr" target="#b62">[61]</ref> proposed Puppet (Pick UP Performance Evaluation Test-bed), a test bed generator used to evaluate QoS properties of services uder development. Also, they propose an approach and a tool <ref type="bibr" target="#b64">[62]</ref> to generate stubs from extra functional contracts expressed as SLA and functional contracts expressed as state machines. Further details can be found in Chapter 5 of this book.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Summary</head><p>Software testing has long been recognized as one of the most costly and risky activities in the life-cycle of any software system. With SOA, the difficulty of thoroughly testing a system increases because of the profound changes that this architectural style induces on both the system and the software business/organization models. Testing challenges derive primarily from the intrinsic dynamic nature of SOA and the clear separation of roles between the users, the providers, the owners, and the developers of a service and the piece of software behind it. Thus, automated service discovery and ultra-late binding mean that the complete configuration of a system is known only at execution time, and this hinder integration testing, while per-use-charge of a service affects unit testing and QoS testing of services and their compositions. Whilst SOA testing is a recent area of investigation, numerous contributions have been presented in the literature, primarily in the areas of unit testing of services and orchestrations, integration testing, regression testing, and testing of non-functional properties. The literature also reports several investigations into means to improve the testability of services and service-centric systems. Nevertheless, several problems remain open, calling for additional research work:</p><p>-Combining testing and run-time verification. The dynamic nature of SOA entails that testing-based validation needs to be complemented with runtime verification. On the one hand, testing is unable to cope with certain aspects of a service-centric system validation, primarily because of the impossibility to test all-often unforeseen-system configurations. On the other hand, run-time monitoring, while able to deal with the intrinsic dynamism and adaptiveness of SOA, is unable to provide confidence that a system will behave correctly before it is actually deployed. Thus, additional research is needed to fully comprehend the role of testing and monitoring in the validation of a service-centric system and to devise systematic ways to combine them with the aim of increasing the confidence and reducing the cost of validation <ref type="bibr" target="#b65">[63]</ref>. -Improving testability. For system integrators and, more in general, users a service is just an interface, and this hinders the use of traditional white-box coverage approaches. Service usage may be charged based on the number of invocations; even worst, many services have permanent effects in the real world-e.g. booking a restaurant table-and this makes stress testing approaches infeasible. Lack of observability and cost of repeated invocations could be addressed by publishing a (state-full) model of a service and providing testing interface to query and change the state of a service without affecting the real world. Additional research work is needed to devise the right formalisms to express the models and to help standardizing the interfaces. As developing the models is costly and error prone, means to reverse engineering them from the observation of a service behavior are to be devised <ref type="bibr" target="#b17">[16,</ref><ref type="bibr" target="#b18">17]</ref>. -Validating fully decentralized systems. Currently, the most widespread approach to service composition is orchestration, which entails the use of an engine that executes a process description and coordinates the invocations of services. With this approach, systems are intrinsically distributed -services run in independent administrative domains-but control remains centralized. Nowadays, different forms of compositions are emerging, such as peer-to-peer choreography, which makes control, in addition to services, completely decentralized. Fully decentralized compositions opens new scenarios, for example, propagation of a query in a network of active services that may subscribe it based on an introspective knowledge of their capabilities <ref type="bibr" target="#b66">[64]</ref>, which poses new challenges to testing and monitoring.</p><p>SOA has great potentials for reducing costs and risks of enterprise systems, improving efficiency and agility of organizations, and mitigating the effects of changing technology. However, many of the benefits of SOA become challenges to testing services and service-centric systems. Addressing these challenges requires a coherent combination of testing, run-time monitoring, and exception management.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Li et al. [26] WS-BPEL Unit testing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 ;Fig. 2 .</head><label>12</label><figDesc>Fig. 2. Dynamic binding and call-coupling in OO and SOA</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Fig.5. SLA testing of composite service: example<ref type="bibr" target="#b51">[50]</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Testing stakeholders: Needs and opportunities</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>test data generation: with respect to test data generation techniques developed so far-see for instance search-based test data generation<ref type="bibr" target="#b19">[18]</ref>-the lack of source code observability makes test data generation harder. With the source code available, the generation heuristic is guided by paths covered when executing test cases and by distances from meeting control-flow conditions<ref type="bibr" target="#b20">[19]</ref>; in a black-box testing scenario, test data generation can only be based on input types-ranges and output values. able to generate test data according to these XML schema. Thus, operators of test data generation algorithms for service operations should be able to produce forests of trees, corresponding to XML representations or operation parameter. To this aim genetic programming can be used, as it was done by Di Penta et al.<ref type="bibr" target="#b21">[20]</ref>.-input/output types not fully specified: to apply functional testing techniques, e.g., category partition, it is necessary to know boundaries or admissible values of each input datum. In principle, XML schema defining service operation input parameters can provide such an information (e.g., defining ranges by means of xs:minInclusive and xs:maxInclusive XML Schema Definition-XSD-tags, or defining occurrences by means of the xs:maxoccurs) tag. However, in the practice, this is almost never done, thus the tester has to specify ranges/admissible values manually.</figDesc><table /><note><p>-complex input/output types: with respect to existing test data generation techniques, most of which only handle simple input data generations, many real-world services have complex inputs defined by means of XML schema. Test data generation should therefore be</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Exception edges are made explicit, loop unfolded, and different control flow structures (e.g., switch and pick) are brought back to a single structure. 2. the BFG is traversed to identify test paths, defined as a partially-ordered list of WS-BPEL activities; 3. Infeasible paths are filtered out by means of constraint solving. Constraint solving is used to solve inequalities for path conditions: if no solution is found then the path is considered unfeasible. Test data produced by constraint solver can be complemented by means of randomly generated test data and manually-produced test cases. 4. Test cases are generated by combining paths and test data. To this aim, only input</figDesc><table /><note><p>(e.g., message receive) and output (e.g., message reply) activities are considered, ignoring data handling activities such as assignments. Test case generation also requires to manually produce expected outputs, i.e., test oracles.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2 .</head><label>2</label><figDesc>Summary of service testing approaches</figDesc><table><row><cell>Level</cell><cell>Reference</cell><cell>Description</cell></row><row><cell>Functional</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>http://www.ws-i.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>www.cc.gatech.edu/jcrasher/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>http://www.parasoft.com</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work is partially founded by the European Commission VI Framework IP Project SeCSE (Service Centric System Engineering) (http://secse.eng.it), Contract No. 511680, and by the Italian Department of University and Research (MIUR) FIRB Project ART-DECO.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semantic matching of web services capabilities</title>
		<author>
			<persName><forename type="first">M</forename><surname>Paolucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kawamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sycara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISWC 2002</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Horrocks</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hendler</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">2342</biblScope>
			<biblScope unit="page" from="333" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<pubPlace>Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">INDISS: Interoperable discovery system for networked services</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">D</forename><surname>Bromberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Issarny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Middleware 2005</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Alonso</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3790</biblScope>
			<biblScope unit="page" from="164" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Assumption-based composition and monitoring of web services</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pistore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Traverso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Test and Analysis of web Services</title>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="307" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Negotiation of service level agreements: An architecture and a search-based approach</title>
		<author>
			<persName><forename type="first">E</forename><surname>Di Nitto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Di Penta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gambi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ripa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Villani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICSOC 2007</title>
		<editor>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Krämer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K.-J</forename><surname>Lin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Narasimhan</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4749</biblScope>
			<biblScope unit="page" from="295" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Towards dynamic monitoring of WS-BPEL processes</title>
		<author>
			<persName><forename type="first">L</forename><surname>Baresi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Guinea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICSOC 2005</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Benatallah</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Casati</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Traverso</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3826</biblScope>
			<biblScope unit="page" from="269" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The vision of autonomic computing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kephart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Self-managing software</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Hinchey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sterritt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="107" to="109" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Turning software into a service</title>
		<author>
			<persName><forename type="first">M</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Budgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Brereton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="38" to="44" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dependability properties of P2P architectures</title>
		<author>
			<persName><forename type="first">J</forename><surname>Walkerdine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Melville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sommerville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Peer-to-Peer Computing</title>
		<meeting><address><addrLine>Linköping</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-09">September 2002. 2002</date>
			<biblScope unit="page" from="173" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Smart Monitors for Composed Services</title>
		<author>
			<persName><forename type="first">L</forename><surname>Baresi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ghezzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Guinea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd International Conference on Service Oriented Computing (ICSOC 2004)</title>
		<meeting>2nd International Conference on Service Oriented Computing (ICSOC 2004)<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="193" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Testing services and service-centric systems: Challenges and opportunities</title>
		<author>
			<persName><forename type="first">G</forename><surname>Canfora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Di Penta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IT Professional</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="10" to="17" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Parameterized object sensitivity for points-to analysis for Java</title>
		<author>
			<persName><forename type="first">A</forename><surname>Milanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rountev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Ryder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Softw. Eng. Methodol</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="41" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Using test cases as contract to ensure service compliance across releases</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bruno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Canfora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Di Penta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Esposito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mazza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICSOC 2005</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Benatallah</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Casati</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Traverso</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3826</biblScope>
			<biblScope unit="page" from="87" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Web services regression testing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Di Penta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bruno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Esposito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mazza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Canfora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Test and Analysis of web Services</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Baresi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Nitto</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page" from="205" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<pubPlace>Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dynamically discovering likely program invariants to support program evolution</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Ernst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cockrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Griswold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Notkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="99" to="123" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automatic generation of software behavioral models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lorenzoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mariani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pezzè</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">30th International Conference on Software Engineering (ICSE 2008)</title>
		<meeting><address><addrLine>Leipzig, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">May 10-18, 2008. 2008</date>
			<biblScope unit="page" from="501" to="510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Efficient recovery of algebraic specifications for stateful components</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ghezzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mocci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Monga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IWPSE 2007: Ninth international workshop on Principles of software evolution</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="98" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Search-based software test data generation: a survey</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mcminn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Softw. Test. Verif. Reliab</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="105" to="156" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Evolutionary test environment for automatic structural testing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wegener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Baresel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sthamer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information &amp; Software Technology</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="841" to="854" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Search-based testing of service level agreements</title>
		<author>
			<persName><forename type="first">M</forename><surname>Di Penta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Canfora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Esposito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mazza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bruno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Genetic and Evolutionary Computation Conference</title>
		<meeting>Genetic and Evolutionary Computation Conference<address><addrLine>London, England, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-07-07">2007. July 7-11, 2007. 2007</date>
			<biblScope unit="page" from="1090" to="1097" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Systematic generation of XML instances to test complex software applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bertolino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Marchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Polini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RISE 2006</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Guelfi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Buchs</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4401</biblScope>
			<biblScope unit="page" from="114" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">TAXI -a tool for XML-based testing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bertolino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Marchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Polini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">29th International Conference on Software Engineering (ICSE 2007)</title>
		<meeting><address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">May 20-26, 2007. 2007</date>
			<biblScope unit="page" from="53" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The category-partition method for specifying and generating functional tests</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ostrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Balcer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the Association for Computing Machinery</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Wsdl-based automatic test case generation for web services testing</title>
		<author>
			<persName><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Workshop on Service-Oriented System Engineering</title>
		<imprint>
			<biblScope unit="issue">SOSE</biblScope>
			<biblScope unit="page" from="215" to="220" />
			<date type="published" when="2005">2005</date>
			<publisher>IEEE Computer Society</publisher>
			<pubPlace>Los Alamitos</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Automatic test generation from GUI applications for testing Web services</title>
		<author>
			<persName><forename type="first">K</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Grechanik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hellige</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Liongosari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Software Maintenance, ICSM 2007</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="345" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">BPEL4WS unit testing: Framework and implementation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">B</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2005 IEEE International Conference on web Services (ICWS 2005)</title>
		<meeting><address><addrLine>Orlando, FL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-07">July 2005. 2005</date>
			<biblScope unit="page" from="103" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A graph-search based approach to BPEL4WS test generation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Software Engineering Advances (ICSEA 2006)</title>
		<meeting>the International Conference on Software Engineering Advances (ICSEA 2006)<address><addrLine>Papeete, Tahiti, French Polynesia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-11-02">October 28 -November 2, 2006. 2006</date>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Cooperative and group testing in verification of dynamic composite web services</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">28th International Computer Software and Applications Conference (COMPSAC 2004), Design and Assessment of Trustworthy Software-Based Systems</title>
		<meeting><address><addrLine>Hong Kong, China, Proceedings</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-09-30">27-30 September 2004. 2004</date>
			<biblScope unit="page" from="170" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Testing service composition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bucchiarone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Melgratti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Severoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Argentine Symposium on Software Engineering</title>
		<meeting>the 8th Argentine Symposium on Software Engineering<address><addrLine>ASSE</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A framework for QoS-aware binding and re-binding of composite Web services</title>
		<author>
			<persName><forename type="first">G</forename><surname>Canfora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Di Penta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Esposito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Villani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Systems and Software</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An approach for QoS-aware service composition based on genetic algorithms</title>
		<author>
			<persName><forename type="first">G</forename><surname>Canfora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Di Penta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Esposito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Villani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic and Evolutionary Computation Conference</title>
		<meeting><address><addrLine>Washington DC, USA; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">June 25-29, 2005. 2005</date>
			<biblScope unit="page" from="1069" to="1075" />
		</imprint>
	</monogr>
	<note>GECCO 2005, Proceedings</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V</forename><surname>Binder</surname></persName>
		</author>
		<title level="m">Testing Object-Oriented Systems: Models, Patterns, and Tools</title>
		<meeting><address><addrLine>Reading</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley Publishing Company</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Coyote: An XML-based framework for Web services testing</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th IEEE International Symposium on High-Assurance Systems Engineering (HASE 2002)</title>
		<meeting><address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-10-25">23-25 October 2002. 2002</date>
			<biblScope unit="page" from="173" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The audition framework for testing Web services interoperability</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bertolino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Polini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">st EUROMICRO Conference on Software Engineering and Advanced Applications (EUROMICRO-SEAA 2005)</title>
		<meeting><address><addrLine>Porto, Portugal; Los Alamitos</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2005-09-03">30 August -3 September 2005. 2005</date>
			<biblScope unit="page" from="134" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Data flow testing of service-oriented workflow applications</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Tse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">30th International Conference on Software Engineering (ICSE 2008)</title>
		<meeting><address><addrLine>Leipzig, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">May 10-18, 2008. 2008</date>
			<biblScope unit="page" from="371" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Data flow-based validation of web services compositions: Perspectives and examples</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bartolini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bertolino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Marchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Parissis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Architecting Dependable Systems</title>
		<editor>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>De Lemos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Di Giandomenico</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Muccini</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Gacek</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vieira</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A faceted approach to service specification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Walkerdine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sawyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dobson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Onditi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Internet and web Applications and Services (ICIW 2007)</title>
		<meeting><address><addrLine>Mauritius</addrLine></address></meeting>
		<imprint>
			<publisher>Le Morne</publisher>
			<date type="published" when="2007">May 13-19, 2007. 2007</date>
			<biblScope unit="page">20</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Speaking a common language: A conceptual model for describing service-oriented systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Di Nitto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Di Penta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Distante</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zuccalà</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICSOC 2005</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Benatallah</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Casati</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Traverso</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3826</biblScope>
			<biblScope unit="page" from="48" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Using acceptance tests as a support for clarifying requirements: A series of experiments</title>
		<author>
			<persName><forename type="first">F</forename><surname>Ricca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Torchiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Di Penta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Mariano Ceccato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information and Software Technology</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Fit for Developing Software: Framework for Integrated Tests</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mugridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cunningham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Contract-based testing for web services</title>
		<author>
			<persName><forename type="first">G</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">st Annual International Computer Software and Applications Conference (COMPSAC 2007)</title>
		<meeting><address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-07-27">24-27 July 2007. 2007</date>
			<biblScope unit="page" from="517" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Object-Oriented Software Construction, 2nd edn</title>
		<author>
			<persName><forename type="first">B</forename><surname>Meyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Towards automating regression test selection for Web services</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ruth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on World Wide Web, WWW 2007</title>
		<meeting>the 16th International Conference on World Wide Web, WWW 2007<address><addrLine>Banff, Alberta, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">May 8-12, 2007. 2007</date>
			<biblScope unit="page" from="1265" to="1266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Towards automatic regression test selection for Web services</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ruth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Loup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Horton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Gallet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">st Annual International Computer Software and Applications Conference (COMPSAC 2007)</title>
		<meeting><address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-07">July 2007. 2007</date>
			<biblScope unit="page" from="729" to="736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A safe, efficient regression test selection technique</title>
		<author>
			<persName><forename type="first">G</forename><surname>Rothermel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Harrold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Softw. Eng. Methodol</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="173" to="210" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">WebSob: A tool for robustness testing of web services</title>
		<author>
			<persName><forename type="first">E</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">29th International Conference on Software Engineering (ICSE 2007)</title>
		<meeting><address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">May 20-26, 2007. 2007</date>
			<biblScope unit="page" from="65" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Automated testing and response analysis ofweb services</title>
		<author>
			<persName><forename type="first">E</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2007 IEEE International Conference on web Services (ICWS 2007)</title>
		<meeting><address><addrLine>Salt Lake City, Utah, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">July 9-13, 2007. 2007</date>
			<biblScope unit="page" from="647" to="654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">JCrasher: an automatic robustness tester for Java</title>
		<author>
			<persName><forename type="first">C</forename><surname>Csallner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Smaragdakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Softw. Pract. Exper</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1025" to="1050" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Testing of Java Web services for robustness</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Milanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wonnacott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM/SIGSOFT International Symposium on Software Testing and Analysis</title>
		<meeting>the ACM/SIGSOFT International Symposium on Software Testing and Analysis<address><addrLine>Boston, Massachusetts, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-07-11">2004. July 11-14, 2004. 2004</date>
			<biblScope unit="page" from="23" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Service composition (re)Binding driven by application-specific qoS</title>
		<author>
			<persName><forename type="first">G</forename><surname>Canfora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Di Penta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Esposito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Perfetto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Villani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICSOC 2006</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Dan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Lamersdorf</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">4294</biblScope>
			<biblScope unit="page" from="141" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Fault injection for the masses</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Voas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="129" to="130" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Generating test cases for Web services using data perturbation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Offutt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIG-SOFT Softw. Eng. Notes -SECTION: Workshop on testing, analysis and verification of Web services (TAV-WEB)</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Software Testing Techniques, 2nd edn</title>
		<author>
			<persName><forename type="first">B</forename><surname>Beizer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>International Thomson Computer Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Ws-fit: A tool for dependability analysis of Web services</title>
		<author>
			<persName><forename type="first">N</forename><surname>Looker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Munro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 28th International Computer Software and Applications Conference (COMP-SAC 2004), Design and Assessment of Trustworthy Software-Based Systems</title>
		<meeting>28th International Computer Software and Applications Conference (COMP-SAC 2004), Design and Assessment of Trustworthy Software-Based Systems<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-09-30">27-30 September 2004. 2004</date>
			<biblScope unit="page" from="120" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Testability of software in service-oriented architecture</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">30th Annual International Computer Software and Applications Conference (COMPSAC 2006)</title>
		<meeting><address><addrLine>Chicago, Illinois, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-09">September 2006. 2006</date>
			<biblScope unit="page" from="163" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Extending WSDL to facilitate Web services testing</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th IEEE International Symposium on High-Assurance Systems Engineering (HASE 2002)</title>
		<meeting><address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-10-25">23-25 October 2002. 2002</date>
			<biblScope unit="page" from="171" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Verification of Web services using an enhanced UDDI server</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Workshop on Object-Oriented Real-Time Dependable Systems</title>
		<meeting>the Eighth International Workshop on Object-Oriented Real-Time Dependable Systems</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="131" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Automatic conformance testing of web services</title>
		<author>
			<persName><forename type="first">R</forename><surname>Heckel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mariani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FASE 2005</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Cerioli</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3442</biblScope>
			<biblScope unit="page" from="34" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Towards contract-based testing of web services</title>
		<author>
			<persName><forename type="first">R</forename><surname>Heckel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lohmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electr. Notes Theor. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="145" to="156" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Dynamic reconfigurable testing of service-oriented architecture</title>
		<author>
			<persName><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">st Annual International Computer Software and Applications Conference (COMPSAC 2007)</title>
		<meeting><address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-07-27">24-27 July 2007. 2007</date>
			<biblScope unit="page" from="368" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">A QoS test-bed generator for web services</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bertolino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>De Angelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Polini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICWE 2007</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Baresi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Fraternali</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G.-J</forename><surname>Houben</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">4607</biblScope>
			<biblScope unit="page" from="17" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<pubPlace>Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Model-Based Generation of Testbeds for Web Services</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bertolino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>De Angelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Frantzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Polini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Test-Com/FATES 2008</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Suzuki</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Higashino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ulrich</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Hasegawa</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">5047</biblScope>
			<biblScope unit="page" from="266" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">SOA: Testing and self-checking</title>
		<author>
			<persName><forename type="first">G</forename><surname>Canfora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Di Penta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Keynote speech at the International Workshop on Web Services -Modeling and Testing</title>
		<imprint>
			<publisher>WS-MATE</publisher>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A scalable architecture for discovery and composition in P2P service networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Forestiero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mastroianni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Papadakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fragopoulou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Troisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zimeo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Grid Computing: Achievements and Prospects</title>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
