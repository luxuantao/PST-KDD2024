<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Instruction Set and Microarchitecture for Instruction Level Distributed Processing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Ho-Seop</forename><surname>Kim</surname></persName>
							<email>hskim@ece.wisc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">James</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">An Instruction Set and Microarchitecture for Instruction Level Distributed Processing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A09B41961C72DA226C3B8E28645B01B8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>An instruction set architecture (ISA) suitable for future microprocessor design constraints is proposed. The ISA has hierarchical register files with a small number of accumulators at the top. The instruction stream is divided into chains of dependent instructions (strands) where intra-strand dependences are passed through the accumulator. The general-purpose register file is used for communication between strands and for holding global values that have many consumers.</p><p>A microarchitecture to support the proposed ISA is proposed and evaluated. The microarchitecture consists of multiple, distributed processing elements. Each PE contains an instruction issue FIFO, a local register (accumulator) and local copy of register file. The overall simplicity, hierarchical value communication, and distributed implementation will provide a very high clock speed and a relatively short pipeline while maintaining a form of superscalar out-of-order execution.</p><p>Detailed timing simulations using translated program traces show the proposed microarchitecture is tolerant of global wire latencies. Ignoring the significant clock frequency advantages, a microarchitecture that supports a 4-wide fetch/decode pipeline, 8 serial PEs, and a twocycle inter-PE communication latency performs as well as a conventional 4-way out-of-order superscalar processor.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>During the past two decades, researchers and processor developers have achieved significant performance gains by finding and exploiting instruction level parallelism (ILP). Today, however, trends in technology, pipeline design principles, and applications all point toward architectures that rely less on increasing ILP and more on simpler, modular designs with distributed processing at the instruction level, i.e. instruction level distributed processing (ILDP) <ref type="bibr" target="#b26">[25]</ref>. Technology trends point to increasing emphasis on on-chip interconnects and better power efficiency. Microarchitects are pushing toward pipelined designs with fewer logic levels per clock cycle (exacerbat-ing interconnect delay problems and reducing sizes of single-cycle RAM) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b14">15]</ref>. Finally, design complexity has become a critical issue. In the RISC heyday of the mid-80s, the objective was a new processor design every two years; now it takes from four to six.</p><p>To study the full potential of future ILDP architectures, we are considering new instruction sets that are suitable for highly distributed microarchitectures. The goal is to avoid the encumbrances of instruction sets designed in a different era and with different constraints. This will enable us to study, in their simplest form, microarchitectures that are highly tolerant of interconnect delays, use a relatively small number of fast (high power) transistors, and support both very high clock frequencies and short pipelines. The resulting fast, lightweight processors will be ideal for chip multiprocessors supporting high throughput server applications <ref type="bibr" target="#b2">[3]</ref> and for general-purpose processor cores that can drive highly integrated systems supporting various consumer applications.</p><p>The overall microarchitecture we propose consists of pipelined instruction fetch, decode, and rename stages of modest width that feed a number of distributed processing elements, each of which performs sequential in-order instruction processing. The instruction set exposes instruction dependences and local value communication patterns to the microarchitecture, which uses this information to steer chains of dependent instructions (strands) to the sequential processing elements. Dependent instructions executed within the same processing element have minimum communication delay as the results of one instruction are passed to the next through an accumulator. Taken collectively, the multiple sequential processing elements implement multi-issue out-of-order execution.</p><p>For applications where binary compatibility may not be a major issue (e.g. in some embedded systems), a new instruction set may be used directly in its native form. However, for general-purpose applications, a requirement of binary compatibility is a practical reality that must be dealt with. For general purpose applications there are two possibilities, both involve binary translation. One method is to perform on-the-fly hardware translation similar to the methods used today by Intel and AMD when they convert x86 binaries to micro-operations. Such a translation re-quires somewhat higher-level analysis than simple instruction mapping, however. Hence, the second method relies on virtual machine software, co-designed with the hardware and hidden from conventional software. This software can map existing binaries to the new ILDP instruction set in a manner similar in concept to the method used by the Transmeta Crusoe processor <ref type="bibr" target="#b18">[19]</ref> and the IBM DAISY project <ref type="bibr" target="#b9">[10]</ref>. A very important difference is that here the binary translation does not require the complex optimizations and scheduling that are used for VLIW implementations. Rather, the hardware we propose will be capable of dynamic instruction scheduling, so translation will involve a straightforward mapping of instructions. Consequently, the emphasis during translation is on identifying instruction inter-dependences and on making register assignments that reduce intra-processor communication. Binary translation can be performed either by a special co-processor <ref type="bibr" target="#b5">[6]</ref> or by the main processor, itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Instruction Set and Microarchitecture</head><p>We begin with a brief description of the ILDP instruction set we propose. Following that is a description of the proposed microarchitecture. Then we discuss the specific features of both.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Instruction set overview</head><p>The proposed ISA uses a hierarchical register file. It has 64 general-purpose registers (GPRs) and 8 accumulators. We refer to the GPRs as registers R0-R63, and the accumulators as A0-A7. We focus here on the integer instruction set. Floating point instructions would likely use additional floating point accumulators, but would share the GPRs.</p><p>In any instruction, a GPR is either the source or destination, but not both; this is intended to simplify the renaming process. In addition, when an accumulator is used for the last time, i.e. becomes dead, this is specified in the instruction's opcode (possibly via a reserved opcode bit).</p><p>The instruction formats are given in Fig. <ref type="figure">1</ref>. Instructions may be either 16 bits (one parcel) or 32 bits (two parcels).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.1.1</head><p>Load/Store instructions The memory access instructions load or store an accumulator value from/to memory. These instructions may only specify one GPR and one accumulator (as with all instructions). All load/store instructions are one parcel and do not perform an effective address addition.</p><p>Ai &lt;-mem(Ai) Ai &lt;-mem(Rj) mem(Ai) &lt;-Rj mem(Rj) &lt;-Ai</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.1.2</head><p>Register instructions The register instructions typically perform an operation on the accumulator and either a GPR or an immediate value, and the result is placed back in the accumulator. However, some instructions place the result into a GPR. Typical register instructions follow.</p><p>Ai &lt;-Ai op Rj Ai &lt;-Ai op immed Ai &lt;-Rj op immed Rj &lt;-Ai Rj &lt;-Ai op immed</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.1.3</head><p>Branch/Jump instructions The conditional branch instructions compare the accumulator with zero or the contents of a GPR. All the usual predicates (&gt;, &lt;, &gt;=, &lt;=, ==, !=) can be used. Branch targets are program counter (P) relative. The indirect jump is through either the accumulator or a GPR. For jump and link, the return address is always stored to a GPR. P &lt;-P + immed; Ai pred Rj P &lt;-P + immed; Ai pred 0 P &lt;-Ai P &lt;-Rj P &lt;-Ai; Rj &lt;-P++</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.1.4</head><p>Example Figure <ref type="figure" target="#fig_0">2</ref> is a sequence of code from SPEC benchmark 164.gzip, as compiled for the Alpha ISA. It is one of the more frequently executed parts of the program. Some Alpha instructions map to multiple ILDP instructions. However, the total number of bytes for instructions is slightly reduced. The Alpha version requires 40 bytes, and the ILDP version requires 36 bytes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Microarchitecture</head><p>The concept behind the instruction set is that the dynamic program dependence graph can be decomposed into strands -chains of dependent instructions. Instructions in each strand are linked via an accumulator. The strands communicate with each other through the GPRs.</p><p>The strand per accumulator concept is reflected in the microarchitecture. Referring to Fig. <ref type="figure" target="#fig_1">3a</ref>, instructions are fetched, parceled, renamed, and steered to one of eight processing elements. Instructions will be fetched four words (16 bytes) at a time. However, in most cases these four words contain more than 4 instructions. After I-fetch, the remainder of the instruction decode/rename pipeline is four instructions wide. Parceling is the process of identifying instruction boundaries and breaking instruction words into individual instructions. One simplification we are considering is to have instructions start and end on a cache line (at least 8 words) boundary. This will avoid instruction words spanning cache line (and page) boundaries -an unnecessary complication. The renaming stage renames only GPRs. The accumulators are not renamed at this stage; they undergo a simpler type of renaming as a byproduct of steering to the sequential processing elements.</p><p>The steering logic directs strands of renamed instructions to one of eight issue FIFOs, depending on the accumulator to be used. Each FIFO feeds a sequential processing element with its own internal physical accumulator (Fig. <ref type="figure" target="#fig_1">3b</ref>). Any instruction that has an accumulator as an output, but not as an input, is steered to the first empty FIFO; consequently, the logical accumulator is renamed to the physical accumulator. Any later instruction that uses the same accumulator as an input is steered to the same FIFO. Whenever all the FIFOs are non-empty and a new accumulator is called for, the steering process either stalls, or uses a heuristic to choose a FIFO to use next. If a FIFO has a "dead" accumulator instruction at its tail, then instructions from a new strand can be steered into the FIFO. A good heuristic is to use the first such FIFO likely to go empty (e.g. the one with the fewest instructions).</p><p>The instructions in a FIFO form a dependence chain, and therefore will issue and execute sequentially. The instruction at the head of the FIFO passes through the GPR pipeline stage, reads its GPR value (if available), and moves into the issue register (IR). If the GPR value is not available, the instruction waits in the IR until the value becomes available. Hence, the IR is like a single reservation station with a single data value entry. When its GPR value is available, the instruction issues and begins execution. Fig. <ref type="figure" target="#fig_1">3b</ref> shows an ALU and an L1 cache as functional units; in practice there will also be a shifter, and some other units. There is no contention/arbitration for any of the replicated functional units. A sequential control unit drives the processing element. Note that the functional units can be single or multi-cycle, but do not require pipelining. Because accumulator values stay within the same processing element, they can be bypassed without additional delay. However, GPR values produced in one PE must be communicated to the others. This will take additional clock cycles. The network for communicating GPR values can be a bus, a ring, or point-to-point. As will be shown, the bandwidth requirements are very modest and performance is relatively insensitive to this latency. The PE in the figure has two write ports to the GPR file; this will avoid contention between the accumu-</p><formula xml:id="formula_0">if (n) do { c = crc_32_tab[((int)c ^ (*s++)) &amp; 0xff] ^ (c &gt;&gt; 8); } while (--n);</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>a) C source code</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Alpha assembly code</head><p>Equivalent register transfer notation ILDP code L1: ldbu t2, 0(a0)</p><formula xml:id="formula_1">L1: R2 &lt;-mem(R0) L1: A0 &lt;-mem(R0) subl a1, 1, a1 R1 &lt;-R1 -1 A1 &lt;-R1 -1 R1 &lt;-A1 lda a0, 1(a0) R0 &lt;-R0 + 1 A2 &lt;-R0 + 1 R0 &lt;-A2 xor t0, t2, t2 R2 &lt;-R2 xor R8 A0 &lt;-A0 xor R8 srl t0, 8, t0 R8 &lt;-R8 &lt;&lt; 8 A3 &lt;-R8 &lt;&lt; 8 R8 &lt;-A3 and t2, 0xff, t2 R2 &lt;-R2 and 0xff A0 &lt;-A0 and 0xff s8addq t2, v0, t2 R2 &lt;-8*R2 + R9 A0 &lt;-8*A0 + R9 ldq t2, 0(t2) R2 &lt;-mem(R2) A0 &lt;-mem(A0) xor t2, t0, t0 R8 &lt;-R2 xor R8 A0 &lt;-A0 xor R8 R8 &lt;-A0 bne a1, L1 P &lt;-L1, if (R1 != 0) P &lt;-L1, if (A1 != 0)</formula><p>b) Alpha assembly code, equivalent register transfer notation, and corresponding ILDP code We plan to replicate the (small) low-latency L1 data cache and use a replication network to keep the contents of all the L1 caches equal (within a 2 clock period window as values are communicated). The L1 cache is fed directly from the issue stage of the PE because the memory instructions do not perform effective address addi-tions. Because the PEs are sequential, issue bandwidth within a PE is not a critical resource as it is in a conventional superscalar processor, so issuing two instructions (in two cycles) for those load/stores that require address additions does not pose a performance problem. However, it does provide a performance advantage for those loads where an effective address addition is not needed (statistics are given in Section 4). Having the memory address available at issue time has other advantages; for example, store address queue checking can be done as part of the issue function, in much the same way as the Cray-1 does memory bank conflict checking at issue time <ref type="bibr" target="#b6">[7]</ref>. Block- Each PE has a copy of the store address queue for memory disambiguation (not shown in the figure). Every load instruction consults the queue for possible conflicts with preceding store instructions. If all previous store addresses are known and do not conflict with the load, the load instruction is allowed to issue. Store address queue entries are allocated prior to the steering stage. As store addresses are computed, the address bits (or, for simplicity, a subset of 8-16 bits) are communicated to the replicated store queues.</p><p>Both GPRs and accumulators need to be rolled back when there is an exception or a branch misprediction. A conventional reorder buffer-based recovery mechanism can be used for GPRs; the GPR rename map is restored to the exception/misprediction point. To recover accumulators, produced accumulator values are buffered by a FIFO inside a PE. In effect, this is a small history buffer. When an instruction retires, the previous older value of the instruction's accumulator is also retired from the accumulator value FIFO. Should there be an exception, the oldest entries in the accumulator value FIFOs (or architectural accumulators) are rolled back. Similar to the GPR rename map recovery, steering information is also rolled back from the reorder buffer. Recovery from a mispredicted branch is done similarly. Here accumulator steering information can be recovered either from branch checkpoints or by sequential roll back from the saved information in the reorder buffer entries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Discussion</head><p>As stated earlier, we are targeting a microarchitecture that will be simple and provide very high performance through a combination of a very fast clock and modest ILP. Because the clock cycle of an aggressive design depends on the details of every pipeline stage, we prefer not to use a few gross aspects of the design (e.g. bypasses, issue logic) to verify a quantitative clock cycle estimate. We prefer to let the simplicity stand as self-evident and defer clock cycle estimates until we have done some detailed, gate-level design. Table <ref type="table" target="#tab_1">1</ref> compares complexity of several of the key functions with a baseline superscalar processor (similar to the one we use in Section 4 for per-formance comparisons). The ILDP microarchitecture complexities are given on a per PE basis, because that is the complexity that will ultimately determine the clock cycle.</p><p>Variable length instructions are aimed at reducing the instruction footprint to permit better I-cache performance, especially if a small single-cycle L1 I-cache is used. Although it may seem un-RISC-like, variable length instructions were a hallmark of the original RISCs at Control Data and Cray Research. That a RISC should have singlelength instructions has intuitive appeal, but to some extent it was a 1980s reaction to the very complex multi-length instruction decoding required by the VAX. There is little real evidence that having only one instruction size is significantly better than having a small number of easily decoded sizes. It is entirely possible that the advantages of a denser instruction encoding and more efficient I-fetch bandwidth may outweigh the disadvantage of having to parcel a simple variable-width instruction stream <ref type="bibr" target="#b11">[12]</ref>. This is not a key part of our research, however, but we feel it is worth exploring, and if it appears that a single instruction size is the better approach, we can go back to all 32-bit instructions with relatively little effort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Strand Formation</head><p>The most important aspect of strand formation is assignment of values to GPRs and accumulators, because, in effect, these assignments drive strand formation itself. To understand the basic idea of accumulator-oriented register assignment it is helpful to consider important register usage patterns, see Fig. <ref type="figure">4</ref>.</p><p>We are interested in separating register values that have a relatively long lifetime and are used many times from those that are used only once or a small number of times in close proximity <ref type="bibr" target="#b12">[13]</ref>. In general, the former values should be placed in GPRs and the latter in accumulators. A useful heuristic is to find register values that are consumed multiple times by the same static instruction. These are defined to be static global register values and will be assigned to GPRs (Ri in the figure). All the other register values will be considered local and will be assigned to accumulators, Ak and An in the figure. If a local value is used only once, then it will never be placed in a GPR. However, if one of these local values is used by more than one consuming instruction, then a copy will be made to a GPR thereby communicating the value to other strands. These are referred to as communication globals.</p><p>If binary compatibility is not required, a static compiler can be used to generate programs in the native ILDP ISA. The compiler will allocate temporary register values to accumulators while keeping the rest in the GPRs. The compiler performs this non-conventional register allocation based on register usage and lifetime analysis.</p><p>In our research, dynamic binary translation is used to form strands. Currently we are using Alpha instruction binaries as the source ISA for translation. For our initial studies, we are analyzing simulator-generated instruction traces, but in the future we plan to use the basic method in <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b18">19]</ref>, where interpretation is first used to produce profile data that is fed to a translator.</p><p>Given a code sequence and the above profile information that identifies static global values, strand formation is implemented via a single-pass linear scan of instructions to be translated; currently we do not perform code reordering during translation. For this discussion, we assume the source instruction set is RISC-like (Alpha in particular), with two source registers and one destination register, and simple addressing modes. At any given point in the scan, some register values are held in accumulators and others are held in GPRs.</p><p>When the scan reaches an instruction that has no input value currently assigned to an accumulator, it begins a new strand. If an instruction has a single input value assigned to an accumulator, then the same accumulator is used as the instruction's input, and the instruction is added to the producer's strand. If there are two input values assigned to accumulators, then two strands are intersecting. At this point, one of the strands is terminated by copying its accumulator into a GPR (to be communicated to the other strand). The other strand continues with the already-assigned accumulator and the just-assigned GPR as inputs. To decide which strand to terminate, a good heuristic is to follow the strand that is longer, up to that point, to avoid introducing the communication latency into the already longer strand.</p><p>If an instruction has its output assigned to a static global register (or has no output value) the strand is terminated. If the new strand requires an accumulator when all the accumulators are live, then one of the live strands is terminated by copying its accumulator into a GPR. We choose the longest active strand as the victim. This tends to balance the lengths of the strands in the FIFOs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example</head><p>We complete this section with a continuation of the code example given in Section 2.1.4. Four accumulators are used (A0 through A3), so the instructions are steered to four different processing elements (FIFOs) as shown in Fig. <ref type="figure">5</ref>. The strands are relatively independent, except where two strands converge to form inputs to the second xor. For this short code sequence, 14 instructions are issued in six clock cycles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>This section contains experimental evaluation of the instruction set properties and microarchitecture design decisions made in the previous sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Simulation methodology</head><p>To evaluate the proposed ILDP instruction set and microarchitecture, we first developed a functional simulator, which will be referred to as the profiler to distinguish it from the timing simulator. The profiler runs Alpha 21264 programs and profiles the dynamic register value usage. If a load/store instruction uses a non-zero immediate field (i.e. requires an address add), then the instruction is split into two instructions for address calculation and memory access. Alpha conditional move instructions require three source operands and are also split into two instructions. Note that the Alpha 21264 processor similarly splits conditional moves into two microinstructions <ref type="bibr" target="#b17">[18]</ref>. Static global registers are first identified using the heuristic of selecting all registers that are consumed multiple times by the same static instruction. Strands are then identified and accumulators and communication globals are assigned using the method described in the previous section. Simulation tools were built on top of the SimpleScalar toolset 3.0B <ref type="bibr" target="#b3">[4]</ref>. The profiler maps the strand-identified Alpha traces into ILDP traces and feeds the timing simulator. The timing simulator models the proposed microarchitecture and executes translated traces of ILDP instructions.</p><formula xml:id="formula_2">Issue cycle FIFO 0: A0 &lt;-mem(R0) 0 A0 &lt;-A0 xor R8 1 A0 &lt;-A0 and 0xff 2 A0 &lt;-8*A0 + R9 3 A0 &lt;-mem(A0) 4 A0 &lt;-A0 xor R8 5 R8 &lt;-A0 6 FIFO 1: A1 &lt;-R1 -1 0 R1 &lt;-A1 1 P &lt;-L1, if (A1 != 0) 2 FIFO 2: A2 &lt;-R0 + 1 0 R0 &lt;-A2 1 FIFO 3: A3 &lt;-R8 &lt;&lt; 8 1 R8 &lt;-A3<label>2</label></formula><p>We selected nine programs from the SPEC 2000 integer benchmarks compiled at the base optimization level (-arch ev6 -non_shared -fast). The compiler flags are same as those reported for Compaq AlphaServer ES40 SPEC 2000 benchmark results. DEC C++ V.6.1-027 (for 252.eon) and C V.5.9-005 (for the rest) compilers were used on Digital UNIX 4.0-1229. The test input set was used and all programs were run to completion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Strand Characteristics</head><p>Table <ref type="table">2</ref> contains some general statistics from the Alpha traces. More than half of the dynamic instructions have zero or one input register operand. Loads, conditional branches, and integer instructions with an immediate operand belong to this category. This statistic implies the data dependence graphs are rather "thin", with relatively little inter-strand communication. We also note there are substantial numbers of load and store instructions that do not require address calculation. With the proposed ILDP instruction set, these instructions can bypass the address addition and be sent to the data cache directly.</p><p>We also collected data regarding types of register values: static global, communication global, and local. Fig. <ref type="figure">6</ref> shows the fraction of values for each of the three classes (and those that have no consumers). Most values produced are locals (about 70%). Since these values are used only once, they do not have to leave their processing element and do not consume GPR bandwidth. Only about 20% of the values have to be placed in global registers (which suggests relatively low global register write bandwidth). Finally, 10% of produced values are never used. Some of these come from high-level program semantics; for example, a function's return value or some of its input arguments might not be used, depending on the program control flow. Also aggressive compiler optimizations, e.g. hoisting instructions above branches, sometimes result in unused values. Fig. <ref type="figure">7</ref> shows the lengths of strands measured in both Alpha and ILDP instructions. Average strand size is 3.85 in ILDP instructions or 2.54 Alpha instructions. There are many single-instruction strands (SIS in the figure) that do not contribute much to the total number of instructions but affect the average strand size significantly. These single-instruction strands include unconditional branch and jump instructions, and instructions whose produced value is not used. An important characteristic of the singleinstruction strands is that they can be steered to any FIFO; no other instruction depends on them. If the singleinstruction strands are ignored, the average size of strands is 4.62 in ILDP instructions and 3.04 in Alpha instructions.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2 Benchmark program properties</head><p>It is also interesting to see how strands end (Figure <ref type="figure">8</ref>). About 35 to 70% of the strands have a "natural" endingdependence chains leading to conditional branch resolution and store address/value calculation. About 20 to 45% produce communicated globals.</p><p>Finally we look at the impact of using two instruction sizes in translated ILDP ISA traces. Fig. <ref type="figure">9</ref> shows that on a dynamic basis, single parcel instructions account for 73 to 85% of total ILDP instructions, resulting in an average of 2.39 bytes per instruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Performance Results</head><p>Timing simulations are trace-driven. Because of different instruction sizes, it was easiest to simply assume an ideal I-cache for both the baseline superscalar and the ILDP microarchitecture. (All nine Alpha benchmark programs with the test input set have an L1 I-cache miss rate less than 0.7% with a 2-way set-associative, 32KB, 64-byte line size I-cache; less than 3.8% for an 8KB Icache). We also believe the performance results from the trace-driven simulations will closely track those of a true dynamically translated system because program execution is dominated by small number of repeating strands in most cases. Fig. <ref type="figure" target="#fig_4">10</ref> shows more than 95% of total executed instructions belong to the strands that repeat more than 1000 times.</p><p>Simulator configurations are summarized in Table <ref type="table" target="#tab_4">3</ref>.    Note that in keeping with the philosophy of smaller/faster memory structures, the L1 caches in the proposed microarchitecture are one quarter the size of the superscalar counterpart. The latency difference of one cycle results from the ILDP microarchitecture not having an address addition in the load path (as described previously); for those loads that require an add, the latencies are effectively the same.</p><p>Because the two microarchitectures being simulated have different ISAs, Instructions Per Cycle (IPC) is not a good metric for comparing performance. Instead the total number of cycles is used.</p><p>The results show that the proposed microarchitecture performs approximately as well as a conventional 4-way out-of-order superscalar processor ignoring any clock frequency advantage, which, based on Table <ref type="table" target="#tab_1">1</ref> and the smaller data cache should be considerable.</p><p>More importantly, the proposed microarchitecture is tolerant of global communication latency. There is only a 2 to 7 percent performance degradation as communication latency increases from 0-cycles to 2-cycles. In most cases global communication latency is not imposed on the critical path by the dependence-based strand formation algorithm.</p><p>For 164.gzip and 186.crafty, the proposed microarchitecture with 0-cycle communication latency outperforms an 8-way out-of-order superscalar processor despite the reduced issue freedom of the proposed microarchitecture. This comes primarily from the reduced load latency for as many as 43.6% of loads where there is no need for an effective address addition.</p><p>To further understand implementation complexity issues, we collected statistics related to rename, steering, and global register bandwidths. Fig. <ref type="figure" target="#fig_0">12</ref>, 13 show the global register rename bandwidths per cycle. With a fourwide pipeline, over 95% of the time three or fewer global register mappings are read, and over 90% of the time only zero or one register mapping is updated. This suggests that three read ports and one write port in the mapping table will likely be sufficient if we want to add the complexity of adding stall logic.</p><p>A significant complexity issue is the number of write ports to the GPR file. Using accumulators for local values greatly reduces the required GPR bandwidth. Collected GPR write bandwidth statistic closely follows Fig. <ref type="figure" target="#fig_1">13</ref>; it shows one register write port is enough more than 95% of time. Hence, if we are willing to add arbitration for a single write port, then the GPR can be reduced to a single Although the steering logic is simplified by only considering accumulator names in making steering decisions, the number of instructions steered to any one FIFO can also affect complexity. We measured the number of ILDP instructions steered to the same FIFO during the same cycle. The results in Fig. <ref type="figure" target="#fig_7">14</ref> show that two or fewer instructions are steered to the same FIFO over 82% of the time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>The instruction set is very much inspired by the S. Cray scalar ISAs (just as the 1980s microprocessor RISCs were). However, in a sense, we follow the Cray ISAs more closely than the microprocessor-based RISCs. In particular, we use hierarchical register files with a very small file at the top of the hierarchy, variable length instructions, and in-order instruction issue (albeit within individual processing elements). Even though the technology was quite different when Cray's designs were undertaken, the issues of interconnect delays, power consumption, and design complexity were of critical importance, just as they are today, and will be in the future. In effect, the proposed ILDP ISA is a cross product of two Cray-2 designs. One is an abandoned Cray-2 design <ref type="bibr" target="#b7">[8]</ref> that had a single re-named accumulator and a general register file of 512 elements. The completed Cray-2 design [9] had 8 integer registers, 64 lower level registers, and used conventional 3 operand instructions.</p><p>The ZS-1 <ref type="bibr" target="#b25">[24]</ref> was an early superscalar design with instructions issuing simultaneously from two FIFOs, motivated by issue logic simplicity. The RS/6000 <ref type="bibr" target="#b1">[2]</ref> used a similar design. In <ref type="bibr" target="#b21">[22]</ref> a dependence-based microarchitecture that issues instructions from multiple FIFOs was proposed. That work, and others <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b10">11]</ref> proposed clustered microarchitectures to localize register communication. Trace processors <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b28">27]</ref> are another form of distributed microarchitecture, with each processing element being a simple superscalar processor. Trace processors also support a hierarchy of register files for local and global communication. Similarly, the multiscalar paradigm <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b27">26]</ref> was designed with a goal of processor scalability and used a number of innovative distributed processing features. The PEWS mechanism <ref type="bibr" target="#b16">[17]</ref> also uses dependencebased instruction steering but uses versioning for both registers and memory.</p><p>RAW architecture <ref type="bibr" target="#b19">[20]</ref> and Grid Processor Architecture <ref type="bibr" target="#b20">[21]</ref> propose network-connected tiles of distributed processing elements running programs compiled for new ISAs that expose underlying parallel hardware organization. Both architectures are targeted to achieve high ILP on scalable hardware. As such, both are sensitive to communication latency and depend heavily on the compiler. In contrast, our aim is to achieve high performance in general purpose applications with a combination of a very high clock frequency, moderate ILP and a relatively conventional compiler target.</p><p>IBM DAISY <ref type="bibr" target="#b9">[10]</ref> and Transmeta Crusoe <ref type="bibr" target="#b18">[19]</ref> use dynamic binary translation to run legacy software on the hardware that executes different instruction set. Ebcioglu et al. <ref type="bibr" target="#b9">[10]</ref> showed the translation overhead is negligible. Both use VLIW as underlying implementation; as a result, the run-time software performs extensive instruction rescheduling to achieve desirable ILP on in-order VLIW implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Research</head><p>For future processors, we propose an instruction set that exposes inter-instruction communication and is targeted at a distributed microarchitecture with both short pipelines and high frequency clocks. A primary goal is high performance by using a small number of logic transistors. This is counter to the conventional trend that uses instruction sets that expose instruction independence; use very long (deep) pipelines, and high logic transistor counts. The major challenge is not to think of enhancements that consume transistors and yield small incremental performance gains, but to develop an overall paradigm that achieves high performance through simplicity.</p><p>The overall microarchitecture we propose consists of a number of distributed processing elements, each of which is a simple in-order pipeline. By using an accumulatorbased instruction set, the hardware implementation can steer chains of dependent instructions, "strands", to the simple in-order issue processing elements. In aggregate, the multiple in-order processing elements enable superscalar out-of-order execution as each of the processing elements adapts to the delays it encounters.</p><p>In this paper we have demonstrated that a distributed microarchitecture is capable of IPC performance levels that are roughly equivalent to a homogeneous 4-to-8-way superscalar processor. Most of the processing stagesrenaming, register access, issuing, bypassing, data cache - The distributed microarchitecture has other advantages that have not been discussed thus far. First, it will be amenable to multiple clock domains, which may be asynchronous with respect to one another. This is a very important feature for an aggressively clocked implementation where clock skew is critical. Second, it is also amenable to microarchitecture-level clock-and power-gating. Some of the processing elements can be gated off when not needed to save power.</p><p>In the future we plan to explore the proposed ISA and microarchitecture greater detail. First, we plan to perform a gate level design of the integer proportion of the proposed processor. This will validate claims of simplicity. Second, we plan to implement a binary translation infrastructure to allow on-the-fly translation of existing program binaries. Then, we will be able to provide accurate overall performance estimates that will demonstrate the feasibility of this overall approach.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Example program segment from benchmark 164.gzip</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. The distributed processor and detail of processing element</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 .Figure 4 .</head><label>54</label><figDesc>Figure 5. Issue timing of the example code</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7 T yp e s o f p r o d u ce d r e g is te r valu eFigure 6 .</head><label>76</label><figDesc>Figure 7. Average strand lengths</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 10 .</head><label>10</label><figDesc>Figure 10. Cumulative strand re-use</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 Figure 9 .</head><label>89</label><figDesc>Figure 8. Strand end</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 11 .Figure 13 .</head><label>1113</label><figDesc>Figure 11. Normalized number of cycles with the 4-way with superscalar processor as the baseline</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 14 .</head><label>14</label><figDesc>Figure 14. Number of instructions steered to the same FIFO at the same cycle</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Instruction formats. Instructions are either 1 parcel (2 bytes) or 2 parcels (4 bytes).</head><label></label><figDesc></figDesc><table><row><cell>7</cell><cell>3</cell><cell>6</cell><cell></cell></row><row><cell cols="2">Opcode Ai</cell><cell>Rj</cell><cell></cell></row><row><cell cols="3">re g is te r fo rm a t</cell><cell></cell></row><row><cell>7</cell><cell>3</cell><cell>6</cell><cell></cell></row><row><cell cols="2">Opcode Ai</cell><cell>imm ed</cell><cell></cell></row><row><cell cols="3">s ho rt imm e d ia te fo rm a t</cell><cell></cell></row><row><cell>7</cell><cell>3</cell><cell>6</cell><cell>16</cell></row><row><cell cols="2">Opcode Ai</cell><cell>Rj</cell><cell>imm ed</cell></row><row><cell cols="3">lo n g im m e dia t e fo rm a t</cell><cell></cell></row><row><cell>Figure 1.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 . Complexity comparison: ILDP processor vs. conventional out-of-order superscalar processor</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell>ILDP microarchitecture</cell><cell>4-way out-of-order superscalar</cell></row><row><cell>Parcel stage</cell><cell>Yes (if 2 inst. Lengths are used)</cell><cell>No</cell></row><row><cell>Decode bandwidth</cell><cell>4 instructions per cycle</cell><cell>4 instructions per cycle</cell></row><row><cell>Rename bandwidth</cell><cell>Total 4 read or write ports to map table</cell><cell>Total 12 read or write ports to map table</cell></row><row><cell>Steering logic</cell><cell>Simple, based on accumulator number</cell><cell>Complex dependence-based heuristic (if clustered)</cell></row><row><cell>Issue logic</cell><cell>Sequential in-order issue</cell><cell>4-way out-of-order issue from 128-entry RUU</cell></row><row><cell>Register file</cell><cell>2 write ports, 1 read port</cell><cell>4 write ports, 8 read ports</cell></row><row><cell>Bypasses</cell><cell>N x 2; for N functional units in a PE</cell><cell>M x 8; for M total functional units (M &gt; N)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 . Simulator configurations</head><label>3</label><figDesc></figDesc><table><row><cell></cell><cell>100%</cell><cell>c ommunic ation</cell></row><row><cell></cell><cell></cell><cell>global</cell></row><row><cell></cell><cell>80%</cell><cell>s tatic global</cell></row><row><cell>S tra nd e nd (%)</cell><cell>20% 40% 60%</cell><cell>no us er no output (inc l. jumps ) s tore</cell></row><row><cell></cell><cell></cell><cell>c onditional</cell></row><row><cell></cell><cell>0%</cell><cell>branc h</cell></row><row><cell></cell><cell>1 6 4 . g z ip 1 7 5 . v p r 1 7 6 . g c c 1 8 1 . m c f 1 8 6 . c r a f t y 1 9 7 . p a r s e r 2 5 2 . e o n 2 5 4 . g a p 3 0 0 . t w o lf</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgements</head><p>We would like to thank Timothy H. Heil and Martin J. Licht for discussions and S. Subramanya Sastry for help on the initial version of the profiling simulator. This work is being supported by SRC grants 2000-HJ-782 and 2001-HJ-902, NSF grants EIA-0071924 and CCR-9900610, Intel and IBM.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">V</forename></persName>
		</author>
		<title level="m">Clock Rate vs. IPC: The End of the Road for Conventional Microarchitectures</title>
		<imprint/>
	</monogr>
	<note>27 th Int. Symp. on</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The IBM RISC System/6000 Processor: Hardware Overview</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bakoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="page" from="12" to="23" />
			<date type="published" when="1990-01">Jan 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Piranha: A Scalable Architecture Based on Single-Chip Multiprocessing</title>
		<author>
			<persName><forename type="first">L</forename><surname>Barroso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">27 th Int. Symp. on Computer Architecture</title>
		<imprint>
			<date type="published" when="2000-06">Jun 2000</date>
			<biblScope unit="page" from="282" to="293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
		<idno>CS-TR-96-1308</idno>
		<title level="m">Evaluating Future Microprocessors: The SimpleScalar Toolset</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
		<respStmt>
			<orgName>Univ. of Wisconsin-Madison</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Cost-Effective Clustered Architecture</title>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. On Parallel Architectures and Compilation Techniques (PACT99)</title>
		<imprint>
			<date type="published" when="1999-10">Oct 1999</date>
			<biblScope unit="page" from="160" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Instruction Path Coprocessors</title>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">27 th Int. Symp. on Computer Architecture</title>
		<imprint>
			<date type="published" when="2000-06">Jun 2000</date>
			<biblScope unit="page" from="270" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Hardware Reference Manual</title>
		<author>
			<persName><surname>Cray-1 S Series</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980">1980</date>
			<publisher>Cray Research, Inc., Publication HR-808</publisher>
			<pubPlace>Chippewa Falls, WI</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">CRAY-2 Central Processor, unpublished document, circa</title>
		<ptr target="http://www.ece.wisc.edu/~jes/papers/cray2a.pdf" />
		<imprint>
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Hardware Reference Manual</title>
		<author>
			<persName><surname>Cray-</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>Cray Research, Inc</publisher>
			<pubPlace>Mendota Heights, MN</pubPlace>
		</imprint>
	</monogr>
	<note>Publication HR-2000</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dynamic Binary Translation and Optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ebcioglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Computers</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="529" to="548" />
			<date type="published" when="2001-06">Jun 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The Multicluster Architecture: Reducing Cycle Time Through Partitioning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Farkas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">30 th Int. Symp. on Microarchitecture</title>
		<imprint>
			<date type="published" when="1997-12">Dec 1997</date>
			<biblScope unit="page" from="149" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Computer Architecture: Pipelined and Parallel Processor Design</title>
		<author>
			<persName><forename type="first">M</forename><surname>Flynn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Jones and Bartlett Publishers</publisher>
			<biblScope unit="page" from="109" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Register Traffic Analysis for Streamlining Inter-Operation Communication in Fine-Grain Parallel Processors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">25 th Int. Symp. on Microarchitecture</title>
		<imprint>
			<date type="published" when="1992-12">Dec 1992</date>
			<biblScope unit="page" from="236" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The Expandable Split Window Paradigm for Exploiting Fine-Grain Parallelism</title>
		<author>
			<persName><forename type="first">M</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">19 th Int. Symp. on Computer Architecture</title>
		<imprint>
			<date type="published" when="1992-12">Dec 1992</date>
			<biblScope unit="page" from="58" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The Future of Wires</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="490" to="504" />
			<date type="published" when="2001-04">Apr 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">DIGITAL FX!32: Combining Emulation and Binary Translation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hookway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Herdeg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Technical Journal</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="12" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">PEWs: A Decentralized Dynamic Scheduler for ILP Processing</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kemp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Franklin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. On Parallel Processing</title>
		<imprint>
			<date type="published" when="1996-08">Aug 1996</date>
			<biblScope unit="page" from="239" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The Alpha 21264 Microprocessor</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kessler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="24" to="36" />
			<date type="published" when="1999-04">Mar/Apr 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<author>
			<persName><forename type="first">A</forename><surname>Klaiber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Technology Behind Crusoe Processors</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Space-Time Scheduling of Instruction-Level Parallelism on a Raw Machine</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th Int. Conf. Architectural Support for Programming Languages and Operating Systems</title>
		<imprint>
			<date type="published" when="1998-10">Oct 1998</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="46" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A Design Space Evaluation of Grid Processor Architectures</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nagarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">34 th Int. Symp. on Microarchitecture</title>
		<imprint>
			<date type="published" when="2001-12">Dec 2001</date>
			<biblScope unit="page" from="40" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Complexity-Effective Superscalar Processors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Palacharla</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m">th Int. Symp. on Computer Architecture</title>
		<imprint>
			<date type="published" when="1997-06">Jun 1997</date>
			<biblScope unit="page" from="206" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Trace Processors</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rotenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">30 th Int. Symp. on</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName><surname>Microarchitecture</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997-12">Dec 1997</date>
			<biblScope unit="page" from="138" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<title level="m">Astronautics ZS-1 Processor&quot;, 2 nd Int. Conf. Architectural Support for Programming Languages and Operating Systems</title>
		<imprint>
			<date type="published" when="1987-10">Oct 1987</date>
			<biblScope unit="page" from="199" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Instruction-Level Distributed Processing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="59" to="65" />
			<date type="published" when="2001-04">Apr 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multiscalar Processors</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">22 nd Int. Symp. on</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Improving Superscalar Instruction Dispatch and Issue by Exploiting Dynamic Code Sequences</title>
		<author>
			<persName><forename type="first">S</forename><surname>Vajapeyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">24 th Int. Symp. on Computer Architecture</title>
		<imprint>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="1997-06">Jun 1997</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
