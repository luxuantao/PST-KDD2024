<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Particle swarm optimization of ensemble neural networks with fuzzy aggregation for time series prediction of the Mexican Stock Exchange</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Martha</forename><surname>Pulido</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Division of Graduate Stusies and Research</orgName>
								<orgName type="institution" key="instit1">Tijuana Institute of Technology</orgName>
								<orgName type="institution" key="instit2">Calzada Tecnologico s/n</orgName>
								<orgName type="institution" key="instit3">Fracc. Tomas Aquino</orgName>
								<address>
									<postCode>22379</postCode>
									<settlement>Tijuana</settlement>
									<region>BC</region>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Patricia</forename><surname>Melin</surname></persName>
							<email>pmelin@tectijuana.mx</email>
							<affiliation key="aff0">
								<orgName type="department">Division of Graduate Stusies and Research</orgName>
								<orgName type="institution" key="instit1">Tijuana Institute of Technology</orgName>
								<orgName type="institution" key="instit2">Calzada Tecnologico s/n</orgName>
								<orgName type="institution" key="instit3">Fracc. Tomas Aquino</orgName>
								<address>
									<postCode>22379</postCode>
									<settlement>Tijuana</settlement>
									<region>BC</region>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Oscar</forename><surname>Castillo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Division of Graduate Stusies and Research</orgName>
								<orgName type="institution" key="instit1">Tijuana Institute of Technology</orgName>
								<orgName type="institution" key="instit2">Calzada Tecnologico s/n</orgName>
								<orgName type="institution" key="instit3">Fracc. Tomas Aquino</orgName>
								<address>
									<postCode>22379</postCode>
									<settlement>Tijuana</settlement>
									<region>BC</region>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Particle swarm optimization of ensemble neural networks with fuzzy aggregation for time series prediction of the Mexican Stock Exchange</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9E0576FCC9B653C82BF658BD43FC344F</idno>
					<idno type="DOI">10.1016/j.ins.2014.05.006</idno>
					<note type="submission">Received 23 October 2013 Received in revised form 27 March 2014 Accepted 3 May 2014</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Ensemble neural network Particle swarm optimization Time series prediction</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes a hybrid method based on particle swarm optimization for designing 25 ensemble neural networks with fuzzy aggregation of responses to forecast complex time 26 series. The time series that was considered in this paper, to compare the hybrid approach 27 with traditional methods, is the Mexican Stock Exchange, and the results shown are for the 28 optimization of the structure of the ensemble neural network with type-1 and type-2 fuzzy 29 logic integration. Simulation results show that the optimized ensemble neural network 30 approach produces good prediction of the Mexican Stock Exchange.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>A time series is a sequence of data points, measured typically at successive points in time and spaced at uniform time intervals <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b10">11]</ref>. Examples of time series are the daily closing value of the Mexican Stock Exchange. Time series are very frequently plotted via line charts. Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy and communications engineering.</p><p>Stock fund managers and financial analysts attempt to predict price activity in the stock market on the basis of either their professional knowledge or stock analyzing tools, in order to obtain gains in prices in the stock market.</p><p>For more than one decade, time series models have also been applied to solve various domain problems, such as financial forecasting.</p><p>In this paper the design of a neural network ensemble with the Particle Swarm Optimization algorithm (PSO) and its integration with type-1 and type-2 fuzzy systems, along with simulation results for the prediction of the Mexican Stock Exchange are presented. In the literature there has been a lot of recent work in time series prediction <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b35">37,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b45">46]</ref>, which indicate the recent importance of the topic. Time series prediction with hybrid models has also been a hot topic in recent years <ref type="bibr" target="#b38">[40,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b42">43]</ref>. This paper shows the results of an optimized ensemble neural network and its fuzzy response aggregation for predicting the time series of the Mexican Stock Exchange <ref type="bibr" target="#b0">[1]</ref>. The PSO technique is used to optimize the neural network ensemble, as this can help in finding a good solution to a complex problem, which in this case is to find the best ensemble neural network architecture to obtain the minimum forecast error for the time series mentioned above and to integrate the results with type-1 and type-2 fuzzy systems.</p><p>The main contribution of the paper is the proposed model of a neural network ensemble with type-2 fuzzy logic for response integration. In addition the particle swarm optimization method determines the number of modules of the neural network ensemble, number of layers and number of neurons per layer, and thus obtains the best architecture of the ensemble neural network. After obtaining this architecture the results from the modules are aggregated with type-1 and type-2 fuzzy systems, the inputs to the fuzzy system are the responses according to the number of network modules and this are the number of inputs of the fuzzy system. In this case, the maximum number of inputs is of 5 inputs and one output with two Gaussian membership functions and these are be granulated in two linguistic variables that are low and high forecast, and the forecast output will also be low or high and thereby obtain the forecast error for this series of the Mexican Stock Exchange. The proposed hybrid ensemble of neural networks with fuzzy response aggregation and its optimization with PSO is main contribution of the paper, as this hybrid approach has not been proposed previously in the literature for this kind of time series prediction problems. This paper considers the times series of the Mexican Stock Exchange because the problem is quite complex and the time series is chaotic in some periods of time and for this reason an ensemble model is justified. To consider different possible behaviors we have also previously worked with other time series, such as the Mackey-Glass s Â¼ 17; 34 and 68 and this series has chaotic behavior and as the value of s increases it will be more chaotic. Also the US/Dollar/MX Peso and the Dow Jones time series, which are quite complex, have been considered with ensembles and have produced good results in these cases <ref type="bibr" target="#b29">[30]</ref>.</p><p>We can find that there are similar ensemble approaches in the literature, but the main difference is that in the proposed approach in this paper we use type-2 fuzzy aggregation of responses in the ensemble, which is not found into other similar works. The idea of using type-2 fuzzy logic is the better manage the uncertainty in prediction. In addition, we also use PSO to optimize ensemble neural network, which is not so commonly used in ensembles.</p><p>We consider this as the new contribution, since the results obtained are better than other methods proposed in the literature.</p><p>The rest of the paper is organized as follows: Section 2 describes the architecture of the ensemble neural network, basic concepts of the proposed method, Section 3 describes the concepts particle swarm optimization, In Section 4 Optimization Ensemble Neural Network with Particle Swarm Optimization. Section 5 describes the concepts of fuzzy systems as methods of integration. In Section 6 the methodology for solving it are represented, Section 7 describes the simulation results of the proposed method, in Section 8 the comparison and the t student test are presented, and Section 9 shows the conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Time series and prediction</head><p>Time series are analyzed to understand the past and to predict the future, enabling managers or policy makers to make properly informed decisions. A time series analysis quantifies the main features in data and the random variation. These facts, combined with improved computing power, have made time series methods widely applicable in government, industry, and commerce. Time series models often form the basis of computer simulations. Some examples are assessing different strategies for control of inventory using a simulated time series of demand; comparing designs of wave power devices using a simulated series of sea states; and simulating daily rainfall to investigate the long-term environmental effects of proposed water management policies A time-series is defined as a sequence of observations on a set of values that takes a variable (quantitative) at different points in time. Time series are widely used today because organizations need to know the future behavior of certain relevant phenomena in order to plan, prevent, and so on, their actions. That is, to predict what will happen with a variable in the future from the behavior of that variable in the past <ref type="bibr" target="#b0">[1]</ref>. The data can behave in different ways over time, this may be a trend, which is the component that represents a long-term growth or decline over a period of time. A cycle is also possible, which refers to the wave motion that occurs around the trend, or may not have a defined or random manner; there are seasonal variations (annual, biannual, etc.), which are a behavior patterns that are repeated year after year at a particular time <ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref>.</p><p>The word ''prediction'' comes from the Latin prognosticum, which means I know in advance. Prediction is to issue a statement about what is likely to happen in the future, based on analysis and considerations of experiments. Making a forecast is to obtain knowledge about uncertain events that are important in decision-making <ref type="bibr" target="#b4">[5]</ref>. Time series prediction tries to predict the future based on past data, it take a series of real data x t Ã n, . . . x t Ã 2.0 x t Ã 1, x t and then obtains the prediction of the data x t + 1, x t + 2 . . . x n + n. The goal of time series prediction or its model is to observe the series of real data, so that future data may be accurately predicted <ref type="bibr" target="#b28">[29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Ensemble neural network</head><p>Artificial neural networks are inspired by the biological nervous system architecture, which consists of a large number of relatively simple neurons that work in parallel to facilitate rapid decision making <ref type="bibr" target="#b30">[32]</ref>.</p><p>A neural network is a system of parallel processors interconnected as a directed graph. Schematically each processing element (neurons) in the network is represented as a node. Its most important advantage is to solve problems that are too complex for conventional technologies, problems that have no solution algorithm and its solution algorithm is very difficult finding. Artificial neural networks are formed by a large number of neurons; these are not called artificial neurons but output nodes or units. Ensemble models are formed by a collection of neural networks with the idea of combining multiple decisions and achieving a better result. These ensemble models behave remarkably well, recently it has become a very hot topic in both the neural networks and machine learning communities <ref type="bibr" target="#b20">[21]</ref>, and has already been successfully applied to diverse areas such as face recognition <ref type="bibr" target="#b33">[35,</ref><ref type="bibr" target="#b18">19]</ref>, optical character recognition <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b27">28]</ref>, scientific image analysis <ref type="bibr" target="#b38">[40]</ref>, medical diagnosis <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b45">46]</ref>, seismic signals classification <ref type="bibr" target="#b34">[36]</ref>, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Training of the neural networks</head><p>In the literature there are many methods for training neural networks like, the gradient descendent method, Levenberg-Marquardt and others.</p><p>The Levenberg-Marquardt method can handle well ill conditioned matrices J T J by using the following equation:</p><formula xml:id="formula_0">h next Â¼ h now Ã J T J Ã¾ kI Ã1 g h<label>Ã°1Ã</label></formula><p>where k is some nonnegative value and g h 1 2 g for simplicity.For instance, we consider a trivial nonlinear model f(x k Ã h)</p><p>with two adjustable parameters p and q; i.e., h = (p, q) T . The objective is to find the optimal h â = (1, 10) that minimizes the following sum of squared errors.</p><formula xml:id="formula_1">EÃ°hÃ Â¼ X 10 kÂ¼1 Ã°t kÃ f Ã°x k ; hÃÃ 2<label>Ã°2Ã</label></formula><p>where t k is the desired output E is the objective function, and the Levenberg-Marquardt direction that is determined by using Eq. ( <ref type="formula" target="#formula_0">1</ref>) when k Â¼ 0:07 or any other particular value. Clearly, the Levenberg-Marquardt direction (in highlighted arrow) is an intermediate between the Gauss Newton direction Ã°k ! 0Ã and the steepest descendent direction Ã°k ! 1Ã.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Particle swarm optimization</head><p>Particle Swarm Optimization (PSO) is a bio-inspired optimization method proposed by Eberhart and Kennedy <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b24">25]</ref> in 1995. PSO is a search algorithm based on the behavior of biological communities that exhibits individual and social behavior <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>, and examples of these communities are groups of birds, schools of fish and swarms of bees <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b43">44]</ref>.</p><p>A PSO algorithm maintains a swarm of particles, where each particle represents a potential solution. In analogy with the paradigms of evolutionary computation, a swarm is similar to a population, while a particle is similar to an individual. In simple terms, the particles are ''flown'' through a multidimensional search space, where the position of each particle is adjusted according to its own experience and that of its neighbors. Let x i denote the position i in the search space at time step t; unless otherwise stated, t denotes discrete time steps. The position of the particle is changed by adding a velocity, m t (t), to the current position, i.e.</p><formula xml:id="formula_2">x i Ã°t Ã¾ 1Ã Â¼ x i Ã°tÃ Ã¾ v i Ã°t Ã¾ 1Ã<label>Ã°3Ã</label></formula><formula xml:id="formula_3">with x i (0) $ U(X min , X max ).</formula><p>It is the velocity vector the one that drives the optimization process, and reflects both the experimental knowledge of the particles and the information exchanged in the vicinity of particles.</p><p>For gbest PSO, the particle velocity is calculated as:</p><formula xml:id="formula_4">v ij Ã°t Ã¾ 1Ã Â¼ v ij Ã°tÃ Ã¾ c 1 r 1 Â½y ij Ã°tÃ Ã x ij Ã°tÃ; Ã¾c 2 r 2 Ã°tÃÂ½Å· j Ã°tÃ Ã x ij Ã°tÃ<label>Ã°4Ã</label></formula><p>where v ij (t) is the velocity of the particle i in dimension j at time step t; c 1 and c 2 are the positive acceleration constants used to scale the contribution of cognitive and social skills, respectively, yr 1j (t), yr 2j (t) $ U(0, 1) are random values in the range</p><formula xml:id="formula_5">[0, 1].</formula><p>The best personal position in the next time step t + 1 is calculated as:</p><formula xml:id="formula_6">y i Ã°t Ã¾ 1Ã Â¼ y i Ã°tÃ if f Ã°x i Ã°x i Ã°t Ã¾ 1ÃÃ P f y i<label>Ã°tÃÃ</label></formula><formula xml:id="formula_7">x i Ã°t Ã¾ 1Ã if f Ã°x i Ã°x i Ã°t Ã¾ 1ÃÃ &gt; f y i Ã°tÃÃ<label>Ã°5Ã</label></formula><p>where f : R nx ! R is the fitness function, as with EAs, the goal is measuring the fitness function closely corresponding to the optimal solution, for example the objective function quantifies the performance, or the quality of a particle (or solution).</p><p>The overall best position, y_ (i) (t) at time step t, is defined as: Å·Ã°tÃ y o Ã°tÃ; . . . ; y s Ã°tÃ f g f Ã°yÃ°tÃÃ Â¼ min f y o Ã°tÃ Ã° Ã; . . . f Ã°y s Ã°tÃÃ; f g Ã°6Ã</p><p>where n s is the total number of particles in the swarm, More importantly, the above equation defining and establishing Å· the best position is uncovered by either of the particles so far as this is usually calculated as the best personal best position. The global best position can also be selected from the particles of the current swarm, in which case it expressed as:</p><formula xml:id="formula_8">Å·Ã°tÃ Â¼ min f Ã°x o Ã°tÃÃ; . . . f Ã°x ns Ã°tÃÃ; f g<label>Ã°7Ã</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Fuzzy systems</head><p>According to <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b43">44]</ref>, fuzzy logic was conceived by Lotfi A. Zadeh in 1965, based on a fuzzy set that differs from the traditional sets considering now that the membership degree is define by a function that represents a membership, which evaluates the input, and according to some predefined rules, assigns the membership degree to a fuzzy set.</p><p>Fuzzy Set: Let X be a space of objects and x be a generic element of X. A classical set A, A # X, is defined as a collection of elements or objects x e X, such that each x can either belong or not belong to the set A. By defining a characteristic function for each element x in X, we can represent a classical set A by a set of ordered pairs (x, 0) or (x, 1) which indicates x R A or xA, respectively. Unlike the aforementioned conventional set, a fuzzy set expresses the degree to which an element belongs to a set. Hence the characteristic function of a fuzzy set is allowed to have values between 0 and 1, which denotes the degree of membership of an element in a given set. The basic structure of a fuzzy inference system consists of three conceptual components: a rule base, which contains a selection of fuzzy rules; a dictionary, which defines the membership functions used in the fuzzy rules; and a reasoning mechanism, which performs the inference produce (usually the fuzzy reasoning) <ref type="bibr" target="#b8">[9]</ref>.</p><p>According to <ref type="bibr" target="#b34">[36]</ref>, there is another class of fuzzy systems called type-2 fuzzy systems, which were also proposed b Q3 y</p><p>Zadeh. The reason to augment the original fuzzy systems is to consider higher levels of uncertainty, broadening their scope.</p><p>In type-2 fuzzy systems the membership functions can now return a range of values that varies depending on the uncertainty involved, not only in the input but also on the same membership function.</p><p>The structure of the type-2 fuzzy rules is the same as for the type-1 case because the distinction between type-2 and type-1 is associated with the nature of the membership functions. Hence, the only difference is that now some or all the sets involved in the rules are of type-2 <ref type="bibr" target="#b45">[46]</ref>.</p><p>As an example: Consider the case of a fuzzy set characterized by a Gaussian membership function with mean m and a standard deviation that can take values in [1r 1 , r 2 ], i.e.,</p><formula xml:id="formula_9">lÃ°xÃ Â¼ exp Ã1=2 x Ã m r h i 2 ; rÂ½r 1 ; r 2<label>Ã°8Ã</label></formula><p>Corresponding to each value of r we will get a different membership curve (as shown in Fig. <ref type="figure">1</ref>). So, the membership grade of any particular x(except x = m) can take any of a number of possible values depending upon the value of r i.e., the membership grade is not a crisp number, it is a fuzzy set. Fig. <ref type="figure">3</ref> shows the domain of the fuzzy set associated with x = 0.7; however, the membership function associated with this fuzzy set is not shown in the Fig. <ref type="figure">2</ref>.</p><p>Gaussian type-2 fuzzy set. A Gaussian type-2 fuzzy set is one in which the membership degree of every domain point is a Gaussian type-1 set contained in [0, 1].</p><p>Interval type-2 fuzzy set. An interval type-2 fuzzy set is one in which the membership degree of every domain point is a crisp set whose domain is some interval contained in [0, 1].</p><p>Footprint of uncertainty: The uncertainty in the primary memberships of a type-2 fuzzy set, Ã, consists of a bounded region that we call the ''footprint of uncertainty'' (FOU). Mathematically, it is the union of all primary membership functions <ref type="bibr" target="#b21">[22]</ref>.</p><p>Upper and lower membership functions. An ''upper membership function'' and a ''lower membership functions'' are two type-1 membership functions that are the bounds for the FOU of a type-2 fuzzy set Ã. The upper membership function is associated with the upper bound of the FOU(Ã). The lower membership function is associated with the lower bound of the FOU(Ã). Fig. <ref type="figure">1</ref>. Type-1 membership functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Operations of type-2 fuzzy sets</head><p>Union of type-2 fuzzy sets. The union of f A 1 and f A 2 is another type-2 fuzzy set, just as the union of type-1 fuzzy sets A 1 and A 2 is another type-1 fuzzy set. More formally, we have the following expression:</p><formula xml:id="formula_10">f A 1 [ f A 2 Â¼ Z x2X l e A 1 [ e A 2 Ã°xÃ=x<label>Ã°9Ã</label></formula><p>Intersection of type-2 fuzzy sets. The intersection of f A 1 and f A 2 is another type-2 fuzzy set, just as the intersection of type-1 fuzzy sets A 1 and f A 2 is another type-1 fuzzy set. More formally, we have the following expression:</p><formula xml:id="formula_11">f A 1 \ f A 2 Â¼ Z x2X l e A 1 \ e A 2 Ã°xÃ=x<label>Ã°10Ã</label></formula><p>Complement of a type-2 fuzzy set. The complement of a set is another type-2 fuzzy set, just as the complement of type-1 fuzzy set A is another type-1 fuzzy set. More formally we have:</p><formula xml:id="formula_12">f A 1 Â¼ Z x l e A 0 1 Ã°xÃ=x<label>Ã°11Ã</label></formula><p>where the prime denotes complement in the above equation. In this equation l e A 0 1 is the secondary membership function.</p><p>Type-2 fuzzy rules. Consider a type-2 FLS having r inputs x 1 2 X 1 ; . . . ; x r 2 X r and one output y e Y. As in the type-1 case, we can assume that there are M rules; but, in the type-2 case the 'th rule has the form:</p><formula xml:id="formula_13">R 1 : IF x 1 is Ã1 1 and . . . x p is e A 1 P ; THEN y is b Y 1 1 Â¼ 1; . . . M:<label>Ã°12Ã</label></formula><p>6. Optimization of the ensemble neural network with particle swarm optimization</p><p>The operation of the optimization algorithm by the swarm of particles is given by a sequence of steps, which are:</p><p>1. Generate the initial swarm.</p><p>2. Evaluate the particles of the swarm.</p><p>3. Updating the particle velocity.</p><p>4. Calculating new positions of the particles.</p><p>From steps 2-4, begins an iterative process until a stopping criterion is satisfied. In Fig. <ref type="figure">3</ref>, we can see the outline of the algorithm of particle swarm optimization.</p><p>To optimize the Ensemble Neural Network following the outline of the algorithm of particle swarm optimization, the first step is to create a swarm of particles, and to create the swarm we have to choose the representation of candidate solutions (particles), for which we choose a real representation.</p><p>Once we have the representation of candidate solutions (particles), set the number of variables to indicate the position of the particle or possible solution to our problem, number of the particle. Set the number of variables that will form the particle, the initial population is generated randomly within a set range for each variable according to upper and lower limits of the search space for each variable. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Model description</head><p>This section describes the proposed model for the neural network ensembles, the objective is to optimize the architecture of a neural network with the particle swarm optimization method.</p><p>Fig. <ref type="figure">3</ref> represents the Ensemble Neural Network Model, where we have first the historical data, then the optimization algorithm based on swarms means of particles determines the number of modules of the ensemble neural network, which can be from 1 to 5 modules, as well as the number of layers that this module, that could of from 1 to 3 and the number of neurons by layer that could be of 1 to 3. Then after the responses of neural network ensemble are obtained the integration is performed with type-1 and type-2 fuzzy systems. The input and output linguistic variables of the fuzzy system have Gaussian membership functions. The performance of the type-2 fuzzy integrators is analyzed under different levels of uncertainty to find out the best design of the membership functions for the rules of the fuzzy system. For the type-2 fuzzy integrator using 2 membership functions, which are called ''low prediction'' and ''high prediction'' for each of the inputs and the output of the fuzzy system. Membership functions are of Gaussian type and we deal with 3 footprint uncertainty sizes of 0.3, 0.4 and 0.5 to obtain a better prediction of the time series.</p><p>If we consider 5 modules in the ensemble then the fuzzy system will have 5 input linguistic variables and the rules used are determined according to the possible combinations according to the number of inputs and membership functions of the fuzzy system. Considering that have 5 inputs and two membership functions for each of the inputs then there are 32 possible combinations.</p><p>Each of the modules in the ensemble is a neural network and the calculations are performed as follows:</p><p>The net input x of a node is defined by the weighted sum of the incoming signals plus a bias term. For instance, the net input of the output of the node j is given as follows.</p><p>x j Â¼ X</p><formula xml:id="formula_14">i x ij Ã¾ x j ; x Â¼ f Ã° x j Ã Â¼ 1 1 Ã¾ expÃ°Ã x j Ã ;<label>Ã°13Ã</label></formula><p>where x i is the output of node i located in any of the previous layers, x ij is the weight associated with the link connecting nodes i and j, and x j is the bias of node j. Since the weights x ij are actually internal parameters associated with each node j changing the weights of the node will alter behavior of the node and in turn alter behavior of the whole backpropagation MLP.</p><p>A squared error measure for the pth input-output pair is defined as:</p><formula xml:id="formula_15">E P Â¼ X Ã°d k Ã x k Ã 2<label>Ã°14Ã</label></formula><p>Fig. <ref type="figure">3</ref>. Ensemble neural network model.</p><p>where d k is the desired output for the node x k is the actual output for the node when the input part of the pth data pair is presented.</p><p>In addition a fuzzy system is used as a response integrator for the ensemble. This means that the outputs of the modules (neural network) are the inputs to the fuzzy system (integrator of the responses). The global or total results are obtained by using the inference process in the fuzzy system.</p><p>The total result of the fuzzy integrator system is calculated with the following equation:</p><formula xml:id="formula_16">y Â¼ P n iÂ¼1 l i Ã°xÃdx P n iÂ¼1 l i Ã°xÃ ;<label>Ã°15Ã</label></formula><p>where x are the input data and l are the corresponding membership functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Methodology</head><p>This section describes the general architecture of the proposed ensemble neural network model. The aim of this work was to implement a PSO algorithm to optimize the neural network architectures, for each of the modules, number of neurons and number of layers and thus find an architecture for the neural network that produces the best results in each particular time series that is considered. Fig. <ref type="figure" target="#fig_0">4</ref> shows the overall architecture, where historical data for each time series prediction, in this case the Mexican Stock Exchange is used as input, and then the time series analyzed and in the next step the data provided to the modules, which are optimized with PSO in which the particle contains information of the ensemble neural network for the optimization. The particle gives us the number of modules, number of layers and number of neurons are then applied to the neural network ensemble and then these results of these modules are integrated with an integration method based on type-1 and type-2 fuzzy logic and finally obtain the prediction error. Derived from the monitoring of global trends and changes that have occurred in legislation, the MSE concluded with the conversion process, becoming a company whose shares are likely to be traded on the market stock exchange, with the initial public offering taking place on June 13 of 2008 with its shares representing its capital <ref type="bibr">[31]</ref>.</p><p>Data of the Mexican Stock Exchange time series: In this case 800 points are used, that correspond to a period from 11/09/ 05 to 01/15/09 where we plot in the x axis the historical data in this case the day and in the y axis the closing of the Mexican Stock Exchange (as shown in Fig. <ref type="figure">5</ref>). In the experiment 70% of the data were used for the ensemble neural network training and 30% to test the network <ref type="bibr">[31]</ref>.</p><p>After some tests were performed, another period of data from 04/08/08 to 05/09/11 for this series was also selected, where we plot in the x axis the historical data in this case day, and the y axis is the closing of the Mexican Stock Exchange (as shown in Fig. <ref type="figure">6</ref>).</p><p>For the optimization of the structure of the ensemble neural network a particle swarm optimization algorithm was used.</p><p>The structure of the swarm particle represents the structure of the ensemble.</p><p>The objective function is defined to minimize the prediction error as follows:</p><formula xml:id="formula_17">EM Â¼ X D iÂ¼1 ja i Ã x i j !, D<label>Ã°16Ã</label></formula><p>where a, corresponds to the predicted data depending on the output of the network modules, X represents real data, D the Number of Data points and EM is the total average prediction error.  The corresponding particle structure is shown in Fig. <ref type="figure">7</ref>.</p><p>Fig. <ref type="figure">7</ref> represents the particle structure to optimize the ensemble neural network, where the parameters that are optimized are the number of modules, number of layers, and number of neurons of the ensemble neural network. PSO determines the number of modules, number of layers and number of neurons per layer, that the neural network ensemble should have and that meets the objective to achieve a better Prediction error.</p><p>The parameters for the particle swarm optimization algorithm are: 100 Particles, 100 iterations, Cognitive Component (C1) = 2, Social Component (C2) = 2, Constriction coefficient of linear increase (C) = (0-0.9) and Inertia weight with linear decrease (W) = (0.9-0). We consider a number of 1-5 modules, number of layers of 1-3, number neurons of 1-30.</p><p>The network parameters used to train the neural network ensemble for each of the ensembles are 100 epochs, learning rate of = 0.01, the error goal 0.01, training method of Levenberg-Marquardt (trainlm), these parameters were used in this work because previous tests were performed and we managed to obtain a good prediction error with these parameters.</p><p>The parameters for the particle swarm optimization algorithm are: 100 particles, 100 iterations and these parameters were used because previously an optimization with a genetic algorithm was considered and to compare it with this method we used similar parameters, Cognitive Component (C1) = 2, Social Component (C2) = 2, Constriction coefficient of linear increase (C) = (0-0.9) and Inertia weight with linear decrease (W) = (0.9-0), these parameters were used since we did perform a manual testing and by changing the values and with these parameters we obtain a better prediction error also. We consider a number of 1-5 modules, number of layers of 1-3, neurons number of 1-30, as maximum number of modules, layers and neurons that had already previously been tested with 3 modules and increasing error gives us better prediction.</p><p>The aggregation of the responses of the optimized ensemble neural network is performed with type-1 and type-2 fuzzy systems. In this work a fuzzy system consisting of 5 inputs depending on the number of modules of the neural network ensemble and one output are used. Each input and output linguistic variable of the fuzzy system uses 2 Gaussian membership functions because the performance of the type-2 fuzzy aggregators is analyzed under different levels of uncertainty to find out the best design of the membership functions for the 32 rules of the fuzzy system with good results. Previous tests have been performed only with a three input fuzzy system, however the fuzzy system changes according to the responses of the neural network to the fuzzy system to give us better prediction error. In the type-2 fuzzy system we also change the levels of uncertainty to obtain the best prediction error.   Fig. <ref type="figure" target="#fig_4">9</ref> represents the possible 32 rules of the fuzzy system; we have 5 inputs in the fuzzy system with 2 membership functions, and outputs with 2 membership functions. These fuzzy rules are used for the type-1 and type-2 fuzzy systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Simulation results</head><p>In this section we present the simulation and test results obtained with the Particle swarm optimization algorithm applied in the design of the ensemble neural network for the Mexican Stock Exchange. A particle swarm algorithm was used to optimize the structure of an ensemble neural network and the best obtained architecture is represented in Fig. <ref type="figure" target="#fig_5">10</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1</head><p>Particle swarm results for the ensemble neural network.</p><p>Table <ref type="table">1</ref> shows the results of the optimization algorithm using particles for which 30 experiments were performed, but this table only shows the best 10 results, where the best obtained result was in the 6 wherein the prediction error was: 0.0089454. Fig. <ref type="figure" target="#fig_7">11</ref> shows the plot of real data against the predicted data generated by the ensemble neural network for time series number 1. Pink color<ref type="foot" target="#foot_1">1</ref> rep Q4 resents the real data and the green color represents prediction data.</p><p>Fuzzy integration is performed by implementing a type-1 fuzzy system in which the best result was in the experiment of row number 7 of Table <ref type="table">2</ref> with an error of: 0.1458.</p><p>Fuzzy aggregation is also performed by implementing a type-2 fuzzy system in which the results are as follows: for the best experiment with a degree of uncertainty of 0.3 a forecast error of 0.3685 was obtained, and with a degree of uncertainty of 0.4 a forecast error of 0.3960 was obtained and with a degree of uncertainty of 0.5 a forecast error of 0.3761 was obtained, as shown in Table <ref type="table" target="#tab_4">3</ref>.</p><p>Fig. <ref type="figure" target="#fig_9">12</ref> shows the architecture of the neural network obtained by the particle swarm optimization method. We used two layers in each module. In module 1, in the first layer we used 12 neurons and 11 neurons, in the second layer; in module 2 we used 6 neurons in the first layer and 18 neurons in the second. The optimization method using swarms of particles determines the number of neurons in the neural network ensemble. The Levenberg-Marquardt (LM) training method was used;</p><p>we also applied 3 delays to the network.</p><p>Table <ref type="table" target="#tab_5">4</ref> shows the particle swarm results (as shown in Fig. <ref type="figure" target="#fig_9">12</ref>), where the best prediction error is of 0.0079875, which is shown in row number two.</p><p>Fig. <ref type="figure" target="#fig_10">13</ref> shows the plot of real data against the predicted data generated by the ensemble neural network for time series number 2. The Pink color represents the real data and the green color represents the prediction data.</p><p>Fuzzy aggregation is performed by implementing a type-1 fuzzy system in which the best result was in the experiment of row number 2 of Table <ref type="table">5</ref> with an error of: 0.0952.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2</head><p>Results type-1 fuzzy aggregation of MSE for time series 1.</p><p>Fuzzy aggregation is also performed by implementing a type-2 fuzzy system in which the results for the best experiment were follows: with a degree of uncertainty of 0.3 yielded a forecast error of 0.1780, with a degree of uncertainty of 0.4 an error of 0.1750 and with a degree of uncertainty of 0.5 an error of 0.1829, as shown in Table <ref type="table">6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">Comparison of results</head><p>A comparison of results for this time series of the Mexican Stock Exchange for the period of 11/09/05 to 01/15/09 with the paper entitled: ''An Ensemble Neural Network Architecture with Fuzzy Response Integration for Complex Time Series Prediction'' <ref type="bibr" target="#b32">[34]</ref>, shows that the best result was using an ensemble neural network architecture with 1 layer using 3 delays.</p><p>The error obtained by the average integration was 0.0479, by the average weighted integration was 0.0519 and by fuzzy integration was 0.1094, respectively. In the same work the authors decided to implement an evolutionary approach to optimize the membership functions and rules of this system and the obtained error was of 0.045848. The genetic algorithm was applied to optimize the monolithic neural network for the Mexican Stock Exchange time series: 0.1092, (as shown in Fig. <ref type="figure" target="#fig_4">9</ref> and Table <ref type="table">1</ref>). In this paper the best result when applying the genetic algorithm to optimize the ensemble neural network was: 0.00112, (as shown in Fig. <ref type="figure" target="#fig_7">11</ref> and Table <ref type="table" target="#tab_5">4</ref>). This shows that our hybrid ensemble neural approach produces better results for this time series.</p><p>After a comparison of results for this time series of the Mexican Stock Exchange for the period of 11/09/05 to 01/15/09 with the paper entitled: ''A new Approach for Time Series Prediction Using Ensembles of ANFIS Models'' <ref type="bibr" target="#b29">[30]</ref>, where the best result was achieved when integration by weighted average was used (an error of 0.0123 was obtained). Also, in this paper with integration by average an error of 0.0127 was obtained, which shows a very similar result. In this case, no significant difference can be found. In the literature there are only two references to forecast the time series of the Mexican Stock Exchange, and this is why the comparison was made with only these two studies.   for Complex Time Series Prediction of the Mexican Exchange Prediction'' <ref type="bibr" target="#b31">[33]</ref>, where the best result was obtained for the network optimization for series 1 was: 0.0112 (as shown in Fig. <ref type="figure" target="#fig_4">9</ref> and Table <ref type="table">1</ref>) and for the series 2 where the best result was obtained for the network optimization for series 1 was: 0.0132 (as shown in Fig. <ref type="figure" target="#fig_7">11</ref> and<ref type="figure" target="#fig_0">Table 4</ref>).</p><p>When we apply the optimization by the particle swarm method to optimize the architecture the for the neural network ensemble, it improves the prediction error for this time series of the Mexican Stock Exchange in 95%, as can be seen when comparing with the Refs. <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b31">33]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.1.">Statistical t students test</head><p>In statistics, the stu Q5 dent t-test or t-test is a test that uses the statistical Student's t distribution to find out if a proposed null hypothesis is true. The test is applied when the population is normally distributed, but the sample size is too small for making the inference based on a normally distributed statistic, using an estimate of the standard deviation instead of the  actual value. In this section the results with the t student test are shown, and it can be noticed that there is statistical evidence of significant difference in the results between the type-1 and type-2 fuzzy systems. In other words, it can be said that for this time series prediction results are better with type-2 fuzzy aggregation than with type-1 fuzzy integration. The number of samples used for the type-1 were 10 and 30 samples for type-2, the t value obtained for type-1 in series number 1 is:</p><p>Ã5.96 and Ã4.56 for series number 2, so that the results show that in our tests more than 99% confidence was obtained of significant improvement with type-2 fuzzy logic according to the achieved value of P, as shown in Table <ref type="table" target="#tab_6">7</ref>.</p><p>Table <ref type="table" target="#tab_7">8</ref> shows results of the prediction error for the Ensemble Neural Network (without fuzzy aggregation), the prediction error with type-1 fuzzy aggregation and the prediction error with type-2 fuzzy and a 0.3 level of uncertainty for the time series 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 5</head><p>Results type-1 fuzzy aggregation of MSE for time series 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 6</head><p>Results type-2 fuzzy aggregation of MSE for time series 2. In Table <ref type="table" target="#tab_7">8</ref> it is clearly noted that using the response aggregation (type-1 or type-2) produces results that are significantly improved with respect to only using the results of the modules in the ensemble (first column of results). Both type-2 and type-1 fuzzy aggregation in the ensemble clearly help outperform the ensemble without fuzzy logic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">Conclusions</head><p>In this paper we considered the PSO algorithm to optimize the architecture of the ensemble neural network to predict the time series of the Mexican Stock Exchange, where good results were obtained, and we can say that this algorithm is good in speed when compared with other optimization techniques. PSO is an effective and efficient meta-heuristic to find the solution of this kind of problems. In conclusion the use of ensemble neural networks with type-2 fuzzy integration could be a good choice in predicting complex time series. Future works would be to optimize with the particle swarm algorithm the type-1 and type-2 fuzzy system aggregators to obtain an even better prediction error. type-1 and type-2 fuzzy systems could be optimized in terms of the parameters of the membership functions, membership type and number of rules.</p><p>12. Uncited references <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b36">38,</ref><ref type="bibr" target="#b37">39,</ref><ref type="bibr" target="#b44">45]</ref>. Q6</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. General architecture of the proposed ensemble neural network design.</figDesc><graphic coords="7,155.91,303.53,227.60,369.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 5 .Fig. 6 .</head><label>56</label><figDesc>Fig. 5. Mexican Stock Exchange of time series 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 8 Fig. 7 .</head><label>87</label><figDesc>Fig.8shows a fuzzy system consisting of 5 inputs depending on the number of modules of the neural network ensemble and one output. Each input and output linguistic variable of the fuzzy system uses 2 Gaussian membership functions. The</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 8 .</head><label>8</label><figDesc>Fig.8. Type-2 fuzzy system for the Mexican Stock Exchange.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Type-2 fuzzy rules for predicting the Mexican Stock Exchange.</figDesc><graphic coords="10,52.50,54.71,439.84,582.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig 10</head><label>10</label><figDesc>Fig 10 shows the architecture of the neural network obtained by particle swarm optimization. We used two layers in each module. In module 1, in the first layer we used 21 neurons and 16 neurons in the second layer and in module 2 we used 21 neurons in the first layer and 28 neurons in the second. The optimization method using swarms of particles determines the number of neurons in the neural network ensemble. The Levenberg-Marquardt (LM) training method was used; we also applied 3 delays to the network.</figDesc><graphic coords="11,113.39,206.48,312.09,188.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Ensemble neural network architecture for the MSE series 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Prediction with the optimized ensemble neural network of the MSE for time series 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>After a comparison of results for this time series of the Mexican Stock Exchange for the period of 11/09/05 to 01/15/09 and period of data from 04/08/08 to 05/09/11 with the paper entitled: '' Genetic Optimization of Ensemble Neural Networks</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Ensemble neural network architecture for the MSE series 2.</figDesc><graphic coords="13,133.23,468.00,269.70,205.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Prediction with the optimized ensemble neural network of the MSE for time series 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="6,117.69,54.71,312.61,272.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc>Results of type-2 fuzzy aggregation of MSE for time series 1.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4</head><label>4</label><figDesc>Particle swarm results for the ensemble neural network of MSE for time series 2.</figDesc><table><row><cell></cell><cell>3.6</cell><cell></cell><cell cols="3">Mexican Stock Exchange</cell><cell></cell></row><row><cell></cell><cell>3.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>3.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>2.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Close</cell><cell>2.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>2.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>2.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>500</cell><cell>550</cell><cell>600</cell><cell>650</cell><cell>700</cell><cell>750</cell><cell>800</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Days</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7</head><label>7</label><figDesc>Results of t student test for the time series.</figDesc><table><row><cell>Time series</cell><cell>N(type-1)</cell><cell>N(type-2)</cell><cell>t value</cell><cell>P value</cell></row><row><cell>Mexican Stock Exchange series 1</cell><cell>30</cell><cell>90</cell><cell>Ã5.96</cell><cell>0.00</cell></row><row><cell>Mexican Stock Exchange series 2</cell><cell>30</cell><cell>90</cell><cell>Ã4.56</cell><cell>0.00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8</head><label>8</label><figDesc>Results of MSE for time series 1.</figDesc><table><row><cell>Experiment</cell><cell>Prediction error for ensemble</cell><cell>Prediction error with type-1</cell><cell>Prediction error with type-2</cell></row><row><cell></cell><cell>neural network</cell><cell>fuzzy aggregation</cell><cell>fuzzy aggregation</cell></row><row><cell>Experiment 1</cell><cell>0.405</cell><cell>0.1726</cell><cell>0.1700</cell></row><row><cell>Experiment 2</cell><cell>0.5763</cell><cell>0.0952</cell><cell>0.1750</cell></row><row><cell>Experiment 3</cell><cell>0.3333</cell><cell>0.1565</cell><cell>0.2176</cell></row><row><cell>Experiment 4</cell><cell>1.8024</cell><cell>0.1554</cell><cell>0.2152</cell></row><row><cell>Experiment 5</cell><cell>1.7938</cell><cell>0.3523</cell><cell>0.1829</cell></row><row><cell>Experiment 6</cell><cell>1.7880</cell><cell>0.2608</cell><cell>0.2129</cell></row><row><cell>Experiment 7</cell><cell>0.3337</cell><cell>0.1070</cell><cell>0.2182</cell></row><row><cell>Experiment 8</cell><cell>0.2724</cell><cell>0.2497</cell><cell>0.2258</cell></row><row><cell>Experiment 9</cell><cell>1.121</cell><cell>0.1126</cell><cell>0.2316</cell></row><row><cell>Experiment 10</cell><cell>0.2916</cell><cell>0.1400</cell><cell>0.1319</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Please cite this article in press as: M. Pulido et al., Particle swarm optimization of ensemble neural networks with fuzzy aggregation for time series prediction of the Mexican Stock Exchange, Inform. Sci. (2014), http://dx.doi.org/10.1016/j.ins.2014.05.006</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>For interpretation of color in Figs.11 and 13, the reader is referred to the web version of this article.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>We would like to express our gratitude to the CONACYT, Tijuana Institute of Technology for the facilities and resources granted for the development of this research</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Introduction optimization, Practical Optimization Algorithms and Engineering Applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Brockwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Davis</surname></persName>
		</author>
		<title level="m">Introduction to Time Series and Forecasting</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="1" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Hybrid intelligent systems for time series prediction using neural networks, fuzzy logic, and fractal theory</title>
		<author>
			<persName><forename type="first">O</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Melin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1395" to="1408" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Simulation and forecasting complex economic time series using neural networks and fuzzy logic</title>
		<author>
			<persName><forename type="first">O</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Melin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Int. Neural Netw. Conf</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1805" to="1810" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Simulation and forecasting complex financial time series using neural networks and fuzzy logic</title>
		<author>
			<persName><forename type="first">O</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Melin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Syst. Man Cybernet</title>
		<meeting>IEEE Int. Conf. Syst. Man Cybernet</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="2664" to="2669" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">O</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Melin</surname></persName>
		</author>
		<title level="m">Type-2 Fuzzy Logic: Theory and Applications</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="29" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Cheng</surname></persName>
		</author>
		<title level="m">A hybr Q7 id ANFIS model based on AR and volatility for TAIEX forecasting</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1388" to="1395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">OWA-based ANFIS model for TAIEX forecasting</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econ. Model</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="442" to="448" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fuzzy time-series based on adaptive expectation model for TAIEX forecasting</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Theo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1126" to="1132" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Multi-attribute fuzzy time series method based on fuzzy clustering</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1235" to="1124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Time series</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cowpertwait</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Metcalfe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Introductory Time Series R</title>
		<imprint>
			<biblScope unit="page" from="2" to="5" />
			<date type="published" when="2009">2009</date>
			<publisher>Springer</publisher>
			<pubPlace>Dordrecht, Heidelberg, London, New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Stability problems with artificial neural networks and the ensemble solution</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jacob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell. Med</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="217" to="225" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Improving performance in neural networks using a boosting algorithm</title>
		<author>
			<persName><forename type="first">H</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Simard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Cowan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</editor>
		<meeting><address><addrLine>Denver, CO, Morgan Kaufmann, San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="42" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A new optimizer using particle swarm theory</title>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th Int. Symp. Micro Machine and Human Science (MHS)</title>
		<meeting>6th Int. Symp. Micro Machine and Human Science (MHS)</meeting>
		<imprint>
			<date type="published" when="1995-10">October 1995</date>
			<biblScope unit="page" from="39" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Swam</forename><surname>Intelligence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Kaufmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<pubPlace>San Mateo, California</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Engelbrecht</surname></persName>
		</author>
		<title level="m">Fundamentals of Computational Swarm Intelligence</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Particle swarm model selection</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Escalante</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Montes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Sucar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="405" to="440" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A novel objective function for improved phoneme recognition using time-delay neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hampshire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Waibel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="216" to="228" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Neural network ensembles</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Salomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Patt. Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="993" to="1001" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Effective lengths of intervals to improve forecasting in fuzzy time series</title>
		<author>
			<persName><forename type="first">K</forename><surname>Huarng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page" from="387" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S R</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mizutani</surname></persName>
		</author>
		<title level="m">Neuro-Fuzzy and Soft Computing</title>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Applications of type-2 fuzzy logic systems to forecasting of time-series</title>
		<author>
			<persName><forename type="first">N</forename><surname>Karnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Mendel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. Sci</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page" from="89" to="111" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Introduction to type-2 fuzzy logic systems</title>
		<author>
			<persName><forename type="first">N</forename><surname>Karnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Mendel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="915" to="920" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Operations on type-2 fuzzy sets</title>
		<author>
			<persName><forename type="first">N</forename><surname>Karnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Mendel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fuzzy Sets Syst</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="page" from="327" to="348" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Particle swam optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Neural Network (ICNN)</title>
		<meeting>IEEE Int. Conf. Neural Network (ICNN)</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Combining the predictions of multiple classifiers: using competitive learning to initialize neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Maclin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Shavlik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IJCAI-95</title>
		<meeting>IJCAI-95<address><addrLine>Montreal, Canada; San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="524" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Predicting a chaotic time series using a fuzzy neural network</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Maguire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Roche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Mcginnity</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Mcdaid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. Sci</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page" from="125" to="136" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A case study on bagging, boosting and basic ensembles of neural networks for O CR</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IJCNN-98</title>
		<meeting>IJCNN-98<address><addrLine>Anchorage, AK, Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1828" to="1833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Design of Modular Neural Networks with</title>
		<author>
			<persName><forename type="first">P</forename><surname>Melin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Trujillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Osuna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fuzzy Integration Applied to Time Series Prediction</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<date type="published" when="2007">2007. 2007</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin/Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">A new approach for time series prediction using ensembles of ANFIS models</title>
		<author>
			<persName><forename type="first">P</forename><surname>Melin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Soto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Soria</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Expert System with Applications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Application of Neural Networks and Other Learning Technologies in Process Engineering</title>
		<author>
			<persName><forename type="first">I</forename><surname>Multaba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hussain</surname></persName>
		</author>
		<idno>03.12.08</idno>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Imperial Collage Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Genetic optimization of ensemble neural networks for complex time series pred Q8 iction of the mexican exchange prediction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pulido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Melin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Innov. Comput. Inform. Control</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="4151" to="4166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An ensemble neural network architecture with fuzzy response integration for complex time series prediction, Evolutionary Design of Intelligent Systems in Modeling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pulido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mancilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Melin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Simulation and Control</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Combining Artificial Neural Nets: Ensemble and Modular Multi-Net Systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sharkey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Intrator classification of seismic signal by integrating ensemble of neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shimshoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">461</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1194" to="1201" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A simple method of forecasting based on fuzzy time series</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Comput</title>
		<imprint>
			<biblScope unit="volume">186</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="330" to="339" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Fuzzy systems theory and its applications to modeling and control</title>
		<author>
			<persName><forename type="first">T</forename><surname>Takagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sugeno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybernet. SMC</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="116" to="132" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Particle swarm optimization: basic concepts, variants and applications in power systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Valle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">K</forename><surname>Venayagamoorthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohagheghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-C</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Harley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="page" from="171" to="195" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">L.-Y</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A hybrid recurrent neural networks model based on synthesis features to forecast the taiwan stock market</title>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Innov. Comput. Inform. Control</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="5559" to="5571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Building an integrated hybrid model for short-term and mid-term load forecasting with genetic optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Watada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Innov. Comput. Inform. Control</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="7381" to="7391" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Time series prediction with single multiplicative neuron model</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Kalra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>John</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Comput. Time Ser. Predict. Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1157" to="1163" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A new mutation operation for faster convergence in genetic algorithm feature selection</title>
		<author>
			<persName><forename type="first">R</forename><surname>Yusof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Khairuddin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Khalid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Innov. Comput. Inform. Control</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="7363" to="7379" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</author>
		<title level="m">Fuzzy Sets and Applications: Selected Papers</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Yager</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley</publisher>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">PSO-based single multiplicative neuron model for time series prediction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="2805" to="2812" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>Part 2</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Lung cancer cell identification based on artificial neural network ensembles</title>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-F</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell. Med</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="36" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
