<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Stephen</forename><surname>Somogyi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">http://www.ece.cmu.edu/~stems Spatial Memory Streaming Computer Architecture Laboratory (CALCM)</orgName>
								<orgName type="institution">Carnegie Mellon University † Dept. of Electrical &amp; Computer Engineering University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">http://www.ece.cmu.edu/~stems Spatial Memory Streaming Computer Architecture Laboratory (CALCM)</orgName>
								<orgName type="institution">Carnegie Mellon University † Dept. of Electrical &amp; Computer Engineering University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anastassia</forename><surname>Ailamaki</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">http://www.ece.cmu.edu/~stems Spatial Memory Streaming Computer Architecture Laboratory (CALCM)</orgName>
								<orgName type="institution">Carnegie Mellon University † Dept. of Electrical &amp; Computer Engineering University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Babak</forename><surname>Falsafi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">http://www.ece.cmu.edu/~stems Spatial Memory Streaming Computer Architecture Laboratory (CALCM)</orgName>
								<orgName type="institution">Carnegie Mellon University † Dept. of Electrical &amp; Computer Engineering University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andreas</forename><surname>Moshovos</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">http://www.ece.cmu.edu/~stems Spatial Memory Streaming Computer Architecture Laboratory (CALCM)</orgName>
								<orgName type="institution">Carnegie Mellon University † Dept. of Electrical &amp; Computer Engineering University of Toronto</orgName>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Prior research indicates that there is much spatial variation in applications' memory access patterns. Modern memory systems, however, use small fixed-size cache blocks and as such cannot exploit the variation. Increasing the block size would not only prohibitively increase pin and interconnect bandwidth demands, but also increase the likelihood of false sharing in shared-memory multiprocessors.</p><p>In this paper, we show that memory accesses in commercial workloads often exhibit repetitive layouts that span large memory regions (e.g., several kB), and these accesses recur in patterns that are predictable through codebased correlation. We propose Spatial Memory Streaming, a practical on-chip hardware technique that identifies codecorrelated spatial access patterns and streams predicted blocks to the primary cache ahead of demand misses. Using cycle-accurate full-system multiprocessor simulation of commercial and scientific applications, we demonstrate that Spatial Memory Streaming can on average predict 58% of L1 and 65% of off-chip misses, for a mean performance improvement of 37% and at best 307%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Spatial Patterns and Generations</head><p>We formalize our notion of spatial correlation similar to prior studies of spatial footprints <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b16">17]</ref>. We define a spatial region as a fixed-size portion of the system's address space, consisting of multiple consecutive cache blocks. A spatial FIGURE 1. Examples of spatial correlation and spatial region generations. The left figure shows example sources of spatial correlation in databases. The right figure illustrates an event sequence and the corresponding spatial region generations and patterns.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Poor memory system behavior limits the performance of commercial applications in high-end servers. One-half to twothirds of execution time in commercial online transaction processing (OLTP), decision support system (DSS), and web server workloads is spent on memory system-related stalls <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b29">30]</ref>. These workloads challenge system designers because they rely on complex algorithms and data structures, have large code footprints, operate on data sets that greatly exceed physical memory, and use sophisticated fine-grain synchronization to maximize concurrency.</p><p>Microarchitectural innovations, such as out-of-order execution, non-blocking caches, and run-ahead execution <ref type="bibr" target="#b18">[19]</ref>, improve memory system performance by increasing the offchip memory-level parallelism (MLP). However, to discover parallel misses, these approaches must correctly predict and execute the instruction stream, which restricts the depth of the instruction window they can explore. In OLTP and web applications, these innovations provide limited benefit because of frequent, long chains of dependent memory accesses <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b29">30]</ref>. Although modern servers provide copious memory bandwidth <ref type="bibr" target="#b6">[7]</ref>, the memory system remains underutilized because these dependence chains severely limit available MLP-one study reports an average of just 1.3 parallel offchip misses for these applications on a current-generation outof-order system <ref type="bibr" target="#b5">[6]</ref>. Enhancing the parallelism and hiding the latency of memory accesses are the keys to server performance improvement.</p><p>Although computer architects have demonstrated great success in improving MLP and hiding memory latency in desktop and scientific applications through memory prefetching or streaming (e.g., <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b28">29]</ref>), few studies have demonstrated success at improving memory system performance for commercial applications. Instruction stream buffers reduce primary instruction cache stalls <ref type="bibr" target="#b20">[21]</ref>. Software prefetching can accelerate certain database operations, such as hash joins <ref type="bibr" target="#b4">[5]</ref>. Temporal streaming reduces coherence stalls by streaming repetitive, temporally-correlated coherence miss sequences <ref type="bibr" target="#b29">[30]</ref>. However, all of these approaches target only limited classes of memory accesses and a significant fraction of memory stalls remain exposed.</p><p>Despite their complexity, commercial applications nonetheless utilize data structures with repetitive layouts and access patterns-such as database buffer pool pages or network packet headers. As these applications traverse their data sets, recurring patterns emerge in the relative offsets of accessed data. Unfortunately, these accesses are frequently non-contiguous and do not follow a constant stride (e.g., binary search in a B-tree). Because sparse patterns may span large regions (e.g., an operating system page), we use the term spatial correlation rather than spatial locality to describe the relationship among accesses. Increasing cache block size to capture spatial correlation leads to inefficient storage and bandwidth utilization.</p><p>Past research on uniprocessor systems has shown that spatial correlation can be predicted in hardware by correlating patterns with the code and/or data address that initiates the pattern <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b16">17]</ref>. Whereas existing spatial pattern prefetching designs are effective for desktop/engineering applications <ref type="bibr" target="#b3">[4]</ref>, the only practical implementation evaluated on server workloads provides less than 20% miss rate reduction <ref type="bibr" target="#b16">[17]</ref>.</p><p>In this paper, we reconsider prediction and streaming of spatially-correlated access patterns to improve MLP and to hide the long latencies of secondary cache and off-chip memory accesses. Our design, Spatial Memory Streaming (SMS), targets commercial server applications and can reduce both primary cache and off-chip misses in multiprocessor servers. SMS exploits repetitive access patterns to predict and stream blocks to the primary cache ahead of demand misses. We evaluate SMS through a combination of trace-based and cycle-accurate full-system simulation of scientific and commercial applications. This work demonstrates: • Effective spatial correlation and prediction. Contrary to previous findings <ref type="bibr" target="#b16">[17]</ref>, address-based correlation is not needed to predict the access stream of commercial workloads. Instead, we show a strong correlation between code and access patterns, which SMS exploits to predict patterns even for previously-unvisited addresses. Because there are far fewer distinct code sequences than data addresses, SMS provides nearly four times the prediction coverage of an address-based predictor with equivalent storage. • Accurate tracking of spatial correlation. We show that the cache-coupled structures used in previous work ( <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b16">17]</ref>) are suboptimal for observing spatial correlation. Accesses to multiple independent patterns are frequently interleaved, which induce conflict behavior in prior detection structures. Instead, we propose a decoupled detection structure that identifies fewer and denser patterns, halving predictor storage requirements and increasing coverage by up to 20%. • Performance enhancement. For commercial workloads, we show that SMS predicts on average 55% and at best 78% of off-chip read misses, providing a mean speedup of 1.22 and at best 1.48 over a system without SMS. In contrast, the global history buffer (GHB) <ref type="bibr" target="#b19">[20]</ref>, the best proposed prefetcher for desktop/engineering applications, eliminates only 30% of off-chip misses on average and 62% at best. In scientific applications, SMS matches GHB's coverage to eliminate on average 81% of off-chip misses, and yields speedups ranging from 1.26 to 4.07. The remainder of this paper is organized as follows. We describe Spatial Memory Streaming in Section 2 and present the details of our hardware implementation in Section 3. In Section 4, we evaluate our design and present performance results. We discuss related work in Section 5 and conclude in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Spatial Memory Streaming</head><p>Spatial Memory Streaming (SMS) improves the performance of scientific and commercial server applications by exploiting spatial relationships among data beyond a single cache block.</p><p>In choosing a cache block size, system designers are forced to balance the competing concerns of spatial locality, transfer latency, cache storage utilization, memory/processor pin bandwidth utilization, and false sharing. Typically, the optimal cache block size sacrifices opportunity to exploit spatial locality for dense data structures to avoid excessive bandwidth overheads for sparse data structures. For simple data structures, such as arrays, spatial relationships can be exploited through simple prefetching schemes, such as stride prefetching <ref type="bibr" target="#b23">[24]</ref>.</p><p>Commercial applications exhibit complex access patterns that are not amenable to simple prefetching or streaming schemes. Nevertheless, data structures in these applications frequently exhibit spatial relationships among cache blocks. For example, in databases, pages in the buffer pool share common structural elements, such as a log serial number in the page header and a slot index that indicates tuple offsets in the page footer, that are always accessed prior to scanning/ modifying the page. In web servers, packet headers and trailers have arbitrarily complex but fixed structure. Further examples appear in Figure <ref type="figure">1</ref> (left). Although accesses within these structures may be non-contiguous, they nonetheless exhibit recurring patterns in relative addresses. We call the relationship between these accesses spatial correlation.</p><p>SMS extracts spatially-correlated access patterns at runtime and predicts future accesses using these patterns. SMS then streams the predicted cache blocks into the processor's primary cache as rapidly as allowed by available resources and bandwidth, thereby increasing memory level parallelism and hiding lower-level cache and off-chip access latencies. Generation B:1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Event sequence Generations &amp; patterns Examples of spatially-correlated elements in DBMSs</head><formula xml:id="formula_0">1 1 0 0 Generation A:2 1 1 1 0 Generation A:1 A+0 A+1 A+2 A+1 A+0 A+1 B+3 A+1 B+2 B+3</formula><p>region generation is the time interval over which SMS records accesses within a spatial region. We call the first access in a spatial region generation the trigger access. A spatial pattern is a bit vector representing the set of blocks in a region accessed during a spatial region generation. Thus, a spatial pattern captures the layout of cache blocks accessed near one another in time. Upon a trigger access, SMS predicts the spatial pattern that will be accessed over the course of the spatial region generation. The precise interval over which a spatial region generation is defined can significantly impact the accuracy and coverage of spatial patterns <ref type="bibr" target="#b16">[17]</ref>. A generation must be defined to ensure that, when SMS streams blocks into the cache upon a future trigger access, no predicted block will be evicted or invalidated prior to its use. Therefore, we choose the interval from the trigger access until any block accessed during the generation is removed from the processor's primary cache by replacement or invalidation. A subsequent access to any block in the region is the trigger access for a new generation. This definition ensures that the set of blocks accessed during a generation were simultaneously present in the cache. Figure <ref type="figure">1</ref> (right) shows an example of three spatial region generations and their corresponding patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Identifying Recurring Spatial Patterns</head><p>Upon a trigger access, SMS predicts the subset of blocks within the region that are spatially correlated and therefore likely to be accessed. Thus, a key problem in SMS is finding a prediction index that is strongly correlated to recurring spatial patterns. Spatial correlation arises because of repetition and regularity in the layout and access patterns of data structures. For instance, spatial correlation can arise because several variables or fields of an aggregate are frequently accessed together. In this case, the spatial pattern correlates to the address of the trigger access, because the address identifies the data structure. Spatial correlation can also arise because a data structure traversal recurs or has a regular structure. In this case, the spatial pattern will correlate to the code (program counter values) executing the traversal.</p><p>A variety of prediction indices have been investigated in the literature. All prior studies found that combining both the address and program counter to construct an index consistently provides the most accurate predictions when correlation table storage is unbounded <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b16">17]</ref>. By combining both quantities, which we call PC+address indexing, a predictor generates distinct patterns when multiple code sequences lead to different traversals of the same data structure. However, this prediction index requires predictor storage that scales with data set size, and predictor coverage drops precipitously with realistic storage constraints.</p><p>For SPEC CPU 2000 applications, PC+address indexing can be approximated by combining the PC with a spatial region offset <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b16">17]</ref>. The spatial region offset of a data address is the distance, in cache blocks, of the address from the start of the spatial region. The spatial region offset allows the predictor to distinguish repetitive patterns generated by the same code fragment that only differ in their alignment relative to spatial region boundaries. PC+offset indexing considerably reduces prediction table storage requirements because applications have far fewer distinct miss PCs than miss addresses.</p><p>We observe that PC+offset indexing, in addition to its storage savings, is fundamentally more powerful than address-based indexing because it can eliminate cold misses. When a code sequence repeats the same access pattern over a large data set, the PC-correlated spatial patterns learned at the start of the access sequence will provide accurate predictions for data that have never previously been visited. Database scan and join operations, which dominate the execution of decision support queries <ref type="bibr" target="#b22">[23]</ref>, contain long repetitive access patterns that visit data only once. In these applications, PC+offset indexing substantially outperforms address-based schemes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Design</head><p>We now describe our design for Spatial Memory Streaming. Unlike prior proposals, we target our design at high-performance commercial server applications in a multiprocessor context. Our most significant departure from prior designs is that those designs target decoupled sectored <ref type="bibr" target="#b21">[22]</ref> or sub-blocked caches. Integrating spatial pattern prediction with such caches simplifies the hardware design because the training structures for spatial region accesses can be integrated with the sub-blocked cache tag array. However, interleaved accesses to different spatial regions cause conflict behavior within the sub-blocked tags, fragmenting spatial region generations and reducing the accuracy of observed patterns. Therefore, we design SMS to integrate with a traditional cache hierarchy.</p><p>SMS comprises two hardware structures. The active generation table records spatial patterns as the processor accesses spatial regions and trains the predictor. The pattern history table stores previously-observed spatial patterns, and is accessed at the start of each spatial region generation to predict the pattern of future accesses. The next two subsections describe these structures and their operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Observing Spatial Patterns</head><p>Spatial Memory Streaming learns spatial patterns by recording which blocks are accessed over the course of a spatial region generation in the active generation table (AGT). When a spatial region generation begins, SMS allocates an entry in the AGT. As cache blocks are accessed, SMS updates the recorded pattern in the AGT. At the end of a generation (eviction/invalidation of any block accessed during the generation), the AGT transfers the spatial pattern to the history table and the AGT entry is freed.</p><p>Although the AGT is logically a single table, we implement it as two content addressable memories, the accumulation table and the filter table, to reduce the size of the associative search within each memory and the overall size of the structure. Because the AGT processes each L1 data access, it is necessary that both tables be able to match the L1 data access bandwidth. The AGT is not on the L1 data access critical path, and thus does not impact cache access latency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spatial patterns are recorded in the accumulation table.</head><p>Entries in the accumulation table are tagged by the spatial region tag, the high order bits of the region base address. Each entry stores the PC and spatial region offset of the trigger access, and a spatial pattern bit vector indicating which blocks have been accessed during the generation.</p><p>New spatial region generations are initially allocated in the filter table. The filter table records the spatial region tag, and the PC and spatial region offset of the trigger access, for spatial regions that have had only a single access in their current generation. A significant minority of spatial region generations never have a second block accessed; there is no benefit to predicting these generations because the only access is the trigger access. By restricting such generations to the filter table, SMS reduces pressure on the accumulation table.</p><p>The detailed operation of the AGT is depicted in Figure <ref type="figure">2</ref>. Each L1 access first searches the accumulation table. If a matching entry is found, the spatial pattern bit corresponding to the accessed block is set. Otherwise, the access searches for its tag in the filter table. If no match is found, this access is the trigger access for a new spatial region generation and a new entry is allocated in the filter table (step 1 in Figure <ref type="figure">2</ref>). If an access matches in the filter table, its spatial region offset is compared to the recorded offset. If the offsets differ, then this block is the second distinct cache block accessed within the generation, and the entry in the filter table is transferred to the accumulation table (step 2). Additional accesses to the region set corresponding bits in the pattern (step 3).</p><p>Spatial region generations end with an eviction or invalidation (step 4). Upon these events, both the filter table and accumulation table are searched for the corresponding spatial region tag. (Note that this search requires reading the tags of replaced cache blocks even if the replaced block is clean). A matching entry in the filter table is discarded because it represents a generation with only a trigger access. A matching entry in the accumulation table is transferred to the pattern history table. If either table is full when a new entry must be allocated, a victim entry is selected and the corresponding generation is terminated (i.e., the entry is dropped from the filter table or transferred from the accumulation table to the pattern history table). In Section 4.5, we observe that small (e.g., 32-or 64-entry) accumulation and filter tables make this occurrence rare.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Predicting Spatial Patterns</head><p>SMS uses a pattern history table (PHT) for long-term storage of spatial patterns and to predict the pattern of blocks that will be accessed during each spatial region generation. The implementation of the PHT and the address stream prediction process is depicted in Figure <ref type="figure">3</ref>. The PHT is organized as a set-associative structure similar to a cache. The PHT is accessed using a prediction index constructed from the PC and spatial region offset of the trigger access for a generation. ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FIGURE 2. Active Generation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>region base offset</head><p>Each entry in the PHT stores the spatial pattern that was accumulated in the AGT. Upon a trigger access, SMS consults the PHT to predict which blocks will be accessed during the generation. If an entry in the PHT is found, the spatial region's base address and the spatial pattern are copied to one of several prediction registers. As SMS streams each block predicted by the pattern into the primary cache, it clears the corresponding bit in the prediction register. The register is freed when its entire pattern has been cleared. If multiple prediction registers are active, SMS requests blocks from each prediction register in a round-robin fashion. SMS stream requests behave like read requests in the cache coherence protocol.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>We evaluate SMS using a combination of trace-driven and cycle-accurate full-system simulation of a shared-memory multiprocessor using FLEXUS <ref type="bibr" target="#b13">[14]</ref>. FLEXUS can execute unmodified commercial applications and operating systems. FLEXUS extends the Virtutech Simics functional simulator with cycle-accurate models of an out-of-order processor core, cache hierarchy, protocol controllers and interconnect. We simulate a 16-processor directory-based shared-memory multiprocessor system running Solaris 8. We employ a wait-free implementation of the total store order memory consistency model <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b9">10]</ref>. We perform speculative load and store prefetching <ref type="bibr" target="#b8">[9]</ref>, and speculatively relax memory ordering constraints at memory barrier and atomic read-modify-write memory operations <ref type="bibr" target="#b9">[10]</ref>. We list other relevant parameters of our system model in Table <ref type="table" target="#tab_2">1</ref> (left).</p><p>Table <ref type="table" target="#tab_2">1</ref> (right) enumerates our commercial and scientific application suite. We include the TPC-C v3.0 OLTP workload on two commercial database management systems, IBM DB2 v8 ESE, and Oracle 10g Enterprise Database Server. We select four queries from the TPC-H DSS workload based on the categorization in <ref type="bibr" target="#b22">[23]</ref>: one scan-dominated query, two join-dominated queries, and one query exhibiting mixed behavior. All four DSS queries are run on DB2. We evaluate web server performance with the SPECweb99 benchmark on Apache HTTP Server v2.0 and Zeus Web Server v4.3. We drive the web servers using a separate client system and a high-bandwidth link tuned to ensure that the server system is fully saturated (client activity is not included in trace or timing results). Finally, we include three scientific applications to provide a frame of reference for our commercial application results.</p><p>Our trace-based analyses use memory access traces collected from FLEXUS with in-order execution, no memory system stalls, and a fixed IPC of 1.0. For OLTP and web workloads, we warm main memory with functional simulation for at least 5000 transactions (or web requests) prior to starting traces, and then trace at least 1000 transactions. For DSS queries, we analyze traces of over three billion total instructions taken from the query execution at steady-state. We have experimentally verified that varying trace start location has minimal impact on simulation results. For scientific applications, we analyze traces of five to ten iterations. We use half of each trace for warm-up prior to collecting experimental results. All results prior to Section 4.7 use this tracebased methodology.</p><p>For cycle-accurate simulations, we use a sampling approach developed in accordance with SMARTS <ref type="bibr" target="#b31">[32]</ref>. Our samples are drawn over an interval of 10 to 30 seconds of simulated time (as observed by the operating system in functional simulation) for OLTP and web applications, over the complete query execution for DSS, and over a single iteration for scientific applications. We show 95% confidence intervals that target ±5% error on change in performance, using pairedmeasurement sampling <ref type="bibr" target="#b30">[31]</ref>. We launch measurements from checkpoints with warmed caches, branch predictors, and predictor table state, then run for 100,000 cycles to warm queue and interconnect state prior to collecting measurements of 50,000 cycles. We use the aggregate number of user instructions committed per cycle (i.e., committed user instructions summed over the 16 processors divided by total elapsed  cycles) as our performance metric, which is proportional to overall system throughput <ref type="bibr" target="#b29">[30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Spatial Characterization</head><p>We begin by quantifying the spatial characteristics of our application suite and identifying the maximum opportunity to reduce miss rates with SMS. We show that there is substantial spatial correlation over regions as large as the operating system page size (8kB). However, an increased cache block size cannot exploit this correlation because of increased conflict misses, false sharing, and inefficient bandwidth utilization. No single cache block size can capture spatial correlation efficiently because access density varies within and across applications. SMS does not suffer these inefficiencies because it tracks spatial correlation at fine granularity.</p><p>We quantify the opportunity for SMS to exploit spatial correlation across a range of region sizes, and compare against the effectiveness of increasing cache block size in Figure <ref type="figure" target="#fig_1">4</ref>. To assess opportunity, at each region size, we consider an oracle predictor that incurs only one miss per spatial region generation (labelled "opportunity"). We also show the miss rate achieved by a cache with block size equal to the region size. (We hold cache capacity fixed across all region/ block sizes). For block sizes larger than 64B, we separate misses caused by false sharing (labelled "false sharing beyond 64B") from all other misses (labelled "other misses"). We report results in terms of misses per instruction, normalized to a cache with 64B blocks and no predictor.</p><p>Our oracle study demonstrates substantial opportunity for SMS to eliminate read misses. Across applications and cache hierarchy levels, SMS opportunity increases as spatial regions are extended to the OS page size.</p><p>Increased cache block size leads to drastic increases in L1 miss rates because of conflict behavior. The commercial workloads use only a subset of the data in large regions and interleave accesses across regions. Thus, as the cache block size increases, conflicts increase, and the effective capacity of the L1 cache is reduced, leading to a sharp increase in miss rate with block sizes beyond 512B. The data sets of the scientific applications are more tightly packed, but nevertheless suffer from similar conflict behavior.</p><p>The larger capacity of L2 reduces the prevalence of conflict effects as compared to L1. However, commercial workloads instead incur misses from false sharing, which accounts for 26%-42% of L2 misses at the 8kB block size.</p><p>The inefficient bandwidth utilization of larger blocks makes it unclear if even block sizes of 512B, despite lower miss rates, can improve performance over 64B blocks at any hierarchy level. Unless data is densely packed, as in the scientific applications, larger block sizes lead to the transfer of more unused data. In the commercial applications, bandwidth efficiency drops exponentially as block size increases above 512B.</p><p>Huh and co-authors demonstrate that the latency penalty of false sharing can be eliminated through coherence decoupling-speculative use of incoherent data <ref type="bibr" target="#b14">[15]</ref>. However, even if false sharing is eliminated, true sharing and replacement misses nonetheless result in nearly double the L2 miss rate of the oracle opportunity at 8kB blocks. Furthermore, coherence decoupling does not eliminate bandwidth wasted by false sharing, and therefore cannot scale to the same region sizes as SMS.</p><p>The root cause of the inefficiency of large cache blocks is the variability of memory access density within and across applications. We quantify memory access density as the fraction of cache misses occurring in spatial region generations that contain a particular number of misses. Figure <ref type="figure" target="#fig_2">5</ref> presents a breakdown of memory access density for each application for a 2kB region size (we establish 2kB as the best choice for region size in Section 4.4). For example, in OLTP-DB2, 22% of L1 misses come from spatial generations in which between four and seven blocks are missed upon during the generation. With the exception of ocean and sparse, all applications exhibit wide variations in their memory access density at both L1 and L2. Thus, no single block size can simultaneously exploit the available spatial correlation while using bandwidth and storage efficiently.  Because SMS learns and predicts spatial patterns over large regions at fine granularity, SMS can approach the miss rates indicated by our opportunity study without the inefficiencies of large blocks. SMS fetches only the 64B blocks within a region that are likely to be used, and therefore does not incur the conflict, false sharing, or bandwidth overhead of larger blocks. Our opportunity results for L1 indicate that accurate spatial pattern prediction allows SMS to deliver blocks directly into L1, despite its small capacity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Indexing</head><p>Prior studies of spatial predictors <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b16">17]</ref> advocate predictor indices that include address information. In this section, we show that PC+offset indexing yields the same or significantly higher coverage than address-based indices, as well as lower storage requirements.</p><p>We compare the Address, PC+address, PC, and PC+offset indexing schemes in Figure <ref type="figure">6</ref>, using an infinite PHT to assess the true opportunity without regard to storage limitations. Coverage represents the fraction of L1 read misses that are eliminated by SMS. Overpredictions represent blocks that are fetched but not used prior to eviction or invalidation, and thus waste bandwidth. Overpredictions can also cause cache pollution; this effect is implicitly taken into account because the additional misses are categorized as uncovered.</p><p>In OLTP and web applications, a majority of spatiallycorrelated accesses arise from heavily-visited code sequences and data structures. Hence, both data addresses and PCs correlate to similar spatial patterns, and the Address, PC+address, and PC+offset indexing schemes perform similarly. PC indexing (without any address information) is less accurate because it cannot distinguish among distinct access patterns to different data structures by the same code (e.g.,   <ref type="bibr" target="#b16">[17]</ref>, which indicated that PC+address provides superior coverage. Indices that correlate primarily based on program context (PC, PC+offset) are fundamentally more powerful than alternatives that include complete addresses (Address, PC+address) because they can predict accesses to data that have not been used previously-a crucial advantage for DSS. The scan and join operations that dominate DSS access many data only once. Address-based indices cannot predict previously-unvisited addresses and thus fail to predict many spatially-correlated accesses. Both the PC and PC+offset schemes can predict unvisited addresses, but, as with OLTP and web applications, the ability of PC+offset to distinguish among traversals allows it to achieve the highest coverage.</p><p>For scientific applications, we corroborate the conclusions of prior work <ref type="bibr" target="#b3">[4]</ref> that indicate PC+offset indexing generally approaches the peak coverage achieved by the PC+address indexing scheme.</p><p>A second advantage of PC+offset indexing over alternatives that include complete addresses is that its storage requirements are proportional to code size rather than data set size. Figure <ref type="figure">7</ref> compares PC+offset and PC+address at practical PHT sizes. PC+offset attains peak coverage with 16k entries-roughly the same hardware cost as a 64kB L1 cache data array. For PC+address, in all workloads except OLTP, 16k entries is far too small to capture a meaningful fraction of program footprint and provide significant coverage. In OLTP, where most coverage arises from frequent accesses to relatively few structures, PC+address achieves 75% of peak coverage with a 16k-entry PHT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Decoupled Training</head><p>The training structure (e.g., the AGT) is a key component in any spatial-correlation predictor because structural limitations can prematurely terminate spatial region generations-particularly when accesses to different regions are interleaved-and thus reduce predictor coverage and/or fragment prediction entries, consequently polluting the PHT.</p><p>Past predictors <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b16">17]</ref> couple the predictor training structure to a sectored (i.e., sub-blocked) cache tag array. In a sectored cache, the valid bits in the tag array for each sector implicitly record a spatial pattern, thus requiring only minimal hardware changes to train a predictor (e.g., to track PC/ address of the trigger access). However, sectored caches are less flexible than traditional caches and experience worse conflict behavior. To mitigate this disadvantage, the spatial footprint predictor <ref type="bibr" target="#b16">[17]</ref> employed a decoupled sectored cache <ref type="bibr" target="#b21">[22]</ref>, whereas the spatial pattern predictor <ref type="bibr" target="#b3">[4]</ref> provided a logical sectored-cache tag array alongside a traditional cache. The logical sectored-cache tag array calculates cache contents as if the cache was sectored, but does not affect actual cache replacements. Nevertheless, both these organizations incur more address conflicts than a traditional cache, and thus cannot accurately track available spatial correlation.</p><p>We compare the AGT to both of these organizations in Figure <ref type="figure" target="#fig_3">8</ref>. We measure coverage by comparing the miss rate of each implementation against a baseline traditional cache. We model an infinite PHT to factor out predictor storage limitations from this analysis.</p><p>In commercial workloads, the additional constraints that the decoupled sectored cache (DS) places on cache contents lead to considerably more misses than in both other approaches. The conflict effects are magnified in applications where few generations are dense (OLTP and web; see Figure <ref type="figure" target="#fig_2">5</ref>). In the scientific applications, blocks in the same  Although the logical sectored scheme achieves similar coverage to AGT, when accesses across regions are interleaved, logical tag conflicts still fragment generations and create more history patterns. Figure <ref type="figure">9</ref> compares the two approaches in terms of PHT storage requirements. In general, for any coverage that the logical sectored design can achieve, it requires twice the PHT storage of AGT. The gap is largest for OLTP, which exhibits the most interleaving.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Spatial Region Size</head><p>Our oracle study (Figure <ref type="figure" target="#fig_1">4</ref>) indicates that there is increasing opportunity as spatial region size increases to 8kB. For SMS to exploit this opportunity, accesses in a region must be repetitive and correlate to the trigger access. However, larger regions are more likely to span unrelated data structures, and therefore some accesses may not be repetitive with respect to the trigger access. We explore SMS's sensitivity to region size in Figure <ref type="figure" target="#fig_4">10</ref>, using AGT training and unlimited PHT storage. We vary region from 128B (two blocks) to the OS page size of 8kB (128 blocks).</p><p>In the database workloads, spatial regions do not span data structures, because the structures are aligned to database pages. Thus, in OLTP, coverage increases with region size. In DSS, most patterns are dense, so the benefit to merging adjacent spatial regions (i.e., eliminating the trigger misses of additional regions) is negligible.</p><p>In scientific applications, at region sizes above 2kB, we observe the negative effect of spanning data structures. Using PC+address (rather than PC+offset) indexing can mitigate this effect by learning specific patterns for each boundary between data structures, at the cost of drastically increased PHT storage requirements.</p><p>Choosing a spatial region size involves a tradeoff between coverage and storage requirements. Storage is domi-nated by PHT size, which scales linearly with the size of spatial regions. All applications except OLTP exhibit peak coverage with 2kB regions. The 2% coverage increase for OLTP when increasing region size to 4kB does not justify the doubled PHT size. Unless otherwise specified, we use 2kB spatial regions for the results in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Active Generation Table</head><p>The AGT is responsible for recording all blocks accessed during a spatial region generation. If the AGT is too small, generations will be terminated prematurely by replacement, leading to reduced pattern density and increased PHT storage requirements. Fortunately, SMS is able to attain the same coverage with a practical AGT as with an infinite AGT-across all applications, a 32-entry filter table and a 64entry accumulation table are sufficient. OLTP-Oracle places the largest demand on the accumulation table; it is the only application to require more than 32 accumulation table entries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Comparison to State-of-the-Art Prefetchers</head><p>Although many prefetching and streaming techniques have been proposed, they do not target general memory access patterns for commercial workloads. We compare SMS against the Global History Buffer (GHB) <ref type="bibr" target="#b19">[20]</ref>, whose PC/DC (program counter / delta correlation) variant was shown to be the most effective prefetching technique for desktop/engineering applications <ref type="bibr" target="#b11">[12]</ref>. Like SMS, GHB-PC/DC exploits spatial relationships between addresses. However, GHB seeks to predict the sequence of offsets across consecutive memory accesses by the same instruction.</p><p>We consider GHB with two history buffer sizes: 256 entries (sufficient for SPEC applications <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b19">20]</ref>) and 16k entries (to roughly match the capacity of the SMS PHT). The GHB lookup mechanism requires multiple buffer accesses upon each prefetch; as such, GHB was proposed for and is only applicable to L2 caches. Thus, we compare the off-chip miss coverage of GHB and SMS in Figure <ref type="figure">11</ref>.</p><p>SMS outperforms GHB in OLTP and web applications. These applications interleave accesses to multiple spatial regions. SMS captures these accesses because the trigger access in each region independently predicts a pattern for the region. With GHB, however, when multiple access sequences are interleaved, the offset sequences are disrupted. Therefore, GHB can only predict interleaved sequences if the interleaving itself is repetitive.</p><p>The DSS workloads access fewer regions in parallel; hence, interleaving is less frequent. Furthermore, DSS access sequences are highly structured-scans and joins, instead of the searches common in OLTP-which allow GHB to nearly match SMS's coverage. Likewise, in the scientific applications, both predictors capture the repetitive access sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.">Performance Results</head><p>We evaluate the performance impact of SMS on scientific and commercial applications with respect to a baseline system without SMS. Figure <ref type="figure">12</ref> show the performance improvement for each application with 95% confidence inter- vals given by our sampling methodology. Figure <ref type="figure" target="#fig_5">13</ref> presents execution time breakdowns for both systems. The two bars for each application are normalized to represent the same amount of completed work. Thus, the relative height of the bars indicates speedup, while the size of each component indicates the time per unit of forward progress spent on the corresponding activity. User busy and system busy time indicate cycles in which at least one instruction is committed. The three depicted stall categories represent stalls waiting for load data from off-chip, from an on-chip cache (e.g., L2), and store-buffer-full stalls. Finally, the remaining category accumulates all other stall sources (e.g., branch mispredictions, instruction cache misses, etc.). In all workloads, SMS improves performance by reducing off-chip read stalls. We observe performance improve-ments of over 20% in the web, scientific, and DSS (except Qry1) workloads.</p><p>In OLTP workloads, many of the misses that SMS predicts coincide with misses that the out-of-order core is able to overlap. Even though overall MLP is low <ref type="bibr" target="#b5">[6]</ref>, misses that the core can issue in parallel also tend to be spatially correlated (e.g., accesses to multiple fields in a structure). Therefore, the impact of correctly predicting these misses is reduced and speedup is lower than our coverage results suggest.</p><p>In the scan-dominated Qry1, SMS has no statistically significant effect, despite high prediction coverage. In this query, a large amount of data is copied to a temporary database table, which rapidly fills the store buffer with requests that miss in the cache hierarchy. Hence, store-buffer-full stalls limit performance improvement. In this situation, load streaming by SMS is counterproductive, because the readonly blocks fetched by SMS must all be upgraded (i.e., write permission obtained via the coherence protocol), delaying the critical path of draining the store buffer.</p><p>One surprising effect we see is an apparent reduction in system busy time with SMS for web and DSS workloads. However, the absolute fraction of system busy time (i.e., not normalized to forward progress) is identical between the base and SMS systems. We infer that the OS activity during these system-busy intervals is not on behalf of the application, but instead OS work that is proportional to time-for example, servicing traffic from a saturated I/O subsystem.</p><p>In em3d, MLP is high (&gt;4.5) and SMS coverage (63%) is insufficient to predict all misses in a burst. Therefore much of the latency for each burst remains exposed. In sparse, because prediction coverage is high (92%), SMS eliminates nearly all off-chip miss time, improving performance by 307%. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Related work</head><p>Several prior proposals use offline analysis to exploit variations in spatial locality. Vleet and co-authors <ref type="bibr" target="#b27">[28]</ref> propose offline profiling to select fetch size upon a miss. Guided region prefetching <ref type="bibr" target="#b28">[29]</ref> uses compiler hints to direct both spatial and non-spatial (e.g., pointer-chasing) prefetches. However, the complex access patterns and rapid changes in data set common in commercial applications present a challenge for static and profile-based approaches. Moreover, these approaches require application changes or recompilation, whereas SMS is software transparent and adapts at runtime to changing application behavior.</p><p>A variety of hardware approaches exploit variations in spatial locality at runtime, including the dual data cache <ref type="bibr" target="#b10">[11]</ref>, the spatial locality detection table <ref type="bibr" target="#b15">[16]</ref>, and caches that dynamically adjust block size <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b26">27]</ref>. All of these techniques exploit spatial locality variation at coarse granularity, thus sacrificing either bandwidth efficiency or prefetch opportunity. SMS does not modify the fetch/block size, and instead predicts, at fine granularity, precisely which blocks to fetch from a larger region.</p><p>A large class of prediction approaches exploit temporal rather than spatial correlation among addresses (e.g., <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b29">30]</ref>). These approaches eliminate recurring pairs or sequences of consecutive misses. SMS identifies multiple simultaneously-active spatially-correlated regions whose accesses are interleaved. Such spatially-correlated accesses appear uncorrelated to temporal predictors because of the interleaving. Furthermore, the storage requirements of temporal predictors are proportional to data set size, and are therefore larger than for SMS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we showed that memory accesses in commercial workloads are spatially correlated over large memory regions (e.g., several kB) and that this correlation is repetitive and predictable. We demonstrated that code-based correlation is fundamentally superior to address-based correlation because it can predict previously-unvisited addresses. We proposed Spatial Memory Streaming, a practical on-chip hardware technique that identifies code-correlated spatial patterns and streams predicted blocks to the primary cache ahead of demand misses. Using cycle-accurate full-system multiprocessor simulation running commercial and scientific applications, we demonstrated that SMS can on average predict 58% of L1 and 65% of off-chip misses, for an average speedup of 1.37 and at best 4.07.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>FIGURE 4 .</head><label>4</label><figDesc>FIGURE 4. L1 and L2 (off-chip) miss rates versus block/region size. Opportunity represents an oracle spatial predictor that incurs one miss per spatial region generation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FIGURE 5 .</head><label>5</label><figDesc>FIGURE 5. Memory access density. Each segment represents the percentage of L1 or L2 misses from generations of the indicated density (i.e., the number of blocks in the 2kB spatial region that incur misses during the generation).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>FIGURE 8 .</head><label>8</label><figDesc>FIGURE 8. Comparison of training structures. DS=Decoupled Sectored. LS=Logical Sectored. AGT=Active Generation Table. PHT size is unbounded.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>FIGURE 10 .</head><label>10</label><figDesc>FIGURE 10. Spatial region size. SMS with PC+offset indexing and AGT training. PHT size is unbounded.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>FIGURE 13 .</head><label>13</label><figDesc>FIGURE 13. Time breakdown comparison. The base and SMS bars for each application are normalized to represent the same amount of completed work. Their relative height indicates speedup.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table .</head><label>.</label><figDesc>The AGT consists of an accumulation table and a filter table. The figure illustrates the actions taken over the course of one spatial region generation.</figDesc><table><row><cell></cell><cell></cell><cell cols="3">Accumulation Table</cell><cell cols="2">Filter Table</cell></row><row><cell></cell><cell></cell><cell cols="3">Tag PC/offset Pattern</cell><cell cols="2">Tag PC/offset</cell></row><row><cell></cell><cell>Access A+3</cell><cell></cell><cell></cell><cell></cell><cell>A</cell><cell>PC / 3</cell><cell>trigger access misses in accumulation table, allocates in filter table</cell></row><row><cell></cell><cell>Access A+2</cell><cell>A</cell><cell>PC / 3</cell><cell>0011</cell><cell></cell><cell>second access transfers generation from filter to accumulation table</cell></row><row><cell></cell><cell>Access A+0</cell><cell>A</cell><cell>PC / 3</cell><cell>1011</cell><cell></cell><cell>additional accesses set pattern bits in accumulation table</cell></row><row><cell></cell><cell>Evict A+2</cell><cell>A</cell><cell>PC / 3</cell><cell>1011</cell><cell></cell><cell>eviction ends generation and sends pattern to Pattern History Table</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">To Pattern History Table</cell></row><row><cell cols="2">Trigger Access</cell><cell></cell><cell cols="3">Pattern History Table</cell><cell>Prediction Register</cell></row><row><cell>PC</cell><cell>Address</cell><cell></cell><cell>Tag</cell><cell cols="2">Spatial Pattern</cell><cell>Spatial Pattern</cell><cell>Region Base Address</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">110100001010</cell><cell>001100101000</cell></row><row><cell></cell><cell cols="3">prediction tag index</cell><cell cols="2">001100101000</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">...</cell><cell>111111011111 ...</cell><cell>base + 2 Address Stream</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>base + 3</cell></row></table><note>FIGURE 3. Pattern History Table and prediction process.Upon a trigger access that matches in the PHT, the region base address and spatial pattern are transferred to a prediction register, beginning the streaming process.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 1 . System and application parameters.</head><label>1</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>).</figDesc><table><row><cell></cell><cell>100%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>32 Blocks</cell></row><row><cell></cell><cell>80%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>24-31 Blocks</cell></row><row><cell>Read Misses</cell><cell>40% 60%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>16-23 Blocks 8-15 Blocks 4-7 Blocks</cell></row><row><cell></cell><cell>20%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>2-3 Blocks</cell></row><row><cell></cell><cell>0%</cell><cell cols="5">L1 L2 L1 L2</cell><cell></cell><cell cols="10">L1 L2 L1 L2 L1 L2 L1 L2</cell><cell cols="2">L1 L2 L1 L2</cell><cell>L1 L2 L1 L2 L1 L2</cell><cell>1 Block</cell></row><row><cell></cell><cell></cell><cell cols="5">DB2 Oracle</cell><cell></cell><cell></cell><cell cols="9">Qry1 Qry2 Qry16 Qry17</cell><cell cols="2">Apache Zeus</cell><cell>em3d ocean sparse</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">OLTP</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>DSS</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Web</cell><cell>Scientific</cell></row><row><cell cols="18">accesses to database tuples of different sizes). PC+offset</cell><cell></cell></row><row><cell cols="18">indexing can distinguish patterns based on the spatial region</cell><cell></cell></row><row><cell cols="18">offset, which is sufficient to capture the common cases. Our</cell><cell></cell></row><row><cell cols="18">result contradicts a prior study of uniprocessor OLTP and</cell><cell></cell></row><row><cell cols="2">web traces</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">Coverage</cell><cell></cell><cell></cell><cell cols="4">Uncovered</cell><cell></cell><cell cols="7">Overpredictions</cell><cell></cell><cell>OLTP PC+addr DSS PC+addr</cell><cell>OLTP PC+off DSS PC+off</cell></row><row><cell>L1 Read Misses</cell><cell>40% 60% 80% 100% 120% 140% 160%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">≈</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Coverage</cell><cell>40% 60% 80% 100%</cell><cell>Web PC+addr Sci. PC+addr</cell><cell>Web PC+off Sci. PC+off</cell></row><row><cell></cell><cell>0% 20%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>20%</cell></row><row><cell></cell><cell></cell><cell>Addr</cell><cell>PC+addr</cell><cell>PC</cell><cell>PC+off</cell><cell>Addr</cell><cell>PC+addr</cell><cell>PC</cell><cell>PC+off</cell><cell>Addr</cell><cell>PC+addr</cell><cell>PC</cell><cell>PC+off</cell><cell>Addr</cell><cell>PC+addr</cell><cell>PC</cell><cell>PC+off</cell><cell></cell><cell>0%</cell><cell>256</cell><cell>1k PHT Size (# of entries) 4k 16k infinite</cell></row><row><cell></cell><cell></cell><cell cols="4">OLTP</cell><cell></cell><cell cols="2">DSS</cell><cell></cell><cell></cell><cell cols="2">Web</cell><cell></cell><cell cols="4">Scientific</cell><cell></cell></row><row><cell cols="16">FIGURE 6. Index comparison. The index type is</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="15">given below each bar. PHT size is unbounded.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>174% FIGURE 7. PHT storage sensitivity for PC+address and PC+offset indexing. The finite PHTs are 16-way set-associative.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Table. PHT size is unbounded.</figDesc><table><row><cell></cell><cell cols="2">140% Coverage 160%</cell><cell>Uncovered</cell><cell cols="2">Overpredictions</cell><cell>100%</cell><cell></cell><cell cols="2">OLTP LS DSS LS Web LS Sci. LS</cell><cell cols="2">OLTP AGT DSS AGT Web AGT Sci. AGT</cell></row><row><cell>L1 Read Misses</cell><cell>40% 60% 80% 100% 120%</cell><cell></cell><cell></cell><cell></cell><cell>Coverage</cell><cell>80% 40% 60%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>20%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>20%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0%</cell><cell>DS OLTP LS AGT</cell><cell>DS DSS LS AGT</cell><cell>DS Web LS AGT</cell><cell>DS Scientific LS AGT</cell><cell>0%</cell><cell>256</cell><cell>512</cell><cell cols="2">1k PHT Size (# of entries) 2k 4k 8k</cell><cell>16k</cell><cell>infinite</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="7">FIGURE 9. PHT storage sensitivity. LS=Logical</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">Sectored. AGT=Active Generation Table.</cell></row><row><cell cols="6">sector tend to be replaced together, and thus the decoupled</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">and logical sectored tags behave identically.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Practical SMS configuration and comparison to the Global History Buffer</head><label></label><figDesc>. GHB•256 and GHB•16k refer to PC/DC GHB with 256-and 16k-entry history buffers, respectively. SMS uses AGT training (with a 32-entry filter table and 64-entry accumulation table), 2kB spatial regions, and a 16k-entry, 16-way set-associative PHT.</figDesc><table><row><cell cols="12">0% 20% 40% 60% 80% 100% 120% 140% 160% FIGURE 11. ≈ GHB•256 GHB•16k SMS GHB•256 GHB•16k SMS GHB•256 GHB•16k SMS GHB•256 GHB•16k SMS GHB•256 GHB•16k SMS GHB•256 GHB•16k SMS GHB•256 GHB•16k SMS GHB•256 GHB•16k SMS GHB•256 GHB•16k SMS DB2 Oracle Qry1 Qry2 Qry16 Qry17 Apache Zeus em3d OLTP DSS Web L2 Read Misses Coverage Uncovered Overpredictions 181%</cell><cell>GHB•256 ocean sparse GHB•16k SMS GHB•256 GHB•16k SMS Scientific</cell></row><row><cell></cell><cell>1.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">4.07 ± 0.31 ≈</cell></row><row><cell></cell><cell>1.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Speedup</cell><cell>1.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>DB2</cell><cell>Oracle</cell><cell>Qry1</cell><cell>Qry2</cell><cell>Qry16</cell><cell>Qry17</cell><cell>Apache</cell><cell>Zeus</cell><cell>em3d</cell><cell>ocean</cell><cell>sparse</cell></row><row><cell></cell><cell cols="2">OLTP</cell><cell></cell><cell cols="2">DSS</cell><cell></cell><cell cols="2">Web</cell><cell cols="3">Scientific</cell></row><row><cell cols="10">FIGURE 12. Speedup with 95% confidence</cell><cell></cell></row><row><cell cols="10">intervals. Geometric mean speedup is 1.37.</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors would like to thank the SimFlex team, and Michael Ferdman, Jared Smolens, and the anonymous reviewers for their feedback on drafts of this paper. This work was partially supported by grants and equipment from Intel, two Sloan research fellowships, an NSERC Discovery Grant, an IBM faculty partnership award, and NSF grants CCR-0205544, CCR-0509356, and IIS-0133686.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Shared memory consistency models: A tutorial</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Adve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gharachorloo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="66" to="76" />
			<date type="published" when="1996-12">Dec. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">DBMSs on a modern processor: Where does time go?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Dewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The VLDB Journal</title>
				<imprint>
			<date type="published" when="1999-09">Sep. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Memory system characterization of commercial workloads</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Barroso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bugnion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Symposium on Computer Architecture</title>
				<meeting>the 25th International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1998-06">June 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Accurate and complexity-effective spatial pattern prediction</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Symposium on High-Performance Computer Architecture</title>
				<meeting>the Tenth Symposium on High-Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2004-02">Feb. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Improving hash join performance through prefetching</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Mowry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on Data Engineering</title>
				<meeting>the 20th International Conference on Data Engineering</meeting>
		<imprint>
			<date type="published" when="2004-04">Apr. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Microarchitecture optimizations for exploiting memory-level parallelism</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fahs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Abraham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Symposium on Computer Architecture</title>
				<meeting>the 31st International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2004-06">June 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Performance analysis of the Alpha 21364-based HP GS1280 multiprocessor</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cvetanovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Symposium on Computer Architecture</title>
				<meeting>the 30th International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2003-06">June 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adjustable block size coherence caches</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dubnicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Leblanc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Symposium on Computer Architecture</title>
				<meeting>the 19th International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1992-06">June 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Two techniques to enhance the performance of memory consistency models</title>
		<author>
			<persName><forename type="first">K</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hennessy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1991 International Conference on Parallel Processing</title>
				<meeting>the 1991 International Conference on Parallel Processing</meeting>
		<imprint>
			<date type="published" when="1991-08">Aug. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Is SC + ILP = RC?</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gniady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Vijaykumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Symposium on Computer Architecture</title>
				<meeting>the 26th International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1999-05">May 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A data cache with multiple caching strategies tuned to different types of locality</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Aliagas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Valero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Supercomputing</title>
				<imprint>
			<date type="published" when="1995-07">July 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mi-croLib: A case for the quantitative comparison of micro-architecture mechanisms</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Gracia</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mouchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Temam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Symposium on Microarchitecture</title>
				<meeting>the 37th International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2004-12">Dec. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Scaling and characterizing database workloads: Bridging the gap between research and practice</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hankins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Diep</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Annavaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hirano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Eri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nueckel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Symposium on Microarchitecture</title>
				<meeting>the 36th International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2003-12">Dec. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">SimFlex: A fast, accurate, flexible full-system simulation framework for performance evaluation of server architecture</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hardavellas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Wunderlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Hoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Nowatzyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGMETRICS Performance Evaluation Review</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="31" to="35" />
			<date type="published" when="2004-04">Apr. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Coherence decoupling: making use of incoherence</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Architectural Support for Programming Languages and Operating Systems</title>
				<meeting>the Eleventh International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="2004-10">Oct. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Run-time spatial locality detection and optimization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Merten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-M</forename><surname>Hwu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Symposium on Microarchitecture</title>
				<meeting>the 31st International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="1998-11">Nov.1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Exploiting spatial locality in data caches using spatial footprints</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wilkerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Symposium on Computer Architecture</title>
				<meeting>the 25th International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1998-06">June 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dead-block prediction &amp; dead-block correlating prefetchers</title>
		<author>
			<persName><forename type="first">A.-C</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Annual International Symposium on Computer Architecture</title>
				<meeting>the 28th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2001-07">July 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Runahead execution: an effective alternative to large instruction windows</title>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wilkerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="20" to="25" />
			<date type="published" when="2003-12">Nov./ Dec. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Data cache prefetching using a global history buffer</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Nesbit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Symposium on High-Performance Computer Architecture</title>
				<meeting>the Tenth Symposium on High-Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2004-02">Feb. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Performance of database workloads on shared-memory systems with out-of-order processors</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ranganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Adve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Barroso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Conference on Architectural Support for Programming Languages and Operating Systems</title>
				<meeting>the Eighth International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="1998-10">Oct. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Decoupled sectored caches</title>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="210" to="215" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">DBmbench: Fast and accurate database workload representation on modern microarchitecture</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th IBM Center for Advanced Studies Conference</title>
				<meeting>the 15th IBM Center for Advanced Studies Conference</meeting>
		<imprint>
			<date type="published" when="2005-10">Oct. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Predictor-directed stream buffers</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sherwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Symposium on Microarchitecture</title>
				<meeting>the 33rd International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2000-12">Dec. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Using a user-level memory thread for correlation prefetching</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Solihin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Torrellas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Symposium on Computer Architecture</title>
				<meeting>the 29th International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2002-05">May 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The memory performance of DSS commercial workloads in shared-memory multiprocessors</title>
		<author>
			<persName><forename type="first">P</forename><surname>Trancoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Larriba-Pey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Torellas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Symposium on High-Performance Computer Architecture</title>
				<meeting>the Third Symposium on High-Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1997-02">Feb. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Adapting cache line size to application behavior</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Veidenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nicolau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Supercomputing</title>
				<imprint>
			<date type="published" when="1999-07">July 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Pursuing the performance potential of dynamic cache line sizes</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">V</forename><surname>Vleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Bear</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Design</title>
				<imprint>
			<date type="published" when="1999-10">Oct. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Guided region prefetching: a cooperative hardware/software approach</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Mckinley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Reinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Weems</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Symposium on Computer Architecture</title>
				<meeting>the 30th International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2003-06">June 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Temporal streaming of shared memory</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hardavellas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Symposium on Computer Architecture</title>
				<meeting>the 32nd International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2005-06">June 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Simulation sampling with live-points</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Wunderlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Hoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Performance Analysis of Systems and Software</title>
				<meeting>the International Symposium on Performance Analysis of Systems and Software</meeting>
		<imprint>
			<date type="published" when="2006-06">June 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">SMARTS: Accelerating microarchitecture simulation through rigorous statistical sampling</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Wunderlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Hoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Symposium on Computer Architecture</title>
				<meeting>the 30th International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2003-06">June 2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
