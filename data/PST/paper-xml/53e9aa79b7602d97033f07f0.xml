<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Gregarious Particle Swarm Optimizer (G-PSO)</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Srinivas</forename><surname>Pasupuleti</surname></persName>
							<email>srinivas@dit.unitn.it</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">Telecommunications University of Trento</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Roberto</forename><surname>Battiti</surname></persName>
							<email>battiti@dit.unitn.it</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">Telecommunications University of Trento</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Gregarious Particle Swarm Optimizer (G-PSO)</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">546B1FE55468A5CA91EDB751BC8DB13E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T10:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>G.1.6 [Numerical Analysis]: Optimization-Global Optimization; I.2.8 [Artificial Intelligence]: Problem Solving</term>
					<term>Control Methods</term>
					<term>and Search-Heuristic methods Particle swarm algorithm</term>
					<term>Repeated Affine Shaker</term>
					<term>Differential Evolution</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents a gregarious particle swarm optimization algorithm (G-PSO) in which the particles explore the search space by aggressively scouting the local minima with the help of only social knowledge. To avoid premature convergence of the swarm, the particles are re-initialized with a random velocity when stuck at a local minimum. Furthermore, G-PSO adopts a "reactive" determination of the step size, based on feedback from the last iterations. This is in contrast to the basic particle swarm algorithm, in which the particles explore the search space by using both the individual "cognitive" component and the "social" knowledge and no feedback is used for the self-tuning of algorithm parameters. The novel scheme presented, besides generally improving the average optimal values found, reduces the computation effort.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The problem being addressed is that of minimizing a function f mapping a vector x ∈ D ⊆ R d of d real numbers into a real number,</p><formula xml:id="formula_0">min x∈D f (x) where f : D ⊆ R d → R</formula><p>where d is the dimension of the search space D. The goal is to find a global optimum x * , such that</p><formula xml:id="formula_1">f (x * ) ≤ f (x), ∀x ∈ D</formula><p>Population-based stochastic local search techniques are a new paradigm in the field of function optimization. Particle Swarm Optimization <ref type="bibr" target="#b12">[11]</ref>, PSO for short, is one of the simplest algorithms using a population of searchers, inspired by bird flocking phenomena and social behavior of humans. We refer to one of the earlier and highly used version of PSO presented in <ref type="bibr" target="#b19">[18]</ref> as the Basic-PSO throughout the paper. In this paper we propose a gregarious particle swarm optimization algorithm (G-PSO), where the only information shared by the swarm members is the best value found during the previous search of the swarm up to the current iteration.</p><p>To make this very simple version effective, an adaptive online tuning of the step size is executed during the search, motivated by the Reactive Search approach presented in <ref type="bibr" target="#b5">[4]</ref>, and a simple individual restart strategy is activated for each particle if there is evidence of stagnation. The experimental results confirm the original findings in <ref type="bibr">[9]</ref> that "social-only" versions can easily outperform the complete model in certain cases. When coupled with the "reactive" and restart mechanisms considered in this paper the conclusion seems to hold not only for the simple case considered in <ref type="bibr">[9]</ref>, but for more general optimization tasks.</p><p>A brief description of Basic-PSO is presented in Section 2. The issues and related work done to improve the performance are discussed in Section 3. In Section 4 the G-PSO algorithm is presented. Different optimization algorithms used for comparison are discussed in Section 5. The simulation settings and results are presented in Section 6 and Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">BASIC-PSO ALGORITHM</head><p>This brief summary of PSO is intended to fix the notation and to specify the precise version used in the comparison. We refer the readers to the cited bibliography for more details, see for example <ref type="bibr" target="#b19">[18,</ref><ref type="bibr" target="#b20">19]</ref>. The position and velocity vectors of the i-th particle in the d-dimensional search space at time t are denoted as xi(t) ≡ xi1(t), . . . , x id (t) ¡ and vi(t) ≡ vi1(t), . . . , v id (t)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>¡</head><p>. The best position of the i-th particle up to time t is referred to as p i (t) and the global best position among all particles in the population up to time t is called g(t). The positions of particles are initialized by picking points at random and with uniform probability in an initialization range delimited by a lower bound L j and an upper bound U j : xij(0) = rand(L j , U j ), where Lj ≤ L j &lt; U j ≤ Uj. Note that the initialization range (L j , U j ) is a subset of the over all search range (Lj, Uj) for reasons explained later in the paper. The initial velocity vi(0) of particle i is chosen with uniform probability within suitable limits: vij (0) = rand(-Vmax, Vmax). The velocity and position update equations are as follows:</p><formula xml:id="formula_2">vij (t) = w • vij (t -1) + c1 • r1,j • (pij(t -1) -xij (t -1)) +c2 • r2,j • (gj(t -1) -xij(t -1)) (1) xij (t) = xij(t -1) + vij (t)<label>( 2 )</label></formula><p>where r1,j and r2,j are different random numbers in the range [0, 1] following the uniform distribution. The parameters c1 and c2 are known as acceleration coefficients. The second and third terms on the right hand side of eqn. (1) represent the "cognitive" and "social" components, respectively. The velocity components of the particle vij are limited to a maximum allowable modulus Vmax, as follows:</p><formula xml:id="formula_3">vij ←- -Vmax if vij &lt; -Vmax Vmax if vij &gt; Vmax vij</formula><p>otherwise.</p><p>(</p><formula xml:id="formula_4">)<label>3</label></formula><p>The value of Vmax is defined as one half of the total search range. The term inertia weight w in equation ( <ref type="formula">1</ref>) is decreased linearly with time as suggested in <ref type="bibr" target="#b18">[17]</ref>:</p><formula xml:id="formula_5">w = (w1 -w2) × (MAXIT ER -t) MAXIT ER + w2<label>(4)</label></formula><p>where w1 and w2 are the initial and final values, respectively. The inertia weight controls the impact of the previous velocity: a large inertia weight favors exploration, while a small inertia weight favors exploitation. Thus, a high inertia weight at the beginning of the search helps in exploring the search space by avoiding local minima, while decreasing the inertia weight as the search proceeds helps in exploiting the search space and converging to the optimal solution <ref type="bibr" target="#b19">[18]</ref>. t is the current iteration number and MAXIT ER is the maximum number of allowed iterations before termination. Following the velocity and position updates, the personal best of a particle at time step t is updated as:</p><formula xml:id="formula_6">p i (t) ←-´pi (t -1) if f (xi(t)) ≥ f (p i (t -1)) xi(t) o t h e r w i s e<label>(5)</label></formula><p>The global best position is asynchronously updated <ref type="bibr" target="#b7">[6]</ref>, as soon as each new best position is evaluated, by using the following equation:</p><formula xml:id="formula_7">g(t) = arg min{f (p 1 (t)), f(p 2 (t)), . . . , f(p s (t))} (<label>6</label></formula><formula xml:id="formula_8">)</formula><p>where s is the swarm size. Fig. <ref type="figure" target="#fig_0">1</ref> summarizes the Basic-PSO algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">ISSUES AND RELATED WORK PSO</head><p>The major advantage of PSO over basic Evolutionary Algorithms (EAs) is that, in PSO, each individual benefits from its history whereas no such mechanism exists in the EAs <ref type="bibr" target="#b3">[2,</ref><ref type="bibr" target="#b8">7]</ref>. Each particle memorizes its previous velocity and the previous best position and uses them in its movement.</p><p>According to <ref type="bibr" target="#b3">[2]</ref>, although PSO finds good solutions much faster than other evolutionary algorithms, it usually cannot  improve the quality of solutions as the number of iterations increases and it suffers from premature convergence when strongly multi-modal problems are being optimized. One of the main reasons is that all particles converge to a single point as the speed of the particles is decreased with time, thus forcing them to converge to the global best point found so far, which is not guaranteed even to be a local minimum. If a particle's current position is very close to the global best position, the particle will move away from this point only if its previous velocity and inertia weight w are non-zero.</p><formula xml:id="formula_9">Algorithm : Basic-PSO(L, U, s, Vmax, MAXIT ER) t ← 1 for i ← 1 to s do for j ← 1 to d do xij ← rand(L j , U j ) vij ← rand(-Vmax, Vmax) p i ← xi g ← arg min{f (p 0 ), f(p 1 ), . . . ,</formula><p>Stochastic search techniques are usually problem dependent and thus an efficient parameter setting forms an important part of the algorithm. PSO is no exception: modifying a single parameter may result in a large effect <ref type="bibr" target="#b7">[6]</ref>. For example, increasing the value of the inertia weight w will increase the speed of the particles resulting in more exploration and less exploitation. Many researchers tried to improve the performance by tuning the parameters of Basic-PSO <ref type="bibr" target="#b21">[20]</ref>, or by adding new parameters such as mutation <ref type="bibr" target="#b18">[17]</ref>. The combination of PSO with other evolutionary algorithms has introduced new parameters and increased the computational effort <ref type="bibr" target="#b14">[13]</ref>, with varying degree of success for different problems. In <ref type="bibr" target="#b17">[16]</ref> genetic programming is used as a tool to derive PSO variants.</p><p>We follow the opposite direction of research, which considers simplifications, elimination of parameters or automated self-tuning schemes so that the final user is not charged with the burden of a preliminary tuning phase. Ofcourse the complexity of the algorithm increases because of the internal feedback scheme, but this burden is on the shoulders of the researcher and not on the end user. As an example, a simplified version called "social-only" has been presented in <ref type="bibr">[9]</ref>, in which the particles are only guided by the social knowledge. The version is shown to perform better than the Basic-PSO for a very simple XOR problem. But the algorithm has not been widely considered and analyzed. Our proposal, G-PSO, differs from this version because it does not take into account the previous velocity, the step size is adjusted in an adaptive manner during the search, therefore avoiding a preliminary tuning, and the velocity is re-initialized to displace the particles away from the local minimum when there is evidence of stagnation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">THE GREGARIOUS-PSO (G-PSO) ALGORITHM</head><p>In G-PSO, the population is attracted by the global best position and each particle is re-initialized with a random velocity if it is stuck close to the global best position. In this manner, the algorithm proceeds by aggressively and greedily scouting the local minima whereas Basic-PSO proceeds by trying to avoid them. Therefore a re-initialization mechanism is needed to avoid the premature convergence of the swarm.</p><p>In every iteration, each particle will either take a step along the direction towards the global best position or be re-initialized if it gets very close to the global best position. The particle's velocity is re-initialized in the range [-Vmax, Vmax], if the Euclidean distance between its current position and the global best position is less than . The d-dimensional velocity vector vi(t) is thus updated as follows:</p><formula xml:id="formula_10">if (||xi(t -1) -g(t -1)|| ≤ ) ∀j vij (t) = randj(-Vmax, Vmax) else ∀j vij (t) = γ • randj(0, 1) • (xij(t -1) -gj(t -1))<label>(7)</label></formula><p>where randj(-Vmax, Vmax) and randj(0, 1) are independent random numbers for every dimension in the range [-Vmax, Vmax] and [0, 1], respectively. Because the best position found by the swarm is the only shared information in the swarm, we call the algorithm the gregarious particle swarm optimization algorithm. The factor γ determines the step size of each particle in the direction of the global best position. Large values of γ will make the current particle i go past the global best position, thus resulting in oscillations and small values of γ will result in small step sizes which will lead to slow convergence to the global best position. Thus, γ is reactively adjusted by checking the improvement on the global best value found at the end of every iteration. The value of γ is bounded by the limits [γmin, γmax] and is linearly adjusted at the end of every iteration, as follows:</p><formula xml:id="formula_11">γ ←- ´max(γ -δ, γmin) if (f (g(t)) &lt; f(g(t -1)) min(γ + δ, γmax) otherwise (<label>8</label></formula><formula xml:id="formula_12">)</formula><p>where δ is a constant. The values of the limits of γ and of δ used in our simulations are <ref type="bibr" target="#b3">[2,</ref><ref type="bibr" target="#b5">4]</ref> and 0.5, respectively. The initial value of γ is set to 3.0. While the choice of the step size δ is robust, the motivation for determining the limits is as follows. Each component of the difference (xi(t -1)g(t -1)) in eqn. ( <ref type="formula" target="#formula_10">7</ref>) is multiplied by a mean factor of 1.5 initially. If there is improvement in the global best value, the value of γ is decreased up to a minimum value equal to 2. Thus, as the performance improves, the particles tend to converge to the global best position, resulting in an aggressive search for local minima. If the global best value in not improved over the iterations, the value of γ is increased</p><formula xml:id="formula_13">Algorithm : G-PSO(L, U, s, Vmax, γ, MAXIT ER) t ← 1 for i ← 1 to s do for j ← 1 to d do ¨xij ← rand(L j , U j ) g ← arg min{f (x0), f(x1), . . . , f(xs)} while t ≤ MAXIT ER do for i ← 1 to s do for j ← 1 to d do</formula><p>Update Velocity using Eq: 7 Limit Velocity using Eq: 3 Update Position using Eq: 2 Update global best applying Eq: 6 Adjust the step size γ applying Eq: 8 t ← t + 1 return (g) Figure <ref type="figure">2</ref>: The Gregarious PSO Algorithm up to a maximum value 4.0, which would help the particles to explore the search space by oscillating around the current minimum, in order to find better directions. The G-PSO algorithm is summarized in the pseudo-code of Fig. <ref type="figure">2</ref>. The difference between Figs. 1 and 2 is that there is no update of the personal best here, as the particles do not memorize their previous search history and the velocity update equation used is <ref type="bibr" target="#b8">(7)</ref> instead of <ref type="bibr" target="#b2">(1)</ref>.</p><p>The advantage of G-PSO is two-fold. Due to its greediness in scouting local minima, it finds promising regions rapidly during the initial phase of the search, while due to re-initialization with random velocities, the particles don't loose the global exploration capability and thus they will tend to find better optima as the search continues.</p><p>An analogy of the principle of G-PSO with nature can be as follows: consider a flock of birds looking for food. If one of the birds locates a region rich with food, all the birds get to that place, although with some exploratory oscillations around the place. As they see that there is no more food left, one after another they leave the place in search of more food, thereby exploring different food regions. The velocity update equation ( <ref type="formula" target="#formula_10">7</ref>) makes all the particles converge close to the global best position found and the re-initialization with random velocities makes the particles explore the search region as they get very close to the global best position found.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">OPTIMIZATION ALGORITHMS USED FOR COMPARISON</head><p>We compare the G-PSO with Basic-PSO, a variant of PSO called HPSO-TVAC <ref type="bibr" target="#b18">[17]</ref> and two other stochastic local search techniques: Repeated Affine Shaker <ref type="bibr" target="#b6">[5]</ref> and Differential Evolution <ref type="bibr" target="#b22">[21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">HPSO-TVAC</head><p>HPSO-TVAC <ref type="bibr" target="#b18">[17]</ref> is a self-organizing hierarchical particle swarm optimizer with time-varying acceleration coefficients. In this, the inertia weight term is set to zero in equation <ref type="bibr" target="#b2">(1)</ref> and hence the movement of the particle is guided only by the "cognitive" and "social" components. If the particles stagnate along any dimension i.e., vij ≡ 0, the particles are re-initialized with a random velocity. The acceleration coefficients c1 and c2 are varied linearly with time to enhance the global search in the early part of the optimization and to make the particles converge toward global optima at the end of the search. The optimal performance has been observed when changing c1 from 2.5 to 0.5 and changing c2 from 0.5 to 2.5, over the full range of the search. We thus consider the same values in our simulation with re-initialization velocity equal to the maximum limit of the velocity Vmax.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Repeated Affine Shaker</head><p>The Affine Shaker algorithm (AS) proposed in <ref type="bibr" target="#b6">[5]</ref> is an adaptive random search algorithm based only on the knowledge of function values. The algorithm starts by choosing an initial point x in the configuration space and an initial search region R surrounding it. At every iteration, a new point is chosen randomly within the search region R. The search region is then modified according to the value of the function at the new point by using an affine transformation. It is compressed if the new function value is greater than the current one (unsuccessful sample) or expanded otherwise (successful sample). If the sample is successful, the new point becomes the current point, and the search region R is translated so that the current point is at its center for the next iteration. Once an improvement in the function value is found, the search region grows in the promising direction, causing a faster movement along that direction. The search region is compressed in every step that fails to find a better point along the chosen search direction. Each AS run is terminated when the size of steps for 8 consecutive times is less than 10 -8 . By design, AS searches for local minimizers and is stopped as soon as one is found. A simple variant of AS is the Repeated Affine Shaker algorithm, in which the search is continued after a local minimum is found by restarting from a different initial random point. This leads to a "population" of AS searchers, but in this case each member of the population is independent, completely unaware of what other members are doing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Differential Evolution</head><p>The Differential Evolution (DE) algorithm <ref type="bibr" target="#b22">[21]</ref> is a stochastic search algorithm which uses a population of potential solutions to exploit the search space. DE borrows the concepts of mutation, crossover and selection to choose potential solutions for each generation. In the initial population the corresponding vectors are chosen randomly in the entire search space. For each generation, a mutant vector for a chosen target vector is generated by adding the weighted difference between two population vectors to a third vector. The mutated vector's parameters are then mixed with the parameters of the target vector, to yield a trial vector. If the trial vector is a better solution compared to the target vector, then the target vector is replaced by the trial vector. DE has been shown to be an efficient algorithm for global optimization with few control parameters namely, the scaling factor (F ) and the crossover factor (CF ). There are many variants of DE based on the choice of vector to be mutated, the number of difference vectors used and the type of crossover scheme. We adopt a well known variant of DE, "DE/best/1/exp" <ref type="bibr" target="#b16">[15]</ref>, in which the best vector is mutated with only one difference vector and the crossover scheme is exponential. The value of F is 0.5 and CF is 0.8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">EXPERIMENTAL SETTINGS</head><p>The benchmark functions are given in Table <ref type="table" target="#tab_1">1</ref>. The first two functions are unimodal whereas the next functions are multimodal. The global minimum for the first five functions is 0.0. The Schaffer f6 function is maximized for a global maximum of 1.0 at origin. The global minimum for Shekel's foxholes f7 function is at (-31.95,-31.95) with value equal to 0.998, approximated to three decimal places. </p><formula xml:id="formula_14">30 d i=1 100(xi+1 -x 2 i ) 2 + (xi -1) 2 ¡ Rastrigin f3(x) 30 d i=1</formula><p>x 2 i -10 cos 2πxi + 10</p><formula xml:id="formula_15">¡ Griewank f4(x) 30 1 4000 d i=1 x 2 i - d i=1 cos xi √ i + 1 Ackley f5(x) 30 -20e -0.2 √ ( 1 d È d i=1 x 2 i ) -e 1 d È d i=1 cos2Πx i + 20 + e Schaffer's f6(x) 2 0.5 - (sin Ô x 2 + y 2 ) 2 -0.5 (1.0 + 0.001(x 2 + y 2 )) 2 Shekel's foxholes f7(x) 2 ( 1 500 + 25 j=1 1 j + È 2 i=1 (xi -aij) 6 ) -1</formula><p>The initialization and search ranges, already used by other researchers, are given in Table <ref type="table" target="#tab_2">2</ref>. The asymmetric initialization method adopted for the experiments suggests deliberately initializing the population in regions that do not include the global optimum for a fair evaluation <ref type="bibr" target="#b3">[2,</ref><ref type="bibr" target="#b4">3]</ref>. The constants c1 and c2 of Basic-PSO are both fixed at 2.0, and the inertia weight w is varied from w1 = 0.9 at the beginning of the search to w2 = 0.4 at the end <ref type="bibr">[10]</ref>. The swarm size s is equal to 40 for the G-PSO, Basic-PSO and HPSO-TVAC, as suggested in <ref type="bibr" target="#b7">[6]</ref>. For DE, the population size is equal to ten times the dimensionality of the search region <ref type="bibr" target="#b22">[21]</ref>. For the Repeated Affine Shaker, there is only one searcher, and the algorithm is restarted when the modulus of subsequent steps becomes less than 10 -8 . The parameter used to measure the proximity of global best position and current position of a particle in G-PSO is 10 -8 . The algorithms are run for 100 trials and the average optimum value f (g) is measured as a function of the number of function evaluations. The number of function evaluations is given by the product of MAXITER and swarm size s. The termination criterion is 200000 function evaluations for each run. The experiments are performed on a computer with Intel Xeon CPU 2.80GHz and 1GB of RAM, by using the gcc compiler.  </p><formula xml:id="formula_16">[L1, U1] × • • • × [L d , U d ] [L 1 , U 1 ] × • • • × [L d , U d ] f1 [-</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">RESULTS</head><p>Figs. <ref type="figure">3</ref><ref type="figure">4</ref><ref type="figure" target="#fig_1">5</ref><ref type="figure">6</ref><ref type="figure">7</ref><ref type="figure">8</ref><ref type="figure">9</ref>show the comparison between G-PSO, Basic-PSO and the other stochastic algorithms. The plots are on a log-log scale. The graphs plot the average optimum value found as a function of the number of function evaluations except for the Schaffer function whose y-axis is one minus the average optimum, i.e., the distance from the optimal value of 1.</p><p>Except for the Schaffer and Griewank functions, G-PSO outperforms the Basic-PSO and HPSO-TVAC for all the benchmark functions. G-PSO improves the quality of the average optimum found as a function of the number of function evaluations and also leads to faster convergence against Basic-PSO. The Griewank function is a non-convex function with over 1000 optima in the range of interest, and the density of local minima increases as one approaches the global optimum. G-PSO, though faster at the beginning, tends to get stuck in one of the local minima.</p><p>The Schaffer function is a 2-dimensional maximization function with many circular valleys surrounding the global maximum of 1 at (0, 0). It is designed to trap algorithms searching for local minima. In G-PSO the searchers tend to settle down on the first valley very close to the global maximum. The Ashaker and DE also find it hard to cross the valleys and converge prematurely. The 2-dim Shekel function contains 25 foxholes of varying depth surrounded by a relatively flat surface. The DE algorithm is stuck in the first foxhole it falls into. And, although the convergence rate is faster at the beginning in the case of Basic-PSO, both G-PSO and Basic-PSO reach the global minimum at approximately the same time.</p><p>The average optimal value obtained at the end of 200000 function evaluations is presented in Table <ref type="table" target="#tab_4">3</ref>. The error on the average is obtained by dividing the standard deviation of results by the square root of the number of runs. If the average optimum value or error is less than 10 -6 , it is shown as 0 in the table. It can be observed that G-PSO tends to yield better average optimal values when compared to other well-known algorithms, with least error on the average.</p><p>The CPU time for each algorithm for 200000 function evaluations is presented in Table <ref type="table" target="#tab_5">4</ref>. DE has the least computational time of all the algorithms except for the last two functions. With functions f5 and f6, DE gets stuck in the first local minima it lands on and it spends lot of time on selection and crossover operations. The computation time of G-PSO is close to DE and is better than DE for the functions f6 and f7, due to the simplicity of the velocity update      <ref type="table" target="#tab_4">3</ref>), but it consumes a large CPU time as the algorithm involves high dimensional matrix-vector multiplications during the affine transformation of the search region.</p><p>To check whether the algorithms converge to global optimum or not, they are run until either the average optimum value is less than 10 -6 (global minimum of all functions is zero except for Shekel function whose minimum is 0.998004) or until a maximum of 2 × 10 6 function evaluations. The algorithms are run for 100 trials for each benchmark function. Table <ref type="table" target="#tab_6">5</ref> shows the number of runs which lead to convergence and the average number of function evaluations for the successful runs. The hyphen(-) mark indicates that none of the runs reached the optimal value. Except for the Griewank function which contains a huge number of local minima, G-PSO converges for all the 100 runs. Also, the mean number of function evaluations required for convergence tends to be less when compared with that of the other algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">CONCLUSION</head><p>The motivation for considering the proposed gregarious PSO algorithm has been to see whether a simplified version of PSO, coupled with a dynamic tuning of the step size and a randomized restart when each particle is stuck could be as affective as more complex versions. In particular, the simplifying assumption is that the only information shared by the swarm particles is the best optimum found so far by the entire swarm.</p><p>Therefore the particles, instead of aiming at a compromise between social knowledge and personal knowledge, are "gregarious" as they aggressively search in the neighborhood of the best optimum found by the entire swarm, with randomized oscillations around the best position. The dynamic re-initialization allows the particles to explore the search space and find new local minima when they are stuck at a local optimum. The reactive adjustment of step size helps in exploiting and exploring the search space based on the success of the last iterations. The gregarious particle swarm optimization algorithm has a fast convergence rate, yielding in many cases better average optimal values with the least error on the average, when compared to the basic particle swarm algorithm and other well-known optimization algo-</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Basic PSO Algorithm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 5 :</head><label>5</label><figDesc>Figure 3: Experimental results on Sphere</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>Figure 6: Experimental results on Griewank</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 8 :Figure 9 :</head><label>89</label><figDesc>Figure 8: Experimental results on Schaffer</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 : Benchmarks for simulations, where d is the dimension of the function</head><label>1</label><figDesc></figDesc><table><row><cell>Function</cell><cell>d</cell><cell>Mathematical Representation</cell></row><row><cell>Name</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>d</cell></row><row><cell>Sphere</cell><cell>30</cell><cell>x 2 i</cell></row><row><cell>f1(x)</cell><cell></cell><cell>i=1</cell></row><row><cell>Rosenbrock</cell><cell></cell><cell></cell></row><row><cell>f2(x)</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 : Search range and initialization range for the benchmark functions</head><label>2</label><figDesc></figDesc><table><row><cell>Func.</cell><cell>Search range</cell><cell>Initialization range</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 : Average optimum value and standard deviation at the end of 200000 function evaluations</head><label>3</label><figDesc></figDesc><table><row><cell>Function</cell><cell>G-PSO</cell><cell cols="2">Basic-PSO HPSO-TVAC</cell><cell>AShaker</cell><cell>DE</cell></row><row><cell>f1</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell>(0)</cell><cell>(0)</cell><cell>(0)</cell><cell>(0)</cell><cell>(0)</cell></row><row><cell>f2</cell><cell>2.46</cell><cell>75.30</cell><cell>7.14</cell><cell>161.921</cell><cell>34.35</cell></row><row><cell></cell><cell>(10.14)</cell><cell>(131.269)</cell><cell>(17.25)</cell><cell>(212.328)</cell><cell>(26.62)</cell></row><row><cell>f3</cell><cell>0.13</cell><cell>28.25</cell><cell>1.59</cell><cell>140.045</cell><cell>27.43</cell></row><row><cell></cell><cell>(0.36)</cell><cell>(7.75)</cell><cell>(3.63)</cell><cell>(16.95)</cell><cell>(16.4193)</cell></row><row><cell>f4</cell><cell>0.066</cell><cell>0.0150</cell><cell>0.0157</cell><cell>0</cell><cell>0.0035</cell></row><row><cell></cell><cell>(0.05)</cell><cell>(0.016)</cell><cell>(0.018)</cell><cell>(0)</cell><cell>(0.0057)</cell></row><row><cell>f5</cell><cell>0.037</cell><cell>3.423</cell><cell>19.381</cell><cell>20.559</cell><cell>0.0008</cell></row><row><cell></cell><cell>(0.205)</cell><cell>(7.564)</cell><cell>(0.287)</cell><cell>(2.04)</cell><cell>(0.0047)</cell></row><row><cell>f6</cell><cell>0.002</cell><cell>0</cell><cell>0.00793</cell><cell>0.0034</cell><cell>0.0488</cell></row><row><cell></cell><cell>(0.0039)</cell><cell>(0)</cell><cell>(0.00588)</cell><cell>(0.0046)</cell><cell>(0.089)</cell></row><row><cell>f7</cell><cell cols="2">0.998004 0.998004</cell><cell>0.998004</cell><cell>0.998004</cell><cell>15.471</cell></row><row><cell></cell><cell>(0)</cell><cell>(0)</cell><cell>(0)</cell><cell>(0)</cell><cell>(6.605)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 : CPU time in seconds at the end of 200000 function evaluations</head><label>4</label><figDesc></figDesc><table><row><cell cols="6">Func. G-PSO Basic-PSO HPSO-TVAC AShaker DE</cell></row><row><cell>f1</cell><cell>0.52</cell><cell>0.80</cell><cell>0.89</cell><cell>24.66</cell><cell>0.39</cell></row><row><cell>f2</cell><cell>0.55</cell><cell>0.80</cell><cell>0.89</cell><cell>26.37</cell><cell>0.44</cell></row><row><cell>f3</cell><cell>1.03</cell><cell>1.28</cell><cell>1.34</cell><cell>24.91</cell><cell>0.93</cell></row><row><cell>f4</cell><cell>1.27</cell><cell>1.51</cell><cell>1.59</cell><cell>26.14</cell><cell>1.25</cell></row><row><cell>f5</cell><cell>1.09</cell><cell>1.35</cell><cell>1.39</cell><cell>24.87</cell><cell>0.98</cell></row><row><cell>f6</cell><cell>0.07</cell><cell>0.09</cell><cell>0.09</cell><cell>0.12</cell><cell>0.30</cell></row><row><cell>f7</cell><cell>0.25</cell><cell>0.27</cell><cell>0.27</cell><cell>0.27</cell><cell>1.52</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 : Number of runs(out of 100) to optimality and corresponding mean number of function evaluations rounded to nearest integer</head><label>5</label><figDesc></figDesc><table><row><cell>Function</cell><cell>G-PSO</cell><cell cols="3">Basic-PSO HPSO-TVAC AShaker</cell><cell>DE</cell></row><row><cell>f1</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell></row><row><cell></cell><cell>(9322)</cell><cell>(138515)</cell><cell>(84262)</cell><cell>(2762)</cell><cell>(112602)</cell></row><row><cell>f2</cell><cell>100</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>89</cell></row><row><cell></cell><cell>(295539)</cell><cell></cell><cell></cell><cell></cell><cell>(462051)</cell></row><row><cell>f3</cell><cell>100</cell><cell>-</cell><cell>92</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>(177331)</cell><cell></cell><cell>(189747)</cell><cell></cell><cell></cell></row><row><cell>f4</cell><cell>12</cell><cell>34</cell><cell>45</cell><cell>100</cell><cell>68</cell></row><row><cell></cell><cell>(204027)</cell><cell>(144599)</cell><cell>(97071)</cell><cell cols="2">(12356) (80436)</cell></row><row><cell>f5</cell><cell>100</cell><cell>83</cell><cell>48</cell><cell>-</cell><cell>100</cell></row><row><cell></cell><cell>(139772)</cell><cell>(155829)</cell><cell>(285132)</cell><cell></cell><cell>216795</cell></row><row><cell>f6</cell><cell>100</cell><cell>100</cell><cell>36</cell><cell>100</cell><cell>18</cell></row><row><cell></cell><cell>(134330)</cell><cell>(48881)</cell><cell>(176996)</cell><cell>(200070)</cell><cell>(120)</cell></row><row><cell>f7</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>1</cell></row><row><cell></cell><cell>(2572)</cell><cell>(13881)</cell><cell>(26008)</cell><cell>(8667)</cell><cell>(440)</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">ACKNOWLEDGMENTS</head><p>This work is supported in part by the project CASCADAS (IST-027807) funded by the FET Program of the European Commission. The authors would like to thank the anonymous reviewers whose comments helped to increase the clarity of this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">reduce the emphasis on the &quot;cognitive&quot; aspects of PSO, and motivate a future more extended analysis. The ongoing work includes extensive comparison of G-PSO with different variants of Basic-PSO</title>
		<imprint/>
	</monogr>
	<note>1, 14, 22, 8] and evaluating the effectiveness of G-PSO on more benchmark functions [12, 23</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<ptr target="http://www.particleswarm.info/Programs.html.Online" />
		<title level="m">Particle swarm central</title>
		<imprint>
			<date type="published" when="2006-04-19">19-April-2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Evolutionary optimization versus particle swarm optimization: Philosophy and performance differences. Evolutionary Programming VII</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Angeline</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="601" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Using Selection to Improve Particle Swarm Optimization</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Angeline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Evolutionary Computation</title>
		<imprint>
			<date type="published" when="1998-05">May 1998</date>
			<biblScope unit="page" from="84" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Reactive search: Machine learning for memory-based heuristics</title>
		<author>
			<persName><forename type="first">R</forename><surname>Battiti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brunato</surname></persName>
		</author>
		<idno>DIT-05-058</idno>
	</analytic>
	<monogr>
		<title level="m">Approximation Algorithms and Metaheuristics</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Teofilo</surname></persName>
		</editor>
		<editor>
			<persName><surname>Gonzalez</surname></persName>
		</editor>
		<imprint>
			<publisher>Taylor &amp; Francis Books (CRC Press</publisher>
			<date type="published" when="2005">Sept. 2005. 2006</date>
		</imprint>
		<respStmt>
			<orgName>Università di Trento</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>To appear as a chapter in the book</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning with first, second and no derivatives: A case study in high energy physiscs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Battiti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tecchiolli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomp</title>
		<imprint>
			<biblScope unit="page" from="181" to="206" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An off-the-shelf pso</title>
		<author>
			<persName><forename type="first">A</forename><surname>Carlisle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dozier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Particle Swarm Optimization Workshop</title>
		<meeting>the Particle Swarm Optimization Workshop</meeting>
		<imprint>
			<date type="published" when="2001-04">April 2001</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Comparison between genetic algorithms and particle swarm optimization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Evolutionary Programming</title>
		<meeting>the 7th International Conference on Evolutionary Programming</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">1447</biblScope>
			<biblScope unit="page" from="611" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A hierarchical particle swarm optimizer and its adaptive variant</title>
		<author>
			<persName><forename type="first">S</forename><surname>Janson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Middendorf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Systems, Man, and Cybernetics-Part B: Cybernetics</title>
		<imprint>
			<date type="published" when="2005-12">December 2005</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1272" to="1282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The particle swarm: Social adaptation of knowledge</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Evolutionary Computation</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="303" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<title level="m">The behavior of particles. 7th Annual Conference on Evolutionary Programming</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="581" to="590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
		<title level="m">Particle Swarm Optimization. IEEE Int. Conf. Neural Networks</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Novel composition test functions for numerical global optimization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Swarm Intelligence Symposium</title>
		<imprint>
			<date type="published" when="2005-06">June 2005</date>
			<biblScope unit="page" from="68" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Hybrid particle swarm optimizer with breeding and subpopulation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lovbjerg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Krink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic And Evolutionary Computation Conference (GECCO&apos;01)</title>
		<imprint>
			<date type="published" when="2001-07">July 2001</date>
			<biblScope unit="page" from="469" to="476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The fully informed particle swarm: simpler, maybe better</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Neves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="204" to="210" />
			<date type="published" when="2004-06">June 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Enhancing differential evolution performance with local search for high dimensional function optimization</title>
		<author>
			<persName><forename type="first">N</forename><surname>Noman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Iba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic And Evolutionary Computation Conference (GECCO&apos;05)</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="967" to="974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Exploring extended particle swarms: a genetic programming approach</title>
		<author>
			<persName><forename type="first">R</forename><surname>Poli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Chio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Langdon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic And Evolutionary Computation Conference (GECCO&apos;05)</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="169" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Self-organizing hierarchical particle swarm optimizer with time-varying acceleration coefficients</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ratnaweera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Halgamuge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="240" to="255" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
		<title level="m">Parameter selection in particle swarm optimization. Annual Conference on Evolutionary Programming</title>
		<imprint>
			<date type="published" when="1998-03">March 1998</date>
			<biblScope unit="page" from="591" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Empirical study of particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE Int. Congr. Evolutionary Computation</title>
		<imprint>
			<biblScope unit="page" from="101" to="106" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Fuzzy adaptive particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE Int. Congr. Evolutionary Computation</title>
		<imprint>
			<biblScope unit="page" from="101" to="106" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Differential evolution -a simple and efficient heuristic for global optimization over continuous spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Global Optimization</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A cooperative approach to particle swarm optimization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Van Den Bergh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Engelbrecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="225" to="239" />
			<date type="published" when="2004-06">June 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Evolutionary programming made faster</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="82" to="102" />
			<date type="published" when="1999-07">July 1999</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
