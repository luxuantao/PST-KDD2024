<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Beyond Spectral Clustering -Tight Relaxations of Balanced Graph Cuts</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Matthias</forename><surname>Hein</surname></persName>
							<email>hein@cs.uni-saarland.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Saarland University</orgName>
								<address>
									<settlement>Saarbrücken</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Simon</forename><surname>Setzer</surname></persName>
							<email>setzer@mia.uni-saarland.de</email>
							<affiliation key="aff1">
								<orgName type="institution">Saarland University</orgName>
								<address>
									<settlement>Saarbrücken</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Beyond Spectral Clustering -Tight Relaxations of Balanced Graph Cuts</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6728C635E77D16157146EF5A6E594F89</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T10:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Spectral clustering is based on the spectral relaxation of the normalized/ratio graph cut criterion. While the spectral relaxation is known to be loose, it has been shown recently that a non-linear eigenproblem yields a tight relaxation of the Cheeger cut. In this paper, we extend this result considerably by providing a characterization of all balanced graph cuts which allow for a tight relaxation. Although the resulting optimization problems are non-convex and non-smooth, we provide an efficient first-order scheme which scales to large graphs. Moreover, our approach comes with the quality guarantee that given any partition as initialization the algorithm either outputs a better partition or it stops immediately.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The problem of finding the best balanced cut of a graph is an important problem in computer science <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b12">13]</ref>. It has been used for minimizing the communication cost in parallel computing, reordering of sparse matrices, image segmentation and clustering. In particular, in machine learning spectral clustering is one of the most popular graph-based clustering methods as it can be applied to any graph-based data or to data where similarity information is available so that one can build a neighborhood graph. Spectral clustering is originally based on a relaxation of the combinatorial normalized/ratio graph cut problem, see <ref type="bibr" target="#b27">[28]</ref>. The relaxation with the best known worst case approximation guarantee yields a semi-definite program, see <ref type="bibr" target="#b2">[3]</ref>. However, it is practically infeasible for graphs with more than 100 vertices due to the presence of O(n 3 ) constraints where n is the number of vertices in the graph. In contrast, the computation of eigenvectors of a sparse graph scales easily to large graphs. In a line of recent work <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b13">14]</ref> it has been shown that relaxation based on the nonlinear graph p-Laplacian lead to similar runtime performance while providing much better cuts. In particular, for p = 1 one obtains a tight relaxation of the Cheeger cut, see <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b13">14]</ref>.</p><p>In this work, we generalize this result considerably. Namely, we provide for almost any balanced graph cut problem a tight relaxation into a continuous problem. This allows flexible modeling of different graph cut criteria. The resulting non-convex, non-smooth continuous optimization problem can be efficiently solved by our new method for the minimization of ratios of differences of convex functions, called RatioDCA. Moreover, compared to <ref type="bibr" target="#b13">[14]</ref>, we also provide a more efficient way how to solve the resulting convex inner problems by transferring recent methods from total variation denoising, cf. <ref type="bibr" target="#b6">[7]</ref>, to the graph setting. In first experiments, we illustrate the effect of different balancing terms and show improved clustering results of USPS and MNIST compared to <ref type="bibr" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Set Functions, Submodularity, Convexity and the Lovasz Extension</head><p>In this section we gather some material from the literature on set functions, submodularity and the Lovasz extension, which we need in the next section. We refer the reader to <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b3">4]</ref> for a more detailed exposition. We work on weighted, undirected graphs G = (V, W ) with vertex set V and a symmetric, non-negative weight matrix W . We define n := |V | and denote by A = V \A the complement of A in V , set functions are denoted with a hat, Ŝ, whereas the corresponding Lovasz extension is simply S. The indicator vector of a set A is written as 1 A . In the following we always assume that for any considered set function Ŝ it holds Ŝ(∅) = 0. The Lovasz extension is a way to extend a set function from</p><formula xml:id="formula_0">2 V to R V . Definition 2.1 Let Ŝ : 2 V → R be a set function with Ŝ(∅) = 0. Let f ∈ R V be ordered in increasing order f 1 ≤ f 2 ≤ . . . ≤ f n and define C i = {j ∈ V | f j &gt; f i } where C 0 = V . Then S : R V → R given by S(f ) = n i=1 f i Ŝ(C i-1 ) -Ŝ(C i ) = n-1 i=1 Ŝ(C i )(f i+1 -f i ) + f 1 Ŝ(V ) is called the Lovasz extension of Ŝ. Note that S(1 A ) = Ŝ(A) for all A ⊂ V .</formula><p>Note that for symmetric set functions Ŝ, that is Ŝ(A) = Ŝ(A) for all A ⊂ V , the property Ŝ(∅) = 0 implies Ŝ(V ) = 0. A particular interesting class of set functions are the submodular set functions as their Lovasz extension is convex.</p><formula xml:id="formula_1">Definition 2.2 A set function, F : 2 V → R is submodular if for all A, B ⊂ V , F (A ∪ B) + F (A ∩ B) ≤ F (A) + F (B).</formula><p>F is called strictly submodular if the inequality is strict whenever A B or B A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Note that symmetric submodular set functions are always non-negative as for all</head><formula xml:id="formula_2">A ⊂ V , 2 F (A) = F (A) + F (A) ≥ F (A ∪ A) + F (A ∩ A) = F (V ) + F (∅) = 0.</formula><p>An important class of set functions for clustering are cardinality-based set functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 2.1 ([4]</head><p>) Let e ∈ R V + and g : R + → R is a concave function, then F : A → g(s(A)) is submodular. If F : A → g(s(A)) is submodular for all s ∈ R V + , then g is concave.</p><p>The following properties hold for the Lovasz extension.</p><p>Proposition 2.2 ( <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b3">4]</ref>) Let S : R V → R be the Lovasz extension of Ŝ : 2 V → R with Ŝ(∅) = 0.</p><p>• Ŝ is submodular if and only if S is convex,</p><p>• S is positively one-homogeneous,</p><formula xml:id="formula_3">• S(f ) ≥ 0, ∀ f ∈ R V and S(1) = 0 if and only if Ŝ(A) ≥ 0, ∀ A ⊂ V and Ŝ(V ) = 0. • S(f + α1) = S(f ) for all f ∈ R V , α ∈ R if and only if Ŝ(V ) = 0,</formula><p>• S is even, if Ŝ is symmetric.</p><p>One might wonder if the Lovasz extension of all submodular set functions generates the set of all positively one-homogeneous convex functions. This is not the case, as already Lovasz <ref type="bibr" target="#b18">[19]</ref> gave a counter-example. In the next section we will be interested in the class of positively onehomogeneous, even, convex functions S with S(f + α1) = S(f ) for all f ∈ R V . From the above proposition we deduce that these properties are fulfilled for the Lovasz extension of any symmetric, submodular set function. However, also for this special class there exists a counter-example. Take</p><formula xml:id="formula_4">S(f ) = f - 1 |V | f, 1 1 ∞ .</formula><p>It fulfills all the stated conditions but it induces the set function Ŝ(A) := S(1 A ) given as</p><formula xml:id="formula_5">Ŝ(A) = 1 |V | max{|A|, |V \A|}, 0 &lt; |A| &lt; |V | 0, else</formula><p>It is easy to check that this function is not submodular. Thus different convex one-homogeneous functions can induce the same set function via Ŝ(A) := S(1 A ).</p><p>It is known <ref type="bibr" target="#b14">[15]</ref> that a large class of functions e.g. every f ∈ C 2 (R n ) can be written as a difference of convex functions. As submodular functions correspond to convex functions in the sense of the Lovasz extension, one can ask if the same result holds for set functions: Is every set function a difference of submodular set functions ? The following result has been reported in <ref type="bibr" target="#b20">[21]</ref>. As some properties assumed in the proof in <ref type="bibr" target="#b20">[21]</ref> do not hold, we give an alternative constructive proof.</p><p>Proposition 2.3 Every set function Ŝ : 2 V → R can be written as the difference of two submodular functions. The corresponding Lovasz extension S : R V → R can be written as a difference of convex functions.</p><p>Note that the proof of Proposition 2.3 is constructive. Thus we can always find the decomposition of the set function into a difference of two submodular functions and thus also the decomposition of its Lovasz extension into a difference of convex functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Tight Relaxations of Balanced Graph Cuts</head><p>In graph-based clustering a popular criterion to partition the graph is to minimize the cut cut(A, A), defined as</p><formula xml:id="formula_6">cut(A, A) = i∈A,j∈A w ij ,</formula><p>where (w ij ) ∈ R |V |×|V | are the non-negative, symmetric weights of the undirected graph G = (V, W ) usually interpreted as similarities of vertices i and j. Direct minimization of the cut leads typically to very unbalanced partitions, where often just a single vertex is split off. Therefore one has to introduce a balancing term which biases the criterion towards balanced partitions. Two popular balanced graph cut criterion are the Cheeger cut RCC(A, A) and the ratio cut RCut(A, A)</p><formula xml:id="formula_7">RCC(A, A) = cut(A, A) min{|A|, |A|} , RCut(A, A) = |V | cut(A, A) |A||A| = cut(A, A) 1 |A| + 1 |A| .</formula><p>We consider later on also their normalized versions. Spectral clustering is derived as relaxation of the ratio cut criterion based on the second eigenvector of the graph Laplacian. While the second eigenvector can be efficiently computed, it is well-known that this relaxation is far from being tight. In particular there exist graphs where the spectral relaxation is as bad <ref type="bibr" target="#b11">[12]</ref> as the isoperimetric inequality suggests <ref type="bibr" target="#b0">[1]</ref>. In a recent line of work <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b13">14]</ref> it has been shown that a tight relaxation for the Cheeger cut can be achieved by moving from the linear eigenproblem to a nonlinear eigenproblem associated to the nonlinear graph 1-Laplacian <ref type="bibr" target="#b13">[14]</ref>.</p><p>In this work we generalize this result considerably by showing in Theorem 3.1 that a tight relaxation exists for every balanced graph cut measure which is of the form cut divided by balancing term. More precisely, let Ŝ : 2 V → R be a symmetric non-negative set function. Then a balanced graph cut criterion φ :</p><formula xml:id="formula_8">2 V → R + of a partition (A, A) has the form, φ(A) := cut(A, A) Ŝ(A) .<label>(1)</label></formula><p>As we consider undirected graphs, the cut is a symmetric set function and thus φ(A) = φ(A). In order to get a balanced graph cut, Ŝ is typically chosen as a function of |A| (or some other type of volume) which is monotonically increasing on [0, |V |/2]. The first part of the theorem showing the equivalence of combinatorial and continuous problem is motivated by a result derived by Rothaus in <ref type="bibr" target="#b24">[25]</ref> in the context of isoperimetric inequalities on Riemannian manifolds. It has been transferred to graphs by Tillich and independently by Houdre in <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b15">16]</ref>. We generalize their result further so that it now holds for all possible non-negative symmetric set functions. In order to establish the link to the result of Rothaus, we first state the following characterization Lemma 3.1 A function S : V → R is positively one-homogeneous, even, convex and S(f</p><formula xml:id="formula_9">+ α1) = S(f ) for all f ∈ R V , α ∈ R if and only if S(f ) = sup u∈U u, f</formula><p>where U ⊂ R n is a closed symmetric convex set and u, 1 = 0 for any u ∈ U .</p><p>Theorem 3.1 Let G = (V, E) be a finite, weighted undirected graph and S : R V → R and let</p><formula xml:id="formula_10">Ŝ : 2 V → R be symmetric with Ŝ(∅) = 0, then inf f ∈R V 1 2 n i,j=1 w ij |f i -f j | S(f ) = inf A⊂V cut(A, A) Ŝ(A) ,</formula><p>if either one of the following two conditions holds 1. S is positively one-homogeneous, even, convex and S(f</p><formula xml:id="formula_11">+ α1) = S(f ) for all f ∈ R V , α ∈ R and Ŝ is defined as Ŝ(A) := S(1 A ) for all A ⊂ V .</formula><p>2. S is the Lovasz extension of the non-negative, symmetric set function Ŝ with Ŝ(∅) = 0.</p><p>Let f ∈ R V and denote by C t := {i ∈ V | f i &gt; t}, then it holds under both conditions,</p><formula xml:id="formula_12">min t∈R cut(C t , C t ) Ŝ(C t ) ≤ 1 2 n i,j=1 w ij |f i -f j | S(f ) .</formula><p>Theorem 3.1 can be generalized by replacing the cut with an arbitrary other set function. However, the emphasis of this paper is to use the new degree of freedom for balanced graph clustering. The more general approach will be discussed elsewhere. Note that the first condition in Theorem 3.1 implies that Ŝ is symmetric as</p><formula xml:id="formula_13">Ŝ(A) = S(1 A ) = S(-1 A ) = S(1 -1 A ) = S(1 A ) = Ŝ(A).</formula><p>Moreover, Ŝ is non-negative with Ŝ(∅) = Ŝ(V ) = 0 as S is even, convex and positively onehomogeneous. For the second condition note that by Proposition 2.3 the Lovasz extension of any set function can be written as a difference of convex (d.c.) functions. As the total variation term in the enumerator is convex, we thus have to minimize a ratio of a convex and a d.c. function. The efficient minimization of such problems will be the topic of the next section.</p><p>We would like to point out a related line of work for the case where the balancing term Ŝ is submodular and the balanced graph cut measure is directly optimized using submodular minimization techniques. In <ref type="bibr" target="#b22">[23]</ref> this idea is proposed for the ratio cut and subsequently generalized <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b16">17]</ref> so that every submodular balancing function Ŝ can be used. While the general framework is appealing, it is unclear if the minimization can be done efficiently. Moreover, note that Theorem 3.1 goes well beyond the case where Ŝ is submodular.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Examples of Balancing Set Functions</head><p>Theorem 3.1 opens up new modeling possibilities for clustering based on balanced graph cuts. We discuss in the experiments differences and properties of the individual balancing terms. However, it is out of the scope of this paper to answer the question which balancing term is the "best". An answer to such a question is likely to be application-dependent. However, for a given random graph model it might be possible to suggest a suitable balancing term given one knows how cut and volume behave. A first step in this direction has been done in <ref type="bibr" target="#b19">[20]</ref> where the limit of cut and volume has been discussed for different neighborhood graph types.</p><p>In the following we assume that we work with graphs which have non-negative edge weights W = (w ij ) and non-negative vertex weights e : V → R + . The volume vol(A) of a set A ⊂ V is defined as vol(A) = i∈A e i . The volume reduces to the cardinality if e i = 1 for all i ∈ V (unnormalized case) or to the volume considered in the normalized cut, vol(A) = i∈A d i for e i = d i for all i ∈ V (normalized case), where d i is the degree of vertex i. We denote by E the diagonal matrix with E ii = e i , i = i, . . . , n. Using general vertex weights allows us to present the unnormalized and normalized case in a unified framework. Moreover, general vertex weights allow more modeling freedom e.g. one can give two different vertices very large vertex weights and so implicitly enforce that they will be in different partitions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Name</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S(f ) Ŝ(A)</head><p>Cheeger p-cut</p><formula xml:id="formula_14">n i=1 ei|fi -wmeanp(f )| p 1 p vol(A) vol(A) 1 p vol(A) 1 p-1 +vol(A) 1 p-1 1-1 p Normalized p-cut n i=1 ei|fi -e,f vol(V ) | p 1 p vol(A) vol(A) p +vol(A) p vol(A) 1 p vol(V ) Trunc. Cheeger cut gmax,α(f ) -gmin,α(f )    vol(A), if vol(A) ≤ α vol(V ), vol(A), if vol(A) ≤ α vol(V ), α vol(V ), else. Hard balanced cut g max, K |V | (f ) -g min, K |V | (f ) -g max, K-1 |V | (f ) -g min, K-1 |V | (f ) 1, if min{|A|, |A|} ≥ K 0, else. Hard Cheeger cut f -median(f )1 1 -g max, K-1 |V | (f ) -g min, K-1 |V | (f )      0, if min{|A|, |A|} &lt; K, min{|A|, |A|} -(K -1), else.</formula><p>Table <ref type="table">1</ref>: Examples of balancing set functions and their continuous counterpart. For the hard balanced and hard Cheeger cut we have unit vertex weights, that is e i ≡ 1.</p><p>We report here the Lovasz extension of two important set functions which will be needed in the sequel. For that we define the functions g max,α and g min,α as:</p><formula xml:id="formula_15">g max,α (f ) = max ρ, f 0 ≤ ρ i ≤ e i , ∀ i = 1, . . . , n, n i=1 ρ i = α vol(V ) , g min,α (f ) = min ρ, f 0 ≤ ρ i ≤ e i , ∀ i = 1, . . . , n, n i=1 ρ i = α vol(V )</formula><p>and the weighted p-mean wmean p (f ) is defined as wmean p (f ) = inf a∈R n i=1 e i |f i -a| p . Note that g max,α is convex, whereas g min,α is concave. Both functions can be easily evaluated by sorting the componentwise product e i f i . Proposition 3.1 Let Ŝ : 2 V → R, Ŝ(A) := min{vol(A), vol(A)}. Then the Lovasz extension S : V → R is given by S(f ) = E(f -wmean 1 (f )1) 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Let e</head><formula xml:id="formula_16">i = 1, ∀i ∈ V and Ŝ : 2 V → R, Ŝ(A) := min{|A|, |A|}, if min{|A|, |A|} ≤ K, K, else. . Then the Lovasz extension S : V → R is given as S(f ) = g max, K |V | (f ) -g min, K |V | (f ).</formula><p>In Table <ref type="table">1</ref> we collect a set of interesting set functions enforcing different levels of balancing. For the Cheeger and Normalized p-cut family and the truncated Cheeger cut the functions S are convex and not necessarily the Lovasz extension of the induced set functions Ŝ (first case in Theorem 3.1).</p><p>In the case of hard balanced and hard Cheeger cut the set function Ŝ is not submodular. However, in both cases we know an explicit decomposition of the set function Ŝ into a difference of submodular functions and thus their Lovasz extension S can be written as a difference of the convex functions. The derivations can be found in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Minimization of Ratios of Non-negative Differences of Convex Functions</head><p>In <ref type="bibr" target="#b13">[14]</ref>, the problem of computing the optimal Cheeger cut partition is formulated as a nonlinear eigenproblem. Hein and Bühler show that the second eigenvector of the nonlinear 1-graph Laplacian is equal to the indicator function of the optimal partition. In Theorem 3.1, we have generalized this relation considerably. In this section, we discuss the efficient computation of critical points of the continuous ratios of Theorem 3.1. We propose a general scheme called RatioDCA for minimizing ratios of non-negative differences of convex functions and thus generalizes Algorithm 1 of <ref type="bibr" target="#b13">[14]</ref> which could handle only ratios of convex functions. As the optimization problem is non-smooth and non-convex, only convergence to critical points can be guaranteed. However, we will show that for every balanced graph cut criterion our algorithm improves a given partition or it terminates directly. Note that such types of algorithms have been considered for specific graph cut criteria <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b1">2]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">General Scheme</head><p>The continuous optimization problem in Theorem 3.1 has the form</p><formula xml:id="formula_17">min f ∈R V 1 2 n i,j=1 w ij |f i -f j | S(f ) , (<label>2</label></formula><formula xml:id="formula_18">)</formula><p>where S is one-homogeneous and either convex or the Lovasz extension of a non-negative symmetric set function. By Proposition 2.3 the Lovasz extension of any set function can be written as a difference of one-homogeneous convex functions. Using the fourth property of Proposition 2.2 the Lovasz extension S is non-negative, that is S(f ) ≥ 0 for all f ∈ R V . With the algorithm RatioDCA below, we provide a general scheme for the minimization of a ratio F (f ) := R(f )/S(f ), where R and S are non-negative and one-homogeneous and each can be written as a difference of convex functions: R(f</p><formula xml:id="formula_19">) = R 1 (f )-R 2 (f ) and S(f ) = S 1 (f )-S 2 (f ) with R 1 , R 2 , S 1 , S 2 being convex. In</formula><p>Algorithm RatioDCA -Minimization of a non-negative of 1-homogeneous d.c. functions 1: Initialization:</p><formula xml:id="formula_20">f 0 = random with f 0 = 1, λ 0 = F (f 0 ) 2: repeat 3: s 1 (f k ) ∈ ∂S 1 (f k ), r 2 (f k ) ∈ ∂R 2 (f k ) 4: f k+1 = arg min u 2 ≤1 R 1 (u) -u, r 2 (f k ) + λ k S 2 (u) -u, s 1 (f k ) 5: λ k+1 = (R 1 (f k+1 ) -R 2 (f k+1 ))/(S 1 (f k+1 ) -S 2 (f k+1 )) 6: until |λ k+1 -λ k | λ k &lt; 7: Output: eigenvalue λ k+1 and eigenvector f k+1 . our setting R(f ) = R 1 (f ) = 1 2 n i,j=1 w i,j |f i -f j |.</formula><p>We refer to the convex optimization problem which has to be solved at each step in RatioDCA (line 4) as the inner problem. The sequence F (f k ) is not only monotonically decreasing but converges to a generalized nonlinear eigenvector as introduced in <ref type="bibr" target="#b13">[14]</ref>. </p><formula xml:id="formula_21">* = R(f * ) S(f * ) ∈ 0, F (f 0 ) in the sense that it fulfills 0 ∈ ∂R 1 (f * ) -∂R 2 (f * ) -λ * ∂S 1 (f * ) -∂S 2 (f * ) . If S 1 -S 2 is continuously differentiable at f * , then F has a critical point at f * .</formula><p>In the balanced graph cut problem (2) we minimize implicitly over non-constant functions. Thus it is important to guarantee that the RatioDCA for this particular problem always converges to a non-constant vector. Lemma 4.1 For every balanced graph cut problem, the RatioDCA converges to a non-constant f * given that the initial vector f 0 is non-constant. Now we are ready to state the following key property of our balanced graph clustering algorithm. Theorem 4.2 Let (A, A) be a given partition of V and let S : V → R + satisfy one of the conditions stated in Theorem 3.1. If one uses as initialization of RatioDCA, f 0 = 1 A , then either RatioDCA terminates after one step or it yields an f 1 which after optimal thresholding as in Theorem 3.1 gives a partition (B, B) which satisfies</p><formula xml:id="formula_22">cut(B, B) Ŝ(B) &lt; cut(A, A) Ŝ(A) .</formula><p>The above "improvement theorem" implies that we can use the result of any other graph partitioning method as initialization. In particular, we can always improve the result of spectral clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Solution of the Convex Inner Optimization Problems</head><p>The performance of RatioDCA depends heavily on how fast we can solve the corresponding inner problem. We propose to use a primal-dual algorithm for the inner problem and show experimentally that this approach yields faster convergence than the FISTA method of <ref type="bibr" target="#b4">[5]</ref> which was applied in <ref type="bibr" target="#b13">[14]</ref>. Let us restrict our attention to the case where R(f</p><formula xml:id="formula_23">) = R 1 (f ) = 1 2 n i,j=1 w ij |f i -f j | and S 2 = 0.</formula><p>In other words, we apply the RatioDCA algorithm to (2) with S = S 1 which is what we need, e.g., for the tight relaxations of the Cheeger cut, normalized cut and truncated Cheeger cut families. Hence, the inner problem of the RatioDCA algorithm (line 4) has the form</p><formula xml:id="formula_24">f k+1 = arg min u 2≤1 { 1 2 n i,j=1 w ij |f i -f j | -λ k u, s 1 (f k ) }.<label>(3)</label></formula><p>Recently, Arrow-Hurwicz-type primal-dual algorithms have become popular, e.g., in image processing, to solve problems whose objective function consists of the sum of convex terms, cf., e.g., <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b6">7]</ref>. We propose to use the following primal-dual algorithm of <ref type="bibr" target="#b6">[7]</ref> where it is referred to as Algorithm 2. We call this method a primal-dual hybrid gradient algorithm (PDHG) here since this term is used for similar algorithms in the literature. Note that the operator P • ∞ ≤1 in the first step is the componentwise projection onto the interval [-1, 1]. For the sake of readability, we define the linear operator B : R V → R E by Bu = (w ij (u i -u j )) n i,j=1 and its transpose is then</p><formula xml:id="formula_25">B T β = n j=1 w ij (β i,j -β j,i ) n i=1 .</formula><p>Algorithm PDHG -Solution of the inner problem of RatioDCA for (2) and S convex 1: Initialization: u 0 , ū0 , β 0 = 0, γ, σ 0 , τ 0 &gt; 0 with σ 0 τ 0 ≤ 1/ B 2 2 2: repeat 3:</p><formula xml:id="formula_26">β l+1 = P • ∞≤1 (β l + σ l B ūl ) 4: u l+1 = 1 1+τ l u l -τ l (B T β l+1 -2λ k s 1 (f k )) 5: θ l = 1/ √ 1 + 2γτ l , τ l+1 = θ l τ l , σ l+1 = σ l /θ l 6: ūl+1 = u l+1 + θ l (u l+1 -u l ) 7: until duality gap &lt; 8: Output: f k+1 ≈ u l+1 / u l+1<label>2</label></formula><p>Although PDHG and FISTA have the same guaranteed converges rates of O(1/l 2 ), our experiments show that for clustering applications, PDHG can outperform FISTA substantially. In Fig. <ref type="figure" target="#fig_0">1</ref>, we illustrate this difference on a toy problem. Note that a single step takes about the same computation time for both algorithms so that the number of iterations is a valid criterion for comparison. In the supplementary material, we also consider the inner problem of RatioDCA for the tight relaxation of the hard balanced cut. Although, in this case we have to deal with S 2 = 0 in the inner problem of RatioDCA, we can derive a similar PDHG method since the objective function is still the a sum of convex terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In a first experiment, we study the influence of the different balancing criteria on the obtained clustering. The data is a Gaussian mixture in R 20 where the projection onto the first two dimensions is shown in Figure <ref type="figure" target="#fig_4">2</ref>   all resulting partitions with respect to all balanced graph cut criteria, cut and the size of the largest component in the following table. The parameter for truncated, hard Cheeger cut and hard balanced cut is set to K = 200. One observes that the normalized 1-cut results in a less balanced partition but with a much smaller cut than the Cheeger 1-cut, which is itself less balanced than the hard Cheeger cut. The latter is fully balanced but has an even higher cut. The truncated Cheeger cut has a smaller cut than the hard balanced cut but its partition is not feasible. Note that the hard balanced cut is similar to the normalized 1-cut but achieves smaller cut at the prize of a larger maximal component. Thus, the example nicely shows how the different balance criterion influence the final partition. Next we perform unnormalized 1-spectral clustering on the full USPS, normal and extended 1 MNIST-datasets (resp. 9298, 70000 and 630000 points) in the same setting as in <ref type="bibr" target="#b13">[14]</ref> with no vertex weights, that is e i = 1, ∀i ∈ V . As clustering criterion for multi-partitioning we use the multicut version of the normalized 1-cut, given as RCut(C 1 , . . . , C M ) = M i=1 cut(Ci,Ci) |Ci|</p><p>. We successively subdivide clusters until the desired number of clusters (M = 10) is reached. This recursive partitioning scheme is used for all methods. In <ref type="bibr" target="#b13">[14]</ref> the Cheeger 1-cut has been used which is not compatible with the multi-cut criterion. We expect that using the normalized 1-cut for the bipartitioning steps we should get better results. The results of the other methods for USPS and MNIST (normal) are taken from <ref type="bibr" target="#b13">[14]</ref>. Each bipartitioning step is initialized randomly. Out of 100 obtained multi-partitionings we report the results of the best clustering with respect to the multi-cut criterion. The next table shows the obtained RCut and errors.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Left: Illustration of different balancing functions (rescaled so that they attain value |V |/2 at |V |/2). Right: Log-log plot of the duality gap of the inner problem vs. the number of iterations of PDHG (dashed) and FISTA (solid) in outer iterations 3 (black), 5 (blue) and 7 (red) of RatioDCA corresponding to increasing difficulty of the problem. PDHG significantly outperforms FISTA.</figDesc><graphic coords="6,126.56,81.86,178.19,101.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Proposition 4 . 1</head><label>41</label><figDesc>The sequence f k produced by RatioDCA satisfies F (f k ) &gt; F (f k+1 ) for all k ≥ 0 or the sequence terminates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Theorem 4 . 1</head><label>41</label><figDesc>Each cluster point f * of the sequence f k produced by the RatioDCA is a nonlinear eigenvector with eigenvalue λ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>}</head><label></label><figDesc>-the remaining 18 dimensions are just noise. The distribution of the 2000 points is [1200,600,200]. A symmetric k-NN-graph with k = 20 is built with Gaussian weights e where σ x,k is the k-NN distance of point x. For better interpretation, we report</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: From left to right: Cheeger 1-cut, Normalized 1-cut, truncated Cheeger cut (TCC), hard balanced cut (HBC), hard Cheeger cut (HCC). The criteria are the normalized ones, i.e., the vertex weights are e i = d i .</figDesc><graphic coords="8,112.92,178.88,75.24,56.33" type="bitmap" /></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Vertices/Edges</head><p>N. 1-cut Ch. We see for all datasets improvements in the obtained cut. Also a slight decrease in the obtained error can be observed. The improvements are not so drastic as the clustering is already very good. The problem is that for both datasets one digit is split (0) and two are merged (4 and 9) resulting in seemingly large errors. Similar results hold for the extended MNIST dataset. Note that the resulting error is comparable to recently reported results on semi-supervised learning <ref type="bibr" target="#b17">[18]</ref>. 1 The extended MNIST dataset is generated by translating each original input image of MNIST by one pixel (8 directions).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">λ1, isoperimetric inequalities for graphs, and superconcentrators</title>
		<author>
			<persName><forename type="first">N</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">D</forename><surname>Milman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Combin. Theory Ser. B</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="73" to="88" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An algorithm for improving graph partitions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 19th ACM-SIAM Symposium on Discrete Algorithms (SODA 2008)</title>
		<meeting>of the 19th ACM-SIAM Symposium on Discrete Algorithms (SODA 2008)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="651" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Expander flows, geometric embeddings and graph partitioning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Naor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 36th Annual ACM Symp. on Theory of Computing (STOC)</title>
		<meeting>36th Annual ACM Symp. on Theory of Computing (STOC)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="222" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1010.4207v2</idno>
		<title level="m">Convex analysis and optimization with submodular functions</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A fast iterative shrinkage-thresholding algorithm for linear inverse problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Teboulle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Imaging Sciences</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="183" to="202" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Spectral clustering based on the graph p-Laplacian</title>
		<author>
			<persName><forename type="first">T</forename><surname>Bühler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 26th Int. Conf. on Machine Learning (ICML)</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Littman</surname></persName>
		</editor>
		<meeting>of the 26th Int. Conf. on Machine Learning (ICML)</meeting>
		<imprint>
			<publisher>Omnipress</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A first-order primal-dual algorithm for convex problems with applications to imaging</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chambolle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Imaging and Vision</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="120" to="145" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Chung</surname></persName>
		</author>
		<title level="m">Spectral Graph Theory</title>
		<meeting><address><addrLine>Providence, RI</addrLine></address></meeting>
		<imprint>
			<publisher>AMS</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Lower bounds for the partitioning of graphs</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Donath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Hoffman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM J. Res. Develop</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="420" to="425" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A general framework for a class of first order primal-dual algorithms for convex optimization in imaging science</title>
		<author>
			<persName><forename type="first">E</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Imaging Sciences</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1015" to="1046" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Submodular functions and optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fujishige</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Discrete Mathematics</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<date type="published" when="2005">2005</date>
			<publisher>Elsevier B. V</publisher>
			<pubPlace>Amsterdam</pubPlace>
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On the quality of spectral separators</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Guattery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gary</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Matrix Analysis and Applications</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="701" to="719" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fast spectral methods for ratio cut partitioning and clustering</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Kahng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Intl. Conf. on Computer-Aided Design</title>
		<meeting>IEEE Intl. Conf. on Computer-Aided Design</meeting>
		<imprint>
			<date type="published" when="1991-11">November 1991</date>
			<biblScope unit="page" from="10" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An inverse power method for nonlinear eigenproblems with applications in 1-spectral clustering and sparse pca</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bühler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 23 (NIPS 2010)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="847" to="855" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Generalized differentiability, duality and optimization for problems dealing with differences of convex functions</title>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Hiriart-Urruty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Convexity and duality in optimization</title>
		<imprint>
			<date type="published" when="1985">1985</date>
			<biblScope unit="page" from="37" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mixed and Isoperimetric Estimates on the Log-Sobolev Constants of Graphs and Markov Chains</title>
		<author>
			<persName><forename type="first">C</forename><surname>Houdré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Combinatorica</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="489" to="513" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Submodular fractional programming for balanced clustering</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nagano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Okamoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="235" to="243" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Large graph construction for scalable semi-supervised learning</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 27th Int. Conf. on Machine Learning (ICML)</title>
		<meeting>of the 27th Int. Conf. on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Submodular functions and convexity</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lovász</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematical programming: the state of the art</title>
		<meeting><address><addrLine>Bonn; Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1982">1982. 1983</date>
			<biblScope unit="page" from="235" to="257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Influence of graph construction on graph-based clustering measures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 21 (NIPS)</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1025" to="1032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A submodular-supermodular procedure with applications to discriminative structure learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bilmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">21st Conference on Uncertainty in Artificial Intelligence (UAI)</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Local search for balanced submodular clusterings</title>
		<author>
			<persName><forename type="first">M</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bilmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">20th International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Improving graph partitions using submodular functions</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Patkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete Appl. Math</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="535" to="553" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Partitioning sparse matrices with eigenvectors of graphs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pothen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-P</forename><surname>Liou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Matrix Analysis and Applications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="430" to="452" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Analytic inequalities, Isoperimetric Inequalities and Logarithmic Sobolev Inequalities</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">S</forename><surname>Rothaus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Functional Analysis</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="296" to="313" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Total variation and Cheeger cuts</title>
		<author>
			<persName><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Machine Learning</title>
		<meeting>the 27th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>Omnipress</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1039" to="1046" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Edge isoperimetric inequalities for product graphs</title>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Tillich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete Mathematics</title>
		<imprint>
			<biblScope unit="volume">213</biblScope>
			<biblScope unit="page" from="291" to="320" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A tutorial on spectral clustering</title>
		<author>
			<persName><forename type="first">U</forename><surname>Luxburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and Computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="395" to="416" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
