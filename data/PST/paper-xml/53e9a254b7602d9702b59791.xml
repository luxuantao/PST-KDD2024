<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Profiler: Integrated Statistical Analysis and Visualization for Data Quality Assessment</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sean</forename><surname>Kandel</surname></persName>
							<email>skandel@cs.stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ravi</forename><surname>Parikh</surname></persName>
							<email>rparikh@cs.stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andreas</forename><surname>Paepcke</surname></persName>
							<email>paepcke@cs.stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joseph</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
							<email>hellerstein@cs.berkeley.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jeffrey</forename><surname>Heer</surname></persName>
							<email>jheer@cs.stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Profiler: Integrated Statistical Analysis and Visualization for Data Quality Assessment</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F1B388C1F40D16496D26D33FFA1BC89C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.5.2 [Information Interfaces and Presentation]: User Interfaces Data analysis</term>
					<term>visualization</term>
					<term>data quality</term>
					<term>anomaly detection</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Data quality issues such as missing, erroneous, extreme and duplicate values undermine analysis and are time-consuming to find and fix. Automated methods can help identify anomalies, but determining what constitutes an error is context-dependent and so requires human judgment. While visualization tools can facilitate this process, analysts must often manually construct the necessary views, requiring significant expertise. We present Profiler, a visual analysis tool for assessing quality issues in tabular data. Profiler applies data mining methods to automatically flag problematic data and suggests coordinated summary visualizations for assessing the data in context. The system contributes novel methods for integrated statistical and visual analysis, automatic view suggestion, and scalable visual summaries that support real-time interaction with millions of data points. We present Profiler's architecture -including modular components for custom data types, anomaly detection routines and summary visualizations -and describe its application to motion picture, natural disaster and water quality data sets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Data sets regularly contain missing, extreme, duplicate or erroneous values that can undermine the results of analysis. These anomalies come from various sources, including human data entry error, inconsistencies between integrated data sets, and sensor interference. Flawed analyses due to dirty data are estimated to cost billions of dollars each year <ref type="bibr" target="#b6">[6]</ref>. Discovering and correcting data quality issues can also be costly: some estimate cleaning dirty data to account for 80 percent of the cost of data warehousing projects <ref type="bibr" target="#b5">[5]</ref>.</p><p>The statistics and database communities have contributed a number of automated routines for detecting dirty data, such as finding outliers or duplicate records. While these techniques can reveal potential issues, human judgment is required to determine if the issues are in fact errors and how they should be treated. For example, outlier detection might flag a high temperature reading; an analyst then needs to assess if the reading is an exceptional event or an error.</p><p>Discovering a potential error is only the first step towards clean data. Before manipulating the data, an analyst may investigate why an anomaly has occurred to inform possible fixes. The analyst must place the anomaly in context by scrutinizing its relationship with other dimensions of the data. Appropriately-chosen visualizations can help reveal and contextualize these anomalies. Histograms and scatter plots, for instance, may reveal outlying values in a distribution. Analysts typically have to choose which views to construct: they must determine which subset of data columns and rows to visualize, how to transform the data, choose visual encodings, and specify other criteria such as sorting and grouping. Determining which visualizations to construct may require significant domain knowledge and expertise with a visualization tool.</p><p>In response we present Profiler, a visual analysis system to aid discovery and assessment of data anomalies. Profiler uses type inference and data mining routines to identify potential data quality issues in tabular data. Profiler then suggests coordinated, multiview visualizations to help an analyst assess anomalies and contextualize them within the larger data set.</p><p>Our first contribution is an extensible system architecture that enables integrated statistical and visual analysis for data quality assessment. This modular architecture supports plug-in APIs for data types, anomaly detection routines and summary visualizations. We populate this framework with commonly-needed data types and detection routines. We focus primarily on univariate anomalies due to their frequency, tractability, and relative ease of explanation. We demonstrate how coupling automated anomaly detection with linked summary visualizations allows an analyst to discover and triage potential causes and consequences of anomalous data.</p><p>Our architecture also introduces novel visual analysis components. We contribute a technique for automatic view suggestion based on mutual information. Profiler analyzes the mutual information between table columns and the output of anomaly detection to suggest sets of coordinated summary visualizations. Our model recommends both table columns and aggregation functions to produce visual summaries that aid assessment of anomalies in context.</p><p>We also contribute the design of scalable summary visualizations that support brushing and linking to assess detected anomalies. Through linked selections, analysts can project anomalies in one column onto other dimensions. Our aggregate-based summary views bin values to ensure that the number of visual marks depends on the number of groups, not the number of data records. We provide optimizations for query execution and rendering to enable real-time interaction with data sets in excess of a million rows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>Profiler draws on three areas of related work: anomaly detection, data cleaning tools, and visual analysis systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Classifying Data Anomalies</head><p>The database and statistics literature includes many taxonomies of anomalous data <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b7">7,</ref><ref type="bibr" target="#b10">10,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b33">33]</ref>. These taxonomies inform   a variety of algorithms for detecting outliers <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b10">10,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b33">33]</ref>, duplicate records <ref type="bibr" target="#b7">[7]</ref>, and key violations <ref type="bibr" target="#b13">[13]</ref>. While these routines flag potential issues, most types of error require some form of human intervention to assess and correct <ref type="bibr" target="#b19">[19]</ref>. Here, we focus on errors that arise within a single relational table. Guided by prior taxonomies, we identified five categories of anomalies to address in Profiler:</p><note type="other">Major Genre Distributor Release Location Error (</note><p>Missing data results from a number of sources, including incomplete collection or redaction due to privacy concerns. Missing data can take the form of missing records or missing attributes. These issues can lead to a loss of statistical power if too many cases are unobserved and can introduce bias into model estimates, especially when data is not missing at random <ref type="bibr" target="#b1">[1]</ref>.</p><p>Erroneous data can arise because of error during data entry, measurement, or distillation <ref type="bibr" target="#b10">[10]</ref>. Obviously, analysis of incorrect data can lead to incorrect conclusions.</p><p>Inconsistent data refers to variable encodings of the same value. Examples include variations in spelling or formatting, measurement units, or coding schemes (e.g., names vs. abbreviations).</p><p>Extreme values such as outliers can undermine robust analysis and may be erroneous. Extreme values may be standard univariate outliers, or may be type specific. For example, time-series outliers generally take two forms <ref type="bibr" target="#b33">[33]</ref>: an additive outlier is an unexpected, transient movement in a measured value over time, whereas an innovation outlier is an unexpected movement that persists over time.</p><p>Key violations refer to data that violate primary key constraints. For example, having two employees with the same social security number violates the assumption that SSN is a key.</p><p>Observed issues can fall into multiple categories: a numeric outlier may result from an accurate measurement of an extreme value, a data entry error, or from inconsistent units (feet vs. meters).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Data Cleaning Tools</head><p>Motivated by the issues above, database and HCI researchers have created interactive systems for data cleaning. Many of these interfaces focus on data integration <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b21">21,</ref><ref type="bibr" target="#b27">27,</ref><ref type="bibr" target="#b34">34]</ref> or entity resolution <ref type="bibr" target="#b17">[17]</ref>. Here we focus on data quality issues in a single table. Profiler does include detectors for duplicate values, but we do not attempt to address the general problem of entity resolution.</p><p>Other interfaces support mass reformatting of raw input data <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b16">16,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b29">29]</ref>. A common form of discrepancy detection is provided by data type definitions that specify constraints for legal values <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b29">29]</ref>. These systems are usually limited to finding formatting discrepancies for individual values. Profiler's data types are similar to domains in Potter's Wheel <ref type="bibr" target="#b25">[25]</ref> and Scaffidi et al.'s Topes <ref type="bibr" target="#b29">[29]</ref>. However, Profiler detects a broader range of discrepancies, including distribution-dependent outliers and duplicate values. Unlike these prior tools, Profiler also generates scalable interactive visual summaries to aid anomaly assessment.</p><p>Perhaps most comparable to Profiler is Google Refine <ref type="bibr" target="#b14">[14]</ref>, which supports both faceted browsing and text clustering to identify data quality issues. Refine users must manually specify which facets and clusters to create. In contrast, Profiler automatically suggests visualizations to aid discovery and assessment of discrepancies.</p><p>Profiler is integrated with the Wrangler <ref type="bibr" target="#b16">[16]</ref> data transformation tool. An analyst can transform raw data using Wrangler. Once the data is properly formatted as a relational table, Profiler can leverage type information to automate anomaly detection and visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Visual Analysis Systems</head><p>Visualization can support discovery of patterns in data, including anomalies <ref type="bibr" target="#b18">[18]</ref>. Aggregation, clustering and sorting have been used in various contexts to support scalable visualization for large data sets <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b20">20,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b35">35]</ref>. Through linked highlighting ("brushing &amp; linking"), coordinated multiple views enable assessment of relationships between data dimensions <ref type="bibr" target="#b22">[22,</ref><ref type="bibr" target="#b36">36]</ref>. Profiler's visualization layer extends this prior work with a set of type-specific aggregate visualizations that aid assessment of data quality issues.</p><p>Visual analytic tools such as Tableau <ref type="bibr" target="#b31">[31]</ref>, GGobi <ref type="bibr" target="#b32">[32]</ref>, and Improvise <ref type="bibr" target="#b36">[36]</ref> enable analysts to construct multi-dimensional views of data. However, these tools generally require users to choose which variables to visualize. As the number of data subsets explodes combinatorially, analysts must often rely on significant domain expertise to identify variables that may contain or help explain anomalies. To facilitate the view selection process, Profiler automatically suggests both data subsets and appropriate summary visualizations based on identified anomalies and inferred data types. While other tools support general exploratory analysis, Profiler provides guided analytics to enable rapid quality assessment.</p><p>Others have explored interfaces for guiding analysis and suggesting appropriate views. Social Action <ref type="bibr" target="#b23">[23]</ref> uses a wizard-like interface to guide users through social network analysis. Seo and Shneiderman's rank-by-feature framework <ref type="bibr" target="#b30">[30]</ref> sorts histograms and scatterplots of numeric data according to user-selected criteria. Others have used dimensionality reduction, clustering and sorting to aid visualization of multidimensional data <ref type="bibr">[8,</ref><ref type="bibr" target="#b11">11,</ref><ref type="bibr" target="#b37">37]</ref>. In Profiler, we use anomaly detection followed by mutual information analysis to suggest a set of coordinated summary views for assessing data quality issues. Our suggestion engine automates the choice of data columns, aggregation functions and visual encodings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">USAGE SCENARIO</head><p>Before describing Profiler's architecture, we begin with a representative usage scenario. Consider an example task, using movie data compiled from IMDB, Rotten Tomatoes and The Numbers. This data set contains 16 columns and over 3,000 movies. The data includes metadata such as the title, primary production location, director, MPAA rating, and release date; financial information such as DVD sales and worldwide gross; and IMDB ratings.</p><p>An analyst is interested in which factors affect a movie's eventual revenue. She first loads the data into Profiler to assess overall data quality. The interface shows a schema browser, anomaly browser, formula editor and an empty canvas (Figure <ref type="figure" target="#fig_1">1</ref>). The schema browser shows the column names in the data set; the analyst could doubleclick column names or drag them into the canvas to visualize the corresponding column. Instead, she examines the anomaly browser.</p><p>The anomaly browser displays potential quality issues, grouped by issue type and sorted by severity. For each issue, Profiler lists the columns containing the issue and the name of the detection routine that flagged the anomaly. Curious why so many values are missing, the analyst adds related visualizations by selecting the 'Anomaly' option in the related views menu -this operation requests views that might explain the observed anomaly. She then selects the grey bar in the MPAA Rating chart to see how missing values project across other columns (Figure <ref type="figure" target="#fig_1">1</ref>). She finds that missing ratings correlate with early release dates. While this is interesting, she determines that the missing values don't have a strong relationship with any financial figures. This result holds for other columns with missing data.</p><p>The analyst next decides to look at extreme values in financial figures and clicks Worldwide Gross in the 'Extreme' anomaly list.  A histogram reveals a small number of high grossing movies. To generate explanatory visualizations, the analyst selects 'Data Values' from the related views menu -this operation requests views that might help explain the total distribution of Worldwide Gross, not just flagged anomalies. She mouses over the bars at the high end of the Worldwide Gross histogram and sees that these values correlate with high values in other financial figures, such as U.S. Gross (Figure <ref type="figure">2</ref>). She notices that Action and Adventure movies account for a disproportionate number of highly grossing movies. The time-series view reveals that these films spike during the summer and holiday seasons. The view groups release dates by month rather than year, as binning by month produces a stronger relationship with Worldwide Gross. The analyst is now confident that the outliers represent exceptional performance, not errors in the data.</p><p>The analyst decides to explore the seemingly strong relationship between Worldwide Gross and U.S. Gross. The analyst first selects 'None' in the related views menu to de-clutter the canvas. She drags U.S. Gross from the schema viewer onto the histogram displaying Worldwide Gross to create a binned scatterplot. The data appear to be log-normally distributed so she uses the chart menu to set log scales for the axes. She notes outlying cells containing very low U.S Gross values compared to Worldwide Gross. She adds a map visualization by dragging Release Location to the canvas and confirms that most of these movies were released outside the U.S (Figure <ref type="figure">3</ref>). The analyst decides to filter these data points from the data set so she chooses a filter transform from the transformation menu. The formula editor shows a predicate based on the current selection criteria and the analyst hits return to filter the points.</p><p>The analyst notices that the Release Location map contains a red bar indicating erroneous country values. She decides to toggle the map visualization to a bar chart to inspect the erroneous values. She clicks the small arrow at the top-right of the chart to open the chart menu and changes the visualization type. She filters the bar chart to only show erroneous values and sees a few 'None' and 'West Germany' values. To fix these errors, the analyst selects a replace transform in the formula editor menu and then specifies parameters; e.g., replace(Release Location, 'West Germany', 'Germany').</p><p>Next, the analyst inspects the 'Inconsistency' list in the anomaly browser. The analyst clicks on Title in order to spot potential duplicate records. Profiler responds by showing a grouped bar chart with movie titles clustered by textual similarity (Figure <ref type="figure" target="#fig_4">4</ref>). Unsurprisingly, the analyst sees that movies and their sequels are clustered together. There also appear to be potential remakes of classic films. The analyst worries that there might also be misspellings of some films, but does not want to verify all the clusters by hand. The analyst reasons that true duplicates are likely to have the same Release Date and so decides to condition the text clustering anomaly detector on Release Date. The analyst clicks 'Levenshtein' next to Title in the anomaly browser. A menu appears which includes selection widgets for conditioning anomaly detection on another column. After rerunning the detector, there are significantly fewer anomalies to check. The analyst is satisfied that there are no duplicate entries and continues with her analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">SYSTEM ARCHITECTURE</head><p>Underlying the Profiler application is an extensible architecture that combines statistical algorithms and coordinated visualizations. The system is implemented in JavaScript, and is intended to run inside browsers with optimized JavaScript execution engines. The architecture consists of five major components.</p><p>First, Profiler represents data tables using a memory-resident column-oriented relational database. The database supports standard SQL-style queries for filtering, aggregation, and generating derived columns. Unlike standard SQL databases, Profiler uses a relaxed type system: values can deviate from their column's defined type. Profiler flags these values as inconsistent; they appear in red within a chart's quality summary bar. The same database system also powers the Wrangler <ref type="bibr" target="#b16">[16]</ref> data transformation tool. Profiler has access to the Wrangler data transformation language and extends it with additional transforms, including more advanced aggregation operations such as binning numeric data to compute histograms and mathematical operations for deriving new columns.</p><p>The rest of the Profiler architecture consists of four modular components (Figure <ref type="figure" target="#fig_6">5</ref>). The Type Registry contains data type definitions and a type inference engine. Profiler uses types to choose appropriate anomaly detection routines and visualizations. The Detector performs anomaly detection by combining type-aware fea-   ture extractors and a set of data mining routines. Using detected anomalies and the mutual information between columns, the Recommender suggests visualizations to help an analyst assess potential issues. The View Manager presents linked summary visualizations; it generates type-specific visualizations and executes coordinated queries across views to support brushing and linking. We now describe each of these components in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Type Registry</head><p>The Type Registry consists of a set of type definitions and routines for type inference. Each column in a data table is assigned a type, whether automatically via inference or manually by the user.</p><p>At minimum, a Profiler type is defined by a binary verification function: given an input value, the function returns true if the value is a member of the type and false otherwise. Verification functions include regular expression matches, set membership (e.g., dictionary lookup of country names) and range constraints (e.g., pH between 0-14). Profiler associates a type with an entire column, but not all values in the column necessarily satisfy the type definition.</p><p>Profiler includes built-in support for primitive types -boolean, string, and numeric (int, double) -and higher-order types such as dates and geographic entities; e.g., state/country names, FIPS codes, zip codes. Profiler's detector and view manager components require that all columns be assigned to a data type. The type system is extensible: as new types are defined, anomaly detection and visualization methods can be specified in terms of pre-existing types or new components (e.g., a novel type-specific visualization) that plug-in to the Profiler architecture.</p><p>A type definition may also include a set of type transforms and group-by functions. A type transform is a function that maps between types (e.g., zip code to lat-lon coordinate). These functions form a graph of possible type conversions, some of which may be lossy. User-defined types can include type transforms to built-in types to leverage Profiler's existing infrastructure. Group-by functions determine how values can be grouped to drive scalable visualizations. For instance, numeric types can be binned at uniform intervals to form histograms, while dates may be aggregated into meaningful units such as days, weeks, months or years.</p><p>Type inference methods automatically assign a type to each column in a data table based on the Minimum Description Length principle (MDL) <ref type="bibr" target="#b26">[26]</ref>. MDL selects the type that minimizes the number of bits needed to encode the values in a column. MDL has been used effectively in prior data cleaning systems, such as Potter's Wheel <ref type="bibr" target="#b25">[25]</ref>. We use the same MDL formulation in Profiler.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Detector</head><p>Profiler's Detector applies a collection of type-specific data mining routines to identify anomalies in data.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">The Detection Pipeline</head><p>The Detector determines which anomaly detection routines to apply, runs them, and produces output for visualization. This process has two phases: feature generation and anomaly detection.</p><p>During feature generation, the Detector derives features of the input columns to use as input to anomaly detection routines. Features are extracted using unary transformations called generators. For example, a generator might compute the lengths of string values; an anomaly detector might then compute z-scores to flag abnormally long strings. The Detector maintains a list of appropriate generators (including the identity function) for each type in the Type Registry. Given an input table, the Detector applies generators to each input column according to its type signature. The result is a set of feature columns that serve as input to anomaly detectors.</p><p>Detection routines then analyze the feature columns. Detection routines accept columns as input and output two columns: a class column and a certainty column. The class column contains integers; 0 indicates that no anomaly was found in that row. Non-zero values indicate the presence of an anomaly and distinct integers indicate distinct classes of anomaly. For example, the z-score routine outputs a class column where each value is either 0 (within 2 standard deviations from the mean), -1 (&lt; 2 stdev), or 1 (&gt; 2 stdev). The certainty column represents the strength of the routine's prediction. For z-scores, these values indicate the distance from the mean.</p><p>The Detector organizes detection routines by the data types they can process. After feature generation, the system visits each column in the data table (including derived columns) and runs all routines with a compatible type. For instance, the z-score routine is applied to all numeric columns. The standardized output of class and certainty columns is then handled in a general fashion by the downstream Recommender and View Manager components.</p><p>The Detector's output appears in the anomaly browser. This browser lists any result of a detection routine that contains at least one anomalous value (i.e., a non-zero value in the class column), grouped by the type of detection routine and sorted by decreasing anomaly count. The browser displays the columns containing the anomaly and which routines detected the anomaly. When a user clicks an item, relevant views appear in the canvas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Detection Routines</head><p>Profiler incorporates a variety of detection routines to flag data anomalies (Figure <ref type="figure" target="#fig_7">6</ref>), and can easily be extended with new rou-tines. The following list focuses on the most common needs and demonstrates the diversity of routines that the system supports.</p><p>Missing value detection identifies cells that do not contain data. Type verification functions identify values inconsistent with a given column type (Sec. 4.1). Verification can flag incorrect use of physical types (e.g., strings vs. integers) or constraint violations.</p><p>Clustering is used to detect a variety of errors relative to a chosen distance metric. Euclidean distance is useful for detecting numeric outliers and inconsistent measurement units. Character-based (Levenshtein distance), token-based (Atomic Strings), and phoneticbased (soundex) distances are useful for detecting inconsistencies in text such as misspellings, different term orderings, and phonetically similar words <ref type="bibr" target="#b7">[7]</ref>. We use nearest neighbor agglomerative hierarchical clustering with each distance metric.</p><p>Univariate outlier detection routines identify extreme and possibly incorrect values for numeric and time-based data. We apply both z-scores and Hampel X84 -a routine based on median absolute deviation -to detect univariate quantitative outliers <ref type="bibr" target="#b10">[10]</ref>.</p><p>Frequency outlier detection identifies values that appear in a set more or less often then expected. Frequency outliers are commonly used to detect primary key violations. Profiler uses the unique value ratio to detect primary keys <ref type="bibr" target="#b10">[10]</ref>. We use numerical outlier routines on aggregated counts to detect other types of anomalies, such as gaps in ranges which may indicate missing observations.</p><p>Profiler supports two methods of multivariate outlier detection. First, detection routines can accept multiple columns as input. For example, Mahalanobis distance can be used to detect multivariate numeric outliers <ref type="bibr" target="#b10">[10]</ref>. Second, conditioning is a general method for converting any routine into a multivariate routine. Conditioning applies an existing routine to subsets of data, grouped by one or more variables (e.g., categorical or binned quantitative values). For instance, conditioning the z-score routine on genre calculates the scores for values within each genre separately. To support conditioning, Profiler uses a partitioner that applies any transformation to data subsets formed by applying specified group-by functions.</p><p>The space of possible routines is combinatorially large and the results of these routines can be difficult to interpret. As a result, Profiler does not automatically run multivariate outlier detection routines by default. Users can initiate multivariate outlier detection by adding conditioning columns to existing univariate detectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">View Recommendation</head><p>For a given anomaly, the Recommender automatically populates the View Manager (discussed next) with relevant visual summaries. Generating summary views requires recommending a view specification -a set of columns to visualize and type-appropriate groupby functions for aggregation. A view specification can also include anomaly class and certainty columns to parameterize a view. The recommender always specifies a primary view that visualizes the column(s) that contain the anomaly. The recommender also determines a set of related views using a model based on mutual information. The Recommender supports two types of related views. Anomaly-oriented views show columns that predict the presence of anomalies. Value-oriented views show columns that best explain the overall distribution of values in the primary column(s). Users select which type of view to show with the related view menu.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Mutual Information</head><p>The mutual information of two variables quantifies how much knowing the value of one variable reduces the uncertainty in predicting a second variable. It is equivalent to the reduction in entropy attained by knowing a second variable. Mutual information is nonnegative and has a minimum of 0 when variables are independent.</p><p>To compare mutual information across pairs of variables, we define a distance metric D that is 0 for completely dependent variables and increases as the mutual information between variables decreases. For variables X and Y with mutual information I(X,Y ) and entropies H(X) and H(Y ), we define D as:</p><formula xml:id="formula_0">D(X, Y ) = 1 - I(X,Y ) max(H(X), H(Y ))<label>(1)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Recommendation</head><p>We use the metric D to recommend both the primary view and related views. A view specification determines how data is aggregated for a visual summary by assigning each row of input a group id (e.g., a bin in a histogram or binned scatterplot). In this way, we can derive a column of group ids from a view specification. We define ViewToColumn as a function that converts a view specification into a column of group ids. For a set of columns C, we use V S C to refer to the set of all possible view specifications containing one column from C and a type-appropriate group-by function.</p><p>The primary view always displays the set of columns that contain the anomaly. Our goal is to produce a summary view with bins that minimize the overlap of anomalies and non-anomalies so that analysts can better discriminate them. Recall that the class column output by the Detector indicates the presence of anomalies. We enumerate pairs of {column, group-by f unctions} and select the pair that best predicts the class column. More formally, if A is the set of columns containing the anomaly, we recommend the view specification vs ∈ V S A that minimizes the quantity D(ViewToColumn(vs), class). This primary view specification (denoted pvs) is assigned the class and certainty columns as parameters.</p><p>To suggest anomaly-oriented views, we find other columns that best predict the class column. We consider the set of all columns R that exclude the columns in C. We then choose view specifications from V S R that predict the class column. We sort specifications vs ∈ V S R by increasing values of D(ViewToColumn(vs), class). The Recommender populates the View Manager with the corresponding visual summaries in sort order until the canvas is full, discarding summaries that contain columns already visualized.</p><p>We use a similar process to recommend value-oriented views. Value-oriented views show visualizations related to the entire distribution of values in the primary view, not just anomalies. Instead of predicting the class column, we predict the group ids generated by the primary view specification. We sort specifications vs ∈ V S R by D(ViewToColumn(vs), ViewToColumn(pvs)). Because V S R only contains view specifications with one column, only univariate summaries are suggested. Our approach extends to multiple columns if we augment R to include larger subsets of columns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">View Manager</head><p>The View Manager converts view specifications into a set of linked visual summaries. The View Manager creates type-specific views to reveal patterns such as gaps, clusters and outliers. A query engine for filtering and aggregating data supports rapid brushing and linking across summaries, allowing an analyst to determine how subsets of data project across other dimensions. In addition to automatic view recommendation, analysts can manually construct views through drag-and-drop and menu-based interactions. Profiler visualizations are implemented in SVG using the D3 library <ref type="bibr" target="#b2">[2]</ref>. We now detail the design of the View Manager, including optimizations for rendering and query performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Summary Visualizations</head><p>Visualizing "raw" data is increasingly difficult with even moderately sized data -even a few hundred data points may make a scatter plot difficult to read due to overplotting. Profiler's summary visualizations use aggregation to scale to a large number of records <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b14">14,</ref><ref type="bibr" target="#b20">20,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b35">35]</ref>: the number of marks in each view depends primarily on the number of bins, not the number of records.</p><p>To compute aggregates, each view requires a group-by function that specifies a binning strategy. For automatically generated views, bins are determined by the Recommender. When a user manually selects columns to visualize, Profiler chooses a group-by function based on the range of data values. Users can also select group-by functions or type transformations through a view's context menu.</p><p>Histograms (numeric data), area charts (temporal data), choropleth maps (geographic data) and binned scatter plots (2D numeric or temporal data) visualize counts of values within binned ranges. Though Carr <ref type="bibr" target="#b3">[3]</ref> recommends hexagonal binning of scatter plots for improved density estimation, we currently use rectangular binning to enable better query and rendering performance.</p><p>Profiler uses bar charts to visualize the frequencies of distinct nominal values. Sorting the bars by frequency helps analysts assess the distribution of values within a set. Grouped bar charts display the frequencies of clustered values (e.g., clusters of possible duplicate values). For columns with high cardinality, it is not feasible to show all the bars at once. In response, Profiler also visualizes the distribution in the chart's scroll bar. We perform windowed aggregation over contiguous bars to form summary counts; the window size is adjusted as needed to match the available pixel resolution.</p><p>Data quality bars summarize column values as valid, type errors, or missing. Profiler annotates each visualization with one or more quality bars to indicate missing or non-conforming data. Quality bars also act as input regions for brushing and linking.</p><p>Higher-dimensional views are depicted using small multiples. Any Profiler visualization can be used in a trellis plot, with subplots showing data subdivided by one or more conditioning variables. Finally, Profiler's table display presents the raw data. Analysts can filter table rows by brushing summary visualizations.</p><p>Profiler visualizations also incorporate design considerations for varying levels of scale. Naïve scaling of bar heights and color ramps can result in low-frequency bins that are essentially invisible due to minuscule bars or near-white colors. This is unacceptable, as outliers often reside in low-frequency bins. We induce a perceptual discontinuity in these scales so that low-frequency bins remain identifiable: we give small bars a minimum height and make colors for any non-zero values suitably distinguishable from the background (Figure <ref type="figure" target="#fig_8">7</ref>). In addition, different tasks may require visualizing data at different levels of detail. Profiler time-series charts support binning by a variety of time spans (day, month, year, etc). Maps include panning and zooming controls. Each view can be parameterized using the class and certainty columns generated by an anomaly detector. The bar chart and small multiples views enable sorting by class and certainty. By default we sort in descending order to reveal anomalies with higher certainty; e.g., a grouped bar chart will sort clusters of similar words by the certainty that the cluster contains misspelled items, with groupings determined by the class column.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Scalable Linked Highlighting</head><p>When a user selects a range of values (e.g., by mouse hover), Profiler highlights the projection of that data across all views. To do so, Profiler first filters the backing data table to include only the selected range. For each view Profiler then computes an aggregate query to determine the count of selected items in each bin. These data points are visualized as orange highlights overlaid over the original view (see Figure <ref type="figure" target="#fig_1">1</ref>). Linked selection extends to all visualizations, including quality bars, scrollbars, and table views.</p><p>To support scalable, real-time interaction we addressed two performance challenges: query execution and rendering. To reduce the query load we first simplify the data. Multiple records in the input data often map to the same bin. In response we pre-aggregate the data, grouping by the bins for all visualized attributes. With a suitable number of bins per dimension (typically 10-30) this step can reduce the number of records by one to two orders of magnitude.</p><p>To further reduce query time, we encode non-numeric types as zero-based integers. Integer codes speed element comparisons and simplify the calculation of dimensional indices during aggregation. The original values are encoded in sort order and stored in a lookup table for reference. To facilitate optimization by the browser's justin-time compiler, the inner loop of the query executor avoids function calls. We also cache query results to eliminate redundant computation. For example, in a scatter plot matrix (SPLOM) crossdiagonal plots visualize the same data, only transposed.</p><p>Rendering bottlenecks also limit performance. Even with aggregated views, the number of marks on-screen can grow large: a 4 × 4 SPLOM containing plots with 50 × 50 bins requires rendering up to 40,000 marks. To speed rendering we minimize modifications to the Document Object Model (DOM) in each interactive update. To avoid churn, we introduce all SVG DOM elements (including highlights) upon initialization. Each update then toggles a minimal set of visibility and style properties. We also try to take advantage of optimized rendering pathways, for example by using squares instead of hexagons in binned scatter plots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3">Performance Benchmarks</head><p>We benchmarked query and render times during interactive brushing and linking. For our test data, we sample from random distributions for up to five columns. Three of the columns are in-dependently normally distributed. The others are linearly or loglinearly dependent with the first column. We visualize the data as a SPLOM with univariate histograms along the diagonal. We then programmatically brush the bins in each univariate histogram. This approach provides a conservative estimate of performance, as brushing scatter plot bins results in smaller selections and hence faster processing. We varied the number of visualized columns <ref type="bibr" target="#b3">(3,</ref><ref type="bibr" target="#b4">4,</ref><ref type="bibr" target="#b5">5)</ref>, bin count <ref type="bibr" target="#b10">(10,</ref><ref type="bibr" target="#b20">20,</ref><ref type="bibr" target="#b30">30)</ref>, and data set size (10K, 100K, 1M rows). For each condition, we averaged the query and render times across 5 runs. The benchmarks were performed in Google Chrome v.16.0.912.75 on a quad-core 2.66 GHz MacPro (OS X 10.6.8) with per-core 256K L2 caches, a shared 8MB L3 cache and 8GB RAM.</p><p>Our results demonstrate interactive rates with million-element data sets (Figure <ref type="figure" target="#fig_9">8</ref>). We see that the number of columns and number of bins have a greater impact on performance than the number of data points. We also performed an analysis of variance (ANOVA) to assess the contribution of each factor to the average response time. We found significant effects for SPLOM dimension (F 2,20 = 21.4, p &lt; 0.0001) and bin count (F 2,20 = 14.8, p = 0.0001). However, we failed to find a significant effect of data set size (F 2,20 = 1.2, p = 0.3114), lending credence to our claim of scalability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">INITIAL USAGE</head><p>We have conducted informal evaluations of Profiler on a variety of data sets -including water quality data, a disasters database, obesity data, a world wide quality-of-life index, and public government data. We now describe two concrete examples of how Profiler has enabled rapid assessment of these data sets.</p><p>The disasters database contains 11 columns, including the type, location, and consequences (cost, number affected) of the disaster. Profiler identified 13 data quality issues. These include 2 columns containing duplicates due to inconsistent capitalization, 6 columns with missing values, and 3 columns with extreme values. For example, Profiler detected disasters with extremely high monetary cost. The recommended views include the Type column. Upon selecting large values in the Cost histogram, it became evident that the vast majority of these outliers were floods, storms or droughts. By selecting these values in the Type bar chart, we confirmed that these disaster types typically lead to higher cost. For columns with missing values, Profiler primarily recommends columns with cooccurrences of missing values. For instance, rows missing values in a Killed column also tend to have missing values in the Cost, Sub Type, and Affected columns. Because of this, the recommended views for each of these anomalies were very similar. Assessing data quality in this data set took just a few minutes.</p><p>We also tested Profiler on World Water Monitoring Day data. Each year, thousands of people collect water quality data using test kits; they manually record the name and location of the body of water as well as measurements such as Turbidity and pH. The data contains 34 columns. Profiler identifies 23 columns with missing data, 2 with erroneous values, 5 containing outliers and 5 containing duplicates. For instance, the Air Temperature column contains extremely low temperatures. Profiler recommends a world map and a visualization of the date of collection, revealing that the extreme lows were collected in Russia during winter. The data set also contains many duplicates. Data collectors often refer to the same city by slightly different names, resulting in hundreds of potential duplicates. After inspecting a few duplicate sets, we conditioned text clustering on the State column to simplify the clustered bar charts significantly. However, Profiler also flagged possible duplicates in the State column itself, prompting us to resolve duplicates there first. Profiler also flagged the Site Country name for containing erroneous country names; a recommended bar chart shows that peo-ple enter extra specifics, such as "Congo, Republic of (Brazaaville)." We then corrected these values to enable proper aggregation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSION</head><p>In this paper we presented Profiler, an extensible system for data quality assessment. Our system architecture can support a flexible set of data types, anomaly detection routines and summary visualizations. Our view recommendation model facilitates assessment of data mining routines by suggesting relevant visual data summaries according to the mutual information between data columns and detected anomalies. We demonstrated how the appropriate selection of linked summary views aids evaluation of potential anomalies and their causes. We also discussed optimizations for scaling query and rendering performance to provide interactive response times for million element data sets within modern web browsers. By integrating statistical and visual analysis, we have found that Profiler can reduce the time spent diagnosing data quality issues, allowing domain experts to discover issues and spend more time performing meaningful analysis.</p><p>In future work, we plan to evaluate Profiler through both controlled studies and public deployments on the web. We intend to develop a tool for end users to define custom types (c.f., <ref type="bibr" target="#b29">[29]</ref>) and to incorporate detectors and visualizations for additional data types such as free-form text. Our query engine is currently limited to data that fits within a browser's memory limit. Future work might examine hybrid approaches that combine server-side aggregation with client-side interactive querying. Our model for view recommendation currently uses pairwise mutual information, which is insensitive to redundant dependencies between data. Other methods, such as structure learning of Bayesian networks, might account for conditional dependencies between sets of columns to side-step redundancy and further improve view ranking.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The Profiler User Interface. The UI contains (clockwise from top-left): (a) schema browser, (b) formula editor, (c) canvas of linked summary visualizations, and (d) anomaly browser. Profiler generates a set of linked views for each identified anomaly. Here, we investigate possible causes of missing MPAA movie ratings. The grey bar above the MPAA rating chart indicates missing values; we select it to highlight matching records. The Release Date chart shows that missing ratings correlate with earlier release dates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>The analyst clicks the MPAA Rating label in the missing values group. In response, Profiler displays the MPAA Rating data as a categorical bar chart showing the counts for each rating type. The chart title includes a data summary bar: green bars indicate parsed values, red bars indicate type verification errors, and grey bars indicate missing values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: Automatically generated views to help assess Worldwide Gross. Worldwide Gross correlates with high US Gross and Production Budgets. High gross also coincides with Action &amp; Adventure movies and the Summer &amp; Winter seasons. Profiler chose to bin Release Date by month instead of by year.Transform:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Conditioned duplicate detection. Left: Movie titles clustered by Levenshtein distance reveal over 200 potential duplicates. Right: Conditioning the clustering routine on 'Release Year' reduces the number of potential duplicates to 10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>. . [] . . . [] . . . [] . . . [] . . . [] . . . [] . . . [] . . . [] . . .(a) Data</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The Profiler Architecture. An (a) input table is analyzed to (b) infer types for each column. Type information is used to (c) generate features prior to running (d) anomaly detection routines. The results of anomaly detection and mutual information analysis are used to perform (e) view recommendation and populate a set of (f) interactive visualizations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure6: Taxonomy of Data Quality Issues. We list classes of methods for detecting each issue, example routines used in Profiler, and visualizations for assessing their output.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Adding perceptual discontinuity to summary views. Left: A binned scatter plot using a naive opacity ramp from 0-1. Right: An opacity scale with a minimum non-zero opacity ensures perception of bins containing relatively few data points.</figDesc><graphic coords="6,316.81,53.80,244.80,126.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Performance (in ms) of linked highlighting in a scatter plot matrix (SPLOM). Orange bars represent query processing time, blue bars represent rendering time. We varied the number of dimensions, bins per dimension and data set size. In most cases we achieve interactive (sub-100ms) response rates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table (</head><label>(</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="3">(d) Anomaly Detection</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>t 1</cell><cell>t 2</cell><cell>t 3</cell><cell>derived</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>[][] 1 0 1 .8 .1 .7</cell><cell>[][] 1 0 1 .8 .1 .7</cell></row><row><cell>t 1</cell><cell>t 2</cell><cell>t 3</cell><cell>t 1</cell><cell>t 2</cell><cell>t 3</cell></row><row><cell cols="3">b) Type Inference</cell><cell cols="3">(c) Feature Generation</cell></row></table><note><p>[] . . . [] . . . [] . . . [] . . . [] . . . (e) View Recommendation [] . . . [] . . . anomalies (f) Interactive Visualization anomalies derived</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">ACKNOWLEDGEMENTS</head><p>The first author was supported by a Stanford Graduate Fellowship. This work was partially funded by NSF grant CCF-0964173.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Missing Data</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Allison</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Sage Publications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">D3: Data-driven documents</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bostock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ogievetsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVCG</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2301" to="2309" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Scatterplot matrix techniques for large N</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Littlefield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Nicholson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Littlefield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">398</biblScope>
			<biblScope unit="page" from="424" to="436" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Anomaly detection: A survey</title>
		<author>
			<persName><forename type="first">V</forename><surname>Chandola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="58" />
			<date type="published" when="2009-07">July 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Exploratory Data Mining and Data Cleaning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Dasu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>John Wiley &amp; Sons, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Data quality and the bottom line: Achieving business success through a commitment to high quality data</title>
		<author>
			<persName><forename type="first">W</forename><surname>Eckerson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
		<respStmt>
			<orgName>The Data Warehousing Institute</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Duplicate record detection: A survey</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Elmagarmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Ipeirotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Verykios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TKDE</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Coordinating computational and visual approaches for interactive feature selection and multivariate clustering</title>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="232" to="246" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Clio grows up: from research prototype to industrial tool</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Hernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Popa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGMOD</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="805" to="810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Quantitative data cleaning for large databases</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>White Paper, U.N. Economic Commission for Europe</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">HD-Eye: visual mining of high-dimensional data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hinneburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wawryniuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE CG&amp;A</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="22" to="31" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A survey of outlier detection methodologies</title>
		<author>
			<persName><forename type="first">V</forename><surname>Hodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Austin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Rev</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="85" to="126" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Tane: An efficient algorithm for discovering functional and approximate dependencies</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huhtala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kärkkäinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Porkka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Toivonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Computer Journal</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="100" to="111" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">D</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mazzocchi</surname></persName>
		</author>
		<author>
			<persName><surname>Google Refine</surname></persName>
		</author>
		<ptr target="http://code.google.com/p/google-refine/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Interactive data integration through smart copy &amp; paste</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">G</forename><surname>Ives</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Knoblock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Minton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pratim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Tuchinda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Gazen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CIDR</title>
		<meeting>CIDR</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Wrangler: Interactive visual specification of data transformation scripts</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kandel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Paepcke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hellerstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM CHI</title>
		<meeting>ACM CHI</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="3363" to="3372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Interactive entity resolution in relational data: A visual analytic tool and its evaluation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bilgic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Licamele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVCG</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="999" to="1014" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Information visualization and visual data mining</title>
		<author>
			<persName><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVCG</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E.-K</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining &amp; Knowl. Discovery</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="81" to="99" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">TimeHistograms for large, time-dependent data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kosara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bendix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VisSym</title>
		<meeting>VisSym</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="45" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">End-user programming of mashups with Vegemite</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nichols</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cypher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Intelligent User Interfaces</title>
		<meeting>Intelligent User Interfaces</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="97" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Snap-together visualization: A user interface for coodinating visualizations via relational schemata</title>
		<author>
			<persName><forename type="first">C</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Advanced Visual Interfaces</title>
		<meeting>Advanced Visual Interfaces</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="128" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Systematic yet flexible discovery: guiding domain experts through exploratory data analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Perer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Intelligent User interfaces</title>
		<meeting>Intelligent User interfaces</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="109" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Data cleaning: Problems and current approaches</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rahm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Do</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Engineering Bulletin</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Potter&apos;s wheel: An interactive data cleaning system</title>
		<author>
			<persName><forename type="first">V</forename><surname>Raman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="381" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Modeling by shortest data description</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rissanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="465" to="471" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Visualization of mappings between schemas</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Czerwinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Churchill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM CHI</title>
		<meeting>ACM CHI</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="431" to="439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Mapping nominal values to numbers for effective visualization</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Rosario</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Rundensteiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="80" to="95" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Intelligently creating and recommending reusable reformatting rules</title>
		<author>
			<persName><forename type="first">C</forename><surname>Scaffidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Intelligent User Interfaces</title>
		<meeting>Intelligent User Interfaces</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="297" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A rank-by-feature framework for interactive exploration of multidimensional data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="96" to="113" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Polaris: a system for query, analysis, and visualization of multidimensional relational databases</title>
		<author>
			<persName><forename type="first">C</forename><surname>Stolte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVCG</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="52" to="65" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">GGobi: evolving from XGobi into an extensible framework for interactive data visualization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Swayne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comp. Stat. &amp; Data Analysis</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="423" to="444" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Outliers, level shifts, and variance changes in time series</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Tsay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Forecasting</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Building mashups by example</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tuchinda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szekely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Knoblock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Intelligent User Interfaces</title>
		<meeting>Intelligent User Interfaces</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="139" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Graphics of Large Datasets: Visualizing a Million</title>
		<author>
			<persName><forename type="first">A</forename><surname>Utwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Theus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hofmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Building highly-coordinated visualizations in Improvise</title>
		<author>
			<persName><forename type="first">C</forename><surname>Weaver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE InfoVis</title>
		<meeting>IEEE InfoVis</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="159" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Visual hierarchical dimension reduction for exploration of high dimensional datasets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Rundensteiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VisSym</title>
		<meeting>VisSym</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="19" to="28" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
