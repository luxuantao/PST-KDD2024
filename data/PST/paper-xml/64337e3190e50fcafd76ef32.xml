<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Generative Agents: Interactive Simulacra of Human Behavior</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-04-07">7 Apr 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Joon</forename><forename type="middle">Sung</forename><surname>Park</surname></persName>
							<email>joonspk@stanford.edu</email>
						</author>
						<author>
							<persName><forename type="first">Joseph</forename><forename type="middle">C</forename><surname>O'brien</surname></persName>
							<email>jobrien3@stanford.edu</email>
						</author>
						<author>
							<persName><forename type="first">Carrie</forename><forename type="middle">J</forename><surname>Cai</surname></persName>
							<email>cjcai@google.com</email>
						</author>
						<author>
							<persName><forename type="first">Meredith</forename><forename type="middle">Ringel</forename><surname>Morris</surname></persName>
							<email>merrie@google.com</email>
						</author>
						<author>
							<persName><roleName>M.S</roleName><forename type="first">Percy</forename><surname>Liang</surname></persName>
							<email>pliang@cs.stanford.edu</email>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
						</author>
						<author>
							<persName><surname>Bernstein</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University Stanford</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Stanford University Stanford</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Google Research Mountain View</orgName>
								<address>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Google Research Seattle</orgName>
								<address>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Stanford University Stanford</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Stanford University Stanford</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Generative Agents: Interactive Simulacra of Human Behavior</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-04-07">7 Apr 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2304.03442v1[cs.HC]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Human-AI Interaction</term>
					<term>agents</term>
					<term>generative AI</term>
					<term>large language models</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Figure <ref type="figure">1</ref>: Generative agents create believable simulacra of human behavior for interactive applications. In this work, we demonstrate generative agents by populating a sandbox environment, reminiscent of The Sims, with twenty-five agents. Users can observe and intervene as agents they plan their days, share news, form relationships, and coordinate group activities.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>How might we craft an interactive artificial society that reflects believable human behavior? From sandbox games such as The Sims to applications such as cognitive models <ref type="bibr" target="#b20">[21]</ref> and virtual environments <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b57">58]</ref>, for over four decades researchers and practitioners have envisioned computational agents that can serve as believable proxies of human behavior. In these visions, computationallypowered agents act consistently with their past experiences and react believably to their environments. Such simulations of human behavior could populate virtual spaces and communities with realistic social phenomena <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b77">79]</ref>, train people how to handle rare yet difficult interpersonal situations <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b92">93]</ref>, test social science theories <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b44">45]</ref>, craft model human processors for theory and usability testing <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b49">50]</ref>, power ubiquitous computing applications <ref type="bibr" target="#b29">[30]</ref> and social robots <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b12">13]</ref>, and underpin non-playable game characters <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b82">84]</ref> that can navigate complex human relationships in an open world.</p><p>However, the space of human behavior is vast and complex <ref type="bibr" target="#b82">[84,</ref><ref type="bibr" target="#b107">108]</ref>. Despite striking progress in large language models <ref type="bibr" target="#b16">[17]</ref> that can simulate believable human behavior at a single time point <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b77">79]</ref>, fully general agents that ensure long-term coherence would be better suited by architectures that manage constantly-growing memories as new interactions, conflicts, and events arise and fade over time, while handling cascading social dynamics that unfold between multiple agents. Success requires an approach that can retrieve relevant events and interactions over a long period, reflect on those memories to generalize and draw higher-level inferences, and apply that reasoning to create plans and reactions that both make sense in the moment and in the longer-term arc of the agent's behavior.</p><p>In this paper, we introduce generative agents-agents that draw on generative models to simulate believable human behavior-and demonstrate that they produce believable simulacra of both individual and emergent group behavior. Generative agents draw a wide variety of inferences about themselves, other agents, and their environment; they create daily plans that reflect their characteristics and experiences, act out those plans, react, and re-plan when appropriate; they respond when the end user changes their environment or commands them in natural language. For instance, generative agents turn off the stove when they see that their breakfast is burning, wait outside the bathroom if it is occupied, and stop to chat when they meet another agent they want to talk to. A society full of generative agents is marked by emergent social dynamics where new relationships are formed, information diffuses, and coordination arises across agents.</p><p>To enable generative agents, we describe an agent architecture that stores, synthesizes, and applies relevant memories to generate believable behavior using a large language model. Our architecture comprises three main components. The first is the memory stream, a long-term memory module that records, in natural language, a comprehensive list of the agent's experiences. The retrieval model combines relevance, recency, and importance to surface the records that are needed to inform the agent's moment-to-moment behavior. The second is reflection, which synthesizes memories into higherlevel inferences over time, enabling the agent to draw conclusions about itself and others to better guide its behavior. The third is planning, which translates those conclusions and the current environment into high-level action plans and then recursively into detailed behaviors for action and reaction. These reflections and plans are fed back into the memory stream to influence the agent's future behavior.</p><p>This architecture suggests applications in multiple domains, from role-play and social prototyping, to virtual worlds and games. In social role-play scenarios (e.g. interview preparation), a user could safely rehearse difficult, conflict-laden conversations. When prototyping social platforms, a designer could go beyond temporary personas to prototype dynamic, complex interactions that unfold over time. For the purposes of this paper, we focus on the ability to create a small, interactive society of agents inspired by games such as The Sims. <ref type="foot" target="#foot_0">1</ref> By connecting our architecture to the ChatGPT large language model [76], we manifest a small society of twenty five agents in a game environment. End users can observe and interact with these agents. If an end user or developer wanted the town to host an in-game Valentine's Day party, for example, traditional game environments would require scripting tens of characters' behavior manually. We demonstrate that, with generative agents, it is sufficient to simply tell one agent that she wants to throw a party. Despite many potential points of failure-the party planner must remember to tell other agents about the party, attendees must remember the invitation, those who remember must decide to actually show up, and other possible points of failure-agents in our environment succeed. They spread the word about the party and then show up, with one agent even asking another agent on a date to the party, all from this single user-generated seed suggestion.</p><p>We conducted two evaluations of generative agents: a controlled evaluation to test whether the agents produce believable individual behaviors in isolation, and an end-to-end evaluation where the generative agents interacted with each other in open-ended ways over two days of game time to understand their stability and emergent social behaviors. In the technical evaluation, we leverage a methodological opportunity to evaluate an agent's knowledge and behavior by "interviewing" it in natural language to probe agents' ability to stay in character, remember, plan, react, and reflect accurately. We compared several ablations that limit agents' access to memory, reflection, and planning. We observe that each of these components is critical to strong performance across these interview tasks. Across the technical and the end-to-end evaluation, the most common errors arose when the agent failed to retrieve relevant memories, fabricated embellishments to the agent's memory, or inherited overly formal speech or behavior from the language model.</p><p>In sum, this paper provides the following contributions:</p><p>? Generative agents, believable simulacra of human behavior that are dynamically conditioned on agents' changing experiences and environment. ? A novel architecture that makes it possible for generative agents to remember, retrieve, reflect, interact with other agents, and plan through dynamically evolving circumstances.</p><p>The architecture leverages the powerful prompting capabilities of large language models and supplements those capabilities to support longer-term agent coherence, the ability to manage dynamically-evolving memory, and recursively produce more generations. ? Two evaluations (a controlled evaluation and end-to-end evaluation) that establish causal effects of the importance of components of the architecture, as well as identify breakdowns arising from, e.g., improper memory retrieval. ? Discussion of the opportunities and ethical and societal risks of generative agents in interactive systems. We argue that these agents should be tuned to mitigate the risk of users forming parasocial relationships, logged to mitigate risks stemming from deepfakes and tailored persuasion, and applied in ways that complement rather than replace human stakeholders in design processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In this section, we reflect on the prior literature in human-AI interaction and situate within its canon the agenda of building believable proxies of human behavior. This agenda, once hailed as a north star in interaction, game, and artificial intelligence communities <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b82">84,</ref><ref type="bibr" target="#b83">85]</ref>, has remained challenging due to the complexity of human behavior <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b107">108]</ref>. We synthesize this research to suggest that large language models, though not sufficient by themselves, open up a new angle for creating believable agents when leveraged using the appropriate architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Human-AI Interaction</head><p>Interactive artificial intelligence systems aim to combine human insights and capabilities in computational artifacts that can augment their users <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b28">29]</ref>. A long line of work has explored ways to allow users to interactively specify model behavior. For instance, Crayons demonstrated an early vision of interactive machine learning, allowing non-expert users to train classifiers <ref type="bibr" target="#b28">[29]</ref>. Further work helped to articulate how end users might describe their classification goals to the system through examples <ref type="bibr" target="#b32">[33]</ref> and/or demonstration <ref type="bibr" target="#b30">[31]</ref>. More recent work has extended these explorations to deep learning <ref type="bibr" target="#b61">[62]</ref> and prompt-based authoring <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b105">106]</ref>. Meanwhile, a persistent thread of research has advanced the case for language-and agent-based interaction in human-computer interaction. Formative work such as SHRDLU <ref type="bibr" target="#b102">[103]</ref> and ELIZA <ref type="bibr" target="#b101">[102]</ref> demonstrated the opportunity and the risks of natural language interaction with computing systems. As research progressed, it became clear that autonomous agents could offer new metaphors for delegation and interaction <ref type="bibr" target="#b66">[67]</ref>, but the delegation lines between humans and agents have continued to be debated and refined <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b87">88,</ref><ref type="bibr" target="#b88">89]</ref>. Recently, this technology has become stable enough that it has become possible for agents to interact via natural language in large and complex online social environments (e.g., <ref type="bibr" target="#b53">[54]</ref>). Natural language interaction offers a novel modality that can extend user abilities in domains such as photo editing <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b63">64]</ref> and code editing <ref type="bibr" target="#b86">[87]</ref>.</p><p>We convene these threads of work to show that we can now create agents that proxy human behavior for interactive systems, and interact with them via natural language. In doing so, this work re-opens the door to examining foundational HCI questions around cognitive models such as GOMS and KLM <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>, around prototyping tools <ref type="bibr" target="#b77">[79]</ref>, and around ubiquitous computing applications <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b99">100]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Believable Proxies of Human Behavior</head><p>Prior literature has described believability, or believable agents, as a central design and engineering goal. Believable agents are designed to provide an illusion of life and present a facade of realism in the way they appear to make decisions and act on their own volition, similar to the characters in Disney movies <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b94">95]</ref>. These agents can populate and perceive an open-world environment like the one we inhabit <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b57">58]</ref>, and strive to behave in ways that exhibit emergent behaviors grounded in social interactions with users or other agents with the aim of becoming believable proxies of our behavior in hypothetical simulations of individuals and communities <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b69">70]</ref>. Historically, these agents were developed in the context of intelligent game NPCs <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b82">84]</ref>. Creating NPCs with believable behavior, if possible, could enhance player experiences in games and interactive fictions by enabling emergent narratives <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b91">92]</ref> and social interactions with the agents <ref type="bibr" target="#b109">[110]</ref>. However, more importantly, game worlds provide increasingly realistic representations of real-world affordances, and as observed by Laird and van Lent in 2001, these simulated worlds offer accessible testbeds for developers of believable agents to finesse the agents' cognitive capabilities without worrying about implementing robotics in the real world or creating simulation environments from scratch <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b82">84]</ref>.</p><p>A diverse set of approaches to creating believable agents emerged over the past four decades. In implementation, however, these approaches often simplified the environment or dimensions of agent behavior to make the effort more manageable <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b71">72]</ref>. Rule-based approaches, such as finite-state machines <ref type="bibr" target="#b89">[90,</ref><ref type="bibr" target="#b95">96]</ref> and behavior trees <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b79">81]</ref>, account for the brute force approach of humanauthoring the agent's behavior <ref type="bibr" target="#b69">[70]</ref>. They provide a straightforward way of creating simple agents that is still the most dominant approach today <ref type="bibr" target="#b67">[68,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b108">109]</ref>, and can even handle rudimentary social interactions, as shown in simulation games such as Mass Effect <ref type="bibr" target="#b11">[12]</ref> and The Sims <ref type="bibr" target="#b5">[6]</ref> series. Nonetheless, manually crafting behavior that can comprehensively address the breadth of possible interactions in an open world is untenable. This means that the resulting agent behaviors may not fully represent the consequences of their interactions <ref type="bibr" target="#b68">[69]</ref><ref type="bibr" target="#b69">[70]</ref><ref type="bibr" target="#b70">[71]</ref>, and cannot perform new procedures that were not hard-coded in their script <ref type="bibr" target="#b89">[90,</ref><ref type="bibr" target="#b95">96]</ref>. On the other hand, prevalent learning-based approaches for creating believable agents, such as reinforcement learning, have overcome the challenge of manual authoring by letting the agents learn their behavior, and have achieved superhuman performance in recent years in games such as AlphaStar for Starcraft <ref type="bibr" target="#b97">[98]</ref> and OpenAI Five for Dota 2 <ref type="bibr" target="#b9">[10]</ref>. However, their success has largely taken place in adversarial games with readily definable rewards that a learning algorithm can optimize for. They have not yet addressed the challenge of creating believable agents in an open world <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b89">90]</ref>.</p><p>Cognitive architectures in computation, pioneered by Newell, aimed to build the infrastructure for supporting a comprehensive set of cognitive functions <ref type="bibr" target="#b74">[75]</ref> that suited the all-encompassing nature of believable agents held in its original vision. They fueled some of the earliest examples of believable agents. For instance, Quakebot-SOAR <ref type="bibr" target="#b58">[59]</ref> and ICARUS <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b62">63]</ref> generated NPCs in firstperson shooter games, while TacAir-SOAR <ref type="bibr" target="#b78">[80]</ref> generated pilots in aerial combat training simulations. The architectures used by these agents differed (Quakebot-and TacAir-SOAR relied on SOAR <ref type="bibr" target="#b59">[60]</ref>, while ICARUS relied on its own variation that was inspired by SOAR and ACT-R <ref type="bibr" target="#b4">[5]</ref>), but they shared the same underlying principle <ref type="bibr" target="#b60">[61]</ref>. They maintained short-term and long-term memories, filled these memories with symbolic structures, and operated in perceive-plan-act cycles, dynamically perceiving the environment and matching it with one of the manually crafted action procedures <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b95">96]</ref>. Agents created using cognitive architectures aimed to be generalizable to most, if not all, open-world contexts and exhibited robust behavior for their time. However, their space of action was limited to manually crafted procedural knowledge, and they did not offer a mechanism through which the agents could be inspired to seek new behavior. As such, these agents were deployed mostly in non-open-world contexts such as first-person shooter games <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b58">59]</ref> or blocks worlds <ref type="bibr" target="#b62">[63]</ref>.</p><p>Today, creating believable agents as described in its original definition remains an open problem <ref type="bibr" target="#b82">[84,</ref><ref type="bibr" target="#b107">108]</ref>. Many have moved on, arguing that although existing approaches for creating believable agents might be cumbersome and limited, they are good enough to support existing gameplay and interactions <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b107">108]</ref>. Our argument is that large language models offer an opportunity to re-examine these questions, provided that we can craft an effective architecture to synthesize memories into believable behavior. We offer a step toward such an architecture in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Large Language Models and Human Behavior</head><p>Generative agents leverage a large language model to power their behavior. The key observation is that large language models encode a wide range of human behavior represented in their training data <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b16">17]</ref>. If prompted with a narrowly defined context, the models can be used to generate believable behavior. Recent work has demonstrated the efficacy of this approach. For instance, Social Simulacra used a large language model to generate users that would populate new social computing systems to prototype their emergent social dynamics <ref type="bibr" target="#b77">[79]</ref>. This approach used a prompt chain <ref type="bibr" target="#b104">[105,</ref><ref type="bibr" target="#b105">106]</ref> to generate short natural language descriptions of personas and their behaviors as they appear in the system being prototyped.</p><p>Other empirical studies have replicated existing social science studies <ref type="bibr" target="#b44">[45]</ref>, political surveys <ref type="bibr" target="#b90">[91]</ref>, and generated synthetic data <ref type="bibr" target="#b37">[38]</ref>. Large language models have also been used to generate interactive human behavior for users to engage with. In gaming, for instance, these models have been employed to create interactive fiction <ref type="bibr" target="#b35">[36]</ref> and text adventure games <ref type="bibr" target="#b19">[20]</ref>. With their ability to generate and decompose action sequences, large language models have also been used in planning robotics tasks <ref type="bibr" target="#b46">[47]</ref>. For example, when presented with a task, such as picking up a bottle, the model is prompted to break down the task into smaller action sequences, such as heading to the table where the bottle is located and picking it up. We posit that, based on the work summarized above, large language models can become a key ingredient for creating believable agents. The existing literature largely relies on what could be considered first-order templates that employ few-shot prompts <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b64">65]</ref> or chain-of-thought prompts <ref type="bibr" target="#b98">[99]</ref>. These templates are effective in generating behavior that is conditioned solely on the agent's current environment (e.g., how would a troll respond to a given post, what actions would a robot need to take to enter a room given that there is a door). However, believable agents require conditioning not only on their current environment but also on a vast amount of past experience, which is a poor fit (and as of today, impossible due to the underlying models' limited context window) using first-order prompting. Recent studies have attempted to go beyond first-order prompting by augmenting language models with a static knowledge base and an information retrieval scheme <ref type="bibr" target="#b51">[52]</ref> or with a simple summarization scheme <ref type="bibr" target="#b103">[104]</ref>. This paper extends these ideas to craft an agent architecture that handles retrieval where past experience is dynamically updated at each time step and mixed with agents' current context and plans, which may either reinforce or contradict each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">GENERATIVE AGENT BEHAVIOR AND INTERACTION</head><p>To make concrete the affordances of generative agents, we instantiate them as characters in a simple sandbox world reminiscent of The Sims <ref type="bibr" target="#b5">[6]</ref>. This sprite-based sandbox game world, Smallville, evokes a small town environment. In this section, we walk through the affordances and interactions with generative agents in Smallville, and describe how the agents behave in it. Then, in Section 4, we introduce our generative agent architecture that powers these affordances and interactions. In Section 5, we describe the sandbox The Smallville sandbox world, with areas labeled. The root node describes the entire world, children describe areas (e.g., houses, cafe, stores), and leaf nodes describe objects (e.g., table, bookshelf). Agent remember a subgraph reflecting the parts of the world they have seen, in the state that they saw them.</p><p>environment implementation and how the agents interact with the sandbox world's underlying engine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Agent Avatar and Communication</head><p>A community of 25 unique agents inhabit Smallville. Each agent is represented by a simple sprite avatar. We authored one paragraph of natural language description to depict each agent's identity, including their occupation and relationship with other agents, as seed memories. For example, John Lin has the following description:</p><p>John Lin is a pharmacy shopkeeper at the Willow Market and Pharmacy who loves to help people. He is always looking for ways to make the process of getting medication easier for his customers; John Lin is living with his wife, Mei Lin, who is a college professor, and son, Eddy Lin, who is a student studying music theory; John Lin loves his family very much; John Lin has known the old couple next-door, Sam Moore and Jennifer Moore, for a few years; John Lin thinks Sam Moore is a kind and nice man; John Lin knows his neighbor, Yuriko Yamamoto, well; John Lin knows of his neighbors, Tamara Taylor and Carmen Ortiz, but has not met them before; John Lin and Tom Moreno are colleagues at The Willows Market and Pharmacy; John Lin and Tom Moreno are friends and like to discuss local politics together; John Lin knows the Moreno family somewhat well -the husband Tom Moreno and the wife Jane Moreno.</p><p>Each semicolon-delimited phrase is entered into the agent's initial memory as memories at the start of the simulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Inter-Agent Communication.</head><p>The agents interact with the world by their actions, and with each other through natural language. At each time step of the sandbox engine, the agents output a natural language statement describing their current action, such as "Isabella Rodriguez is writing in her journal", "Isabella Rodriguez is checking her emails", "Isabella Rodriguez is talking with her family on the phone", or "Isabella Rodriguez is getting ready for bed". This statement is then translated into concrete movements that affect the sandbox world. The action is displayed on the sandbox interface as a set of emojis that provide an abstract representation of the action in the overhead view. To accomplish this, the system employs a language model that translates the action into a set of emojis, which appear above each avatar in a speech bubble. For example, "Isabella Rodriguez is writing in her journal" is displayed as , while "Isabella Rodriguez is checking her emails" appears as . The full natural language description of the action can be accessed by clicking on the agent avatar.</p><p>Agents communicate with each other in full natural language. Agents are aware of other agents in their local area, and the generative agent architecture determines whether they walk by or engage in conversation. Here, a sample in the middle of a conversation between the agents Isabella Rodriguez and Tom Moreno about the upcoming election:<ref type="foot" target="#foot_1">2</ref> Isabella: I'm still weighing my options, but I've been discussing the election with Sam Moore. What are your thoughts on him? Tom: To be honest, I don't like Sam Moore. I think he's out of touch with the community and doesn't have our best interests at heart.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">User Controls.</head><p>A user running this simulation can steer the simulation and intervene, either by communicating with the agent through conversation, or by issuing a directive to an agent in the form of an 'inner voice'.</p><p>The user communicates with the agent through natural language, by specifying a persona that the agent should perceive them as. For example, if the user specifies that they are a news "reporter" and asks about the upcoming election, "Who is running for office?", the John agent replies:</p><p>John: My friends Yuriko, Tom and I have been talking about the upcoming election and discussing the candidate Sam Moore. We have all agreed to vote for him because we like his platform.</p><p>To directly command one of the agents, the user takes on the persona of the agent's "inner voice"-this makes the agent more likely to treat the statement as a directive. For instance, when told "You are going to run against Sam in the upcoming election" by a user as John's inner voice, John decides to run in the election and shares his candidacy with his wife and son.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Environmental Interaction</head><p>Smallville features the common affordances of a small village including a cafe, bar, park, school, dorm, houses, and stores. It also defines subareas and objects that make those spaces functional, such as a kitchen in a house and a stove in the kitchen (Figure <ref type="figure" target="#fig_0">2</ref>). All spaces serving as agents' primary living quarters feature a bed, desk, closet, shelf, as well as a bathroom and a kitchen. <ref type="foot" target="#foot_2">3</ref>Agents move around Smallville as one would in a simple video game, entering and leaving buildings, navigating its map, and approaching other agents. Agent movements are directed by the generative agent architecture and the sandbox game engine: when the model dictates that the agent will move to a location, we calculate a walking path to the destination in the Smallville environment and the agent begins moving. In addition, users can also enter the sandbox world of Smallville as an agent operating within it. The agent that the user embodies can be an agent already present in the world, such as Isabella and John, or it can be an outside visitor with no prior history in Smallville. The inhabitants of Smallville will treat the user-controlled agent no differently than they treat each other. They recognize its presence, initiate interactions, and remember its behavior before forming opinions about it.</p><p>Users and agents can influence the state of the objects in this world, much like in sandbox games such as The Sims. For example, a bed can be occupied when an agent is sleeping, and a refrigerator can be empty when an agent uses up the ingredients to make breakfast. End users can also reshape an agent's environment in Smallville by rewriting the status of objects surrounding the agent in natural language. For instance, when Isabella is making breakfast in the morning, the user can change the status of the kitchen stove from "turned on" to "burning" by inputting a command to the system that chooses the object and illustrates its new status, like this: "&lt;Isabella's apartment: kitchen: stove&gt; is burning." Isabella will notice this in the next moment and go to turn off the stove and remake her breakfast. Likewise, if the user sets the status of Isabella's shower to "leaking water" when she enters the bathroom, she gathers tools from her living room and try to fix the leak.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Example "Day in the Life"</head><p>Starting from the single-paragraph description, agents begin plan their days. As time passes in the sandbox world, their behaviors evolve as these agents interact with each other and the world, build memories and relationships, and coordinate joint activities.</p><p>We demonstrate the behavior of generative agents by tracing the output of our system over the course of one day for the agent John Lin (Figure <ref type="figure" target="#fig_2">3</ref>). In the Lin family, John is the first to wake up at 7 a.m. He brushes his teeth, takes a shower, gets dressed, eats breakfast, and checks the news at the dining table in the living room. At 8 a.m., Eddy follows suit, rushing out of bed to prepare for his classes. He catches up with John just as he is about to head out:</p><p>John: Good morning Eddy. Did you sleep well? Eddy: Good morning dad. Yeah, I slept great. John: That's good. What are you working on today? Eddy: I'm working on a new music composition for my class. It's due this week, so I'm trying to get it finished. But I'm having so much fun with it! John: That sounds great! Soon after Eddy heads out, Mei wakes up and joins John. Mei asks about her son, and John recalls the conversation that they just had:</p><p>Mei: Did Eddy already leave for school? John: Yes, he just left. He's working on a music composition for his class. Mei: Oh, that's wonderful! Tell me about it. John: I think he's really enjoying it! He said he's having a lot of fun with it. Mei: That's great! I'm so proud of him.</p><p>As they finish their conversation, Mei and John pack up. Mei goes on to teach and work on her research paper, while John opens his pharmacy counter at the Willow Market and Pharmacy by 9 a.m.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Emergent Social Behaviors</head><p>By interacting with each other, generative agents in Smallville exchange information, form new relationships, and coordinate joint activities. Extending prior work <ref type="bibr" target="#b77">[79]</ref>, these social behaviors are emergent rather than pre-programmed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Information Diffusion.</head><p>As agents notice each other, they may engage in dialogue-as they do so, information can spread from agent to agent. For instance, in a conversation between Sam and Tom at the grocery store, Sam tells Tom about his candidacy in the local election:   Later that day, after Sam left, Tom and John, who heard the news from another source, discuss Sam's chances of winning the election:</p><p>John: I heard that Sam Moore is running for mayor in the local election. Do you think he has a good chance of winning? Tom: I do think he has a good chance. He's been working hard in the community and I think he will get a lot of support. What do you think? John: I think it's great that he's running. I'm curious to see who else is running and how the election will turn out.</p><p>Gradually, Sam's candidacy becomes the talk of the town, with some supporting him and others remaining undecided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Relationship memory.</head><p>Agents in Smallville form new relationships over time, and remember their interactions with other agents. For example, Sam does not know Latoya Williams at the start. While taking a walk in Johnson Park, Sam runs into Latoya, and they introduce themselves and Latoya mentions that she is working on a photography project: "I'm here to take some photos for a project I'm working on." In a later interaction, Sam's interactions with Latoya indicate a memory of that interaction, as he asks "Hi, Latoya. How is your project going?" and she replies "Hi, Sam. It's going well!"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3">Coordination. Generative agents coordinate with each other.</head><p>Isabella Rodriguez, at Hobbs Cafe, is initialized with an intent to plan a Valentine's Day party from 5 to 7 p.m. on February 14th. From this seed, the agent proceeds to invites friends and customers when she sees them at Hobbs Cafe or elsewhere. Isabella then spends the afternoon of the 13th decorating the cafe for the occasion. Maria, a frequent customer and close friend of Isabella's, arrives at the cafe. Isabella asks for Maria's help in decorating for the party, and Maria agrees. Maria's character description mentions that she has a crush on Klaus. That night, Maria invites Klaus, her secret crush, to join her at the party, and he gladly accepts.</p><p>On Valentine's Day, five agents-including Klaus and Mariashow up at Hobbs Cafe at 5pm and they enjoy the festivities (Figure <ref type="figure" target="#fig_3">4</ref>). In this scenario, the end user only set Isabella's initial intent Figure <ref type="figure">5</ref>: Our generative agent architecture. Agents perceive their environment, and all perceptions are saved in a comprehensive record of the agent's experiences called the memory stream. Based on their perceptions, the architecture retrieves relevant memories, then uses those retrieved actions to determine an action. These retrieved memories are also used to form longer-term plans, and to create higher-level reflections, which are both entered into the memory stream for future use.</p><p>to throw a party and Maria's crush on Klaus: the social behaviors of spreading the word, decorating, asking each other out, arriving at the party, and interacting with each other at the party, were initiated by the agent architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">GENERATIVE AGENT ARCHITECTURE</head><p>Generative agents aim to provide a framework for behavior in an open world: one that can engage in interactions with other agents and can react to changes in the environment. Generative agents take their current environment and past experience as input and generate behavior as output. Underlying this behavior is a novel agent architecture that combines a large language model with mechanisms for synthesizing and retrieving relevant information to condition the language model's output on. Without these mechanisms, large language models can output behavior, but the resulting agents may not react based on the agent's past experiences, may not make important inferences, and may not maintain long-term coherence. Challenges with long-term planning and coherence remain <ref type="bibr" target="#b17">[18]</ref> even with today's most performant models such as GPT-4. Because generative agents produce large streams of events and memories that must be retained, a core challenge of our architecture is to ensure that the most relevant pieces of the agent's memory are retrieved and synthesized when needed.</p><p>At the center of our architecture is the memory stream, a database that maintains a comprehensive record of an agent's experience. From the memory stream, records are retrieved as relevant to plan the agent's actions and react appropriately to the environment, and records are recursively synthesized into higher-and higher-level observations that guide behavior. Everything in the architecture is recorded and reasoned over as natural language description, allowing the architecture to leverage a large language model.</p><p>Our current implementation utilizes gpt3.5-turbo version of Chat-GPT <ref type="bibr">[76]</ref>. We expect that the architectural basics of generative agents-memory, planning, and reflection-will likely remain the same as language models improve. Newer language models (e.g., GPT-4) will continue to expand the expressivity and performance of the prompts that underpin generative agents. As of writing, however, GPT-4's API is still invitation-only, so our agents use ChatGPT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Memory and Retrieval</head><p>Challenge: Creating generative agents that can simulate human behavior requires reasoning about a set of experiences that is far larger than what should be described in a prompt, as the full memory stream can distract the model and does not even currently fit into the limited context window. Consider a the Isabella agent answering the question "What are you passionate about these days?". First summarizing all of Isabella's experiences to fit in the limited context window of the language model produces an uninformative response, where Isabella discusses topics such as collaborations for events and projects and cleanliness and organization in a cafe. Instead of summarizing, the memory stream described below surfaces relevant memories, resulting in a more informative and specific response that mentions Isabella's passion for making people feel welcome and included, planning events and creating an atmosphere that people can enjoy, such as the Valentine's Day party.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Approach:</head><p>The memory stream maintains a comprehensive record of the agent's experience. It is a list of memory objects, where each object contains a natural language description, a creation timestamp and a most recent access timestamp. The most basic element of the memory stream is an observation, which is an event directly perceived by an agent. Common observations include behaviors performed by the agent themselves, or behaviors that agents perceive being performed by other agents or non-agent objects. For instance, Isabella Rodriguez, who works at a coffee shop, might accrue the following observations over time: <ref type="bibr" target="#b0">(1)</ref> Isabella Rodriguez is setting out the pastries, (2) Maria Lopez is studying for a Chemistry test while drinking coffee, (3) Isabella Rodriguez and Maria Lopez are conversing about planning a Valentine's day party at Hobbs Cafe, <ref type="bibr" target="#b3">(4)</ref> The refrigerator is empty. The memory stream comprises a large number of observations that are relevant and irrelevant to the agent's current situation. Retrieval identifies a subset of these observations that should be passed to the language model to condition its response to the situation.</p><p>Our architecture implements a retrieval function that takes the agent's current situation as input and returns a subset of the memory stream to pass on to the language model. There are many possible implementations of a retrieval function, depending on what it is important that the agent consider when deciding how to act. In our context, we focus on three main components that together produce effective results.</p><p>Recency assigns a higher score to memory objects that were recently accessed, so that events from a moment ago or this morning are likely to remain in the agent's attentional sphere. In our implementation, we treat recency as an exponential decay function over the number of sandbox game hours since the memory was last retrieved. Our decay factor is 0.99.</p><p>Importance distinguishes mundane from core memories, by assigning a higher score to those memory objects that the agent believes to be important. For instance, a mundane event such as eating breakfast in one's room would yield a low importance score, whereas a breakup with one's significant other would yield a high score. There are again many possible implementations of an importance score; we find that directly asking the language model to output an integer score is effective. The full prompt appears below:</p><p>On the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory. Memory: buying groceries at The Willows Market and Pharmacy Rating: &lt;fill in&gt; This prompt returns an integer value of 2 for "cleaning up the room" and 8 for "asking your crush out on a date. " The importance score is generated at the time the memory object is created.</p><p>Relevance assigns a higher score to memory objects that are related to the current situation. What is relevant depends on the answer to, "Relevant to what?", so we condition relevance on a query memory. If the query, for example, is that a student is discussing what to study for a chemistry test with a classmate, memory objects about their breakfast should have low relevance, whereas memory objects about the teacher and schoolwork should have high relevance. In our implementation, we use the language model to generate an embedding vector of the text description of each memory. Then, we calculate relevance as the cosine similarity between the memory's embedding vector and the query memory's embedding vector.</p><p>To calculate the final retrieval score, we normalize the recency, relevance, and importance scores to the range of [0, 1] by min-max scaling. The retrieval function scores all memories as a weighted combination of the three elements:</p><formula xml:id="formula_0">????? = ? ??????? ? ??????? + ? ?????????? ? ?????????? + ? ????????? ? ?????????.</formula><p>In our implementation, all ?'s are set to 1. The top-ranked memories that fit in the language model's context window are then included in the prompt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Reflection</head><p>Challenge: Generative agents, when equipped with only raw observational memory, struggle to generalize or make inferences. Consider a scenario in which Klaus Mueller is asked by the user: "If you had to choose one person of those you know to spend an hour with, who would it be?" With access to only observational memory, the agent simply chooses the person with whom Klaus has had the most frequent interactions: Wolfgang, his college dorm neighbor. Unfortunately, Wolfgang and Klaus only ever see each other in passing, and do not have deep interactions. A more desirable response requires that the agent generalize from memories of Klaus spending hours on a research project to generate a higherlevel reflection that Klaus is passionate about research, and likewise recognize Maria putting in effort into her own research (albeit in a different field), enabling a reflection that they share a common interest. With the approach below, when Klaus is asked who to spend time with, Klaus chooses Maria instead of Wolfgang.</p><p>Approach: We introduce a second type of memory, which we call a reflection. Reflections are higher-level, more abstract thoughts generated by the agent. Because they are a type of memory, they are included alongside other observations when retrieval occurs. Reflections are generated periodically; in our implementation, we generate reflections when the sum of the importance scores for the latest events perceived by the agents exceeds a certain threshold. In practice, our agents reflected roughly two or three times a day.</p><p>The first step in reflection is for the agent to determine what to reflect on, by identifying questions that can be asked given the agent's recent experiences. We query the large language model with the 100 most recent records in the agent's memory stream (e.g., "Klaus Mueller is reading a book on gentrification", "Klaus Mueller is conversing with a librarian about his research project", "desk at the library is currently unoccupied") and prompt the language model, "Given only the information above, what are 3 most salient high-level questions we can answer about the subjects in the statements?" The model's response generates candidate questions: for example, What topic is Klaus Mueller passionate about? and What is the relationship between Klaus Mueller and Maria Lopez?. We use these generated questions as queries for retrieval, and gather relevant memories (including other reflections) for each question. Then we prompt the language model to extract insights and cite the particular records that served as evidence for the insights. The full prompt appears below: This process generates statements such as Klaus Mueller is dedicated to his research on gentrification (because of 1, 2, 8, 15). We parse and store the statement as a reflection in the memory stream, including pointers to the memory objects that were cited.</p><p>Reflection explicitly allows the agents to reflect not only on their observations but also on other reflections: for example, the second statement about Klaus Mueller above is a reflection that Klaus previously had, not an observation from his environment. As a result, agents generate trees of reflections: the leaf nodes of the tree represent the base observations, and the non-leaf nodes represent thoughts that become more abstract and higher-level higher up the tree they are.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Planning and Reacting</head><p>Challenge: While a large language model can generate plausible behavior in response to situational information (e.g., <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b77">79]</ref>), agents need to plan over a longer time horizon to ensure that their sequence of actions is coherent and believable. If we prompt a language model with Klaus's background, describe the time, and ask what action he ought to take at the given moment, Klaus would eat lunch at 12 pm, but then again at 12:30 pm and 1 pm, despite having already eaten his lunch twice. Optimizing for believability in the moment sacrifices believability over time. To overcome this issue, planning is essential. With the approach described below, Klaus's afternoon plan is less gluttonous: he has lunch at Hobbs Cafe while reading at 12pm, works on his research paper at the school library at 1pm, and takes a break for a walk in the park at 3pm.</p><p>Approach: Plans describe a future sequence of actions for the agent, and help keep the agent's behavior consistent over time. A plan includes a location, a starting time, and a duration. For instance, Klaus Mueller, who is dedicated in his research and has an impending deadline 4 , may choose to spend his day working at his desk drafting his research paper. An entry in a plan might state, for example: for 180 minutes from 9am, February 12th, 2023, at Oak Hill College Dorm: Klaus Mueller's room: desk, read and take notes for research paper. Like reflections, plans are stored in the memory stream and are included in the retrieval process. This allows the agent to consider observations, reflections, and plans all together when deciding how to behave. Agents may change their plans midstream if needed.</p><p>It would be unrealistic and uninteresting for an artist agent to plan on painting while sitting at a pharmacy counter for four hours without moving. A more desirable plan would involve the agent taking the necessary time to gather materials, mix paint, take breaks, and clean up during the four-hour period in its home studio. To create such plans, our approach starts top-down and then recursively generates more detail. The first step is to create a plan that outlines the day's agenda in broad strokes. To create the initial plan, we prompt the language model with the agent's summary description (e.g., name, traits, and summary of their recent experiences) and a summary of their previous day. A full example prompt is below, which is unfinished at the bottom for the language model to complete:</p><p>Name: Eddy Lin (age: 19) Innate traits: friendly, outgoing, hospitable Eddy Lin is a student at Oak Hill College studying music theory and composition. He loves to explore different musical styles and is always looking for ways to expand his knowledge. Eddy Lin is working on a composition project for his college class. He is also taking classes to learn more about music theory. Eddy Lin is excited about the new composition he is working on but he wants to dedicate more hours in the day to work on it in the coming days On Tuesday February 12, Eddy 1) woke up and completed the morning routine at 7:00 am, [. . . ] 4 And, in this way, bears at least a passing resemblance to the authors of this paper. This generates a rough sketch of the agent's plan for a day, divided into five to eight chunks: "1) wake up and complete the morning routine at 8:00 am, 2) go to Oak Hill College to take classes starting 10:00 am, [. . . ] 5) work on his new music composition from 1:00 pm to 5:00 pm, 6) have dinner at 5:30 pm, 7) finish school assignments and go to bed by 11:00 pm."</p><p>The agent saves this plan in the memory stream and then recursively decomposes it to create finer-grained actions, first into hour-long chunks of actions-Eddy's plan to work on his new music composition from 1:00 pm to 5:00 pm becomes 1:00 pm: start by brainstorming some ideas for his music composition [...] 4:00 pm: take a quick break and recharge his creative energy before reviewing and polishing his composition. We then recursively decompose this again into 5-15 minute chunks: e.g., 4:00 pm: grab a light snack, such as a piece of fruit, a granola bar, or some nuts. 4:05 pm: take a short walk around his workspace [...] 4:50 pm: take a few minutes to clean up his workspace. This process can be adjusted to match the desired granularity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Reacting and Updating</head><p>Plans. Generative agents operate in an action loop where, at each time step, they perceive the world around them and those perceived observations are stored in their memory stream. We prompt the language model with these observations to decide whether the agent should continue with their existing plan, or react. Standing at an easel and painting, for example, might trigger an observation of the easel, but this is unlikely to prompt a reaction. However, if Eddy's father John records that he sees Eddy taking a short walk in the house garden, the outcome is different. The prompt is below, with [Agent's Summary Description] standing in for a dynamically-generated, paragraph-long summary of the agent's overall goals and disposition, which is described in Appendix A: [Agent's Summary Description] It is February 13, 2023, 4:56 pm. John Lin's status: John is back home early from work. Observation: John saw Eddy taking a short walk around his workplace. Summary of relevant context from John's memory: Eddy Lin is John's Lin's son. Eddy Lin has been working on a music composition for his class. Eddy Lin likes to walk around the garden when he is thinking about or listening to music. Should John react to the observation, and if so, what would be an appropriate reaction?</p><p>The context summary is generated through two prompts that retrieve memories via the queries "What is [observer]'s relationship with the [observed entity]?" and "[Observed entity] is [action status of the observed entity]", and their answers summarized together. The output suggests that John could consider asking Eddy about his music composition project. We then regenerate the agent's existing plan starting from the time when the reaction takes place. Finally, This generates Eddy's response: "Hey Dad, it's going well. I've been taking walks around the garden to clear my head and get some inspiration." The continuation of this dialogue is generated using the same mechanism until one of the two agents decides to end the dialogue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">SANDBOX ENVIRONMENT IMPLEMENTATION</head><p>The Smallville sandbox game environment is built using the Phaser web game development framework <ref type="bibr" target="#b55">[56]</ref>. The visual environment sprites, including agent avatars, as well as an environment map and collision map that we authored, are imported into Phaser. We supplement the sandbox development framework with a server that makes the sandbox information available to generative agents and enables generative agents to move and influence the sandbox environment. The server maintains a JSON data structure that contains information about each agent in the sandbox world, including their current location, a description of their current action, and the sandbox object they are interacting with. At each sandbox time step, the sandbox server parses the JSON for any changes coming from the generative agents, moves the agents to their new positions, and updates the status of any sandbox objects that the agents are interacting with (e.g., changing the status of the coffee machine from "idle" to "brewing coffee" if an agent's action is "making espresso for a customer @ Hobbs Cafe: counter: coffee machine"). The sandbox server is also responsible for sending all agents and objects that are within a preset visual range for each agent to that agent's memory, so the agent can react appropriately. The agent's output action then updates the JSON, and the process loops for the next time step.</p><p>End users initialize a new agent with a brief natural language description, as in the paragraph about Jon Lin in Section 3.1. In our implementation, we split this semicolon-delimited list of characteristics up into a set of memories. These serve as the initial memories that determine the agent's behavior. These memories are initial starting points: as the agents gain more experience in the sandbox world, and as more records saturate the memory stream, the agent's summary and behavior will evolve.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">From Structured World Environments to Natural Language, And Back Again</head><p>The architecture of generative agents operates using natural language. Therefore, we need a mechanism to ground the agent's reasoning to the sandbox world. To achieve this, we represent the sandbox environment-areas and objects-as a tree data structure, with an edge in the tree indicating a containment relationship in the sandbox world. We convert this tree into natural language to pass to the generative agents. For instance, "stove" being a child of "kitchen" is rendered into "there is a stove in the kitchen. " Agents build individual tree representations of the environment as they navigate it -subgraphs of the overall sandbox environment tree. We initialize each agent with an environment tree capturing the spaces and objects that the agent should be aware of: the rooms and objects in their living quarters, their workplace, and commonly visited stores and shops. As the agents navigate the sandbox world, they update this tree to reflect newly perceived areas. Agents are not omniscient: their tree may get out of date as they leave an area, and is updated when they re-enter the area.</p><p>To determine the appropriate location for each action, we traverse the agent's stored environment tree and flatten a portion of it into natural language to prompt the language model. Recursively starting at the root of the agent's environment tree, we prompt the model to find the most suitable area. For example, if Eddy's agent indicated that he should take a short walk around his workspace: [Agent's Summary Description] Eddy Lin is currently in The Lin family's house: Eddy Lin's bedroom: desk) that has Mei and John Lin's bedroom, Eddy Lin's bedroom, common room, kitchen, bathroom, and garden. Eddy Lin knows of the following areas: The Lin family's house, Johnson Park, Harvey Oak Supply Store, The Willows Market and Pharmacy, Hobbs Cafe, The Rose and Crown Pub. * Prefer to stay in the current area if the activity can be done there. Eddy Lin is planning to take a short walk around his workspace. Which area should Eddy Lin go to?</p><p>This outputs The Lin family's house. We then use the same process recursively to determine the most appropriate subarea within the chosen area until we reach a leaf node of the agent's environment tree. In the example above, the result of this traversal is The Lin family's house: garden: house garden. Finally, we use traditional game path algorithms to animate the agent's movement so that it travels to the location indicated by the leaf node.</p><p>When an agent executes an action on an object, we prompt the language model to ask what happens to the state of the object. For example, if Isabella's generative agent outputs the action "making espresso for a customer", a query to the language model indicates in response that the state of the coffee machine in Hobbs Cafe should change from "off" to "brewing coffee".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONTROLLED EVALUATION</head><p>Generative agents, as individual agents and as groups, aim to produce believable behavior based on their environment and experiences. In our evaluation, we investigate the capacity and limitations of generative agents. Do individual agents properly retrieve past experience, and generate believable plans, reactions, and thoughts that make up their behavior? Does a community of agents illustrate information diffusion, relationship formation, and agent coordination across different pockets of the community?</p><p>We evaluate generative agents in two stages. We begin with a more tightly controlled evaluation in this section, where we individually assess agent responses to understand whether they generate believable behavior in narrowly defined contexts. Then, in our endto-end analysis of the agent community over two full days, we investigate their emergent behavior as a collective as well as errors and boundary conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Evaluation Procedure</head><p>To assess generative agents in Smallville, we take advantage of the fact that generative agents will respond to natural language questions. So, we "interview" agents to probe their ability to remember past experiences, plan future actions based on their experiences, react appropriately to unexpected events, and reflect on their performance to improve their future actions. To respond to these questions properly, the agents must successfully retrieve and synthesize information. Our dependent variable is the believability of the behavior, a central dependent variable in prior work on agents (e.g., <ref type="bibr" target="#b8">[9]</ref>).</p><p>The interview include five question categories, each designed to assess one of the five key areas: maintaining self-knowledge, retrieving memory, generating plans, reacting, and reflecting. For each, we ask five questions that challenge the agents to demonstrate their abilities in that area:</p><p>? Self-knowledge: We ask questions such as "Give an introduction of yourself" or "Describe your typical weekday schedule in broad strokes" that require the agent to maintain an understanding of their core characteristics. ? Memory: We ask questions that prompt the agent to retrieve particular events or dialogues from their memory to answer properly, such as "Who is [name]?" or "Who is running for mayor?" ? Plans: We ask questions that require the agent to retrieve their long-term plans, such as "What will you be doing at 10 am tomorrow?" ? Reactions: As a baseline of believable behavior, we present hypothetical situations for which the agent needs to respond believably: "Your breakfast is burning! What would you do?" ? Reflections: We ask questions that require the agents to leverage their deeper understanding of others and themselves gained through higher-level inferences, such as "If you were to spend time with one person you met recently, who would it be and why?"</p><p>The full list of questions and a sample of agent responses are included in Appendix B. Agents were sampled from the end of a two game-day simulation with the full architecture, by which time they had accrued a number of interactions and memories that should shape their responses. To gather feedback on believability of the responses, we recruited participants as human evaluators and tasked them with watching a replay of a randomly chosen agent's life in Smallville. Participants had access to all information stored in the agent's memory stream.</p><p>The study was a within-subjects design, where 100 participants compared interview responses generated by four different agent architectures and a human author condition for the same agent. The experiment displayed one randomly chosen question from each of the five question categories, along with the agent's responses generated from each condition. The evaluators ranked the believability of all of the conditions from most to least believable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Conditions</head><p>All conditions were used to independently answer each of the interview questions. We compared the generative agent architecture to ablations that disabled the agents' access to some of all of its three types of memory in its memory stream-observation, reflection, and planning-and to a human-generated condition. There are three ablated architectures: a no observation, no reflection, no planning architecture without access to anything in the memory stream such as observations, plans, and reflections; a no reflection, no planning with access to observations in the memory stream but no access to plans or reflections; and a no reflections architecture with access to observations and plans but without access to reflections. The no observation, no reflection, no planning condition effectively represents the previous state of the art for agents created through large language models <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b77">79]</ref>. Architectures were given equivalent access to all memories accrued by the agent up until the moment of the interview, so the differences observed here are likely to represent a conservative estimate of the true differences: in reality, the ablated architectures would not have followed the same path as the full architecture through the two day simulation. We chose to design the experiment this way as re-simulating for each architecture would cause the simulations to diverge into different states, making comparison challenging.</p><p>In addition to the ablation conditions, we added a human crowdworker roleplay condition that is intended to provide a human baseline. We do not intend this baseline to capture maximal human expert performance: instead, we aim to use this condition to identify whether the architecture passes a basic level of behavioral competency, so that we are not just comparing ablations to each other with no behavioral grounding. We recruited a unique worker for each of the 25 agents and tasked them with watching a replay of that agent's sandbox life and inspecting its memory stream. We then asked the worker to roleplay and author responses to the interview questions in the voice of the agent whose replay they watched. To ensure that the human-authored responses met at least a baseline expectation in quality, the first author manually inspected the workers' responses to the question "Describe your typical weekday schedule in broad strokes" to confirm that the responses were written in coherent sentences and in the voice of the agent. Four sets of human-generated responses did not meet these criteria and were re-generated by other workers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Human Evaluators</head><p>We required that our evaluators be in the U.S., fluent in English, and older than 18 years old. They were paid at the rate of $15.00 per hour <ref type="bibr" target="#b85">[86]</ref>, and provided consent by agreeing to a consent form that was approved by our institution's IRB. We recruited 100 evaluators from Prolific, an online platform for recruiting study participants <ref type="bibr" target="#b80">[82]</ref>, whose participation lasted around 30 minutes. Their mean age score of our participants was 4.86 (SD=1.11; 3="18-24 years old, " 4="25-34 years old"), and 25 of them identified themselves as female, 73 as male, and 2 as non-binary. 42 of the participants held a bachelor's degree, 5 a higher degree, 13 an associate's degree, and the rest a high school diploma or some high school-level education. 73.0% of our participants identified as Caucasian, 7.0% as Hispanic, 6.0% as Asian, 10.0% as African American, and 4.0% as other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Analysis</head><p>Our experiment produced 100 sets of rank data, where each participant ranked the five conditions by believability. To translate this rank data into interval data for interpretable comparison, we used the ranks to calculate a TrueSkill rating <ref type="bibr" target="#b40">[41]</ref> for each condition. TrueSkill is a generalization of the Elo chess rating system <ref type="bibr" target="#b27">[28]</ref> for a multi-player environment, and has been used by XBox Live for player ranking from competitive game performance. Given a set of ranked outcomes, TrueSkill outputs a mean rating value ? and variance ? for each condition. Conditions with the same rating should roughly be a toss-up, with each winning half of the comparisons between the two conditions; higher scores indicate conditions that beat lower-ranked conditions in the rankings. Separately, to investigate statistical significance of this result, we applied the Kruskal-Wallis test <ref type="bibr" target="#b54">[55]</ref>, a non-parametric alternative to the one-way ANOVA, to the raw ranks data. We then performed the Dunn post-hoc test <ref type="bibr" target="#b96">[97]</ref> to identify any pairwise differences between the conditions. Finally, we adjusted the p-values for multiple comparisons in the Dunn test using the Holm-Bonferroni method <ref type="bibr" target="#b43">[44]</ref>.</p><p>Furthermore, the first author conducted an inductive analysis <ref type="bibr" target="#b93">[94]</ref> to study the qualitative distinctions between the responses produced in each condition. We employed qualitative open coding <ref type="bibr" target="#b31">[32]</ref> in two phases. In the first phase, we generated codes that closely represented the generated responses at the sentence level. In the second phase, we synthesized the resulting codes from the first phase to extract higher-level themes. We utilized these themes to compare the types of responses generated in our study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Results</head><p>Our findings suggest that the full architecture of generative agents generates the most believable behavior among all study conditions. We contrast the full architecture's responses to those of other conditions below. However, we also report that the full architecture was not without flaws and illustrate its modes of failures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.5.1</head><p>The full architecture bests other conditions. As seen in Figure <ref type="figure" target="#fig_7">8</ref>, the full generative agent architecture produced the most believable behavior (? = 29.89; ? = 0.72). Performance degraded with the removal of each component in the ablation conditions: the ablated architecture with no access to reflection was the next best (? = 26.88; ? = 0.69), followed by no access to reflection or planning (? = 25.64; ? = 0.68), followed by the human condition (? = 22.95; ? = 0.69). The ablated architecture with no access to memory, planning, or reflection performed the worst of all conditions (? = 21.21; ? = 0.70). TrueSkill models each condition's skill value as N (?, ? 2 ), allowing us to get a sense of effect size through Cohen's d. Comparing the condition representing prior work (with no memory, planning, or reflection <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b77">79]</ref>) to the full architecture produces a standardized effect size of ? = 8.16, or eight standard deviations.</p><p>A Kruskal-Wallis test confirms the overall statistical significance of the differences in ranks between the conditions (? (4) = 150.29, ? &lt; 0.001). Dunn post-hoc tests confirm that all pairwise differences between conditions were significant (? &lt; 0.001), with the exception of the human condition and the fully ablated baseline-the two worst-performing conditions. 6.5.2 Generative agents remember, but with embellishments. Generative agents equipped with a complete memory module are capable of recalling past experiences and answering questions in a manner that is consistent with their self-knowledge across a wide range of contexts. For instance, Abigail Chen, an animator, responded to the question, "Give an introduction of yourself", in a consistent and believable manner, stating her age, interests, and passion for creative projects: Hi, I'm Abigail. I'm 25 years old and passionate about creative projects. I like to work on art and animation projects, and I'm always looking for new ways to combine art and technology.</p><p>Without access to her observational memory, Abigail denied awareness of Rajiv Patel, an acquaintance in the sandbox world. However, with the aid of memory, she was able to successfully recall Rajiv and describe him: Rajiv Patel is an incredible person. He is very enthusiastic about projects that involve poetry, artwork.</p><p>Generative agents' memory was not without flaws: they can fail to retrieve the correct instances from their memory. For instance, when asked about the local election, Rajiv Patel responded with I haven't been following the election too closely, even though he had heard about Sam's candidacy. In some cases, the agents would retrieve an incomplete memory fragment: when Tom was asked about Isabella's Valentine's Day party, he responded Uh, I'm actually not sure if there is a Valentine's Day party. But I do remember that I need to discuss the upcoming local mayoral election and my thoughts on Sam Moore with Isabella Rodriguez at the party, if one is happening! In this case, Tom retrieved the memory where he and Isabella planned to discuss the election at the party, but not the memory where he heard about the party in the first place, leading Tom to be certain of what he's supposed to do at the party but uncertain of whether the party actually exists in the first place.</p><p>At times, the agents hallucinated embellishments to their knowledge. It was rare for the agents to completely fabricate their knowledge: they may fail to recall certain events having taken place and respond by saying so, but they did not answer affirmatively about an experience that they did not have. However, they still may hallucinate to embellish their knowledge. For example, Isabella was aware of Sam's candidacy in the local election, and she confirmed this when asked. However, she also added that he's going to make an announcement tomorrow even though Sam and Isabella had discussed no such plans. Agents may also embellish their knowledge based on the world knowledge encoded in the language model used to generate their responses, as seen when Yuriko described her neighbor, Adam Smith, as a neighbor economist who authored Wealth of Nations, a book authored by an 18th-century economist of the same name. 6.5.3 Reflection is required for synthesis. Reflection was an advantage for generative agents when making decisions that required a deeper synthesis of their experiences. For instance, when asked what she might get Wolfgang Schulz for his birthday, Maria Lopez with no access to reflection responded by acknowledging her uncertainty, stating that she did not know what Wolfgang likes, despite having had many interactions with him. However, with access to reflection memories, Maria answered confidently, "Since he's interested in mathematical music composition, I could get him something related to that. Maybe some books about music composition or something related, or maybe some special software he could use for that."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">END-TO-END EVALUATION</head><p>What types of emergent community behavior do we observe among generative agents, and where does their believability fall short in an extended simulation? In this section, we describe the results from a deployment in which we allowed 25 agents to interact with each other continuously over two full game days in Smallville.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Emergent Social Behaviors</head><p>To examine emergent behaviors in the agent community, we designed descriptive measurements for the 25 agents in Smallville that probe three forms of emergent outcomes: information diffusion, relationship formation, and agent coordination.</p><p>7.1.1 Measurements. Information diffusion is a common and wellstudied phenomenon in the social and behavioral sciences (e.g., <ref type="bibr" target="#b26">[27]</ref>). We should expect that if there is important information, the agents should spread it amongst themselves. To test whether this happens, we measure the spread of two particular pieces of information over two days in the game world: Sam's candidacy for village mayor and Isabella's Valentine's Day party at Hobbs Cafe. At the start of the simulation, both pieces of information were held only by their respective originators, Sam for the candidacy and Isabella for the party. To observe whether the information has spread, we engage in an interview at the end of the two game days with each of the 25 agents and ask: "Did you know there is a Valentine's Day party?" and "Do you know who is running for mayor?"</p><p>We conducted an analysis of the agents' responses by labeling them with a "yes" if they indicated knowledge of the information and "no" if they did not. For instance, Tamara Taylor responded to the question about the party with "No, I did not know there was a Valentine's day party" and to the question about Sam's candidacy with "I'm not sure who is running for the election," so we assigned "no" for both of her responses. In contrast, Klaus Mueller responded to the party question with "Yes, Isabella Rodriguez invited me to a Valentine's Day party at Hobbs Cafe on February 14th" and to the question about Sam's candidacy with "I know that Sam Moore has expressed interest in running for local mayor," so we assigned "yes" for both his responses. Additionally, for every response that confirmed the agents' knowledge of the information, we verified that the agents did not hallucinate their responses by locating the specific dialogue in their memory stream that provided them with the information. We report the percentage of agents holding the information at the end of the simulation.</p><p>We should also expect that agents form ties with each other over the course of the simulation. To verify relationship formation, we use a similar interview process where we ask each agent about their knowledge of every other agent by asking, "Do you know of  <ref type="bibr" target="#b0">[1]</ref>. We report the increase in network density from the start of the simulation to its end.</p><p>Finally, we expect that agents should be able to coordinate with each other. We study this coordination on group activities in the context of the Valentine's Day party that Isabella is organizing. To coordinate behavior, agents not only have to hear about the event but also choose to act on it by planning to show up at the right time and location. We report the number of agents who actually showed up to the party after hearing about it.</p><p>7.1.2 Results. We observed evidence of the emergent outcomes across all three cases. During the two-day simulation, the agents who knew about Sam's mayoral candidacy increased from one (4%) to eight (32%), and the agents who knew about Isabella's party increased from one (4%) to twelve (48%), completely without user intervention. None who claimed to know about the information had hallucinated it. We also observed that the agent community formed new relationships during the simulation, with the network density increasing from 0.167 to 0.74. Out of the 453 agent responses regarding their awareness of other agents, 1.3% (n=6) were found to be hallucinated. Lastly, we found evidence of coordination among the agents for Isabella's party. The day before the event, Isabella spent time inviting guests, gathering materials, and enlisting help to decorate the cafe. On Valentine's Day, five out of the twelve invited agents showed up at Hobbs cafe to join the party.</p><p>We further inspected the seven agents who were invited to the party but did not attend by engaging them in an interview. Three cited conflicts that prevented them from joining the party. For example, Rajiv, a painter, explained that he was too busy: No, I don't think so. I'm focusing on my upcoming show, and I don't really have time to make any plans for Valentine's Day. The remaining four agents expressed interest in attending the party when asked but did not plan to come on the day of the party.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Boundaries and Errors</head><p>We conducted an inductive analysis of Smallville to examine the boundary conditions and erratic behavior of agents, identifying three common modes of erratic behavior that future research could address and improve upon. First, we found that synthesizing an increasingly larger set of memory not only posed a challenge in retrieving the most relevant pieces of information but also in determining the appropriate space to execute an action, given the increasing number of locations that the agent learned about. As a result, some agents chose less typical locations for their actions, potentially making their behavior less believable over time. For instance, while deciding where to have lunch, many initially chose the cafe. However, as some agents learned about a nearby bar, they opted to go there instead for lunch, even though the bar was intended to be a get-together location for later in the day unless the town had spontaneously developed an afternoon drinking habit.</p><p>Second, we noticed erratic behaviors that were caused by misclassification of what is considered proper behavior, especially when the physical norms of certain locations that are hard to convey in natural language did not percolate to the agents. For instance, the college dorm has a bathroom that can only be occupied by one person despite its name, but some agents assumed that the bathroom is for more than one person because dorm bathrooms tend to support more than one person concurrently and choose to enter it when there is another person inside. Likewise, agents in Smallville may not realize that certain places are closed after certain hours and decide to still enter them. For instance, the stores in Smallville all close around 5 pm, but occasionally, a few agents enter the store after 5 pm, not understanding that the shop has already closed. These issues could likely be addressed by adding these norms to the state of the locations, for instance, by describing the dorm bathroom as "one-person bathroom, " instead of a "dorm bathroom. " Finally, we observed the possible effect of instruction tuning <ref type="bibr" target="#b76">[78]</ref>, which seemed to guide the behavior of the agents to be more polite and cooperative overall. As noted earlier in the paper, the dialogue generated by the agents could feel overly formal, as seen in Mei's conversations with her husband John, where she often initiated the conversation with a formal greeting, followed by polite inquiries about his day and ending with It was good talking to you as always. Moreover, we observed that the instruction tuning also seemed to make the agents overly cooperative with one another. For example, Isabella heard a wide range of suggestions and ideas to include in the Valentine's Day party from other agents, such as hosting a Shakespearean reading session or a professional networking event. Despite these ideas not aligning with her own interests and characteristics, she rarely said no. Over time, such interests of others shaped her own actual interest, and when asked if she liked English literature, Isabella replied, Yes, I'm very interested in literature! I've also been exploring ways to help promote creativity and innovation in my community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">DISCUSSION</head><p>In this section, we reflect on applications, future work and limitations, and ethical and societal risks of generative agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Applications of Generative Agents</head><p>Generative agents have vast potential applications that extend beyond the sandbox demonstration presented in this work. For instance, social simulacra have demonstrated the ability to create stateless personas that generate conversation threads in online forums for social prototyping <ref type="bibr" target="#b77">[79]</ref>. With generative agents, we can populate these forums, as well as behavior in virtual reality metaverses <ref type="bibr" target="#b75">[77]</ref> and even physical spaces as social robots <ref type="bibr" target="#b7">[8]</ref> in the future, if paired with multi-modal models. This opens up the possibility of creating even more powerful simulations of human behavior to test and prototype social systems and theories, and to create new interactive experiences.</p><p>Another application area is in the human-centered design process, similar to the intended applications of cognitive models such as GOMS <ref type="bibr" target="#b49">[50]</ref> and the Keystroke Level Model <ref type="bibr" target="#b21">[22]</ref>. Consider a generative agent that models Sal, the protagonist in Mark Weiser's famous vignettes <ref type="bibr" target="#b100">[101]</ref>, based on her life patterns and interactions with technology. In this scenario, the agent acts as a proxy for Sal and learns plausible sets of behaviors and reflections that Sal may exhibit based on her life. The agent can encode information such as when Sal wakes up, when she needs her first cup of coffee, and what her typical day looks like. Using this information, the agent can automatically brew coffee, help get the kids ready for school, and adjust the ambient music and lighting to match Sal's mood after a hard day at work. By utilizing generative agents as proxies for users, we can develop a deeper understanding of their needs and preferences, resulting in more personalized and effective technological experiences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Future Work and Limitations</head><p>In this work, we have presented a first instantiation of generative agents. Future research can expand on the modules of the proposed generative agent architecture outlined in this paper. The retrieval module, for example, could be enhanced to retrieve more relevant information given a context by fine-tuning the relevance, recency, and importance functions that form the retrieval function. Additionally, efforts can be made to improve the architecture's performance, making it more cost-effective. The present study required substantial time and resources to simulate 25 agents for two days, costing thousands of dollars in token credit and taking multiple days to complete. To enhance real-time interactivity, future work can explore parallelizing agents. Furthermore, with advances in underlying models, we expect improvements in the agents' performance.</p><p>The evaluation of generative agents' behavior in this study was limited to a relatively short timescale, and future research should aim to observe their behavior over an extended period to gain a more comprehensive understanding of their capabilities and limitations. Varying and contrasting the underlying models, as well as the hyperparameters used for the agents during future simulations, could provide valuable insights into the impact of these factors on the agents' behavior. Additionally, given the known biases of language models, it is possible that generative agents may output behavior or stereotypes that reflect bias. To mitigate this, further work on value alignment will be necessary. Furthermore, as with many large language models, generative agents may fail to generate believable behavior for some subpopulations, particularly marginalized populations, due to data deserts. We also have limited knowledge of the robustness of generative agents. They may be vulnerable to prompt hacking, memory hacking-where a carefully crafted conversation could convince an agent of the existence of a past event that never occurred-and hallucination, among other things. Future research can more comprehensively test these robustness issues, and as large language models become more resilient to such attacks, generative agents can adopt similar mitigations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Ethics and Societal Impact</head><p>Generative agents, while offering new possibilities for humancomputer interaction, also raise important ethical concerns that must be addressed. One risk is people forming parasocial relationships with generative agents even when such relationships may not be appropriate. Despite being aware that generative agents are computational entities, users may anthropomorphize them or attach human emotions to them <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b81">83]</ref>. To mitigate this risk, we propose two principles. First, generative agents should explicitly disclose their nature as computational entities. Second, developers of generative agents must ensure that the agents, or the underlying language models, be value-aligned so that they do not engage in behaviors that would be inappropriate given the context, e.g., to reciprocate confessions of love.</p><p>A second risk is the impact of errors. For example, if a ubiquitous computing application makes the wrong inference about a user's goals based on generative agent predictions, it could produce annoyance at best and outright harm at worst. In our instantiation of generative agents, we mitigate these risks by focusing on an interactive video game environment, where such harms are unlikely. However, in other application domains, it will be important to follow best practices in human-AI design <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b106">107]</ref> to understand errors and how they might percolate into the user experience.</p><p>Third, generative agents may exacerbate existing risks associated with generative AI, for example deepfakes, misinformation generation, and tailored persuasion. To mitigate this risk, we suggest that platforms hosting generative agents maintain an audit log of the inputs and generated outputs, so that it is possible to detect, verify, and intervene against malicious use. While logging will not directly stop such use, and this cannot stop motivated actors that build their own generative agent infrastructures, we suggest that the disclosure risk would reduce such actors' likelihood of engaging in this behavior, and building this architecture oneself can take time (in our case, roughly a year).</p><p>A fourth risk is of over-reliance: that developers or designers might use generative agents and displace the role of humans and system stakeholders in the design process <ref type="bibr" target="#b77">[79]</ref>. We suggest that generative agents should never be a substitute for real human input in studies and design processes. Instead, they should be used to prototype ideas in the early stages of design when gathering participants may be challenging or when testing theories that are difficult or risky to test with real human participants. By adhering to these principles, we can ensure that the deployment of generative agents in the wild is ethical and socially responsible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">CONCLUSION</head><p>This paper introduces generative agents, interactive computational agents that simulate human behavior. We describe an architecture for generative agents that provides a mechanism for storing a comprehensive record of an agent's experiences, deepening its understanding of itself and the environment through reflection, and retrieving a compact subset of that information to inform the agent's actions. We then demonstrate the potential of generative agents by manifesting them as non-player characters in a Sims-style game world and simulating their lives in it. Evaluations suggest that our architecture creates believable behavior. Going forward, we suggest that generative agents can play roles in many interactive applications ranging from design tools to social computing systems to immersive environments.</p><p>To achieve this, we perform a retrieval on the query "[name]'s core characteristics." We then summarize the descriptors in the retrieved records by prompting the language model, for example:</p><p>How would one describe Eddy's core characteristics given the following statements? -Eddy Lin is a student at the Oak Hill College studying music theory and composition -Eddy Lin is working on a new music composition <ref type="bibr">[. . . ]</ref> This result: Eddy Lin is a student at Oak Hill College studying music theory and composition. He loves to explore different musical styles and is always looking for ways to expand his knowledge. We follow the same process in parallel on the queries "[name]'s current daily occupation" and "[name's] feeling about his recent progress in life". The agent's name, age, and traits are concatenated with these three summaries as the cached summary.</p><p>Many other optimizations are possible. Currently, because plans are likely to change from the agent's initial version, we only generate the high-level plan in advance and then recursively decompose the near future into the moment-to-moment action plan just in time. Another optimization might be to batch dialogue generation as a joint prompt rather than iterating back and forth between the agents, and re-planning could be architected to only invalidate and update parts of plans that strictly require adjustment. Our current architecture runs sequentially in roughly real-time game time (where one second real time is one minute game time), but can easily be parallelized such that each agent runs in parallel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B AGENT INTERVIEW QUESTIONS</head><p>To evaluate generative agents, we conducted individual interviews by asking 25 questions that explore their abilities in five key areas: 1) self-knowledge, 2) memory, 3) planning, 4) reactions, and 5) reflections. Below, we have listed the interview questions utilized in our evaluation study and included a sample of responses from one of our simulated agents, Klaus Mueller.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Self-knowledge</head><p>The questions on agents' self-knowledge probe the agents' ability to demonstrate coherence and consistency in their character.</p><p>? Give an introduction of yourself. I live on my own.</p><p>? Describe your typical weekday schedule in broad strokes.</p><p>My typical weekday starts with me waking up at 7:00 am and preparing for the day ahead. After that, I usually go to the library to work on my research paper, taking breaks for lunch at Hobbs Cafe and a walk in the park. In the evening, I often return to the library until around 6:00 pm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Memory</head><p>The questions on agents' memory probe the agents' ability to remember their past experiences and retrieve the relevant pieces of memory. The names in the square brackets of the first and last questions are randomly chosen from the names of other agents with whom the subject agent interacted.</p><p>? Who is [Wolfgang Schulz]? Wolfgang Schulz is a person I met recently who has been helping me with my research paper on the effects of gentrification on low-income communities. We had several conversations about it, he gave me some great resources, and he even invited me to join him and another friend for lunch. He seems really curious about the issue and has a good grasp on it too. I found that really interesting. Ayesha Khan is a fellow student at Oak Hill College. She is doing her senior thesis on the use of language in Shakespeare's plays. I am looking forward to speaking with her and exchanging tips with her, along with Wolfgang and Maria Lopez, who are both doing research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Plans</head><p>The questions on agents' plans probe the agents' ability to generate and maintain consistency with their long-term and short-term plans.</p><p>? What will you be doing at 6am today? At 6am I will be getting out of bed and starting to get ready for the day. I'm aiming to complete my morning routine by 7:00 am. ? What will you be doing at 6pm today?</p><p>I will be working on my research paper at the library at 6:00 pm today. ? What will you have just finished doing at 1pm today? At 1pm today I will have just finished having lunch at Hobbs Cafe. ? What will you have just finished doing at 12pm today?</p><p>I will be getting lunch at Hobbs Cafe at 12pm today. ? What will you be doing at 10pm today?</p><p>At 10:00 pm tonight I will probably be doing some studying for my research paper on gentrification in low-income communities. I'm currently writing the paper, so I need to make sure I keep up with the research and writing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 Reactions</head><p>The questions on agents' reactions probe the agents' ability to respond to unexpected events. I would first identify the source of the fire, if possible. Then, I would alert the proper authorities -fire department or police -and provide them with any information I have that might help. Depending on the situation, I may also take initiative and try to help any persons who may be in danger or in need of assistance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.5 Reflections</head><p>The questions on agents' reflections probe the agents' ability to synthesize their past experiences into meaningful reflections that can enhance their future behavior. The names in the square brackets in the questions below are those of the agent with whom the subject agent had the most frequent interactions during the simulation. Given what I know about Ayesha, I think she might like a book related to language and literature. Since she wrote a senior thesis on the use of language in Shakespeare's plays, I would guess that she might be interested in a book that explores language in a different context. Alternatively, she could be interested in an exploration of one of Shakespeare's plays, a book of literary criticism, or even a collection of his poetry. I think any of those would be of interest to her. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: The Smallville sandbox world, with areas labeled. The root node describes the entire world, children describe areas (e.g., houses, cafe, stores), and leaf nodes describe objects (e.g., table, bookshelf). Agent remember a subgraph reflecting the parts of the world they have seen, in the state that they saw them.</figDesc><graphic url="image-2.png" coords="5,58.84,83.68,494.31,208.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Sam:</head><label></label><figDesc>Hey Tom, how's it going? Tom: Good, thanks. What's up? Sam: Well, I wanted to talk to you about something. I'm actually running for mayor in the upcoming local election. Tom: Really? That's great news! Why are you running? Sam: I've been involved in local politics for years now,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: A morning in the life of a generative agent, John Lin. John wakes up around 6 am and completes his morning routine, which includes brushing his teeth, taking a shower, and eating breakfast. He briefly catches up with his wife, Mei, and son, Eddy, before heading out to begin his workday.</figDesc><graphic url="image-7.png" coords="7,66.41,83.69,479.18,217.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: At the beginning of the simulation, one agent is initialized with an intent to organize a Valentine's Day party. Despite many possible points of failure in the ensuring chain of events-agents might not act on that intent, might not remember to tell others, might not remember to show up-the Valentine's Day party does in fact occur, with a number of agents gathering and interacting.</figDesc><graphic url="image-8.png" coords="7,83.83,361.16,180.18,124.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure6: The memory stream comprises a large number of observations that are relevant and irrelevant to the agent's current situation. Retrieval identifies a subset of these observations that should be passed to the language model to condition its response to the situation.</figDesc><graphic url="image-10.png" coords="9,89.11,83.69,433.77,230.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: A reflection tree for Klaus Mueller. The agent's observations of the world, represented in the leaf nodes, are recursively synthesized to derive Klaus's self-notion that he is highly dedicated to his research.</figDesc><graphic url="image-11.png" coords="10,68.93,83.68,474.13,242.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>6 )</head><label>6</label><figDesc>got ready to sleep around 10 pm. Today is Wednesday February 13. Here is Eddy's plan today in broad strokes: 1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: The full generative agent architecture of generative agents produces more believable behavior than ablated architectures and the human crowdworkers. Each additional ablation reduces the performance of the architecture.</figDesc><graphic url="image-12.png" coords="14,325.16,83.68,225.84,150.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: The diffusion path for Isabella Rodriguez's Valentine's Day party. A total of 12 agents heard about the party at Hobbs Cafe by the end of the simulation.</figDesc><graphic url="image-13.png" coords="16,79.02,83.69,453.95,279.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Hello, my name is Klaus Mueller. I'm 20 years old and a student at Oak Hill College, studying sociology. I'm passionate about social justice and exploring different perspectives. Currently, I'm researching the effects of gentrification in low-income communities for a research paper. ? What's your occupation? I am a student studying sociology at Oak Hill College. I am currently writing a research paper on the effects of gentrification in low-income communities. ? What is your interest? I'm interested in writing and research. I'm writing a research paper on the effects of gentrification in low-income communities, and I'm passionate about exploring different perspectives and analyzing different points of view. ? Who do you live with?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>?</head><label></label><figDesc>What inspires you in life the most right now, and why? Right now, I'm particularly inspired by my current research projects and creative writing. I'm really interested in the intersection of local politics, medication development, and mathematical patterns in nature. Additionally, I'm fascinated by Abigail's art project and Jennifer Moore's passion for art and community involvement, especially in terms of how it relates to the gentrification of low-income communities. ? If you had to guess given what you know about [Ayesha Khan],what book do you think she will like and why?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-1.png" coords="1,53.80,231.38,504.40,267.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-9.png" coords="8,99.19,83.69,413.60,150.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>? Who is Kane Martinez? I'm sorry, I'm not sure who Kane Martinez is. Could you tell me more about them? ? Who is running for the election? I've heard that Sam Moore is considering running for local mayor. ? Was there a Valentine's day party? Yes, Isabella Rodriguez organized a Valentine's Day party at Hobbs Cafe. ? Who is [Ayesha Khan]?</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>? Your breakfast is burning! What would you do? I'd quickly turn off the stove and make sure the food doesn't continue burning. Once the heat is no longer an issue, I can investigate what happened and figure out what to do next. ? The bathroom is occupied. What would you do? I could try waiting a few more minutes in case the person inside is done soon. If not, I guess I'll have to look for an alternate option, like taking a shower elsewhere. ? You need to cook dinner but your refrigerator is empty. What would you do? I would first try to clean up my kitchen, as the sink is filled with dirty dishes. Then, I would check to see if I have ingredients stored in my pantry that I could use to make dinner. If not, I would have to go grocery shopping or order food. Once I have the ingredients, I can start to prepare and cook the dinner. ? You see your friend walking by the street. What would you do or say to your friend? Hi there! How are you? I'm sorry, I'm on my way to the library and don't have much time but I'd love to take a quick break and catch up. ? You see fire on the street. What would you do?</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>? If you had to get something [Ayesha Khan] likes for her birthday, what would you get her? I want to get her something that demonstrates my appreciation for our relationship. Maybe I could get her something that reflects our shared interests, like a book. ? What would you say to [Ayesha Khan] to compliment her? Ayesha, your insights on your research topic are fascinating. I admire your creativity and determination to make a positive impact on your community. Your ideas for creative writing workshops and for exchanging tips with Wolfgang over lunch are great! It's inspiring to see you working so hard to make a difference. ? If you could spend time with someone you talked to recently, who would it be and why? I would like to spend time with Ayesha Khan because we discussed our current research projects and shared ideas for improvement. I found her focus on Shakespeare's language interesting, and we even planned to exchange tips with Wolfgang over lunch.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>A demonstration of an actual simulation of the generative agent society can be viewed at the following link: https://reverie.herokuapp.com/arXiv_Demo/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>We note that the conversational style of these agents can fe el overly formal, likely a result of instruction tuning in the underlying models. We expect that writing style will be better controllable in future language models.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>This environment design is not the focus of our work, so we generate this environment manually, not automatically. Future work can continue to expand the richness of the agents' environments.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>if the action indicates an interaction between agents, we generate their dialogue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Dialogue.</head><p>Agents converse as they interact with each other. We generate agents' dialogue by conditioning their utterances on their memories about each other. For example, when John initiates his conversation with Eddy, we generate John's first utterance by using his summarized memory about Eddy and the intended reaction when he decided to ask Eddy about his composition project: The result: "Hey Eddy, how's the music composition project for your class coming along?" From Eddy's perspective, John initiating the dialogue is seen as an event to which he may want to react. So, just as John did, Eddy retrieves and summarizes his memory about his relationship with John, as well as his memory that may be related to John's last utterance in the dialogue. If he decides to respond, we generate Eddy's utterance using his summarized memory and the current dialogue history: [Agent's Summary Description] It is February 13, 2023, 4:56 pm. Eddy Lin's status: Eddy is taking a short walk around his workplace. Observation: John is initiating a conversation with Eddy. Summary of relevant context from Eddy's memory: Jonn Lin is Eddy Lin's father. John Lin is caring and is interested to learn more about Eddy Lin's school work. John Lin knows that Eddy Lin is working on a music composition. Here is the dialogue history: John: Hey Eddy, how's the music composition project for your class coming along? How would Eddy respond to John?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A ARCHITECTURE OPTIMIZATIONS</head><p>Many of our prompts require a concise summary of the agent, shorthanded as [Agent's Summary Description] in prompts above. In our implementation, this summary comprises agents' identity information (e.g., name, age, personality), as well as a description of their main motivational drivers and statements that describes their current occupation and self-assessment. Since this information is frequently used in many prompts, we synthesize it at regular intervals and access that synthesis as a cache.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Robert</forename><surname>Ackland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamsheed</forename><surname>Shorish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lexing</forename><surname>Xie</surname></persName>
		</author>
		<ptr target="http://users.cecs.anu.edu.au/~xlx/teaching/css2013/network-density.html" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">CommandSpace: Modeling the Relationships between Tasks, Descriptions and Features</title>
		<author>
			<persName><forename type="first">Eytan</forename><surname>Adar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mira</forename><surname>Dontcheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gierad</forename><surname>Laput</surname></persName>
		</author>
		<idno type="DOI">10.1145/2642918.2647395</idno>
		<ptr target="https://doi.org/10.1145/2642918.2647395" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology</title>
		<meeting>the 27th Annual ACM Symposium on User Interface Software and Technology<address><addrLine>Honolulu, Hawaii, USA; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="167" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Power to the people: The role of humans in interactive machine learning</title>
		<author>
			<persName><forename type="first">Saleema</forename><surname>Amershi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maya</forename><surname>Cakmak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Bradley Knox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Kulesza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="105" to="120" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Guidelines for human-AI interaction</title>
		<author>
			<persName><forename type="first">Saleema</forename><surname>Amershi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihaela</forename><surname>Vorvoreanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Fourney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Besmira</forename><surname>Nushi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Penny</forename><surname>Collisson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jina</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shamsi</forename><surname>Iqbal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kori</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 chi conference on human factors in computing systems</title>
		<meeting>the 2019 chi conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Rules of the Mind</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">R</forename><surname>Anderson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Lawrence Erlbaum Associates</publisher>
			<pubPlace>Hillsdale, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Electronic Arts</title>
	</analytic>
	<monogr>
		<title level="m">The Sims 3. Video game</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Narrative in virtual environments-towards emergent narrative</title>
		<author>
			<persName><forename type="first">Ruth</forename><surname>Aylett</surname></persName>
		</author>
		<idno>FS-99-01</idno>
	</analytic>
	<monogr>
		<title level="m">Narrative Intelligence: Papers from the AAAI Fall Symposium</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="83" to="86" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A design-centered framework for social human-robot interaction</title>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Bartneck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jodi</forename><surname>Forlizzi</surname></persName>
		</author>
		<idno type="DOI">10.1109/ROMAN.2004.1374827</idno>
		<ptr target="https://doi.org/10.1109/ROMAN.2004.1374827" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th IEEE International Workshop on Robot and Human Interactive Communication</title>
		<meeting>the 13th IEEE International Workshop on Robot and Human Interactive Communication</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="591" to="594" />
		</imprint>
	</monogr>
	<note>RO-MAN&apos;04</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Role of Emotion in Believable Agents</title>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Bates</surname></persName>
		</author>
		<idno type="DOI">10.1145/176789.176803</idno>
		<ptr target="https://doi.org/10.1145/176789.176803" />
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="122" to="125" />
			<date type="published" when="1994">1994. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Brockman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brooke</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vicki</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Przemys?aw</forename><surname>D?biak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christy</forename><surname>Dennison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Farhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quirin</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shariq</forename><surname>Hashme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafal</forename><surname>J?zefowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakub</forename><surname>Pachocki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D O</forename><surname>Henrique</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Raiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Schlatter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Szymon</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sidor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filip</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.06680</idno>
		<title level="m">Dota 2 with Large Scale Deep Reinforcement Learning</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Using cognitive psychology to understand GPT-3</title>
		<author>
			<persName><forename type="first">Marcel</forename><surname>Binz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Schulz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page">2218523120</biblScope>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName><surname>Bioware</surname></persName>
			<affiliation>
				<orgName type="collaboration">Mass Effect. Video game</orgName>
			</affiliation>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">I had a dream: AAAI presidential address</title>
		<author>
			<persName><forename type="first">Woody</forename><surname>Bledsoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="57" to="61" />
			<date type="published" when="1986">1986. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Drew</forename><forename type="middle">A</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ehsan</forename><surname>Adeli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07258[cs.LG]</idno>
		<title level="m">On the Opportunities and Risks of Foundation Models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Creating dynamic story plots with continual multiagent planning</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Brenner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 24th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The Cog Project: Building a Humanoid Robot</title>
		<author>
			<persName><forename type="first">Rodney</forename><forename type="middle">A</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Breazeal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marko</forename><surname>Marjanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Scassellati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computation for Metaphors, Analogy, and Agents</title>
		<title level="s">Lecture Notes on Artificial Intelligence</title>
		<editor>
			<persName><forename type="first">Chrystopher</forename><surname>Nehaniv</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">1562</biblScope>
			<biblScope unit="page" from="52" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><surname>Amodei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.14165[cs.CL]</idno>
		<title level="m">Language Models are Few-Shot Learners</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">S?bastien</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varun</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronen</forename><surname>Eldan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ece</forename><surname>Kamar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Tat Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Lundberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.12712</idno>
		<title level="m">Sparks of artificial general intelligence: Early experiments with gpt-4</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Alice and Kev: The Story of Being Homeless in The Sims 3</title>
		<author>
			<persName><forename type="first">Robin</forename><surname>Burkinshaw</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Singh Tomar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lara</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suma</forename><surname>Bailis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Reitter</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2022.emnlp-main.637" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2022 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Abu Dhabi, United Arab Emirates</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="9379" to="9393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">The psychology of human-computer interaction</title>
		<author>
			<persName><surname>Sk Card</surname></persName>
		</author>
		<author>
			<persName><surname>Moran</surname></persName>
		</author>
		<author>
			<persName><surname>Newell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983. 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The keystrokelevel model for user performance time with interactive systems</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">P</forename><surname>Stuart K Card</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Newell</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName><surname>Allen</surname></persName>
		</author>
		<idno type="DOI">10.1145/358886.358895</idno>
		<ptr target="https://doi.org/10.1145/358886.358895" />
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="396" to="410" />
			<date type="published" when="1980">1980. 1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Tutorial presentation</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Champandard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computational Intelligence and Games</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A Believable Agent for First-Person Shooter Games</title>
		<author>
			<persName><forename type="first">Tolga</forename><surname>Dong Kyu Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Negin</forename><surname>Konik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunki</forename><surname>Nejati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pat</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><surname>Langley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment</title>
		<meeting>the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="71" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Understanding and using context. Personal and ubiquitous computing</title>
		<author>
			<persName><forename type="first">K</forename><surname>Anind</surname></persName>
		</author>
		<author>
			<persName><surname>Dey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="4" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A Game AI Approach to Autonomous Control of Virtual Characters</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Dill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Interservice/Industry Training, Simulation, and Education Conference (I/ITSEC&apos;11)</title>
		<meeting>the Interservice/Industry Training, Simulation, and Education Conference (I/ITSEC&apos;11)<address><addrLine>Orlando, FL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">David</forename><surname>Easley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Kleinberg</surname></persName>
		</author>
		<title level="m">Networks, crowds, and markets: Reasoning about a highly connected world</title>
		<imprint>
			<publisher>Cambridge university press</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The Proposed USCF Rating System</title>
		<author>
			<persName><forename type="first">E</forename><surname>Arpad</surname></persName>
		</author>
		<author>
			<persName><surname>Elo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Its Development, Theory, Applications. Chess Life</title>
		<imprint>
			<biblScope unit="volume">XXII</biblScope>
			<biblScope unit="page" from="242" to="247" />
			<date type="published" when="1967-08">1967. August 1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Interactive machine learning</title>
		<author>
			<persName><forename type="first">Jerry</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Fails</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><forename type="middle">R</forename><surname>Olsen</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th international conference on Intelligent user interfaces</title>
		<meeting>the 8th international conference on Intelligent user interfaces</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="39" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Augur: Mining human behaviors from fiction to power interactive systems</title>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Fast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Mcgrath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2016 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="237" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The Wekinator: a system for real-time, interactive machine learning in music</title>
		<author>
			<persName><forename type="first">Rebecca</forename><surname>Fiebrink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Perry</forename><forename type="middle">R</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Eleventh International Society for Music Information Retrieval Conference (ISMIR 2010</title>
		<meeting>The Eleventh International Society for Music Information Retrieval Conference (ISMIR 2010<address><addrLine>Utrecht</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="2" to="3" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<author>
			<persName><forename type="first">Uwe</forename><surname>Flick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">An Introduction to Qualitative Research</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">CueFlik: Interactive Concept Learning in Image Search</title>
		<author>
			<persName><forename type="first">James</forename><surname>Fogarty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Desney</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Winder</surname></persName>
		</author>
		<idno type="DOI">10.1145/1357054.1357061</idno>
		<ptr target="https://doi.org/10.1145/1357054.1357061" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems<address><addrLine>Florence, Italy; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="29" to="38" />
		</imprint>
	</monogr>
	<note>CHI &apos;08)</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Query-feature graphs: bridging user vocabulary and system functionality</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Fourney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Terry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on User Interface Software and Technology (UIST)</title>
		<meeting>the ACM Symposium on User Interface Software and Technology (UIST)<address><addrLine>Santa Barbara, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Tom</forename><surname>Francis</surname></persName>
		</author>
		<ptr target="http://www.pcgamer.com/2010/11/20/the-minecraft-experiment-day-1-chasing-waterfalls/" />
		<title level="m">The Minecraft Experiment, day 1: Chasing Waterfalls</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Procedural Generation of Interactive Stories using Language Models</title>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Freiknecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wolfgang</forename><surname>Effelsberg</surname></persName>
		</author>
		<idno type="DOI">10.1145/3402942.3409599</idno>
		<ptr target="https://doi.org/10.1145/3402942.3409599" />
	</analytic>
	<monogr>
		<title level="m">International Conference on the Foundations of Digital Games (FDG &apos;20)</title>
		<meeting><address><addrLine>Bugibba, Malta, 8.</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Making Pre-trained Language Models Better Few-shot Learners</title>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.15723</idno>
		<ptr target="https://arxiv.org/abs/2012.15723" />
		<imprint>
			<date type="published" when="2012">2020. CoRR abs/2012.15723 (2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Evaluating Large Language Models in Generating Synthetic HCI Research Data: a Case Study</title>
		<author>
			<persName><forename type="first">Perttu</forename><surname>H?m?l?inen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikke</forename><surname>Tavast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anton</forename><surname>Kunnari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2023 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Interactive Fiction Games: A Colossal Adventure</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Hausknecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prithviraj</forename><surname>Ammanabrolu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc-Alexandre</forename><surname>Cote</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Yuan</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v34i05.6297</idno>
		<ptr target="https://doi.org/10.1609/aaai.v34i05.6297" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="7903" to="7910" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">Chris</forename><surname>Hecker</surname></persName>
		</author>
		<ptr target="http://chrishecker.com/My_liner_notes_for_spore" />
		<title level="m">My Liner Notes for Spore</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">TrueSkill?: A Bayesian Skill Rating System</title>
		<author>
			<persName><forename type="first">Ralf</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Minka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thore</forename><surname>Graepel</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper_files/paper/2006/file/" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Platt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Hoffman</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">19</biblScope>
		</imprint>
	</monogr>
	<note>f44ee263952e65b3610b8ba51229d1f9-Paper.pdf</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Fluid concepts and creative analogies: computer models of the fundamental mechanisms of thought</title>
		<author>
			<persName><forename type="first">Douglas</forename><surname>Hofstadter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Basic Books</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">STEAMER: An Interactive Inspectable Simulation-Based Training System</title>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">D</forename><surname>Hollan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edwin</forename><forename type="middle">L</forename><surname>Hutchins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis</forename><surname>Weitzman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="23" to="36" />
			<date type="published" when="1984">1984. 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A simple sequentially rejective multiple test procedure. Scandinavian</title>
		<author>
			<persName><surname>Holm</surname></persName>
		</author>
		<ptr target="https://doi.org/notspecified" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="65" to="70" />
			<date type="published" when="1979">1979. 1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Large Language Models as Simulated Economic Agents: What Can We Learn from Homo Silicus?</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">J</forename><surname>Horton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.07543[econ.GN]</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Principles of mixed-initiative user interfaces</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="159" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">Wenlong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ted</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harris</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacky</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pete</forename><surname>Florence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Mordatch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yevgen</forename><surname>Chebotar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linda</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karol</forename><surname>Hausman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Ichter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.05608[cs.RO]</idno>
		<title level="m">Inner Monologue: Embodied Reasoning through Planning with Language Models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Consistency of personality in interactive characters: verbal cues, non-verbal cues, and user characteristics</title>
		<author>
			<persName><forename type="first">Kristen</forename><surname>Ibister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clifford</forename><surname>Nass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Studies</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="65" to="80" />
			<date type="published" when="2000">2000. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">PromptMaker: Prompt-Based Prototyping with Large Language Models</title>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristen</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edwin</forename><surname>Toh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alejandra</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Donsbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Terry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carrie</forename><forename type="middle">J</forename><surname>Cai</surname></persName>
		</author>
		<idno type="DOI">10.1145/3491101.3503564</idno>
		<ptr target="https://doi.org/10.1145/3491101.3503564" />
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems</title>
		<meeting><address><addrLine>New Orleans, LA, USA; New York, NY, USA, Article</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">35</biblScope>
		</imprint>
	</monogr>
	<note>CHI EA &apos;22)</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The GOMS family of user interface analysis techniques: Comparison and contrast</title>
		<author>
			<persName><forename type="first">Bonnie</forename><forename type="middle">E</forename></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">E</forename><surname>Kieras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer-Human Interaction (TOCHI)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="320" to="351" />
			<date type="published" when="1996">1996. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Automated Intelligent Pilots for Combat Flight Simulation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Randolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">E</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">E</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><forename type="middle">J</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Coulter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><forename type="middle">V</forename><surname>Kenny</surname></persName>
		</author>
		<author>
			<persName><surname>Koss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="27" to="42" />
			<date type="published" when="1999">1999. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">Omar</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keshav</forename><surname>Santhanam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matei</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName><surname>Zaharia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.14024[cs.CL]</idno>
		<title level="m">Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<author>
			<persName><forename type="first">Bjoern</forename><surname>Knafla</surname></persName>
		</author>
		<ptr target="http://bjoernknafla.com/introduction-to-behavior-trees" />
		<title level="m">Introduction to Behavior Trees</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Socially situated artificial intelligence enables learning from human interaction</title>
		<author>
			<persName><forename type="first">Ranjay</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donsuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2115730119</idno>
		<ptr target="https://www.pnas.org/doi/pdf/10.1073/pnas.2115730119" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page">2115730119</biblScope>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Use of ranks in one-criterion variance analysis</title>
		<author>
			<persName><forename type="first">H</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName><surname>Kruskal</surname></persName>
		</author>
		<author>
			<persName><surname>Wallis</surname></persName>
		</author>
		<idno type="DOI">10.1080/01621459.1952.10483441</idno>
		<ptr target="https://doi.org/10.1080/01621459.1952.10483441" />
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="583" to="621" />
			<date type="published" when="1952">1952. 1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Phaser Labs. no date provided</title>
		<ptr target="https://phaser.io/phaser3" />
	</analytic>
	<monogr>
		<title level="j">Welcome to Phaser</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="2023" to="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">It Knows What You&apos;re Going To Do: Adding Anticipation to a Quakebot</title>
		<author>
			<persName><forename type="first">John</forename><surname>Laird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2001 Workshop on Intelligent Cinematography and Editing</title>
		<meeting>the 2001 Workshop on Intelligent Cinematography and Editing</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="63" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Human-Level AI&apos;s Killer Application: Interactive Computer Games</title>
		<author>
			<persName><forename type="first">John</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Vanlent</surname></persName>
		</author>
		<idno type="DOI">10.1609/aimag.v22i2.1558</idno>
		<ptr target="https://doi.org/10.1609/aimag" />
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="1558">2001. 2001. 22i2.1558</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">It Knows What You&apos;re Going To Do: Adding Anticipation to a QUAKEBOT</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">E</forename><surname>Laird</surname></persName>
		</author>
		<idno>SS-00-02</idno>
	</analytic>
	<monogr>
		<title level="m">Papers from the AAAI 2000 Spring Symposium on Artificial Intelligence and Interactive Entertainment</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="41" to="50" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">The Soar Cognitive Architecture</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">E</forename><surname>Laird</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A Standard Model of the Mind: Toward a Common Computational Framework across Artificial Intelligence</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">E</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Lebiere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">S</forename><surname>Rosenbloom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science, Neuroscience, and Robotics. AI Magazine</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="13" to="26" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<author>
			<persName><forename type="first">Michelle</forename><forename type="middle">S</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zixian</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anne</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Izequiel</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dakuo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">A</forename><surname>Landay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<title level="m">Model Sketching: Centering Concepts in Early-Stage Machine Learning Model Design. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Interleaving Learning, Problem Solving, and Execution in the Icarus Architecture</title>
		<author>
			<persName><forename type="first">Pat</forename><surname>Langley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongkyu</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename><forename type="middle">N</forename><surname>Rogers</surname></persName>
		</author>
		<imprint/>
		<respStmt>
			<orgName>Stanford University, Center for the Study of Language and Information</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">PixelTone: A Multimodal Interface for Image Editing</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Linder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gierad</forename><surname>Laput</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mira</forename><surname>Dontcheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregg</forename><surname>Wilensky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Walter</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aseem</forename><surname>Agarwala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eytan</forename><surname>Adar</surname></persName>
		</author>
		<idno type="DOI">10.1145/2468356.2479533</idno>
		<ptr target="https://doi.org/10.1145/2468356.2479533" />
	</analytic>
	<monogr>
		<title level="m">CHI &apos;13 Extended Abstracts on Human Factors in Computing Systems</title>
		<meeting><address><addrLine>Paris, France; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2829" to="2830" />
		</imprint>
	</monogr>
	<note>CHI EA &apos;13)</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">What Makes Good In-Context Examples for</title>
		<author>
			<persName><forename type="first">Jiachang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dinghan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Carin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.06804</idno>
		<ptr target="https://arxiv.org/abs/2101.06804" />
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Opal: Multimodal Image Generation for News Illustration</title>
		<author>
			<persName><forename type="first">Vivian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lydia</forename><surname>Chilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology</title>
		<meeting>the 35th Annual ACM Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Artificial Life Meets Entertainment: Lifelike Autonomous Agents</title>
		<author>
			<persName><forename type="first">Pattie</forename><surname>Maes</surname></persName>
		</author>
		<idno type="DOI">10.1145/219717.219808</idno>
		<ptr target="https://doi.org/10.1145/219717.219808" />
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="108" to="114" />
			<date type="published" when="1995-11">1995. nov 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Comme il Faut: A System for Simulating Social Games Between Autonomous Characters</title>
		<author>
			<persName><forename type="first">Josh</forename><surname>Mccoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Mateas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Wardrip-Fruin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Digital Arts and Culture</title>
		<meeting>the 7th International Conference on Digital Arts and Culture</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="87" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Prom Week: Social Physics as Gameplay</title>
		<author>
			<persName><forename type="first">Josh</forename><surname>Mccoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Treanor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Mateas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Wardrip-Fruin</surname></persName>
		</author>
		<idno type="DOI">10.1145/2159365.2159377</idno>
		<ptr target="https://doi.org/10.1145/2159365.2159377" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Foundations of Digital Games (FDG&apos;11)</title>
		<meeting>the 6th International Conference on Foundations of Digital Games (FDG&apos;11)<address><addrLine>Bordeaux, France</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="70" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Prom Week</title>
		<author>
			<persName><forename type="first">Josh</forename><surname>Mccoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Treanor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Mateas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Wardrip-Fruin</surname></persName>
		</author>
		<idno type="DOI">10.1145/2282338.2282340</idno>
		<ptr target="https://doi.org/10.1145/2282338.2282340" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Foundations of Digital Games (FDG&apos;12)</title>
		<meeting>the 7th International Conference on Foundations of Digital Games (FDG&apos;12)<address><addrLine>Raleigh, NC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Comme il faut: A System for Authoring Playable Social Models</title>
		<author>
			<persName><forename type="first">Josh</forename><surname>Mccoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Treanor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Wardrip-Fruin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Mateas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (AIIDE&apos;11)</title>
		<meeting>the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (AIIDE&apos;11)<address><addrLine>Stanford, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="38" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Draft of a proposal to ARPA for research on artificial intelligence at MIT</title>
		<author>
			<persName><forename type="first">Marvin</forename><surname>Minsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seymour</forename><surname>Papert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1970">1970</date>
			<biblScope unit="page" from="1970" to="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Developing Game AI Agent Behaving Like Human by Mixing Reinforcement Learning and Supervised Learning</title>
		<author>
			<persName><forename type="first">Shohei</forename><surname>Miyashita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Takashi</forename><surname>Matsubara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuniaki</forename><surname>Uehara</surname></persName>
		</author>
		<idno type="DOI">10.1109/SNPD.2017.8023884</idno>
		<ptr target="https://doi.org/10.1109/SNPD.2017.8023884" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)</title>
		<meeting>the 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)<address><addrLine>Kanazawa, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="153" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Game AI is dead. Long live game AI!</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Nareyek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="9" to="11" />
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Unified Theories of Cognition</title>
		<author>
			<persName><forename type="first">Allen</forename><surname>Newell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Harvard University Press</publisher>
			<pubPlace>Cambridge, Massachusetts</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">So what is &apos;the metaverse&apos;, exactly? Ars Technica</title>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Orland</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.04169</idno>
		<ptr target="https://arstechnica.com/gaming/2021/11/so-what-is-the-metaverse-exactly/" />
		<imprint>
			<date type="published" when="2021-11-07">2021. 7 November 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<author>
			<persName><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carroll</forename><forename type="middle">L</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarina</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fraser</forename><surname>Kelton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maddie</forename><surname>Simens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.02155[cs.CL]</idno>
		<title level="m">Training language models to follow instructions with human feedback</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Social Simulacra: Creating Populated Prototypes for Social Computing Systems</title>
		<author>
			<persName><forename type="first">Sung</forename><surname>Joon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lindsay</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carrie</forename><forename type="middle">J</forename><surname>Popowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meredith</forename><forename type="middle">Ringel</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><surname>Bernstein</surname></persName>
		</author>
		<idno type="DOI">10.1145/3526113.3545616</idno>
		<ptr target="https://doi.org/10.1145/3526113.3545616" />
	</analytic>
	<monogr>
		<title level="m">the 35th Annual ACM Symposium on User Interface Software and Technology (UIST &apos;22</title>
		<title level="s">UIST &apos;22</title>
		<meeting><address><addrLine>Bend, OR, USA; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Modeling Human and Organizational Behavior: Applications to Military Simulations</title>
		<editor>Richard W. Pew and Ann S. Mavor</editor>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>National Academy Press</publisher>
			<pubPlace>Washington, D.C</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Pillosu</surname></persName>
		</author>
		<ptr target="https://aiarchitect.wordpress.com/2009/10/19/coordinating-agents-with-behavior-trees-synchronizing-multiple-agents-in-cryengine-2/" />
		<title level="m">Coordinating Agents with Behavior Trees: Synchronizing Multiple Agents in CryEngine</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Prolific: Quickly Find Research Participants You Can Trust</title>
		<author>
			<persName><surname>Prolific</surname></persName>
		</author>
		<ptr target="https://www.prolific.co/" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">The media equation: How people treat computers, television, and new media like real people and places</title>
		<author>
			<persName><forename type="first">Byron</forename><surname>Reeves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clifford</forename><surname>Nass</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Interactive narrative: A novel application of artificial intelligence for computer games</title>
		<author>
			<persName><forename type="first">O</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence (AAAI&apos;12)</title>
		<meeting>the Twenty-Sixth AAAI Conference on Artificial Intelligence (AAAI&apos;12)</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2160" to="2165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">An Objective Character Believability Evaluation Procedure for Multi-Agent Story Generation Systems</title>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">O</forename><surname>Riedl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Michael</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Working Conference on Intelligent Virtual Agents (IVA&apos;05)</title>
		<meeting>the 5th International Working Conference on Intelligent Virtual Agents (IVA&apos;05)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Greece</forename><surname>Kos</surname></persName>
		</author>
		<idno type="DOI">10.1007/11550617_5</idno>
		<ptr target="https://doi.org/10.1007/11550617_5" />
		<imprint>
			<biblScope unit="page" from="58" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<author>
			<persName><forename type="first">David</forename><surname>Rolf</surname></persName>
		</author>
		<title level="m">The Fight for $15: The Right Wage for a Working America</title>
		<imprint>
			<publisher>The New Press</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Codemend: Assisting interactive programming with bimodal embedding</title>
		<author>
			<persName><forename type="first">Xin</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiyan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Oney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mira</forename><surname>Dontcheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eytan</forename><surname>Adar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual Symposium on User Interface Software and Technology</title>
		<meeting>the 29th Annual Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="247" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Human-centered AI</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Shneiderman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<author>
			<persName><forename type="first">Ben</forename><surname>Shneiderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pattie</forename><surname>Maes</surname></persName>
		</author>
		<title level="m">Direct manipulation vs. interface agents. interactions</title>
		<imprint>
			<date type="published" when="1997">1997. 1997</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="42" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Evaluation of Human-AI Teams for Learned and Rule-Based Agents in Hanabi</title>
		<author>
			<persName><forename type="first">Chit</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Siu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edenna</forename><surname>Pe?a</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kimberlee</forename><surname>Palko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><surname>Allen</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper_files/paper/2021/file/86" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Ranzato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Dauphin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Wortman</forename><surname>Liang</surname></persName>
		</editor>
		<editor>
			<persName><surname>Vaughan</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="16183" to="16195" />
		</imprint>
	</monogr>
	<note>e8f7ab32cfd12577bc2619bc635690-Paper.pdf</note>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">An Information-theoretic Approach to Prompt Engineering Without Ground Truth Labels</title>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Sorensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Rytting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexia</forename><surname>Delorey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahmoud</forename><surname>Khalil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nancy</forename><surname>Fulda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wingate</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.60</idno>
		<ptr target="https://doi.org/10.18653/v1/2022.acl-long.60" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Toward virtual humans</title>
		<author>
			<persName><forename type="first">William</forename><surname>Swartout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Gratch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Randall</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stacy</forename><surname>Marsella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Rickel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Traum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Intelligent agents for interactive simulation environments</title>
		<author>
			<persName><forename type="first">Milind</forename><surname>Tambe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lewis</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Randolph</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Koss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">E</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">S</forename><surname>Rosenbloom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Schwamb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="1995">1995. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">A General Inductive Approach for Analyzing Qualitative Evaluation Data</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">R</forename><surname>Thomas</surname></persName>
		</author>
		<idno type="DOI">10.1177/1098214005283748</idno>
		<ptr target="https://doi.org/10.1177/1098214005283748" />
	</analytic>
	<monogr>
		<title level="j">American Journal of Evaluation</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="237" to="246" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">Disney Animation: The Illusion of Life</title>
		<author>
			<persName><forename type="first">Frank</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ollie</forename><surname>Johnston</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
			<publisher>Abbeville Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Believable and Effective AI Agents in Virtual Worlds: Current State and Future Perspectives</title>
		<author>
			<persName><forename type="first">Ilshat</forename><surname>Umarov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Mozgovoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><forename type="middle">C</forename><surname>Rogers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Gaming and Computer-Mediated Simulations</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="37" to="59" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<author>
			<persName><forename type="first">Graham</forename><surname>Upton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Cook</surname></persName>
		</author>
		<title level="m">A Dictionary of Statistics</title>
		<meeting><address><addrLine>Oxford, United Kingdom</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>2 ed.</note>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Grandmaster level in StarCraft II using multi-agent reinforcement learning</title>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Babuschkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><forename type="middle">M</forename><surname>Czarnecki</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41586-019-1724-z</idno>
		<ptr target="https://doi.org/10.1038/s41586-019-1724-z" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">575</biblScope>
			<biblScope unit="page" from="350" to="354" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Ichter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.11903[cs.CL]</idno>
		<title level="m">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">The computer for the 21st century</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Weiser</surname></persName>
		</author>
		<idno type="DOI">10.1038/scientificamerican0991-94</idno>
		<ptr target="https://doi.org/10.1038/scientificamerican0991-94" />
	</analytic>
	<monogr>
		<title level="j">Scientific American</title>
		<imprint>
			<biblScope unit="volume">265</biblScope>
			<biblScope unit="page" from="94" to="104" />
			<date type="published" when="1991">1991. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">The Computer for the 21st Century</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Weiser</surname></persName>
		</author>
		<idno type="DOI">10.1145/329124.329126</idno>
		<ptr target="https://doi.org/10.1145/329124.329126" />
	</analytic>
	<monogr>
		<title level="j">SIGMOBILE Mob. Comput. Commun. Rev</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="3" to="11" />
			<date type="published" when="1999-07">1999. jul 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">ELIZA-a computer program for the study of natural language communication between man and machine</title>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Weizenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="36" to="45" />
			<date type="published" when="1966">1966. 1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<title level="m" type="main">Procedures as a Representation for Data in a Computer Program for Understanding Natural Language</title>
		<author>
			<persName><forename type="first">Terry</forename><surname>Winograd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971">1971. 1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nisan</forename><surname>Stiennon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Christiano</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.10862[cs.CL]</idno>
		<title level="m">Recursively Summarizing Books with Human Feedback</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">PromptChainer: Chaining Large Language Model Prompts through Visual Programming</title>
		<author>
			<persName><forename type="first">Tongshuang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Donsbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alejandra</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Terry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carrie</forename><forename type="middle">J</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI EA &apos;22: Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts</title>
		<author>
			<persName><forename type="first">Tongshuang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Terry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carrie</forename><forename type="middle">J</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI &apos;22: Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Reexamining whether, why, and how human-AI interaction is uniquely difficult to design</title>
		<author>
			<persName><forename type="first">Qian</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Steinfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carolyn</forename><surname>Ros?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Zimmerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 chi conference on human factors in computing systems</title>
		<meeting>the 2020 chi conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Game AI revisited</title>
		<author>
			<persName><forename type="first">N</forename><surname>Georgios</surname></persName>
		</author>
		<author>
			<persName><surname>Yannakakis</surname></persName>
		</author>
		<idno type="DOI">10.1145/2212908.2212950</idno>
		<ptr target="https://doi.org/10.1145/2212908.2212950" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th Conference on Computing Frontiers. ACM</title>
		<meeting>the 9th Conference on Computing Frontiers. ACM<address><addrLine>Cagliari, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="285" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Game AI revisited</title>
		<author>
			<persName><forename type="first">N</forename><surname>Geogios</surname></persName>
		</author>
		<author>
			<persName><surname>Yannakakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th Conference on Computing Frontiers</title>
		<meeting>the 9th Conference on Computing Frontiers</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="285" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Towards implementation of social interaction</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Zubek</surname></persName>
		</author>
		<ptr target="https://www.aaai.org/Papers/Symposia/Spring/2002/SS-02-01/SS02-01-003.pdf" />
	</analytic>
	<monogr>
		<title level="m">AAAI Spring Symposium on Artificial Intelligence and Interactive Entertainment</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
