<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Distributionally robust joint chance constraints with second-order moment information</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Steve</forename><surname>Zymler</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<addrLine>180 Queen&apos;s Gate</addrLine>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<addrLine>180 Queen&apos;s Gate</addrLine>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Kuhn</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<addrLine>180 Queen&apos;s Gate</addrLine>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<addrLine>180 Queen&apos;s Gate</addrLine>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Berç</forename><surname>Rustem</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<addrLine>180 Queen&apos;s Gate</addrLine>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<addrLine>180 Queen&apos;s Gate</addrLine>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Distributionally robust joint chance constraints with second-order moment information</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">75E3CE04B11EB8AA2D515500CE5FF94C</idno>
					<idno type="DOI">10.1007/s10107-011-0494-7</idno>
					<note type="submission">Received: 20 August 2010 / Accepted: 26 August 2011</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Mathematics Subject Classification (2010) 90C15 • 90C22 1 Introduction</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We develop tractable semidefinite programming based approximations for distributionally robust individual and joint chance constraints, assuming that only the first-and second-order moments as well as the support of the uncertain parameters are given. It is known that robust chance constraints can be conservatively approximated by Worst-Case Conditional Value-at-Risk (CVaR) constraints. We first prove that this approximation is exact for robust individual chance constraints with concave or (not necessarily concave) quadratic constraint functions, and we demonstrate that the Worst-Case CVaR can be computed efficiently for these classes of constraint functions. Next, we study the Worst-Case CVaR approximation for joint chance constraints. This approximation affords intuitive dual interpretations and is provably tighter than two popular benchmark approximations. The tightness depends on a set of scaling parameters, which can be tuned via a sequential convex optimization algorithm. We show that the approximation becomes essentially exact when the scaling parameters are chosen optimally and that the Worst-Case CVaR can be evaluated efficiently if the scaling parameters are kept constant. We evaluate our joint chance constraint approximation in the context of a dynamic water reservoir control problem and numerically demonstrate its superiority over the two benchmark approximations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><formula xml:id="formula_0">minimize x∈R n c T x subject to Q a i ( ξ ) T x ≤ b i ( ξ ) ∀i = 1, . . . , m ≥ 1 -<label>(1)</label></formula><p>x ∈ X , where x ∈ R n is the decision vector, X ⊆ R n is a convex closed set that can be represented by semidefinite constraints, and c ∈ R n is a cost vector. Without much loss of generality, we assume that c is deterministic. The chance constraint in (1) requires a set of m uncertainty-affected inequalities to be jointly satisfied with a probability of at least 1 -, where ∈ (0, 1) is a desired safety factor specified by the modeler. The uncertain constraint coefficients a i ( ξ ) ∈ R n and b i ( ξ ) ∈ R, i = 1, . . . , m, depend affinely on a random vector ξ ∈ R k , whose distribution Q is assumed to be known. We thus have</p><formula xml:id="formula_1">a i ( ξ ) = a 0 i + k j=1 a j i ξ j and b i ( ξ ) = b 0 i + k j=1 b j i ξ j .</formula><p>For ease of notation we introduce auxiliary functions y j i : R n → R, which are defined through</p><formula xml:id="formula_2">y j i (x) = (a j i ) T x -b j i , i = 1, . . . , n, j = 0, . . . , k.</formula><p>These functions enable us to rewrite the chance constraint in problem <ref type="bibr" target="#b0">(1)</ref> as</p><formula xml:id="formula_3">Q y 0 i (x) + y i (x) T ξ ≤ 0 ∀i = 1, . . . , m ≥ 1 -,<label>(2)</label></formula><p>where y i (x) = [y 1 i (x), . . . , y k i (x)] T is affine in x for i = 1, . . . , m. By convention, (2) is referred to as an individual or joint chance constraint if m = 1 or m &gt; 1, respectively. Chance constrained programs were first discussed by Charnes et al. <ref type="bibr" target="#b7">[8]</ref>, Miller and Wagner <ref type="bibr" target="#b17">[18]</ref> and Prékopa <ref type="bibr" target="#b22">[23]</ref>. Although they have been studied for a long time, they have not found wide application in practice due to the following reasons.</p><p>Firstly, computing the optimal solution of a chance constrained program is notoriously difficult. In fact, even checking the feasibility of a fixed decision x requires the computation of a multi-dimensional integral, which becomes increasingly difficult as the dimension k of the random vector ξ increases. Furthermore, even though the inequalities in the chance constraint <ref type="bibr" target="#b1">(2)</ref> are biaffine in x and ξ , the feasible set of problem <ref type="bibr" target="#b0">(1)</ref> is typically nonconvex and sometimes even disconnected.</p><p>Secondly, in order to evaluate the chance constraint <ref type="bibr" target="#b1">(2)</ref>, full and accurate information about the probability distribution Q of the random vector ξ is required. However, in many practical situations Q must be estimated from historical data and is therefore itself uncertain. Typically, one has only partial information about Q, e.g. about its moments or its support. Replacing the unknown distribution Q in (1) by an estimate Q corrupted by measurement errors may lead to over-optimistic solutions which often fail to satisfy the chance constraint under the true distribution Q.</p><p>In a few special cases chance constraints can be reformulated as tractable convex constraints. For example, it is known that if the random vector ξ follows a Gaussian distribution and ≤ 0.5, then an individual chance constraint can be equivalently expressed as a single second-order cone constraint. In this case, the chance constrained problem becomes a tractable second-order cone program (SOCP), which can be solved in polynomial time, see Alizadeh and Goldfarb <ref type="bibr" target="#b0">[1]</ref>. More generally, Calafiore and El Ghaoui <ref type="bibr" target="#b5">[6]</ref> have shown that for ≤ 0.5 individual chance constraints can be converted to second-order cone constraints whenever the random vector ξ is governed by a radial distribution. Tractability results for joint chance constraints are even more scarce. In a seminal paper, Prékopa <ref type="bibr" target="#b22">[23]</ref> has shown that joint chance constraints are convex when only the right-hand side coefficients b i ( ξ ) are uncertain and follow a log-concave distribution. However, under generic distributions, chance constrained programs are computationally intractable. Indeed, Shapiro and Nemirovski <ref type="bibr" target="#b19">[20]</ref> point out that computing the probability of a weighted sum of uniformly distributed variables being nonpositive is already N P-hard.</p><p>Recently, Calafiore and Campi <ref type="bibr" target="#b4">[5]</ref> as well as Luedtke and Ahmed <ref type="bibr" target="#b16">[17]</ref> have proposed to replace the chance constraint (2) by a pointwise constraint that must hold at a finite number of sample points drawn randomly from the distribution Q. A similar approach was suggested by Erdoǧan and Iyengar <ref type="bibr" target="#b11">[12]</ref>. The advantage of this Monte Carlo approach is that no structural assumptions about Q are needed and that the resulting approximate problem is convex. Calafiore and Campi <ref type="bibr" target="#b4">[5]</ref> showed that one requires O(n/ ) samples to guarantee that a solution of the approximate problem is feasible in the original chance constrained program. However, this implies that it may be computationally prohibitive to solve large problems or to solve problems for which a small violation probability is required.</p><p>A natural way to immunize the chance constraint (2) against uncertainty in the probability distribution is to adopt a distributionally robust approach. To this end, let P denote the set of all probability distributions on R k that are consistent with the known properties of Q, such as its first and second moments and/or its support. Consider now the following ambiguous or distributionally robust chance constraint.</p><formula xml:id="formula_4">inf P∈P P y 0 i (x) + y i (x) T ξ ≤ 0 ∀i = 1, . . . , m ≥ 1 -<label>(3)</label></formula><p>It is easily verified that whenever x satisfies (3) and Q ∈ P, then x also satisfies the chance constraint (2) under the true probability distribution Q. Replacing the chance constraint (2) with its distributionally robust counterpart (3) yields the following distributionally robust chance constrained program minimize</p><formula xml:id="formula_5">x∈R n c T x subject to inf P∈P P y 0 i (x) + y i (x) T ξ ≤ 0 ∀i = 1, . . . , m ≥ 1 - x ∈ X , (4)</formula><p>which constitutes a conservative approximation for problem <ref type="bibr" target="#b0">(1)</ref> in the sense that it has the same objective function but a smaller feasible set.</p><p>A common method to simplify the distributionally robust joint chance constraint (3), which looks even less tractable than <ref type="bibr" target="#b1">(2)</ref>, is to decompose it into m individual chance constraints by using Bonferroni's inequality. Indeed, by ensuring that the total sum of violation probabilities of the individual chance constraints does not exceed , the feasibility of the joint chance constraint is guaranteed. Nemirovski and Shapiro <ref type="bibr" target="#b19">[20]</ref> propose to divide the overall violation probability equally among the m individual chance constraints. However, the Bonferroni inequality is not necessarily tight, and the corresponding decomposition could therefore be over-conservative. In fact, for positively correlated constraint functions, the quality of the approximation is known to decrease as m increases <ref type="bibr" target="#b8">[9]</ref>. Consequently, the Bonferroni method may result in a poor approximation for problems with joint chance constraints that involve many inequalities.</p><p>A recent attempt to improve on the Bonferroni approximation is due to Chen et al. <ref type="bibr" target="#b8">[9]</ref>. They first elaborate a convex conservative approximation for a joint chance constraint in terms of a Worst-Case Conditional Value-at-Risk (CVaR) constraint. Then, they rely on a classical inequality in order statistics to determine a tractable conservative approximation for the Worst-Case CVaR and show that the resulting approximation for the joint chance constraint necessarily outperforms the Bonferroni approximation. An attractive feature of this method is that the arising approximate constraints are second-order conic representable. However, the employed probabilistic inequality is not necessarily tight, which may again render the approximation over-conservative.</p><p>The principal aim of this paper is to develop new tools and models for approximating robust individual and joint chance constraints under the assumption that only the firstand second-order moments as well as the support of the random vector ξ are known. We embrace the modern approach to approximate robust chance constraints by Worst-Case CVaR constraints, but in contrast to the state-of-the-art methods described above, we find exact semidefinite programming (SDP) reformulations of the Worst-Case CVaR which do not rely on potentially loose probabilistic inequalities. These reformulations are facilitated by the theory of moment problems and by conic duality arguments. We prove that the CVaR approximation is in fact exact for individual chance constraints whose constraint functions are either concave or (possibly nonconcave) quadratic in ξ and for joint chance constraints whose constraint functions depend linearly on ξ . We also demonstrate that robust individual chance constraints have manifestly tractable SDP representations in most cases in which the CVaR approximation is exact.</p><p>The main contributions of this paper can be summarized as follows:</p><p>(1) In Sect. 2 we review and extend existing approximations for distributionally robust individual chance constraints and prove that a robust individual chance constraint is equivalent to a tractable Worst-Case CVaR constraint if the underlying constraint function is either concave or (possibly nonconcave) quadratic in ξ . We also demonstrate that this equivalence can fail to hold even if the constraint function is convex and piecewise linear in ξ . (2) In Sect. 3 we develop a new tractable CVaR approximation for robust joint chance constraints and prove that this approximation consistently outperforms the stateof-the-art methods described above. We show that the approximation quality is controlled by a set of scaling parameters and that the CVaR approximation becomes essentially exact if the scaling parameters are chosen optimally. We also present an intuitive dual interpretation for the CVaR approximation in this case. <ref type="bibr" target="#b2">(3)</ref> In Sect. <ref type="bibr" target="#b3">4</ref> we analyze the performance of the new joint chance constraint approximation when applied to a dynamic water reservoir control problem.</p><p>Notation We use lower-case bold face letters to denote vectors and upper-case bold face letters to denote matrices. The space of symmetric matrices of dimension n is denoted by S n . For any two matrices X, Y ∈ S n , we let X, Y = Tr(XY) be the trace scalar product, while the relation X Y (X Y) implies that X -Y is positive semidefinite (positive definite). Random variables are always represented by symbols with tildes, while their realizations are denoted by the same symbols without tildes. For x ∈ R, we define x + = max{x, 0}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Distributionally robust individual chance constraints</head><p>It is known that robust individual chance constraints can be conservatively approximated by Worst-Case CVaR constraints. In this section, we first show how the theory of moment problems can be used to reformulate these Worst-Case CVaR constraints in terms of tractable semidefinite constraints. Subsequently, we prove that the Worst-Case CVaR constraints are in fact equivalent to the underlying robust chance constraints for a large class of constraint functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Distributional assumptions</head><p>In the remainder of this paper we let μ ∈ R k be the mean vector and ∈ S k be the covariance matrix of the random vector ξ under the true distribution Q. Thus, we implicitly assume that Q has finite second-order moments. Without loss of generality we also assume that 0. Furthermore, we let P denote the set of all probability distributions on R k that have the same first-and second-order moments as Q. For notational simplicity, we let</p><formula xml:id="formula_6">= + μμ T μ μ T 1</formula><p>be the second-order moment matrix of ξ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Worst-Case CVaR approximation</head><p>For m = 1, (3) reduces to a distributionally robust individual chance constraint inf</p><formula xml:id="formula_7">P∈P P y 0 (x) + y(x) T ξ ≤ 0 ≥ 1 -,<label>(5)</label></formula><p>whose feasible set is denoted by</p><formula xml:id="formula_8">X ICC = x ∈ R n : inf P∈P P y 0 (x) + y(x) T ξ ≤ 0 ≥ 1 -.</formula><p>In the remainder of this section we will demonstrate that X ICC has a manifestly tractable representation in terms of Linear Matrix Inequalities (LMIs). To this end, we first recall the definition of CVaR due to Rockafellar and Uryasev <ref type="bibr" target="#b23">[24]</ref>. For a given measurable loss function L : R k → R, probability distribution P on R k , and tolerance ∈ (0, 1), the CVaR at level with respect to P is defined as</p><formula xml:id="formula_9">P-CVaR (L( ξ )) = inf β∈R β + 1 E P (L( ξ ) -β) + , (<label>6</label></formula><formula xml:id="formula_10">)</formula><p>where E P (•) denotes expectation with respect to P. CVaR essentially evaluates the conditional expectation of loss above the (1 -)-quantile of the loss distribution. It can be shown that CVaR represents a convex functional of the random variable L( ξ ).</p><p>CVaR can be used to construct convex approximations for chance constraints. Indeed, it is well known that</p><formula xml:id="formula_11">P L( ξ ) ≤ P-CVaR (L( ξ )) ≥ 1 -</formula><p>for any measurable loss function L, see, e.g. , Ben-Tal et al. <ref type="bibr" target="#b2">[3,</ref><ref type="bibr">Sect. 4.3.3</ref>]. Thus, P-CVaR (L( ξ )) ≤ 0 is sufficient to imply P(L( ξ ) ≤ 0) ≥ 1 -. As this implication holds for any probability distribution and loss function, we conclude that sup</p><formula xml:id="formula_12">P ∈ P P-CVaR y 0 (x)+ y(x) T ξ ≤ 0 ⇒ inf P∈P P y 0 (x) + y(x) T ξ ≤ 0 ≥ 1 -. (7)</formula><p>Thus, the Worst-Case CVaR constraint on the left hand side constitutes a conservative approximation for the distributionally robust chance constraint on the right hand side of <ref type="bibr" target="#b6">(7)</ref>. The above discussion motivates us to define the feasible set</p><formula xml:id="formula_13">Z ICC = x ∈ R n : sup P∈P P-CVaR y 0 (x) + y(x) T ξ ≤ 0 , (<label>8</label></formula><formula xml:id="formula_14">)</formula><p>and the implication <ref type="bibr" target="#b6">(7)</ref> gives rise to the following elementary result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 2.1</head><p>The feasible set Z ICC constitutes a conservative approximation for X ICC , that is, Z ICC ⊆ X ICC .</p><p>We will now show that Z ICC has a tractable representation in terms of LMIs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 21</head><p>The feasible set Z ICC can be written as</p><formula xml:id="formula_15">Z ICC = ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ x ∈ R n : ∃(β, M) ∈ R × S k+1 , M 0, β + 1 , M ≤ 0, M - 0 1 2 y(x) 1 2 y(x) T y 0 (x) -β 0 ⎫ ⎪ ⎪ ⎬ ⎪ ⎪ ⎭ .</formula><p>Proof By using <ref type="bibr" target="#b5">(6)</ref>, the Worst-Case CVaR in (8) can be expressed as</p><formula xml:id="formula_16">sup P∈P P-CVaR y 0 (x) + y(x) T ξ = sup P∈P inf β∈R β + 1 E P (y 0 (x) + y(x) T ξ -β) + = inf β∈R β + 1 sup P∈P E P (y 0 (x) + y(x) T ξ -β) + , (<label>9</label></formula><formula xml:id="formula_17">)</formula><p>where the interchange of the maximization and minimization operations is justified by a stochastic saddle point theorem due to Shapiro and Kleywegt <ref type="bibr" target="#b25">[26]</ref>, see also Delage and Ye <ref type="bibr" target="#b10">[11]</ref> or Natarajan et al. <ref type="bibr" target="#b18">[19]</ref>. We now show that the Worst-Case CVaR (9) of some fixed decision x ∈ R n can be computed by solving a tractable SDP. To this end, we first derive an SDP reformulation of the worst-case expectation problem sup</p><formula xml:id="formula_18">P∈P E P (y 0 (x) + y(x) T ξ -β) + ,</formula><p>which can be identified as the subordinate maximization problem in <ref type="bibr" target="#b8">(9)</ref>. Lemma A.1 in the Appendix enables us to reformulate this worst-case expectation problem as inf</p><formula xml:id="formula_19">M∈S k+1 , M s. t. M 0, ξ T 1 M ξ T 1 T ≥ y 0 (x) + y(x) T ξ -β ∀ξ ∈ R k . (<label>10</label></formula><formula xml:id="formula_20">)</formula><p>Note that the semi-infinite constraint in <ref type="bibr" target="#b9">(10)</ref> can be written as the following LMI.</p><formula xml:id="formula_21">ξ 1 T M - 0 1 2 y(x) 1 2 y(x) T y 0 (x) -β ξ 1 ≥ 0 ∀ξ ∈ R k ⇐⇒ M - 0 1 2 y(x) 1 2 y(x) T y 0 (x) -β 0</formula><p>This in turn allows us to reformulate the worst-case expectation problem as inf</p><formula xml:id="formula_22">M∈S k+1 , M s. t. M 0, M - 0 1 2 y(x) 1 2 y(x) T y 0 (x) -β 0.<label>(11)</label></formula><p>By replacing the subordinate worst-case expectation problem in ( <ref type="formula" target="#formula_16">9</ref>) by ( <ref type="formula" target="#formula_22">11</ref>), we obtain</p><formula xml:id="formula_23">sup P∈P P-CVaR y 0 (x)+ y(x) T ξ = inf β + 1 , M s. t. M ∈ S k+1 , β∈ R M 0, M- 0 1 2 y(x) 1 2 y(x) T y 0 (x) -β 0,<label>(12)</label></formula><p>and thus the claim follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Exactness of the Worst-Case CVaR approximation</head><p>So far we have shown that the feasible set Z ICC defined in terms of a Worst-Case CVaR constraint constitutes a tractable conservative approximation for X ICC . We now demonstrate that this approximation is in fact exact, that is, we show that the implication ( <ref type="formula">7</ref>) is in fact an equivalence. We first recall the nonlinear Farkas Lemma as well as the S-lemma, which are crucial ingredients for the proof of this result. We refer to Pólik and Terlaky <ref type="bibr" target="#b21">[22]</ref> for a derivation and an in-depth survey of the S-lemma as well as a review of the Farkas Lemma.</p><p>Lemma 2.2 (Farkas Lemma) Let f 0 , . . . , f p : R k → R be convex functions, and assume that there exists a strictly feasible point ξ with f i ( ξ</p><formula xml:id="formula_24">) &lt; 0, i = 1, . . . , p. Then, f 0 (ξ ) ≥ 0 for all ξ with f i (ξ ) ≤ 0, i = 1, . .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>. , p, if and only if there exist constants</head><formula xml:id="formula_25">τ i ≥ 0 such that f 0 (ξ ) + p i=1 τ i f i (ξ ) ≥ 0 ∀ξ ∈ R k . Lemma 2.2 (S-lemma) Let f i (ξ ) = ξ T A i ξ with A i ∈ S n be quadratic functions of ξ ∈ R n for i = 0, . . . , p. Then, f 0 (ξ ) ≥ 0 for all ξ with f i (ξ ) ≤ 0, i = 1, . . . , p, if there exist constants τ i ≥ 0 such that A 0 + p i=1 τ i A i 0.</formula><p>For p = 1, the converse implication holds if there exists a strictly feasible point ξ with f 1 ( ξ ) &lt; 0.</p><p>Theorem 2.2 Let L : R k → R be a continuous loss function that is either</p><formula xml:id="formula_26">(i) concave in ξ , or (ii) (possibly nonconcave) quadratic in ξ .</formula><p>Then, the following equivalence holds.</p><formula xml:id="formula_27">sup P∈P P-CVaR L( ξ ) ≤ 0 ⇐⇒ inf P∈P P L( ξ ) ≤ 0 ≥ 1 -<label>(13)</label></formula><p>Proof Consider the Worst-Case Value-at-Risk of the loss function L, which is defined as</p><formula xml:id="formula_28">WC-VaR (L( ξ )) = inf γ ∈R γ : inf P∈P P L( ξ ) ≤ γ ≥ 1 -. (<label>14</label></formula><formula xml:id="formula_29">)</formula><p>By definition, the WC-VaR is indeed equal to the (1 -)-quantile of L( ξ ) evaluated under some worst-case distribution in P. We first show that the following equivalence holds.</p><p>inf</p><formula xml:id="formula_30">P∈P P L( ξ ) ≤ 0 ≥ 1 -⇐⇒ WC-VaR L( ξ ) ≤ 0 (15)</formula><p>Indeed, if the left hand side of ( <ref type="formula">15</ref>) is satisfied, then γ = 0 is feasible in <ref type="bibr" target="#b13">(14)</ref>, which implies that WC-VaR (L( ξ )) ≤ 0. To see that the converse implication holds as well, we note that for any fixed P ∈ P, the mapping γ → P(L( ξ ) ≤ γ ) is upper semi-continuous, see <ref type="bibr" target="#b20">[21]</ref>. Thus, the related mapping γ → inf</p><formula xml:id="formula_31">P∈P P(L( ξ ) ≤ γ ) is also upper semi-continuous. If WC-VaR (L( ξ )) ≤ 0,</formula><p>there exists a sequence {γ n } n∈N that converges to zero and is feasible in ( <ref type="formula" target="#formula_28">14</ref>), which implies</p><formula xml:id="formula_32">inf P∈P P L( ξ ) ≤ 0 ≥ lim sup n→∞ inf P∈P P L( ξ ) ≤ γ n ≥ 1 -.</formula><p>Thus, ( <ref type="formula">15</ref>) follows.</p><p>To prove the postulated equivalence <ref type="bibr" target="#b12">(13)</ref>, it is now sufficient to show that</p><formula xml:id="formula_33">sup P∈P P-CVaR L( ξ ) = WC-VaR L( ξ ) .</formula><p>Note that ( <ref type="formula" target="#formula_28">14</ref>) can be rewritten as</p><formula xml:id="formula_34">WC-VaR (L( ξ )) = inf γ ∈R γ : sup P∈P P L( ξ ) &gt; γ ≤ . (<label>16</label></formula><formula xml:id="formula_35">)</formula><p>We proceed by simplifying the subordinate worst-case probability problem sup P∈P P(L( ξ ) &gt; γ ), which, by Lemma A.2 in the Appendix, can be expressed as inf</p><formula xml:id="formula_36">M∈S k+1 , M : M 0, ξ T 1 M ξ T 1 T ≥ 1 ∀ξ : γ -L(ξ ) &lt; 0 . (<label>17</label></formula><formula xml:id="formula_37">)</formula><p>We will now argue that for all but one value of γ problem (17</p><formula xml:id="formula_38">) is equivalent to inf , M s. t. M ∈ S k+1 , τ ∈ R, M 0, τ ≥ 0 ξ T 1 M ξ T 1 T -1 + τ (γ -L(ξ )) ≥ 0 ∀ξ ∈ R k . (<label>18</label></formula><formula xml:id="formula_39">)</formula><p>For ease of exposition, we define h = inf ξ ∈R k γ -L(ξ ). The equivalence of ( <ref type="formula" target="#formula_36">17</ref>) and ( <ref type="formula" target="#formula_38">18</ref>) is proved case by case. Assume first that h &lt; 0. Then, the strict inequality in the parameter range of the semi-infinite constraint in <ref type="bibr" target="#b16">(17)</ref> can be replaced by a weak inequality without affecting its optimal value. The equivalence then follows from the Farkas Lemma (when L(ξ ) is concave in ξ ) or from the S-lemma (when L(ξ ) is quadratic in ξ ). Assume next that h &gt; 0. Then, the semi-infinite constraint in <ref type="bibr" target="#b16">(17)</ref> becomes redundant and, since 0, the optimal solution of ( <ref type="formula" target="#formula_36">17</ref>) is given by M = 0 with a corresponding optimal value of 0. The optimal value of problem <ref type="bibr" target="#b17">(18)</ref> is also equal to 0. Indeed, by choosing τ = 1/ h, the semi-infinite constraint in ( <ref type="formula" target="#formula_38">18</ref>) is satisfied for any M 0. Finally, note that ( <ref type="formula" target="#formula_36">17</ref>) and ( <ref type="formula" target="#formula_38">18</ref>) may be different for h = 0.</p><p>Since ( <ref type="formula" target="#formula_36">17</ref>) and ( <ref type="formula" target="#formula_38">18</ref>) are equivalent for all but one value of γ and since their optimal values are nonincreasing in γ , we can express WC-VaR (L( ξ )) in ( <ref type="formula" target="#formula_34">16</ref>) as</p><formula xml:id="formula_40">WC-VaR (L( ξ )) = inf γ s. t. M ∈ S k+1 , τ ∈ R, γ ∈ R , M ≤ , M 0, τ ≥ 0 ξ T 1 M ξ T 1 T -1 + τ (γ -L(ξ )) ≥ 0 ∀ξ ∈ R k . (<label>19</label></formula><formula xml:id="formula_41">)</formula><p>It can easily be shown that , M ≥ 1 for any feasible solution of ( <ref type="formula" target="#formula_40">19</ref>) with vanishing τ -component. However, since &lt; 1, this is in conflict with the constraint , M ≤ . We thus conclude that no feasible point can have a vanishing τ -component. This allows us to divide the semi-infinite constraint in problem <ref type="bibr" target="#b18">(19)</ref> by τ . Subsequently we perform variable substitutions in which we replace τ by 1/τ and M by M/τ . This yields the following reformulation of problem <ref type="bibr" target="#b18">(19)</ref>.</p><formula xml:id="formula_42">WC-VaR (L( ξ )) = inf γ s. t. M ∈ S k+1 , τ ∈ R, γ ∈ R 1 , M ≤ τ, M 0, τ ≥ 0 ξ T 1 M ξ T 1 T -τ + γ -L(ξ ) ≥ 0 ∀ξ ∈ R k</formula><p>Note that, since 0 and M 0, we have 1 , M ≥ 0. This allows us to remove the redundant nonnegativity constraint on τ . We now introduce a new decision variable β = γ -τ , which allows us to eliminate γ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>WC-VaR</head><formula xml:id="formula_43">(L( ξ )) = inf β + τ s. t. M ∈ S k+1 , τ ∈ R, β ∈ R 1 , M ≤ τ, M 0 ξ T 1 M ξ T 1 T + β -L(ξ ) ≥ 0 ∀ξ ∈ R k</formula><p>Note that at optimality τ = 1 , M , which finally allows us to express WC-VaR</p><formula xml:id="formula_44">(L( ξ )) as WC-VaR (L( ξ )) = inf β + 1 , M s. t. M ∈ S k+1 , β ∈ R, M 0 ξ T 1 M ξ T 1 T + β -L(ξ ) ≥ 0 ∀ξ ∈ R k . (<label>20</label></formula><formula xml:id="formula_45">)</formula><p>Recall now that by Lemma A.1 we have</p><formula xml:id="formula_46">sup P∈P P-CVaR L( ξ ) = inf β∈R β + 1 sup P∈P E P (L( ξ ) -β) + = inf β + 1 , M s. t. M ∈ S k+1 , β ∈ R, M 0 ξ T 1 M ξ T 1 T + β -L(ξ ) ≥ 0 ∀ξ ∈ R k ,</formula><p>which is clearly equivalent to <ref type="bibr" target="#b19">(20)</ref>. This observation completes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corollary 2.1</head><p>The following equivalence holds</p><formula xml:id="formula_47">sup P∈P P-CVaR y 0 (x) + y(x) T ξ ≤ 0 ⇐⇒ inf P∈P P y 0 (x) + y(x) T ξ ≤ 0 ≥ 1 -, which implies that Z ICC = X ICC .</formula><p>Proof The claim follows immediately from Theorem 2.2 by observing that L(ξ ) = y 0 (x) + y(x) T ξ is linear (and therefore concave) in ξ .</p><p>In the following example we demonstrate that the equivalence (13) can fail to hold even if the loss function L is convex and piecewise linear in ξ .</p><p>Example 2.1 Let ξ be a scalar random variable with mean μ = 0 and standard deviation σ = 1. Moreover, let P be the set of all probability distributions on R consistent with the given mean and standard deviation. Consider now the loss function L(ξ ) = max{ξ -1, 4ξ -4}, and note that L is strictly increasing and convex in ξ . In particular, L is neither concave nor quadratic and thus falls outside the scope of Theorem 2.2. We now show that for this particular L the Worst-Case CVaR constraint sup P∈P P-CVaR 1 2 (L( ξ )) ≤ 0 is violated even though the distributionally robust individual chance constraint inf P∈P P(L( ξ ) ≤ 0) ≥ 1/2 is satisfied. To this end, we note that the Chebychev inequality</p><formula xml:id="formula_48">P( ξ -μ ≥ κσ ) ≤ 1/(1 + κ 2 ) for κ = 1 implies sup P∈P P ξ ≥ 1 ≤ 1 2 ⇐⇒ sup P∈P P L( ξ ) ≥ L(1) = 0 ≤ 1 2 ⇒ sup P∈P P L( ξ ) &gt; 0 ≤ 1 2 ⇐⇒ inf P∈P P L( ξ ) ≤ 0 ≥ 1 2 ,</formula><p>where the first equivalence follows from the monotonicity of L. Assume now that the true distribution Q of ξ is discrete and defined through</p><formula xml:id="formula_49">Q( ξ = -2) = 1/8, Q( ξ = 0) = 3/4, and Q( ξ = 2) = 1/8. It is easy to verify that Q ∈ P and that Q-CVaR 1 2 (L( ξ )) = 0.25. Thus, sup P∈P P-CVaR 1 2 (L( ξ )) ≥ 0.25 &gt; 0.</formula><p>We therefore conclude that the Worst-Case CVaR constraint is not equivalent to the robust chance constraint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Tractability of the Worst-Case CVaR approximation</head><p>We have already seen that Worst-Case CVaR constraints are equivalent to distributionally robust chance constraints when the loss function is continuous and either concave or quadratic in ξ . We now prove that the Worst-Case CVaR can also be computed efficiently for these classes of loss functions.</p><p>Theorem 2.3 Assume that L : R k → R is either (i) concave piecewise affine in ξ with a finite number of pieces or (ii) (possibly nonconcave) quadratic in ξ .</p><p>Then, sup P∈P P-CVaR (L( ξ )) can be computed efficiently as the optimal value of a tractable SDP.</p><p>Proof Assume that (i) holds and that </p><formula xml:id="formula_50">L( ξ ) = min i=1,...,l {a i + b T i ξ } for some a i ∈ R and b i ∈ R k , i = 1, . . . ,</formula><formula xml:id="formula_51">{a i + b T i ξ } -β + . (<label>21</label></formula><formula xml:id="formula_52">)</formula><p>By Lemma A.1, the subordinate worst-case expectation problem in ( <ref type="formula" target="#formula_51">21</ref>) can be rewritten as inf</p><formula xml:id="formula_53">M ∈ S k+1 , M s. t. M 0, ξ T 1 M ξ T 1 T ≥ min i=1,...,l {a i + b T i ξ } -β ∀ξ ∈ R k . (<label>22</label></formula><formula xml:id="formula_54">)</formula><p>Noting that min i=1,...,l</p><formula xml:id="formula_55">{a i + b T i ξ } = min λ∈ l i=1 λ i (a i + b T i ξ ),</formula><p>where = {λ ∈ R l : l i=1 λ i = 1, λ ≥ 0} denotes the probability simplex in R l , we can use techniques developed in [4, Theorem 2.1] to reexpress the semi-infinite constraint in <ref type="bibr" target="#b21">(22)</ref> as</p><formula xml:id="formula_56">ξ T 1 M ξ T 1 T -min λ∈ l i=1 λ i (a i + b T i ξ ) + β ≥ 0 ∀ξ ∈ R k ⇐⇒ min ξ ∈R k max λ∈ ξ T 1 M ξ T 1 T - l i=1 λ i (a i + b T i ξ ) + β ≥ 0 ⇐⇒ max λ∈ min ξ ∈R k ξ T 1 M ξ T 1 T - l i=1 λ i (a i + b T i ξ ) + β ≥ 0 ⇐⇒ min ξ ∈R k ξ T 1 M ξ T 1 T - l i=1 λ i (a i + b T i ξ ) + β ≥ 0, λ ∈ ⇐⇒ M - 0 l i=1 λ i 2 b i l i=1 λ i 2 b T i l i=1 λ i a i -β 0, λ ∈ .</formula><p>The second equivalence in the above expression follows from the classical saddle point theorem. Thus, the Worst-Case CVaR ( <ref type="formula" target="#formula_51">21</ref>) can be rewritten as the optimal value of the following tractable SDP.</p><formula xml:id="formula_57">inf β + 1 , M s. t. β ∈ R, M ∈ S k+1 , λ ∈ R l M 0, M - 0 l i=1 λ i 2 b i l i=1 λ i 2 b T i l i=1 λ i a i -β 0, λ ∈<label>(23)</label></formula><p>Assume now that (ii) holds and that L(ξ ) = ξ T Qξ + q T ξ + q 0 for some Q ∈ S k , q ∈ R k , and q 0 ∈ R. In this case we have</p><formula xml:id="formula_58">sup P∈P P-CVaR (L( ξ )) = inf β∈R β + 1 sup P∈P E P ξ T Q ξ + ξ T q + q 0 -β + . (<label>24</label></formula><formula xml:id="formula_59">)</formula><p>As usual, we first find an SDP reformulation of the subordinate worst-case expectation problem in <ref type="bibr" target="#b23">(24)</ref>. By Lemma A.1, this problem can be rewritten as inf</p><formula xml:id="formula_60">M ∈ S k+1 , M s. t. M 0, ξ T 1 M ξ T 1 T ≥ ξ T Qξ + ξ T q + q 0 -β ∀ξ ∈ R k . (<label>25</label></formula><formula xml:id="formula_61">)</formula><p>Note that the semi-infinite constraint in ( <ref type="formula" target="#formula_60">25</ref>) is equivalent to</p><formula xml:id="formula_62">ξ 1 T M- Q 1 2 q 1 2 q T q 0 -β ξ 1 ≥ 0 ∀ξ ∈ R k ⇐⇒ M - Q 1 2 q 1 2 q T q 0 -β 0,</formula><p>123 which enables us to rewrite the Worst-Case CVaR <ref type="bibr" target="#b23">(24)</ref> as the optimal value of</p><formula xml:id="formula_63">inf β + 1 , M s. t. M ∈ S k+1 , β ∈ R M 0, M - Q 1 2 q 1 2 q T q 0 -β 0,</formula><p>which is indeed a tractable SDP.</p><p>Remark If the loss function is concave but not piecewise affine, the Worst-Case CVaR can sometimes still be evaluated efficiently, though not by solving an explicit SDP. Indeed, the Worst-Case CVaR can be computed in polynomial time with an ellipsoid method if L(ξ ) is concave and if, for any ξ ∈ R k , one can evaluate both L(ξ ) as well as a super-gradient ∇ ξ L(ξ ) in polynomial time. This is an immediate consequence of a result on the computation of worst-case expectations by Delage and Ye [11, Proposition 2].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Distributionally robust joint chance constraints</head><p>We define the feasible set X JCC of the distributionally robust joint chance constraint (3) as</p><formula xml:id="formula_64">X JCC = x ∈ R n : inf P∈P P y 0 i (x) + y i (x) T ξ ≤ 0 ∀i = 1, . . . , m ≥ 1 -.</formula><p>The aim of this section is to investigate the structure of X JCC and to elaborate tractable conservative approximations. We first review two existing approximations and discuss their benefits and shortcomings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Bonferroni approximation</head><p>A popular approximation for X JCC is based on Bonferroni's inequality. Note that the robust joint chance constraint (3) is equivalent to</p><formula xml:id="formula_65">inf P∈P P m i=1 y 0 i (x) + y i (x) T ξ ≤ 0 ≥ 1 - ⇐⇒ sup P∈P P m i=1 y 0 i (x) + y i (x) T ξ &gt; 0 ≤ .</formula><p>Furthermore, Bonferroni's inequality implies that</p><formula xml:id="formula_66">P m i=1 y 0 i (x) + y i (x) T ξ &gt; 0 ≤ m i=1 P y 0 i (x) + y i (x) T ξ &gt; 0 ∀P ∈ P.</formula><p>For any vector of safety factors</p><formula xml:id="formula_67">∈ E = { ∈ R m + : m i=1 i ≤ }, the system of distributionally robust individual chance constraints inf P∈P P y 0 i (x) + y i (x) T ξ ≤ 0 ≥ 1 -i ∀i = 1, . . . , m<label>(26)</label></formula><p>represents a conservative approximation for the distributionally robust joint chance constraint <ref type="bibr" target="#b2">(3)</ref>. By Theorem 21, we can reformulate each of the individual chance constraints in <ref type="bibr" target="#b25">(26)</ref> in terms of tractable LMIs. In fact, we can further reduce these LMIs to SOCP constraints, but this further simplification is irrelevant for our purposes. Thus, for any ∈ E, the assertion that x ∈ Z JCC B ( ), where</p><formula xml:id="formula_68">Z JCC B ( ) = ⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩ x ∈ R n : ∃(β i , M i ) ∈ R × S k+1 ∀i = 1, . . . , m, M i 0, β i + 1 i , M i ≤ 0 ∀i = 1, . . . , m, M i - 0 1 2 y i (x) 1 2 y i (x) T y 0 i (x) -β i 0 ∀i = 1, . . . , m ⎫ ⎪ ⎪ ⎪ ⎬ ⎪ ⎪ ⎪ ⎭ ,</formula><p>is a sufficient condition to guarantee that x satisfies the original distributionally robust joint chance constraint (3). The above arguments culminate in the following result.</p><p>Theorem 3.1 (Bonferroni approximation) For any ∈ E we have Z JCC B ( ) ⊆ X JCC . A major shortcoming of the Bonferroni approximation is that the approximation quality depends critically on the choice of ∈ E. Unfortunately, the problem of finding the best ∈ E for a generic chance constrained problem of type ( <ref type="formula">4</ref>) is nonconvex and believed to be intractable <ref type="bibr" target="#b19">[20]</ref>. As a result, in most applications of Bonferroni's inequality the "risk budget" is equally divided among the m individual chance constraints in <ref type="bibr" target="#b25">(26)</ref> by setting i = /m for i = 1, . . . , m. This approach was first advocated by Nemirovski and Shapiro <ref type="bibr" target="#b19">[20]</ref>.</p><p>The Bonferroni approximation can be overly conservative even if ∈ E is chosen optimally. The following example, which is adapted from Chen et al. <ref type="bibr" target="#b8">[9]</ref>, highlights this shortcoming.</p><p>Example 3.1 Assume that the inequalities in the chance constraint (3) are perfectly positively correlated in the sense that</p><formula xml:id="formula_69">y 0 i (x) = δ i ŷ0 (x) and y i (x) = δ i ŷ(x)</formula><p>for some affine functions ŷ0 : R n → R and ŷ : R n → R k and for some fixed constants δ i &gt; 0 for i = 1, . . . , m. In this case, it can readily be seen that the joint chance constraint (3) is equivalent to the robust individual chance constraint inf</p><formula xml:id="formula_70">P∈P P y 0 (x) + y(x) T ξ ≤ 0 ≥ 1 -. (<label>27</label></formula><formula xml:id="formula_71">)</formula><p>Thus, the least conservative choice for i which guarantees that (26) implies (3) is i = for i = 1, . . . , m. However, this means that the i sum to m instead of as required by the Bonferroni approximation. In fact, the optimal choice for ∈ E is i = /m for i = 1, . . . , m. This example demonstrates that the quality of the Bonferroni approximation diminishes as m increases if the inequalities in the joint chance constraint are positively correlated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Approximation by Chen, Sim, Sun and Teo</head><p>In order to mitigate the potential over-conservatism of the Bonferroni approximation, Chen et al. <ref type="bibr" target="#b8">[9]</ref> proposed an approximation based on a different inequality from probability theory. The starting point is the observation that the joint chance constraint (3) can be reformulated as inf</p><formula xml:id="formula_72">P∈P P max i=1,...,m α i y 0 i (x) + y i (x) T ξ ≤ 0 ≥ 1 -<label>(28)</label></formula><p>for any vector of strictly positive scaling parameters α ∈ A = {α ∈ R m : α &gt; 0}.</p><p>Note that the choice of α ∈ A does not affect the feasible region of the chance constraint <ref type="bibr" target="#b27">(28)</ref>. Although these scaling parameters are seemingly unnecessary, it turns out that they can be tuned to improve the approximation to be developed below. Chen et al. <ref type="bibr" target="#b8">[9]</ref> note that (28) represents a distributionally robust individual chance constraint, which can be conservatively approximated by a Worst-Case CVaR constraint. Thus, for any α ∈ A, the requirement</p><formula xml:id="formula_73">x ∈ Z JCC (α) = x ∈ R n : sup P∈P CVaR max i=1,...,m α i y 0 i (x) + y i (x) T ξ ≤ 0<label>(29)</label></formula><p>implies that x ∈ X JCC , see Proposition 2.1. It is important to note that, in contrast to the chance constraint <ref type="bibr" target="#b27">(28)</ref>, the Worst-Case CVaR constraint x ∈ Z JCC (α) does depend on the choice of α ∈ A. Thus, the Worst-Case CVaR constraint in <ref type="bibr" target="#b28">(29)</ref> is not equivalent to the robust chance constraint (28) since the max function in ( <ref type="formula" target="#formula_72">28</ref>) is convex piecewise linear, see also Theorem 2.2 and Example 2.1.</p><p>The following theorem due to Chen et al. <ref type="bibr" target="#b8">[9]</ref> relies on a classical result in order statistics and provides a tractable SOCP-based conservative approximation for Z JCC (α).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 3.2 (Approximation by Chen et al.) For any α ∈</head><formula xml:id="formula_74">A we have Z JCC U (α) ⊆ Z JCC (α) ⊆ X JCC where Z JCC U (α) = {x ∈ R n : Ĵ (x, α) ≤ 0} and Ĵ (x, α) = min w 0 ∈R,w∈R k min β∈R β + 1 π w 0 -β, w + 1 m i=1 π α i y 0 i (x) -w 0 , α i y i (x) -w , where π z 0 , z = 1 2 z 0 + μ T z + 1 2 z 0 + μ T z, 1/2 z 2</formula><p>Note that, since the feasible set Z JCC U (α) constitutes a tractable conservative approximation for X JCC for any α ∈ A, the union α∈A Z JCC U (α) still constitutes a conservative approximation for X JCC . Chen et al. <ref type="bibr" target="#b8">[9]</ref> prove also that their approximation is tighter than the Bonferroni approximation by showing that Z JCC B ( ) ⊆ α∈A Z JCC U (α) for all ∈ E. Unfortunately, similar to the Bonferroni approach, the approximation by Chen et al. depends critically on the choice of α, while the problem of finding the best α ∈ A for a generic chance constrained program of the type ( <ref type="formula">4</ref>) is nonconvex and therefore believed to be intractable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The Worst-Case CVaR approximation</head><p>Both approximations discussed so far rely on inequalities from probability theory, which are not necessarily tight. In this section we show that the set Z JCC (α) has in fact an exact tractable representation in terms of LMIs and therefore promises to provide a tight convex approximation for X JCC . Theorem 3.3 For any fixed x ∈ R n and α ∈ A, we have</p><formula xml:id="formula_75">Z JCC (α) = ⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩ x ∈ R n : ∃(β, M) ∈ R × S k+1 , β + 1 , M ≤ 0, M 0, M - 0 1 2 α i y i (x) 1 2 α i y T i α i y 0 i (x) -β 0 ∀i = 1, . . . , m ⎫ ⎪ ⎪ ⎪ ⎬ ⎪ ⎪ ⎪ ⎭ . (<label>30</label></formula><formula xml:id="formula_76">)</formula><p>Proof We note that the constraint x ∈ Z JCC (α) is equivalent to J (x, α) ≤ 0, where</p><formula xml:id="formula_77">J (x, α) = sup P ∈ P CVaR max i=1,...,m α i y 0 i (x) + y i (x) T ξ = inf β∈R β + 1 sup P∈P E P max i=1,...,m α i y 0 i (x) + y i (x) T ξ -β + (31)</formula><p>denotes the Worst-Case CVaR. As in Sect. 2, the first step towards a tractable reformulation of J (x, α) is to solve the worst-case expectation problem sup</p><formula xml:id="formula_78">P∈P E P max i=1,...,m α i y 0 i (x) + y i (x) T ξ -β + . (<label>32</label></formula><formula xml:id="formula_79">)</formula><p>For any fixed x ∈ X , β ∈ R, and α ∈ A, Lemma A.1 enables us to reformulate (32) as inf</p><formula xml:id="formula_80">M∈S k+1 , M s. t. M 0, ξ T 1 M ξ T 1 T ≥ max i=1,...,m α i y 0 i (x)+ y i (x) T ξ -β ∀ξ ∈ R k . (<label>33</label></formula><formula xml:id="formula_81">)</formula><p>We emphasize that (33) represents a lossless reformulation of the worst-case expectation problem (32). The semi-infinite constraint in (33) can be expanded into m simpler semi-infinite constraints of the form</p><formula xml:id="formula_82">ξ T 1 M ξ T 1 T ≥ α i y 0 i (x) + y i (x) T ξ -β ∀ξ ∈ R k , i = 1, . . . , m,</formula><p>which can be equivalently expressed as the following system of LMIs.</p><formula xml:id="formula_83">M - 0 1 2 α i y i (x) 1 2 α i y i (x) T α i y 0 i (x) -β 0 ∀i = 1, . . . , m</formula><p>We can therefore reformulate the worst-case expectation problem (32) as inf</p><formula xml:id="formula_84">M ∈ S k+1 , M s. t. M 0, M - 0 1 2 α i y i (x) 1 2 α i y i (x) T α i y 0 i (x) -β 0 ∀i = 1, . . . , m. (<label>34</label></formula><formula xml:id="formula_85">)</formula><p>Substituting (34) into (31) yields</p><formula xml:id="formula_86">J (x, α) = inf β + 1 , M s. t. M ∈ S k+1 , β ∈ R M 0, M - 0 1 2 α i y i (x) 1 2 α i y i (x) T α i y 0 i (x)-β 0 ∀i = 1, . . . , m,<label>(35)</label></formula><p>and thus the claim follows.</p><p>Theorem 3.3 establishes that Z JCC (α) has an exact representation in terms of LMIs. We have already seen in Sect. 3.2 that Z JCC (α) ⊆ X JCC for all α ∈ A and that Z JCC U (α) ⊆ Z JCC (α), see Theorem 3.2. Thus, Z JCC (α) constitutes a tractable conservative approximation for X JCC which is at least as tight as Z JCC U (α). Recall from Sect. 3.2 that Z JCC B ( ) ⊆ α∈A Z JCC U (α) for all ∈ E. Moreover, we have Z JCC U (α) ⊆ Z JCC (α) ⊂ X JCC for all α ∈ A. This allows us to conclude that our new approximation is at least as tight as the two state-of-the-art approximations discussed above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remark 3.1 In contrast to the classical Bonferroni approximation, the Worst-Case</head><p>CVaR approximation behaves reasonably in situations in which the m inequalities in the chance constraint (3) are positively correlated. Indeed, by choosing</p><formula xml:id="formula_87">α i := 1/δ i &gt; 0 for all i = 1, . . . , m in Example 3.1, the constraint x ∈ Z JCC (α) is equivalent to ∃β ∈ R, M ∈ S k+1 : β + 1 , M ≤ 0, M 0, M - 0 1 2 y(x) 1 2 y(x) T y 0 (x) -β 0,</formula><p>which can easily be identified as the SDP reformulation of the individual chance constraint <ref type="bibr" target="#b26">(27)</ref>. This implies that Z JCC (α) = X ICC for all α ∈ A in Example 3.1, see also Theorem 21. Thus, by choosing α appropriately, our method can provide tight approximations for distributionally robust joint chance constraints, even in situations when the m inequalities are positively correlated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Dual interpretation of the Worst-Case CVaR approximation</head><p>In this section we explore a different way to find a tractable conservative approximation for the chance constraint (3). Subsequently, we will prove that this approximation is equivalent to the Worst-Case CVaR approximation. Consider again the robust individual chance constraint <ref type="bibr" target="#b27">(28)</ref> which is equivalent to the robust joint chance constraint (3) for any fixed α ∈ A. Instead of approximating ( <ref type="formula" target="#formula_72">28</ref>) by a Worst-Case CVaR constraint, we can approximate the max-function in the chance constraint (28) by a quadratic majorant of the form q(ξ ) = ξ T Qξ + ξ T q + q 0 that satisfies</p><formula xml:id="formula_88">q(ξ ) ≥ max i=1,...,m α i y 0 i (x) + y i (x) T ξ ∀ξ ∈ R k , ⇐⇒ q(ξ ) ≥ α i y 0 i (x) + y i (x) T ξ ∀ξ ∈ R k , i = 1, . . . , m. (<label>36</label></formula><formula xml:id="formula_89">)</formula><p>Replacing the max function in <ref type="bibr" target="#b27">(28)</ref> by q(ξ ) yields the distributionally robust (individual) quadratic chance constraint inf</p><formula xml:id="formula_90">P∈P P ξ T Q ξ + ξ T q + q 0 ≤ 0 ≥ 1 -. (<label>37</label></formula><formula xml:id="formula_91">)</formula><p>For further argumentation, we define</p><formula xml:id="formula_92">Z JCC Q (α) = x ∈ R n : ∃Q ∈ S k , q ∈ R k , q 0 ∈</formula><p>R such that q(ξ ) = ξ T Qξ + ξ T q + q 0 satisfies (36) and (37) . (38)</p><formula xml:id="formula_93">Proposition 3.1 For any fixed α ∈ A the feasible set Z JCC Q (α) constitutes a conser- vative approximation for X JCC , that is, Z JCC Q (α) ⊆ X JCC .</formula><p>Proof Note that any x feasible in ( <ref type="formula" target="#formula_72">28</ref>) is also feasible in (38) since</p><formula xml:id="formula_94">P ξ T Q ξ + ξ T q + q 0 ≤ 0 ≤ P max i=1,...,m α i (y 0 i (x) + y i (x) T ξ ) ≤ 0 ∀P ∈ P.</formula><p>Since x is feasible in <ref type="bibr" target="#b27">(28)</ref> if and only if x ∈ X JCC , the claim follows.</p><p>Theorem 3.4 For any fixed x ∈ R n and α ∈ A we have</p><formula xml:id="formula_95">Z JCC Q (α) = ⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩ x ∈ R n : ∃Q ∈ S k , q ∈ R k , q 0 ∈ R, β ∈ R, M ∈ S k+1 , β + 1 , M ≤ 0, M 0, M - Q 1 2 q 1 2 q T q 0 -β 0, Q 1 2 (q -α i y i (x)) 1 2 (q -α i y i (x)) T q 0 -α i y 0 i (x) 0 ∀i = 1, . . . , m ⎫ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎬ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎭ .</formula><p>Proof Note that the constraints in (36) are equivalent to</p><formula xml:id="formula_96">Q 1 2 (q -α i y i (x)) 1 2 (q -α i y i (x)) T q 0 -α i y 0 i (x) 0 ∀i = 1, . . . , m.</formula><p>Moreover, by Theorem 2.2, the robust quadratic chance constraint (37) is equivalent to the Worst-Case CVaR constraint</p><formula xml:id="formula_97">sup P∈P P-CVaR ξ T Q ξ + ξ T q + q 0 = inf β∈R β + 1 sup P∈P E P ξ T Q ξ + ξ T q + q 0 -β + ≤ 0. (<label>39</label></formula><formula xml:id="formula_98">)</formula><p>By the proof of part (ii) in Theorem 2.3, we know that (39) can be written as</p><formula xml:id="formula_99">0 ≥ inf β + 1 , M s. t. M ∈ S k+1 , β ∈ R M 0, M - Q 1 2 q 1 2 q T q 0 -β 0.</formula><p>Thus, the claim follows.</p><p>In the following theorem we show that the approximate feasible set Z JCC Q (α) is equivalent to the set Z JCC (α) found in Sect. 3.3. This implies that the approximation of a distributionally robust joint chance constraint by a Worst-Case CVaR constraint is equivalent to the approximation of the max function implied by the joint chance constraint by a quadratic majorant. Note that both approximations depend of the choice of the scaling parameters α.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 3.5 For any α</head><formula xml:id="formula_100">∈ A we have Z JCC Q (α) = Z JCC (α).</formula><p>Proof By defining the combined variable</p><formula xml:id="formula_101">Y = Q 1 2 q 1 2 q T q 0 ,</formula><p>the set Z JCC Q (α) can be rewritten as</p><formula xml:id="formula_102">Z JCC Q (α) = ⎧ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎩ x ∈ R n : ∃Y ∈ S k , β∈ R, M ∈ S k+1 , β + 1 , M ≤ 0, M 0 M+ 0 0 0 T β Y 0 1 2 α i y i (x) 1 2 α i y i (x) T α i y 0 i (x) ∀i = 1, . . . , m ⎫ ⎪ ⎪ ⎪ ⎪ ⎬ ⎪ ⎪ ⎪ ⎪ ⎭ ,</formula><p>It is easy to see that Y may be eliminated from the above representation of Z JCC Q (α) by rewriting the last constraint group as</p><formula xml:id="formula_103">M - 0 1 2 α i y i (x) 1 2 α i y i (x) T α i y 0 i (x) -β 0 ∀i = 1, . . . , m.</formula><p>This observation establishes the postulated equivalence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Exactness of the Worst-Case CVaR approximation</head><p>So far we have shown that, for any fixed α ∈ A, the feasible set Z JCC (α) constitutes a tractable conservative approximation for X JCC . This implies that the union Z JCC = α∈S Z JCC (α) still constitutes a conservative approximation for X JCC . We now demonstrate that this improved approximation is essentially exact. To this end, we introduce the feasible set</p><formula xml:id="formula_104">X JCC • = x ∈ R n : sup P∈P P m i=1 y 0 i (x) + y i (x) T ξ &lt; 0 ≥ 1 -</formula><p>corresponding to a strict version of the joint chance constraint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 3.6</head><p>The Worst-Case CVaR approximation is essentially exact if α is treated as a decision variable. Formally, we have</p><formula xml:id="formula_105">X JCC • ⊆ Z JCC ⊆ X JCC .</formula><p>Proof The theorem can be proved by invoking a Chebyshev-type bound for the worstcase probability of a random vector to lie in the intersection of a set of quadratic (or, a fortiori, linear) inequalities, see Vandenberghe et al. <ref type="bibr" target="#b27">[28]</ref>. To keep this paper selfcontained, we provide here an elementary proof which is reminiscent of the exactness proof in Sect. 3.5.</p><p>The second inclusion follows immediately from the known conservativeness of the CVaR approximation. Therefore, it is sufficient to prove the first inclusion. By using similar arguments as in Sect. 3.1, we can rewrite X JCC • as</p><formula xml:id="formula_106">X JCC • = x ∈ R n : sup P∈P P m i=1 y 0 i (x) + y i (x) T ξ ≥ 0 ≤ .</formula><p>By Lemma A.2 in the Appendix we may thus conclude that</p><formula xml:id="formula_107">X JCC • = x ∈ R n : ∃M ∈ S k+1 , , M ≤ , M 0, ξ T 1 M ξ T 1 T ≥ 1 ∀ξ ∈ m i=1 y 0 i (x) + y i (x) T ξ ≥ 0 .</formula><p>The semi-infinite constraint in the above representation of X JCC</p><p>• can be reexpressed as</p><formula xml:id="formula_108">ξ T 1 M ξ T 1 T ≥ 1 ∀ξ : y 0 i (x) + y i (x) T ξ ≥ 0, ∀i = 1, . . . , m,</formula><p>which, by the S-lemma, is equivalent to</p><formula xml:id="formula_109">∃α ≥ 0, M - 0 1 2 α i y i (x) 1 2 α i y i (x) T α i y 0 i (x) + 1 0 ∀i = 1, . . . , m.</formula><p>Thus, the feasible set X JCC</p><p>• can be written as</p><formula xml:id="formula_110">X JCC • = ⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩ x ∈ R n : ∃M ∈ S k+1 , α ∈ R m , , M ≤ , M 0, α &gt; 0, M - 0 1 2 α i y i (x) 1 2 α i y i (x) T α i y 0 i (x) + 1 0 ∀i = 1, . . . , m ⎫ ⎪ ⎪ ⎪ ⎬ ⎪ ⎪ ⎪ ⎭ . (<label>40</label></formula><formula xml:id="formula_111">)</formula><p>Note that we require here without loss of generality that α is strictly positive. Indeed, it can be shown that no feasible α has any vanishing components. By Theorem 3.3, we have</p><formula xml:id="formula_112">Z JCC = ⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩ x ∈ R n : ∃β ∈ R, M ∈ S k+1 , α ∈ A β + 1 , M ≤ 0, M 0, M - 0 1 2 α i y i (x) 1 2 α i y T i α i y 0 i (x) -β 0 ∀i = 1, . . . , m ⎫ ⎪ ⎪ ⎪ ⎬ ⎪ ⎪ ⎪ ⎭ . (<label>41</label></formula><formula xml:id="formula_113">)</formula><p>It is now clear that X JCC • ⊆ Z JCC since we are free to set β = -1 in (41) and since -1 +<ref type="foot" target="#foot_0">1</ref> , M ≤ 0 is equivalent to , M ≤ . This observation completes the proof. Remark 3.2 Note that Z JCC = X JCC for m = 1; see Corollary 2.1. In general, however, both inclusions in Theorem 3.6 can be strict. If there is no degenerate constraint function with (y 0 i (x),</p><formula xml:id="formula_114">y i (x) T ) T = 0 ∀x ∈ R n , then N = m i=1</formula><p>x ∈ R n : (y 0 i (x), y i (x) T ) T = 0 constitutes a Lebesgue null set as it is a finite union of strict affine subspaces of R n . By using similar arguments as in the proof of Theorem 3.6 one can show that X JCC \X JCC • ⊆ N , which implies that X JCC and X JCC attain the same optimal value except in degenerate cases. Unfortunately, optimizing jointly over x ∈ X ∩ Z JCC (α) and α ∈ A in (42) involves Bilinear Matrix Inequalities (BMIs). It is known that generic BMI constrained problems are N P-hard, see <ref type="bibr" target="#b26">[27]</ref>. Similar nonconvexities arise also in the approximations discussed in Sects. 3.1 and 3.2, which underlines the general perception that problems with distributionally robust joint chance constraints are hard to solve. Recall, however, that for any fixed α ∈ A, the set Z JCC (α) is representable in terms of tractable LMI constraints involving the auxiliary variables β and M. In particular, the constraints in (41) are convex in β, M, and x for any fixed α, and convex in α for any fixed β, M, and x. In Sect. 3.7 we will use this property to propose an algorithm for solving (42) approximately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Injecting support information</head><p>In many practical applications the support of the (true) distribution Q of ξ is known to be a strict subset of R k . Disregarding this information in the definition of P can result in unnecessarily conservative robust chance constraints. In this section we briefly outline how support information can be used to tighten robust joint chance constraints and their approximations developed in Sect. 3. To this end, we first revise our distributional assumptions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Distributional assumptions</head><p>The random vector ξ has a distribution Q with mean vector μ and covariance matrix 0. We assume that Q is supported on</p><formula xml:id="formula_115">= {ξ ∈ R k : [ξ T 1]W i [ξ T 1] T ≤ 0 ∀i = 1, . . . ,</formula><p>l}, where W i ∈ S k+1 for all i = 1, . . . , l. 1 Thus, we have Q( ξ ∈ ) = 1. We define P as the set of all probability distributions supported on that have the same first-and second-order moments as Q.</p><p>In this section we are interested in tractable conservative approximations for the feasible set</p><formula xml:id="formula_116">X JCC = x ∈ R n : inf P∈P P y 0 i (x) + y i (x) T ξ ≤ 0 ∀i = 1, . . . , m ≥ 1 -.</formula><p>As before, we study approximate feasible sets of the form</p><formula xml:id="formula_117">Z JCC (α) = x ∈ R n : sup P∈P CVaR max i=1,...,m α i y 0 i (x) + y i (x) T ξ ≤ 0</formula><p>for α ∈ A. By using similar arguments as in Sect. 2.1, one can show that Z JCC (α) ⊆ X JCC for all α ∈ A. However, the sets Z JCC (α) have no longer an exact representation in terms of LMIs. Instead, they need to be conservatively approximated.</p><p>Theorem 3.7 For any fixed α ∈ A, we have Y JCC (α) ⊆ Z JCC (α) ⊆ X JCC , where Y JCC (α) has the following tractable reformulation in terms of LMIs.</p><formula xml:id="formula_118">Y JCC (α) = ⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩ x ∈ R n : ∃M ∈ S k+1 , β ∈ R, τ i ∈ R l , β + 1 , M ≤ 0, τ i ≥ 0 ∀i = 0, . . . , m M + l j=1 τ 0, j W j 0 M + l j=1 τ i, j W j - 0 1 2 α i y i (x) 1 2 α i y i (x) T α i y 0 i (x) -β 0 ∀i = 1, . . . , m ⎫ ⎪ ⎪ ⎪ ⎪ ⎪ ⎬ ⎪ ⎪ ⎪ ⎪ ⎪ ⎭ . (<label>43</label></formula><formula xml:id="formula_119">)</formula><p>Furthermore, for l = 1, we have Y JCC (α) = Z JCC (α).</p><p>Proof The proof widely parallels the proof of Theorem 3.3. The only difference is that R k is replaced by and that we use the S-lemma to approximate (for l &gt; 1) or reformulate (for l = 1) the semi-infinite constraints over by LMI constraints.</p><p>Remark 3.3 While Z JCC (α) is exactly representable in terms of LMIs in the absence of support information, Theorem 3.7 only provides a conservative LMI approximation for Z JCC (α). Nevertheless, it is easily verified that Z JCC (α) ⊆ Y JCC (α) and therefore Y JCC (α) constitutes a better approximation for Z JCC (α) than Z JCC (α). In fact, by setting τ i = 0 for all i = 0, . . . , m, (43) reduces to (35).</p><p>Remark 3.4 Support information can also be used in a straightforward way to tighten the approximations discussed in Sects. 3.1 and 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Optimizing over the scaling parameters</head><p>By Theorem 3.6, the original distributionally robust chance constrained program (4) can be written as minimize</p><formula xml:id="formula_120">x∈R n ,α∈A c T x subject to J (x, α) ≤ 0 x ∈ X ,<label>(44)</label></formula><p>where the Worst-Case CVaR functional J (x, α) is defined as in (31). Unfortunately, as discussed in Sect. 3.3, J (x, α) is merely biconvex, but not jointly convex in x and α. Thus, optimization problem (44) is nonconvex. By Theorem 3.3, however, the problem becomes convex and tractable when the values of the scaling parameters α are frozen.</p><p>For the further argumentation we define the set Ā = {α : α ≥ δe}, where e denotes the vector of ones and δ &gt; 0 represents a small tolerance, which we set to 10 -7 . Note that, unlike A, the set Ā is closed. Consider now the following optimization model where α ∈ Ā is fixed.</p><formula xml:id="formula_121">min x∈R n c T x s. t. J (x, α) ≤ 0 x ∈ X (45)</formula><p>We emphasize again that by Theorem 3.3 (45) is equivalent to a tractable SDP and that any x feasible in (45) is also feasible in the original chance constrained problem (4). In the remainder of this section we develop an algorithm that repeatedly solves (45) while systematically improving the scaling parameters α.</p><p>The main idea of this approach, which is inspired by <ref type="bibr" target="#b8">[9]</ref>, is to minimize J (x, α) over α ∈ Ā with the aim of enlarging the feasible region of problem (45) and thereby improving the objective value. To this end, we introduce the following optimization model which depends parametrically on x ∈ X . min</p><formula xml:id="formula_122">α∈R m J (x, α) s. t. α ∈ Ā<label>(46)</label></formula><p>Theorem 3.3 implies that (46) can also be expressed as a tractable SDP. Assume that x * is an optimal solution of problem (45) for a given α ∈ Ā. By the feasibility of x * in (45) we know that J (x * , α) ≤ 0. Keeping x * fixed, we then solve problem (46) to obtain the optimal scaling parameters α * corresponding to x * . By construction, we find</p><formula xml:id="formula_123">J (x * , α * ) ≤ J (x * , α) ≤ 0. (<label>47</label></formula><formula xml:id="formula_124">)</formula><p>The above inequalities imply that the optimal objective value of problem (45) with input α * must not exceed c T x * . Therefore, by solving the problems (45) and (46) in alternation, we obtain a sequence of monotonically decreasing objective values. This motivates the following algorithm, which relies on the availability of an initial feasible solution x init for problem (45).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3.1 Sequential Convex Optimization Procedure</head><p>1. Initialization Let x init be some feasible solution of problem (45). Set the current solution to x 0 ← x init , the current objective value to f 0 ← c T x 0 , and the iteration counter to t ← 1.</p><formula xml:id="formula_125">l 0 + t i=1 ξi - t i=1</formula><p>x t ( ξ t ).</p><p>We require that the water level remains between some upper threshold l high (flood reserve) and some lower threshold l low (dead storage) over all time periods t = 1, . . . , T with probability 1 -, where ∈ (0, 1). The water released in any period t is used to produce electric energy which is sold at a periodic price</p><formula xml:id="formula_126">c t = 10 + 5 sin π(1 -t) 3 ∀t = 1, . . . , T.</formula><p>The worst-case expected profit over all time periods is computed as</p><formula xml:id="formula_127">inf P∈P E P T t=1 c t x t ( ξ t ) .</formula><p>In order to determine an admissible control strategy that maximizes the worst-case profit, we must solve the following distributionally robust joint chance constrained problem. maximize</p><formula xml:id="formula_128">x 1 (•),...,x T (•) inf P∈P E P T t=1 c t x t ( ξ t ) subject to inf P ∈ P P l low ≤l 0 + t i=1 ξi - t i=1</formula><p>x t ( ξ t ) ≤l high ∀t = 1, . . . , T ≥ 1-</p><p>x t ( ξ t ) ≥ 0 P-a.s. ∀P ∈ P , t = 1, . . . , T</p><p>Note that (48) is an infinite dimensional problem since the control decisions x t (•) are generic measurable functionals of the uncertain inflows. To reduce the problem complexity, we focus on policies that are affine functions of ξ . Thus, we optimize over affine disturbance feedback policies of the form x t ( ξ t ) = x 0 t + x T t P t ξ ∀t = 1, . . . , T, (</p><p>where x 0 t ∈ R, x t ∈ R t and P t : R T → R t is a truncation operator that maps ξ to ξ t . By focusing on affine control policies we conservatively approximate the infinite dimensional dynamic problem (48) by a problem with a polynomial number of variables, namely, the coefficients {x 0 t , x t } T t=1 . For more details on the use of affine control policies in robust control and stochastic programming, see, e.g. , Ben-Tal et al. <ref type="bibr" target="#b2">[3]</ref>, Chen et al. <ref type="bibr" target="#b9">[10]</ref>, and Kuhn et al. <ref type="bibr" target="#b14">[15]</ref>.</p><p>By applying now standard robust optimization techniques <ref type="bibr" target="#b2">[3]</ref>, the requirement that x t ( ξ t ) ≥ 0 holds almost surely can be expressed as </p><formula xml:id="formula_131">x 0 t +</formula><p>Note that the joint chance constraint in (50) involves 2T inequalities that are bilinear in the decisions {x t } T t=1 and the random vector ξ . Problem (50) can therefore be identified as a special instance of problem (4) and is amenable to the approximation methods described in Sect. 3. In the remainder of this section, we compare the performance of these approximation methods.</p><p>In the subsequent tests, we set T = 5, l 0 = 1, l low = 1, and l high = 5. The mean value of ξt is assumed to be 1, while its standard deviation is set to 10%, over all time periods. Furthermore, we set the correlation of different stochastic inflows to 25% for adjacent time periods and 0% otherwise. Finally, we assume that = [0, 2] T . All tests are run for a range of reliability levels between 1 and 10% in steps of 1%.</p><p>We first solve problem (50) using the Bonferroni approximation by decomposing the joint chance constraint into 2T individual chance constraints with reliability factors i = /(2T ) for i = 1, . . . , 2T . The resulting optimal objective value is denoted by V B , and the associated optimal solution is used to initialize Algorithm 3.1. We run the algorithm using the Worst-Case CVaR approximation as well as the approximation by Chen et al. described in Sect. 3.2. We denote the resulting optimal objective values by V M and V U , respectively. In both cases the algorithm's convergence threshold is set to γ = 10 -6 . All SDPs arising from the Worst-Case CVaR approximation are solved with SDPT3 using the YALMIP interface <ref type="bibr" target="#b15">[16]</ref>, while all SOCPs arising from the Bonferroni approximation and the approximation by Chen et al. are solved with MOSEK using the algebraic modeling toolbox ROME <ref type="bibr" target="#b12">[13]</ref>.</p><p>Table <ref type="table">1</ref> reports the optimal objective values and the improvement of V M relative to V U and V B . As expected, all three methods yield optimal objective values that increase</p><formula xml:id="formula_133">ξ T 1 M ξ T 1 T ≥ 0 ∀ξ ∈ R k (54a) ξ T 1 M ξ T 1 T ≥ f (ξ ) ∀ξ ∈ R k (54b)</formula><p>Since (54a) is equivalent to M 0, the claim follows.</p><p>Lemma A.2 Let S ⊆ R k be any Borel measurable set (which is not necessarily convex), and define the worst-case probability π wc as</p><formula xml:id="formula_134">π wc = sup P∈P P{ ξ ∈ S}, (<label>55</label></formula><formula xml:id="formula_135">)</formula><p>Then,</p><formula xml:id="formula_136">π wc = inf M∈S k+1</formula><p>, M : M 0, ξ T 1 M ξ T 1</p><formula xml:id="formula_137">T ≥ 1 ∀ξ ∈ S .</formula><p>. Proof The proof is due to Calafiore et al. <ref type="bibr" target="#b6">[7]</ref>, see also Zymler et al. <ref type="bibr" target="#b28">[29]</ref>. A sketch of the proof is provided here to keep this paper self-contained. Define the indicator function of the set S as</p><formula xml:id="formula_138">I S (ξ ) = 1 if ξ ∈ S, 0 otherwise.</formula><p>The worst-case probability problem (55) can equivalently be expressed as</p><formula xml:id="formula_139">π wc = sup μ∈M + R k I S (ξ )μ(dξ ) s. t. R k μ(dξ ) = 1 R k ξ μ(dξ ) = μ R k ξξ T μ(dξ ) = + μμ T .</formula><p>By dualizing this problem and applying similar manipulations as in the proof of Lemma A.1 we obtain the postulated result.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>•</head><label></label><figDesc>differ at most by a Lebesgue null set for well-specified chance constraints. Theorem 3.6 implies that the original joint chance constrained program minimize x∈X ∩X JCC c T x and its Worst-Case CVaR approximation minimize x∈X ∩Z JCC (α) α∈A c T x (42)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>l. Then, the Worst-Case CVaR is representable as</figDesc><table><row><cell>inf β∈R</cell><cell>β +</cell><cell>1</cell><cell>sup P∈P</cell><cell>E P</cell><cell>min i=1,...,l</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>x T t P t ξ ≥ 0 ∀ξ ∈ ⇐⇒ 0 ≤ min ⇐⇒ ∃λ t ∈ R T : x 0 t + x T t P t u + λ T t (lu) ≥ 0, λ t ≥ P T t x t , λ t ≥ 0. subject to λ t ∈ R T , x t ∈ R t ∀t = 1, . . . , T</figDesc><table><row><cell></cell><cell></cell><cell cols="2">ξ ∈R T</cell><cell cols="2">x 0 t + x T</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">λ t ∈R T</cell><cell cols="3">x 0 t + x T</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="11">By substituting (49) into (48) we thus obtain the following conservative approximation</cell></row><row><cell>for (48).</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>T</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>maximize</cell><cell cols="4">c t x 0 t + x T t P t μ</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>t=1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>⎛</cell><cell></cell><cell></cell><cell>t</cell><cell></cell><cell>t</cell><cell></cell><cell>⎞</cell></row><row><cell>inf P∈P</cell><cell>P</cell><cell>⎜ ⎜ ⎜ ⎜ ⎝</cell><cell cols="2">l 0 -l high +</cell><cell>i=1 t</cell><cell>ξi -ξi +</cell><cell>i=1 t</cell><cell>x 0 i + x T x 0 i + x T</cell><cell>⎟ ⎟ ⎟ ⎟ ⎠</cell><cell>≥ 1 -</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>i=1</cell><cell></cell><cell cols="2">i=1</cell><cell></cell></row><row><cell cols="2">x 0 t + x T</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>t P t ξ : l ≤ ξ ≤ u ⇐⇒ 0 ≤ max t P t u + λ T t (lu) : λ t ≥ P T t x t , λ t ≥ 0 i P i ξ ≤ 0 ∀t = 1, . . . , T l lowl 0i P i ξ ≤ 0 ∀t = 1, . . . , T t P t u + λ T t (lu) ≥ 0 λ t ≥ P T t x t , λ t ≥ 0 ∀t = 1, . . . , T</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Note that every finite intersection of half-spaces and ellipsoids in R k is representable as a set of the form .</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors are indebted to Prof. A. Ben-Tal for valuable discussions on the topic of this paper and would also like to thank EPSRC for financial support under grant EP/H0204554/1.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Scaling Parameter Optimization</head><p>Solve problem (46) with input x t-1 and let α * denote an optimal set of scaling parameters. Set α t ← α * . 3. Decision Optimization Solve problem (45) with input α t and let x * denote an optimal solution. Set x t ← x * and f t ← c T x t . <ref type="bibr" target="#b3">4</ref>. Termination If ( f tf t-1 )/| f t-1 | ≤ γ (where γ is a given small tolerance), output x t and stop. Otherwise, set t ← t + 1 and go back to Step 2.</p><p>Theorem 3.8 Assume that x init is feasible in problem (45) for some α ∈ Ā. Then, the sequence of objective values { f t } generated by Algorithm 3.1 is monotonically decreasing. If the set X is bounded, then the sequence {x t } is also bounded, while the sequence { f t } converges to a finite limit.</p><p>Proof By the inequality (47), an update of the scaling parameters from α We emphasize that Algorithm 3.1 does not necessarily find the global optimum of problem (44). Nevertheless, as confirmed by the numerical results in the next section, the method can perform well in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Numerical results</head><p>We consider a dynamic water reservoir control problem for hydro power generation, which is inspired by a model due to Andrieu et al. <ref type="bibr" target="#b1">[2]</ref>. Let ξ = ( ξ1 , ξ2 , . . . , ξT ) denote the sequence of stochastic inflows (precipitation) into the reservoir at time instances t = 1, . . . , T . The history of inflows up to time t is denoted by ξ t = ( ξ1 , . . . , ξt ), where ξ T = ξ . We let μ ∈ R T and ∈ S T denote the mean vector and covariance matrix of ξ , respectively. Furthermore, ξ is supported on a rectangle of the form = [l, u]. However, we assume that no further information about the true distribution of ξ is available. As usual, we let P denote the set of all distributions supported on with matching first-and second-order moments. We denote by x t ( ξ t ) the amount of water released from the reservoir in period t. Note that the decision x t ( ξ t ) is selected at time t after ξ t has been observed and is therefore a function of the observation history. We require x t ( ξ t ) ≥ 0 almost surely for all P ∈ P and t = 1, . . . , T . The water level at time t is computed as the sum of the initial level l 0 and the cumulative inflows minus the cumulative releases up to time t, that is,  The table also reports the percentage gaps (V M -V U )/V U and (V M -V B )/V B as well as the runtimes for the three algorithms (R M , R U , R B ) in seconds with because the joint chance constraint becomes less restrictive as grows. At = 1% the objective values of the different approximations coincide. However, V M exceeds V U and V B for all the other values of . In this particular example, our method outperforms the Bonferroni approximation by up to 25% and the approximation by Chen et al. by up to 12%. Table <ref type="table">1</ref> also reports the runtimes of the different algorithms. All instances based on the Worst-Case CVaR approximation are solved in less then 20 seconds, while the instances based on the approximation by Chen et al. and the Bonferroni approximation are solved in less then 5 and 1 seconds, respectively. Thus, as expected, the improved solution quality offered by the (SDP-based) Worst-Case CVaR approximation over the two (SOCP-based) benchmark approximations comes at an increased computational overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A: Worst-Case expectation and probability problems</head><p>Lemma A.1 Let f : R k → R be a measurable function, and define the worst-case expectation θ wc as</p><p>where P represents the usual set of all probability distributions on R k with given mean vector μ and covariance matrix 0. Then,</p><p>where is the second-order moment matrix of ξ .</p><p>Proof The worst-case expectation θ wc can equivalently be expressed as</p><p>where M + represents the cone of nonnegative Borel measures on R k . The optimization variable of the semi-infinite linear program (51) is the nonnegative measure μ. Note that the first constraint forces μ to be a probability measure. The other two constraints enforce consistency with the given first-and second-order moments, respectively. We now assign dual variables y 0 ∈ R, y ∈ R k , and Y ∈ S k to the equality constraints in (51), respectively, and introduce the following dual problem (see, e.g. , <ref type="bibr" target="#b24">[25]</ref>). Because 0, it can be shown that strong duality holds <ref type="bibr" target="#b13">[14]</ref>. Therefore, the worstcase probability θ wc coincides with the optimal value of the dual problem (52). By defining the combined variable M = Y Note that the semi-infinite constraint in (53) can be expanded in terms of two equivalent semi-infinite constraints.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Second-order cone programming</title>
		<author>
			<persName><forename type="first">F</forename><surname>Alizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Goldfarb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="51" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A model for dynamic chance constraints in hydro power reservoir management</title>
		<author>
			<persName><forename type="first">L</forename><surname>Andrieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Henrion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Römisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">207</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="579" to="589" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Ben-Tal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>El Ghaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nemirovski</surname></persName>
		</author>
		<title level="m">Robust Optimization</title>
		<meeting><address><addrLine>Princeton</addrLine></address></meeting>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Models for minimax stochastic linear optimization problems with risk aversion</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bertsimas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Doan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Teo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="580" to="602" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The scenario approach to robust control design</title>
		<author>
			<persName><forename type="first">G</forename><surname>Calafiore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Campi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Control</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="742" to="753" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Distributionally robust chance-constrained linear programs with applications</title>
		<author>
			<persName><forename type="first">G</forename><surname>Calafiore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>El Ghaoui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optim. Theory Appl</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Parameter estimation with expected and residual-at-risk criteria</title>
		<author>
			<persName><forename type="first">G</forename><surname>Calafiore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Topcu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>El Ghaoui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Syst. Control Lett</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="46" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cost horizons and certainty equivalents: an approach to stochastic programming of heating oil</title>
		<author>
			<persName><forename type="first">A</forename><surname>Charnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Symonds</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Manag. Sci</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="235" to="263" />
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">From CVaR to uncertainty set: implications in joint chance-constrained optimization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Teo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="470" to="485" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A robust optimization perspective on stochastic programming</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1058" to="1071" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Distributionally robust optimization under moment uncertainty with application to data-driven problems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Delage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Ambiguous chance constrained problems and robust optimization</title>
		<author>
			<persName><forename type="first">E</forename><surname>Erdoǧan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Iyengar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program. Series B</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="37" to="61" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Robust optimization made easy with ROME</title>
		<author>
			<persName><forename type="first">J</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="973" to="985" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The extrema of probability determined by generalized moments (i) bounded random variables</title>
		<author>
			<persName><forename type="first">K</forename><surname>Isii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Inst. Stat. Math</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="119" to="134" />
			<date type="published" when="1960">1960</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Primal and dual linear decision rules in stochastic and robust optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wiesemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Georghiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="177" to="209" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">YALMIP : a toolbox for modeling and optimization in MATLAB</title>
		<author>
			<persName><forename type="first">J</forename><surname>Löfberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CACSD Conference</title>
		<meeting>the CACSD Conference<address><addrLine>Taipei</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A sample approximation approach for optimization with probabilistic constraints</title>
		<author>
			<persName><forename type="first">J</forename><surname>Luedtke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ahmed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="674" to="699" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Chance-constrained programming with joint constraints</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="930" to="945" />
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Constructing risk measures from uncertainty sets</title>
		<author>
			<persName><forename type="first">K</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pachamanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1129" to="1141" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Convex approximations of chance constrained programs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nemirovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="969" to="996" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sample average approximation method for chance constrained programming: theory and applications</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Pagnoncelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optim. Theory Appl</title>
		<imprint>
			<biblScope unit="volume">142</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="399" to="416" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A survey of the S-lemma</title>
		<author>
			<persName><forename type="first">I</forename><surname>Pólik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Terlaky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Rev</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="371" to="481" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On probabilistic constrained programming</title>
		<author>
			<persName><forename type="first">A</forename><surname>Prékopa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Princeton Symposium on Mathematical Programming</title>
		<meeting>the Princeton Symposium on Mathematical Programming<address><addrLine>Princeton</addrLine></address></meeting>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="1970">1970</date>
			<biblScope unit="page" from="113" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Optimization of conditional value-at-risk</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Rockafellar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Uryasev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Risk</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="21" to="41" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">On duality theory of conic linear problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Semi-Infinite Programming: Recent Advances</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Goberna</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Lopez</surname></persName>
		</editor>
		<meeting><address><addrLine>Dordrecht</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Minimax analysis of stochastic problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Kleywegt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optim. Methods Softw</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="523" to="542" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On the NP-hardness of solving bilinear matrix inequalities and simultaneous stabilization with static output feedback</title>
		<author>
			<persName><forename type="first">O</forename><surname>Toker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ozbay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the American Control Conference</title>
		<meeting>the American Control Conference</meeting>
		<imprint>
			<publisher>Seatle</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="2525" to="2526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Generalized Chebyshev bounds via semidefinite programming</title>
		<author>
			<persName><forename type="first">L</forename><surname>Vandenberghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Comanor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Rev</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="52" to="64" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Worst-case value-at-risk of non-linear portfolios</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zymler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rustem</surname></persName>
		</author>
		<ptr target="http://www.optimization-online.org/DB_HTML/2009/08/2379.html" />
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
