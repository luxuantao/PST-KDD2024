<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Perceptual Organization in Computer Vision: A Review and a Proposal for a Classificatory Structure</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Student Member, IEEE</roleName><forename type="first">Sudeep</forename><surname>Sarkar</surname></persName>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Kim</forename><forename type="middle">L</forename><surname>Boyer</surname></persName>
						</author>
						<title level="a" type="main">Perceptual Organization in Computer Vision: A Review and a Proposal for a Classificatory Structure</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">49AB4D489E2FF70D31E265836634D612</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The evolution of perceptual organization in biological vision, and its necessity in advanced computer vision systems, arises from the characteristic that perception, the extraction of meaning from sensory input, is an intelligent process. This is particularly so for high order organisms and, analogically, for more sophisticated computational models. The role of perceptual organization in computer vision systems is explored. This is done from four vantage points. First, a brief history of perceptual organization research in both humans and computer vision is offered. Next, a classificatory structure in which to cast perceptual organization research to clarify both the nomenclature and the relationships among the many contributions is proposed. Thirdly, the perceptual organization work in computer vision in the context of this classificatory structure is reviewed. Finally, the array of computational techniques applied to perceptual organization problems in computer vision is surveyed.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>"Perception is not a mere passive recording of information impressed upon my sensory organs by the environment. Rather, it consists of an active construction by means of which sensory data are selected, analyzed, and integrated with properties not directly noticeable but only hypothesized, deduced, or anticipated, according to available information and intellectual capacities." Gaetano Kanizsa  T is this ability to impose organization on sensory data I which makes human perception so powerful and so versatile. This phenomenon has been recognized by the computer vision community in reducing the computational complexity of visual recognition. Most vision systems organize primary data, be it edges or regions, into perceptually significant groups and structures that are invariant over a range of viewpoints to increase the efficiency of model matching. Perceptual organization also assists a vision system in coping with unreliable low level processing, making it more resistant to minor changes in the input and achieving the much desired goal of graceful degradation.</p><p>Perceptual organization can be defined as the ability to impose structural organization on sensory data, so as to group sensory primitives arising from a common underlying cause. This sort of organization lets us form object hypotheses with minimal domain knowledge and, therefore, minimal restrictions, beyond the fact that our world is not visually chaotic; it has structure and organization. The role of perceptual organization in vision, or any other sensory modality, is critical to success. It imparts robustness and computational efficiency to the perceptual process. The importance of finding organization in sensory data has long been recognized by researchers in human visual perception, especially the Gestalt psychologists. Its role in computer vision was emphasized and demonstrated much later by researchers such as Witkin and  Tenenbaum [l] and Lowe [2]. Perceptual organization has since appeared in various guises in a large body of work, sometimes without being explicitly identified.</p><p>Perceptual organization provides significant computational leverage and can do so over several layers of abstraction.</p><p>The sophistication of a vision system, on the whole, lies largely in the sophistication of its perceptual organization processes. In biological systems, visual capability is developed to a degree appropriate to the ambulatory capabilities of the organism, Le., the degree to which it can use the information to acquire food, elude danger, or otherwise restructure its environment. The performance of a machine vision system is coupled to the chosen problem domain, which is analogous. It is the recognition, development, and exploitation of perceptual organization concepts, models, paradigms, and computational techniques that brings efficiency to machine vision systems.</p><p>Perceptual organization allows us to assign computational resources intelligently, which is also important in biological systems because of the relative expense of neural tissue from an evolutionary standpoint. As we shall see, perceptual organization in computer vision uses computational resources effectively to extract organizations from which features are hypothesized, instead of the expensive alternative of directly applying feature detectors over the entire image.</p><p>Because of this state of affairs, a variety of researchers pursuing various specific goals have advanced numerous interesting computational approaches based on different sets of mathematical tools. This has engendered a proliferation of research on perceptual organization embodying many approaches over many levels, with no particular agreement on the terminology and vocabulary. In short, the term has become somewhat ambiguous, meaning different things to different people. Our goals in this are, therefore, twofold: to review and organize the research already accomplished in perceptual organization and to propose a standard nomenclature with 0018-9472/93$03.00 0 1993 JEEE which to discuss existing and future work.</p><p>In Section I1 we review the history of perceptual organization, from work in human vision to work in computer vision. The classificatory structure for perceptual organization is proposed in Section 111. The computer vision work is reviewed in Section IV. Section V discusses the various computational techniques that have been used to compute organization. Based on the observations arising from the review and classification, new research areas are suggested in Section VI. Conclusions are presented in Section VII. The role of perceptual organization is best illustrated by the very interesting experiment reported by Smith [3]. A perceptually random stimulus was presented to subjects who were asked to reproduce it. The reproduced set was used as stimulus to a second set of subjects who were also asked to reproduce what they were shown. After about 12 cascades the final reproduction had a definite structure to it. The subjects had (gradually) imposed organization on an entirely random stimulus! The experiment indicates the importance of organization in human perception. The human visual system values organization to such a degree that it attempts to find (or impose) it even when none actually exists. Clearly this heuristic behavior has evolved in a world which, generally, is very much structured.</p><p>We will start by asking what is computed in perceptual organization and then see if we can address why. How is considered in a later section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. What?</head><p>The Gestalt psychologists observed and emphasized the importance of organization in vision. They demonstrated that shapes have some elusive, immeasurable collective properties that do not appear when analyzed by their constituent parts. The Gestalt school of psychology, founded by Koffka [4], Kohler [5] and <ref type="bibr">Wertheimer [6]</ref> in the early 20th century, demonstrated the role of structure or organization by a number of self evident examples. Besides the convincing examples, their lucid and polemic writing style made their work very popular. They recognized what is computed in perceptual organization, but did not convincingly answer why it is calculated or how. This spurred several debates which obscured some of the original ideas and created a number of misconceptions. Kanizsa <ref type="bibr" target="#b5">[7]</ref> offers some interesting comments about the popular misconceptions regarding Gestalt psychology, which are important to keep in mind as we try to incorporate Gestaltic behavior in computer vision systems. He translates Gestalt to "organized structure" as opposed to "form," "aggregate," or "heap." The stress is on the concept of organization and on a whole that is orderly, rule-governed, and nonrandom. His other assertions are listed below. 1) Gestalt Psychology is not basically a psychology of perception. Gestaltists have experimented in perception [4], productive thinking [8], problem solving [9], memory and learning [lo], and more. The Gestalt theory is a very general system of psychological concepts that can be used to understand virtually any aspect of experience and behavior. Thus, these principles should prove useful, in multiple ways, in building an autonomous robot exhibiting intelligent behavior.</p><p>2) Gestalt Psychology proposes that the "properties of the whole are not the result of a summation of those of the parts" and not quite the tenet that "the whole is greater than the sum of its parts." Thus, a part has properties that depend on the whole in which it is included. However, this does not necessarily imply that everything depends on everything else, which would certainly hinder scientific analysis. The dependence of parts on the whole has a varying nature. Gestalt psychology merely maintains that the parts of the whole are not completely independent and hence cannot be analyzed separately.</p><p>3) Gestalt psychology does not deny the importance of attention, intention, interest, attitude, and organizational factors in our perceptual experience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4)</head><p>Gestalt Psychology does not deny the influence of past experience on perception. However, it does deny the empiricist view that past experience is a universal explanatory principle. Wertheimer [6, pp. 231-2321 explicitly states that past experience helps in building the dependencies among various parts. If AB and C, but not BC, have become habitual (or "associated"), there is then a tendency for ABC to be perceived as AI3 and C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5)</head><p>The regularity of a structure is not just its symmetry. One of the basic principles of Gestalt psychology is that organization tends towards Pragnanz, i.e., the tendency of a process to realize the most regular, ordered, stable, and balanced state possible in a given situation. It is not just geometric regularity (see Fig. <ref type="figure">2(c</ref>)); stability, simplicity, and cohesion also play a role. It is interesting to note that very few of the above aspects of Gestalt theory have so far been used in computer vision. As we shall see from the review, issues of attention (point 3), use of a knowledge base and learning (point 4), and criteria other than geometric regularity (point 5) are rarely considered. We hope that future work in perceptual organization will take these factors into account. Issues of attention, intention, and attitude might be important in the context of task based or active vision. Learning Gestalt organizations and the use of knowledge bases in perceptual organization are still open issues. Criteria other than geometric regularity are likewise uninvestigated but this is partly due to the semantic imprecision of those other factors.</p><p>Kanizsa <ref type="bibr" target="#b5">[7]</ref> suggests that perception of form or shape can be divided into two processes. The primary process segregates the visual field into regions having spatial and temporal regularities. The secondary process, which helps us in going beyond the information given, is the perceptual inference of totalization, of completion, of integration, of "filling in the gaps," i.e., of inferring that which is absent. This way of approaching the problem is beneficial in the context of machine vision; the second process should help us to bridge the gaps created by imperfect segmentation in the first or by occlusions in the scene. However, as Kanizsa illustrates exploiting transparency, we might perceive organizations that are physically impossible or "meaningless" based on past experience (see Fig. <ref type="figure">2(b</ref>)) but which are perceived because of the strong segmentation cues provided by the first process. This indicates that the second process is not the sole determining factor of organization.</p><p>Kanizsa observed that the completion of contours which are partially occluded is decided mainly by continuity in direction at the occluding point and the minimal distance criterion when the first criterion does not give rise to closed figures. Symmetry plays only a minor role. There is also a preference for convex forms over symmetric ones' (see Fig. <ref type="figure">2(c)</ref>). Kanizsa studied in some detail the phenomenon of anomalous contours. In Fig. <ref type="figure" target="#fig_2">1</ref> we see a white triangle even though the triangle has not been drawn. It is an artifact of the alignment of the three "Pacmans." He observed that anomalous contours arose when the constituents were not "complete" or self sufficient and is necessary for the completion of incomplete parts of the image. The completion of a part is dependent on the amount of Pragnanz it possesses. There have been several attempts to quantify Pragnanz.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Why?</head><p>It is natural to ask why organization in vision is so important. The answer is neither simple nor self evident and has far reaching effects in general cognition because we seem to use this principle in other forms of perception. The functional role of organization is very difficult to frame. However, this does not diminish its importance. Any theory of perceptual organization should explain not only organization in vision, but also in other cognitive activity like learning (where the organization of knowledge in the form of "chunks" is well known), music appreciation, and so on.</p><p>Many have attempted formulating a reason for the importance of perceptual organization. One of the theories which appeals due to its simplicity and elegance is that of nonaccidentalness, also known as the principle of common-cause, or coincidence explanation. This was independently proposed by Witkin and Tenenbaum [l], Lowe [2], and <ref type="bibr">Rock [12]</ref> in explaining the preference for one perceived form over another. The low probability of the chance occurrence of a particular organization imparts a very high significance to it if found. This implies a single causal entity for those features so organized. In vision we are most interested in spatiotemporal coherence or regularity.</p><p>The importance of organization can be made more explicit using the following mathematical language. Let Causality denote the event that a set of features are part of (or caused by) the same object and let Organization denote the event that the features have some organization among themselves. Then we are interested in the probability that the features come from the same underlying cause, given that we have found some organization among them: P ( Causality [Organization). Using Bayes' rule we can write:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P( Causality [Organization)</head><p>P( Organization I Causality ) P ( Causality)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P( Organization)</head><p>.</p><p>(1) --'Most researchers in computer vision consider a Euclidean space for their perceptual organizer. However, there is considerable evidence that the human visual system is not Euclidean. Watson <ref type="bibr">[ll]</ref>, postulated that the visual spaces are Riemann spaces to explain the interaction between the elements of the visual field. Using this he was elegantly able to explain a number of visual illusions and figural after effects, such as the Poggendorff, Enclosure, Muller-Lyer, Ponzo, Wundt-Hering, Orbison, Zollner, and Delboeuf illusions, and the Kohler, Willems, and Delboeuf figural after effects.</p><p>Each of the three terms on the right-hand side of the equation denotes an important concept. P(Causa1ity) is that prior probability that a set of features comes from a common cause. This in some way captures the meaningfulness of a scene. In an entirely random world this would be very low. In actual life this is quite high. P(0rganization) is the prior probability of organization being present among a set of features. The value of this decreases as the complexity of the organization increases. This captures the probability of accidental occurrence of the organization. P( OrganizationICausality) is the probability that we will observe an organization among a set of features given that they come from the same cause. This captures the fact that matter is coherent and behaves according to some fixed law (disclosed or yet to be disclosed). This value is high. Thus we see that we can safely infer causality from those organizations which have a very low prior probability of accidental occurrence and a very high probability of being exhibited by matter. Both terms must be considered. Considering one alone will not suffice. For example, a given organization may have a very low probability of occurrence owing to sheer complexity. However, if the probability of that structure being a part of an object it also low, it will still be less than useful. Similarly, there might be relations or organizations that occur frequently in real objects. But if their random occurrence probability is also high, then their significance is diminished.</p><p>Depending on the world we have, our set of salient organizations will differ. The Gestalt psychologists have found a set of properties which are important in the perceptual organization of images in our real world. They are proximity, continuity, similarity, closure, symmetry, and the new properties [ 131 of common region and connectedness (see Fig. <ref type="figure" target="#fig_4">3</ref>). These properties are exhibited by any salient organization and so we should search for groupings exhibiting these properties. The importance of proximity was demonstrated empirically by Brunswick and Kamiya [14] using several stills from a motion picture. The number of adjacent straight and parallel lines were counted along with their separation. The pairs of lines were then classified according what they represented in the scene. A correlational analysis on the separation gap between features on objects and the gap between objects yielded a significantly high correlation coefficient. This means that P(ProximityICausa1ity) is very high.</p><p>The types of organizations considered by the computer vision community are parallelism, rectangularity, and orthogonality (forms of symmetry), convexity, and continuity of edge contours. Patterns exhibiting any of the Gestalt principles are also significant. In summary, organization provides a very good indicator of common causality and the saliency of an organization depends on its probability of accidental occurrence and its probability of being part of an object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="111.">CLASSIFICATORY STRUCTURE: A PROPOSAL</head><p>The concept of perceptual organization can be applied to a number of cognitive activities, not just to vision. In vision, it can be applied at a number of stages and use different types of features. This state of affairs gives rise to some ambiguity in the term "perceptual organization." In this section we propose a classificatory structure for perceptual organization in computer vision strictly from a dimensionality, domain, and 1/0 point of view. We do not classify algorithms per se.</p><p>Perceptual groupings differ from one another with respect to the types of features they comprise and the dimensions over which the organizations are sought [l, p. 5211. We use these two factors as two axes in our classificatory structure. Fig. <ref type="figure" target="#fig_5">4</ref> presents the classificatory structure we advocate. It should become clearer as we proceed. One axis represents the dimensions over which organization is sought: 2-D, 3-D or 2i-D, 2-D plus motion, and 3-D (2;-D) plus motion. The other axis denotes the feature types to be organized stratified by layers of abstraction: signal level, primitive level, structural level, and assembly level. Although somewhat self explanatory, the definitions for these will become clearer presently. Thus one can talk of "2-D signal level" perceptual organization or "2-D + time structural level" organization and we in the computer vision community will have a common understanding.</p><p>The features to be organized are classified into four categories: signal, primitive, structural, and assembly. The signal level pertains to organizing the raw signal. For example, the gray level image in 2-D, the range image in 2$-D, the motion sequence in 2-D plus motion, and the range sequence in 3-D plus motion. The delineation of the next two types is based on the "dimensionality" of the feature with respect to the domain of organization. The criteria of dimensionality, although not mathematically strictly defined here, refers to the number of parameters that are needed to define a feature. For example, a contour segment is one-dimensional and a ribbon is two-dimensional.</p><p>The primitive level deals with organizing signal level extracted features into lower dimensional manifestations in the organizing field. For example, constant curvature segments and  Let us consider the layout of Fig. <ref type="figure" target="#fig_5">4</ref>. The information in each box of the matrix is arranged as follows. The first row lists some of the typical features to be organized at this level and dimension set. The second row lists some typical output organizations from modules at this level and dimension. The third row lists, by author names, some of the representative work in this area. None of these lists are exhaustive; this is just a sampling to convey the ideas. A more complete list of pertinent work follows in Section IV.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. 2-0 Organization</head><p>We first consider 2-D organization. At the signal level we are mainly concerned with organizing pixels or interest points into extended regions, edge chains, or dot clusters. Most of the work in edge detection and region segmentation fall into this category. Edge detection organizes points which are possible object boundaries by looking for those exhibiting certain photometric characteristics. Region segmentation groups pixels into regions using mainly proximity and similarity.</p><p>At the primitive level we organize edge chains and regions. Most of the work in contour segmentation falls under this category, in which we search for contiguous edge pixels similar in such attributes as curvature and contrast. The organized features are of dimensionality one. For example, constant curvature segments, segments broken at points of high curvature, and region boundaries.</p><p>The features produced at the primitive level are then organized at the structural level, where we look for structures which are of dimensionality two such as ribbons, comers, merges, polygons, closed regions, and strands among them. These basic structures are then organized at the assembly level to identify arrangements of these. So we may look for groups of rectangles and groups of ellipses. Incidentally, in all cases we take "assembly level" perceptual organization to be unbounded from above. That is, if the situation permits, this can continue indefinitely.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. 3 -0 Organization</head><p>In 3-D organization our input is a 3-D world map or a 2;-D sketch obtained by active ranging or by reconstructing the world from a stereo pair. Thus the signal primitives may be range points, or points in 3-D space. These are organized into elemental 2-D surface patches, surface discontinuities, or clusters of points in 3-D space. The work in range image segmentation falls into this category. The surface patches or clusters of points in 3-D space are then organized into coparametric surface patches or cluster groups at the primitive level. Fitting biquadrics and splines falls under this heading. At this level we will have groups of surface patches which possibly come from the same underlying object surface. At the structural level we organize the coparametric surface patches and their junctions into useful surface combinations which are 3-D manifestations, such as convex groups, parallel surfaces, and orthogonal surfaces. This helps us to form part hypotheses. These (possible) object parts are then organized based on proximity or other geometric constraints into object hypotheses at the assembly level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. 2-0 + Motion</head><p>Here we consider perceptual organization in a sequence of 2-D images. Signal level organizations will include moving streams of interest points, edges, or regions to create optic flow vectors, or edge point correspondences between frames. Finding correspondences can be looked upon as finding that organization having the least distortion, retaining the most "parallelism" among the image sequences [ 11. Primitive level organization here involves organizing the optic flow field into significant flow patterns like swirls, vortices, sinks, sources, and saddles. Geometric edge structures, like ribbons and polygons, which persist over time are also considered. At the structural level we consider organizations of these basic flow patterns to form part hypotheses. The assembly level organizes the above found structures into significant groups to form object hypotheses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. 3-0 + Motion</head><p>This is the area where the least amount of work has been done and we are necessarily a bit speculative. The concepts should crystallize as the field matures. Here we look for organization in 3-D space plus motion, as in dynamic vision. Organizations found here are highly significant because of the high dimensionality of the space. Our signal level primitives are moving points in 3-D space, or changing 2;-D or 3- D sketches. These are organized into 3-D optic vectors or segmented into surface patches having similar motion. The primitive level organizes them into optic lines, or coparametric surfaces so as to group surfaces hidden because of occlusions or missing because of noise. At the structural level we look for surfaces which exhibit regularity in 3-D shape and motion and group them. Assembly level organization forms groupings of articulated objects, or groups of objects exhibiting similar motion (like a flock of geese).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I v . PRIOR WORK REVIEWED IN CONTEXT</head><p>In computer vision, perceptual organization is important because the grouping of tokens reduces the combinatorial search inevitable in stereopsis, object recognition, and other forms of high level analysis. Recently, perceptual organization has been identified as one of the insufficiently emphasized areas in early computer vision and the US. High Performance Computing and Communications (HPCC) initiative also identifies perceptual grouping as one its four problem areas <ref type="bibr">[15]</ref>. Marr [ 161 suggested incorporating groupings based on curvilinearity into larger structures in the primal sketch. Grouping points into parameterized curves using Hough transforms [ 171 has received a lot of attention. Although the method has been generalized to handle a very large class of curves, it suffers from the fact that it ignores proximity.</p><p>Witkin and Tenenbaum [l] recognized the broad implications of perceptual grouping methods for computational theories in machine vision in providing an interpretation more from a common cause. Thus, the nonaccidental nature of some organizations ascribes significance to them. Perceptual organization can impart the robust, qualitative, and holistic nature of human perception to the frail, quantitative, and local character of most current algorithms in computer vision. They remark that the "hallmark of structure-oriented perception, from the most primitive levels, is the ongoing search for regularity and coherence, and attempt to explain the observed structure in terms of models at many levels."' The perceived structure provides us with a more meaningful description than do local surface characteristics.</p><p>An important observation that can made from this review is that the role of perceptual organization (in the true Gestaltic sense) has been very minor if not altogether absent in computer vision r e ~e a r c h . ~</p><p>The efficacy of perceptually significant structures in model based vision has been shown by Lowe and others. The general approach entails detecting simple organizations, like parallel lines and rectangles, followed by model based matching. In this scenario, the organizations impose constraints to prune the search tree. Although these are good, solid results, we feel that perceptual organization has an even wider role to play in vision and hope that this review will offer pointers to further research.</p><p>Clearly, not all categories in our classificatory structure have representative work to cite. Those categories lacking exemplars are simply omitted from the following discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. 2-0 Organization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I )</head><p>Signal Level: This level involves the most basic form of organization. Here our primitives (or tokens) may be points of high gradient, as in edge detection [MI- <ref type="bibr">[22]</ref>, or points of constant gray level as in region segmentation [23], <ref type="bibr">[24]</ref>.</p><p>Liou, Chiu, and Jain [24] use the term signal level perceptual organization to mean the partitioning of gray level or range images into regions. Since the term is very descriptive, we have adopted it for our classificatory structure and extend the notion to dynamic scene analysis, to which they allude, as well. Their contributions are threefold. First, they suggest a parallel, single pass algorithm in contrast to iterative region segmentation schemes. Secondly, they successfully integrate edge and region information. Thirdly, they explicitly recognize the low level process as a class of perceptual organization.</p><p>The starting point of their algorithm is an image or range map to which an edge detector is applied. A set of a- images are created by thresholding the gradient magnitude at a and identifying the connected components. The range of thresholds to use is either determined from the image or provided externally. These a-images are evaluated in parallel by fitting surfaces to the partitions and analyzing the residuals. Poor partitions are deleted, giving a set of filtered a-images which are inclusive "ORed" to produce the final segmentation, along with the fitted surface model. The algorithm is simple and has been shown to work on a wide variety of images. The in keeping with its qualitative and holistic character. They argue that spatiotemporal coherence or regularity is very entities, implying that such structures (almost always) arise Emphasis ours. 3This is not to say that work has not been done but that the full potential of perceptual organization has not been realized. We expound on this in the to Occur through the chance Of independent section on future work.</p><p>Gestalt principles of similarity, continuity, and connectedness are used in the organizational process. <ref type="bibr">Zucker [25]</ref> studied the problem of contour inference from a collection of dots, which is an instance of the problem of early orientation selection. Algorithms for extracting orientation information are devised by taking a differential geometric point of view. M u j a and Tuceryan <ref type="bibr">[26]</ref> propose a novel way to extract structure from dot patterns by integrating information from multiple constraining agents using probabilistic relaxation. The geometric structure of an arrangement of dots is represented in terms of the geometric properties of their Voronoi neighborhood^.^ Gestalt criteria, such as border and curve smoothness, serve as constraints in the process. The output is a set of perceptual segments of dots that group together and are classified as being interior to a region, bordering a region, or isolated. The strength of the approach, obvious from the results presented, derives partly from the use of a small number of adaptive thresholds.</p><p>Reed and Wechsler [28] use a joint spatial/spatial frequency representation, specifically the Wigner distribution, to do texture segmentation and Gestalt grouping. The use of frequency domain concepts to explain the Gestalt phenomena in visual perception is discussed in [29], <ref type="bibr">[30]</ref>. Their results are in good agreement with those predicted by the Gestalt laws for very simple test images. The findings of Beck, Sutter, and Ivy [31] also suggest that at least tripartite segmentation is primarily a function of the spatial frequency components. However, they point out that the effect of geometric attributes and spatial relations such as elongatedness, contour smoothness, and contour alignment on texture segmentation cannot be explained in terms of low spatial frequency differences and suggest the existence of a symbolic grouping process.</p><p>2) Primitive Level: This level involves the organization of curves into primitives which are manifestations of dimensionality less than two such as linear segments, constant curvature segments, and basic region primitives (like convex region boundaries). Fischler and Bolles [32] studied the problem of perceptual organization in the partitioning of curves. They concluded that the partitioning problem does not have a unique definition and depends on the purpose, data representation, and tradeoff between error types. They identified two important criteria for segmentation: the stability of the partitions under minor perturbations and the Gestalt principles of simplicity, conciseness, and completeness of the description. Based on these principles, they suggest two algorithms for curve partitioning. One of the algorithms analyzes the deviations of the curve from a chord that is iteratively advanced along it. The algorithm has two parameters: the length of the chord and the deviation tolerance. The second algorithm fits lines and circular arcs to segments. It selects a small number of seed segments from the curve, analyzes line or arc fits to them, and the good fits are then grown as far as possible. After a large number of seeds have been grown, a histogram of the start 4Voronoi neighborhoods are an elegant way to compute neighbors of points not only in a 2-D space but also for higher dimensions. However, the computational complexity grows with the number of dimensions. In fact it is and end points is used to select critical points, starting with the point that occurs most often. <ref type="bibr">Lowe [33]</ref> organizes curves at multiple scales of Gaussian smoothing and corrects for curve shrinkage before segmenting. The criterion for segmentation is the rate of change of curvature; this is form of the Gestalt principle of continuity. Thus, a contour with slowly changing curvature is classified as smooth and is not partitioned. Wuescher and Boyer 1341 study the partitioning of curves based on constancy of curvature using voting methods. Each point on the curve votes for a range of curvature and the constant curvature segments are extracted iteratively beginning with the largest.</p><formula xml:id="formula_0">O(d3 N rd/*l log N ) + O(dlVrd/</formula><p>Zucker, David, Dobbins, and Iverson [35] tackle the problem of curve detection in a novel fashion using the principle of continuity. They have two distinct phases: first inferring the tangent (orthogonal to the local gradient) field and then inferring a covering of the field using global splines. The discrete tangent field represents the trace of the curve together with a coarse estimate of the tangent and curvature at those points. The field is calculated by minimizing a functional of position, tangent, and curvature. In the second stage a spline covering of the tangent field is sought. The initial splines are those dictated by the tangent field. These later migrate according to an energy function which is minimized. The global curves are recovered to subpixel accuracy.</p><p>Straight line extraction in 2-D based on perceptual factors of proximity and continuity is presented by <ref type="bibr">[36]</ref>. They consider four important issues in the development of the algorithm. Firstly, the global structure be constructed from a local process. They advocate a locally parallel hierarchical grouping process. Secondly, that the grouping process should aid in data abstraction into an easily accessible structure. Thirdly, the procedure should be computationally efficient. Lastly, the organization should provide a multiscale geometric description of the image tokens. In their system symbolic line tokens are used and geometric relations such as collinearity, proximity, and similarity are used to control the grouping process. Each step of the algorithm involves linking, optimization, and replacement of token groups by new tokens having additional emergent properties. The number of levels in the hierarchy is controlled by the neighborhood size of each token considered at each step. The neighborhood size is controlled, in turn, by the amount of search one is willing to do at each step. As the grouping cycle proceeds, shorter line tokens are replaced by longer line tokens. In the linking process a global, directed link graph is created in which the set of vertices represent all the line segments in the image at the given scale, and the arcs represent the links. Each link denotes that the two line segments satisfy appropriate Gestalt properties. In the optimization step all paths in the line graph of length appropriate to the scale and containing the line under consideration are generated. Each path is a possible replacement hypothesis and is evaluated using a least squares fit. Each group whose fit error is low is replaced by a new line token in the replacement step. And the cycle continues. The starting point is a Laplacian image with gradient estimates at each point. The results are quite impressive with 6 to 7 hierarchical steps.</p><p>The above results are extended by Dolan and Weiss [37],</p><p>[38] using the same philosophy of hierarchical organization and principles of perceptual organization such as proximity and smooth continuation to identify cocurving and curvilinear structures. The system is iterative, at least in concept, over a range of perceptual scale, or increasing neighborhood size at every step. They construct an association graph under some compatibility relation defined between two tokens. As demonstrated, they link single pixels based on proximity and orientation to form a graph and enumerate all paths (of length 5 pxiels) of the subgraph within a perceptual window (of 0.5 pixels). These paths are called strands. The strands are classified into straight, inflection, cusp, corner, conic, and noise. These are then evaluated and replaced to create the next level. The identification of curvilinear structure at multiple scales is also investigated by Saund <ref type="bibr" target="#b32">[39]</ref>. He primarily uses the Gestalt principles of proximity and continuity.</p><p>3) Structural Level: This is the level that most people mean when they use the term "perceptual organization" and is the one where the most work appears. Line or region tokens found at the primitive level (straight lines, curved lines, and extended regions) are organized into a variety of 2-D shapes. The most sought after organization is parallelism. Others include rectangles, circles, convex strands, ribbons, closed figures, and symmetrical figures. Most often these organizations are used to index a model base to speed up recognition. Although the detection of more complex features is possible, very few attempts are reported.</p><p>Lowe, who has conducted much of the pioneering work on perceptual organization in machine vision [2], <ref type="bibr" target="#b33">[40]</ref>, did his most of his work in this category. In the SCERPO system, he used grouping to find collinear and parallel lines. He advocates an organization strategy based on a viewpoint invariance condition and the nonaccidentalness constraint. That is, the perceptual features should remain stable over a wide range of viewpoints and be sufficiently constrained so that accidental instances of particular spatial relationships are unlikely to arise. He ranks perceptual groups according to their significance. The significance of a grouping is inversely proportional to the a priori probability of the occurrence of that event. The negative logarithm of the probability, which is the amount of information gained by observation of that event, is a good measure of the significance. To build the grouping, one has to search all possible pairs of tokens and calculate the grouping significance. This is computationally expensive, so Lowe limits the search to a small neighborhood of the token in a parameter space. To increase the efficiency, he indexes his segments in a grid-like data structure according to the endpoint positions. The matrix can further be indexed according to orientation and length. Although he gains temporal efficiency, this scheme requires lots of storage space.</p><p>Henikoff and Shapiro <ref type="bibr" target="#b34">[41]</ref> use the significant relation of a triple, which is a convex strand of three line segments, to do model based vision via consistent labeling. McCafferty <ref type="bibr" target="#b35">[42]</ref> has made a unique contribution by formulating the grouping problem in perceptual organization as an energy minimization problem, which he then solves using simulated annealing. His formulation handles lines and regions in the same framework.</p><p>The energy functional involves terms related to continuity, similarity, closure, and proximity. The relative contribution of each term can be adjusted using multiplicative constants to allow for higher level interactions. Results on synthetic and simple real images are demonstrated. The idea is unique in the sense that it recognizes the need for the influence of higher level knowledge and has a means of doing so, even though it is not clear how this will be achieved in practice.</p><p>Mohan and Nevatia <ref type="bibr" target="#b36">[43]</ref> use perceptual organization concepts to detect and describe buildings in aerial images. They recognize the usefulness of the structural relationships made explicit by perceptual organization in complex image understanding. They call the emergent structures collated features, which are described by the generic shape of the target objects in the scene. All reasonable feature groupings are first detected and the promising ones are then selected by a constraint satisfaction network. They demonstrate impressive results on real scenes. Buildings are approximated by rectangles or combinations thereof. They first detect linear features, which are then grouped into parallels. Parallel collation with aligned endpoints triggers the formation of a U structure. Two U structures trigger the formation of a rectangle hypothesis. The search for these structures is done exhaustively. They extend the results to curved segments in <ref type="bibr" target="#b37">[44]</ref>. Cocurvilinearity is detected by imposing continuity and proximity constraints and exhaustive search. This algorithm is used by Chung and Nevatia <ref type="bibr" target="#b38">[45]</ref> in their hierarchical stereo system with explicit occlusion detection. A hierarchy of edges, curves, and ribbons are created from each image and matched.</p><p>Structures such as rectangles are important cues for buildings in aerial images and are used in several implementations, for example <ref type="bibr" target="#b39">[46]</ref>, <ref type="bibr" target="#b40">[47]</ref>. In <ref type="bibr" target="#b40">[47]</ref> the search for rectangle hypotheses proceeds by local contour tracing techniques. Shadows are used to confirm hypotheses and estimate the height of the buildings. In <ref type="bibr" target="#b41">[48]</ref>, Heurtas et al. detect runways in aerial images. They form hypotheses by looking for extended rectangular shapes, or extended strips. These are verified by looking for expected markings and the like.</p><p>Computing salient structures from local characteristics is suggested by Sha'ashua and Ullman <ref type="bibr" target="#b42">[49]</ref> using a locally connected network. The output is a saliency map, a representation emphasizing conspicuous locations. The idea is to model preattentive vision. To restrict the computational demands, only local structural saliency is considered; global saliency such as symmetry is ignored. The local saliency measure depends on two factors: the total length of the curve and its smoothness. The global optimum is obtained by recursive local optimization, similar to dynamic programming. Each pixel in the image represents a computational element with k local communication links. The final output is a set of smoothed traced curves with gaps filled in and associated saliency measures. As is evident, the Gestalt principles of proximity and continuity play a large role in this formalism.</p><p>Horaud et al. <ref type="bibr" target="#b43">[50]</ref> describe a method to compute, by exhaustive search, an intermediate level description in terms of curves and rectangles by grouping image features into abstract structures useful for object recognition [2], or for structural stereo <ref type="bibr" target="#b44">[51]</ref>, <ref type="bibr" target="#b45">[52]</ref>. Their vocabulary of description includes linear and curved contours, junctions, and local symmetries like parallels, ribbons, and parallelograms. The input to the process is a list of straight line segments.</p><p>Nitzberg and Mumford <ref type="bibr" target="#b46">[53]</ref> organize regions to detect occlusions using energy minimization. The energy functional is biased toward constant, larger regions with smooth boundaries. The algorithm incorporates three stages: finding edges and T junctions, hypothesizing combinations, and minimizing the energy functional combinatorially. They demonstrate the potential to detect occluding surfaces in real images and on Kanizsa's triangle. Williams <ref type="bibr" target="#b47">[54]</ref> detects occluding contours using linear integer programming over a set of constraints. From detected lines, corners and collinear lines are identified. Nearby endpoints are joined using virtual lines, and the intersections of virtual lines are also identified. Each corner and vertex has a fixed number of constraints and the optimal solution is found using the Simplex algorithm. The constraints derive from physical validity and involve occlusion polarity, consistency with the image data, and human visual preferences such as that for closed, convex figures. Impressive results are demonstrated on simple Kanizsa patterns. How well it performs in real images is not discussed.</p><p>Rearick, Frawley, and Cortopassi <ref type="bibr" target="#b48">[55]</ref> organize binary regions into cusps, loops, and elongated regions. At the next level they look for adjacency of different types, and then for unions of structures. They demonstrate results only for synthetic occluded objects. They speculate that intelligent behavior is more likely to originate from simple grouping processes than from previously non-existent symbolic representations. In <ref type="bibr" target="#b49">[56]</ref> Quan and Mohr use perceptual groups to hypothesize matches in two motion sequences. The organizations they compute are skewed and Euclidean parallelism, and collinearity; they work with straight lines.</p><p>Kanatani <ref type="bibr" target="#b50">[57]</ref> proposes a hierarchical model to detect geometric configurations by first hypothesizing a configuration and then determining how much the original edge must be displaced to support it. It is not clear how the hypotheses are formed. Among other work related to structural level perceptual organization is a rich body of literature on symmetry detection, e.g. <ref type="bibr" target="#b51">[58]</ref>- <ref type="bibr" target="#b56">[63]</ref>. Van Goo1 et al. <ref type="bibr" target="#b57">[64]</ref> report a novel way of detecting similarities in a curves using an "arc-length space."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Assembly Level:</head><p>The assembly level builds on the structural organizations found in the previous level and extracts organizational information about them. Typically this will involve finding organizations of rectangles, or ribbons, or closed figures. Organizations such as rectangles with aligned symmetry axes are very significant, for example as an indicator of city blocks in aerial images. Little work has been done in this regard. We should also point out (again) that assembly level organization is unbounded from above. This is mostly a language restriction. In our lexicon, an organization of lines of rectangles into blocks of lines of rectangles (for instance) would be just an additional layer of assembly level organization.</p><p>Although they do not use the term, the work of Rao and Nevatia <ref type="bibr" target="#b58">[65]</ref> is a typical example of assembly level perceptual organization. They search for 2-D ribbons among edge segments. The symmetry of ribbons renders them perceptually significant and a useful descriptor of shape. The algorithm involves two steps: forming ribbon hypotheses from edge fragments, and their verification using sophisticated geometric reasoning methods. Using the ribbons a scene graph is constructed and ribbon intersections are found by searching for cycles in the graph. They then look for supercycles, or combinations of cycles, that correspond to a group of joints in the physical object. Thus, they form compound object hypotheses. Impressive results on real and synthetic data are reported.</p><p>Rosin and West <ref type="bibr" target="#b59">[66]</ref> extract surfaces of revolution by perceptually grouping ellipses. First, ellipses with parallel axis of symmetry are grouped together. Then the Hough transform groups those ellipses whose centers lie on a straight line. The confidence in the resulting grouping is assessed by looking for line segments or edge pixels that are equidistant from the center line.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. 3 -0 (23-0) Organization 1) Signal Level:</head><p>This level organizes 3-D or 2;-D points, as in range image segmentation. A lot of work is being done in this area; we can mention only a few examples. The common thread among the work is that they organize range points into regions which are constant according to some parameter, for example curvature. Brady et al. grouped range points into regions using local curvature properties. Besl and Jain <ref type="bibr" target="#b60">[67]</ref> also used curvature to form seed regions and then fitted variable order surface models to grow the regions.</p><p>2) Primitive Level: Work at this level involves organizing signal surface patches into primitives. Mirza and Boyer <ref type="bibr" target="#b61">[68]</ref>, however, chose biquadric patches as their primitives. The segmentation is done using robust statistical techniques. The method has a certain elegance in that parameter estimation, surface discontinuity detection, and the joining of coparametric surfaces are all done together.</p><p>Parvin and Medioni <ref type="bibr" target="#b62">[69]</ref> solve the problem of boundary contour completion in range images. Though they do not explicitly cast it as a perceptual organization problem, they solve an organizational problem with good results. Pointwise detection of surface discontinuities such as occlusion and orientation changes lead to broken and open boundaries. Before any meaningful analysis can be done, we need closed boundary contours. The construction of closed boundaries is formulated as an energy minimization problem involving three terms: one for the binding energy between two compatible curve segments, a second denoting the binding energy between a curve segment and a junction, and a third capturing the binding between two curve segments to form a new vertex. A dynamic network finds a suboptimal solution to the energy minimization problem over the whole image. The network solves a set of differential equations capturing the changing importance of different features as the solution evolves. The idea is to derate contributions from features which do not take part in the organization as the network iterates. This is modeled as a first order system with time constants determining how the weights change. Thus, we can change the importance of, say, long segments over short segments by choosing a time constant proportional to their lengths. The perceptual significance of corners is also appropriately encoded in the system. The system can be said to implement the Gestalt principles of proximity, continuity, and closure. The results on range images are impressive. The enclosed closed regions are described using various surface descriptors and matched with a range image of the same scene from another view to develop a 3-D model.</p><p>3) Structural Level: Work at this level groups surfaces into 3-D organizations. Pentland <ref type="bibr" target="#b63">[70]</ref> suggests using superquadrics. He argues that they capture the physical regularities of the objects and describes the perceptual organization that people impose on the world. The claim is substantiated with examples and a method to compute the parameters; the idea is certainly promising. Fisher <ref type="bibr" target="#b64">[71]</ref> uses an intermediate representation, called surface clusters, to bridge the conceptual distance between the segmented image surface and the objects, to help focus on distinct regions in the image and to gain a computational advantage. The work can be said to span both the structural and the assembly level. The surface clusters are formed by organizing surface patches produced by the primitive level organization. The process involves three steps: locally classifying surface region connectedness, forming primitive surface clusters from connected groups, and merging primitive clusters. The adjacent surfaces are classified as sharing a connecting or segmenting boundary. Connectivity is assumed to hold across convex shape boundaries and not across concave and crack shape boundaries5 Connectivity also does not hold across occlusions except in the case of laminar surfaces.6 To form clusters a graph is built with the surface patches as the nodes and the links denoting connections or boundaries. Connected components in the graph form our primitive surface clusters. These surfaces are grouped in two stages to form the final organization. In the first level primitive clusters are grouped into equivalent depth clusters. To this end, he forms a graph with the primitive clusters as the nodes and the links denoting the relation that the primitive clusters have surfaces which are mutually occluding or a pairs of contiguous surfaces which are segmenting. The connected components of this graph form the equivalent depth clusters. In the next level, the equivalent depth clusters are then grouped to form depth merged surfaces in a similar manner using a graph constructed by considering occluding relationships between them and considering all subsets of the nodes of each of the connected components. These surface clusters form object level chunks. Thus, this work also spans assembly level organization. The organization is achieved, as we can see, based on the Gestalt principles of proximity and surface continuity embedded in the relationships of convex, concave, or occluding surface junctions.</p><p>Fisher's work can be considered an extension of work by others, including Sugihara <ref type="bibr" target="#b65">[72]</ref> and Kak et al. <ref type="bibr" target="#b66">[73]</ref>. Fisher's formulation is more clearly Gestaltic. One of its drawbacks, as Crack boundary between surfaces are coincidental alignments of surfaces 6Laminar surfaces are thin surfaces which may occlude each other but be or part of a flush contact boundary. part of the same surface, e.g., a hollow cylinder. acknowledged by Fisher <ref type="bibr" target="#b64">[71]</ref>, is the large number of surface clusters produced. We feel that these can be reduced by considering other Gestalt criteria such as symmetry in the form of parallel or orthogonal surfaces, and closure.</p><p>4) Assembly Level: As mentioned above, Fisher's work <ref type="bibr" target="#b64">[71]</ref> also contains elements of assembly level organization. Little else currently appears in this category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. 2 -0 Plus Time Organization</head><p>Although the importance of motion in vision was recognized by the psychologist Gibson <ref type="bibr" target="#b67">[74]</ref>, <ref type="bibr" target="#b68">[75]</ref>, who coined the term "optic flow," and by numerous computer vision researchers, the role of perceptual organization in image motion analysis has been minimal. This contributes, we feel, to the fragile nature of some algorithms. Perceptual organization will shift the emphasis from a quantitative recovery of structure to a more reliable and fast qualitative recovery of structure. Murray and Buxton <ref type="bibr" target="#b69">[76]</ref> provide an excellent study of the state of art in motion. The reader is referred there for details; we will mention work relevant to perceptual organization.</p><p>Murray and Buxton <ref type="bibr" target="#b69">[76]</ref> recognized the very important role of motion segmentation as a precursor to recovering structure from motion in that it identifies groups of motion vectors in the image which arise from a single moving entity in the scene.</p><p>They observe that ". . . segmentation using motion properties alone proves to be a difficult and, we suggest, largely unsolved problem in computational vision." We feel that the automatic grouping of scene motion vectors can provide a good starting point. Studying patterns in the motion field can definitely reveal various qualitative behaviors. Consider the motion of specularities <ref type="bibr" target="#b70">[77]</ref> or of external boundaries <ref type="bibr" target="#b71">[78]</ref>. Borjesson and Hofstein <ref type="bibr" target="#b72">[79]</ref>, [80] studied the perception of three dot motion patterns. They concluded that translatory motion in depth is evoked by the concurrent (convergent/divergent) relative motion of the points while rotation is induced by parallel relative motion. They also found that under certain conditions the visual system is able to split up a complex motion pattern into simple relative patterns. These studies indicate the importance of organization in visual motion perception.</p><p>I ) Signal Level: Signal level organization in the 2-D plus time environment involves the computation of optic flow, point wise or feature wise, Point wise flow estimation techniques typically involve constraints like smoothness, which is related to the Gestalt principle of continuity. The final organizations are optic vectors or lines.</p><p>2) Primitive Level: At this level one organizes the optic lines into more meaningful structures. Verri and Poggio <ref type="bibr" target="#b74">[81]</ref> argue for a qualitative description of optic flow and suggest descriptions in term of saddles, sinks, sources, and periodic attractors. They draw analogy with dynamical systems and point out that these features are structurally stable. This implies perceptual significance. A good example of organization in qualitative vision is the optic flow divergence pattern's use in collision avoidance <ref type="bibr" target="#b75">[82]</ref>. Divergence patterns are highly symmetric and hence very significant. Carlsson <ref type="bibr" target="#b76">[83]</ref> studied the information content of geometric structures in retinal flow fields. The planarity constraint along with tracking made it possible to compute unique values for the direction of motion and surface orientation considering just the symmetry property of the flow field.</p><p>Hoffman and Flinchbaugh <ref type="bibr" target="#b77">[84]</ref> infer motion by organizing moving dots using the planarity assumption. First, they divide the dots into groups of two or three elements. The planarity assumption, or the assumption that the dots are moving in a plane, is used to test each group for planar motion. These local groupings are combined to form a globally consistent interpretation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>v. COMPUTATIONAL TECHNIQUES</head><p>In the previous section we saw how the work in perceptual organization can be classified based on the types of features being organized and the domain of organization. Works which are classified together can be distinguished by computational technique. Detecting organization is a very difficult problem. An exhaustive enumeration of all possible arrangements of perceptual tokens is computationally hopeless and intellectually very unsatisfying. A variety of techniques have been proposed to compute perceptual organization. These differ in their applicability, from the highly specialized and domain dependent to the very general. In this section we outline the formalisms of some of the different approaches; the reader is directed to the original work for more detail. This selection is intended to sample the spectrum of approaches but is not an exhaustive review. For each technique we chose a representative work in 2-D structural level organization, where most of the work in perceptual organization has been done. We might add that there is a rich body of work in signal level organization with very similar techniques. For example, the relaxation method is used not only at the structural level but also in signal level organization (e.g., in region segmentation). Since reviews of work at the signal level may be found in various surveys of edge detection, region segmentation, optic flow [ S I , and range image segmentation 1671, we do not consider them here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Group Theory</head><p>Palmer <ref type="bibr" target="#b79">[86]</ref> proposes a unified framework for perceptual organization, using the concept of local invariance over a group of Euclidean similarity transformations. This is conducive to a parallel implementation and is constructed from many spatial analyzers that are related to each other by similarity transformations. He recognizes that shape constancy is one of the enigmatic problems of perceptual organization. Two figures differing only in position, orientation, size, sense (reflection), or some combination of these are defined to have the same shape. Euclid built shape constancy into his geometry in the form of "similar" figures. Palmer suggests detecting shape constancies using Euclidean similarity group transformations, which can easily be extended to 3-D projective transformation groups. The properties that are invariant with respect to these transformations are the set of invariant properties that can be used to recognize objects [87], 1881. Thus angle size, relative length of lines, number of lines, number of angles, closedness, group. The figural goodness of an organization is measured by its transformational invariance. So good figures have greater transformational invariance (symmetry) than do bad figures. The problem with such a measure is that it lays too much stress on symmetry and we noted earlier Pragnanz is more than symmetry.</p><p>The laws of Gestalt organization can also be cast as group transformations. The law of proximity is formulated as the grouping preference with the ordering imposed by a metric on a set of local translations in the pattern. Organization by similarity can also be cast in similar fashion as a group of transformations involving rotation, dilation, reflection, and translation. The elements (tokens) having similar translational distances among themselves are grouped together. This is akin to visualizing the 2-D stimulus array as being projected into a higher dimensional space that includes factors other than position such as color, size, orientation, etc. The elements having similar features will be clustered in this space. The concept of transformational distance is extended to cover factors such as continuity, by considering pairs of points. Each pair of points, with an associated position and direction, is projected into a position and orientation space. All the points lying on a continuous contour will tend to be close together in this space. The use of a temporary 3-D space (the rhospace) is also suggested by Chen and Hsu 1891 to explain line continuation in human visual perception. <ref type="bibr">Leyton [90]</ref> postulates that a highly constrained form of analyzer structure, based on a transformation and an algebraic decomposition of that group, can explain a number of perceptual organization phenomena. In some ways this is similar to that of Palmer, where transformation groups are used to analyze patterns composed of many individual shapes. However, Leyton uses this idea to analyze highly complex shapes, providing a theory of perceptual shape encoding. Given a stimulus set, it is encoded by an analyzer system structured by the transformation group composed of three subgroups of a true deformation, shear, and rotation and the group's algebraic structure constitutes the perceptual organization of the stimulus. The usefulness of this formalism arises from its simplicity and elegance. By extending it to 3-D it could be used in machine vision to encode various shapes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Coding Theory</head><p>There have been attempts to reduce some of the Gestalt principles to quantitative information-theoretical statements to provide a way to compute them. The percept that can be encoded with the fewest parameters will be preferred. Regular, symmetrical configurations are, from the standpoint of information theory, redundant and so can be encoded economically.</p><p>Leeuwenberg <ref type="bibr" target="#b84">[91]</ref> proposed some measures based on coding theory to measure structural information and to predict the saliency and the similarity between patterns. Figural goodness is reduced to figural simplicity, implying that perceptual organization is guided by a "minimal coding principle." One of the arguments against information-theoretic approaches in connectedness, and the like are all invariant over the similarity perceptual Organization is that a universal set of codes which works on all figures has not been found and thus the results obtained are different. Leeuwenberg demonstrates impressively high correlation between the subjective complexity and the calculated structural information content of patterns according to his scheme. Even the subparts of the codes of the total figure appear to correspond with subparts that the subject conceives of in the total figure. He uses the coding of the figure to determine its distinctive salience and contrast salience. Distinctive salience is the contrast between the features of a pattern with respect to those of the background pattern and contrast salience is the difference between alternative interpretations of the same pattern. Based on his codes he also measures the similarity between two patterns. These measures are taken as indicative of structural "goodness" or Pragnanz and can be used to rank the perceptual structures hypothesized in machine vision. Complex patterns are described as composed of simple patterns, thus implying a hierarchical nature of organization. The lower most level is usually angles, intersections, and lines or curves. Pomerantz <ref type="bibr" target="#b85">[92]</ref> deduces from a set of controlled experiments that configural features such as angles and intersections may be the primitive units of visual pattern analysis.</p><p>Barnard <ref type="bibr" target="#b86">[93]</ref> suggests a computational solution to the problem of interpreting an image as a projection of rectangular forms. The Gestalt justification for the search of rectangular forms is that they can be described using an orthogonal basis. An orthogonal basis can be specified as two vectors and the handedness and is symmetrical, whereas complete specification is needed in the general case. <ref type="bibr" target="#b87">[94]</ref> suggest computing qualitatively significant perceptual groupings by the repeated application of rules. They suggest a format for describing the rules, image structures, and relationships to which they apply. A hierarchical organizational structure is suggested with increasing neighborhoods. To control the combinatorics, only "interesting" structures are passed to the next higher level. Interestingness is evaluated by considering size, contrast, extent, type of similarity, and the number of groupings the structure is associated with. They suggest the concept of a label plane associated with different structures. A label plane is an abstract image in register with a sensor surface where each pixel consists of a list of pointers to all objects which occur at and occupy that pixel. As new groups are formed they deposit their points in the label plane according to their spatial arrangement. The algorithm starts with an initial arrangement of groups on the label plane which may be extracted from edge detection, motion and stereo, or shape description processes. Similarity relationships between objects are created, based on local or global features and relations. These are sorted according to interestingness. Grouping rules are applied to the most interesting to produce new groups, or merge groups. A nice feature of this algorithm is that they do not use a single measure for shape significance, instead they use various measures such as group membership scores, number of attributes of the group, time since the group was created, and so on to prune the groups. This framework is very useful in building a rule based perceptual organization system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Rule Bused</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lawton and McConnell</head><p>Nazif and Levine <ref type="bibr" target="#b88">[95]</ref> built an expert system for low level image segmentation. This enabled them to bridge gaps and to deal with the fragmentation of edge features from noise. To this end they stored knowledge about low level processes and a set of control rules. Metarules were used to infer the order in which the knowledge rules were applied and attention rules determined the processing path. The processing strategy is controlled by still higher level rules. Although they do not explicitly use the term, their rules incorporate the essential features of perceptual organization such as collinearity and parallelism. The method has the disadvantage of requiring that rules be specified for all sorts of special cases, which is generally tedious and error prone. Such systems do not generalize well; they tend to be very much domain dependent and representation specific.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Frequency Methods</head><p>Frequency domain methods in vision are primarily motivated by neurophysiological evidence for frequency selective cortical cells. The applicability of this method has been restricted to texture groups. Perceptual organization in textured images can be looked upon as low pass filtering <ref type="bibr">[31]</ref>. However, <ref type="bibr">Janez [29]</ref> has evidence for high frequency components in grouping. One of the disadvantages of frequency based methods is that they are global in nature, contrary to the fact that visual discrimination is a more local process. Besides, as Reed and Wechsler [28] point out, Gestalt grouping depends on both shape similarity (a spatial property) and organization (a spectral property). This suggests joint spatial and spatial-frequency characterizations of the 2-D signal. These are methods that indicate frequency content in localized spatial regions and include techniques like the spectrogram, difference of Gaussian representations, Gabor representations, and Wigner distributions. Reed and Wechsler <ref type="bibr">[28]</ref> argued that the Wigner distribution has superior resolution capabilities.</p><p>Reed and Wechsler [28] proposed a four stage algorithm. The first stage is a preprocessing antialiasing step. Next is the computation of the Wigner distribution followed by a stage of data reduction in which we select the frequency content at the frequency containing maximum energy for each pixel. The last stage is low pass filtering implemented as relaxation followed by grouping of similar valued pixels. Results on textured images were demonstrated. They also show that the results are in conformity with some of the Gestalt principles. <ref type="bibr">Beck et al.</ref> demonstrate the correlation between human segmentation of tripartite textured images and the outputs of a bank of 2-D Gabor filters, which are direction sensitive Fourier transforms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. EnergylProbubilistic Optimization Methods</head><p>Sometimes perceptual organization is formulated as an energy minimization problem. This has origins in the early Gestalt days. One the mechanisms suggested to explain perceptual organization was based on an interacting electric field settling to an optimal state. The idea drew inspiration from the "soap bubble" solution of the shape. The idea of an Fig. <ref type="figure">5</ref>. Note the competing organizations that are observed, analogous to an optimization problem stuck in a limit cycle.</p><p>electric field failed to gain much acceptance because of a lack of neurophysiological support. But mechanisms based on the minimization principle have proven very successful in computing perceptual organization in computer vision, where one is not restricted by neurophysiology. The presence of an underlying optimization process in perceptual organization is particularly evident in the Marroquin pattern (see Fig. <ref type="figure">5</ref>) where competing organizations are observed. Typically, one associates energies to binary interactions of tokens to capture their compatibility in terms of various Gestalt criteria and tokens are linked so that the total energy is minimized. The method has the advantage of computing global percepts from local interactions. It may be pointed out that the method can be used at each level of a hierarchical formulation. We consider energy and probabilistic formulations together because of their equivalence in some cases, e.g., Markov Random Fields and Gibbs' energy distributions (961. In a probabilistic formulation local interactions are modeled as low order conditional probabilities or Markov Random Fields. The optimization of the total energy or probability can be done in a number of ways. We review the best known methods next. Some of the less investigated techniques like genetic algorithms <ref type="bibr" target="#b90">[97]</ref> are not considered here.</p><p>1) Neural Networks: Grossberg and Mingolla <ref type="bibr" target="#b93">[98]</ref> hypothesize a system of neural dynamics to explain a wide variety of perceptual grouping and segmentation phenomena. Their hypothetical system has three components: a boundary contour system, a feature contour system, and an object recognition system. The boundary contour system is responsible for preattentive perceptual grouping to generate a coherent boundary structure. It consists of two subsystems: one sensitive to the image contrast, which forms an input to the second, a competitive-cooperative network encoding spatially short range competitive and long range cooperative interactions between edge elements. Feedback between the competitive and cooperative stages synthesizes a global context sensitive segmentation from among the many possible groupings of local features.</p><p>Neural networks can be used to solve parallel optimization problems. Details regarding the formulation of the method and its convergence can be found in the neural network literature <ref type="bibr" target="#b94">[99]</ref>- <ref type="bibr">[102]</ref>. The method is used in computer vision as follows.</p><p>A preprocessing stage first extracts primitive symbolic tokens.</p><p>The interactions (support or conflict) among them are modeled using energy values and the problem of finding a set of stable perceptual groups is posed as an energy minimization problem. The neural network is used to find a local energy minimum. To illustrate the method we concentrate on the excellent work of Mohan and Nevatia <ref type="bibr" target="#b36">[43]</ref>.</p><p>As discussed earlier, Mohan and Nevatia find organizations such as lines, U structures, and rectangles by constrained search. This detection stage generally produces a large number of supporting and conflicting groupings (or collations). The neural network helps to select the best subset of these. Let us call the original set of organizations, the initial set of hypotheses, H = {h,}. To each hypothesis or organization we assign a confidence value, 0 5 V ( h , ) 5 1, which changes with iteration and settles to a final value. The binary interaction between organizations, or hypotheses, is modeled using the energy function, TZ3 KV, . TZ3 models the type and strength of the interaction; T,, &gt; 0 for supporting interaction and Tz3 &lt; 0 for conflicting interaction. The "input" to each hypothesis, denoted by I ( h , ) = I,, is the sum of the evidence for that organization based on photometric and geometric information.</p><p>The "energy" of a singleton hypothesis is modeled as I,V,, measuring the contribution to the total evidence from hypothesis h,. Finding the best set of hypotheses is now formulated as the assignment of confidence values V, which maximizes T,,V,v, + LV,.</p><p>(2)</p><formula xml:id="formula_1">2 3 z</formula><p>The double sum represents the total energy of interaction and the second is the sum of the energies in the individual hypotheses. This is solved using the Hopfield network. Each of the organizations, or hypotheses, is a node or "neuron." The relationships between the organizations define the link weights between the nodes. The link weights depend on the type of organizations connected and were determined empirically. To avoid cases where an organization is selected because it is the only grouping of its component edges, a "winner take all" type of network is superimposed on the Hopfield net. For more detail the reader is referred to <ref type="bibr" target="#b36">[43]</ref>. In <ref type="bibr" target="#b37">[44]</ref> they use the same formalism to find the best groupings of ribbons. Parvin and Medioni <ref type="bibr" target="#b62">[69]</ref> use neural networks to find boundary groupings in range images. The interaction variables are corners, junctions, and segments. The constraints among them are captured using link weights, as before. However, they use another nice aspect of neural networks: the time constant. In a neural network, each node can be shown to solve a first order differential equation with an associated time constant and the node response can be modeled as a solution to a differential equation. The previous work used the same time constant for all organizations. However, Parvin and Medioni use a different value for each organization depending on the length of the segments involved. Longer segments compete longer in the network, while shorter segments settle to equilibrium faster. They achieve impressive results on range images.</p><p>2) Relaxation Labeling: As discussed earlier, Ahuja and  Tuceryan [26] propose an efficient algorithm to organize dot patterns. First the geometric structure is represented in terms of the Voronoi neighborhoods of the dot patterns. Geometric properties such as compactness, area, elongation, eccentricity, distance measure, squeezedness (density), and the Gabriel measure for the neighborliness (dependent on the number of neighbors and how far they are) of a point are calculated for the Voronoi polygons. The goal is to label each as: interior of a region, border of a region, curve, or isolated dot. This is achieved through the cooperation of a number of "expert" modules over three levels. At the first level, the interior identification, border identification, and curve identification modules independently label the dots as being in the interior, on the border, or belonging to a curve, respectively. At the second level we have the interior correction and border correction modules which use the outputs of the interior and border modules to correct the labels based on global consistencies. In the third level a module combines the interior and border results. Another module labels the curves based on the curve identification module and border correction module results to form the final interiorborder combination results.</p><p>Each module uses probabilistic relaxation [ 1031 for inference. The initial probability vector assignments for the dots are computed based on the local compatibilities and the initial labeling is done based on the Voronoi polygon attributes. The interior identification is formulated as a relaxation process on the labels INTERIOR and NONINTERIOR. Similarly, the border identification module labels dots as BORDER and NONBORDER and so on. The correction processes uses the labels CHANGE or NOCHANGE. The reader is referred to <ref type="bibr">[26]</ref> for the actual assignments of compatibilities in the relaxation process. The probability updating formula is the one suggested in <ref type="bibr">[103]</ref>. Impressive results are shown on various dot patterns. The algorithm does not use a large number of thresholds and the authors suggest explicit ways of calculating them.</p><p>3) Regularization: Trytten and Tuceryan [lo41 describe an algorithm based on energy minimization to perform curvilinear grouping of incomplete edge contours or edgels. This is a very important task in intermediate level vision because most high level algorithms expect complete, closed contours whereas low level algorithms usually give fragmented edge contours or edgels. The algorithm completes and smooths boundaries and detects discontinuities in curvature. A Delaunay graph of all the edge points is first created and only that subgraph corresponding to the edgel end points is kept. This defines a neighborhood for the endpoints. This is used to hypothesize about possible extensions of an edgel. These are evaluated using an energy term encoding local curve smoothness and discontinuity. The edgels are sorted according to their length and we start with the largest. The edge contour under consideration is grown like a crystal, by choosing the neighboring edgel, based on the Delaunay subgraph, which decreases the total fit energy the most. The process continues until it cannot decrease the energy any further. A new edgel is then considered and the process of crystal growing repeats. The algorithm has reasonably good performance but, as the authors point out, has problems in detecting obtuse angles. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Simulated</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Graph Theory</head><p>The use of graphs to extract Gestalt percepts was proposed by <ref type="bibr">Zahn [109]</ref>. He used a family of graph theoretical tech: niques based on the minimal spanning tree to describe several kinds of dot clusters. Although the results were demonstrted on 2-D dot clusters, the method is applicable for higher dimensions or general metric spaces. The minimal spanning tree captures the local neighborhood of a point. Different neighborhoods are possible for each point: k nearest neighbors, absolute distance neighbors, and Voronoi neighbors. <ref type="bibr">Ahuja [110]</ref> offers a good review of the various neighborhood definitions.</p><p>Graphical representations are particularly suited for perceptual organization. The explicit nature of the stored information allows for the ready extraction of higher order features. Sarkar and Boyer [ l l l ] , <ref type="bibr" target="#b103">[112]</ref> use such a representation to build a hierarchical representation of the scene. They create graphs for the Gestalt criteria: proximity, continuity, common region, and closure using voting methods. Extracting various graph structures such as cliques, cycles, paths, and trees gives continuous lines, closed boundaries, or continuous curves. These latter organizations are integrated using a class of geometric knowledge base called Perceptual Inference Networks (PINS) <ref type="bibr">[113]</ref>, <ref type="bibr">[114]</ref>. The PIN is based on Bayesian Networks and encodes information about geometric organizations. It hypothesizes organizations in the presence of uncertain information and integrates multiple sources of information. For example, a rectangle can be defined as an organization which has the features of parallelism, closure, and four orthogonal corners. The confidence in a rectangle organization will vary with the features that are detected. The PIN is used for such inferences.</p><p>Huttenlocher and Wayner [ 1151 use graph representations to extact convex edge groupings. Convexity, as pointed out earlier, has been found by psychologists to have very high perceptual significance and hence is a good form of organization to look for. They start with linear edge segments and triangulate to get a local neighborhood definition of the end points. In this respect they are similar to Trytten and Tuceryan Section 1V-A-37 the grouping problem in perceptual 7The dynamic nature of perception is evident from the Marroquin pattern organization as an energy minimization problem, which he [16]. Some believe it to be the result of multiple minimum "energy" states.</p><p>[104]. However, the latter work with curvilinear segments and not just linear segments. From the local neighborhood graph a local convexity graph, with the segments as nodes, is constructed by keeping the best convex pairs8 of neighbors using a cost function based on distance and convexity angle. This ensures, as the authors show, that each vertex can belong to at most two cycles. A path in the local convexity graph will correspond to convex chains, and cycles give convex polygon hypotheses. The work demonstrates the power of graphical representations in encoding spatial relationships and extracting organizations. In [ 1161 Wayner discusses interfacing the above convex grouping module with a model based matching module. The grouping module provides the model base with a manageable number of hypotheses to consider.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. NEW AREAS OF RESEARCH</head><p>From this brief review on perceptual organization in computer vision one observes that only a few of the Gestaltic principles have been effectively used in most of the work. Only the principles of proximity, continuity, and similarity play a major role. Although the importance of symmetry has been recognized and a significant amount of research done, it has rarely been used in conjunction the other Gestaltic principles. There is a need for research into frameworks for integration of various Gestaltic cues including nongeometric ones like simplicity and cohesion. McCafferty <ref type="bibr" target="#b35">[42]</ref> provides such a framework based on energy minimization. <ref type="bibr">Sarkar and Boyer [113]</ref>, [114] use a geometric knowledge base for such an integrative purpose. The knowledge base, in the form of a Bayesian network, not only helps in the integration of different cues in the presence of uncertain information but also incorporates experimental knowledge. However, the automatic learning of an organization knowledge base is still an open issue. Lastly, the use of intention, attention, and attitude is lacking in perceptual organization work. We feel these criteria to be important in organizing motion data in an active or task based vision framework.</p><p>The classificatory structure of perceptual organization work also suggests many new subareas. In the classification table (Fig. <ref type="figure" target="#fig_5">4</ref>) we see that the blocks towards the upper right corner are "empty" as opposed to those to the lower left. More work needs to be done in these "empty" areas. Research in range image segmentation has been mainly in the area of signal level and primitive level organization. Although there is some work in structural and assembly level organization, more needs to be done. The structural level will involve finding useful surface combinations like parallel surfaces, vertices, and convex junctions. The assembly level will organize these surface clusters into meaningful parts based on the Gestalt principles.</p><p>Research on perceptual organization in motion sequences has been minimal. Except for some work in signal level organization, work at the primitive, structural, or assembly level is lacking. Extracting organizations in the optic flow field will help in fast navigation without explicitly solving for the 3-D structure of the world. A n organization which *Convexity among segments may be anticlockwise or clockwise persists in time is very significant and suggests a common cause. Primitive level organization could include 2-D patterns in the flow field like swirls, vortices, sinks, and sources. The structural level would involve finding organizations among these. This would help in segmenting the field into regions of interest. We speculate that the assembly level will involve organizing the regions of interest into clusters which would roughly correspond to objects (consistent dynamics).</p><p>We could not find work related to extracting organizations in a 3-D world over time. Organizations in dynamic 3-D scenes are the most significant because of the dimensionality of the space. Work in active vision and nonrigid motion might benefit from this. As to the nature of future work in this area we can be only highly speculative. Signal level work might involve extracting 3-D optic flow vectors. The primitive level will organize them into stream lines or coparametric surfaces. At the structural level we can look for surfaces which exhibit regularity in 3-D shape and motion. Assembly level organization might group objects exhibiting similar motion.</p><p>Efficient computational structures for perceptual organization also need to be developed. Some innovative approaches have been advanced with varying success. Efficient data structures and search strategies are needed; hierarchical structures appear promising. As a computational method, energy minimization seems to be a good criterion for computing organization. However, much needs to be done on the formulation of the local energy functionals. We have also found Bayesian networks to be very useful as a computational tool and as a knowledge base.</p><p>To summarize, we reviewed the work in perceptual organization in machine vision and suggested a framework to help direct future research and to provide a consistent lexicon. The role of organization in vision is indisputable and many artificial systems are starting to use it, sometimes without recognizing it as such. We hope that this paper will attract new researchers in this area and help to focus future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Manuscript received February 28, 1992; revised August 20, 1992. This work was supported by the NASA Center for Commercial Development of Space, by a grant from Texas Instruments, and by a CISE Equipment Grant from the National Science Foundation. The authors are with the Signal Analysis and Machine Perception Laboratory, Department of Electrical Engineering, The Ohio State University, Columbus, OH 43210. IEEE Log Number 9206217.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>11. A BRIEF HISTORY OF PERCEPTUAL ORGANIZATION RESEARCH "Progress, far from consisting in change, depends on retentiveness.. . Those who cannot remember the past are condemned to fulfill it." -George Santayana</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Subjective contours. (a) The region bounded by the subjective contours appear to be more intense than the background. (b) Line segments are not necessary for the generation of subjective contours. (c) Geometric regularity is not necessary for the formation of subjective contours. Closure seems to be sufficient to sustain the illusion. (d) Irregular figures can generate subjective contours.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Fig. 2. Some experiments (adapted from Kanizsa) demonstrating the importance of perceptual organizations. (a) The vertical rectangle passes behind the stripped rectangle, even when all of it is completely visible. (b) Symmetrization, by using mirror images of letters, makes word invisible. Formation of groupings based on closure, symmetry, and good continuation prevail over knowledge of letters. (c) Continuity of direction prevails over maximum symmetry.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Gestalt laws of grouping.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>IFig. 4 .</head><label>4</label><figDesc>Fig. 4. Classificatory structure for perceptual organization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>21+1) where d is the number of dimensions and N is the number of points [27].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Annealing:McCafferty [42], as see saw in then solves using simulated annealing. His energy formulation allows for the interactions of a higher level module. The ability to identify objects on the basis of a limited set of features is evidence of high level influences[105]. The influence of top down sources, such as from the conscious conceptual knowledge, on the perceptual process is recognized byPerkins [106]. The perceiver is thought to make use of the Gestalt criteria of rectangularity, symmetry and parallelism [ 1061, using a constraint handling process with relaxation to a minimum state,' or a production system that triggers rules when some salient features are detected[107]. Freuder [lo81 also acknowledges the role played by knowledge in vision inferring of features missing because of noise or occlusion. For example, if a line finder misses an interior line of a brick, a knowledge of bricks, or more generally of parallelepipeds, could be used to infer its presence.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>We thank the reviewers for their prompt response and M.</p><p>Mirza for pointing out some of the work in range image understanding.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">On the role of structure in vision</title>
		<author>
			<persName><forename type="first">A</forename><surname>Witkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
		<editor>Human and Machine Vision, J. Beck, B. Hope, and A. Rosenfeld</editor>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>Academic</publisher>
			<biblScope unit="page" from="481" to="543" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Perceptual Organization and Visual Recognition</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>Kluwer</publisher>
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Perceptual organization in a random stimulus</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human and Machine Vision II</title>
		<title level="s">Principles of Gestalt Psychology</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Kofka</surname></persName>
		</editor>
		<meeting><address><addrLine>New York; New York; Harcourt</addrLine></address></meeting>
		<imprint>
			<publisher>Academic</publisher>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="237" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">W</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName><surname>Gestalt Psycholom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1929">1929</date>
			<publisher>Liveright</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Unte;suchu$en zur lehre von der Gestalt ii</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wertheimer</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Kanizsa</surname></persName>
		</author>
		<title level="m">Organization in Vision</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Wertheimer</surname></persName>
		</author>
		<title level="m">Uber Schlussprozesse im produktiven Denken. ogischen Forschung</title>
		<meeting><address><addrLine>New York; Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Praeger</publisher>
			<date type="published" when="1920">1923. 1979. 1920. 1945</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="301" to="350" />
		</imprint>
	</monogr>
	<note>L 1 De Gruyter</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">G. Katona, Organizing and Memorizing</title>
		<author>
			<persName><forename type="first">K</forename><surname>Duncker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Monogr</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="1940">1940</date>
			<publisher>Colombia University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>On problem solving</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Reimann geometric explanation of the visual illusions and figural after-effects</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Formal Theories of Visual Perception</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">L J</forename><surname>Leeuwenberg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">F J M</forename><surname>Buffart</surname></persName>
		</editor>
		<meeting><address><addrLine>New York; Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
	<note>The Logic of Perception</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The legacy of Gestalt psychology</title>
		<author>
			<persName><forename type="first">I</forename><surname>Rock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Amer</title>
		<imprint>
			<biblScope unit="page" from="84" to="90" />
			<date type="published" when="1990-12">Dec. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Ecological cue validity of &apos;proximity&apos; and other Gestalt factors</title>
		<author>
			<persName><forename type="first">E</forename><surname>Brunswick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kamiya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Amer. J. Psychol</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="20" to="32" />
			<date type="published" when="1953">1953</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Challenges in computer vision: Future research directions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Negahdaripour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Proc. Comput. SOC. Conf Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="189" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Vision: A Computational Investigation into the Human Representation of Processing of Visual Information</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
			<pubPlace>San Francisco, C A Freeman</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Method and Means for Recognizing Complex Patterns</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">V C</forename><surname>Hough</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1962">1962</date>
			<pubPlace>U.S. Pat</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A computational approach to edge detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Canny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="679" to="714" />
			<date type="published" when="1986-11">Nov. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Using Canny&apos;s criteria to derive a recursively implemented optimal edge detector</title>
		<author>
			<persName><forename type="first">R</forename><surname>Deriche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="page" from="167" to="187" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Optimal, efficient, recursive edge detection filters</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Boyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf: Pattern Recognition</title>
		<meeting><address><addrLine>Atlantic City, NJ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990-06">June 1990</date>
			<biblScope unit="page" from="931" to="936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Optimal infinite impulse response zero crossing based edge detectors</title>
	</analytic>
	<monogr>
		<title level="m">Comput. Vision, Graphics, Image Processing: Image Understanding</title>
		<imprint>
			<date type="published" when="1991-09">Sept. 1991</date>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="224" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Extracting straight lines</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Hanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Riseman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="425" to="455" />
			<date type="published" when="1986-07">July 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Integrating region growing and edge detection</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pavlidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="225" to="223" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A parallel technique for signal level perceptual organization</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Liou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="317" to="325" />
			<date type="published" when="1991-04">Apr. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Early orientation selection: Tangent fields and the dimensionality of their support</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Zucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human and Machine Vision</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Extraction of early perceptual structure in dot patterns: Integrating region, boundary, and component gestalt</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tuceryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wechsler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Comput. Vision, Graphics, Image Processing</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Avis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Bhattacharya</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1989-01">1989. Jan. 1990</date>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
	<note>Advances Comput. Res., T. R. Reed and</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Visual grouping without low spatial frequencies</title>
		<author>
			<persName><forename type="first">L</forename><surname>Janez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Res</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="271" to="274" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Reference frames in the perception of shape and orientation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Object Perceptions: Structure and Process</title>
		<editor>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Shepp</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Ballesteros</surname></persName>
		</editor>
		<meeting><address><addrLine>Hillsdale, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Erlbaum</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="121" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Spatial frequency channels and perceptual grouping in texture segregation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ivry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vision, Graphics, Image Processing</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="299" to="325" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Perceptual organization and curve partitioning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Fischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Bolles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="100" to="105" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Organization of smooth image curves at multiple scales</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd Int. Conf Computer Vision</title>
		<meeting>2nd Int. Conf Computer Vision</meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="558" to="567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Robust contour decomposition using a constant curvature criterion</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Wuescher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Boyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="41" to="51" />
			<date type="published" when="1991-01">Jan. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The organization of curve detection: Coarse tangent fields and fine spline coverings</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Zucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dobbins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Iverson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd Int. Conf Computer Vision</title>
		<meeting>2nd Int. Conf Computer Vision</meeting>
		<imprint>
			<date type="published" when="1988-12">Dec. 1988</date>
			<biblScope unit="page" from="568" to="577" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Token-based extraction of straight lines</title>
		<author>
			<persName><forename type="first">M</forename><surname>Boldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Riseman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE Cambridge</title>
		<meeting>SPIE Cambridge</meeting>
		<imprint>
			<date type="published" when="1988">1989. Nov. 1988</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
	<note>Perceptual grouping of curved lines</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Computing curvilinear structure by tokenbased grouping</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Riseman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Proc. Comput. SOC. Conf Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic</publisher>
			<date type="published" when="1978">1992. 1978. 1986</date>
			<biblScope unit="page" from="335" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Labeling of curvilinear structure across scales by token grouping</title>
		<author>
			<persName><forename type="first">E</forename><surname>Saund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Proc. Comput. SOC. Conf Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="257" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Three-dimensional object recognition from single twodimensional images</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intell</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="355" to="395" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Interesting pattems for model based machine vision</title>
		<author>
			<persName><forename type="first">J</forename><surname>Henikoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Shapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conf: Computer Vision</title>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="535" to="538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Human and Machine Vision: Computing Perceptual Organization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Mccafferty</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Using perceptual organization to extract 3-D structures</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1121" to="1139" />
			<date type="published" when="1989-11">Nov. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Perceptual organization for scene segmentation and description</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">6164535</biblScope>
			<date type="published" when="1992-06">June 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Use of monocular groupings and occlusion analysis in a hierarchical stereo system</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C K</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Proc. Comput. SOC. Conf: Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="50" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Methods for exploiting the relationship between buildings and their shadows in aerial imagery</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Irvin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Mckeown</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1564" to="1575" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Detecting buildings in aerial images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Huertas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vision Graphics Image Processing</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="131" to="152" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Detecting runways in complex airport scenes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Huertas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vision Graphics Image Processing</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="107" to="145" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Structural saliency: The detection of globally salient structures using a locally connected network</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf: Computer Vision</title>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="321" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Finding geometric and relational structures in an image</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hourad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Veillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Skordas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eur. Conf Computer Vision</title>
		<imprint>
			<date type="published" when="1990-04">Apr. 1990</date>
			<biblScope unit="page" from="374" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Structural stereopsis for 3-D vision</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Boyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Kak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="144" to="166" />
			<date type="published" when="1988-03">Mar. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Stereo correspondence through feature grouping and maximal cliques</title>
		<author>
			<persName><forename type="first">R</forename><surname>Horaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Skordas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1168" to="1180" />
			<date type="published" when="1989-11">Nov. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The 2.1-D sketch</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nitzberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf Computer Vision</title>
		<imprint>
			<date type="published" when="1990-12">Dec. 1990</date>
			<biblScope unit="page" from="138" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Perceptual organization of occluding contours</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf: Computer Vision</title>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="133" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Using perceptual grouping to recognize and locate partially occluded objects</title>
		<author>
			<persName><forename type="first">T</forename><surname>Rearick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Frawley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cortopassi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Proc. Comput. Conf Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="840" to="846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Matching perspective images using geometric constraints and perceptual grouping</title>
		<author>
			<persName><forename type="first">L</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mohr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf: Computer Vision</title>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page">679484</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Hypothesizing and testing geometric attributes of image data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kanatani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf Computer Vision</title>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="370" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">On characterizing ribbons and finding skewed symmetries</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vision Graphics Image Processing</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="328" to="340" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Shape from contours using symmetries</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Yuen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eur. Con6 Computer Vision</title>
		<imprint>
			<date type="published" when="1990-04">Apr. 1990</date>
			<biblScope unit="page" from="437" to="453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Using symmetries for analysis of shape from contour</title>
		<author>
			<persName><forename type="first">F</forename><surname>Ulupinar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf Computer Vision</title>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page">414426</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">An extremum principle for shape from contour</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="288" to="301" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">B-spline contour representation and symmetry detection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Saint-Marc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Medioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eur. Conf Computer Vision</title>
		<imprint>
			<date type="published" when="1990-04">Apr. 1990</date>
			<biblScope unit="page" from="604" to="606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Detection of interest points using symmetry</title>
		<author>
			<persName><forename type="first">D</forename><surname>Reisfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wolfson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yeshurun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf Computer vision</title>
		<imprint>
			<date type="published" when="1990-12">Dec. 1990</date>
			<biblScope unit="page" from="6" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Similarity extraction and modelling</title>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wagemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vandeneede</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oosterlinck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf: Computer Vision</title>
		<imprint>
			<date type="published" when="1990-12">Dec. 1990</date>
			<biblScope unit="page" from="530" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Descriptions of complex objects from incomplete and imperfect data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. DARPA Image Understanding Workshop</title>
		<meeting>DARPA Image Understanding Workshop</meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="399" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Extracting surfaces of revolution by perceptual grouping of ellipses</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Rosin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A W</forename><surname>West</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Proc. Comput. SOC. Conf: Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="677" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Segmentation through variable-order surface fitting</title>
		<author>
			<persName><forename type="first">P</forename><surname>Besl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="167" to="192" />
			<date type="published" when="1988-03">Mar. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">The robust sequential estimator: A computationally efficient algorithm for estimating surface curvature</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Boyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Ellis Horwood</publisher>
			<pubPlace>West Sussex, England</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">A dynamic system for object description and correspondence</title>
		<author>
			<persName><forename type="first">B</forename><surname>Parvin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Medioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Proc. Comput. SOC. Con$ Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="393" to="399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Perceptual organization and the representation of natural form</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intell</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="293" to="331" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">From Surfaces to Objects: Computer Vision and Three Dimensional Scene Analysis</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Fisher</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Automatic construction of junction dictionaries and their exploitation of the analysis of range data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sugihara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Joint Conf: Artificial Intelligence</title>
		<imprint>
			<date type="published" when="1979">1979</date>
			<biblScope unit="page" from="859" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Knowledgebased stereo and structured light for 3-d robot vision</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Kak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Boyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Safranek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Techniques for 3 -0 Machine Perception</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</editor>
		<meeting><address><addrLine>Ed. Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="185" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">The Perception of the Visual World</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Gibson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1950">1950</date>
			<pubPlace>Boston, M A Houghton Mifflin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Theories of Visual Perception</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">E</forename><surname>Gordon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Experiments in the Machine Interpretation of Visual Motion</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">F</forename><surname>Buxton</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">The information available to a moving observer from specularities</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Giblin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vision Comput</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="38" to="42" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Robust estimation of surface curvature from deformation of apparent contours</title>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eur. Conf: Computer Vision</title>
		<imprint>
			<date type="published" when="1990-04">Apr. 1990</date>
			<biblScope unit="page">465474</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Spatial determinants of depth perception in two dot motion patterns</title>
		<author>
			<persName><forename type="first">E</forename><surname>Borjesson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Von Hofsten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception Psychophys</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="263" to="268" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Visual perception of motion in depth: Application of a vector model to 3 dot motion patterns</title>
	</analytic>
	<monogr>
		<title level="j">Perception Psychophys</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Against quantitative optic flow</title>
		<author>
			<persName><forename type="first">A</forename><surname>Verri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf Computer Vision</title>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Towards qualitative vision: Using flow field divergence for obstacle avoidance in visual navigation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aloimonos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf Computer Vision</title>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="188" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Information in the geometric structure of retinal flow fields</title>
		<author>
			<persName><forename type="first">S</forename><surname>Carlsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Con6 Computer Vision</title>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="629" to="633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">The interpretation of biological motion</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Flinchbaugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Cybern</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="195" to="204" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Performance of optical flow techniques</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Beauchemin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Burkitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Proc. Comput. SOC. Conf Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="236" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">The psychology of perceptual organization: A transformational approach</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Palmer</surname></persName>
		</author>
		<editor>Human and Machine Vision, J. Beck, B. Hope, and A. Rosenfeld</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Pattern recognition by machine</title>
		<author>
			<persName><forename type="first">G</forename><surname>Selfridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Neisser</surname></persName>
		</author>
		<editor>Computers and Thought, E. A. Feigenbaum and J. Feldman</editor>
		<imprint>
			<date type="published" when="1963">1963</date>
			<publisher>McGraw Hill</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Principles of PerceptualLearning and Development</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Gibson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1969">1969</date>
			<publisher>Appleton-Century-Crofts</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">An interpretive model of line continuation in human visual perception</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="619" to="639" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Generative systems of analyzers</title>
		<author>
			<persName><forename type="first">M</forename><surname>Leyton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human and Machine Vision II</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic</publisher>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="149" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Quantification of certain visual pattern properties: Salience, transperancy, similarity</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L J</forename><surname>Leeuwenberg</surname></persName>
		</author>
		<editor>E. L. J. Leeuwenberg and H. F. J. M. Buffart</editor>
		<imprint>
			<date type="published" when="1978">1978</date>
			<biblScope unit="page" from="277" to="298" />
			<pubPlace>New York Wiley</pubPlace>
		</imprint>
	</monogr>
	<note>in Formal Theories of Visuaf Perception</note>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Are complex visual features derived from simple ones,&apos;&apos; in Formal Theories of Visual Perception</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Pomerantz</surname></persName>
		</author>
		<editor>E. L. J. Leeuwenberg and H. F. J. M. Buffart</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Choosing a basis for perceptual space</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Barnard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vision, Graphics, Image Processing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="87" to="99" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Perceptual organization using interestingness</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Lawton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Mcconnell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1987 Workshop Spatial Reasoning and Multi-Sensor Fusion</title>
		<meeting>1987 Workshop Spatial Reasoning and Multi-Sensor Fusion</meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page">405419</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Low level segmentation: An expert system</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Nazif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Stochastic relaxation, Gibbs distribution, and the Bayesian restoration of images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="721" to="741" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Geometric primitive extraction using a genetic algorithm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Proc. Comput. SOC. Con8 Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="640" to="643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Cambridge</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">New</forename><surname>York</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wiley</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1978">1978</date>
			<biblScope unit="page" from="217" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Neural dynamics of perceptual groupings: Texture, boundaries, and emergent segmentation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Grossberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mingolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception Psychophys</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="141" to="171" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Neural networks and physical systems with emergent colective computational abilities</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Hopfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Tank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Nat. Acad. Sci</title>
		<meeting>Nat. Acad. Sci</meeting>
		<imprint>
			<date type="published" when="1982">1985. 1986. 1982</date>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="2554" to="2558" />
		</imprint>
	</monogr>
	<note>Neural computation of decisions in optimization problems</note>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">On the foundations of relaxation labeling process</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Hummel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Zucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Scene labeling by relaxation operations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Hummel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Zucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ZEEE Trans. Syst., Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4 2 W 3 3</biblScope>
			<date type="published" when="1976-06">June 1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Segmentation and grouping of object boundaries using energy minimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Trytten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tuceryan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Proc. Comput. SOC. Conf: Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="730" to="731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">Reading pictures: Some cognitive aspects of visual perception</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Kolers</surname></persName>
		</author>
		<editor>Picture Bandwidth Compression, T. S . Huang and 0. J. Tretiak</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title level="m" type="main">Why the human perceiver is a bad machine</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Perkins</surname></persName>
		</author>
		<editor>Human and Machine Vision, J. Beck, B. Hope, and A. Rosenfeld</editor>
		<imprint>
			<date type="published" when="1983">1983</date>
			<biblScope unit="page" from="341" to="364" />
			<pubPlace>New York Academic</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">in Representation and Organization in Perception</title>
		<author>
			<persName><forename type="first">E</forename><surname>Freuder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Beck</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1982">1982</date>
			<publisher>Erlbaum</publisher>
			<pubPlace>Ed. Hillsdale, NJ</pubPlace>
		</imprint>
	</monogr>
	<note>Knowledge-mediated perception</note>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Graph theoretical methods for detecting and describing gestalt clusters</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Zahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="68" to="86" />
			<date type="published" when="1971-01">Jan. 1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">A highly efficient computational structure for perceptual organization</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Boyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">336342</biblScope>
			<date type="published" when="1982-05">May 1982. Nov. 1990</date>
			<pubPlace>Man, Cybern</pubPlace>
		</imprint>
		<respStmt>
			<orgName>OSU</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep. SAMPL-90-06</note>
	<note>IEEE Trans. Syst.</note>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Integration, inference, and management of spatial information using Bayesian networks: Perceptual organization</title>
		<idno>SAMPL-91-08</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Proc. Comput. SOC. Con&amp; Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1992-06">Aug. 1992. Nov. 1992. Mar. 1993. June 1992</date>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="251" to="256" />
		</imprint>
		<respStmt>
			<orgName>SAMP-Lab, Dep. EE, OSU</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
	<note>Int. Conf Pattern Recognition</note>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Finding convex edge grouping in an image</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Wayner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Proc. Comput. SOC. Conf Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="406" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Efficiently using invariant theory for model based matching</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Wayner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Proc. Comput. SOC. Conf: Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>Gordon and Breach</publisher>
			<date type="published" when="1972">1991. 1983. 1972</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="267" to="287" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
