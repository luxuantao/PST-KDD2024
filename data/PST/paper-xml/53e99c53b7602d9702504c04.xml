<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">LLVA: A Low-level Virtual Instruction Set Architecture</title>
				<funder ref="#_KvPpjUS #_ANJSs9a">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_HCb2b7u">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Vikram</forename><surname>Adve</surname></persName>
							<email>vadve@cs.uiuc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chris</forename><surname>Lattner</surname></persName>
							<email>lattner@cs.uiuc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Brukman</surname></persName>
							<email>brukman@cs.uiuc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anand</forename><surname>Shukla</surname></persName>
							<email>ashukla@cs.uiuc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Brian</forename><surname>Gaeke</surname></persName>
							<email>gaeke@cs.uiuc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">LLVA: A Low-level Virtual Instruction Set Architecture</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A virtual instruction set architecture (V-ISA) implemented via a processor-specific software translation layer can provide great flexibility to processor designers. Recent examples such as Crusoe and DAISY, however, have used existing hardware instruction sets as virtual ISAs, which complicates translation and optimization. In fact, there has been little research on specific designs for a virtual ISA for processors. This paper proposes a novel virtual ISA (LLVA) and a translation strategy for implementing it on arbitrary hardware. The instruction set is typed, uses an infinite virtual register set in Static Single Assignment form, and provides explicit control-flow and dataflow information, and yet uses low-level operations closely matched to traditional hardware. It includes novel mechanisms to allow more flexible optimization of native code, including a flexible exception model and minor constraints on self-modifying code. We propose a translation strategy that enables offline translation and transparent offline caching of native code and profile information, while remaining completely OS-independent. It also supports optimizations directly on the representation at install-time, runtime, and offline between executions. We show experimentally that the virtual ISA is compact, it is closely matched to ordinary hardware instruction sets, and permits very fast code generation, yet has enough high-level information to permit sophisticated program analyses and optimizations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In recent years, traditional superscalar processors and compilers have had to resort to increasingly complex designs for small improvements in performance. This has spurred a wide range of research efforts exploring novel microarchitecture and system design strategies in search of cost-effective long-term solutions <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b32">33]</ref>. While the outcome is far from clear, what seems clear is that an extensive rethinking of processor design has begun.</p><p>Along with design alternatives for the microarchitecture and system architecture, we believe it is also important to rethink the instruction set architecture -software's sole interface to the processor. Traditional processor instruction sets are a strait-jacket for both hardware and software. They provide little useful information about program behavior to the execution engine of a processor, they make it difficult for hardware designers to develop innovative softwarecontrolled mechanisms or modify instruction sets, and they greatly constrain compiler optimizations to those that can be expressed by an instruction set that must also serve as an external program representation. The fundamental problem is that the same instruction set (the hardware ISA) is used for two very different purposes: as the persistent representation of software, and as the interface by which primitive hardware operations are specified and sequenced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Virtual Instruction Set Computers</head><p>As a step towards loosening these restrictions, several research and commercial groups have advocated a class of architectures we term Virtual Instruction Set Computers (VISC) <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b31">32]</ref>. Such an architecture defines a virtual instruction set (called the V-ISA in Smith et al.'s terminology <ref type="bibr" target="#b31">[32]</ref>) that is used by all user and operating system software, as illustrated in Fig. <ref type="figure">1</ref>. An implementation of the architecture includes both (a) a hardware processor with its own instruction set (the implementation ISA or I-ISA), and (b) an implementation-specific software translation layer that translates virtual object code to the I-ISA. Because the translation layer and the hardware processor are designed together, Smith et al. refer to this implementation strategy as a codesigned virtual machine <ref type="bibr" target="#b31">[32]</ref>. Fisher has described a closely related vision for building families of processors customized for specific application areas that maintain compatibility and performance via software translation <ref type="bibr" target="#b14">[15]</ref>.</p><p>At the most basic level, a VISC architecture decouples the program representation (V-ISA) from the actual hardware interface (I-ISA), allowing the former to focus on capturing program behavior while the latter focuses on software control of hardware mechanisms. This brings two fun-Figure <ref type="figure">1</ref>. System organization for a virtual architecture. This is similar to Fig. <ref type="figure">1(c</ref>) in <ref type="bibr" target="#b31">[32]</ref> and Fig. <ref type="figure">5</ref> in <ref type="bibr" target="#b23">[24]</ref>.</p><p>damental benefits to the hardware processor design and its software translation layer:</p><p>1. The virtual instruction set can include rich program information not suitable for a direct hardware implementation, and can be independent of most implementation-specific design choices.</p><p>2. The I-ISA and its translator provide a truly cooperative hardware/software design: the translator can provide information to hardware through implementation-specific mechanisms and instruction encodings, while the hardware can expose novel microarchitectural mechanisms to allow cooperative hardware/software control and also to assist the translator.</p><p>These two fundamental benefits could be exploited in potentially unlimited ways by processor designers. Prior work <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b10">11]</ref> has discussed many potential hardware design options enabled by this approach, which are impractical with conventional architectures. Furthermore, I-ISA instruction encodings and software-controlled mechanisms can both be changed relatively easily with each processor design, something that is quite difficult to do for current processors. Finally, external compilers can focus on machine-independent optimizations while the translator serves as a common back-end compiler customized for the processor implementation.</p><p>The cost of this increased flexibility is the possible overhead of software translation (if it must be done "online"). Nevertheless, recent advances in dynamic compilation, program optimization, and hardware speed can mitigate the performance penalty, and could make this idea more viable today than it has been in the past. Furthermore, hardware mechanisms can be used to assist these tasks in many ways <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b29">30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Our Contribution: Design for A Virtual Instruction Set</head><p>Although virtual architectures have been discussed for a long time and real implementations exist (viz., IBM S/38 and AS/400, DAISY, and Transmeta's Crusoe), there has been little research exploring design options for the V-ISA. Both DAISY and Crusoe used traditional hardware ISAs as their V-ISA. The IBM machines do use a specially developed V-ISA, but, as we explain in Section 6, it is also extremely complex, OS-dependent, requires complex OS services for translation, and is designed more for a particular application domain than for general-purpose software.</p><p>We believe a careful design for the V-ISA driven by the needs of compiler technology, yet "universal" enough to support arbitrary user and OS software, is crucial to achieve the full benefits of the virtual architecture strategy. A common question is whether Java bytecode (as suggested by Smith et al. <ref type="bibr" target="#b31">[32]</ref>) or Microsoft's Common Language Infrastructure (CLI) could be used as a V-ISA for processors. Since a processor V-ISA must support all external user software and arbitrary operating systems, we believe the answer is "no". These representations are designed for a certain class of languages, and are not sufficiently languageindependent for a processor interface. They include complex runtime software requirements, e.g., garbage collection and extensive runtime libraries, which are difficult to implement without operating system support. Finally, they are generally not well-suited for low-level code such as operating system trap handlers, debuggers, and performance monitoring tools.</p><p>This paper proposes a design for a Virtual Instruction Set Architecture, and an accompanying compilation strategy for arbitrary hardware. More specifically, this work makes three contributions:</p><p>? It proposes a V-ISA design that is rich enough to support sophisticated compiler analyses and transformations, yet low-level enough to be closely matched to native hardware instruction sets and to support all external code, including OS and kernel code.</p><p>? It carefully defines the behavior of exceptions and selfmodifying code to minimize the difficulties faced by previous translators for DAISY <ref type="bibr" target="#b13">[14]</ref> and Crusoe <ref type="bibr" target="#b10">[11]</ref>.</p><p>? It describes a translation strategy that allows offline translation and offline caching of native code and profile information, using an OS-independent interface to access external system resources. The translation strategy also leverages aggressive optimization at installtime, runtime, and offline ("idle-time"), tailored to the particular hardware and to profiling information from actual users (these capabilities follow directly from the V-ISA <ref type="bibr" target="#b25">[26]</ref>).</p><p>The virtual instruction set we propose uses simple RISClike operations, but is fully typed using a simple languageindependent type system, and includes explicit control flow and dataflow information in the form of a Static Single Assignment (SSA) representation. Equally important is what the V-ISA does not include: a fixed register set, stack frame layout, low-level addressing modes, limits on immediate constants, delay slots, speculation, predication, or explicit interlocks. All of these are better suited to the I-ISA than the V-ISA. Nevertheless, the V-ISA is low-level enough to permit extensive machine-independent optimization in sourcelevel and link-time compilers (unlike Java bytecode, for example), reducing the amount of optimization required during translation from V-ISA to I-ISA.</p><p>The benefits of a V-ISA design can only be determined after developing new processor design options and the software/hardware that exploit its potential. Instead, our goal in this work is to evaluate the design in terms of its suitability as a V-ISA. We have implemented the key components of the compilation strategy for SPARC V9 and Intel IA-32 hardware processors, including an aggressive link-time interprocedural optimization framework (which operates on the V-ISA directly), native code generators that can be run in either offline or JIT mode, and a software trace cache to support trace-based runtime optimizations for the SPARC V9. With these components, we address two questions:</p><p>? Qualitatively, is the instruction set rich enough to enable both machine-independent and dependent optimizations during code generation?</p><p>? Experimentally, is the instruction set low-level enough to map closely to a native hardware instruction set, and to enable fast translation to native code?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Design Goals for A Virtual ISA</head><p>Figure <ref type="figure">1</ref> shows an overview of a system based on a VISC processor. A VISC architecture defines an external instruction set (V-ISA) and a binary interface specification (V-ABI). An implementation of the architecture includes a hardware processor plus a translator, collectively referred to as the "processor." We use "external software" to mean all software except the translator. The translator is essentially a compiler which translates "virtual object code" in the V-ISA to native object code in the I-ISA.</p><p>In our proposed system architecture, all external software may only use the V-ISA. This rigid constraint on external software is important for two reasons:</p><p>1. To ensure that the hardware processor can evolve (i.e., both the I-ISA and its implementation details visible to the translator can be changed), without requiring any external software to be recompiled.</p><p>2. To ensure that arbitrary operating systems that conform to the V-ABI can run on the processor.</p><p>Supporting arbitrary operating systems and system designs raises significant potential challenges for supporting offline translation and caching, as described in Section 4.1.</p><p>Because the primary consumer of a V-ISA is the software translation layer, the design of a V-ISA must be driven by an understanding of compiler technology. Most non-trivial optimization and code generation tasks rely on information about global control-flow, dataflow, and data dependence properties of a program. Such properties can be extremely difficult to extract from native machine code.</p><p>The challenge is to design a V-ISA that provides such high-level information about program behavior, yet is appropriate as an architecture interface for all external software, including applications, libraries, and operating systems. We propose a set of design goals for such a V-ISA:</p><p>1. Simple, low-level operations that can be implemented without a runtime system: To serve as a processorlevel instruction set for arbitrary software and enable implementation without operating system support, the V-ISA must use simple, low-level operations that can each be mapped directly to a small number of hardware operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">No execution-oriented features that obscure program behavior:</head><p>The V-ISA should exclude ISA features that make program analysis difficult and which can instead be managed by the translator, such as limited numbers and types of registers, a specific stack frame layout, low-level calling conventions, limited immediate fields, or low-level addressing modes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Portability across some family of processor designs:</head><p>It is impractical to design a "universal" V-ISA for all conceivable hardware processor designs. Instead, a good V-ISA design must enable some broad class of processor implementations and maintain compatibility at the level of virtual object code for all processors in that class (key challenges include endianness and pointer size).</p><p>4. High-level information to support sophisticated program analysis and transformations: Such high-level information is important not only for optimizations but also for good machine code generation, e.g., effective instruction scheduling and register allocation. Furthermore, improved program analysis can enable more powerful cooperative software/hardware mechanisms as described above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Language independence:</head><p>Despite including high-level information (especially type information), it is essential that the V-ISA should be completely languageindependent, i.e., the types should be low-level and general enough to implement high-level language operations correctly and reasonably naturally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.</head><p>Operating system support: The V-ISA must fully support arbitrary operating systems that implement the virtual Application Binary Interface (V-ABI) associated with the V-ISA (discussed in Section 3.1). Therefore, it must provide all the necessary low-level mechanisms such as traps, memory management, and lowlevel device I/O.</p><p>Note that high-level virtual machines such as JVM and CLI fail to meet goals #1 (they use complex, high-level operations with large runtime libraries), #5 (e.g., JVM and CLI are tailored for object-oriented languages with a particular inheritence model), and #6 (their complex runtime systems require significant OS support in practice). In contrast, traditional machine ISAs fail to meet goals #2 and #4, and satisfy #3 only to a limited extent (e.g., existing programs cannot exploit new hardware instructions or larger architected register files).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">LLVA: A V-ISA for high performance</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Components of the V-ISA</head><p>The LLVA Virtual Instruction Set is a source-languageneutral, low-level, orthogonal, three-address instruction set. Figure <ref type="figure" target="#fig_1">2</ref> shows an example C function and the corresponding LLVA code. The basic components of the instruction set are as follows.</p><p>Register Set and Memory Model LLVA uses an infinite, typed, register file where all registers are in Static Single Assignment (SSA) form <ref type="bibr" target="#b9">[10]</ref> (described below). Registers can only hold scalar values, viz., boolean, integer, floating point, and pointer. This type information and the SSA representation together provide the information needed for simple or aggressive register allocation algorithms. To support an infinite register set, we use a self-extending instruction encoding, but define a fixed-size 32-bit format to hold small instructions for compactness and translator efficiency. Memory is partitioned into stack, heap, and global memory, and all memory is explicitly allocated. LLVA is a load/store architecture: only load and store instructions access data values in memory.</p><p>LLVA Instructions LLVA has a small, orthogonal instruction set consisting of only the 28 instructions listed in Table 1. The orthogonality makes optimal pattern-matching instruction selectors easier to use. Because almost all instructions are simple, three-address instructions with register operands (add, mul, seteq, etc), the translation process is primarily concerned with combining multiple LLVA instructions into more complex I-ISA instructions wherever possible. Furthermore, the simple low-level operations allow arbitrary machine-independent optimizations to be performed ahead of time by static compilers when generating LLVAcode (unlike JVM bytecode, where operations like array bounds checks, virtual function call resolution, and inlining are difficult to eliminate statically).</p><p>LLVA provides low-level operations that can be used to implement high-level language features, but in a machineindependent manner. For example, array and structure indexing operations are lowered to typed pointer arithmetic with the getelementptr instruction (explained below). Source-level array bounds checks are turned into explicit comparisons. Virtual function dispatch in C++ becomes a pair of loads to retrieve the function pointer followed by a call (optimizations can eliminate some of these in the static compiler, translator, or both) <ref type="bibr" target="#b25">[26]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Type</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Global Data-flow (SSA) &amp; Control Flow Information</head><p>A key feature of LLVA that enables efficient dynamic translation is the use of SSA form as the primary representation for scalar register values. SSA form is widely used for compiler optimizations because it allows for efficient "sparse" algorithms for global dataflow problems and provides explicit def-use chains.</p><p>To represent SSA information directly in the code, LLVA uses an explicit phi instruction to merge values at controlflow join points. (for example, the %Ret.1 value in Figure <ref type="figure" target="#fig_1">2(b)</ref>). The translator elimiantes the ?-nodes by introducing copy operations into predecessor basic blocks. These copies are usually eliminated during register allocation.</p><p>Exposing an explicit Control flow Graph (CFG) is another crucial feature of LLVA <ref type="foot" target="#foot_0">1</ref> . Each function in LLVA is a list of basic blocks, and each basic block is a list of instructions ending in a single control flow instruction that explicitly specifies its successor basic blocks. A control flow instruction can be a branch, multi-way branch, function return, invoke or unwind. invoke and unwind are used to implement source-language exceptions via stack unwinding, in a manner that is explicit, portable, and can be translated into efficient native code <ref type="bibr" target="#b25">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LLVA Type System</head><p>The LLVA instruction set is fullytyped, using a low-level, source-language-independent type  system. The type system is very simple, consisting of primitive types with predefined sizes (ubyte, uint, float, double, etc...) and 4 derived types (pointer, array, structure, and function). We chose this small set of derived types for two reasons. First, we believe that most high-level language data types are eventually represented using some combination of these low-level types, e.g., a C++ class with base classes and virtual functions is usually represented as a nested structure type with data fields and a pointer to an constant array of function pointers. Second, standard language-independent optimizations use only some subset of these types (if any), including optimizations that require array dependence analysis, pointer analysis (even field-sensitive algorithms <ref type="bibr" target="#b15">[16]</ref>), and call graph construction.</p><p>All instructions in the V-ISA have strict type rules, and most are overloaded by type (e.g. 'add int %X, %Y' vs. 'add float %A, %B'). There are no mixed-type operations and hence, no implicit type coercion. An explicit cast instruction is the sole mechanism to convert a register value from one type to another (e.g. integer to floating point or integer to pointer).</p><p>The most important purpose of the type system, however, is to enable typed memory access. LLVA achieves this via type-safe pointer arithmetic using the getelementptr instruction. This enables pointer arithmetic to be expressed directly in LLVA without exposing implementation details, such as pointer size or endianness. To do this, offsets are specified in terms of abstract type properties (field number for a structure and element index for an array).</p><p>In the example, the %tmp.1 getelementptr instruction calculates the address of T[0].Children <ref type="bibr" target="#b2">[3]</ref>, by using the symbolic indexes 0, 1, and 3. The "1" index is a result of numbering the fields in the structure. On systems with 32-bit and 64-bit pointers, the offset from the %T pointer would be 20 bytes and 32 bytes respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Representation Portability</head><p>As noted in Section 2, a key design goal for a V-ISA is to maintain object code portability across a family of processor implementations. LLVA is broadly aimed to support general-purpose uniprocessors (Section 3.6 discusses some possible extensions). Therefore, it is designed to abstract away implementation details in such processors, including the number and types of registers, pointer size, endianness, stack frame layout, and machine-level calling conventions.</p><p>The stack frame layout is abstracted by using an explicit alloca instruction to allocate stack space and return a (typed) pointer to it, making all stack operations explicit. As an example, the V variable in Figure <ref type="figure" target="#fig_1">2</ref>(a) is allocated on the stack (instead of in a virtual register) because its address is taken for passing to Sum3rdChildren. In practice, the translator preallocates all fixed-size alloca objects in the function's stack frame at compile time.</p><p>The call instruction provides a simple abstract calling convention, through the use of virtual register or constant operands. The actual parameter passing and stack adjustment operations are hidden by this abstract, but low-level, instruction.</p><p>Pointer size and endianness of a hardware implementation are difficult to completely to abstract away. Type-safe programs can be compiled to LLVA object code will be automatically portable, without exposing such I-ISA details. Non-type-safe code, however, (e.g., machine-dependent code in C that is conditionally compiled for different platforms) requires exposing such details of the actual I-ISA configuration. For this reason, LLVA includes flags for properties that the source-language compiler can expose to the source program (currently, these are pointer size and endianness). This information is also encoded in the object file so that, using this information, the translator for a different hardware I-ISA can correctly execute the object code (although this emulation would incur a substantial performance penalty on I-ISAs without hardware support).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Exception Semantics</head><p>Previous experience with virtual processor architectures, particularly DAISY and Transmeta, show that there are three especially difficult features to emulate in traditional hardware interfaces: load/store dependences, precise exceptions, and self-modifying code. The LLVA V-ISA already simplifies detecting load/store dependences in one key way: the type, control-flow, and SSA information enable sophisticated alias analysis algorithms in the translator, as discussed in 5.1. For the other two issues also, we have the opportunity to minimize their impact through good V-ISA design.</p><p>Precise exceptions are important for implementing many programming languages correctly (without overly complex or inefficient code), but maintaining precise exceptions greatly restricts the ability of compiler optimizations to reorder code. Static compilers often have knowledge about operations that cannot cause exceptions (e.g., a load of a valid global in C), or operations whose exceptions can be ignored for a particular language (e.g., integer overflow in many languages).</p><p>We use two simple V-ISA rules to retain precise exceptions but expose non-excepting operations to the translator:</p><p>? Each LLVA instruction defines a set of possible exceptions that can be caused by executing that instruction. Any exception delivered to the program is precise, in terms of the visible state of an LLVA program.</p><p>? Each LLVA instruction has a boolean attribute named ExceptionsEnabled. Exceptions generated by an instruction are ignored if ExceptionsEnabled is false for that instruction; otherwise all exception conditions are delivered to the program. Exceptions-Enabled is true by default for load, store and div instructions. It is false by default for all other operations, notably all arithmetic operations.</p><p>Note also that the ExceptionsEnabledattribute is a static attribute and is provided in addition to other mechanisms provided by the V-ABI to disable exceptions dynamically at runtime (e.g. for use in trap handlers).</p><p>A second attribute for instructions we are considering would allow exceptions caused by the instruction to be delivered without being precise. Static compilers for languages like C and C++ could flag many untrapped exception conditions (e.g., memory faults) in this manner, allowing the translator to reorder such operations more freely (even if the hardware only supported precise exceptions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Self-modifying and Self-extending Code</head><p>We use the term Self-Modifying Code (SMC) for a program that explicitly modifies its own pre-existing instructions. We use the term Self-Extending Code (SEC) to refer to programs in which new code is added at runtime, but that do not modify any pre-existing code. SEC encompasses several behaviors such as class loading in Java <ref type="bibr" target="#b16">[17]</ref>, function synthesis in higher-order languages, and program-controlled dynamic code generation. SEC is generally much less problematic for virtual architectures than SMC. Furthermore, most commonly cited examples of "self-modifying code" (e.g., dynamic code generation for very high performance kernels or dynamic code loading in operating systems and virtual machines) are really examples of SEC rather than SMC. Nevertheless, SMC can be useful for implementing runtime code modifications in certain kinds of tools such as runtime instrumentation tools or dynamic optimization systems.</p><p>LLVA allows arbitrary SEC, and allows a constrained form of SMC that exploits the execution model for the V-ISA. In particular, a program may modify its own (virtual) instructions via a set of intrinsic functions, but such a change only affects future invocations of that function, not any currently active invocations. This ensures that SMC can be implemented efficiently and easily by the translator, simply by marking the function's generated code invalid, forcing it to be regenerated the next time the function is invoked.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Support for Operating Systems</head><p>LLVA uses two key mechanisms to support operating systems and user-space applications: intrinsic functions and a privileged bit. LLVA uses a small set of intrinsic functions to support operations like manipulating page tables and other kernel operations. These intrinsics are implemented by the translator for a particular target. Intrinsics can be defined to be valid only if the privileged bit is set to true, otherwise causing a kernel trap. A trap handler is an ordinary LLVA function with two arguments: the trap number and a pointer of type void* to pass in additional information to the handler. Trap handlers can refer to the register state of an LLVM program using a standard, program-independent register numbering scheme for virtual registers. Other intrinsic functions can be used to traverse the program stack and scan stack frames in an I-ISA-independent manner, and to register the entry points for trap handlers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Possible Extensions to the V-ISA</head><p>Thre are two important kinds of functionality that could be added to the V-ISA. First, the architecture certainly requires definition of synchronization operations and a memory model to support parallel programs (these primitives are difficult to make universal, and thus may have to be defined with a family of implementations in mind). Second, packed operations (also referred to as subword parallelism) are valuable to media and signal-processing codes. These operations must be encoded in the V-ISA because it is difficult for the translator to automatically synthesize them from ordinary sequential code. Finally, we are developing V-ISA extensions that provide machine-independent abstractions for chip parallelism. These extensions could be valuable as explicit on-chip parallelism becomes more prevalent (e.g., <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b30">31]</ref>), raising potentially serious challenges for preserving portability while achieving the highest possible performance across different generations of processors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Translation Strategy</head><p>The goals of our translation strategy are to (a) minimize the need for online translation, and (b) to exploit the novel optimization capabilities enabled by a rich, persistent code representation. This paper does not aim to develop new optimization techniques. We are developing such techniques in ongoing research, as part of a complete framework for lifelong code optimization on ordinary processors <ref type="bibr" target="#b25">[26]</ref>. Here, we focus on the VISC translation strategy and on the implications of the optimization capabilities for VISC designs.</p><p>We begin by describing the "on-chip" runtime execution engine (LLEE) that manages the translation process. We focus in particular on strategies by which it interacts with the surrounding software system to get access to offline storage and enable offline translation. We then describe how the translation strategy exploits the optimization capabilities enabled by a rich persistent code representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">LLEE: OS-Independent Translation System</head><p>We distinguish two scenarios with different primary constraints on the translation system. The first is when a processor is designed or optimized for a particular OS (e.g., PowerPCs customized for AS/400 systems running IBM's OS/400 <ref type="bibr" target="#b8">[9]</ref>). For a VISC processor in such a scenario, the translator can live in offline storage as part of the OS, it can be invoked to perform offline translation, and it can use OSspecific interfaces directly to read and write translations and profile information to offline storage. It can exploit all the optimization mechanisms enabled by the V-ISA, described below. Such a processor should obtain all the benefits of a VISC design without any need for online translation.</p><p>More commonly, however, a processor is designed with no assumptions about the OS or available storage. The lack of such knowledge places constraints on the translator, as can be seen in DAISY's and Crusoe's translation schemes <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b13">14]</ref>. Not only is the entire translator program located in ROM, but the translated code and any associated profile information live only in memory and are never cached in persistent storage between executions of a program. Consequently, programs are always translated online after being launched, if the translation does not exist in an in-memory cache.</p><p>We propose a translation strategy for such a situation that can enable offline translation and caching, if an OS ported to LLVA chooses to exploit it. We have developed a transparent execution environment called LLEE that embodies this strategy, though it is currently implemented at user-level on a standard POSIX system, as described below. It is depicted in Figure <ref type="figure" target="#fig_2">3</ref>.</p><p>The LLEE translation strategy can be summarized as "offline translation when possible, online translation whenever necessary." A subset (perhaps all) of the translator sufficient for translation and some set of optimizations would live in ROM or flash memory on the processor chip. It is invoked only by LLEE. The V-ABI defines a standard, OSindependent interface with a set of routines that enables LLEE to read, write, and validate data in offline storage. This interface is the sole "gateway" that LLEE could use to call into the OS. An OS ported to LLVA can choose to implement these routines for higher performance, but they are strictly optional and the system will operate correctly in their absence.</p><p>Briefly, the basic gateway includes routines to create, delete, and query the size of an offline cache, read or write a vector of N bytes tagged by a unique string name from/to a cache, and check a timestamp on an LLVA program or on a cached vector. Because these routines are implemented by the OS, and so cannot be linked into the translator, we also define one special LLVA intrinsic routine (recall that an intrinsic is a function implemented by the translator) that the OS can use at startup to register the address of the gateway routine with the translator. This gateway routine can then be called directly by the translator to query the addresses of other gateway routines, also at startup. This provides a simple but indefinitely extensible linkage mechanism between translator and OS.</p><p>LLEE orchestrates the translation process as follows. When the OS loads and transfers control to an LLVA executable in memory, LLEE is invoked by the processor hardware. If the OS gateway has been implemented, LLEE uses it to look for a cached translation of the code, checks its timestamp if it exists, and reads it into memory if the translation is not out of date. If successful, LLEE performs relocation as necessary on the native code and then transfers control to it directly. If any condition fails, LLEE invokes the JIT compiler on the entry function. Any new translated code generated by the JIT compiler can be written back to the offline cache if the gateway is available. During idle times, the OS can notify LLEE to perform offline translation of an LLVA program by initiating "execution" as above, but flagging it for translation and not actual execution.</p><p>Our implementation of LLEE is faithful to this description except: (a) LLEE is a user-level shared library that is loaded when starting a shell. This library overrides execve() with a new version that recognizes LLVA executables and either invokes the JIT on them or executes the cached native translations from the disk, using a user-level version of our gateway. (b) Both the JIT and offline compilers are ordinary programs running on Solaris and Linux, and the offline compiler reads and writes disk files directly. (c) LLVA executables can invoke native libraries not yet compiled to LLVA, e.g., the X11 library.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Optimization Strategy</head><p>The techniques above make it possible to perform offline translation for LLVA executables, even with a completely OS-independent processor design. There are also important new optimization opportunities created by the rich V-ISA code representation, that a VISC architecture can exploit, but most of which are difficult to for programs compiled directly to native code. These include:</p><p>1. Compile-time and link-time machine-independent optimization (outside the translator).</p><p>2. Install-time, I-ISA-specific optimization (before translation).</p><p>3. Runtime, trace-driven machine-specific optimization.</p><p>4. "Idle-time" (between executions) profile-guided, machine-specific optimization using profile information reflecting actual end-user behavior.</p><p>As noted earlier, the LLVA representation allow substantial optimization to be performed before translation, minimizing optimization that must be performed online. Of this, optimization at link-time is particularly important because it is the first time that most or all modules of an application are simultaneously available, without requiring changes to application Makefiles and without sacrificing the key benefits of separate compilation. In fact, many commercial compilers today perform interprocedural optimization at linktime, by exporting their proprietary compiler internal representation during static compilation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b19">20]</ref>. Such compilerspecific solutions are unnecessary with LLVA because it retains rich enough information to support extensive optimizations, as demonstrated in 5.1.</p><p>Install-time optimization is just an application of the translator's optimization and code generation capabilities to generate carefully tuned code for a particular system configuration. This is a direct benefit of retaining a rich code representation until software is installed, while still retaining the ability to do offline code generation.</p><p>Unlike other trace-driven runtime optimizers for native binary code, such as Dynamo <ref type="bibr" target="#b3">[4]</ref>, we have both the rich V-ISA and a cooperating code generator. Our V-ISA provides us with ability to perform static instrumentation to assist runtime path profiling, and to use the CFG at runtime to perform path profiling within frequently executed loop regions while avoiding interpretation. It also lets us develop an aggressive optimization strategy that operates on traces of LLVA code corresponding to the hot traces of native code. We have implemented the tracing strategy and software trace cache, including the ability to gather crossprocedure traces, <ref type="bibr" target="#b25">[26]</ref>, and we are now developing runtime optimizations that exploit these traces.</p><p>The rich information in LLVA also enables "idle-time" profile-guided optimization (PGO) using the translator's optimization and code generation capabilities. The important advantage is that this step can use profile information gathered from executions on an end-user's system. This has three distinct advantages over static PGO: (a) the profile information is more likely to reflect end-user behavior than hypothetical profile information generated by developers using predicted input sets; (b) developers often do not use profile-guided optimization or do so only in limited ways, whereas "idle-time" optimization can be completely transparent to users, if combined with low-overhead profiling techniques; and (c) idle-time optimization can combine profile information with detailed information about the user's specific system configuration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Initial Evaluation</head><p>We believe the performance implications of a Virtual ISA design cannot be evaluated meaningfully without (at least) a processor design with hardware mechanisms that support translation and optimization <ref type="bibr" target="#b10">[11]</ref>), and (preferably) basic cooperative hardware/software mechanisms that exploit the design. Since the key contribution of this paper is the design of LLVA, we focus on evaluating the features of this design. In particular, we consider the 2 questions listed in the Introduction: does the representation enable high-level analysis and optimizations, and is the representation low-level enough to closely match with hardware and to be translated efficiently?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Supporting High Level Optimizations</head><p>The LLVA code representation presented in this paper is also used as the internal representation of a sophisticated compiler framework we call Low Level Virtual Machine (LLVM) <ref type="bibr" target="#b25">[26]</ref>. LLVM includes front-ends for C and C++ based on GCC, code generators for both Intel IA-32 and SPARC V9 (each can be run either offline or as a JIT compiling functions on demand), a sophisticated link-time optimization system, and a software trace cache. Compared with the instruction set in Section 3, the differences in the compiler IR are: (a) the compiler extracts type information for memory allocation operations and converts them into typed malloc and free instructions (the back-ends translate these back into the library calls), and (b) the Excep-tionEnabled bit is hardcoded based on instruction opcode. The compiler system uses equivalent internal and external representations, avoiding the need for complex translations at each stage of the compilation process.</p><p>The compiler uses the virtual instruction set for a variety of analyses and optimizations including many classical dataflow and control-flow optimizations, as well as more aggressive link-time interprocedural analyses and transformations. The classical optimizations directly exploit the control-flow graph, SSA representation, and several choices of pointer analysis. They are usually performed on a per module-basis, before linking the different LLVA object code modules, but can be performed at any stage of a program's lifetime where LLVA code is available.</p><p>We also perform several novel interprocedural techniques using the LLVA representation, all of which operate at link-time. Data Structure Analysis is an efficient, contextsensitive pointer analysis, which computes both an accurate call graph and points-to information. Most importantly, it is able to identify information about logical data structures (e.g., an entire list, hashtable, or graph), including disjoint instances of such structures, their lifetimes, their internal static structure, and external references to them. Automatic Pool Allocation is a powerful interprocedural transformation that uses Data Structure Analysis to partition the heap into separate pools for each data structure instance <ref type="bibr" target="#b24">[25]</ref>. Finally, we have shown that the LLVA representation is rich enough to perform complete, static analysis of memory safety for a large class of type-safe C programs <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b12">13]</ref>. This work uses both the techniques above, plus an interprocedural array bounds check removal algorithm <ref type="bibr" target="#b23">[24]</ref> and some custom interprocedural dataflow and control flow analyses <ref type="bibr" target="#b12">[13]</ref>.</p><p>The interprocedural techniques listed above are traditionally considered very difficult even on source-level imperative languages, and are impractical for machine code. In fact, all of these techniques fundamentally require type information for pointers, arrays, structures and functions in LLVA plus the Control Flow Graph. The SSA representation significantly improves both the precision and speed of the analyses and transformations. Overall, these examples amply demonstrate that the virtual ISA is rich enough to support powerful (language-independent) compiler tasks traditionally performed only in source-level compilers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Low-level Nature of the Instruction Set</head><p>Table <ref type="table" target="#tab_1">2</ref> presents metrics to evaluate the low-level nature of the LLVA V-ISA. The benchmarks we use include the PtrDist benchmarks <ref type="bibr" target="#b1">[2]</ref> and the SPEC CINT2000 benchmarks (we omit three SPEC codes because their LLVAobject code versions fail to link currently). The first two columns in the table list the benchmark names and the number of lines of C source code for each.</p><p>Columns 3 and 4 in the table show the fully linked code sizes for a statically compiled native executable and for the LLVA object program. The native code is generated from the LLVA object program using our static back end for SPARC V9. These numbers are comparable because they reflect the same LLVA optimizations were applied in both cases. The numbers show that the virtual object code is significantly smaller than the native code, roughly 1.3x to 2x for the larger programs in the table (the smaller programs have even larger ratios) <ref type="foot" target="#foot_1">2</ref> . Overall, despite containing extra type and control flow information and using SSA form, the virtual code is still quite compact for two reasons. First, most instructions usually fit in a single 32-bit word. Second, the virtual code does not include verbose machine-specific code for argument passing, register saves and restores, loading large immediate constants, etc.</p><p>The next five columns show the number of LLVA instructions, the total number of machine instructions generated by the X86 back-end, and the ratio of the latter to the former (also for Sparc). This back-end performs virtually no optimization and very simple register allocation resulting in significant spill code. Nevertheless, each LLVA instruction translates into very few I-ISA instructions on average; about 2-3 for X86 and 3-4 for SPARC V9. Furthermore, all LLVA instructions are translated directly to native machine code -no emulation routines are used at all. These results indicate that the LLVA instruction set uses low-level operations that match closely with native hardware instructions.</p><p>Finally, the last three columns in the table show the total code generation time taken by the X86 JIT compiler to compile the entire program (regardless of which functions are actually executed), the total running time of each program when compiled natively for X86 using gcc -O3, and the ratio of the two. As the table shows, the JIT compilation times are negligible, except for large codes with short running time. Furthermore, this behavior should extend to much larger programs as well because the JIT translates functions on demand, so that unused code is not translated (we show the compilation time for the entire program, since that makes the data easier to understand). Overall, this data Overall, both the instruction count ratio and the JIT compilation times show that the LLVA V-ISA is very closely matched to hardware instruction sets in terms of the complexity of the operations, while the previous subsection showed that it includes enough high-level information for sophisticated compiler optimizations. This combination of high-level information with low-level operations is the crucial feature that (we believe) makes the LLVA instruction set a good design for a Virtual Instruction Set Architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Related Work</head><p>Virtual machines of different kinds have been widely used in many software systems, including operating systems (OS), language implementations, and OS and hardware emulators. These uses do not define a Virtual ISA at the hardware level, and therefore do not directly benefit processor design (though they may influence it). The challenges of using two important examples -Java Virtual Machine and Microsoft CLI -as a processor-level virtual ISA were discussed in the Introduction.</p><p>We know of four previous examples of VISC architectures, as defined in Section 1: the IBM System/38 and AS/400 family <ref type="bibr" target="#b8">[9]</ref>, the DAISY project at IBM Research <ref type="bibr" target="#b13">[14]</ref>, Smith et al.'s proposal for Codesigned Virtual Machines in the Strata project <ref type="bibr" target="#b31">[32]</ref>, and Transmeta's Crusoe family of processors <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b10">11]</ref>. All of these distinguish the virtual and physical ISAs as a fundamental processor design technique. To our knowledge, however, none except the IBM S/38 and AS/400 have designed a virtual instruction set for use in such architectures.</p><p>The IBM AS/400, building on early ideas in the S/38, defined a Machine Interface (MI) that was very high-level, abstract and hardware-independent (e.g., it had no registers or storage locations). It was the sole interface for all application software and for much of OS/400. Their design, however, differed from ours in fundamental ways, and hence does not meet the goals we laid out in Section 2. Their MI was targeted at a particular operating system (the OS/400), it was designed to be implemented using complex operating system and database services and not just a translator, and was designed to best support a particular workload class, viz., commercial database-driven workloads. It also had a far more complex instruction set than ours (or any CISC processors), including string manipulation operations, and "object" manipulation operations for 15 classes of objects (e.g., programs and files). In contrast, our V-ISA is philosophically closer to modern processor instruction sets in being a minimal, orthogonal, load/store architecture; it is OSindependent and requires no software other than a translator; and it is designed to support modern static and dynamic optimization techniques for general-purpose software. DAISY <ref type="bibr" target="#b13">[14]</ref> developed a dynamic translation scheme for emulating multiple existing hardware instruction sets (Pow-erPC, Intel IA-32, and S/390) on a VLIW processor. They developed a novel translation scheme with global VLIW scheduling fast enough for online use, and hardware extensions to assist the translation. Their translator operated on a page granularity. Both the DAISY and Transmeta translators are stored entirely in ROM on-chip. Because they focus on existing V-ISAs with existing OS/hardware interface specifications, they cannot assume any OS support and thus cannot cache any translated code or profile information in off-processor storage, or perform any offline translation.</p><p>Transmeta's Crusoe uses a dynamic translation scheme to emulate Intel IA-32 instructions on a VLIW hardware processor <ref type="bibr" target="#b22">[23]</ref>. The hardware includes important supporting mechanisms such as shadowed registers and a gated store buffer for speculation and rollback recovery on exceptions, and alias detection hardware in the load/store pipeline. Their translator, called Code Morphing Software (CMS), exploits these hardware mechanisms to reorder instructions aggressively in the presence of the challenging features identified in Section 3.3, namely, precise exceptions, memory dependences, and self-modifying code (as well as memory-mapped I/O) <ref type="bibr" target="#b10">[11]</ref>. They use a trace-driven reoptimization scheme to optimize frequently executed dynamic sequences of code. Crusoe does do not perform any offline translation or offline caching, as noted above.</p><p>Smith et al. in the Strata project have recently but perhaps most clearly articulated the potential benefits of VISC processor designs, particularly the benefits of codesigning the translator and a hardware processor with an implementation-dependent ISA <ref type="bibr" target="#b31">[32]</ref>. They describe a number of examples illustrating the flexibility hardware designers could derive from this strategy. They have also developed several hardware mechanisms that could be valuable for implementing such architectures, including relational profiling <ref type="bibr" target="#b18">[19]</ref>, a microarchitecture with a hierarchical register file for instruction-level distributed processing <ref type="bibr" target="#b21">[22]</ref>, and hardware support for working set analysis <ref type="bibr" target="#b11">[12]</ref>. They do not propose a specific choice of V-ISA, but suggest that one choice would be to use Java VM as the V-ISA (an option we discussed in the Introduction).</p><p>Previous authors have developed Typed Assembly Languages <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b6">7]</ref> with goals that generally differ significantly from ours. Their goals are to enable compilation from strongly typed high-level languages to typed assembly language, enabling sound (type preserving) program transformations, and to support program safety checking. Their type systems are higher-level than ours, because they attempt to propagate significant type information from source programs. In comparison, our V-ISA uses a much simpler, lowlevel type system aimed at capturing the common low-level representations and operations used to implement computations from high-level languages. It is also designed to to support arbitrary non-type-safe code efficiently, including operating system and kernel code.</p><p>Binary translation has been widely used to provide binary compatibility for legacy code. For example, the FX!32 tool uses a combination of online interpretation and offline profile-guided translation to execute Intel IA-32 code on Alpha processors <ref type="bibr" target="#b7">[8]</ref>. Unlike such systems, a VISC architecture makes binary translation an essential part of the design strategy, using it for all codes, not just legacy codes.</p><p>There is a wide range of work on software and hardware techniques for transparent dynamic optimization of programs. Transmeta's CMS <ref type="bibr" target="#b10">[11]</ref> and Dynamo <ref type="bibr" target="#b3">[4]</ref> identify and optimize hot traces at runtime, similar to our re-optimization strategy but without the benefits of a rich V-ISA. Many JIT compilers for Java, Self, and other languages combine fast initial compilation with adaptive reoptimization of "hot" methods (e.g., see <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b33">34]</ref>). Finally, many hardware techniques have been proposed for improving the effectiveness of dynamic optimization <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b34">35]</ref>. When combined with a rich V-ISA that supports more effective program analyses and transformations, these software and hardware techniques can further enhance the benefits of VISC architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions and Future Work</head><p>Trends in modern processors indicate that CPU cycles and raw transistors are becoming increasingly cheap, while control complexity, wire delays, power, reliability, and testing cost are becoming increasingly difficult to manage. Both trends favor virtual processor architectures: the extra CPU cycles can be spent on software translation, the extra transistors can be spent on mechanisms to assist that translation, and a cooperative hardware/software design supported by a rich virtual program representation could be used in numerous ways to reduce hardware complexity and potentially increase overall performance.</p><p>This paper presented LLVA, a design for a languageindependent, target-independent virtual ISA. The instruction set is low-level enough to map directly and closely to hardware operations but includes high-level type, controlflow and dataflow information needed to support sophisticated analysis and optimization. It includes novel mechanisms to overcome the difficulties faced by previous virtual architectures such as DAISY and Transmeta's Crusoe, including a flexible exception model, minor constraints on self-modifying code to dovetail with the compilation strategy, and an OS-independent interface to access offline storage and enable offline translation.</p><p>Evaluating the benefits of LLVA requires a long-term research program. We have three main goals in the near future: (a) Develop and evaluate cooperative (i.e., codesigned) software/hardware design choices that reduce hardware complexity and assist the translator to achieve high overall performance. (b) Extend the V-ISA with machineindependent abstractions of fine-and medium-grain parallelism, suitable for mapping to explicitly parallel processor designs, as mentioned in Section 3.6. (c) Port an existing operating system (in incremental steps) to work on top of the LLVA architecture, and explore the OS design implications of such an implementation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>t y p e d e f s t r u c t QuadTree { d o u b l e D a t a ; s t r u c t</head><label></label><figDesc>QuadTree * C h i l d r e n [ 4 ] ; } QT ; v o i d S u m 3 r d C h i l d r e n (QT * T , d o u b l e * R e s u l t ) { d o u b l e R e t ; i f ( T = = 0 ) { R e t = 0 ; } e l s e { QT * C h i l d 3 = T [ 0 ] . C h i l d r e n [ 3 ] ; d o u b l e V; S u m 3 r d C h i l d r e n ( C h i l d 3 , &amp;V ) ; R e t = V + T [ 0 ] . D a t a ; } * R e s u l t = R e t ; } (a) Example function %s t r u c t . QuadTree = t y p e { double , [ 4 x %QT * ] } %QT = t y p e % s t r u c t . QuadTree v o i d % S u m 3 r d C h i l d r e n (%QT * %T , d o u b l e * % R e s u l t ) { e n t r y : %V = a l l o c a d o u b l e ; ; %V i s t y p e ' d o u b l e * ' %tmp . 0 = s e t e q %QT * %T , n u l l ; ; t y p e ' b o o l ' br b o o l %tmp . 0 , l a b e l % e n d i f , l a b e l % e l s e e l s e : ; ; tmp . 1 = &amp; T [ 0 ] . C h i l d r e n [ 3 ] ' C h i l d r e n ' = F i e l d # 1 %tmp . 1 = g e t e l e m e n t p t r %QT * %T , l o n g 0 , u b y t e 1 , l o n g 3 %C h i l d 3 = l o a d %QT * * %tmp . 1 c a l l v o i d % S u m 3 r d C h i l d r e n (%QT * % C h i l d 3 , d o u b l e * %V) %tmp . 2 = l o a d d o u b l e * %V %tmp . 3 = g e t e l e m e n t p t r %QT * %T , l o n g 0 , u b y t e 0 %tmp . 4 = l o a d d o u b l e * %tmp . 3 %R e t . 0 = add d o u b l e %tmp . 2 , % tmp . 4 br l a b e l % e n d i f e n d i f : %R e t . 1 = p h i d o u b l e [ % R e t . 0 , % e l s e ] , [ 0 . 0 , % e n t r y ] s t o r e d o u b l e % R e t . 1 , d o u b l e * % R e s u l t r e t v o i d ; ; R e t u r n w i t h no v a l u e } (b) Corresponding LLVA code</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. C and LLVA code for a function</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. The LLVA execution manager and interface to offline storage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 . Entire LLVA Instruction Set</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell>Name</cell></row><row><cell>arithmetic</cell><cell>add, sub, mul, div, rem</cell></row><row><cell>bitwise</cell><cell>and, or, xor, shl, shr</cell></row><row><cell cols="2">comparison seteq, setne, setlt, setgt, setle, setge</cell></row><row><cell>control-flow</cell><cell>ret, br, mbr, invoke, unwind</cell></row><row><cell>memory</cell><cell>load, store, getelementptr, alloca</cell></row><row><cell>other</cell><cell>cast, call, phi</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 . Metrics demonstrating code size and low-level nature of the V-ISA shows</head><label>2</label><figDesc>that it is possible to do a very fast, non-optimizing translation of LLVA code to machine code at very low cost. Any support to translate code offline and/or to cache translated code offline should further reduce the impact of this translation cost.</figDesc><table><row><cell>Program</cell><cell>#LOC</cell><cell>Native</cell><cell>LLVM code</cell><cell>#LLVM</cell><cell>#X86</cell><cell>Ratio</cell><cell>#SPARC</cell><cell>Ratio</cell><cell>Translate</cell><cell>Run</cell><cell>Ratio</cell></row><row><cell></cell><cell></cell><cell>size (KB)</cell><cell>size (KB)</cell><cell>Inst.</cell><cell>Inst.</cell><cell></cell><cell>Inst.</cell><cell></cell><cell>Time (s)</cell><cell>time (s)</cell><cell></cell></row><row><cell>ptrdist-anagram</cell><cell>647</cell><cell>21.7</cell><cell>10.7</cell><cell>776</cell><cell>1817</cell><cell>2.34</cell><cell>2550</cell><cell>3.29</cell><cell>0.0078</cell><cell>1.317</cell><cell>0.006</cell></row><row><cell>ptrdist-ks</cell><cell>782</cell><cell>24.9</cell><cell>12.1</cell><cell>1059</cell><cell>2732</cell><cell>2.58</cell><cell>4446</cell><cell>4.20</cell><cell>0.0039</cell><cell>1.694</cell><cell>0.002</cell></row><row><cell>ptrdist-ft</cell><cell>1803</cell><cell>20.9</cell><cell>10.1</cell><cell>799</cell><cell>1990</cell><cell>2.49</cell><cell>2818</cell><cell>3.53</cell><cell>0.0117</cell><cell>2.797</cell><cell>0.004</cell></row><row><cell>ptrdist-yacr2</cell><cell>3982</cell><cell>58.3</cell><cell>36.5</cell><cell>4279</cell><cell>10881</cell><cell>2.54</cell><cell>12252</cell><cell>2.86</cell><cell>0.0429</cell><cell>2.686</cell><cell>0.016</cell></row><row><cell>ptrdist-bc</cell><cell>7297</cell><cell>112.0</cell><cell>74.4</cell><cell>7276</cell><cell>19286</cell><cell>2.65</cell><cell>25697</cell><cell>3.53</cell><cell>0.1308</cell><cell>1.307</cell><cell>0.100</cell></row><row><cell>179.art</cell><cell>1283</cell><cell>37.8</cell><cell>17.9</cell><cell>2027</cell><cell>5385</cell><cell>2.66</cell><cell>7031</cell><cell>3.47</cell><cell>0.0253</cell><cell>114.723</cell><cell>0.000</cell></row><row><cell>183.equake</cell><cell>1513</cell><cell>44.4</cell><cell>23.9</cell><cell>2863</cell><cell>6409</cell><cell>3.14</cell><cell>8275</cell><cell>2.89</cell><cell>0.0273</cell><cell>18.005</cell><cell>0.002</cell></row><row><cell>181.mcf</cell><cell>2412</cell><cell>32.0</cell><cell>17.3</cell><cell>2039</cell><cell>4707</cell><cell>2.31</cell><cell>4601</cell><cell>2.26</cell><cell>0.0175</cell><cell>24.516</cell><cell>0.001</cell></row><row><cell>256.bzip2</cell><cell>4647</cell><cell>73.5</cell><cell>55.7</cell><cell>5103</cell><cell>11984</cell><cell>2.35</cell><cell>14157</cell><cell>2.77</cell><cell>0.0371</cell><cell>20.896</cell><cell>0.002</cell></row><row><cell>164.gzip</cell><cell>8616</cell><cell>94.0</cell><cell>68.6</cell><cell>7594</cell><cell>17500</cell><cell>2.30</cell><cell>20880</cell><cell>2.75</cell><cell>0.0527</cell><cell>19.332</cell><cell>0.003</cell></row><row><cell>197.parser</cell><cell>11391</cell><cell>223.0</cell><cell>175.3</cell><cell>17138</cell><cell>41671</cell><cell>2.43</cell><cell>57274</cell><cell>3.34</cell><cell>0.1601</cell><cell>4.718</cell><cell>0.034</cell></row><row><cell>188.ammp</cell><cell>13483</cell><cell>265.1</cell><cell>163.2</cell><cell>21961</cell><cell>53529</cell><cell>2.44</cell><cell>67679</cell><cell>3.08</cell><cell>0.1074</cell><cell>58.758</cell><cell>0.002</cell></row><row><cell>175.vpr</cell><cell>17729</cell><cell>331.0</cell><cell>184.4</cell><cell>18041</cell><cell>58982</cell><cell>3.27</cell><cell>74696</cell><cell>4.14</cell><cell>0.1425</cell><cell>7.924</cell><cell>0.018</cell></row><row><cell>300.twolf</cell><cell>20459</cell><cell>487.7</cell><cell>330.0</cell><cell>45017</cell><cell>104613</cell><cell>2.32</cell><cell>119691</cell><cell>2.66</cell><cell>0.0156</cell><cell>9.680</cell><cell>0.002</cell></row><row><cell>186.crafty</cell><cell>20650</cell><cell>555.5</cell><cell>336.4</cell><cell>34080</cell><cell>104093</cell><cell>3.05</cell><cell>110630</cell><cell>3.25</cell><cell>0.4531</cell><cell>15.408</cell><cell>0.029</cell></row><row><cell>255.vortex</cell><cell>67223</cell><cell>976.3</cell><cell>719.3</cell><cell>72039</cell><cell>195648</cell><cell>2.72</cell><cell>224488</cell><cell>3.12</cell><cell>0.7773</cell><cell>6.753</cell><cell>0.115</cell></row><row><cell>254.gap</cell><cell>71363</cell><cell>1088.1</cell><cell>854.4</cell><cell>111482</cell><cell>246102</cell><cell>2.21</cell><cell>272483</cell><cell>2.44</cell><cell>0.4824</cell><cell>3.729</cell><cell>0.129</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In contrast, extracting a Control Flow Graph from normal machine code can be quite difficult in practice, due to indirect branches.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>The GCC compiler generates more compact SPARC V8 code, which is roughly equal in size to the bytecode<ref type="bibr" target="#b25">[26]</ref>.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We thank <rs type="person">Jim Smith</rs>, <rs type="person">Sarita Adve</rs>, <rs type="person">John Criswell</rs> and the anonymous referees for their detailed feedback on this paper. This work has been supported by an <rs type="funder">NSF</rs> <rs type="grantName">CA-REER award</rs>, <rs type="grantNumber">EIA-0093426</rs>, the <rs type="funder">NSF</rs> <rs type="programName">Operating Systems and Compilers program</rs> under grant number <rs type="grantNumber">CCR-9988482</rs>, and the <rs type="institution">SIA</rs>'s <rs type="programName">MARCO Focus Center program</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_KvPpjUS">
					<idno type="grant-number">EIA-0093426</idno>
					<orgName type="grant-name">CA-REER award</orgName>
				</org>
				<org type="funding" xml:id="_ANJSs9a">
					<idno type="grant-number">CCR-9988482</idno>
					<orgName type="program" subtype="full">Operating Systems and Compilers program</orgName>
				</org>
				<org type="funding" xml:id="_HCb2b7u">
					<orgName type="program" subtype="full">MARCO Focus Center program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fast and effective code generation in a just-in-time Java compiler</title>
		<author>
			<persName><forename type="first">A.-R</forename><surname>Adl-Tabatabai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="1998-05">May 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The pointer-intensive benchmark suite</title>
		<author>
			<persName><forename type="first">T</forename><surname>Austin</surname></persName>
		</author>
		<ptr target="www.cs.wisc.edu/?austin/ptr-dist.html" />
		<imprint>
			<date type="published" when="1995-09">Sept 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Scalable cross-module optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peyton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schooler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGPLAN Notices</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="301" to="312" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Dynamo: A transparent dynamic optimization system</title>
		<author>
			<persName><forename type="first">V</forename><surname>Bala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Duesterwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Banerjia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="2000-06">June 2000</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Billion-transistor architectures</title>
		<author>
			<persName><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="46" to="49" />
			<date type="published" when="1997-09">Sept 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The Jalape?o Dynamic Optimizing Compiler for Java</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Serrano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">C</forename><surname>Sreedhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Whaley</surname></persName>
		</author>
		<editor>Java Grande</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="129" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A provably sound TAL for back-end optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Appel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<meeting><address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-06">Jun 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">FX!32: A profile-directed binary translator</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chernoff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>IEEE Micro</publisher>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="56" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Application system/400 performance characteristics</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Corrigan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Systems Journal</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="407" to="423" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Efficiently computing static single assignment form and the control dependence graph</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cytron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ferrante</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Rosen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Wegman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">K</forename><surname>Zadeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TOPLAS</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="451" to="490" />
			<date type="published" when="1991-10">October 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The Transmeta Code Morphing Software: Using speculation, recovery and adaptive retranslation to address real-life challenges</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Dehnert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1 st IEEE/ACM Symp. Code Generation and Optimization</title>
		<meeting>1 st IEEE/ACM Symp. Code Generation and Optimization<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-03">Mar 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Managing multiconfiguration hardware via dynamic working set analysis</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Dhodapkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<meeting><address><addrLine>Alaska</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-05">May 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Memory safety without runtime checks or garbage collection</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dhurjati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kowshik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Adve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lattner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LCTES</title>
		<meeting><address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-06">Jun 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">DAISY: Dynamic compilation for 100% architectural compatibility</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ebcioglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Altman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="26" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Walk-time techniques: Catalyst for architectural change</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="46" to="88" />
			<date type="published" when="1997-09">Sept 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On the importance of points-to analysis and other memory disambiguation methods for C programs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ghiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lavery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sehr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Gosling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Joy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Steele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bracha</surname></persName>
		</author>
		<title level="m">The Java Language Specification, 2 nd Ed</title>
		<meeting><address><addrLine>Reading, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">The Java HotSpot Virtual Machine Architecture</title>
		<author>
			<persName><forename type="first">D</forename><surname>Griswold</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Relational profiling: enabling thread-level parallelism in virtual machines</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Heil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO</title>
		<meeting><address><addrLine>Monterey, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-12">Dec 2000</date>
			<biblScope unit="page" from="281" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">XL FORTRAN: Eight Ways to Boost Performance</title>
		<author>
			<persName><surname>Ibm Corp</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>White Paper</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Special Issue on Intel HyperThreading Technology in Pentium 4 Processors</title>
		<author>
			<persName><forename type="first">Intel</forename><surname>Corp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intel Technology Journal, Q</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An instruction set and microarchitecture for instruction level distributed processing</title>
		<author>
			<persName><forename type="first">H.-S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<meeting><address><addrLine>Alaska</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-05">May 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Klaiber</surname></persName>
		</author>
		<title level="m">The Technology Behind Crusoe Processors</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Ensuring code safety without runtime checks for real-time control systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kowshik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dhurjati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Adve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CASES</title>
		<meeting><address><addrLine>Grenoble, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-10">Oct 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automatic Pool Allocation for Disjoint Data Structures</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lattner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Adve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGPLAN Workshop on Memory System Performance</title>
		<meeting>ACM SIGPLAN Workshop on Memory System Performance<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-06">Jun 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">LLVM: A Compilation Framework for Lifelong Program Analysis and Transformation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lattner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Adve</surname></persName>
		</author>
		<idno>UIUCDCS-R-2003-2380</idno>
		<imprint>
			<date type="published" when="2003-09">Sept 2003</date>
		</imprint>
		<respStmt>
			<orgName>Computer Science Dept., Univ. of Illinois at Urbana-Champaign</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Report</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A hardware mechanism for dynamic extraction and relayout of program hot spots</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Merten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Trick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Nystrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M W</forename><surname>Hwu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="2000-06">Jun 2000</date>
			<biblScope unit="page" from="59" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">From System F to typed assembly language</title>
		<author>
			<persName><forename type="first">G</forename><surname>Morrisett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Crary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Glew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TOPLAS</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="528" to="569" />
			<date type="published" when="1999-05">May 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Parallelism in the front-end</title>
		<author>
			<persName><forename type="first">P</forename><surname>Oberoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="2003-06">June 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">rePLay: A Hardware Framework for Dynamic Optimization</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Lumetta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<date type="published" when="2001-06">Jun 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Exploiting ILP, TLP, and DLP with the Polymorphous TRIPS Architecture</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sankaralingam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nagarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="2003-06">June 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Achieving high performance via co-designed virtual machines</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Heil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bezenek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Innovative Architecture (IWIA)</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Sinharoy. The POWER4 system microarchitecture</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Tendler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Dodson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Fields</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="26" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Self: The power of simplicity</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OOPSLA</title>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A programmable coprocessor for profiling</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zilles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
		<imprint>
			<date type="published" when="2001-01">Jan 2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
