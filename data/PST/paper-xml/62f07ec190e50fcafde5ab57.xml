<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GLOBAL POINTER: NOVEL EFFICIENT SPAN-BASED APPROACH FOR NAMED ENTITY RECOGNITION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-08-08">August 8, 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jianlin</forename><surname>Su</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Zhuiyi Technology Co</orgName>
								<address>
									<settlement>Ltd. Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ahmed</forename><surname>Murtadha</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Zhuiyi Technology Co</orgName>
								<address>
									<settlement>Ltd. Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shengfeng</forename><surname>Pan</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Zhuiyi Technology Co</orgName>
								<address>
									<settlement>Ltd. Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jing</forename><surname>Hou</surname></persName>
							<email>houjing21@mails.ucas.ac.cn</email>
							<affiliation key="aff3">
								<orgName type="department">School of Economics and Management</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jun</forename><surname>Sun</surname></persName>
							<email>jainasun@wezhuiyi.com</email>
							<affiliation key="aff4">
								<orgName type="institution">Zhuiyi Technology Co</orgName>
								<address>
									<settlement>Ltd. Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wanwei</forename><surname>Huang</surname></persName>
							<email>huangwanwei@wezhuiyi.com</email>
							<affiliation key="aff5">
								<orgName type="institution">Zhuiyi Technology Co</orgName>
								<address>
									<settlement>Ltd. Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bo</forename><surname>Wen</surname></persName>
							<affiliation key="aff6">
								<orgName type="institution">Zhuiyi Technology Co</orgName>
								<address>
									<settlement>Ltd. Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yunfeng</forename><surname>Liu</surname></persName>
							<affiliation key="aff7">
								<orgName type="institution">Zhuiyi Technology Co</orgName>
								<address>
									<settlement>Ltd. Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">GLOBAL POINTER: NOVEL EFFICIENT SPAN-BASED APPROACH FOR NAMED ENTITY RECOGNITION</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-08-08">August 8, 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2208.03054v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Named Entity Recognition</term>
					<term>Relation Extraction</term>
					<term>Natural Language Processing</term>
					<term>Multi-label loss</term>
					<term>Deep Neural Networks</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Named entity recognition (NER) task aims at identifying entities from a piece of text that belong to predefined semantic types such as person, location, organization, etc. The state-of-the-art solutions for flat entities NER commonly suffer from capturing the fine-grained semantic information in underlying texts. The existing span-based approaches overcome this limitation, but the computation time is still a concern. In this work, we propose a novel span-based NER framework, namely Global Pointer (GP), that leverages the relative positions through a multiplicative attention mechanism. The ultimate goal is to enable a global view that considers the beginning and the end positions to predict the entity. To this end, we design two modules to identify the head and the tail of a given entity to enable the inconsistency between the training and inference processes. Moreover, we introduce a novel classification loss function to address the imbalance label problem. In terms of parameters, we introduce a simple but effective approximate method to reduce the training parameters. We extensively evaluate GP on various benchmark datasets. Our extensive experiments demonstrate that GP can outperform the existing solution. Moreover, the experimental results show the efficacy of the introduced loss function compared to softmax and entropy alternatives.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>and nested entities. Flat NER has been widely addressed as a sequence labeling problem <ref type="bibr">Lample et al. [2016a]</ref>. Nested entities have shown importance in various real-world applications due to their multi-granularity semantic meaning <ref type="bibr" target="#b7">Alex et al. [2007]</ref>, <ref type="bibr" target="#b8">Yuan et al. [2020]</ref>. However, a given token may have multiple labels and thus renders applying sequence labeling-based approaches unattainable Finkel and <ref type="bibr" target="#b9">Manning [2009]</ref>.</p><p>With the rapid development of deep neural network (DNN), NER task has experienced a shift towards the contextual representation learning. The earlier DNN-based approaches have treated NER as a sequence labeling problem <ref type="bibr" target="#b10">Huang et al. [2015]</ref>, <ref type="bibr">Wang et al. [2020]</ref>, <ref type="bibr">Lample et al. [2016b]</ref>. They commonly attempt to address each token individually by capturing the type and position information. Despite the effectiveness of these approaches, they cannot perform span-based NER, also called nested NER, in which the entity consists of more than one token Finkel and <ref type="bibr" target="#b9">Manning [2009]</ref>. DNN-based approaches for nested NER usually attempt to learn span-specific deep representation in order to classify the corresponding typeZheng et al. <ref type="bibr">[2019]</ref>, <ref type="bibr" target="#b14">Wadden et al. [2019]</ref>, <ref type="bibr" target="#b15">Tan et al. [2020]</ref>, <ref type="bibr">Wang et al. [2020]</ref>, <ref type="bibr" target="#b16">Yu et al. [2020]</ref>. Recently, nested NER has experienced a shift towards pretrained language model. Several works show that the fine-tuning approach for span representation and classification can achieve satisfactory results <ref type="bibr" target="#b17">Luan et al. [2019]</ref>, <ref type="bibr" target="#b18">Zhong and Chen [2020]</ref>. The authors of <ref type="bibr" target="#b19">Yuan et al. [2021]</ref> introduced modeling heterogeneous factors (e.g., inside tokens) to enhance span representation learning.</p><p>Despite the effectiveness of the aforementioned approaches for nested NER, the representation of a given span is simply the combination of its head and tail and thus ignores the boundary information. To carry out a segment classification, the number of segments is set to the maximum length of span. Moreover, the low-quality spans, especially with long entities, dominate the corpus and thus requires high computational costs. To address the aforementioned limitations, there exist some approaches initiated the solution. The authors of <ref type="bibr">Fu et al. proposed</ref> to take the span length information into account during the training process. Another work <ref type="bibr">Shen et al. introduced</ref> to jointly address span classification and boundary regression in a unified framework to alleviate boundary information issue. However, the implantation of these approaches is a bit complicated and may be bothersome in real-world scenarios.</p><p>In this paper, we propose a novel solution, namely Global Pointer (GP), to address span-based NER task. Specifically, we leverage the relative positions through a multiplicative attention mechanism <ref type="bibr" target="#b22">Su et al. [2021]</ref>. The ultimate goal is to enable a global view that considers the beginning and the end positions (i.e., the head and tail information) to predict the entity. To achieve this, we design two modules to identify the head and the tail of a given entity to enable the inconsistency between the training and inference processes. In addition, to alleviate the burden of class imbalance in NER, we extend the softmax and cross-entropy in a universal loss function. It is noteworthy that the number of parameters of the proposed solution increases when a new entity type is added. Note that the introduced loss can be applied to any task suffering from the label imbalance issue. To remedy this issue, we introduce another extension of GP, namely efficient GP, based on an effective approximate method to reduce the number of parameters. We extensively evaluate GP on various benchmark datasets. Our extensive experiments demonstrate that GP can outperform the existing solution. Moreover, the experimental results show the efficacy of the introduced loss function compared to softmax and entropy alternatives.</p><p>In brief, the main contributions are three-fold:</p><p>? We propose a novel solution, namely Global Pointer (GP), to address span-based NER task that leverages the relative positions through a multiplicative attention mechanism. ? we extend the softmax and cross-entropy in a universal loss function to perform class imbalance scenarios, NER is an example. In addition, we propose an effective approximation method to reduce the training parameters when a new entity type is added. ? We extensively evaluate the proposed solution on various benchmark datasets. Our extensive experiments demonstrate that the proposed solution can outperform the existing solutions. Moreover, the experimental results validate the efficacy of the introduced loss function compared to softmax and entropy alternatives.</p><p>The remaining of the paper is organized as follows. Section 2 reviews related work. Section 3 describes the propose solution. Section 4 presents the experimental settings and empirically evaluates the performance of the proposed solution. Finally, we conclude this paper with Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>NER has received extensive attention of researchers in the last decades. The earlier solutions include rule-based <ref type="bibr" target="#b23">Kim and Woodland [2000]</ref>, <ref type="bibr" target="#b24">Sekine and Nobata [2004]</ref>, <ref type="bibr" target="#b25">Hanisch et al. [2005]</ref>, Quimbaya et al. <ref type="bibr">[2016]</ref>, Unsupervised learning <ref type="bibr" target="#b5">Etzioni et al. [2005]</ref>, <ref type="bibr" target="#b27">Zhang and Elhadad [2013]</ref>, Feature-based supervised learning approaches <ref type="bibr" target="#b28">Szarvas et al. [2006]</ref>, <ref type="bibr" target="#b29">Liu et al. [2011]</ref>, <ref type="bibr" target="#b30">Rockt?schel et al. [2012]</ref>. However, the performance of these approaches heavily relies on feature extraction and hand-crafted rules, which may be bothersome in real-world scenarios. With the rapid development of deep neural networks, various approaches were introduced to address NER task as a classification problem <ref type="bibr" target="#b31">Zhang et al. [2015]</ref>. The key idea is to learn entity-specific representation to model the semantic relation between two entities. Convolutional neural networks <ref type="bibr" target="#b32">Yao et al. [2015]</ref>, <ref type="bibr" target="#b33">Strubell et al. [2017]</ref>, <ref type="bibr" target="#b34">Zhai et al. [2017]</ref>, recursive neural networks <ref type="bibr" target="#b35">Li et al. [2017]</ref>, <ref type="bibr" target="#b36">Gridach [2017]</ref>, <ref type="bibr" target="#b37">Wang et al. [2018]</ref>, <ref type="bibr" target="#b38">Akbik et al. [2018]</ref>, <ref type="bibr">Liu et al. [2019a]</ref>, <ref type="bibr" target="#b40">Ghaddar and Langlais [2018]</ref> and long-short term memory based approaches <ref type="bibr" target="#b10">Huang et al. [2015]</ref>, <ref type="bibr" target="#b41">Tran et al. [2017]</ref>, <ref type="bibr" target="#b42">Jie and Lu [2019]</ref>. The authors of <ref type="bibr" target="#b43">Zheng et al. [2017]</ref>, <ref type="bibr" target="#b44">Zhou et al. [2017]</ref> introduced to jointly extract the entities and their relations in a unified framework.</p><p>Recently, pre-trained language models (PLMs) have mostly achieved the state-of-the-art performance of various NLP tasks <ref type="bibr" target="#b45">Devlin et al. [2018]</ref>, <ref type="bibr">Liu et al. [2019b]</ref>, <ref type="bibr" target="#b46">Yang et al. [2019]</ref>. Following this approach, NER has experienced a shift towards PLMs. An end-to-end model based on sequence-to-sequence learning with copy mechanism and the graph convolutional networks, which introduced to jointly extract relation and entity from sentences <ref type="bibr" target="#b47">Zeng et al. [2018]</ref>, <ref type="bibr" target="#b48">Fu et al. [2019]</ref>. A reinforcement learning-based approach <ref type="bibr" target="#b49">Zeng et al. [2019]</ref> was proposed to tackle the extraction order of relation extraction task. A cascade binary tagging-based framework <ref type="bibr" target="#b50">Wei et al. [2020]</ref> was introduced to treat relations as functions mapping subjects to objects in a sentence to alleviate the overlapping problem in relation extraction. <ref type="bibr">Table-Sequence Wang and Lu [2020]</ref> consists of two encoders, including a table encoder and a sequence encoder, that work together to learn the entity-specific representation. A partition filter network-based approach Yan et al. introduced to model two-way interaction between entity and relation extraction tasks. The authors of <ref type="bibr" target="#b19">Yuan et al. [2021]</ref> introduced modeling relevant features by leveraging heterogeneous factors, e.g., inside tokens, boundaries, and related spans to enhance learn span representation, resulting in accurate classification performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head><p>In this section, we describe the proposed solution. We begin by defining span-based NER task. Then, we present the technical details of our approach. Finally, we present the approximation method to reduce the number of parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem definition</head><p>Named Entity Recognition (NER) task aims to extract the entity segments and then correspondingly identify their types in the given text. Let S = [s 1 , s 2 , ...s m ] be the possible spans in the sentence. The span s is represented as s[i : j] where i and j are the head and tail indexes, respectively. The goal of NER is to identify all s ? E, where E is the entity type set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Global Pointer</head><p>The architecture of our proposed GP consists of two layers, including token representation span prediction. An illustrative example of GP is shown in Figure <ref type="figure" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Token Representation</head><p>Given a sentence X = [x 1 , x 2 , ...x n ] with n token, we begin by associating each token in X with its corresponding representation in the pre-training language model (PLM), e.g., BERT. We end up with a new matrix H ? R n?v , where v is dimension of representation:</p><formula xml:id="formula_0">h 1 , h 2 , ...h n = P LM (x 1 , x 2 , ...x n ).</formula><p>(1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Span Prediction</head><p>Now that we have already obtained the sentence representation H, we then compute the span representation. To this end, we use two feedforward layers that rely on the begin and end indices of the span.</p><formula xml:id="formula_1">q i,? = W q,? h i + b q,? ,<label>(2)</label></formula><formula xml:id="formula_2">k i,? = W k,? h i + b k,? ,<label>(3)</label></formula><p>where q i,? ? R d , k i,? ? R d is the vector representation of the token which used to identify the entity of type ?. Specifically, the representation of the start and end position is q i,? and k i,? for span s[i : j] of type ?. Then, the score of the span s[i : j] to be an entity of type ? is calculated as follows:</p><formula xml:id="formula_3">s ? (i, j) = q i,? k j,?<label>(4)</label></formula><p>To leverage the boundary information, we explicitly inject relative position information to the model. We apply ROPE position coding into the entity representation, which satisfies R i R j = R j-i . In this way, our scoring function is calculated as follows:</p><p>(5)</p><formula xml:id="formula_4">s ? (i, j) = (R i q i,? ) (R j k j,? ) = q i,? R i R j k j,? = q i,? R j-i k j,?</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Parameter Reduction</head><p>It is noteworthy to mention that when W q,? , W k,? ? R v?d , the parameters increase to 2vd for each new added entity type. Compared with the method of sequence labeling, the increase of parameters under the same conditions is about 2v. Generally speaking, v &gt;&gt; d, in the bert-base model v is 768, while the common choice of d is 64.</p><p>To alleviate this issue, we introduce an approximation technique to enable Global Pointer to perform under fewer parameters settings. In the next sections, we refer to it as Efficient Global Pointer. The key idea is to capture the shared score calculation under each entity type. Specifically, we treat NER task as two subtasks, including extraction and classification. The former extracts segments as entities, and the latter identifies the type of each entity. In this way, the extraction step is equivalent to the NER task with only one entity type. We can complete it with a scoring matrix (W q h i ) (W k h j ). The classification step can be read as w ? [h i ; h j ], where w ? ? R 2v denotes the identification of the entity type ?, and [h i ; h j ] is the span representation, which is the concatenation of the start and end representations .</p><p>The new scoring function is the combination of :</p><formula xml:id="formula_5">s ? (i, j) = (W q h i ) (W k h j ) + w ? [h i ; h j ].<label>(6)</label></formula><p>Note that the extraction task's parameters are shared by all entity types. Therefore, when a new entity type is added, the parameters of classification task increase by 2v, which is less compared to the original number of parameters 2vd.</p><p>To further reduce the parameters, we consider using [q i ; k i ] instead of h i to represent a token. Then, the final scoring function becomes:</p><formula xml:id="formula_6">s ? (i, j) = q i k j + w ? [q i ; k i ; q j ; k j ],<label>(7)</label></formula><p>where w ? ? R 4d , [q i ; k i ; q j ; k j ] is the span representation. Intuitively, the number of parameters increases for each new entity type is 4d, which is indeed less than And 4v.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Class Imbalance Loss</head><p>Inspired by the circle loss, we introduce a loss function to alleviate class imbalance. In single-class classification, the cross-entropy loss function is:</p><formula xml:id="formula_7">(8) log e st n i =1 e si = -log 1 n i=1 e si-st = log n i=1 e si-st = log ? ? 1 + n i=1,i =t e si-st ? ? ,</formula><p>where s i is the non target score and s t is the target score. Here, we consider the loss function in the scenario of multi-label classification. The goal is to make the score of the target class not less than that of the non-target class. Therefore, the loss function is:</p><formula xml:id="formula_8">log ? ? 1 + i??neg e si j??pos e -sj ? ?<label>(9)</label></formula><p>where ? pos and ? neg are positive sample set and negative sample set, respectively. Considering the multi-label scenario where the number of classes is not fixed, we introduce an additional class T H as the threshold value. We expect that the scores of target classes are greater than s T H and those of non-target classes are less than s T H . Then, the loss function is calculated as: For sake of simplicity, we set the threshold to 0 and the final loss function:</p><formula xml:id="formula_9">log ? ? 1 + i??neg e si ? ? + log ? ? 1 + j??pos e -sj ? ?<label>(12)</label></formula><p>Specifically, the entity type of ? is represented by:</p><formula xml:id="formula_10">log ? ? 1 + (q,k)?P? e -s?(q,k) ? ? + log ? ? 1 + (q,k)?Q? e s?(q,k) ? ? (<label>13</label></formula><formula xml:id="formula_11">)</formula><p>where q, k represent the start and tail indexes of a span, P ? represents a collection of spans with entity type ?, Q ? represents a collection of spans that are not entities or whose entity type is not ?, s ? (q, k) is the score that a span s[q : k] is an entity of type ?.</p><p>In inference step, the segments that satisfy s ? (q, k) &gt; 0 are the output of the entity of type ?.</p><p>4 Experiments and Evaluation  <ref type="table">2</ref>: Comparative evaluation on various benchmark dataset for flat and nested NER. The results represent the Macro-F1 scores averaged of five runs with different randomization. The Note that all the results are our implementations and best scores are highlighted in bold. <ref type="bibr" target="#b54">Hongying et al. [2020]</ref>, which has been widely used in the literature. Moreover, we also experiment with various English datasets, including <ref type="bibr">CONLL04 Roth and Yih [2004]</ref>, Genia <ref type="bibr" target="#b56">Ohta et al. [2002]</ref>, <ref type="bibr">NYT Riedel et al. [2010]</ref>, WebNLG <ref type="bibr" target="#b47">Zeng et al. [2018]</ref> and <ref type="bibr">ADE Gurulingappa et al. [2012]</ref>. Note that CMeEE and Genia were designed for nested NER task, while the others are flat task. Table <ref type="table">4</ref> shows the statistics of the datasets.</p><p>Evaluation Metrics. We use strict evaluation metrics that if the entity type and the corresponding entity boundary are correct, the entity is correct. We use F1-score to evaluate the performance of our model.</p><p>Parameter Settings. We use 12 heads and layers and keep the dropout probability at 0.1 with 30 epochs. The initial learning rate is 2e -5 for all layers with a batch size of 32 Note that we used the bert-base model <ref type="bibr" target="#b45">Devlin et al. [2018]</ref> to initialize the weights of our GP with Adam optimizer.</p><p>Comparative Baselines. We validate the performance of our Global Pointer by comparing it with its alternatives:</p><p>? Bert-CRF. A baseline for entity extraction task that incorporates pre-trained language model <ref type="bibr" target="#b45">BERT Devlin et al. [2018]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Main results</head><p>We use the Dev set to select the best model and report the average of five runs on each dataset as shown in Table <ref type="table">2</ref> from which we have made the following observations: (1) our proposed solution gives the best Macro-F1 scores compared to the baselines across all datasets; (2) our Global Pointer can significantly outperform BERT-CRF with more challenging datasets. For example, Global Pointer can achieve even about 0.74 and 1.59 with CLUENER CMeEE datasets, respectively, over BERT-CRF. Due to the widely recognized challenge of these datasets, the achieved improvements can be deemed very considerable. Moreover, the experimental results in  <ref type="bibr" target="#b47">Zeng et al. [2018]</ref> 82.1 GraphRel <ref type="bibr" target="#b48">Fu et al. [2019]</ref> 91.9 CasRel Wei et al. [2020]  ? 95.5 PFN Yan et al.  ?  98.0 Global Pointer ? 98.0 ADE Multi-head <ref type="bibr" target="#b60">Bekoulis et al. [2018a]</ref> 86.4 Multi-head + AT <ref type="bibr" target="#b61">Bekoulis et al. [2018b]</ref> 86.7 Rel-Metric <ref type="bibr" target="#b62">(Tran and Kavuluru, 2019)</ref> 87  <ref type="table">4</ref>: Comparative evaluation in terms of computational cost between the proposed Global Pointer and BERT-CRF Furthermore, we compared Global Pointer to its alternative Bert-CRF in terms of computational costs of both training and inference steps. The comparative results are reported in Table <ref type="table">4</ref>. As can be seen, our Global Pointer is faster than CRF, especially, with large datasets, such as the People's daily and CMeEE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Relative Position &amp; Class Imbalance loss Evaluation</head><p>To illustrate the affect of encoding the relative position information, we conduct an ablation study on the CONLL04 dataset as follows. We drop Non-ROPE encoding component of our Global Pointer and compare the performance as shown in Table <ref type="table" target="#tab_5">7</ref>. As can be seen, the Macro-F1 scores drop even about 11.43%, and thus suggests that a well-designed mechanism that leverages the relative position information can boost the performance on NER task. Moreover, we validate the efficacy of the proposed class imbalance loss function as follows. We replace the proposed loss function with the binary cross-entropy (BCE). We observe that the performance of Global Pointer with BCE drops in terms of precision and F1 scores and thus demonstrates the effectiveness of our proposed loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Global </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Reduce Parameters Evaluation</head><p>In Section 3.3, we introduce a new variant of the proposed solution, namely Efficient Global Pointer, which can perform under less parameters settings. We conduct empirical experiments on the people's daily, CLUENER and CMeEE datasets to evaluate the performance of both variants. The comparative results are shown in Table <ref type="table" target="#tab_3">5</ref> from which we have made the following observations. (1) Overall, Efficient Global Pointer can mostly give the best F1 scores. (2) Despite the limited number of parameters, Efficient Global Pointer can still be competitive on the easy dataset, e.g., People's daily dataset. (3) CLUENER and CMeEE were annotated with 10 and 9 entity types, respectively, which are widely recognized as more challenging datasets; however, Efficient Global Pointer with less parameters can still perform better than its alternative with all parameters. The performance is expected as the number of parameters increases with each entity type leading to an overfiting problem. In brief, the experimental results suggest that a carefully-designed mechanism to reduce the number of parameters can enhance the performance of NER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Empirical Analysis</head><p>In the section, we perform in-depth analysis in terms of entity length and entity density. Specifically, we conducted relevant experiments on CONLL04 dataset to evaluate the performance of Global Pointer and PFN Yan et al.. First, we map the sentences into three groups according to their length: L &lt; 3, 3 =&lt; L &lt; 6, and L &gt;= 6, denoted as L 1 , L 2 and L 3 , respectively. Second, we categorized the sentences according to their density: dense&lt;=0.1, 0.1 &lt; dense &lt; = 0.3, dense &gt; 0.3, denoted as D 1 , D 2 and D 3 . Note that we use the ratio of the number of entity words to the total number of text words as the index of entity density.</p><p>The comparative evaluation is depicted in Table <ref type="table" target="#tab_4">6</ref>. We observe that when the entity length exceeds the half (e.g., 6), Global Pointer can achieve even about 7% improvements higher than PFN in terms of F1 score. These improvements demonstrate the importance of relative position information in the large number of entities recognition. In addition, we also observe that when the density of entities in the text is at the middle level, both models give the worse scores. However, as can be seen, Global Pointer performs better in most scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper, we presented a novel solution to address span-based NER framework, namely Global Pointer (GP), by leveraging the relative positions through a multiplicative attention mechanism. GP is designed of two modules that aim to identify the head and the tail of a given entity to enable the inconsistency between the training and inference processes. Moreover, GP contributed with a novel loss function to address the imbalance label problem. To reduce the training cost, we introduced a new variant of GP based on approximate method to reduce the training parameters. We extensively evaluated GP on various benchmark datasets. Our extensive experiments demonstrate that GP can outperform the existing solution. Moreover, the experimental results show the efficacy of the introduced loss function compared to softmax and entropy alternatives.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of our proposed Global Pointer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>and the additional Conditional Random Field (CRF) layer<ref type="bibr" target="#b59">Lafferty et al. [2001]</ref>.? CopyRE<ref type="bibr" target="#b47">Zeng et al. [2018]</ref>. An end-to-end model based on sequence-to-sequence learning with copy mechanism, which introduced to jointly extract relation and entity from sentences. ? GraphRel<ref type="bibr" target="#b48">Fu et al. [2019]</ref>. An end-to-end relation extraction model built upon the graph convolutional networks to jointly learn named entities and their corresponding relations. ? CasRel Wei et al. [2020]. A cascade binary tagging-based framework introduced to treat relations as functions mapping subjects to objects in a sentence to alleviate the overlapping problem in relation extraction. ? PFN Yan et al.. A partition filter network-based approach introduced to model two-way interaction between entity and relation extraction tasks. Moreover, we also compare to the baselines that achieve competitive performance, including Multi-head Bekoulis et al. [2018a], Multi-head + AT Bekoulis et al. [2018b], Rel-Metric Tran and Kavuluru [2019], SpERT Eberts and Ulges [2019].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Statistics of datasets.</figDesc><table><row><cell>Dataset</cell><cell>Train</cell><cell cols="4">Test Sentence length Number of Entities</cell></row><row><cell cols="3">The People's daily 23,182 46,36</cell><cell>46.93</cell><cell>3</cell><cell></cell></row><row><cell>CLUENER</cell><cell cols="2">10,748 1,343</cell><cell>37.38</cell><cell>10</cell><cell></cell></row><row><cell>CMeEE</cell><cell cols="2">15,000 5,000</cell><cell>54.15</cell><cell>9</cell><cell></cell></row><row><cell>CONLL04</cell><cell cols="2">4,270 1,079</cell><cell>28.77</cell><cell>4</cell><cell></cell></row><row><cell>Genia</cell><cell cols="2">16,692 1,854</cell><cell>25.35</cell><cell>5</cell><cell></cell></row><row><cell>NYT</cell><cell cols="2">56,195 5,000</cell><cell>128</cell><cell>-</cell><cell></cell></row><row><cell>WebNLG</cell><cell>5,019</cell><cell>703</cell><cell>128</cell><cell>-</cell><cell></cell></row><row><cell>ADE</cell><cell cols="2">4,272 (10-fold)</cell><cell>128</cell><cell>2</cell><cell></cell></row><row><cell>Method</cell><cell cols="5">The People's daily CLUENER CMeEE CONLL04 Genia</cell></row><row><cell>Bert-CRF</cell><cell>95.46</cell><cell>78.70</cell><cell>64.39</cell><cell>85.46</cell><cell>73.02</cell></row><row><cell>PFN Yan et al.</cell><cell>94.00</cell><cell>79.29</cell><cell>63.68</cell><cell>87.43</cell><cell>74.31</cell></row><row><cell>Global Pointer</cell><cell>95.51</cell><cell>79.44</cell><cell>65.98</cell><cell>88.57</cell><cell>74.64</cell></row><row><cell>Table</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p><p><p>4.1 Experimental Setup</p>Dataset. To validate the proposed solution, we conduct extensive experiments on various benchmark datasets. Specifically, we rely on three Chinese NER datasets, including The People's daily,</p>CLUENER Xu et al. [2020]  </p>and CMeEE</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Table 3 have shown that our proposed solution can achieve a competitive performance compared to the state-of-the-art baselines with less training and inference costs.</figDesc><table><row><cell>Method</cell><cell>F1 score</cell></row><row><cell>NYT</cell><cell></cell></row><row><cell>CopyRE Zeng et al. [2018]</cell><cell>86.2</cell></row><row><cell>GraphRel Fu et al. [2019]</cell><cell>89.2</cell></row><row><cell>CasRel Wei et al. [2020]  ?</cell><cell>93.5</cell></row><row><cell>PFN Yan et al.  ?</cell><cell>95.8</cell></row><row><cell>Global Pointer  ?</cell><cell>95.6</cell></row><row><cell>WebNLG</cell><cell></cell></row><row><cell>CopyRE</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Comparative evaluation, ? , ? and ? denotes the use of BERT, ALBERT and SCIBERT<ref type="bibr" target="#b45">Devlin et al. [2018]</ref>,<ref type="bibr" target="#b64">Lan et al. [2019]</ref>,<ref type="bibr" target="#b65">Beltagy et al. [2019]</ref> pre-trained embedding. and denotes the use of micro-F1 and macro-F1 score.</figDesc><table><row><cell>.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5 :</head><label>5</label><figDesc>Comparison of the Efficient Global Pointer with the original Global Pointer in F1 score. Best scores are highlighted in bold.</figDesc><table><row><cell></cell><cell cols="2">Pointer Efficient Global Pointer</cell></row><row><cell>The People's daily</cell><cell>95.51</cell><cell>95.36</cell></row><row><cell>CLUENER</cell><cell>79.44</cell><cell>80.04</cell></row><row><cell>CMeEE</cell><cell>65.98</cell><cell>66.54</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6 :</head><label>6</label><figDesc>Comparative evaluation of Global Pointer and PFN in terms of entity length and entity density. Best scores are highlighted in bold.</figDesc><table><row><cell>Ablations</cell><cell cols="2">Precision Recall</cell><cell>F1</cell></row><row><cell>Non ROPE</cell><cell>77.14</cell><cell cols="2">77.14 77.14</cell></row><row><cell>BCE loss</cell><cell>88.72</cell><cell cols="2">88.22 88.48</cell></row><row><cell>Global Pointer</cell><cell>89.19</cell><cell cols="2">87.95 88.57</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 7 :</head><label>7</label><figDesc>The comparative evaluation of relative position information and class imbalance loss on CONLL04 dataset.</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Named entity recognition in query</title>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 32nd international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="267" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Proximity-based document representation for named entity retrieval</title>
		<author>
			<persName><forename type="first">Desislava</forename><surname>Petkova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixteenth ACM conference on Conference on information and knowledge management</title>
		<meeting>the sixteenth ACM conference on Conference on information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="731" to="740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A trainable summarizer with knowledge acquired from robust nlp techniques. Advances in automatic text summarization</title>
		<author>
			<persName><forename type="first">Chinatsu</forename><surname>Aone</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="71" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Named entity recognition for question answering</title>
		<author>
			<persName><forename type="first">Diego</forename><surname>Moll?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Menno</forename><surname>Van Zaanen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Australasian language technology workshop 2006</title>
		<meeting>the Australasian language technology workshop 2006</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="51" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Improving machine translation quality with automatic named entity recognition</title>
		<author>
			<persName><forename type="first">Bogdan</forename><surname>Babych</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Hartley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International EAMT workshop on MT and other language technology tools, Improving MT through other language technology tools, Resource and tools for building MT at EACL 2003</title>
		<meeting>the 7th International EAMT workshop on MT and other language technology tools, Improving MT through other language technology tools, Resource and tools for building MT at EACL 2003</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unsupervised named-entity extraction from the web: An experimental study</title>
		<author>
			<persName><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ana-Maria</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Daniel S Weld</surname></persName>
		</author>
		<author>
			<persName><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="134" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neural architectures for named entity recognition</title>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1030</idno>
		<ptr target="https://aclanthology.org/N16-1030" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06">June 2016</date>
			<biblScope unit="page" from="260" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Recognising nested named entities in biomedical text</title>
		<author>
			<persName><forename type="first">Beatrice</forename><surname>Alex</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Grover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Biological, translational, and clinical language processing</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Unsupervised multi-granular chinese word segmentation and term discovery via graph partition</title>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanhao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiuyang</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boyao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaobin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page">103542</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Nested named entity recognition</title>
		<author>
			<persName><forename type="first">Jenny</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 conference on empirical methods in natural language processing</title>
		<meeting>the 2009 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="141" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Bidirectional lstm-crf models for sequence tagging</title>
		<author>
			<persName><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.01991</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Pyramid: A layered model for nested named entity recognition</title>
		<author>
			<persName><forename type="first">Jue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lidan</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.525</idno>
		<ptr target="https://aclanthology.org/2020.acl-main.525" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07">jul 2020</date>
			<biblScope unit="page" from="5918" to="5928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural architectures for named entity recognition</title>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1030</idno>
		<ptr target="https://aclanthology.org/N16-1030" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06">June 2016</date>
			<biblScope unit="page" from="260" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A boundary-aware neural model for nested named entity recognition</title>
		<author>
			<persName><forename type="first">Changmeng</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingyun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guandong</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Entity, relation, and event extraction with contextualized span representations</title>
		<author>
			<persName><forename type="first">David</forename><surname>Wadden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulme</forename><surname>Wennberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1585</idno>
		<ptr target="https://aclanthology.org/D19-1585" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11">November 2019</date>
			<biblScope unit="page" from="5784" to="5789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Boundary enhanced neural span classification for nested named entity recognition</title>
		<author>
			<persName><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mosha</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="9016" to="9023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Named entity recognition as dependency parsing</title>
		<author>
			<persName><forename type="first">Juntao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.577</idno>
		<ptr target="https://aclanthology.org/2020.acl-main.577" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="page" from="6470" to="6476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A general framework for information extraction using dynamic span graphs</title>
		<author>
			<persName><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dave</forename><surname>Wadden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amy</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1308</idno>
		<ptr target="https://aclanthology.org/N19-1308" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06">June 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3036" to="3046" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A frustratingly easy approach for entity and relation extraction</title>
		<author>
			<persName><forename type="first">Zexuan</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.12812</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Fusing heterogeneous factors with triaffine mechanism for nested named entity recognition</title>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Songfang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.07480</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">SpanNER: Named entity re-/recognition as span prediction</title>
		<author>
			<persName><forename type="first">Jinlan</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="7183" to="7195" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Locate and label: A two-stage identifier for nested named entity recognition</title>
		<author>
			<persName><forename type="first">Yongliang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiming</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2782" to="2794" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Roformer: Enhanced transformer with rotary position embedding</title>
		<author>
			<persName><forename type="first">Jianlin</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengfeng</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunfeng</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.09864</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A rule-based named entity recognition system for speech input</title>
		<author>
			<persName><forename type="first">Ji-Hwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">C</forename><surname>Woodland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth International Conference on Spoken Language Processing</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Definition, dictionaries and tagger for extended named entity hierarchy</title>
		<author>
			<persName><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chikashi</forename><surname>Nobata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<meeting><address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="1977" to="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Prominer: rule-based protein and gene entity recognition</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Hanisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katrin</forename><surname>Fundel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heinz-Theodor</forename><surname>Mevissen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ralf</forename><surname>Zimmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juliane</forename><surname>Fluck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC bioinformatics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Juli?n Camilo Daza Rodr?guez, Oscar Mauricio Mu?oz Velandia, Angel Alberto Garcia Pe?a, and Cyril Labb?. Named entity recognition over electronic health records through a combined dictionary-based approach</title>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Pomares Quimbaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alejandro</forename><surname>Sierra M?nera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><surname>Andr?s</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gonz?lez</forename><surname>Rivera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Computer Science</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="55" to="61" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Unsupervised biomedical named entity recognition: Experiments with clinical and biological texts</title>
		<author>
			<persName><forename type="first">Shaodian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">No?mie</forename><surname>Elhadad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of biomedical informatics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1088" to="1098" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A multilingual named entity recognition system using boosting and c4. 5 decision tree learning algorithms</title>
		<author>
			<persName><forename type="first">Gy?rgy</forename><surname>Szarvas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rich?rd</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andr?s</forename><surname>Kocsor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Discovery Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="267" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Recognizing named entities in tweets</title>
		<author>
			<persName><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaodian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th annual meeting of the association for computational linguistics: human language technologies</title>
		<meeting>the 49th annual meeting of the association for computational linguistics: human language technologies</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="359" to="367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Chemspot: a hybrid system for chemical named entity recognition</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rockt?schel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Weidlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulf</forename><surname>Leser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1633" to="1640" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The fixed-size ordinally-forgetting encoding method for neural network language models</title>
		<author>
			<persName><forename type="first">Shiliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingbin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junfeng</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li-Rong</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="495" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Biomedical named entity recognition based on deep neutral network</title>
		<author>
			<persName><forename type="first">Lin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhammad</forename><forename type="middle">Waqas</forename><surname>Anwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Hybrid Inf. Technol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="279" to="288" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Fast and accurate entity recognition with iterated dilated convolutions</title>
		<author>
			<persName><forename type="first">Emma</forename><surname>Strubell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Verga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.02098</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Neural models for sequence chunking</title>
		<author>
			<persName><forename type="first">Feifei</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saloni</forename><surname>Potdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Leveraging linguistic structures for named entity recognition with bidirectional recursive neural networks</title>
		<author>
			<persName><surname>Peng-Hsuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruo-Ping</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu-Siang</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ju-Chieh</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Yun</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2664" to="2669" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Character-level neural network for biomedical named entity recognition</title>
		<author>
			<persName><forename type="first">Mourad</forename><surname>Gridach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of biomedical informatics</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="85" to="91" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Code-switched named entity recognition with embedding attention</title>
		<author>
			<persName><forename type="first">Changhan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching</title>
		<meeting>the Third Workshop on Computational Approaches to Linguistic Code-Switching</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="154" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Contextual string embeddings for sequence labeling</title>
		<author>
			<persName><forename type="first">Alan</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duncan</forename><surname>Blythe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th international conference on computational linguistics</title>
		<meeting>the 27th international conference on computational linguistics</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1638" to="1649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Towards improving neural named entity recognition with gazetteers</title>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin-Ge</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5301" to="5307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Robust lexical features for improved neural network named-entity recognition</title>
		<author>
			<persName><forename type="first">Abbas</forename><surname>Ghaddar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Langlais</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.03489</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">Quan</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Jimeno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yepes</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1706.07598</idno>
		<title level="m">Named entity recognition with stack residual lstm and trainable bias decoding</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Dependency-guided lstm-crf for named entity recognition</title>
		<author>
			<persName><forename type="first">Zhanming</forename><surname>Jie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.10148</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Joint extraction of entities and relations based on a novel tagging scheme</title>
		<author>
			<persName><forename type="first">Suncong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuexing</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05075</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Joint extraction of multiple relations and entities by using a hybrid neural network</title>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suncong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaming</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenyu</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Chinese Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="135" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><surname>Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><surname>Roberta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russ</forename><forename type="middle">R</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
	</analytic>
	<monogr>
		<title level="m">A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page">32</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Extracting relational facts by an end-to-end neural model with copy mechanism</title>
		<author>
			<persName><forename type="first">Xiangrong</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="506" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">GraphRel: Modeling text as relational graphs for joint entity and relation extraction</title>
		<author>
			<persName><forename type="first">Tsu-Jui</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng-Hsuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Yun</forename><surname>Ma</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1136</idno>
		<ptr target="https://aclanthology.org/P19-1136" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07">July 2019</date>
			<biblScope unit="page" from="1409" to="1418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning the extraction order of multiple relational facts in a sentence with reinforcement learning</title>
		<author>
			<persName><forename type="first">Xiangrong</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengping</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1035</idno>
		<ptr target="https://aclanthology.org/D19-1035" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11">November 2019</date>
			<biblScope unit="page" from="367" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A novel cascade binary tagging framework for relational triple extraction</title>
		<author>
			<persName><forename type="first">Zhepei</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianlin</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.136</idno>
		<ptr target="https://aclanthology.org/2020.acl-main.136" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="page" from="1476" to="1488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Two are better than one: Joint entity and relation extraction with table-sequence encoders</title>
		<author>
			<persName><forename type="first">Jue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.03851</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">A partition filter network for joint entity and relation extraction</title>
		<author>
			<persName><forename type="first">Zhiheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinlan</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongyu</forename><surname>Wei</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="185" to="197" />
			<pubPlace>Dominican Republic</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Cluener2020: fine-grained named entity recognition dataset and benchmark for chinese</title>
		<author>
			<persName><forename type="first">Liang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qianqian</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixuan</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weitang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiquan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanwei</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.04351</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Building a pediatric medical corpus: Word segmentation and named entity annotation</title>
		<author>
			<persName><forename type="first">Zan</forename><surname>Hongying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Wenxin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhang</forename><surname>Kunli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye</forename><surname>Yajuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Baobao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sui</forename><surname>Zhifang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Chinese Lexical Semantics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="652" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">A linear programming formulation for global inference in natural language tasks</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>Illinois Univ at Urbana-Champaign Dept of Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">The genia corpus: An annotated research abstract corpus in molecular biology domain</title>
		<author>
			<persName><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuka</forename><surname>Tateisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hideki</forename><surname>Mima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the human language technology conference</title>
		<meeting>the human language technology conference</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="73" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Modeling relations and their mentions without labeled text</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint European Conference on Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="148" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Development of a benchmark corpus to support the automatic extraction of drug-related adverse effects from medical case reports</title>
		<author>
			<persName><forename type="first">Harsha</forename><surname>Gurulingappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdul</forename><surname>Mateen Rajput</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angus</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juliane</forename><surname>Fluck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Hofmann-Apitius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Toldo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of biomedical informatics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="885" to="892" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<author>
			<persName><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernando Cn</forename><surname>Pereira</surname></persName>
		</author>
		<title level="m">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Adversarial training for multi-context joint entity and relation extraction</title>
		<author>
			<persName><forename type="first">Giannis</forename><surname>Bekoulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Deleu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Demeester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Develder</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1307</idno>
		<ptr target="https://aclanthology.org/D18-1307" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-11">October-November 2018a</date>
			<biblScope unit="page" from="2830" to="2836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Joint entity recognition and relation extraction as a multi-head selection problem</title>
		<author>
			<persName><forename type="first">Giannis</forename><surname>Bekoulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Deleu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Demeester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Develder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="34" to="45" />
			<date type="published" when="2018">2018b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Neural metric learning for fast end-to-end relation extraction</title>
		<author>
			<persName><forename type="first">Tung</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramakanth</forename><surname>Kavuluru</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.07458</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Span-based joint entity and relation extraction with transformer pre-training</title>
		<author>
			<persName><forename type="first">Markus</forename><surname>Eberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Ulges</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.07755</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Albert: A lite bert for self-supervised learning of language representations</title>
		<author>
			<persName><forename type="first">Zhenzhong</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingda</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piyush</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.11942</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">SciBERT: A pretrained language model for scientific text</title>
		<author>
			<persName><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1371</idno>
		<ptr target="https://aclanthology.org/D19-1371" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11">November 2019</date>
			<biblScope unit="page" from="3615" to="3620" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
