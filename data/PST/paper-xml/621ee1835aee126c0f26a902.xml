<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GraphWorld: Fake Graphs Bring Real Insights for GNNs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-02-28">28 Feb 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">John</forename><surname>Palowitch</surname></persName>
							<email>palowitch@google.com</email>
						</author>
						<author>
							<persName><forename type="first">Anton</forename><surname>Tsitsulin</surname></persName>
							<email>tsituslin@google.com</email>
						</author>
						<author>
							<persName><forename type="first">Brandon</forename><surname>Mayer</surname></persName>
							<email>bmayer@google.com</email>
						</author>
						<author>
							<persName><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
						</author>
						<title level="a" type="main">GraphWorld: Fake Graphs Bring Real Insights for GNNs</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-02-28">28 Feb 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2203.00112v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Products ed ge ho mo ge ne ity a v g . d e g r e e Mean reciprocal rank GCN 0 0.5 1 0 10 20 0 0.5 1 Cora Citeseer OGB-ArXiv PubMed OGB-Products ed ge ho mo ge ne ity a v g . d e g r e e APPNP 0 0.5 1 0 10 20 0 0.5 1 Cora Citeseer OGB-ArXiv PubMed OGB-Products ed ge ho mo ge ne ity a v g . d e g r e e FiLM 0 0.2 0.4 0.6 0.8</p><p>Figure <ref type="figure">1</ref>: GraphWorld uses synthetic data to elucidate fundamental differences between graph neural network convolutions. Shown here are the relative performance results of GCN [23], APPNP [24], and FiLM [6] across 50,000 distinct node classification tasks. The ? and ? axes group the synthetic graphs by their structural properties, while the ?-axis shows the mean reciprocal-rank (MRR) relative to other baselines (Section 4.1). We find that standard GNN benchmark datasets (Cora, OGB, etc.) exist in regions of the GraphWorld where model rankings do not change. GraphWorld can discover previously unexplored graphs which reveal new insights about GNN architectures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Graph Neural Networks (GNNs) have extended the benefits of deep learning to the non-Euclidean domain, allowing for standardized and re-usable machine learning approaches to problems that involve relational (graph-structured) data <ref type="bibr" target="#b47">[48]</ref>. GNNs now admit an extremely wide range of architectures and possible tasks, including node classification, whole-graph classification, and link prediction <ref type="bibr" target="#b7">[8]</ref>. With this growth has come increased calls for proper GNN experimental design <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b49">50]</ref>, refreshed benchmark datasets <ref type="bibr" target="#b17">[18]</ref>, and fair comparisons of GNN models in reproducible settings <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b29">30]</ref>.</p><p>Despite the proliferation of new GNN models, only a few handpicked benchmarked datasets are currently used to evaluate them <ref type="bibr" target="#b17">[18]</ref>. The limited scope of these datasets introduces a number of problems. First, it makes it hard for practitioners to infer which models will generalize well to unseen datasets. Second, new architectures are proposed only when they beat existing methods on these datasets, which can cause architectural overfitting <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b33">34]</ref>. Finally, recent efforts at expanding the diversity of available GNN benchmark data have focused on size -increasing the cost of evaluating models without significantly increasing the variation of graphs considered.</p><p>In this work, we introduce GraphWorld, the first tunable, scalable, and reproducible method for analyzing the performance of GNN models on synthetic benchmark data for any given GNN task (i.e. all {un/semi}supervised node/graph problems <ref type="bibr" target="#b47">[48]</ref>). With its ability to generate a vast and diverse "world" of graph datasets for any specified task, GraphWorld allows comparisons between GNN models and architectures that are not possible with the handful of standard graph datasets on which the current literature depends. As seen in Figure <ref type="figure">1</ref>, GNN models change sharply in performance ranking when tested on GraphWorld synthetic datasets that are distant in graph property space from standard real-world datasets.</p><p>GraphWorld is directly motivated by challenges observed in developing and applying GNNs to a wide variety of datasets at Google. Synthetic datasets have an additional advantage for industrial use -as there are no underlying privacy concerns, the data is easy to share. This can help facilitate new model development. We currently use GraphWorld for model understanding, and will soon be incorporating it into the newly-released TF-GNN package <ref type="bibr" target="#b0">[1]</ref>, as well as in internal systems for testing GNN modules. This paper's contributions are:</p><p>(1) Problem Formulation. We pose the question: how can we measure GNN model performance across graph datasets with high statistical variance? Modern benchmark datasets, however well-maintained, can be limited in scope, and can be computationally inaccessible to the average researcher. (2) Methodology. We provide GraphWorld, a graph sampling and GNN training procedure which is capable of testing state-ofthe-art GNNs on task datasets beyond the scope of any existing benchmarks.</p><p>(3) Insights. We use GraphWorld to conduct large-scale experimental study on over 1 million graph datasets for each of three GNN tasks -node classification, link prediction, and graph property prediction. We provide a novel method to explore the GNN model performance across all locations in the graph worlds that we generate.</p><p>Importantly, the GraphWorld methodology enables experimental analysis of GNNs across any task that can be expressed in the theoretical framework we introduce in Section 3, including tasks not mentioned above such as node regression. Therefore, particular random graph models (RGMs) for synthetic dataset generation are not the focus of our investigation.</p><p>The rest of this paper is as follows. First we discuss recent work and current challenges in benchmarking GNNs. We then formally propose GraphWorld as a novel benchmarking system that features many advantages unavailable to GNN experiments that depend only on natural datasets from the literature. Next, in Section 4, we demonstrate GraphWorld on node classification, link prediction, and graph property prediction tasks, and show brand-new aggregate performance metrics on GNN models, some of which raise surprising conclusions about prior work and common-sense intuitions. We close with a discussion about the GraphWorld platform, including its scalability and accessibility compared with large-scale experiments on real-world graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">GNN EXPERIMENTS: PAST AND FUTURE</head><p>Progress on GNN architectures is recorded, in large part, by comparing the empirical performance of proposed and existing architectures on particular tasks. In these empirical studies, each task is associated with a number of graph datasets on which GNN models attempt to perform well for the given task. For example, the CORA dataset is a graph of research papers connected by citation edges, curated from online records, on which GNNs must classify the papers (nodes) into research fields (categorical labels). In this case, if a novel GNN model statistically outperforms previously proposed models on the node classification task, this would usually be seen as an indicator that the model makes progress in the field.</p><p>In general, such experiments are used to arrive at some insights about how new architectures will perform in realistic scenarios. Most studies feature 1-3 tasks and 1-5 datasets per-task. Note that some datasets contain many graphs, such as a dataset containing molecules represented as atom graphs <ref type="bibr" target="#b30">[31]</ref>. Multiple-graph datasets have primarily been used to train GNNs on the task of classifying whole graphs, or estimating some property of them. Such datasets can be considered equivalent to a dataset with only one (usually much larger) graph, given that GNN performance on each dataset is measured by a single task and a single set of metrics. Even when the dataset collection itself is large, such as TUDataset <ref type="bibr" target="#b30">[31]</ref>, which currently contains more than 130 graph collections, researchers can not report the results on all these datasets due to the lack of space, limiting the reporting to 3-6 most common ones.</p><p>These concerns are not specific to the field of GNNs -the broader machine learning community has identified problems in benchmarking protocols and reporting in other subfields <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b33">34]</ref>. New benchmarks are being actively created in nearly all areas of machine learning <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b45">46]</ref>. In the field of GNNs, recent comparative benchmarking studies <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b50">51]</ref> limit themselves to just a few datasets, mainly targeting making fair experimental settings and performing fair hyperparameter tuning.</p><p>Possibly due to the existence of well-studied random graph models such as the Stochastic Block Model <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b19">20]</ref>, there has been a very recent trend of featuring small synthetic datasets in GNN research, to tease apart model differences that would be harder to observe on standard datasets <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b52">53]</ref>. However, to date, there is no generalized methodology for producing synthetic, tunable populations of GNN task datasets at-scale, nor a concept of how to analyze GNN performance on such populations. This is the main problem we aim to solve with GraphWorld.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Pitfalls of Standard GNN Benchmarks</head><p>In this paper, we question whether or not the status quo of GNN evaluation as described above, is enough to measure progress in the field. While there has been much recent work on improving and standardizing GNN benchmark datasets, relying only on a handful of graph datasets over time is detrimental to the field, for the following three reasons: Inadequate generalization. Each curated graph dataset represents just one point in the space of all possible datasets that can be associated with the particular GNN task at-hand. The graph (or graphs) in a particular dataset may have properties that favor some GNN models over others, whereas yet-unseen graphs will have different characteristics that could reverse any insights made from the singular trial. Figure <ref type="figure" target="#fig_0">2</ref> illustrates this point by plotting the joint distribution of the average node clustering coefficient and the degree distribution gini coefficient, for each graph dataset from two populations. The grey points, and the 2D kernel density estimate contours, represent datasets from the massive Network Repository, an open, online graph dataset collection <ref type="bibr" target="#b34">[35]</ref>. The blue points represent node classification and link prediction datasets from the recent Open Graph Benchmark (OGB) <ref type="bibr" target="#b17">[18]</ref>, a library and dataset collection specifically created for reproducible GNN experimentation.</p><p>Here it is important to note that, unlike graph datasets in the OGB, most Network Repository (NR) graph datasets do not have graph or node labels. This is not necessarily by design. The NR is an open, community-sourced collection of graph datasets, and most contributors either do not provide labels, or they determine that labels are not readily available from the graph data source. This means that most NR datasets are not readily available for GNN experimentation. However, it is worth asking the question: if all NR datasets did have labels, would GNN model performance generalize to them? There is not currently a way to answer this.</p><p>Incremental overfitting. As it is in many machine learning subfields, GNN task datasets are successively re-used across papers, to accurately measure incremental improvements of new architectures. However, this can easily cause, over time, overfitting of new architectures to the datasets, as observed for NLP tasks <ref type="bibr" target="#b31">[32]</ref> and computer vision tasks <ref type="bibr" target="#b33">[34]</ref>. This effect will be especially pronounced if the main collection of benchmark graphs have similar structural and statistical properties.</p><p>Un-scalable development. In recent years, there has been a particular focus on scalability in GNN research. The Open Graph Benchmark <ref type="bibr" target="#b17">[18]</ref> increased the size of experiment-friendly benchmark citation graphs by over 1,000x the number of nodes. From one perspective, this can only be natural as computing capabilities grow and graph-based learning problems become increasingly data-flush. On the other hand, while the availability of giant graphs is important for testing GNN software, platforms, and model complexity, it is not obvious that giant graphs are needed to test GNN accuracy or scientific usefulness. As the field's benchmark graphs become ever-larger, standardized graph datasets for testing GNN expressiveness become less accessible to the average researcher. Additionally, with large benchmark datasets, it is nearly impossible to investigate GNN hyperparameter tuning techniques or training variance without access to institution-scale computing resources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">GRAPHWORLD</head><p>The three problems described in the previous section -inadequate generalization, incremental overfitting, and un-scalable development -are inherent to the need of GNN researchers to benchmark on datasets sourced from the real world. Any handful of such datasets will be necessarily limited, and it is in the best interest of researchers to re-use well maintained datasets from prior work to show how novel methods improves over existing architectures in the field. Additionally, studies on very large graphs are necessary to demonstrate the scalability of proposed GNN architectures. Such large graphs are expensive to collect and process, and require specialized hardware or computing clusters to train the models, limiting access to research for under-represented groups.</p><p>Given that these problems can not be solved with the status quo approach to benchmark design, a complementary system is necessary to fill in the gaps that re-usable benchmark datasets cannot. For this, we propose GraphWorld: a distributed framework for simulating diverse populations of GNN benchmark datasets, tuning and testing an arbitrary number of GNN models on the population, and extracting population-level insights from the logs of the system. As we explain in this section, and demonstrate with our experiment results, GraphWorld provides generalizable GNN insights in a scalable manner that is accessible to researchers with low computational resources. In a discussion further in the paper (Section 6), we elaborate on how GraphWorld and its experimental results help resolve the three aforementioned problems. In the rest of this section we describe the core components of GraphWorld, leaving some specifics and implementation details to the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Graph Generation</head><p>The core component of GraphWorld is the simulation of GNN test datasets using attributed-graph and label generators. Each test dataset is a realization of a parameterized probability distribution P (? 1 , ? 2 , . . .) on D = G ? F ? L, where G is a collection of graphs, F is a collection of features, and L is a collection of labels. (This formulation supports graph classification datasets, which can be represented as a single graph of disjoint graph examples.) The space of possible test datasets D is fully determined by regions of generator parameters ? 1 ? ? 1 , ? 2 ? ? 2 , . . . provided by the user to the workers via the manager. Each worker in a GraphWorld pipeline generates a single realization ? ? D by sampling a generator parameter set (? 1 , ? 2 , . . .), and then sampling a single dataset from P (? 1 , ? 2 , . . .). Note: each dataset sampled is actually a combination ? = [? ????? , ? ???? ] of training data and testing data for the GNN models.</p><p>Example. We illustrate the simulation component of GraphWorld with a node classification task generation. In this paper, we generate worlds of node classification tasks from samples ? ? ? ? G ? L as a Degree-Corrected Stochastic Block Model (DC-SBM) graphs <ref type="bibr" target="#b1">[2]</ref>, where cluster assignments double as class labels, and node features ? ? F are drawn from within-cluster multivariate Normals. Each of these distributions have many dependent parameters, such as the ?-to-? ratio (where ? and ? are the probabilities of in-cluster, outcluster edges), the degree power-law ?, the variance of multivariate Normal centers, the cluster size distribution, and many more that we detail fully in the Appendix. Figure <ref type="figure" target="#fig_2">3</ref> contains visualizations of two separate attributed DC-SBM realizations from a graph world. In a full run of GraphWorld, each of these parameters (and more) will be randomly sampled from a wide range, producing a diverse classification of node classification datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training, Testing, and Evaluation</head><p>The GraphWorld method simulates a pre-specified number of GNN test datasets ? 1 , ? 2 , . . . ? D, in the manner described above, and trains and tests an arbitrary list of GNN models on each dataset. Note that the particular task is fully-generalizable beyond node classification; we demonstrate link prediction and graph property prediction in Section 4. Similarly to the test data distributions, the hyperparameters of GNN model ? (for a particular dataset) is determined by a sample or specification (? ?1 , ? ?2 , . . .) ? H ? = ? ?1 ? ? ?2 ? . . .. The complete set of inputs to the GraphWorld method are:</p><p>? Models: list of models ? 1 , ? 2 , . . . and associated hyperparameter spaces H 1 , H 2 , . . .. ? Task formulation: space of possible datasets D, and a probability distribution P (? 1 , ? 2 , . . .) defined on D. ? Task metric: test accuracy function EvalMetric(?, ?).</p><p>? Size ? : number of datasets to sample on the graph world.</p><p>With these inputs, the GraphWorld system is trivially parallel over ? location on the graph world. We give more architecture details in Appendix A. In the following Section 4, we specify the above inputs for three different GraphWorld pipelines, and discuss the results of those pipelines in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Efficient exploration of graph worlds</head><p>A key aspect of GraphWorld is the ability to analyze the response of GNN models to the task generator parameters described previously. However, not all configurations (? 1 , ? 2 , . . .) in parameter space will provide equivalent insights. As a trivial example, extremely small values of ? ? = number of vertices (such as 2 or 3) will clearly not be useful to exploring other parameters, like edge density, or the skewness of the degree distribution, since GNN models will either perform poorly or perfectly on trivially-sized graphs regardless of other parameters.</p><p>We provide a methodology to mine a large (random) sample of GraphWorld generator configurations for the most "affective" configuration, meaning that deviations from that configuration affect GNN model performance most strongly. Assume we have generated a graph world for a given task? with generator parameter space ?, and at each location ? at the graph world we have a sampled configuration ?? ? ? and an average GNN test metric ? ? . Conceptually, a sampled configuration ? = (? 1 , ? 2 , . . .) is most affective if for every ? ? ? ?, changing the value of any other parameter ? ? produces variance in the test metrics of GNN models.</p><p>To find such a configuration, we perform marginal optimization on the space of parameters ?. Using the samples {( ?? , ? ? )} on an initial run of a GraphWorld pipeline, we find a (locally) optimal setting for each ? ? in the following manner. We first bin each dimension of ? into a fixed number of quantile bins. Then for each quantized value ? ? = ?, we compute the average F statistic <ref type="bibr" target="#b39">[40]</ref> between the other parameter values ? ? and the test metric ? (on graph world locations where ? ? = ?). We then set ? ? to the ? value that produced the highest F statistic. This produces an optimal generator configuration from which we can efficiently sample a smaller but still-interesting graph world. In Section 4 we describe how we apply this technique to GraphWorld experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL DESIGN</head><p>In this section, we introduce novel experimental design for the GraphWorld method, showing how to efficiently sample a useful part of any graph world. We describe three tasks -node classification, graph classification, and link prediction -and how they are generated in various graph worlds. We also list the GNN models tested with the GraphWorld applications, and present novel GraphWorld modes of hyperparameter tuning and inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Methods</head><p>For the experiments in this paper, we choose 11 representative GNNs and 3 baselines to illustrate the strengths of our proposed approach.</p><p>? ARMA <ref type="bibr" target="#b3">[4]</ref>: A GNN with auto-regressive moving average filters.</p><p>? APPNP <ref type="bibr" target="#b23">[24]</ref>: One of the first 'linear' GNNs, accelerating propagation using Personalized PageRank. ? FiLM <ref type="bibr" target="#b5">[6]</ref>: A model that modulates an incoming message by the features of the target node.</p><p>? GAT <ref type="bibr" target="#b44">[45]</ref>: An early model of graph attention.</p><p>? GATv2 <ref type="bibr" target="#b6">[7]</ref>: An improved variant of graph attention that allows any node to attend to any other one.</p><p>? GCN <ref type="bibr" target="#b22">[23]</ref>: A seminal model that averages neighbor state at each iteration.  ? GIN <ref type="bibr" target="#b48">[49]</ref>: This model uses MLPs to transform summations of neighbor features.</p><p>? GraphSAGE <ref type="bibr" target="#b16">[17]</ref>: A variant of the GCN which adds uses sampling and improved propagation of the hidden state.</p><p>? SGC <ref type="bibr" target="#b46">[47]</ref>: Linear GNNs using matrix multiplication.</p><p>? SuperGAT <ref type="bibr" target="#b21">[22]</ref>: An approach to improve the graph attention layer.</p><p>? Transformer <ref type="bibr" target="#b37">[38]</ref>: A multi-head attention-based model. In addition we examine several baselines which are not GNNs: ? Linear Regression: (graph property prediction only) Simple ordinary least-squares with edge density as the sole feature. ? Multi-Layer Perceptron: (features only) Transforms the node features via a DNN for classification. ? Personalized PageRank <ref type="bibr" target="#b4">[5]</ref>: (graph only) Predicts node labels for unseen nodes via Personalized PageRank seeded by the labelled nodes. For each unseen node, we compute the total probability mass that comes from the vertices of each label, and pick the label with the highest score. ? Link prediction heuristics <ref type="bibr" target="#b29">[30]</ref>: (graph only) Creates a link prediction ranking using eight different reweighting schemes for counting common neighbors. We pick one of the following schemes: (i) S?rensen-Dice coefficient <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b40">41]</ref>, (ii) cosine similarity, (iii, iv) hub-promoted and hub-suppressed similarity <ref type="bibr" target="#b32">[33]</ref>, (v) Jaccard similarity <ref type="bibr" target="#b18">[19]</ref>, (vi) Adamic-Adar index <ref type="bibr" target="#b2">[3]</ref>, (vii) Resource Allocation index <ref type="bibr" target="#b51">[52]</ref>, and (viii) Leicht-Holme-Newman similarity <ref type="bibr" target="#b25">[26]</ref>. The GNN models use the reference implementations from the PyTorch-Geometric library <ref type="bibr" target="#b14">[15]</ref>. We note that by design it is trivial to add additional models into GraphWorld.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Hyperparameter Optimization</head><p>GNN hyperparameter tuning is essential for understanding model performance, and is an aspect of GNN experimentation that can be efficiently explored with GraphWorld. A GraphWorld pipeline can be run in one of three hyperparameter modes: Mode 1 Each model ? is trained and tested with a random draw (? ?1 , ? ?2 , ...) ? H ? , its hyperparameter configuration space. Mode 2 Assume a GraphWorld pipeline has already been run in Mode 1. For any model ?, let ?? be the ?-th unique configuration sampled (at any location in the graph world). Let D ? be the collection of GraphWorld datasets for which ?? was sampled for ?. Mode 2 is to run another GraphWorld pipeline with the best config ? * ? defined as:</p><formula xml:id="formula_0">? * = arg max ?? |D ? | -1 ?? ? ?D ? EvalMetric(?( ?? ), ?).<label>(1)</label></formula><p>Intuitively, we pick the hyperparameters that achieve the best average performance across all GraphWorld samples. Mode 3 Each model ? receives a budget of ? tuning rounds, and the hyperparameter configuration which performed best on a held-out validation set is used to compute the test metric. We give more model and hyperparameter details in Appendix B.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Tasks</head><p>Here we describe three tasks that will be explored with three separate GraphWorld pipelines. We provide the ranges of generator distribution parameters in Appendix B.2. In Section 5 we show results from each of tasks run in each of the hyperparameter tuning modes described previously in Section 4.2. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Node Classification (NC).</head><p>In this GraphWorld experiment, we generate graphs using the Stochastic Block Model (SBM). First, node labels (classification targets) are generated from a multinomial distribution, which define the node clusters. Edges are generated as Bernoulli random variables following within-block probability ? and between-block probability ? (? ? ?). Node features are generated from a within-cluster multivariate Normal distribution, with unit (diagonal) covariance, and cluster centers are drawn from a prior multivariate Normal. The variance of the prior controls the degree of separation between the cluster feature centers. The number of clusters, the cluster size, and the power law of the expected degree distribution, are also varied as described further in the Appendix. We tune and test GNN models with ROC-AUC one-vs-rest (AUC-ovr). We train models on a random sample of 5 nodes perclass, tune on a (disjoint) random sample of 5 nodes per-class, and test on the rest of the nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Link Prediction (LP).</head><p>In this GraphWorld experiment, we generate graphs using the SBM, as for node classification. However, to simulate a link prediction setting, we randomly split edges into training, validation, and test sets. The task is to predict the "unseen" edges in the test set, which we evaluate with the ROC-AUC metric against randomly chosen negatives, imitating the setting in <ref type="bibr" target="#b15">[16]</ref>. We train on 80% of the edges, tune on 10% of the edges, and test on the remaining 10%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Graph Property Prediction (GPP).</head><p>In this GraphWorld experiment, we generate a dataset of small Erd?s-Renyi random graphs. The task is to infer the number of a certain motif in each test graph. In this paper, we evaluate tailed-triangle motif counting. We evaluate the models with scaled mean-squared-error (S-MSE):</p><p>(? ? -?? ) 2 / (? ??) 2 , which is comparable across datasets with different scales of motif counts. As in <ref type="bibr" target="#b8">[9]</ref>, we give a dummy unit one-dimensional feature to each node. Here, the number of training graphs is a variable parameter (see Appendix B.2 for details). We tune on 20% of the data, and test on the remainder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS AND INSIGHTS</head><p>In this section, we present preliminary results from the GraphWorld pipeline. Following the experimental design described in the previous section, we ran nine GraphWorld pipelines, one for each of three tasks, and with all three hyperparameter optimization modes per task (see Section 4.2). To sample more efficiently from useful regions of the graph worlds, we applied the GraphWorld exploration technique described in Section 3.3 to the Mode 1 experiments, extracting default configurations to use for Mode 2 and Mode 3. In those modes, we sample only one parameter from the generator, holding the other parameters fixed at the default config. We provide the default configuration values in Section B.2.</p><p>The following two sections cover global-distribution and marginal-distribution insights uncovered by GraphWorld. While our primary aim is not to confirm or overturn established results in the literature, to illustrate the utility of GraphWorld, we point out previously-unseen behavior of GNN models which GraphWorld has exposed with synthetic graph generation.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Global Results</head><p>In this section we cover two insights from analyzing the global performance of GNN models on complete GraphWorld distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Insight: Globally Optimal Hyperparameters Work Well.</head><p>As shown in Tables <ref type="table" target="#tab_0">1,</ref><ref type="table" target="#tab_1">2</ref>, and 3, most models tested in GraphWorld Mode 2 (training each model with its best-performing hyperparameter set from Mode 1) uniformly outperform their counterparts tested in Mode 1 (with the exception of baselines like PPR, which do not have tunable hyperparameters). While Mode 2 models still do not uniformly outperform Mode 3 models (which each receive a budget of 100 tuning rounds), they do come close, especially on the link prediction task. This shows that GraphWorld can cheaply find hyperparameter improvements that work for a large variety of graphs. Furthermore, as seen in Figure <ref type="figure" target="#fig_6">6</ref> many of the top-performing hyperparameter configurations from GraphWorld Mode 1 have similar average test accuracy (there is no stand-out best configuration). Figure <ref type="figure" target="#fig_6">6</ref> displays the dropoff in performance of all unique sampled hyperparameter configurations for the GraphWorld Link Prediction Mode 1 experiment. Each configuration has an average test metric score, averaged over each graph world location at which it was sampled. The lines in this plot represent the ordered scores for each model, the x-axis representing the inverse percentile rank of the score. This depiction illustrates that for most models, there is no "elbow" <ref type="bibr" target="#b41">[42]</ref> or clear break between top-performing hyperparameter configuration and the next 10-20 top performing configurations.</p><p>While we are cautious about how these observations apply to graphs with more complex features, it does suggest that finding good hyper-parameters for models in GraphWorld is low-cost. As a result of this finding all figures and tables (other than Tables <ref type="table" target="#tab_0">1</ref><ref type="table" target="#tab_1">2</ref><ref type="table" target="#tab_2">3</ref>) contain data from just GraphWorld Mode 2 experiments, as in Mode 2 we are able to sample more graphs than in Mode 3 with the same computational budget.</p><p>Another important observation from GraphWorld mode comparisons regard one family of models-variations of Graph Attention Networks-that exhibit high sensitivity for hyperparameters in the node classification experiments in Table2. While not achieving the absolute best performance, the difference between Mode 2 and Mode 3 is the most profound for GAT models. We can also compare the improvements to the original GAT architecture. We observe that SuperGAT achieves significantly better performance in Mode 3, whereas GATv2 struggles to improve over its parent model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Insight:</head><p>Most GNNs Can't Count Substructures. Table <ref type="table" target="#tab_0">1</ref> shows that among GNNs we tested on the Graph Property Prediction graph world, only GIN achieved better-than-mean-fitting MSE, along with simple linear regression with edge density as a feature, which outperformed all other GNNs. In fact, all other methods performed no better (on average) than the naive mean-predictor which produces a scaled MSE of exactly 1.0. This result both accords with and contrasts with various results from the paper "Can graph neural networks count substructures?" <ref type="bibr" target="#b8">[9]</ref>, which contains a synthetic data experiment that GraphWorld replicates thousands of times. We make the following observations and comparisons:</p><p>? The conclusion of <ref type="bibr" target="#b8">[9]</ref> generally holds that "Message-Passing Neural Networks cannot count substructures". Interestingly however, the GIN architecture is able to learn a representation which has some utility for the task, significantly outperforming performing the linear regression baseline. This makes intuitive sense, as GIN was developed specifically to be more-expressive for whole-graph encoding tasks. ? We show that simple linear regression using edge density as a feature can count substructures better than most GNNs.  With GraphWorld, we reveal a more controlled and reproducible study into substructure counting, using appropriately-scaled MSE, showing that most GNNs fail on the task, but surprisingly GIN does not (even though none of the GNNs are given meaningful features). Due to the lack of good performance of most GNNs on this task, for the rest of this section we analyze GraphWorld results only on Link Prediction and Node Classification tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Marginal Results</head><p>We now turn to marginal analysis of GNN models. Marginal parameter analysis is a unique and powerful property of GraphWorld, allowing us to examine the average response of GNN models to particular, explainable characteristics of the task. We rely on plots in figures 1, 4, and 5 for these insights. We produced those plots using data from GraphWorld Mode 2, using only samples in each plot from which the corresponding parameter was varied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.2.1</head><p>Insight: GNN models switch ranks outside of standard benchmark space. To establish our key empirical result, as seen in the three plots inside Figure <ref type="figure">1</ref>, we project the GraphWorld node classification task distribution space into a 2-D plane measuring each graph's average degree and edge homogeneity, which is the proportion of edges that connect nodes in the same class <ref type="bibr" target="#b52">[53]</ref>. Our first finding is that standard benchmark graphs (shown as black points on the plot) cover only a small region of this graph space that GraphWorld is able to cover via synthetic graph generation. This adds to the strong overall motivation for the GraphWorld method described in Section 2, since these statistics should (intuitively) strongly affect graph convolutions.</p><p>On the ?-axis of each plot in Figure <ref type="figure">1</ref>, we measure the mean reciprocal rank of GCN, APPNP, and FiLM (respectively) against the other 12 models. Our second finding is that-indeed, as expected-GNN models exhibit high ranking variance across this slice of synthetic graph space. We find sharp MRR phase transitions around 0.5 edge homogeneity, and for lower values of average degree. Furthermore, importantly, standard benchmark datasets mostly avoid regions of phase transitions. This strongly suggests that standard benchmark datasets are insufficient to produce generalizable rankings of models and that there is a serious risk of overfitting to the small number of available benchmark datasets for GNNs. We are hopeful that more comprehensive benchmarking by the means of GraphWorld will help the field to continue to make forward progress.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Insight: GNNs respond surprisingly to graph characteristics.</head><p>Our GraphWorld experiments on node classification (NC) and link prediction (LP) tasks offer both intuitive and counter-intuitive insights about GNN responsiveness to graph and node feature distributions. We make the following observations:</p><p>? Number of vertices doesn't matter. Across NC and LP tasks, the size of the graph (number of vertices) has negligible effect on test AUC. This suggests that in many cases, it may be sufficient to test new GNN architectures on small graphs produced by GraphWorld, rather than focusing on large graphs that are currently being proposed as a one-size-fits-all solution to benchmarking GNNs <ref type="bibr" target="#b17">[18]</ref>. ? NC: Differential sensitivity to graph and feature signal. For NC, most models increased test AUC as the ?-to-? ratio (graph cluster signal) and feature-center-distance (feature cluster signal) increased. Interestingly, attention-based methods (GAT, GATv2) did not respond as well to these parameters, and seemed to respond negatively to stronger feature signal. FiLM and MLP, which depend strongly on the features, do not respond at all to p /q, but are among the top-performers as the feature signal increases. ? LP: weaker dependence on cluster strength. For link prediction, interestingly, the distance between feature clusters and p /q ratio do not have as strong of an effect on models as in the NC task, and some models even seem to exhibit local-maxima behavior in response to these parameters. This suggests that these models (GAT, GATv2, and FiLM) can not harness very powerful node features and translate them to positional embedding for link prediction.</p><p>The insights described in this section and Section 5.1 are not possible without a method like GraphWorld, which (1) has the capability to generate millions of test datasets with diverse characteristics and (2) logs the dataset characteristics along with test metrics for each model. The insights above are certainly not all that could be gleaned from GraphWorld experiments, or even the particular GraphWorld experiments that we ran. We hope that future GNN researchers will include GraphWorld studies as complements to real data analyses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Cost and scale</head><p>It is relatively cheap to perform large-scale GNN model analyses such as those in this paper with GraphWorld. Our node classification experiments featured in the paper cost under $120, involving 13 models on 1M+ benchmark datasets, with no GPUs and negligible RAM. By comparison, the experiment with real-world OGB data from <ref type="bibr" target="#b26">[27]</ref> involved only 3 models, only 1 Open Graph Benchmark (OGB) dataset, 4 GPUs, and &gt;480GB of RAM per &gt;24 CPUs. These resources would cost &gt;$500 on modern cloud compute platforms (see https://cloud.google.com/compute). Additionally, that OGB experiment completed in &gt;40hrs, whereas our GraphWorld experiments took 10hrs total.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS AND FUTURE WORK</head><p>The reliance on standardized real-world benchmark datasets in GNN research has been an important way to track technological progress over time on tangible applications. However, as we argued in Section 2, existing benchmark graph datasets are too limited to fully explore the relative performances of GNN models, and can be too costly for the majority of labs to rapidly experiment with. In this paper, we have shown that GraphWorld addresses these problems via the following features:</p><p>(1) Generalizable analyses. With tunable parameters for GNN dataset generators, GraphWorld can simulate graphs with farwider ranges of graph properties than currently exist in any collection of benchmark datasets. As shown in our results (especially Figure <ref type="figure">1</ref>), the marginal analysis of these parameters and statistics can generate insights about GNN architectures that are unavailable from any small collection of re-used benchmark datasets. (2) Reproducibility without overfitting. Using our code and platform, a researcher can use GraphWorld to test their model as easily as with any existing collection of GNN benchmarks, but without the risk of overfitting to graphs with a limited set of properties. (3) Accessibility. As described in Section 5.3, GraphWorld does not require excessive resources, and can actually test many more models at a time for lower cost than standard benchmarks. Furthermore, our experiments show that assessing GNN test performance does not depend on having natural, society-scale graph data. Combining these observations, we have shown that with GraphWorld it is possible to derive new insights with less resources. This is particularly important to facilitate GNN research in smaller labs.</p><p>These characteristics make GraphWorld the perfect complement to GNN experiments on graph datasets sourced from nature. While performance on such natural datasets will always be of scientific interest and essential for new research, GraphWorld can expose when progress on them may not transfer to other datasets. More importantly, GraphWorld can help uncover certain distributions of graphs that have not yet been used to test GNNs, which we hope will inspire new architecture development. At Google, we are integrating GraphWorld with GNN experimental pipelines and unit tests, as well as with TF-GNN <ref type="bibr" target="#b0">[1]</ref>.</p><p>A complementary and follow-up line of research to our work could be the development of new random graph models with tunable properties that target classes of GNN architectures. For instance, we may wish to design clustered graph models with tunable numbers of certain graph motifs, or attributed graph models with non-trivial feature correlations. GraphWorld is the perfect tool to understand how these variations in these graph properties cause differential responses from various GNN architectures.</p><p>Overall, GraphWorld facilitates cheap, comprehensive, and principled investigation into the nuances of GNN model performance. By releasing our codebase at http://release/pending and integrating GraphWorld with TF-GNN, we hope to make GNN experimental results more robust and transferable -helping researchers reach more reliable conclusions when developing new architectures. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A IMPLEMENTATION AND COST</head><p>Design goals for GraphWorld focused on accessibility, scalability and efficiency; any researcher should be able to run GraphWorld simulations with minimal setup, while having the system automatically scale up experiments to available resources only as needed.</p><p>To this end, GraphWorld is implemented as a containerized Apache Beam 1 pipeline allowing researchers to run a hermetic copy of Graph World on any infrastructure i.e., a local machine, compute cluster, or cloud framework. Experiments in this paper were run on Google Cloud Platform (GCP) using Cloud Dataflow. Experiments were allowed to scale up to a maximum of 1000 workers using n1-standard-1 machines capable of sampling millions of graphs in ? 10 hours.</p><p>Figure <ref type="figure">7</ref> shows the design of the GraphWorld distributed processing system. Table <ref type="table" target="#tab_4">5</ref> shows the number of virtual-CPU hours needed to complete the nine pipelines discussed in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B EXPERIMENT DETAILS</head><p>In this Appendix section, we provide more details about GraphWorld pipelines, the task dataset generators, and the model architectures.</p><p>In particular, we specify all the GraphWorld configuration elements (see Section 3) of each pipeline described in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Models</head><p>Here we list hyperparameter values available to each GNN model (and some non-GNN models) for tuning. We note that GraphWorld experiments are focused on a comparison of the convolution layers introduced by each model (defined by its corresponding convolution implementation in PyTorch-geometric).</p><p>Graph Property Prediction. In order to generate the global readout of the node state, we take the final layer's activations for all the nodes and apply mean pooling to create a graph representation. This representation is then used for regressing substructure counts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Generator parameters</head><p>In Tables <ref type="table">6</ref> and<ref type="table">7</ref>, we list generator parameters for task dataset generators. Table <ref type="table">6</ref> has parameter values for the Node Classification and Link Prediction pipelines. Table <ref type="table">7</ref> has parameter values for the Graph Property Prediction pipelines. Each table contains the 1 https://beam.apache.org/ parameter names, their description, and their default values found using the technique described in Section 3.3.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The distribution of graphs from the Open Graph Benchmark does not match the general population. Our proposed method, GraphWorld, allows statistically sound insights about GNN model performance via extensive, scalable sampling from an expansive distribution of graphs.</figDesc><graphic url="image-1.png" coords="2,340.86,83.68,192.20,185.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a) Unbalanced clusters, ? /? = 25.0 (b) Features PCA, center distance = 0.05 (c) Balanced clusters, ? /? = 5.0 (d) Features PCA, center distance = 3.0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: GraphWorld node classification datasets simulated using a Stochastic Block Model with (independent) Gaussian node features. These plots show the effect of toggling GraphWorld generator parameters like ? /? and the distance between feature cluster centers.</figDesc><graphic url="image-4.png" coords="3,66.56,234.79,100.87,86.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: GraphWorld node classification results (mode 2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>GraphWorld link prediction results (mode 2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Hyperparameter tuning performance dropoff.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-6.png" coords="11,53.80,286.95,504.39,279.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Graph property prediction performance averages in terms of scaled MSE. Lower is better.</figDesc><table><row><cell>model</cell><cell>Mode 1</cell><cell>Mode 2</cell><cell>Mode 3</cell></row><row><cell>APPNP</cell><cell>1.04 ? 0.00</cell><cell>1.02 ? 0.00</cell><cell>1.03 ? 0.00</cell></row><row><cell>ARMA</cell><cell>1.03 ? 0.00</cell><cell>0.97 ? 0.00</cell><cell>0.92 ? 0.01</cell></row><row><cell>FiLM</cell><cell>1.06 ? 0.01</cell><cell>1.01 ? 0.00</cell><cell>1.01 ? 0.00</cell></row><row><cell>GAT</cell><cell>1.04 ? 0.00</cell><cell>1.02 ? 0.00</cell><cell>1.03 ? 0.00</cell></row><row><cell>GATv2</cell><cell>1.04 ? 0.00</cell><cell>1.02 ? 0.00</cell><cell>1.03 ? 0.00</cell></row><row><cell>GCN</cell><cell>1.04 ? 0.00</cell><cell>1.02 ? 0.00</cell><cell>1.03 ? 0.00</cell></row><row><cell>GIN</cell><cell>0.86 ? 0.07</cell><cell>0.21 ? 0.01</cell><cell>0.33 ? 0.03</cell></row><row><cell>GraphSAGE</cell><cell>1.04 ? 0.00</cell><cell>1.01 ? 0.00</cell><cell>1.01 ? 0.00</cell></row><row><cell>LR</cell><cell>0.52 ? 0.00</cell><cell>0.52 ? 0.00</cell><cell>0.51 ? 0.03</cell></row><row><cell>MLP</cell><cell>1.04 ? 0.00</cell><cell>1.02 ? 0.00</cell><cell>1.03 ? 0.00</cell></row><row><cell>SGC</cell><cell>1.08 ? 0.00</cell><cell>1.02 ? 0.00</cell><cell>1.03 ? 0.01</cell></row><row><cell>SuperGAT</cell><cell>1.04 ? 0.00</cell><cell>1.02 ? 0.00</cell><cell>1.03 ? 0.01</cell></row><row><cell>Transformer</cell><cell>1.04 ? 0.00</cell><cell>1.00 ? 0.00</cell><cell>1.00 ? 0.01</cell></row><row><cell>model</cell><cell>Mode 1</cell><cell>Mode 2</cell><cell>Mode 3</cell></row><row><cell>APPNP</cell><cell>62.31 ? 0.05</cell><cell>74.16 ? 0.10</cell><cell>79.16 ? 0.33</cell></row><row><cell>ARMA</cell><cell>65.03 ? 0.05</cell><cell>71.43 ? 0.10</cell><cell>77.97 ? 0.33</cell></row><row><cell>FiLM</cell><cell>66.07 ? 0.05</cell><cell>71.52 ? 0.11</cell><cell>72.00 ? 0.34</cell></row><row><cell>GAT</cell><cell>63.38 ? 0.05</cell><cell>70.42 ? 0.09</cell><cell>80.32 ? 0.36</cell></row><row><cell>GATv2</cell><cell>63.40 ? 0.05</cell><cell>69.79 ? 0.09</cell><cell>80.24 ? 0.36</cell></row><row><cell>GCN</cell><cell>63.50 ? 0.05</cell><cell>71.31 ? 0.09</cell><cell>81.46 ? 0.36</cell></row><row><cell>GIN</cell><cell>61.29 ? 0.04</cell><cell>68.18 ? 0.08</cell><cell>76.05 ? 0.36</cell></row><row><cell>GraphSAGE</cell><cell>64.58 ? 0.05</cell><cell>71.55 ? 0.10</cell><cell>78.41 ? 0.33</cell></row><row><cell>MLP</cell><cell>64.14 ? 0.05</cell><cell>71.46 ? 0.11</cell><cell>70.92 ? 0.34</cell></row><row><cell>PPR</cell><cell>59.62 ? 0.03</cell><cell>52.28 ? 0.03</cell><cell>59.59 ? 0.28</cell></row><row><cell>SGC</cell><cell>58.36 ? 0.04</cell><cell>66.06 ? 0.09</cell><cell>71.79 ? 0.42</cell></row><row><cell>SuperGAT</cell><cell>63.58 ? 0.05</cell><cell>71.56 ? 0.09</cell><cell>81.26 ? 0.35</cell></row><row><cell>Transformer</cell><cell>64.07 ? 0.05</cell><cell>71.52 ? 0.10</cell><cell>77.67 ? 0.33</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Node classification performance averages in terms of ROC-AUC. Higher is better.</figDesc><table><row><cell>model</cell><cell>Mode 1</cell><cell>Mode 2</cell><cell>Mode 3</cell></row><row><cell>APPNP</cell><cell>70.41 ? 0.02</cell><cell>76.48 ? 0.01</cell><cell>76.80 ? 0.11</cell></row><row><cell>ARMA</cell><cell>69.21 ? 0.03</cell><cell>79.49 ? 0.01</cell><cell>79.77 ? 0.13</cell></row><row><cell>Heuristics</cell><cell>69.65 ? 0.03</cell><cell>65.92 ? 0.02</cell><cell>65.91 ? 0.19</cell></row><row><cell>FiLM</cell><cell>66.28 ? 0.03</cell><cell>77.40 ? 0.01</cell><cell>77.22 ? 0.14</cell></row><row><cell>GAT</cell><cell>60.40 ? 0.03</cell><cell>75.45 ? 0.01</cell><cell>75.48 ? 0.13</cell></row><row><cell>GATv2</cell><cell>59.62 ? 0.03</cell><cell>75.44 ? 0.01</cell><cell>75.50 ? 0.13</cell></row><row><cell>GCN</cell><cell>64.13 ? 0.03</cell><cell>77.54 ? 0.01</cell><cell>78.00 ? 0.12</cell></row><row><cell>GIN</cell><cell>71.06 ? 0.03</cell><cell>79.97 ? 0.01</cell><cell>79.79 ? 0.13</cell></row><row><cell>GraphSAGE</cell><cell>61.89 ? 0.04</cell><cell>76.94 ? 0.01</cell><cell>75.20 ? 0.14</cell></row><row><cell>MLP</cell><cell>56.28 ? 0.02</cell><cell>76.01 ? 0.01</cell><cell>75.90 ? 0.14</cell></row><row><cell>SGC</cell><cell>66.56 ? 0.03</cell><cell>74.62 ? 0.01</cell><cell>75.76 ? 0.11</cell></row><row><cell>SuperGAT</cell><cell>60.41 ? 0.03</cell><cell>75.66 ? 0.01</cell><cell>75.54 ? 0.13</cell></row><row><cell>Transformer</cell><cell>65.37 ? 0.03</cell><cell>77.21 ? 0.01</cell><cell>77.10 ? 0.14</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Link prediction mode averages in terms of ROC-AUC. Higher is better.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Hyperparameter values for all models used by all GraphWorld experiments.</figDesc><table><row><cell cols="3">Hyperparameter</cell><cell></cell><cell></cell><cell></cell><cell>Values</cell></row><row><cell cols="3">Learning Rate</cell><cell></cell><cell></cell><cell cols="2">[0.01, 0.001, 0.0001]</cell></row><row><cell cols="3">Hidden Channels</cell><cell></cell><cell></cell><cell></cell><cell>[4, 8, 16]</cell></row><row><cell cols="3">Number of Layers</cell><cell></cell><cell></cell><cell></cell><cell>[1, 2, 3, 4]</cell></row><row><cell cols="3">Dropout</cell><cell></cell><cell></cell><cell></cell><cell>[0, 0.3, 0.5, 0.8]</cell></row><row><cell cols="5">? (APPNP, SGC, and PPR baseline)</cell><cell></cell><cell>[0.1, 0.2, 0.3]</cell></row><row><cell cols="4">Iterations (APPNP and SGC)</cell><cell></cell><cell></cell><cell>[5, 10, 15]</cell></row><row><cell cols="6"># of attention heads (GATs and Transformer)</cell><cell>[1, 2, 3, 4]</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">GCN</cell><cell>GIN</cell><cell>GAT</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">GraphSAGE</cell><cell>APPNP</cell><cell>SGC</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">ARMA</cell><cell>GATv2</cell><cell>FiLM</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">SuperGAT</cell><cell cols="2">Transformer</cell><cell>MLP</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Heuristics</cell><cell></cell></row><row><cell></cell><cell></cell><cell>100</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Link prediction</cell><cell>ROC AUC?100</cell><cell>60 80</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>1</cell><cell>20</cell><cell>40</cell><cell>60</cell><cell>80</cell><cell>100</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="4">% rank of hyperparameter config</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Resource complexity for GraphWorld experiments.</figDesc><table><row><cell cols="4">Task Mode Samples (? ) Tuning Rounds</cell><cell>vCPU hours</cell></row><row><cell>LP</cell><cell>1</cell><cell>1e6</cell><cell>0</cell><cell>1,681</cell></row><row><cell>LP</cell><cell>2</cell><cell>7e5</cell><cell>0</cell><cell>1,672</cell></row><row><cell>LP</cell><cell>3</cell><cell>7e3</cell><cell>100</cell><cell>1,896</cell></row><row><cell>NC</cell><cell>1</cell><cell>1e6</cell><cell>0</cell><cell>1,047</cell></row><row><cell>NC</cell><cell>2</cell><cell>7e5</cell><cell>0</cell><cell>755</cell></row><row><cell>NC</cell><cell>3</cell><cell>7e3</cell><cell>100</cell><cell>937</cell></row><row><cell cols="2">GPP 1</cell><cell>1e6</cell><cell>0</cell><cell>9,767</cell></row><row><cell cols="2">GPP 2</cell><cell>4e5</cell><cell>0</cell><cell>3,399</cell></row><row><cell cols="2">GPP 3</cell><cell>4e3</cell><cell>100</cell><cell>3,553</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>We thank <rs type="person">Google Cloud</rs> for supporting this project.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<ptr target="https://github.com/tensorflow/gnn" />
	</analytic>
	<monogr>
		<title level="j">Tensorflow GNN</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Community detection and stochastic block models: recent developments</title>
		<author>
			<persName><forename type="first">Emmanuel</forename><surname>Abbe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Lada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eytan</forename><surname>Adamic</surname></persName>
		</author>
		<author>
			<persName><surname>Adar</surname></persName>
		</author>
		<title level="m">Friends and neighbors on the web. Social networks</title>
		<imprint>
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Graph neural networks with convolutional filters</title>
		<author>
			<persName><forename type="first">Maria</forename><surname>Filippo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniele</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorenzo</forename><surname>Grattarola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cesare</forename><surname>Livi</surname></persName>
		</author>
		<author>
			<persName><surname>Alippi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The anatomy of a large-scale hypertextual web search engine. Computer networks and ISDN systems</title>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Page</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Gnn-film: Graph neural networks with feature-wise linear modulation</title>
		<author>
			<persName><forename type="first">Marc</forename><surname>Brockschmidt</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Shaked</forename><surname>Brody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eran</forename><surname>Yahav</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.14491</idno>
		<title level="m">How Attentive are Graph Attention Networks? arXiv preprint</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Ines</forename><surname>Chami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sami</forename><surname>Abu-El-Haija</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>R?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.03675</idno>
		<title level="m">Machine learning on graphs: A model and comprehensive taxonomy</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Zhengdao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soledad</forename><surname>Villar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.04025</idno>
		<title level="m">Can graph neural networks count substructures? arXiv preprint</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Leveraging procedural generation to benchmark reinforcement learning</title>
		<author>
			<persName><forename type="first">Karl</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Are we really making much progress? A worrying analysis of recent neural recommendation approaches</title>
		<author>
			<persName><forename type="first">Maurizio</forename><surname>Ferrari Dacrema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Cremonesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dietmar</forename><surname>Jannach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Measures of the amount of ecologic association between species</title>
		<author>
			<persName><surname>Lee R Dice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecology</title>
		<imprint>
			<date type="published" when="1945">1945. 1945</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Prakash Dwivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chaitanya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><surname>Bresson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.00982</idno>
		<title level="m">Benchmarking graph neural networks</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A fair comparison of graph neural networks for graph classification</title>
		<author>
			<persName><forename type="first">Federico</forename><surname>Errica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Podda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Davide</forename><surname>Bacciu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessio</forename><surname>Micheli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fast Graph Representation Learning with PyTorch Geometric</title>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop on Representation Learning on Graphs and Manifolds</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><forename type="first">Rex</forename><surname>William L Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Open Graph Benchmark: Datasets for machine learning on graphs</title>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Catasta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The distribution of the flora in the alpine zone</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Jaccard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New Phytologist</title>
		<imprint>
			<date type="published" when="1912">1912. 1912</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Stochastic blockmodels and community structure in networks</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Karrer</surname></persName>
		</author>
		<author>
			<persName><surname>Mark Ej Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review E</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page">16107</biblScope>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A comparative study for unsupervised network representation learning</title>
		<author>
			<persName><forename type="first">Megha</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinay</forename><surname>Setty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avishek</forename><surname>Anand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">How to Find Your Friendly Neighborhood: Graph Attention Design with Self-Supervision</title>
		<author>
			<persName><forename type="first">Dongkwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alice</forename><surname>Oh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Predict then propagate: Graph neural networks meet personalized pagerank</title>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Klicpera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>G?nnemann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.05997</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Wilds: A benchmark of in-the-wild distribution shifts</title>
		<author>
			<persName><forename type="first">Pang</forename><surname>Wei Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiori</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sang</forename><surname>Michael Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marvin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akshay</forename><surname>Balsubramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<meeting><address><addrLine>Richard Lanas Phillips, Irena Gao, Tony Lee</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Vertex similarity in networks</title>
		<author>
			<persName><forename type="first">Elizabeth</forename><forename type="middle">A</forename><surname>Leicht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petter</forename><surname>Holme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">Ej</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">Guohao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesus</forename><surname>Zarzar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hesham</forename><surname>Mostafa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sohil</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcel</forename><surname>Nassar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Cummings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sami</forename><surname>Abu-El-Haija</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>M?ller</surname></persName>
		</author>
		<title level="m">DEEPERBIGGERBETTER for OGB-LSC at KDD cup 2021</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Zachary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName><surname>Steinhardt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03341</idno>
		<title level="m">Troubling trends in machine learning scholarship</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Enxhell</forename><surname>Luzhnica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Day</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Li?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.04682</idno>
		<title level="m">On graph classification networks, datasets and baselines</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Reproducible Evaluations of Network Representation Learning Models Using EvalNE. WWW&apos;21, Workshop on Graph Learning Benchmarks</title>
		<author>
			<persName><forename type="first">Alexandru</forename><surname>Mara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jefrey</forename><surname>Lijffijt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tijl</forename><surname>De Bie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Tudataset: A collection of benchmark datasets for learning with graphs</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nils</forename><forename type="middle">M</forename><surname>Kriege</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franka</forename><surname>Bause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristian</forename><surname>Kersting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petra</forename><surname>Mutzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marion</forename><surname>Neumann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.08663</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.14599</idno>
		<title level="m">Adversarial NLI: A new benchmark for natural language understanding</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<author>
			<persName><forename type="first">Erzs?bet</forename><surname>Ravasz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><forename type="middle">Lisa</forename><surname>Somera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><forename type="middle">A</forename><surname>Mongru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zolt?n</forename><forename type="middle">N</forename><surname>Oltvai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A-L</forename><surname>Barab?si</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Hierarchical organization of modularity in metabolic networks</title>
		<imprint>
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rebecca</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vaishaal</forename><surname>Shankar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.00451</idno>
		<title level="m">Do cifar-10 classifiers generalize to cifar-10?</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The Network Data Repository with Interactive Graph Analytics and Visualization</title>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">A</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nesreen</forename><forename type="middle">K</forename><surname>Ahmed</surname></persName>
		</author>
		<ptr target="https://networkrepository.com" />
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Scale-Free, Attributed and Class-Assortative Graph Generation to Facilitate Introspection of Graph Neural Networks. WWW&apos;21, Workshop on Graph Learning Benchmarks</title>
		<author>
			<persName><forename type="first">Neil</forename><surname>Shah</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">Oleksandr</forename><surname>Shchur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maximilian</forename><surname>Mumme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>G?nnemann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.05868</idno>
		<title level="m">Pitfalls of graph neural network evaluation</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Masked label prediction: Unified message passing model for semisupervised classification</title>
		<author>
			<persName><forename type="first">Yunsheng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengjie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shikun</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenjin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Alfred: A benchmark for interpreting grounded instructions for everyday tasks</title>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Shridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Thomason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Winson</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roozbeh</forename><surname>Mottaghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dieter</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">W</forename><surname>Snedecor</surname></persName>
		</author>
		<title level="m">Statistical methods</title>
		<imprint>
			<date type="published" when="1957">1957</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A method of establishing groups of equal amplitude in plant sociology based on similarity of species content and its application to analyses of the vegetation on Danish commons</title>
		<author>
			<persName><forename type="first">A</forename><surname>Th</surname></persName>
		</author>
		<author>
			<persName><surname>S?rensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Skar</title>
		<imprint>
			<date type="published" when="1948">1948. 1948</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Who belongs in the family?</title>
		<author>
			<persName><forename type="first">Thorndike</forename><surname>Robert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<date type="published" when="1953">1953. 1953</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Graph clustering with graph neural networks</title>
		<author>
			<persName><forename type="first">Anton</forename><surname>Tsitsulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Palowitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emmanuel</forename><surname>M?ller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.16904</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Synthetic Graph Generation to Benchmark Graph Learning. WWW&apos;21, Workshop on Graph Learning Benchmarks</title>
		<author>
			<persName><forename type="first">Anton</forename><surname>Tsitsulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benedek</forename><surname>Rozemberczki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Palowitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">Graph attention networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Break it down: A question understanding benchmark</title>
		<author>
			<persName><forename type="first">Tomer</forename><surname>Wolfson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mor</forename><surname>Geva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankit</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Deutch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACL</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Simplifying graph convolutional networks</title>
		<author>
			<persName><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amauri</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Fifty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><surname>Weinberger</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A comprehensive survey on graph neural networks</title>
		<author>
			<persName><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fengwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.00826</idno>
		<title level="m">How powerful are graph neural networks? arXiv preprint</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Design space for graph neural networks</title>
		<author>
			<persName><forename type="first">Jiaxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">A pipeline for fair comparison of graph neural networks in node classification tasks</title>
		<author>
			<persName><forename type="first">Wentao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dalin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinguo</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.10619</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Predicting missing links via local information</title>
		<author>
			<persName><forename type="first">Tao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linyuan</forename><surname>L?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi-Cheng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The European Physical Journal B</title>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<author>
			<persName><forename type="first">Jiong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujun</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingxiao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Heimann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leman</forename><surname>Akoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danai</forename><surname>Koutra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.11468</idno>
		<title level="m">Beyond homophily in graph neural networks: Current limitations and effective designs</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
