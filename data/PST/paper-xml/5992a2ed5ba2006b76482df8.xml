<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Graph Edge Partitioning via Neighborhood Heuristic</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chenzi</forename><surname>Zhang</surname></persName>
							<email>czzhang@cs.hku.hk</email>
						</author>
						<author>
							<persName><forename type="first">Fan</forename><surname>Wei</surname></persName>
							<email>fanwei@stanford.edu</email>
						</author>
						<author>
							<persName><forename type="first">Qin</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhihao</forename><forename type="middle">Gavin</forename><surname>Tang</surname></persName>
							<email>zhtang@cs.hku.hk</email>
						</author>
						<author>
							<persName><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
							<email>li.zhenguo@huawei.com</email>
						</author>
						<author>
							<persName><forename type="first">Hong</forename><surname>Kong</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Graph Edge Partitioning via Neighborhood Heuristic</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3097983.3098033</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We consider the edge partitioning problem that partitions the edges of an input graph into multiple balanced components, while minimizing the total number of vertices replicated (one vertex might appear in more than one partition). This problem is critical in minimizing communication costs and running time for several largescale distributed graph computation platforms (e.g., PowerGraph, Spark GraphX). We first prove that this problem is NP-hard, and then present a new partitioning heuristic with polynomial running time. We provide a worst-case upper bound of replication factor for our heuristic on general graphs. To our knowledge, we are the first to provide such bound for edge partitioning algorithms on general graphs. Applying this bound to random power-law graphs greatly improves the previous bounds of expected replication factor. Extensive experiments demonstrated that our partitioning algorithm consistently produces much smaller replication factors on various benchmark data sets than the state-of-the-art. When deployed in the production graph engine, PowerGraph, in average it reduces replication factor, communication, and running time by 54%, 66%, and 21%, respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>To handle large-scale graphs, distributed graph engines <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b15">16]</ref> partition the input graph and parallelize the computation on a cluster of machines. A traditional approach to graph partitioning is vertex partitioning: a distributed graph engine partitions the vertex set of a graph into balanced partitions such that the number of edges across different partitions is minimized. However, for most of the large real-world graphs, edge partitioning (Fig. <ref type="figure" target="#fig_0">1</ref>) is found to be more effective in advanced distributed graph engines <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b15">16]</ref>, which evenly assigns edges to machines in a way that minimizes the number of times each vertex is cut (i.e., replicated). Because most real-world graphs (e.g., social networks, web graphs) have skewed power-law degree distribution, which means that most vertices have relatively few neighbors while a few have many neighbors (e.g., celebrities on Facebook's social network). The power-law degree distribution can lead to substantial work imbalance in distributed graph systems that adopt vertex partitioning. Since the storage, communication, and computation complexity of a partition is linear in the number of edges in the partition, the running time of each vertex partition can vary widely. Not surprisingly, researchers demonstrated that edge partitioning performs better on many large real-world graphs <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. This important finding attracts great interests in edge partitioning recently <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b16">17]</ref>. Edge partitioning has been widely adopted in recent graph systems including PowerGraph <ref type="bibr" target="#b5">[6]</ref>, Spark GraphX <ref type="bibr" target="#b6">[7]</ref>, and Chaos <ref type="bibr" target="#b15">[16]</ref>, to divide the graph across machines. It turns out that the overall system performance depends greatly on the quality of graph partitioning. To understand what makes a good edge partitioning, two issues should be addressed. Firstly, the jobs should be distributed evenly across machines, in order to minimize delay caused by stragglers during each round or superstep of computations. More critically, the communication between machines should be minimized, which is often a bottleneck in graph computing due to the intrinsic dependency and expensive random access in the graph <ref type="bibr" target="#b5">[6]</ref>. While it is relatively easy to solve the first issue by partitioning the edges evenly, the second issue can be highly challenging, which asks to minimize the so-called vertex replication (Section 2.2) that is caused when two adjacent edges (join at the same vertex) are allocated to different machines.</p><p>Quite a few methods have been proposed for edge partitioning. Chaos <ref type="bibr" target="#b15">[16]</ref> distributes the edges randomly (RAND) under high network bandwidth. RAND ignores all graph structure and incurs high vertex replication (Section 5). The density-based hashing method (DBH) <ref type="bibr" target="#b16">[17]</ref> first partitions the vertices randomly, and then assigns each edge (x,y) by following one of its end vertices (i.e., x and y) of smaller degree. DBH can exploit the skewed degree distribution of power-law graphs, but it leverages little graph structure, like RAND. Oblivious <ref type="bibr" target="#b5">[6]</ref> is a streaming algorithm that considers the distribution of previously assigned edges when assigning an incoming edge -an edge is more likely to be assigned to the partition with more adjacent edges. HDRF <ref type="bibr" target="#b14">[15]</ref> is another streaming algorithm that extends Oblivious by further exploiting the power-law degree distribution, like DBH. Both HDRF and Oblivious rely only on historical data, and thus use the graph structure only partially. Sheep <ref type="bibr" target="#b12">[13]</ref> partitions the graph in a divide and conquer manner, which uses more graph structure than Oblivious and HDRF, but it works well only for tree-like graphs. Those methods mentioned above, due to their not attempting to exploit the graph structure, typically yield high replication factor. The notable multi-level vertex partitioning algorithm METIS <ref type="bibr" target="#b7">[8]</ref> is extended for edge partitioning <ref type="bibr" target="#b2">[3]</ref>, which makes full access to the graph structure by partitioning the graph entirely in memory. This does lead to the state-of-the-art replication factors on a great number of graphs <ref type="bibr" target="#b12">[13]</ref>, but it is not applicable to large graphs.</p><p>In this paper, we present a heuristic called NE (Neighbor Expansion) that is developed based on a new, theoretically sound partitioning model that greedily maximizes edge locality. Our main contributions are summarized as follows:</p><p>• We establish theoretical understanding of the edge partitioning problem, including proving its NP-hardness and showing that every graph can be p-edge partitioned with replication factor O ( √ p).</p><p>• We propose a new edge partitioning heuristic called NE, and provide a worst-case upper bound of replication factor for our heuristic on general graphs. To the best of our knowledge, we are the first to provide such bound for edge partitioning algorithms on general graphs. We also show that it improves over existing bounds on random power-law graphs. We conduct extensive experiments which show that it significantly reduces the replication factor.</p><p>• We apply our partitioner to a distributed graph engine, Pow-erGraph. In average it reduces replication factor, communication, and running time by 54%, 66%, and 21%, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">GRAPH EDGE PARTITIONING</head><p>In this section, we first formalize the graph edge partitioning problem. We then show it is NP-hard and prove a sharp bound of replication factors (Section 2.2) for general graphs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Notation</head><formula xml:id="formula_0">Let G = (V ,E)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Problem Statement</head><p>A p-edge partitioning of G refers to a disjoint partitioning of its edge set E into p subsets E i , such that</p><formula xml:id="formula_1">E i ⊆ E, ∪ i ∈[p] E i = E,<label>and</label></formula><formula xml:id="formula_2">E i ∩ E j = ∅ for i j. A p-edge partitioning is α-balanced if max i ∈[p] {|E i |} ≤ ⌈ α |E | /p⌉.<label>(1)</label></formula><p>The replication factor <ref type="bibr" target="#b2">[3]</ref> of a partitioning is defined as</p><formula xml:id="formula_3">RF(E 1 , . . . ,E p ) := 1 |V | i ∈[p] |V (E i )|.<label>(2)</label></formula><p>Definition 1 (MIN-RF(p,α )). The MIN-RF(p,α ) problem is to find an α-balanced p-edge partitioning {E i } i ∈[p] to minimize the replication factor RF(E 1 , . . . ,E p ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">NP-Hardness</head><p>The p-edge partitioning problem has been proved to be NP-hard in <ref type="bibr" target="#b2">[3]</ref> when p grows with n = |V |. To our best knowledge, it has not been proved elsewhere that this problem is NP-hard when p is constant <ref type="foot" target="#foot_0">1</ref> . We fill this gap and give the following NP-hardness result (proof in Appendix A). Theorem 2.1. For any α ≥ 1, p ≥ 2, the MIN-RF(p,α ) problem is NP-hard with respect to the number of vertices. In particular, the MIN-RF(2,α ) problem is NP-hard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Bound for General Graphs</head><p>In this section, we show that it is always possible to achieve O ( √ p) </p><formula xml:id="formula_4">m/k • t l ≥ m • t − 2 l − 2 , which is equivalent to t (t −1) /l (l −1) ≥ k. However, l &gt; t/ √ k, which means t (t − 1) l (l − 1) &lt; t − 1 l − 1 2 = k. □</formula><p>Given the claim, in G 0 = G, we can find a vertex set U 1 such that the number of edges induced by U 1 , i.e., the number of edges in</p><formula xml:id="formula_5">G 0 [U 1 ] is at least |E (G 0 )|/p. By the claim, we know |U 1 | ≤ n−1 √ p + 1.</formula><p>Then we remove |E (G 0 )|/p edges in G 0 [U 1 ] from G 0 , obtaining G 1 . By a similar argument, we can find a vertex set U 2 such that the number of edges induced by U 2 , i.e., the number of edges in</p><formula xml:id="formula_6">G 1 [U 2 ] is at least |E (G 1 )|/(p − 1) = |E (G)|/p. By the claim, we know |U 2 | ≤ n−1 √ p−1 + 1. Removing |E (G 1 )|/(p − 1) edges in G 1 [U 2 ]</formula><p>from G 1 , obtaining G 2 . Repeating this process, eventually we have obtained U 1 ,U 2 , . . . ,U p that exhaust all the edges in G, while</p><formula xml:id="formula_7">|U i | ≤ n − 1 p − (i − 1) + 1.</formula><p>Therefore the replication factor is 1≤i ≤p</p><formula xml:id="formula_8">|U i |/n ≤ 1 n 1≤i ≤p n − 1 p − (i − 1) + 1 ≤ 2 √ p + p n . □ Remark 1.</formula><p>For a graph, the lemma gives a 1-balanced p-partitioning, which is also a valid partitioning of MIN-RF(p,α ) problem for α ≥ 1. Lemma 2.3. There exists a graph such that the replication factor is at least p/2 (n − 1)/n = p/2(1 − o n (1)) for any 2-balanced partitioning.</p><p>The proof also generalizes to α-partitioning for any α ≥ 1.</p><p>Proof. Consider a complete graph on n vertices. After partitioning into p parts, we have the vertex sets being V 1 , . . . ,V p . Suppose |V i | = n i and the edges in the i-th machine is e i . Therefore</p><formula xml:id="formula_9">n i 2 ≥ e i , which means n i ≥ √ 2e i . We know p i=1 e i = n</formula><p>2 and e i ≤ 2 n 2 /p by the definition of 2-balancedness. Therefore</p><formula xml:id="formula_10">p i=1 n i ≥ p i=1 √ 2e i ≥ p/2 • 2 • 2 n 2 /p = p/2 n(n − 1),</formula><p>where the last inequality is by Jensen inequality. Thus the replication factor is at least</p><formula xml:id="formula_11">1 n p i=1 n i ≥ 1 n p/2 n(n − 1) = p/2 (n − 1)/n. □</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ALGORITHM</head><p>In this section, we propose a new edge partitioning algorithm, which partitions the graph iteratively in p rounds. In each round, one edge set is generated (for one machine). Specifically, in round i, edge set E i is selected from the working graph G i containing all un-assigned edges so far, i.e.,</p><formula xml:id="formula_12">G i = (V ,E \ ∪ j &lt;i E j ). Empty initially, E i is expanded in steps until |E i | &gt; αm /p.</formula><p>In each step, one vertex x is selected according to a neighbor expansion heuristic discussed below. Then, adjacent edges of x are added to E i , and x is added to core set C. Boundary set S = V (E i ) is the vertex set covered by E i . Since edges covered by S are not necessarily in E i , we also add those edges to E i without increasing vertex replication. The above step is repeated until |E i | &gt; αm /p. We now elaborate the heuristic to select the core vertex x.</p><p>Neighbor Expansion. By construction the core set C is always contained in the boundary set S. In case S \ C = ∅, x is picked randomly from V \ C. Otherwise, it is selected as follows,</p><formula xml:id="formula_13">x := arg min v ∈S \C |N (v) \ S |.</formula><p>The objective |N (v) \ S | is the number of vertices that will be assigned to machine i, if v is selected as core vertex and its adjacent edges are added to E i . Our heuristic is to select x to minimize the number of vertices to be added to the boundary set S, thereby to minimize the increment of replication factor due to adjacent edges of x.</p><p>Example. We illustrate one step of our algorithm in Fig. <ref type="figure" target="#fig_2">2</ref>. The left and right figures stand for the graph before and after this step. Allocated edges are denoted in solid line and edges in dashed line have not been allocated yet. At the beginning, there are 2 vertices in the core set C, 4 vertices in the boundary set S, and there are 4 allocated edges. Now we need to choose the next core vertex to expand the core set C. Among the candidates S \ C = {x,z}, vertex</p><formula xml:id="formula_14">x is selected because |N (x ) \ S | = 1 &lt; |N (z) \ S | = 3. Then, vertex</formula><p>x is added to C and S, and its neighbor y is added to S. Two edges e x,y and e y,z are allocated in this step.</p><p>We summarize our heuristic in Algorithm 1, where for ease of presentation the sub-routine of core set update and boundary set update is described in Algorithm 2. while</p><formula xml:id="formula_15">|E k | ≤ δ do 4: if S \ C = ∅ then 5:</formula><p>x is selected randomly in V \ C 6:</p><formula xml:id="formula_16">else 7: x ← arg min v ∈S \C |N (v) \ S | 8:</formula><p>AllocEdges(C,S,E k ,x)</p><p>Algorithm 2 Allocate edges for core vertex x.</p><formula xml:id="formula_17">1: procedure AllocEdges(C,S,E k ,x) 2: C ← C ∪ {x }, S ← S ∪ {x } 3:</formula><p>for y ∈ N (x ) \ S do for z ∈ N (y) ∩ S do</p><p>6:</p><formula xml:id="formula_18">E k ← E k ∪ {e y,z } 7: E ← E \ {e y,z } 8: if |E k | &gt; δ then return 4 ANALYSIS 4.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Upper bound of replication factor</head><p>We analyze the replication factor for Algorithm 1. Let S k = V (E k ) be the covered vertex set when the algorithm terminates for partition k. To the best of our knowledge, we are the first to provide a worstcase upper bound of replication factor on general graphs.</p><p>Theorem 4.1. Suppose G has no isolated vertex, and let E i 's be the edge sets produced by Algorithm 1 solving MIN-RF(p,α ) and</p><formula xml:id="formula_19">S i = V (E i ). Then, we have RF = 1 n i ∈[p] |S i | ≤ 1 n 3 2 |E| + 1 2 σ + p − 1 , (<label>3</label></formula><formula xml:id="formula_20">)</formula><p>where σ is the number of connected components in the original graph.</p><p>Remark 2. A trivial bound for the replication factor is</p><formula xml:id="formula_21">1 n i ∈[p] |S i | ≤ 2|E |</formula><p>n as each edge corresponds to 2 vertices. To our best knowledge, our bound is the first improvement for general graphs that brings down the constant from 2 to 3/2. Proof. Observe that Alg. 1 contains p rounds of iterations. In the i-th iteration, a new vertex in S i \ C i is added to the core C i and some edges are added to</p><formula xml:id="formula_22">E i until |E i | &gt; αm k . Recall S i = V (E i ).</formula><p>We analyze how these variables change as the number of steps t increase. We rename the variables and sets above in terms of t for convenience. Let s 0 = 0. At each step t ≥ 1, a new vertex is added to the core C s t . Thus 1 ≤ s t ≤ p. Let C i,t ,S i,t , and E i,t be the sets C i ,S i ,E i at the beginning of step t respectively. Let σ t be the number of connected components of G t = G \ p j=1 E j,t removing the isolated vertices. Let |G t | be the number of edges in G t .</p><p>We define a potential function</p><formula xml:id="formula_23">Φ t = 3 2 |G t | + 1 2 σ t + p − s t + i ∈[p] |S i,t |.</formula><p>Initially, all S i,0 = ∅. We will show that when the algorithm terminates at t = T , Φ T ≤ Φ 0 . We show this by showing (1) Φ 1 ≤ Φ 0 , and (2</p><formula xml:id="formula_24">) Φ t ≤ Φ t −1 or Φ t ≤ Φ t −2 . For simplicity, denote s t = i. Define the difference operator ∆ as ∆(•) = (•) t +1 − (•) t .</formula><p>In step t, a vertex x is added to C i,t ; then one of the four following cases happens. Let k be the number of x's adjacent edges added to E i,t , and let h be the number of non-adjacent edges of x added to E i,t . We analyze Φ t in each of the cases.</p><p>C1. When E i,t is full (i.e., the i-th machine is full); x is the first vertex added to S i+1,t +1 : Thus s t +1 = s t + 1. Counting x and k of its adjacent neighbor vertices, we have</p><formula xml:id="formula_25">∆|S i+1 | = k + 1.</formula><p>The total number of edges allocated is</p><formula xml:id="formula_26">∆|G | = −(k + h).</formula><p>However, ∆σ ≤ k + h as deleting each edge can increase the number of connected components by at most 1. Then we</p><formula xml:id="formula_27">have ∆Φ = 3 2 ∆|G | + 1 2 ∆σ − ∆s + ∆|S i+1 | ≤ − 3(k +h) 2 + k +h 2 − 1 + (1 + k ) = −h ≤ 0. (thus Φ 1 ≤ Φ 0 ). C2. When E i,t is not full; x ∈ S i,t \ C i,t . At the end of step t + 1,</formula><p>there are still edges in the same connected component as x in G t not assigned:</p><formula xml:id="formula_28">Similarly ∆|G | = −(k + h), ∆σ t ≤ k + h, and ∆|S i,t | = k. Hence, ∆Φ = 3 2 ∆|G | + 1 2 ∆σ + ∆|S i | ≤ − 3(k +h) 2 + k +h 2 + k = −h ≤ 0. C3. When E i,t is not full; x ∈ S i,t \ C i,t . At the end of step t + 1,</formula><p>all edges in the same connected component as x in G t are assigned to E i,t : We have</p><formula xml:id="formula_29">∆|G | = −(h + k ) and ∆|S i | = k.</formula><p>By assumption, this step removes fully in G t the connected component containing x, meaning ∆σ = −1. </p><formula xml:id="formula_30">Therefore ∆Φ = 3 2 ∆|G | + 1 2 ∆σ + ∆|S i | = − 3(k +h) 2 − 1 2 + k ≤ − k+1 2 ≤ 0. C4. When E i,t is not full but S i,t \C i,t = ∅.</formula><formula xml:id="formula_31">∆|S i | = k + 1.</formula><p>Note that Φ will not decrease in this step.</p><formula xml:id="formula_32">However, if take into consideration Φ t − Φ t −1 ≤ −(k ′ +1) 2 for k ′ ≥ 1, we have Φ t +1 − Φ t −1 = (Φ t +1 − Φ t ) + (Φ t − Φ t −1 ) ≤ −3(k +h) 2 + k +h 2 + 1 + k + −(k ′ +1) 2 ≤ 0.</formula><p>Moreover, right before Alg. 1 terminates, we are in Case 3. Therefore</p><formula xml:id="formula_33">Φ T − Φ T −1 ≤ −(k +1) 2 ≤ −1. Furthermore, since Φ T −1 ≤ Φ 0 , we have that Φ T ≤ Φ 0 − 1. In other words Φ 0 = 3 2 |G 0 | + 1 2 σ + p ≥ Φ end + 1 = i ∈[p] |S i | + 1, which finishes the proof. □</formula><p>We construct the following example, showing that the analysis for Algorithm 1 (Theorem 4.1) is tight. Example. In this example, our algorithm is required to partition the edges (in Fig. <ref type="figure" target="#fig_4">3</ref>) into four parts. In the worst case, the edge set E 1 can be selected as the green edges, by first including the two green edges in the first line and then the middle edge in the second line. Similarly, E 2 ,E 3 ,E 4 may be partitioned as the blue, brown, and red edges respectively. In this case, |E| = 12,σ = 6,p = 4, while</p><formula xml:id="formula_34">|S green | = |S blue | = |S red | = |S brown | = 6. Hence i |S i | = 24 = 3 2 • 12 + 1 2 • 6 + 4 − 1 = 3 2 |E| + 1 2 σ + p − 1,</formula><p>which achieves equality in Theorem 4.1. This example can be easily extended to any p. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Upper bound for random power-law graphs</head><p>Prior to this work, DBH <ref type="bibr" target="#b16">[17]</ref> and HDRF <ref type="bibr" target="#b14">[15]</ref> give upper bounds of expected replication factor of their graph edge partitioners for random power-law graphs. In this section, we apply Theorem 4.1 to give an improved numerical upper bound of replication factor for a "typical" random power-law graph, and compare our upper bound with the existing ones in literature.</p><p>Power-law graphs specify the degree distribution in the way that the fraction of k-degree vertices p k is proportional to k −τ e −k /κ , where τ and κ are constants. τ &gt; 2 controls the skewness of the distribution, and κ gives a soft upper bound of the vertex degree, i.e., p k decreases exponentially when k ≥ κ.</p><p>To apply Theorem 4.1, we need to estimate the expectation of |E | /n and σ /n. Here we apply the elegant treatment of random power-law graphs by Newman <ref type="bibr" target="#b13">[14]</ref> using generating functions, and derive the expected number of connected components and the expected number of edges. Recall that a generating function carries a sequence of numbers as coefficients of a series expansion. The following is a generating function that carries the degree distribution,</p><formula xml:id="formula_35">G 0 (x ) = ∞ k =1 p k x k ,</formula><p>where p k = Ck −τ e −k /κ , with C being a normalization constant so that G 0 (1) = 1.</p><formula xml:id="formula_36">Computing E [ |E | /n]. We can calculate the expectation of |E | /n as E |E | n = 1 /2 k ≥1 kp k = /2G ′ 0 (1). Computing E [ σ /n]. We now estimate the term E[ σ /n]. When τ &gt; 2,</formula><p>it is almost sure that the graph is not fully connected <ref type="bibr" target="#b13">[14]</ref>; when 2 &lt; τ &lt; 3.4785 and κ → ∞, besides small connected components the graph contains a giant component of constant fraction of vertices <ref type="bibr" target="#b0">[1]</ref>. To give a quantitative argument, we define the following terms. If we pick an edge and go to one of its end vertices uniformly at random, then the probability qk that the end vertex has degree k is proportional to kp k . Let q k = qk+1 be the probability that the end vertex has outgoing degree k, not counting the edge we come from. This sequence q k is expressed in the following generating function</p><formula xml:id="formula_37">G 1 (x ) = ∞ k=0 q k x k = ∞ k =1 qk x k −1 = ∞ k =1 kp k x k −1 ∞ k =1 kp k = G ′ 0 (x ) G ′ 0<label>(1)</label></formula><p>, where the last two steps normalize the sequence so that G 1 (1) = 1.</p><p>We study the size of a component reached by choosing a random edge and following it to one of its ends. Let H 1 (x ) be the generating function for the component size distribution, excluding the giant one, i.e., H 1 (x ) = a • 0 + t k x k , where a is the probability that this edge leads to the giant component, and t k is the probability that this edge leads to a small component of size k. Here we follow Newman's assumption <ref type="bibr" target="#b13">[14]</ref> that there is no loop in the small components.</p><p>Hence we have</p><formula xml:id="formula_38">H 1 (x ) = a • 0 + xq 0 + xq 1 H 1 (x ) + xq 2 [H 1 (x )] 2 + . . . ,</formula><p>and thus</p><formula xml:id="formula_39">H 1 (x ) = xG 1 (H 1 (x )).<label>(4)</label></formula><p>Combining H 1 (1) + a = 1 and H 1 (1) = G 1 (H 1 (1)) we can solve G 1 (1 − a) = 1 − a for a ∈ (0, 1). Knowing a, we can approximate H 1 (x ) by solving Equation 4 numerically for the first few hundred terms. Similarly, if we start with a randomly chosen vertex, the size of the small component reached by this vertex is encoded by the generating function</p><formula xml:id="formula_40">H 0 (x ) = xG 0 (H 1 (x )) = ∞ k =2 h k x k .</formula><p>The term E[ σ /n] can be expressed as</p><formula xml:id="formula_41">E σ n = 1 n + k ≥2 h k k ,</formula><p>where the first term 1 /n stands for the giant component. As we can numerically compute the first few hundred coefficients of H 1 (x ), we can numerically compute the coefficients for H 0 (x ), which are the h k 's.</p><p>Expected Upper Bound. Plugging E [ σ /n] and E [ |E | /n] into the bound in Theorem 4.1, we obtain an upper bound of expected replication factor for a random power-law graph.</p><p>Comparison with Existing Bounds. Let us compare our theoretical bounds with the ones in literature. Prior to ours, DBH <ref type="bibr" target="#b16">[17]</ref> and HDRF <ref type="bibr" target="#b14">[15]</ref> give upper bounds of expected replication factor for random power-law graphs. In HDRF <ref type="bibr" target="#b14">[15]</ref>, an average-case analysis is applied to their streaming method to give a bound for powerlaw graphs. In DBH <ref type="bibr" target="#b16">[17]</ref>, an upper bound on expected replication factor is derived for their randomized algorithm. However, they only study the case when κ → ∞. To apply these bounds, we let κ = ∞, and consider the graph n = 10 6 , i.e. set p k = 0 for k &gt; 10 6 .</p><p>The results in Fig. <ref type="figure" target="#fig_5">4</ref> indicate that our upper bound is consistently lower than theirs for τ ∈ (2, 3) with a wide margin. We also plot the general bound derived in Lemma 2.2. As expected, it is worse than the bound we derived in this section that relies on special properties of random power-law graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTAL RESULTS</head><p>In this section, we evaluate our neighbor expansion (NE) algorithm and compare it against other state-of-the-art partitioners.</p><p>To evaluate a partitioner, we consider the following metrics: workload balance, replication factor, and time consumption. For workload balance, we ensure results of each partitioner are 1.1-balanced and do not report the detailed values. We compare the replication factor and running time in Section 5.1. Since one important application of edge-partitioning algorithms is to partition graphs for distributed graph processing systems, we also evaluate whether the given partitioner can reduce the communication cost and execution time on distributed graph processing systems like PowerGraph <ref type="bibr" target="#b5">[6]</ref> and PowerLyra <ref type="bibr" target="#b3">[4]</ref> in Section 5.2.</p><p>Testbed. We evaluate all partitioners and run graph analytic applications (Section 5.2) on a cluster of nine machines, each with 24 Intel E5-2620 2.40 GHz cores and 125 GB RAM connected via Gigabit Ethernet.</p><p>Datasets. Five real-world benchmark graphs of various scales are used for our evaluation. Most of the graphs can be found in SNAP <ref type="bibr" target="#b9">[10]</ref>. The statistics of the graphs are listed in Table <ref type="table" target="#tab_2">1</ref>.</p><p>Competing partitioners. We compare our NE algorithm with six existing edge partitioners, including METIS <ref type="bibr" target="#b7">[8]</ref>, RAND <ref type="bibr" target="#b5">[6]</ref>, DBH <ref type="bibr" target="#b16">[17]</ref>, Oblivious <ref type="bibr" target="#b5">[6]</ref>, HDRF <ref type="bibr" target="#b14">[15]</ref>, and Sheep <ref type="bibr" target="#b12">[13]</ref>. METIS is the state-of-the-art method for vertex partitioning which minimizes edge cut and balances user-defined vertex weight. One can turn a vertex-partitioner into an edge-partitioner while preserving its performance <ref type="bibr" target="#b2">[3]</ref>. To transform METIS to an edge-partitioner, we first call METIS with the vertex weight equal to its degree. Then based on the vertex partitioning produced by METIS, each edge is randomly assigned to one of its adjacent vertices' partition. For Oblivious and HDRF, following <ref type="bibr" target="#b14">[15]</ref>, we feed the edges in a random order, to balance the resulting partitions.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiments on real-world graphs</head><p>In this section, we compare the performance of partitioners on real-world graphs.</p><p>Replication factor. As shown in Table <ref type="table" target="#tab_3">2</ref>, our NE algorithm<ref type="foot" target="#foot_1">2</ref> outperforms all existing methods with large margins. Among existing partitioners, METIS gives the lowest replication factor which is consistent with literature <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b12">13]</ref>. However, METIS runs out of memory when partitioning the Twitter, Friendster and UK-union graphs on our 125 GB RAM machine. This result also echoes the fact reported by <ref type="bibr" target="#b12">[13]</ref>.</p><p>Running time. Fig. <ref type="figure" target="#fig_6">5</ref> plots the running time of all partitioners for a variety of input graphs. As expected, DBH is the fastest since they only scan the input graph once. We did not report the running time of RAND, Oblivious and HDRF since they are integrated in PowerGraph and we cannot get the standalone running time. But their performance should be similar to DBH since they all scan the input graph once sequentially <ref type="bibr" target="#b16">[17]</ref>. Using only a single thread, NE and Sheep <ref type="bibr" target="#b12">[13]</ref> have similar running time. But Sheep can be speeded up significantly by multi-threading, which is not directly applicable to NE due to the difference in memory access pattern. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experiments on graph analytics</head><p>Table <ref type="table" target="#tab_4">3</ref> compares our NE algorithm against two partitioners, RAND and Oblivious, in PowerGraph and one partitioner, Hybrid_Ginger, in PowerLyra, in terms of replication factor, communication cost, and execution time for running the PageRank (100 iterations) and triangle counting applications on a cluster of nine machines. Each result reported in Table <ref type="table" target="#tab_4">3</ref> is an average of three runs to ensure that their relative standard error is less than 5%. We observe that the communication cost is closely related to the replication factor, roughly as a linear function. This is not surprising because replication factor is designed to model the communication cost. Our NE algorithm optimizes the replication factor and successfully reduces the communication cost for all cases.</p><p>Running time depends on replication factor in a similar pattern. For most cases, a reduction of replication factor (hence the communication cost) means a reduction in running time. The only exception is the triangle counting application on Twitter graph. In this case, comparing the NE and the Oblivious methods, we find that a reduction of replication factor dose not reduce the running time. Based on our understanding of the PowerGraph system, this may be explained by several factors. One factor is that, in Pow-erGraph, the computation and network communication happen concurrently, so the reduction of the communication cost can only reduce the running time when the network communication is the bottleneck of the whole system. Another factor is the potential unbalanced computation workload on each machine. For each vertex with multiple replicas in PowerGraph, one replica is nominated as the master, while others are mirrors. The computation in Power-Graph is conducted on each edge and each master replica. Since our algorithm only guarantees the edge partitioning is balanced, the unbalanced allocation of master replicas may cause congestion on some machines.</p><p>In conclusion, compared with other existing methods, our partitioner NE successfully reduces the communication cost for all graphs and reduces the running time for most graphs. In average<ref type="foot" target="#foot_2">3</ref> NE reduces replication factor, communication, and running time by 54%, 66%, and 21%, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND FUTURE WORK</head><p>In this paper, we proposed a new graph edge partitioner Neighbor Expansion (NE) that outperforms other state-of-the-art ones including METIS <ref type="bibr" target="#b7">[8]</ref> and Sheep <ref type="bibr" target="#b12">[13]</ref> in terms of replication factors. Applying the NE algorithm to distributed graph mining effectively reduces communication cost and running time for applications such as PageRank and triangle counting.</p><p>Our algorithm can be further improved in several aspects. Firstly, it will be very interesting if any theoretical approximation results can be proved for the NE algorithm, to explain its good performance in the experiments. Secondly, we might need new data structures to support the NE heuristic in a distributed, multi-thread environment. Thirdly, the NE algorithm needs to load the whole graph edge set in main memory, while other methods like Sheep or DBH only store vertex set. For instance, our implementation of NE takes about 90 GB RAM to partition uk-union <ref type="bibr" target="#b1">[2]</ref>. We have made some preliminary attempts to extend the NE algorithm to a streaming algorithm via sampling methods (Appendix B), which is able to partition the clueweb graph <ref type="bibr" target="#b1">[2]</ref> (|V | = 978M, |E| = 42.5B) whose edge set exceeds the volume of main memory.</p><p>Since x +y + s = k we know x + 2y ≤ 2(k − s). Also e (U )</p><formula xml:id="formula_42">≤ |U | 2 = s 2 . Therefore (5) satisfies |E (V 1 ) ∪ E (V 1 ,S )| ≥|W | + n 2 − s 2 + 2 e (G) − s 2 − 2(k − s) ≥|W | + n 2 − k 2 + 2 e (G) − k 2 (6) =e (H ) − 3 k 2 . (<label>7</label></formula><formula xml:id="formula_43">)</formula><p>The second to last inequality holds because to minimize the expression over 0 ≤ s ≤ k we should choose s = k for k ≥ 2 by simple computation. The last equality holds because e (H ) = |W | + n 2 + 2e (G). However, by our choice of |W |, we have that</p><formula xml:id="formula_44">(1 − β )e (H ) = |W | + 3 k 2 .</formula><p>Thus e (H ) − 3 k 2 &gt; βe (H ). However, if this is the case, then <ref type="bibr" target="#b6">(7)</ref> </p><formula xml:id="formula_45">tells us that |E (V 1 ) ∪ E (V 1 ,S )| &gt; βe (H ). This is a contradiction.</formula><p>Therefore v 1 ∈ S. Suppose the separator of size k consists of s vertices U ⊆ {v 1 ,v 2 , . . . ,v n } and v 1 ∈ U , x vertices X in W , and y vertices Y in {u i j }. Suppose v ∈ {v 1 ,v 2 , . . . ,v n } \ {v 1 }. Then similarly, by the construction, we know that v is connected to all the vertices in {v 1 ,v 2 , . . . ,v n } \ U , and it is connected to all the vertices in i,jnot all in U {u i j }. Since V 1 ,V 2 are not connected to each other, we know all the neighbors of v excluding S should be in V 1 . Therefore the edges we are certain to be in</p><formula xml:id="formula_46">E (V 1 ) ∪ E (V 1 ,S ) include the n 2 − s 2 edges within {v 1 ,v 2 , .</formula><p>. . ,v n } excluding the edges within U , and the edges coming out from u i j with v i ,v j not both in U and not including the edges coming from vertices in X . The latter case consists of 2(e (G) − e (U )) − 2y edges. Thus we have</p><formula xml:id="formula_47">|E (V 1 ) ∪ E (V 1 ,S )| ≥ n 2 − s 2 + 2(e (G) − e (U )) − 2y ≥ n 2 − s 2 + 2(e (G) − e (U )) − 2(k − s)</formula><p>where the last inequality holds because x + y + s = k and thus</p><formula xml:id="formula_48">−2y ≥ −2(k − s). If 1 ≤ s ≤ k − 1, we know |E (V 1 ) ∪ E (V 1 ,S )| ≥ n 2 − s 2 + 2(e (G) − e (U )) − 2(k − s) ≥ n 2 − s 2 + 2 e (G) − s 2 − 2(k − s) ≥ n 2 − k − 1 2 + 2 e (G) − k − 1 2 − 2,</formula><p>where the last inequality is by optimizing the quadratic in s. However, n</p><formula xml:id="formula_49">− k − 1 2 + 2 e (G) − k − 1 2 − 2 &gt;βe (H ) = n 2 − k 2 + 2 e (G) − k 2 .<label>2</label></formula><p>Thus we have that s = k. Thus we must have</p><formula xml:id="formula_50">βe (H ) = n 2 − k 2 + 2 e (G) − k 2 (8) ≥|E (V 1 ) ∪ E (V 1 ,S )| (9) ≥ n 2 − k 2 + 2(e (G) − e (U )).<label>(10)</label></formula><p>This means that U must be a clique of size k and it contains v 1 . In total, we need to scan through the edge list<ref type="foot" target="#foot_3">4</ref> from the hard disk twice. In the first scan, we randomly shuffle the edge list, and record the number of vertices, the number of edges, and the degree of each vertex. In the second scan, we stream in the edges one by one from the shuffled edge list, and maintain CacheSize number of edges in memory. The value of CacheSize is determined mostly by the memory budget. In general the larger of CacheSize the better the partitioning quality. In practice, we find that CacheSize = 2×|V | produces balanced partitions of good replication factor.</p><p>Like Alg. 1, the streaming algorithm produces edge partition for each machine in turn. In round i, it constructs the working graph consisting of the sampled edges (denoted as Ê), and then applies Alg. 1 to allocate a | Ê | /p−i+1 fraction of edges for machine i. The allocated edges E i are immediately stored to the hard disk, while the core set C i and the boundary set S i are stored in the main memory for partitioning the unallocated edges.</p><p>Prior to round i, the CheckEdge procedure (Alg. 4) is used to add extra unallocated edges to the edge set E j for |E j | ≤ αm /p and j &lt; i. The reason is that by the time E j is established, the sampled edge set Ê does not contain the full information of the graph and E j has fewer edges than expected. The edges allocated to E j is based on its core set C j and boundary set S j . The CheckEdge procedure is applied to the current sampled edge set Ê, and also the edges to be loaded into memory. An edge e = {x,y} is allocated to E j if one of the following two conditions is true.</p><p>(1) if e is covered by S j , i.e., e ⊆ S j , or (2) if e is touched by C j , i.e., |e ∩ C j | = 1, and the degree of each adjacent vertex is less than the average degree of the original graph, i.e., max{d x ,d y } ≤ 2m /n. (In this case, when edge e is added to E j the boundary set S j is augmented as S j ← S j ∪ e.)</p><p>Algorithm 3 Partitioning via sampling. if e ⊆ S j then</p><p>6:</p><p>E j ← E j ∪ {e} Experiments. We compare the replication factor of NE and the streaming algorithm (Alg. 3) in Table <ref type="table" target="#tab_7">4</ref>. To evaluate the scalability of the streaming we add a new graph clue-web <ref type="bibr" target="#b1">[2]</ref> of 978, 408, 098 vertices and 42, 574, 107, 469 edges. Comparing with NE, the streaming algorithm enables us to process much larger graphs with some compromise on replication factor. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Vertex vs edge partitioning. (a) Ideal vertex partitioning cuts two edges; (b) Ideal edge partitioning cuts only one vertex, Replication Factor=1.14 (solid edges for one partition, dashed edges for the other); (c) Worst edge partitioning, Replication Factor=2.</figDesc><graphic url="image-2.png" coords="1,410.72,216.04,54.72,88.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>be an undirected, unweighted graph with n = |V | vertices and m = |E| edges. An edge connecting vertices x and y is denoted as (x,y) or e x,y . For a vertex x, denote by N (x ) = {y|(x,y) ∈ E} the set of vertices adjacent to x. For a vertex set S, denote by N (S ) = ∪ x ∈S N (x ) and E S = {(x,y) ∈ E : x,y ∈ S }. For an integer p ≥ 2, denote by [p] = {1, 2, . . . ,p}. For an edge set E i , denote V (E i ) = {x |{x,y} ∈ E i } as the set of vertices covered by E i .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Illustrating a step in our algorithm. Left: a core vertex x is selected. Right: the core vertex set C, the boundary vertex set S, and the edge set E i are updated.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Bound in Theorem 4.1 is tight.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Theoretical bounds of NE, DBH, HDRF and the bound (Lemma 2.2) for general graphs (p = 30).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Running time of different partitioning methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Note that Alg. 3 needs to maintain and work on an edge set of size | Ê| = CacheSize, while the NE algorithm works on the whole edge set of size |E|. Both algorithms need to store the core set C i and boundary set S i in memory for all the p machines. They also need to maintain the vertex degree d x in memory. So the total memory consumptions of the NE algorithm and the streaming algorithm are O (|E| + p|V |) and O (CacheSize + p|V |), respectively. Given that CacheSize = O (|V |) and p = O (1), we show that, by running our NE algorithm on a sampled graph, we can reduce the memory consumption from O (|E| + |V |) to O (|V |). Next, we use the experiments to study the partitioning quality of our streaming algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Real-world graphs.</figDesc><table><row><cell>Graph</cell><cell>Alias</cell><cell>|V |</cell><cell>|E|</cell></row><row><cell cols="2">com-LiveJournal LJ</cell><cell>3,997,962</cell><cell>34,681,189</cell></row><row><cell>com-Orkut</cell><cell>Orkut</cell><cell>3,072,441</cell><cell>117,185,083</cell></row><row><cell>Twitter [9]</cell><cell>TW</cell><cell cols="2">41,652,230 1,468,364,884</cell></row><row><cell>com-Friendster</cell><cell>FS</cell><cell cols="2">65,608,366 1,806,067,135</cell></row><row><cell>uk-union [2]</cell><cell>UK</cell><cell cols="2">133,633,040 5,507,679,822</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Replication factors for real-world graphs (p = 30, α = 1.1).</figDesc><table><row><cell></cell><cell></cell><cell>LJ</cell><cell cols="2">Orkut TW</cell><cell>FS</cell><cell>UK</cell></row><row><cell cols="2">METIS</cell><cell>2.16</cell><cell>5.24</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">RAND</cell><cell cols="5">8.27 19.48 11.68 11.84 15.99</cell></row><row><cell cols="2">DBH</cell><cell cols="2">5.18 11.97</cell><cell>3.67</cell><cell>6.88</cell><cell>5.14</cell></row><row><cell cols="3">Oblivious 3.43</cell><cell>6.94</cell><cell>8.60</cell><cell>8.82</cell><cell>2.03</cell></row><row><cell cols="2">HDRF</cell><cell>3.33</cell><cell>7.27</cell><cell>7.90</cell><cell>8.87</cell><cell>1.62</cell></row><row><cell cols="2">Sheep</cell><cell>3.33</cell><cell>7.94</cell><cell>2.34</cell><cell>4.45</cell><cell>1.29</cell></row><row><cell>NE</cell><cell></cell><cell cols="2">1.55 2.48</cell><cell cols="3">1.88 1.98 1.04</cell></row><row><cell></cell><cell></cell><cell></cell><cell>DBH</cell><cell>Sheep</cell><cell>NE</cell><cell>METIS</cell></row><row><cell></cell><cell>10 4</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Running Time (s)</cell><cell>10 1 10 2 10 3</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>10 0</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>10 8</cell><cell cols="2">10 9</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>|V | + |E |</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Replication factor, network communication cost (GB), and running time (second) for distributed graph mining.</figDesc><table><row><cell></cell><cell></cell><cell cols="3">PowerGraph + RAND</cell><cell cols="6">PowerGraph + Oblivious PowerLyra + Hybrid_Ginger</cell><cell cols="3">PowerGraph + NE</cell></row><row><cell>Task</cell><cell>Graph</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">RF Comm.</cell><cell>Time</cell><cell cols="2">RF Comm.</cell><cell>Time</cell><cell cols="2">RF Comm.</cell><cell>Time</cell><cell cols="3">RF Comm. Time</cell></row><row><cell></cell><cell>LJ</cell><cell>4.81</cell><cell>40.51</cell><cell>101.07</cell><cell>3.25</cell><cell>26.37</cell><cell>80.77</cell><cell>2.98</cell><cell>12.24</cell><cell>43.12</cell><cell>1.35</cell><cell>3.65</cell><cell>39.23</cell></row><row><cell></cell><cell cols="2">Orkut 8.04</cell><cell>54.65</cell><cell>123.37</cell><cell>5.79</cell><cell>37.05</cell><cell>94.67</cell><cell>5.99</cell><cell>25.63</cell><cell>64.90</cell><cell>1.75</cell><cell>6.66</cell><cell>44.93</cell></row><row><cell>PageRank</cell><cell>TW</cell><cell cols="2">6.18 509.96</cell><cell>851.30</cell><cell cols="2">2.43 209.46</cell><cell>335.53</cell><cell cols="2">2.76 152.25</cell><cell>311.40</cell><cell cols="3">1.38 51.45 297.97</cell></row><row><cell></cell><cell>FS</cell><cell cols="5">5.39 768.33 1183.90 3.40 411.82</cell><cell>670.10</cell><cell cols="2">3.60 294.54</cell><cell>589.24</cell><cell cols="3">1.48 92.16 392.70</cell></row><row><cell></cell><cell>UK</cell><cell cols="5">6.89 1535.57 2582.93 1.86 540.48</cell><cell>764.10</cell><cell cols="2">2.12 386.41</cell><cell>759.26</cell><cell cols="3">1.02 55.89 554.77</cell></row><row><cell></cell><cell>LJ</cell><cell>4.81</cell><cell>4.10</cell><cell>3.90</cell><cell>3.25</cell><cell>3.05</cell><cell>3.01</cell><cell>2.99</cell><cell>3.76</cell><cell>3.02</cell><cell>1.35</cell><cell>0.88</cell><cell>1.39</cell></row><row><cell>Triangle Count</cell><cell cols="3">Orkut 8.04 TW 6.18 FS 5.39 128.12 9.24 91.63</cell><cell>9.93 154.73 138.05</cell><cell>5.79 2.43 3.40</cell><cell>7.59 56.52 99.22</cell><cell>8.08 119.97 111.82</cell><cell cols="2">6.02 2.74 3.60 152.69 11.69 97.77</cell><cell>10.41 188.36 234.71</cell><cell cols="2">1.75 1.38 30.45 2.53 1.48 41.29</cell><cell>4.36 154.91 84.18</cell></row><row><cell></cell><cell>UK</cell><cell cols="5">6.89 344.13 2166.17 1.86 157.32</cell><cell>185.54</cell><cell cols="2">2.13 299.49</cell><cell>1207.06</cell><cell cols="3">1.02 72.34 166.07</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Based on Alg. 1, we propose a streaming algorithm (Alg. 3) that considers the trade-off between the partitioning quality and memory consumption. This algorithm only requires O (|V |) memory, hence can process graphs whose edge set exceeds main memory. Our technique is to sample edges uniformly from the original graph, and then run Alg. 1 on the sampled graph.</figDesc><table><row><cell cols="2">Therefore we reduce MAX-CLIQUE problem to MIN-β-separator</cell></row><row><cell cols="2">problem. Since MAX-CLIQUE problem is NP-hard, we have that</cell></row><row><cell>MIN-β-separator problem is NP-hard.</cell><cell>□</cell></row><row><cell>The claim is a direct consequence of the two lemmas.</cell><cell>□</cell></row><row><cell>B THE STREAMING ALGORITHM</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>1 :</head><label>1</label><figDesc>Randomly shuffle edge list, record n, m, d 2: Ê ← ∅, E ← shuffled edge list 3: for i ∈ [p] do C i ,S i ,E i ← Expand( Ê, | Ê | /p−i+1)Algorithm 4 Allocating edges for partitions.</figDesc><table><row><cell>4:</cell><cell>Ẽ ← Ê, Ê ← ∅</cell></row><row><cell>5:</cell><cell>for e ∈ Ẽ do</cell></row><row><cell>6:</cell><cell>Ê ← Ê ∪ CheckEdge(e,i)</cell></row><row><cell>7:</cell><cell>while | Ê| ≤ CacheSize AND E ∅ do</cell></row><row><cell>8:</cell><cell>pick next edge e ∈ E, E ← E \ {e}</cell></row><row><cell>9:</cell><cell>Ê ← Ê ∪ CheckEdge(e,i)</cell></row><row><cell>10:</cell><cell></cell></row><row><cell>11:</cell><cell>Ê ← Ê \ E i</cell></row><row><cell>12:</cell><cell>update d, remove degree due to E i</cell></row></table><note>1: procedure CheckEdge(e = {x,y},i)2: for j ∈ {1 ≤ t &lt; i : |E j | ≤ αm /p} do 3: if e ∩ C j ∅ AND max{d x ,d y } ≤ 2m /n then 4:S j ← S j ∪ e 5:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Replication factors (p = 30,α = 1.1).</figDesc><table><row><cell></cell><cell cols="3">LJ Orkut TW FS</cell><cell>UK</cell><cell>clue-web</cell></row><row><cell>NE</cell><cell>1.55</cell><cell>2.48</cell><cell cols="2">1.88 1.98 1.04 Out of memory</cell></row><row><cell cols="2">Alg. 3 1.88</cell><cell>4.49</cell><cell cols="2">2.83 3.00 1.65</cell><cell>1.94</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">In<ref type="bibr" target="#b2">[3]</ref>, the NP-hardness is proved by a reduction from 3-partition problem. When p is constant, the 3-partition problem, hence the derived edge partitioning problem, is polynomial time solvable.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">Since there is randomness in the NE algorithm, we report the average replication factor, with relative standard error less than 1%.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">We report the average decrease of ten cases (five from PageRank and five from triangle counting). Each decrease is calculated as (y−x ) /y, where x is the value of NE and y is the lowest value of existing methods.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">We assume the graph is stored in edge list format. Each line represents an edge as a pair of vertex IDs.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Theorem A.1. For any α ≥ 1, MIN-RF(p,α ) problem is NP-hard with respect to n. In particular, we show that MIN-RF(2,α ) problem is NP-hard.</p><p>Proof. We claim that MIN-RF(2,α ) problem is equivalent to the following MIN-β-separator problem which we will prove to be NP-hard. Definition 2 (MIN-β-separator problem). Given a graph G = (V ,E), a β-separator is a vertex subset S such that V (G) \ S can be partitioned into two vertex sets W 1 ,W 2 such that W 1 ,W 2 are disconnected from each other and e (W i ) + e (W i ,S ) ≤ ⌈βe (G)⌉ for i = 1, 2. The MIN-β-separator problem is to find the smallest β-separator S.</p><p>1 ,E * 2 } be the optimal solution to the MIN-RF(2,α ) problem. Let S * be the optimal solution to the MIN-β-separator problem with β = α /2. We show that</p><p>, and this will infer that two problems are equivalent.</p><p>Given Proof. The proof is motivated by <ref type="bibr" target="#b4">[5]</ref> which proves that a vertex constraint MIN-separator problem is NP-hard. To the best of our knowledge, our work here is the first focusing on the edge constraint of separator and showing that MIN-β-separator problem is NP-hard.</p><p>We reduce MAX-CLIQUE problem to MIN-β-separator problem. Given a graph G on n vertices v 1 , . . . ,v n , we show that checking whether there is a clique in G containing a fixed v 1 with size k can be reduced to our problem of checking whether there is a separator of size k that satisfies the edge β-separator constraint. (Notice that there are at most n choices of v 1 and at most n choices of k).</p><p>We create an auxiliary graph</p><p>Let the vertex set of H be {v 1 , . . . ,v n } ∪ v i ∼v j u i j ∪W , where u i j are newly created vertices corresponding to each un-ordered pair i, j with v i ,v j adjacent in G.</p><p>The edges in H are as follows. Within {v 1 , . . . ,v n } all edges are connected (thus it is a clique on n vertices). Vertex u i j is only connected to v i ,v j . There is a complete bipartite graph between W and v 1 while within W it is an independent set. Thus the number of edges in H is e (H ) = |W | + n 2 + 2e (G). We show that finding the β-separator of size k containing v 1 in H is equivalent to finding a k-clique containing v 1 in G. Suppose V (H ) \ S can be partitioned into two connected components (each</p><p>Suppose the separator of size k consists of s vertices U ⊆ {v 2 , . . . ,v n }, x vertices X in W , and y vertices Y in {u i j }. By the construction, we know that v 1 is connected to all the vertices in {v 2 , . . . ,v n } \ U , and it is connected to all the vertices in i,j not all in U {u i j }. Since V 1 ,V 2 are not connected to each other, all the neighbors of v 1 excluding S should be in V 1 . Therefore the following edges are known to be in E (V 1 ) ∪ E (V 1 ,S ): the |W | − |X | edges from v 1 to W \ Y , the n 2 − s 2 edges within {v 1 ,v 2 , . . . ,v n } excluding the edges within U , and the edges coming out from u i j with v i ,v j not both in U and not including the edges coming from vertices in X . The latter case consists of 2(e (G) − e (U )) − 2y edges. Thus we have </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A random graph model for massive graphs</title>
		<author>
			<persName><forename type="first">William</forename><surname>Aiello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linyuan</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC</title>
				<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A large time-aware web graph</title>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Boldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Santini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastiano</forename><surname>Vigna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGIR Forum</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="33" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Balanced graph edge partition</title>
		<author>
			<persName><forename type="first">Florian</forename><surname>Bourse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Lelarge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milan</forename><surname>Vojnovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1456" to="1465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Powerlyra: Differentiated graph computation and partitioning on skewed graphs</title>
		<author>
			<persName><forename type="first">Rong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanzhe</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haibo</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth European Conference on Computer Systems</title>
				<meeting>the Tenth European Conference on Computer Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Finding small balanced separators</title>
		<author>
			<persName><forename type="first">Uriel</forename><surname>Feige</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Mahdian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC</title>
				<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="375" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Powergraph: Distributed graph-parallel computation on natural graphs</title>
		<author>
			<persName><forename type="first">Yucheng</forename><surname>Joseph E Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haijie</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danny</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Bickson</surname></persName>
		</author>
		<author>
			<persName><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="17" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Graphx: Graph processing in a distributed dataflow framework</title>
		<author>
			<persName><forename type="first">Reynold</forename><forename type="middle">S</forename><surname>Joseph E Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Crankshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ion</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="599" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A fast and high quality multilevel scheme for partitioning irregular graphs</title>
		<author>
			<persName><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vipin</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on scientific Computing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="359" to="392" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Haewoon</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changhyun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hosung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sue</forename><surname>Moon</surname></persName>
		</author>
		<title level="m">WWW</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="591" to="600" />
		</imprint>
	</monogr>
	<note>What is twitter</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrej</forename><surname>Krevl</surname></persName>
		</author>
		<title level="m">SNAP Datasets:Stanford large network dataset collection</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Distributed graphlab: a framework for machine learning and data mining in the cloud</title>
		<author>
			<persName><forename type="first">Yucheng</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danny</forename><surname>Bickson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">VLDB</biblScope>
			<biblScope unit="page" from="716" to="727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Pregel: a system for large-scale graph processing</title>
		<author>
			<persName><forename type="first">Grzegorz</forename><surname>Malewicz</surname></persName>
		</author>
		<author>
			<persName><surname>Matthew H Austern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Aart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">C</forename><surname>Bik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilan</forename><surname>Dehnert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naty</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grzegorz</forename><surname>Leiser</surname></persName>
		</author>
		<author>
			<persName><surname>Czajkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="135" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A scalable distributed graph partitioner</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Margo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margo</forename><surname>Seltzer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1478" to="1489" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Random graphs with arbitrary degree distributions and their applications</title>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">H</forename><surname>Mark Ej Newman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duncan</forename><forename type="middle">J</forename><surname>Strogatz</surname></persName>
		</author>
		<author>
			<persName><surname>Watts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review E</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">26118</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Hdrf: Stream-based partitioning for power-law graphs</title>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonardo</forename><surname>Querzoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khuzaima</forename><surname>Daudjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shahin</forename><surname>Kamali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giorgio</forename><surname>Iacoboni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="243" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Chaos: Scale-out graph processing from secondary storage</title>
		<author>
			<persName><forename type="first">Amitabha</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Bindschaedler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jasmina</forename><surname>Malicevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Willy</forename><surname>Zwaenepoel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SOSP</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="410" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Distributed power-law graph computing: Theoretical and empirical analysis</title>
		<author>
			<persName><forename type="first">Cong</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ling</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wu-Jun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihua</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1673" to="1681" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
