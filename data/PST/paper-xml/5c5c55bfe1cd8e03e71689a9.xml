<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Simple Convolutional Generative Network for Next Item Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-11-29">29 Nov 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Fajie</forename><surname>Yuan</surname></persName>
							<email>fajieyuan@tencent.com</email>
						</author>
						<author>
							<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
							<email>alexandros.karatzoglou@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Joemon</forename><forename type="middle">M</forename><surname>Jose</surname></persName>
							<email>joemon.jose@glasgow.ac.uk</email>
						</author>
						<author>
							<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
							<email>xiangnanhe@gmail.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<address>
									<settlement>Tencent Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Telefonica Research Barcelona</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Ioannis Arapakis Telefonica Research</orgName>
								<address>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">University of Glagow Glasgow</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">National University</orgName>
								<address>
									<country>Singapore Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Telefonica Research</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Simple Convolutional Generative Network for Next Item Recommendation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-11-29">29 Nov 2018</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3289600.3290975</idno>
					<idno type="arXiv">arXiv:1808.05163v4[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Convolutional Neural Networks (CNNs) have been recently introduced in the domain of session-based next item recommendation. An ordered collection of past items the user has interacted with in a session (or sequence) are embedded into a 2-dimensional latent matrix, and treated as an image. The convolution and pooling operations are then applied to the mapped item embeddings. In this paper, we first examine the typical session-based CNN recommender and show that both the generative model and network architecture are suboptimal when modeling long-range dependencies in the item sequence. To address the issues, we introduce a simple, but very effective generative model that is capable of learning high-level representation from both short-and long-range item dependencies. The network architecture of the proposed model is formed of a stack of holed convolutional layers, which can efficiently increase the receptive fields without relying on the pooling operation. Another contribution is the effective use of residual block structure in recommender systems, which can ease the optimization for much deeper networks. The proposed generative model attains state-of-the-art accuracy with less training time in the next item recommendation task. It accordingly can be used as a powerful recommendation baseline to beat in future, especially when there are long sequences of user feedback.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Leveraging sequences of user-item interactions (e.g., clicks or purchases) to improve real-world recommender systems has become increasingly popular in recent years. These sequences are automatically generated when users interact with online systems in sessions (e.g., shopping session, or music listening session). For example, users on Last.fm <ref type="foot" target="#foot_0">1</ref> or Weishi<ref type="foot" target="#foot_1">2</ref> typically enjoy a series of songs/videos during a certain time period without any interruptions, i.e., a listening or watching session. The set of music videos played in one session usually have strong correlations <ref type="bibr" target="#b5">[6]</ref>, e.g., sharing the same album, writer, or genre. Accordingly, a good recommender system is supposed to generate recommendations by taking advantage of these sequential patterns in the session.</p><p>A class of models often employed for these sequences of interactions are the Recurrent Neural Networks (RNNs). RNNs typically generate a softmax output where high probabilities represent the most relevant recommendations. While effective, these RNN-based models, such as <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">15]</ref>, depend on a hidden state of the entire past that cannot fully utilize parallel computation within a sequence <ref type="bibr" target="#b7">[8]</ref>. Thus their speed is limited in both training and evaluation.</p><p>By contrast, training CNNs does not depend on the computations of the previous time step and therefore allow parallelization over every element in a sequence. Inspired by the successful use of CNNs in image tasks, a newly proposed sequential recommender, referred to as Caser <ref type="bibr" target="#b28">[29]</ref>, abandoned RNN structures, proposing instead a convolutional sequence embedding model, and demonstrated that this CNN-based recommender is able to achieve comparable or superior performance to the popular RNN model in the top-N sequential recommendation task. The basic idea of the convolution processing is to treat the t × k embedding matrix as the "image" of the previous t interactions in k dimensional latent space and regard the sequential pattens as local features of the "image". A max pooling operation that only preserves the maximum value of the convolutional layer is performed to increase the receptive field, as well as dealing with the varying length of input sequences. Fig. <ref type="figure" target="#fig_0">1</ref> depicts the key architecture of Caser. Considering the training speed of networks, in this paper we follow the path of sequential convolution techniques for the next item recommendation task. We show that the typical network architecture used in Caser has several obvious drawbacks -e.g.,: <ref type="bibr" target="#b0">(1)</ref> the max pooling scheme that is safely used in computer vision may discard important position and recurrent signals when modeling long-range sequence data; (2) generating the softmax distribution only for the desired item fails to effectively use the compete set of dependencies. Both drawbacks become more severe as the length of the sessions and sequences increases. To address these issues, we introduce a simple but fundamentally different CNN-based sequential recommendation model that allows us to model the complex conditional distributions even in very long-range item sequences. To be more specific, first our generative model is designed to explicitly encode item inter-dependencies, which allows to directly estimates the distribution of the output sequence (rather than the desired item) over the raw item sequence. Second, instead of using inefficient huge filters, we stack the 1D dilated convolutional layers <ref type="bibr" target="#b30">[31]</ref> on top of each other to increase the receptive fields when modeling long-range dependencies. The pooling layer can be safely removed in the proposed network structure. It is worth noting that although the dilated convolution was invented for dense prediction in image generation tasks <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b30">31]</ref>, and has been applied in other fields (e.g., acoustic <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b25">26]</ref> and translation <ref type="bibr" target="#b17">[18]</ref> tasks), it is yet unexplored in recommender systems with huge sparse data. Furthermore, to ease the optimization of the deep generative architecture, we propose using residual network to wrap convolutional layer(s) by residual block. To the best of our knowledge, this is also the first work in terms of adopting residual learning to model the recommendation task. The combination of these choices enables us to tackle largescale problems and attain state-of-the-art results in both short-and long-range sequential recommendation data sets. In summary, our main contributions include a novel recommendation generative model (Section 3.1) and a fundamentally different convolutional network architecture (Sections 3.2 ∼ 3.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARIES</head><p>First, the problem of recommending items from sequences is described. Next, a recent convolutional sequence embedding recommendation model (Caser) is shortly recapitulated along with its limitations. Lastly, we review previous work on sequence-based recommender systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Top-N Session-based Recommendation</head><p>Let {x 0 , x 1 , ..., x t −1 , x t } (interchangeably denoted by x 0:t ) be an user-item interaction sequence (or a session), where x i ∈ R (0 ≤ i ≤ t) is the index of the clicked item out of a total number of t + 1 items in the sequence. The goal of sequential recommendation is to seek a model such that for a given prefix item sequence, x = {x 0 , ..., x i } (0 ≤ i &lt; t), it generates a ranking or classification distribution y for all candidate items, where y = [y 1 , ..., y n ] ∈ R n . y j can be a score, probability or a rank of item i + 1 that will occur in this sequence. In practice, we typically make more than one recommendation by choosing the top-N items from y, referred to as the top-N sessionbased (sequential) recommendations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Limitations of Caser</head><p>The basic idea of Caser is to embed the previous t items as a t × k matrix E by the embedding look-up operation, as shown in Fig. <ref type="figure" target="#fig_0">1 (a)</ref>. Each row vector of the matrix corresponds to the latent features of one item. The embedding matrix can be regarded as the "image" of the t items in the k-dimensional latent space. Intuitively, models of various CNNs that are successfully applied in computer vision can be adapted to model the "image" of an item sequence. However, there are two aspects that differentiate sequence modeling from image processing, which makes the use of CNN based models non-straightforward. First, the variable-length item sequences in real-world scenarios produce a large number of "images" of different sizes, where traditional convolutional structures with fix-sized filters may fail. Second, the most effective filters for images, such as 3 × 3 and 5 × 5, are not suitable for sequence "images" since these small filters (in terms of row-wise orientation) are not suitable to capture the representations of full-width embedding vectors.</p><p>To address the above limitations, filters in Caser slide over full columns of the sequence "image" by large filter. That is, the width of filters is usually the same as the width of the input "images". The height typically varies by sliding windows over 2 − 5 items at a time (Fig. <ref type="figure" target="#fig_0">1 (a)</ref>). Filters of different sizes will generate variable-length feature maps after convolution (Fig. <ref type="figure" target="#fig_0">1 (b)</ref>). To ensure that all maps have the same size, the max pooling is performed over each map, which selects only the largest number of each feature map, resulting in a 1 × 1 map (Fig. <ref type="figure" target="#fig_0">1 (c)</ref>). Finally, these 1 × 1 maps from all filters are concatenated to form a feature vector, followed by a softmax layer that yields the probabilities of next item (Fig. <ref type="figure" target="#fig_0">1 (d)</ref>). Note that we have omitted the vertical convolution in Fig. <ref type="figure" target="#fig_0">1</ref>, since it does not solve the major problems discussed below.</p><p>Based on the above analysis of the convolutions in Caser, one may find that there exist several drawbacks with the current design. First, the max pooling operator has obvious disadvantages. It cannot distinguish whether an important feature in the map occurs just one or multiple times and it ignores the position in which it occurs. The max pooling operator while safely used in image processing (with small pooling filters, e.g., 3 × 3) may be harmful for modeling long-range sequences (with large filters, e.g., 1 × 20). Second, the shallow network structure in Caser that suits for only one hidden convolutional layer is likely to fail when modeling complex relations or long-range dependences. The last important disadvantage comes from the generative process of next item, which we will describe in detail in Section 3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Related Work</head><p>Early work in sequential recommendations mostly rely on the markov chain <ref type="bibr" target="#b4">[5]</ref> and feature-based matrix factorization <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref> approaches. Compared with neural network models, the markov chain based approaches fail to model complicated relations in the sequence data. For example, in Caser, the authors showed that markov chain approaches failed to model union-level sequential patterns and did not allow skip behaviors in the item sequences. Factorization based approaches such as factorization machines model a sequence by the sum of its item vectors. However, these methods do not consider the order of items and are not specifically invented for sequential recommendations.</p><p>Recently, deep learning models have shown state-of-the-art recommendation accuracy in contrast to conventional models. Moreover, RNNs, a class of deep neural networks, have almost dominated the area of sequential recommendations. For example, a Gated Recurrent Unit (GRURec) architecture with a ranking loss was proposed by <ref type="bibr" target="#b14">[15]</ref> for session-based recommendation. In the follow-up papers, various RNN variants have been designed to extend the typical one for different application scenarios, such as by adding personalization <ref type="bibr" target="#b24">[25]</ref>, content <ref type="bibr" target="#b8">[9]</ref> and contextual features <ref type="bibr" target="#b26">[27]</ref>, attention mechanism <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b19">20]</ref> and different ranking loss functions <ref type="bibr" target="#b13">[14]</ref>.</p><p>By contrast, CNN based sequential recommendation models are more challenging and much less explored because convolutions are not a natural way to capture sequential patterns. To our best knowledge, only two types of sequential recommendation architectures have been proposed to date: the first one by Caser is a standard 2D CNN, while the second is a 3D CNN <ref type="bibr" target="#b29">[30]</ref> designed to model high-dimensional features. Unlike the aforementioned examples, we plan to investigate the effects of 1D CNNs with efficient dilated convolution filters and residual blocks for building the recommendation architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MODEL DESIGN</head><p>To address the above limitations, we introduce a new probabilistic generative model that is formed of a stack of 1D convolution layers. We first focus on the form of the distribution, and then the architectural innovations. Generally, our proposed model is fundamentally different from Caser in several key ways: (1) our probability estimator explicitly models the distribution transition of all individual items at once, rather than the final one, in the sequence; (2) our network has a deep, rather than shallow, structure; (3) our convolutional layers are based on the efficient 1D dilated convolution rather than standard 2D convolution; and (4) pooling layers are removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">A Simple Generative Model</head><p>In this section, we introduce a simple yet very effective generative model directly operating on the sequence of previous interacted items. Our aim is to estimate a distribution over the original item interaction sequences that can be used to tractably compute the likelihood of the items and to generate the future items that users would like to interact. Let p(x) be the joint distribution of item sequence x = {x 0 , ..., x t }. To model p(x), we can factorize it as a product of conditional distributions by the chain rule.</p><formula xml:id="formula_0">p(x) = t i=1 p(x i |x 0:i−1 , θ )p(x 0 )<label>(1)</label></formula><p>where the value p(x i |x 0:i−1 , θ ) is the probability of i-th item x i conditioned on all the previous items x 0:i−1 . A similar setup has been explored by NADE <ref type="bibr" target="#b18">[19]</ref>, PixelRNN/CNN <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref> in biological and image domains.</p><p>Owing to the ability of neural networks in modeling complex nonlinear relations, in this paper we model the conditional distributions of user-item interactions by a stack of 1D convolutional networks. To be more specific, the network receives x 0:t −1 as the input and outputs distributions over possible x 1:t , where the distribution of x t is our final expectation. For example, as illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>, the output distribution of x 15 is determined by x 0:14 , while x 14 is determined by x 0:13 . It is worth noting that in previous sequential recommendation literatures, such as Caser, GRURec and <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30]</ref>, they only model a single conditional distribution p(x i |x 0:i−1 , θ ) rather than all conditional probabilities t i=1 p(x i |x 0:i−1 , θ )p(x 0 ). Within the context of the above example, assuming {x 0 , ..., x 14 } is given, models like Caser only estimate the probability distribution (i.e., softmax) of the next item x 15 (also see Fig. <ref type="figure" target="#fig_0">1 (d</ref>)), while our generative method estimates the distributions of all individual items in {x 1 , ..., x 15 }. The comparison of the generating process is shown below.</p><formula xml:id="formula_1">Caser /GRU Rec : {x 0 , x 1 , ..., x 14 } input ⇒ x 15 output Ours : {x 0 , x 1 , ..., x 14 } input ⇒ {x 1 , x 2 , ..., x 15 } output (2)</formula><p>where ⇒ denotes 'predict'. Clearly, our proposed model is more effective in capturing the set of all sequence relations, whereas Caser and GRURec fail to explicitly model the internal sequence features between {x 0 , ..., x 14 }. In practice, to address the drawback, such models will typically generate a number of sub-sequences (or sub-sessions) for training by means of data augmentation techniques <ref type="bibr" target="#b27">[28]</ref> (e.g., padding, splitting or shifting the input sequence), such as shown in Eq. ( <ref type="formula">3</ref>) ( see <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30]</ref>).</p><formula xml:id="formula_2">Caser /GRU Rec sub − session − 1 : {x −1 , x 0 , ..., x 13 } ⇒ x 14 Caser /GRU Rec sub − session − 2 : {x −1 , x −1 , ..., x 12 } ⇒ x 13 ...... Caser /GRU Rec sub − session − 12 : {x −1 , x −1 , ..., x 2 } ⇒ x 3 (3)</formula><p>While effective, the above approach to generate sub-session cannot guarantee the optimal results due to the separate optimization for each sub-session. In addition, optimizing these sub-sessions separately will result in corresponding computational costs. Detailed comparison with empirical results has also been reported in our experimental sections.  <ref type="formula">b</ref>) respectively. We will refer to a dilated convolution with a dilation factor l as l -dilated convolution. Apparently, compared with the standard CNN that linearly increases the receptive field by the depth of the network, the dilated CNN has a much larger receptive field by the same stacks without introducing more parameters. It can be seen that the standard convolution is a special case of 1-dilated convolution.</p><p>3.2 Network Architecture 3.2.1 Embedding Look-up Layer: Given an item sequence {x 0 , ..., x t }, the model retrieves each of the first t items {x 0 , ..., x t −1 } via a lookup table, and stacks these item embeddings together. Assuming the embedding dimension is 2k, where k can be set as the number of inner channels in the convolutional network. This results in a matrix of size t × 2k. Note that unlike Caser that treats the input matrix as a 2D "image" during convolution, our proposed architecture learns the embedding layer by 1D convolutional filters, which we will describe later.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Dilated layer:</head><p>As shown in Fig. <ref type="figure" target="#fig_1">2</ref> (a), the standard filter is only able to perform convolution with the receptive field linearly by the depth of the network. This makes it difficult to handle longrange sequences. Similar to Wavenet <ref type="bibr" target="#b21">[22]</ref>, we employ the dilated convolution to construct the proposed generative model. The basic idea of dilation is to apply the convolutional filter over a field larger than its original length by dilating it with zeros. As such, it is more efficient since it utilizes fewer parameters. For this reason, a dilated filter is also referred to as a holed or sparse filter. Another benefit is that dilated convolution can preserve the spatial dimensions of the input, which makes the stacking operation much easier for both convolutional layers and residual structures.</p><p>Fig. <ref type="figure" target="#fig_1">2</ref> shows the network comparison between the standard convolution and dilated convolutions with the proposed sequential generative model. The dilation factor in (b) are 1, 2, 4 and 8. To describe the network architecture, we denote receptive field, j-th convolutional layer, channel and dilation as r , F j , C and l respectively. By setting the width of convolutional filter f as 3, we can see that the dilated convolutions (Fig. <ref type="figure" target="#fig_1">2 (b</ref>)) allow for exponential increase in the size of receptive fields (r = 2 j+1 − 1), while the same stacking structure for the standard convolution (Fig. <ref type="figure" target="#fig_1">2 (a)</ref>) has only linear receptive fields (r = 2j + 1). Formally, with dilation l, the filter window from location i is given as</p><formula xml:id="formula_3">x i x i+l x i+2l ... x i+(f −1)•l</formula><p>and the 1D dilated convolution operator * l on element h of the item sequence is given below</p><formula xml:id="formula_4">(x * l д)(h) = f −1 i=0 x h−l •i • д(i)<label>(4)</label></formula><p>where д is the filter function. Clearly, the dilated convolutional structure is more effective to model long-range item sequences, and thus more efficient without using larger filters or becoming deeper.</p><p>In practice, to further increase the model capacity and receptive fields, one just need to repeat the architecture in Fig. <ref type="figure" target="#fig_1">2</ref> multiple times by stacking, e.g., 1, 2, 4, 8, 1, 2, 4, 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">One-dimensional Transformation:</head><p>Although our dilated convolution operator depends on the 2D input matrix E, the proposed network architecture is actually composed of all 1D convolutional layers. To model the 2D embedding input, we perform a simple reshape operation, which serves as a prerequisite for performing 1D convolution. Specifically, the 2D matrix E is reshaped from t ×2k to a 3D tensor T of size 1 × t × 2k, where 2k is treated as the "image" channel rather than the width of the standard convolution filter in Caser. Fig. <ref type="figure" target="#fig_2">3</ref> (b) illustrates the reshaping process. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Masked Convolutional Residual Network</head><p>Although increasing the depth of network layers can help obtain higher-level feature representations, it also easily results in the vanishing gradient issue, which makes the learning process much harder. To address the degradation problem, residual learning <ref type="bibr" target="#b9">[10]</ref> has been introduced for deep networks. While residual learning has achieved huge success in the domain of computer vision, it has not appeared in the recommender system literature.</p><p>The basic idea of residual learning is to stack multiple convolutional layers together as a block and then employ a skip connection scheme that passes the previous layers's feature information to its posterior layer. The skip connection scheme allows to explicitly fit the residual mapping rather than the original identity mapping, which can maintain the input information and thus enlarge the propagated gradients. Formally, denoting the desired mapping as H (E), we let the residual block fit another mapping of F (E) = H (E) − E. The desired mapping now is recast into F (E) + E by element-wise addition (assuming that F (E) and E are of the same dimension). As has been evidenced in <ref type="bibr" target="#b9">[10]</ref>, optimizing the residual mapping F (E) is much easier than the original, unreferenced mapping H (E).</p><p>Inspired by <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b17">18]</ref>, we introduce two residual modules in Fig. <ref type="figure" target="#fig_2">3 (a)  and (b)</ref>.</p><p>In (a), we wrap each dilated convolutional layer by a residual block, while in (b) we wrap every two dilated layers by a different residual block. That is, with the design of block (b), the input layer and the second convolutional layer should be connected by skip connection (i.e., the blue lines in Fig. <ref type="figure" target="#fig_1">2</ref>). Specifically, each block is made up of the normalization, activation (e.g., ReLU <ref type="bibr" target="#b20">[21]</ref>), convolutional layers and a skip connection in a specific order. In this work we adopt the state-of-the-art layer normalization <ref type="bibr" target="#b0">[1]</ref> before each activation layer, as it is well suited to sequence processing and online learning in contrast with batch normalization <ref type="bibr" target="#b15">[16]</ref>.</p><p>Regarding the properties of the two residual networks, the residual block in (a) consists of 3 convolution filters: one dilated filter of size 1 × 3 and two regular filters of size 1 × 1. The 1 × 1 filters are introduced to change the size of C so as to reduce the parameters to be learned by the 1 × 3 kernel. The first 1 × 1 filter (close to input E in Fig. <ref type="figure" target="#fig_2">3 (a)</ref>) is to change C from 2k to k, while the second 1 × 1 filter does the opposite transformation in order to maintain the spatial dimensions for the next stacking operation. To show the effectiveness of the 1 × 1 filters in (a), we the number of parameters in both (a) and (b). For simplicity, we omit the activation and normalization layers. As we can see, the number of parameters for the 1 × 3 filter is 1 × 3 × 2k × 2k = 12k 2 (i.e., in (b)) without the 1 × 1 filters. While in (a), the number of parameters to be learned is</p><formula xml:id="formula_5">1 × 1 × 2k × k + 1 × 3 × k × k + 1 × 1 × k × 2k = 7k 2 .</formula><p>The residual mapping F (E, {W i }) in (a) and (b) is formulated as:</p><formula xml:id="formula_6">F (E, {W i }) = W 3 (σ (ψ (W 2 (σ (ψ (W 1 (σ (ψ (E)))))))))) Fig.3 (a) σ (ψ (W ′ 4 (σ (ψ (W ′ 2 (E))))) Fig.3 (b)<label>(5)</label></formula><p>where σ and ψ denote ReLU and layer-normalization, W 1 and W 3 denote the convolution weight function of standard 1 × 1 convolutions, and W 2 , W ′ 2 and W ′ 4 denote the weight function of l-dilated convolution filter with size of 1 × 3. Note that bias terms are omitted for simplifying notations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Dropout-mask:</head><p>To avoid the future information leakage problem, we propose a masking-based dropout trick for the 1D dilated convolution to prevent the network from seeing the future items. Specifically, when predicting p(x i |x 0:i−1 ), the convolution filters are not allowed to make use of the information from x i:t . Fig. <ref type="figure" target="#fig_3">4</ref> shows several different ways to perform convolution. As shown, our dropout-masking operation can be implemented either by padding the input sequence in (d) or shifting the output sequence by a few timesteps in (e). The padding method in (e) is very likely to result in information loss in a sequence, particularly for short sequences. Hence in this work, we apply the padding strategy in (d) with the padding size of (f − 1) * l.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Final Layer, Network Training and Generating</head><p>As mentioned, the matrix in the last layer of the convolution architecture (see Fig. <ref type="figure" target="#fig_1">2</ref>), denoted by E o , preserves the same dimensional size of the input E, i.e., E o ∈ R t ×2k . However, the output should be a matrix or tensor that contains probability distributions of all items in the output sequence x 1:t , where the probability distribution of x t is the desired one that generates top-N predictions. To do this, we can simply use one more convolutional layer on top of the last convolutional layer in Fig. <ref type="figure" target="#fig_1">2</ref> with filter of size 1 × 1 × 2k ×n, where n is the number of items. Following the procedure of one-dimensional transformation in Fig. <ref type="figure" target="#fig_2">3 (c)</ref>, we obtain the expected ouput matrix E p ∈ R t ×n , where each row vector after the softmax operation represents the categorical distribution over x i (0</p><formula xml:id="formula_7">&lt; i ≤ t).</formula><p>The aim of optimization is to maximize the log-likelihood of the training data w.r.t. θ . Clearly, maximizing log p(x) is mathematically equivalent to minimizing the sum of the binary cross-entropy loss for each item in x 1:t . For practical recommender systems with tens of millions items, the negative sampling strategy can be applied to bypasses the generation of full softmax distributions, where the 1 × 1 convolutional layer is replaced by a fully-connected (FC) layer with weight matrix E д ∈ R 2k ×n . For example, we can apply either the sampled softmax <ref type="bibr" target="#b16">[17]</ref> or kernel based sampling <ref type="bibr" target="#b1">[2]</ref>. The recommendation accuracy by these negative sampling strategies is nearly identical with the full softmax method with properly tuned sampling size.</p><p>For comparison purpose, we only predict the next one item in our evaluation, and then stop the generating process. Nevertheless, the model is able to generate a sequence of items simply by feeding the predicted one item (or sequence) into the network to predict the next one, and thus the prediction at the generating phrase is sequential. This matches most real-world recommendation scenarios, where the next action is followed when the current one has been observed. But at both training and evaluation phases, the conditional predictions for all timesteps can be made in parallel, because the complete sequence of input items x is already available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>In this section we detail our experiments, report results for several data sets, and compare our model (called NextItNet) with the wellknown RNN-based model GRURec <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b27">28]</ref> and the state-of-the-art CNN-based model Caser. Note that (1) since the main contributions in this paper do not focus on combining various features, we omit the comparison with content-or context-based sequential recommendation models, such as the 3D CNN recommender <ref type="bibr" target="#b29">[30]</ref> and other RNN variants <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27]</ref>; <ref type="bibr" target="#b1">(2)</ref> the GRURec baseline could be regarded as the state-of-the-art Improved GRURec <ref type="bibr" target="#b27">[28]</ref> when dealing with the long-range session data sets because our main data augmentation technique for the two baseline models follows the same way in Improved GRURec.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets and Experiment Setup</head><p>4.1.1 Datasets and Preprocessing. The first data set 'Yoochoosebuys' (YOO for short) is chosen from the RecSys Challenge 2015 3 . We use the buying dataset for evaluation. For preprocessing, we filter out sessions of length shorter than 3. Meanwhile, we find that in the processed Yoo data 96% sessions have a length shorter than 10, and we simply remove the 4% longer sessions and refer it as a short-range sequential data.</p><p>The remaining data sets are extracted from Last.fm 4 : one mediumsize (MUSIC_M) and one large-scale (MUSIC_L) collection by randomly drawing 20,000 and 200,000 songs respectively. In the Last.fm data set, we observe that most users listen to music several hundred times a week, and some even listen to more than one hundred songs 3 http://2015.recsyschallenge.com/challenge.html 4 http://www.dtic.upf.edu/ ocelma/MusicRecommendationDataset/lastfm-1K.html within a day. Hence, we are able to test our model in both shortand long-range sequences by cutting up these long-range listening sessions. In MUSIC_L, we define the maximum session length t as 5, 10, 20, 50 and 100, and then extract every t successive items as our input sequences. This is done by sliding a window of both size and stride of t over the whole data. We ignore sessions in which the time span between the last two items is longer than 2 hours. In this way, we create 5 data sets, referred to as RAW-SESSIONS. We randomly split these RAW-SESSIONS data into training (50%), validation (5%), and testing (45%) sets.</p><p>As mentioned before, the performance of Caser and GRURec is supposed to degrade significantly for long sequence inputs, such as when t = 20, 50 and 100. For example, when setting t = 50, Caser and GRURec will predict x 49 by using x 0:48 , but without explicitly modeling the item inter-dependencies between x 0 and x 48 . To remedy this defect, when t &gt; 5, we follow the common approach <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b27">28]</ref> by manually creating additional sessions from the training sets of RAW-SESSIONS so that Caser and GRURec can leverage the full dependency to a large extent. Still setting t = 50, one training session will then produce 45 more sub-sessions by padding the beginning and removing the end indices, referred to as SUB-SESSIONS. The example of the 45 sub-sessions are given as follows: {x −1 , x 0 , x 1 , ..., x 48 }, {x −1 , x −1 , x 0 , ..., x 47 },..., {x −1 , x −1 , x −1 , ..., x 4 }. Regarding MUSIC_M, we only show the results when t = 5. We show the statistics of RAW-SESSIONS &amp; training data of SUB-SESSIONS (i.e., SUB-SESSIONS-T ) in Table <ref type="table" target="#tab_0">1</ref>.</p><p>All models were trained on GPUs (TITAN V) using Tensorflow. The learning rates and batch sizes of baseline methods were manually set according to performance in validation sets. For all data sets, NextItNet used the learning rate of 0.001 and batch size of 32. Embedding size 2k is set to 64 for all models without special mention. We report results with residual block (a) and full softmax. We have validated the performance of results block (b) separately. To further evaluate the effectiveness of the two residual blocks, we have also tested our model in another dataset, namely, Weishi <ref type="foot" target="#foot_2">5</ref> . The improvements are about two times compared with the same model without residual blocks.</p><p>4.1.2 Evaluation Protocols. We reported the evaluated results by three popular top-N metrics, namely MRR@N (Mean Reciprocal Rank) <ref type="bibr" target="#b14">[15]</ref>, HR@N (Hit Ratio) <ref type="bibr" target="#b12">[13]</ref> and NDCG@N <ref type="bibr" target="#b33">[34]</ref> (Normalized Discounted Cumulative Gain). N is set to 5 and 20 for comparison. We evaluate the prediction accuracy of the last (i.e., next) item of each sequence in the testing set, similarly to <ref type="bibr" target="#b13">[14]</ref>.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results Summary</head><p>Overall performance results of all methods are illustrated in Table 2 and 3, which clearly show that the neural network models (i.e., Caser, GRURec and our model) obtain very promising accuracy in the top-N sequential recommendation task. For example, in embedding matrix E without any information lost. The third advantage is that NextItNet can support deeper layers by using residual learning, which better suits for modeling complicated relations and long-range dependencies. We have separately validated the performance of residual block in Fig. <ref type="figure" target="#fig_2">3</ref> (b) and showed the results in Table <ref type="table" target="#tab_4">5</ref>. It can be observed that the performance of NextItNet can be significantly improved by the residual block design. Table <ref type="table" target="#tab_5">6</ref> shows the impact of embedding sizes.</p><p>In addition to the advantage of recommendation accuracy, we have also evaluated the efficiency of NextItNet in Table <ref type="table" target="#tab_6">7</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this paper, we presented a simple, efficient and highly effective convolutional generative model for session-based top-N item recommendations. The proposed model combines masked filters with 1D dilated convolutions to increase the receptive fields, which is very important to model the long-range dependencies. In addition, we have applied residual learning to enable training of much deeper networks. We have shown that our model can greatly outperform state-of-the-arts in real-world session-based recommendation tasks.</p><p>The proposed model can serve as a generic method for modeling both short-and long-range session-based recommendation data.</p><p>For comparison purposes, we have not considered additional contexts in either our model or baselines. However, our model is flexible to incorporate various context information. For example, if we know the user identity u and location p, the distribution in Eq. ( <ref type="formula" target="#formula_0">1</ref>) can be modified as follows to incorporate these information. </p><p>where we can combine E (before convolution) or E o (after convolution) with the user embedding vector u and location matrix P by element-wise operations, such as multiplication, addition or concatenation. We leave the evaluation for future work. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The basic structure of Caser [29]. The red, yellow and blue regions denotes a 2 ×k , 3 ×k and 4 ×k convolution filter respectively, where k = 5. The purple row stands for the true next item.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The proposed generative architecture with 1D standard CNNs (a) and efficient dilated CNNs (b). The blue lines are the identity map which exists only for residual block (b) in Fig. 3. An example of a standard 1D convolution filter and dilated filters are shown at the bottom of (a) and (b) respectively. We will refer to a dilated convolution with a dilation factor l as l -dilated convolution. Apparently, compared with the standard CNN that linearly increases the receptive field by the depth of the network, the dilated CNN has a much larger receptive field by the same stacks without introducing more parameters. It can be seen that the standard convolution is a special case of 1-dilated convolution.</figDesc><graphic url="image-1.png" coords="4,269.99,194.34,269.30,99.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Dilated residual blocks (a), (b) and one-dimensional transformation (c). (c) shows the transformation from the 2D filter (C = 1)(left) to the 1D 2-dilated filter (C = 2k) (right); the vertical black arrows represent the direction of the sliding convolution. In this work, the default stride for the dilated convolution is 1. Note the reshape operation in (b) is performed before each convolution in (a) and (b) (i.e., 1 × 1 and masked 1 × 3), which is then followed by a reshape back step after convolution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The future item can only be determined by the past ones according to Eq. (1). (a) (d) and (e) show the correct convolution process, while (b) and (c) are wrong. E.g., in (d), items of {1, 2, 3, 4} are masked when predicting 1, which can be technically implemented by padding.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>First, it can be seen that NextItNet and Caser requires less training time than GRURec in all three data sets. The reason that CNN-based models can be trained much faster is due to the full parallel mechanism of convolutions. Clearly, the training speed advantage of CNN models are more preferred by modern parallel computing systems. Second, it shows that NextItNet achieves further improvements in training time compared with Caser. The faster training speed is mainly because NextItNet leverages the complete sequential information during training and then converges much faster by less training epochs. To better understand of the convergence behaviours, we have shown them in Fig. 5. As can be seen, our model with the same number of training sessions converges faster (a) and better (b, c, d) than Caser and GRURec. This confirms our claim in Section 3.1 since Caser and GRURec cannot make full use of the internal sequential information in the session.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>i |x 0:i−1 , u, P, θ )p(x 0 )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>5 Figure 5 :</head><label>55</label><figDesc>Figure 5: Convergence behaviors of MUSIC_L100. GRU is short for GRURec. д = 256k means the number of training sequences (or sessions) of one unit in x-axis is 256k. Note that (1) to speed up the experiments, all of the convergence tests are evaluated on the first 1024 sessions in the testing set; (2) only NextItNet has converged in above figures, while GRU and Caser require more training instances for convergence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Session statistics of all data sets.MUSIC_M5 denotes MUSIC_M with maximum session size of 5. The same applies to MUSIC_L. 'M' denotes 1 million.</figDesc><table><row><cell>DATA</cell><cell>YOO</cell><cell>MUSIC_M5</cell><cell>MUSIC_L5</cell><cell>MUSIC_L10</cell><cell>MUSIC_L20</cell><cell>MUSIC_L50</cell><cell>MUSIC_L100</cell></row><row><cell>RAW-SESSIONS</cell><cell>0.14M</cell><cell>0.61M</cell><cell>2.14M</cell><cell>1.07M</cell><cell>0.53M</cell><cell>0.21M</cell><cell>0.11M</cell></row><row><cell>SUB-SESSIONS-T</cell><cell>0.07M</cell><cell>0.31M</cell><cell>1.07M</cell><cell>3.21M</cell><cell>4.28M</cell><cell>4.91M</cell><cell>5.10M</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Accuracy comparison. The upper, middle and below tables are MRR@5, HR@5 and NDCG@5 respectively.MostPop returns the most popular item respectively. Regarding the setup of our model, we use two-hidden-layer convolution structure with dilation factor 1, 2, 4 for the first four data sets (i.e., YOO, MUSIC_M5 , MUSIC_L5 and MUSIC_L10), while for the last three long-range sequence data sets, we use 1, 2, 4, 8, 1, 2, 4, 8, to obtain above results.</figDesc><table><row><cell>DATA</cell><cell>YOO</cell><cell>MUSIC_M5</cell><cell>MUSIC_L5</cell><cell>MUSIC_L10</cell><cell>MUSIC_L20</cell><cell>MUSIC_L50</cell><cell>MUSIC_L100</cell></row><row><cell>MostPop</cell><cell>0.0050</cell><cell>0.0024</cell><cell>0.0006</cell><cell>0.0007</cell><cell>0.0008</cell><cell>0.0007</cell><cell>0.0007</cell></row><row><cell>GRURec</cell><cell>0.1645</cell><cell>0.3019</cell><cell>0.2184</cell><cell>0.2124</cell><cell>0.2327</cell><cell>0.2067</cell><cell>0.2086</cell></row><row><cell>Caser</cell><cell>0.1523</cell><cell>0.2920</cell><cell>0.2207</cell><cell>0.2214</cell><cell>0.1947</cell><cell>0.2060</cell><cell>0.2080</cell></row><row><cell>NextItNet</cell><cell>0.1715</cell><cell>0.3133</cell><cell>0.2327</cell><cell>0.2596</cell><cell>0.2748</cell><cell>0.2735</cell><cell>0.2583</cell></row><row><cell>MostPop</cell><cell>0.0151</cell><cell>0.0054</cell><cell>0.0014</cell><cell>0.0016</cell><cell>0.0016</cell><cell>0.0016</cell><cell>0.0016</cell></row><row><cell>GRURec</cell><cell>0.2773</cell><cell>0.3610</cell><cell>0.2626</cell><cell>0.2660</cell><cell>0.2694</cell><cell>0.2589</cell><cell>0.2593</cell></row><row><cell>Caser</cell><cell>0.2389</cell><cell>0.3368</cell><cell>0.2443</cell><cell>0.2631</cell><cell>0.2433</cell><cell>0.2572</cell><cell>0.2588</cell></row><row><cell>NextItNet</cell><cell>0.2871</cell><cell>0.3754</cell><cell>0.2695</cell><cell>0.3014</cell><cell>0.3166</cell><cell>0.3218</cell><cell>0.3067</cell></row><row><cell>MostPop</cell><cell>0.0075</cell><cell>0.0031</cell><cell>0.0008</cell><cell>0.0009</cell><cell>0.0010</cell><cell>0.0009</cell><cell>0.0009</cell></row><row><cell>GRURec</cell><cell>0.1923</cell><cell>0.3166</cell><cell>0.2294</cell><cell>0.2258</cell><cell>0.2419</cell><cell>0.2197</cell><cell>0.2212</cell></row><row><cell>Caser</cell><cell>0.1738</cell><cell>0.3032</cell><cell>0.2267</cell><cell>0.2318</cell><cell>0.2068</cell><cell>0.2188</cell><cell>0.2207</cell></row><row><cell>NextItNet</cell><cell>0.2001</cell><cell>0.3288</cell><cell>0.2419</cell><cell>0.2700</cell><cell>0.2853</cell><cell>0.2855</cell><cell>0.2704</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Accuracy comparison. The upper, middle and below tables are MRR@20, HR@20 and NDCG@20 respectively.</figDesc><table><row><cell>DATA</cell><cell>YOO</cell><cell>MUSIC_M5</cell><cell>MUSIC_L5</cell><cell>MUSIC_L10</cell><cell>MUSIC_L20</cell><cell>MUSIC_L50</cell><cell>MUSIC_L100</cell></row><row><cell>MostPop</cell><cell>0.0090</cell><cell>0.0036</cell><cell>0.0009</cell><cell>0.0010</cell><cell>0.0011</cell><cell>0.0011</cell><cell>0.0011</cell></row><row><cell>GRURec</cell><cell>0.1839</cell><cell>0.3103</cell><cell>0.2242</cell><cell>0.2203</cell><cell>0.2374</cell><cell>0.2151</cell><cell>0.2162</cell></row><row><cell>Caser</cell><cell>0.1660</cell><cell>0.2979</cell><cell>0.2234</cell><cell>0.2268</cell><cell>0.2017</cell><cell>0.2133</cell><cell>0.2153</cell></row><row><cell>NextItNet</cell><cell>0.1901</cell><cell>0.3223</cell><cell>0.2375</cell><cell>0.2669</cell><cell>0.2815</cell><cell>0.2794</cell><cell>0.2650</cell></row><row><cell>MostPop</cell><cell>0.0590</cell><cell>0.0180</cell><cell>0.0052</cell><cell>0.0053</cell><cell>0.0056</cell><cell>0.0056</cell><cell>0.0056</cell></row><row><cell>GRURec</cell><cell>0.4603</cell><cell>0.4435</cell><cell>0.3197</cell><cell>0.3434</cell><cell>0.3158</cell><cell>0.3406</cell><cell>0.3336</cell></row><row><cell>Caser</cell><cell>0.3714</cell><cell>0.3937</cell><cell>0.2703</cell><cell>0.3150</cell><cell>0.3110</cell><cell>0.3273</cell><cell>0.3298</cell></row><row><cell>NextItNet</cell><cell>0.4645</cell><cell>0.4626</cell><cell>0.3159</cell><cell>0.3709</cell><cell>0.3814</cell><cell>0.3789</cell><cell>0.3731</cell></row><row><cell>MostPop</cell><cell>0.0195</cell><cell>0.0066</cell><cell>0.0018</cell><cell>0.0019</cell><cell>0.0021</cell><cell>0.0020</cell><cell>0.0020</cell></row><row><cell>GRURec</cell><cell>0.2460</cell><cell>0.3405</cell><cell>0.2460</cell><cell>0.2481</cell><cell>0.2553</cell><cell>0.2433</cell><cell>0.2427</cell></row><row><cell>Caser</cell><cell>0.2122</cell><cell>0.3197</cell><cell>0.2342</cell><cell>0.2469</cell><cell>0.2265</cell><cell>0.2392</cell><cell>0.2412</cell></row><row><cell>NextItNet</cell><cell>0.2519</cell><cell>0.3542</cell><cell>0.2554</cell><cell>0.2904</cell><cell>0.3041</cell><cell>0.3021</cell><cell>0.2895</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Effects of sub-session in terms of MRR@5. The upper, middle and below tables represent GRU, Caser and NextItNet respectively. "10","20","50" and "100" are the session lengths.</figDesc><table><row><cell>Sub-session</cell><cell>10</cell><cell>20</cell><cell>50</cell><cell>100</cell></row><row><cell>Without</cell><cell>0.1985</cell><cell>0.1645</cell><cell>0.1185</cell><cell>0.0746</cell></row><row><cell>With</cell><cell>0.2124</cell><cell>0.2327</cell><cell>0.2067</cell><cell>0.2086</cell></row><row><cell>Without</cell><cell>0.1571</cell><cell>0.1012</cell><cell>0.0216</cell><cell>0.0084</cell></row><row><cell>With</cell><cell>0.2214</cell><cell>0.1947</cell><cell>0.2060</cell><cell>0.2080</cell></row><row><cell>Without</cell><cell>0.2596</cell><cell>0.2748</cell><cell>0.2735</cell><cell>0.2583</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Effects of the residual block in terms of MRR@5. "With-</figDesc><table><row><cell cols="5">out" means no skip connection. "M5", "L5", "L10" and "L50" denote</cell></row><row><cell cols="5">MUSIC_M5 , MUSIC_L5 , MUSIC_L10 and MUSIC_L50 respectively.</cell></row><row><cell>DATA</cell><cell>M5</cell><cell>L5</cell><cell>L10</cell><cell>L50</cell></row><row><cell>Without</cell><cell>0.2968</cell><cell>0.2146</cell><cell>0.2292</cell><cell>0.2432</cell></row><row><cell>With</cell><cell>0.3300</cell><cell>0.2455</cell><cell>0.2645</cell><cell>0.2760</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Effects (MRR@5) of increasing embedding size. The upper and below tables are MUSIC_M5 and MUSIC_L100 respectively.MUSIC_M5, the three neural models perform more than 120 times better on MRR@5 than MostPop, which is a widely used recommendation benchmark. The best MRR@20 result we have achieved by NextItNet is 0.3223 in this data set, which roughly means that the desired item is ranked on position 3 in average among the 20,000 candidate items. We then find that among these neural network based models, NextItNet largely outperforms Caser &amp; GRURec. We believe there are several reasons contributing to the state-of-the-art results. First, as highlighted in Section 3.1, NextItNet takes full advantage of the complete sequential information. This can be easily verified in Table4, where we observe that Caser &amp; GRURec without subsession perform extremely worse with long sessions. In addition, even with sub-session Caser &amp; GRURec still show significantly worse results than NextItNet because the separate optimization of each sub-session is clearly suboptimal compared with leveraging full sessions by NextItNet. Second, unlike Caser, NextItNet has no pooling layers, although it is also a CNN based model. As a result, NextItNet preserves the whole spatial resolution of the original</figDesc><table><row><cell>2k</cell><cell>16</cell><cell>32</cell><cell>64</cell><cell>128</cell></row><row><cell>GRURec</cell><cell>0.2786</cell><cell>0.2955</cell><cell>0.3019</cell><cell>0.3001</cell></row><row><cell>Caser</cell><cell>0.2855</cell><cell>0.2982</cell><cell>0.2979</cell><cell>0.2958</cell></row><row><cell>NextItNet</cell><cell>0.2793</cell><cell>0.3063</cell><cell>0.3133</cell><cell>0.3183</cell></row><row><cell>GRURec</cell><cell>0.1523</cell><cell>0.1826</cell><cell>0.2086</cell><cell>0.2043</cell></row><row><cell>Caser</cell><cell>0.0643</cell><cell>0.1129</cell><cell>0.2080</cell><cell>0.2339</cell></row><row><cell>NextItNet</cell><cell>0.1668</cell><cell>0.2289</cell><cell>0.2583</cell><cell>0.2520</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Overall training time (mins).</figDesc><table><row><cell>Model</cell><cell>GRURec</cell><cell>Caser</cell><cell>NextItNet</cell></row><row><cell>MUSIC_L5</cell><cell>66</cell><cell>59</cell><cell>54</cell></row><row><cell>MUSIC_L20</cell><cell>282</cell><cell>191</cell><cell>76</cell></row><row><cell>MUSIC_L100</cell><cell>586</cell><cell>288</cell><cell>150</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https://www.last.fm</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">http://weishi.qq.com/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2">We are working to release this dataset, which has very good sequential property.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This paper was supported by the European Union's Horizon 2020 Research and Innovation program under grant agreement No 780787.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lei Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Ryan Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">Layer normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">Guy</forename><surname>Blanc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.00527</idno>
		<title level="m">Adaptive Sampled Softmax with Kernel Based Sampling</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Recurrent Latent Variable Networks for Session-Based Recommendation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sotirios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panayiotis</forename><surname>Chatzis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><forename type="middle">S</forename><surname>Christodoulou</surname></persName>
		</author>
		<author>
			<persName><surname>Andreou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Deep Learning for Recommender Systems</title>
				<meeting>the 2nd Workshop on Deep Learning for Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.00915</idno>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Where You Like to Go Next: Successive Point-of-Interest Recommendation</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haiqin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irwin</forename><surname>Michael R Lyu</surname></persName>
		</author>
		<author>
			<persName><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Exploiting Music Play Sequence for Music Recommendation</title>
		<author>
			<persName><forename type="first">Zhiyong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialie</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohan</forename><surname>Kankanhalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A Hierarchical Contextual Attention-based GRU Network for Sequential Recommendation</title>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05114</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denis</forename><surname>Yarats</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.03122</idno>
		<title level="m">Convolutional Sequence to Sequence Learning</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning to refine text based recommendations</title>
		<author>
			<persName><forename type="first">Youyang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tommi</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2103" to="2108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="630" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Neural factorization machines for sparse predictive analytics</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="355" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Adversarial personalized ranking for recommendation</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhankui</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyu</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="355" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Recurrent Neural Networks with Top-k Gains for Session-based Recommendations</title>
		<author>
			<persName><forename type="first">Balázs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03847</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Session-based recommendations with recurrent neural networks</title>
		<author>
			<persName><forename type="first">Balázs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06939</idno>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Linas Baltrunas, and Domonkos Tikk</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roland</forename><surname>Memisevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.2007</idno>
		<title level="m">On using very large target vocabulary for neural machine translation</title>
				<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.10099</idno>
		<title level="m">Neural machine translation in linear time</title>
				<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The neural autoregressive distribution estimator</title>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="29" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Neural Attentive Session-based Recommendation</title>
		<author>
			<persName><forename type="first">Jing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengjie</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhumin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1419" to="1428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sander</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiga</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.03499</idno>
		<title level="m">Wavenet: A generative model for raw audio</title>
				<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1601.06759</idno>
		<title level="m">Pixel recurrent neural networks</title>
				<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Conditional image generation with pixelcnn decoders</title>
		<author>
			<persName><forename type="first">Aäron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="4797" to="4805" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Personalizing Session-based Recommendations with Hierarchical Recurrent Neural Networks</title>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Quadrana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Balázs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Cremonesi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.04148</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Tom</forename><surname>Sercu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vaibhava</forename><surname>Goel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.09288</idno>
		<title level="m">Dense Prediction on Sequences with Time-Dilated Convolutions for Speech Recognition</title>
				<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">Elena</forename><surname>Smirnova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Flavian</forename><surname>Vasile</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.07684</idno>
		<title level="m">Contextual Sequence Modeling for Recommendation with Recurrent Neural Networks</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Improved recurrent neural networks for session-based recommendations</title>
		<author>
			<persName><forename type="first">Yong</forename><surname>Kiam Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinxing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Deep Learning for Recommender Systems</title>
				<meeting>the 1st Workshop on Deep Learning for Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="17" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding</title>
		<author>
			<persName><forename type="first">Jiaxi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Web Search and Data Mining</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">3D Convolutional Networks for Session-based Recommendation with Content Features</title>
		<author>
			<persName><forename type="first">Xuan</forename><surname>Trinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tuan</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Tu</forename><surname>Minh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phuong</forename></persName>
		</author>
		<editor>RecSys</editor>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.07122</idno>
		<title level="m">Multi-scale context aggregation by dilated convolutions</title>
				<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Lambdafm: learning optimal ranking with factorization machines using lambda surrogates</title>
		<author>
			<persName><forename type="first">Fajie</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guibing</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Joemon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haitao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weinan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="227" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Boostfm: Boosted factorization machines for top-n feature-based recommendation</title>
		<author>
			<persName><forename type="first">Fajie</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guibing</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Joemon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haitao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weinan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IUI</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="45" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">Fajie</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guibing</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joemon</forename><surname>Jose</surname></persName>
		</author>
		<title level="m">fBGD: Learning Embeddings From Positive Unlabeled Data with BGD. UAI</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
