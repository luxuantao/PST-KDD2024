<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><roleName>Member, IEEE</roleName><forename type="first">Gai-Ge</forename><surname>Wang</surname></persName>
							<email>gaigewang@gmail.com</email>
							<idno type="ORCID">0000-0002-3295-8972</idno>
						</author>
						<author>
							<persName><forename type="first">G.-G</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Improving Metaheuristic Algorithms With Information Feedback Models</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Computer Science and Technology</orgName>
								<orgName type="department" key="dep2">School of Computer</orgName>
								<orgName type="institution">Ocean University of China</orgName>
								<address>
									<postCode>266100</postCode>
									<settlement>Qingdao</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Jiangsu Normal University</orgName>
								<address>
									<postCode>221116</postCode>
									<settlement>Xuzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Institute of Algorithm and Big Data Analysis and School of Computer Science and Information Technology</orgName>
								<orgName type="institution">Northeast Normal University</orgName>
								<address>
									<postCode>130117</postCode>
									<settlement>Changchun</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Department of Machine Intelligence</orgName>
								<orgName type="department" key="dep2">School of Electronics Engineering and Computer Science</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0D537C6D96EF6A106375C8E1DD9FED7A</idno>
					<idno type="DOI">10.1109/TCYB.2017.2780274</idno>
					<note type="submission">received September 20, 2017; revised November 30, 2017; accepted December 3, 2017.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Benchmark</term>
					<term>evolutionary algorithms (EAs)</term>
					<term>evolutionary computation</term>
					<term>information feedback</term>
					<term>metaheuristic algorithms</term>
					<term>optimization algorithms</term>
					<term>swarm intelligence</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In most metaheuristic algorithms, the updating process fails to make use of information available from individuals in previous iterations. If this useful information could be exploited fully and used in the later optimization process, the quality of the succeeding solutions would be improved significantly. This paper presents our method for reusing the valuable information available from previous individuals to guide later search. In our approach, previous useful information was fed back to the updating process. We proposed six information feedback models. In these models, individuals from previous iterations were selected in either a fixed or random manner. Their useful information was incorporated into the updating process. Accordingly, an individual at the current iteration was updated based on the basic algorithm plus some selected previous individuals by using a simple fitness weighting method. By incorporating six different information feedback models into ten metaheuristic algorithms, this approach provided a number of variants of the basic algorithms. We demonstrated experimentally that the variants outperformed the basic algorithms significantly on 14 standard test functions and 10 CEC 2011 real world problems, thereby, establishing the value of the information feedback models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>other fields, optimization problems seek the maximum or minimum value of a given objective function. These problems are often approached using optimization algorithms. Optimization algorithms can be divided loosely into two categories: 1) the traditional deterministic methods and 2) modern metaheuristic algorithms. The former will generate the same results for different runs under the same conditions. For the latter, different runs will generate different solutions in most cases, even under the same conditions. Because metaheuristic algorithms can solve many complicated problems successfully, they have received increased attention in many fields, ranging from academic research to engineering practice.</p><p>Inspired by nature, a variety of metaheuristic algorithms have been proposed recently to deal with complicated optimization problems <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b4">[5]</ref>. Many of them have solved complex, challenging problems that are difficult to approach using traditional mathematical optimization techniques. These nature-inspired algorithms include ant colony optimization (ACO) <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, artificial bee colony <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, differential evolution (DE) <ref type="bibr" target="#b9">[10]</ref>- <ref type="bibr" target="#b11">[12]</ref>, evolutionary strategy (ES) <ref type="bibr" target="#b12">[13]</ref>, cuckoo search (CS) <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, fireworks algorithm (FWA) <ref type="bibr" target="#b15">[16]</ref>, brain storm optimization <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, earthworm optimization algorithm <ref type="bibr" target="#b18">[19]</ref>, elephant herding optimization <ref type="bibr" target="#b19">[20]</ref>, krill herd (KH) <ref type="bibr" target="#b20">[21]</ref>- <ref type="bibr" target="#b27">[28]</ref>, biogeography-based optimization (BBO) <ref type="bibr" target="#b28">[29]</ref>, genetic algorithm (GA) <ref type="bibr" target="#b29">[30]</ref>- <ref type="bibr" target="#b31">[32]</ref>, harmony search (HS) <ref type="bibr" target="#b32">[33]</ref>- <ref type="bibr" target="#b34">[35]</ref>, monarch butterfly optimization (MBO) <ref type="bibr" target="#b35">[36]</ref>, probabilitybased incremental learning (PBIL) <ref type="bibr" target="#b36">[37]</ref>, moth search algorithm <ref type="bibr" target="#b37">[38]</ref>, particle swarm optimization (PSO) <ref type="bibr" target="#b38">[39]</ref>- <ref type="bibr" target="#b45">[46]</ref>, and bat algorithm (BA) <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b47">[48]</ref>.</p><p>However, these basic metaheuristic algorithms have failed to make full use of valuable information available from the individuals in previous iterations to guide their current and later search. Some of them, such as ABC <ref type="bibr" target="#b7">[8]</ref>, ACO <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b48">[49]</ref>, BA <ref type="bibr" target="#b46">[47]</ref>, and BBO <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b49">[50]</ref>, abandon previous instances directly. Others, such as CS <ref type="bibr" target="#b13">[14]</ref>, FWA <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b50">[51]</ref>, PSO <ref type="bibr" target="#b38">[39]</ref>- <ref type="bibr" target="#b41">[42]</ref>, KH <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, and MBO <ref type="bibr" target="#b35">[36]</ref>, use only the best previous individuals. In practice, any of the previous individuals could contain a variety of useful information. If such information could be fully exploited and utilized in the later optimization process, the performance of these metaheuristic algorithms surely would be significantly improved.</p><p>Accordingly, many researchers enhanced these metaheuristic algorithms, and some useful information obtained from the surrogate, an individual, the whole population/swarm, dynamical environments, and/or neighbors has been extracted 2168-2267 c 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.</p><p>See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p><p>Surrogate information is found to be very effective in reducing user effort. Therefore, many researchers have improved various metaheuristic algorithms through the use of surrogate information, as in GA and PSO.</p><p>Sun et al. <ref type="bibr" target="#b30">[31]</ref> proposed a new surrogate-assisted interactive genetic algorithm (IGA), where the uncertainty in subjective fitness evaluations was exploited both in training the surrogates and in managing surrogates. Moreover, uncertainty in the interval-based fitness values was also considered in model management, so that not only the best individuals but also the most uncertain individuals would be chosen to be re-evaluated by the human user. The experimental results indicated that the new surrogate-assisted IGA could alleviate user fatigue effectively and was more likely to find acceptable solutions in solving complex design problems.</p><p>Gong et al. <ref type="bibr" target="#b52">[53]</ref> proposed a computationally cheap surrogate model-based multioperator search strategy for evolutionary optimization. In this strategy, a set of candidate offspring solutions were generated by using the multiple offspring reproduction operators. The best one according to the surrogate model was chosen as the offspring solution. The proposed strategy was used to implement a multioperator ensemble in two popular evolutionary algorithms (EAs), DE, and PSO.</p><p>Aiming to solve medium-scale problems (i.e., 20-50 decision variables), Liu et al. <ref type="bibr" target="#b53">[54]</ref> proposed a Gaussian process surrogate model-assisted EA for medium-scale computationally expensive optimization problems (GPEME). A new framework was developed and used in GPEME that carefully coordinated the surrogate modeling and the evolutionary search. In this way, the search could focus on a small promising area and was supported by the constructed surrogate model. Sammon mapping was also introduced to transform the decision variables from tens of dimensions to a few dimensions, in order to take advantage of Gaussian process surrogate modeling in a low-dimensional space.</p><p>Wang et al. <ref type="bibr" target="#b54">[55]</ref> divided data-driven optimization problems into two categories: 1) offline and 2) online data-driven optimization. An EA was then presented to optimize the design of a trauma system, which is a typical offline datadriven multiobjective optimization problem. As each single function evaluation involved a large amount of patient data, Wang et al. <ref type="bibr" target="#b54">[55]</ref> developed a multifidelity surrogate management strategy to reduce the computation time of the evolutionary optimization.</p><p>Mendes et al. <ref type="bibr" target="#b55">[56]</ref> proposed the use of genetic programming to obtain high-quality surrogate functions that were evaluated quickly. Such functions could be used to compute the values of the optimization functions in place of the burdensome methods. The proposal was tested successfully on a version of the TEAM 22 benchmark problem with uncertainties in decision parameters.</p><p>Kattan and Ong <ref type="bibr" target="#b56">[57]</ref> proposed a surrogate genetic programming (or sGP for short) to retain the appeal of the semantic-based evolutionary search for handling challenging problems with enhanced efficiency. The proposed sGP divided the population into two parts, then it evolved the population using standard GP search operators and meta-models that served as a surrogate to the original objective function evaluation. In contrast to previous works, two forms of metamodels were introduced in this paper to make the idea of using a surrogate in GP search feasible and successful.</p><p>Rosales-Pérez et al. <ref type="bibr" target="#b57">[58]</ref> introduced an approach for addressing model selection for support vector machines used in classification tasks. The model selection problem was transferred mathematically as a multiobjective one, aiming to minimize simultaneously two components closely related to the error of a model. A surrogate-assisted evolutionary multiobjective optimization approach was adopted to explore the hyper-parameters space. The surrogate-assisted optimization was used to reduce the number of solutions evaluated by the fitness functions so that the computational cost would be reduced as well.</p><p>Hildebrandt and Branke <ref type="bibr" target="#b58">[59]</ref> presented a new way to use surrogate models with GP. Rather than using the genotype directly as input to the surrogate model, they used a phenotypic characterization in their method. This phenotypic characterization could be computed efficiently, which allowed them to define approximate measures of equivalence and similarity. Using a stochastic, dynamic job shop scenario as an example of simulation-based GP with an expensive fitness evaluation, they demonstrated that these ideas can be used to construct surrogate models and improve the convergence speed and solution quality of GP.</p><p>PSO is one of the most excellent swarm intelligencebased metaheuristic algorithms <ref type="bibr" target="#b38">[39]</ref>, in which particles are updated according to the best individuals in the population and the best position for each particle so far. Lin et al. <ref type="bibr" target="#b59">[60]</ref> proposed a binary PSO based on surrogate information with proportional acceleration coefficients (BPSOSIPAC) for the 0-1 multidimensional knapsack problem (MKP). The BPSOSIPAC was based on the surrogate information concept to repair an infeasible particle and make the infeasible solution become a feasible one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Individual Information</head><p>ABC is a relatively new swarm intelligence-based metaheuristic algorithm <ref type="bibr" target="#b7">[8]</ref>. In the basic ABC, previous individuals were not reused at all. In addition, Gao et al. <ref type="bibr" target="#b60">[61]</ref> proposed a bare bones ABC called BABC that used parameter adaptation and fitness-based neighborhood. In BABC, the useful information in the best individual and a Gaussian search equation were used to generate a new candidate individual at the onlooker phase <ref type="bibr" target="#b60">[61]</ref>. On other hand, at the employed bee phase, the information from the previous search and from the better individuals was incorporated into the parameter adaptation strategy and a fitness-based neighborhood mechanism in order to improve the search ability <ref type="bibr" target="#b60">[61]</ref>.</p><p>GA has been applied successfully to address all kinds of engineering problems, especially in discrete optimization <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref>. Bingul <ref type="bibr" target="#b51">[52]</ref> first used information feedback in adaptive GAs for dynamic MOPs. Bingul transformed the multiobjective optimization problem into a singleobjective problem by using a static fitness function and rule-based weight fitness function. Bingul <ref type="bibr" target="#b51">[52]</ref> also used a square-based fitness function because it generated the best solutions among various types of fitness functions.</p><p>Gong et al. <ref type="bibr" target="#b61">[62]</ref> combined the advantages of the GA and PSO, and proposed a generalized "learning PSO" paradigm, the *L-PSO. In *L-PSO, genetic operators were used to generate exemplars according to the historical search information of particles. By performing crossover, mutation, and selection on the historical information of particles, the constructed exemplars were not only well diversified but also highly qualified.</p><p>Ly and Lipson <ref type="bibr" target="#b62">[63]</ref> proposed a strategy to select the most informative individuals in a teacher-learner type coevolution by using the surprisal of the mean, based on Shannon information theory. This selection strategy was verified by an iterative coevolutionary framework, which consisted of symbolic regression for model inference, and a GA for optimal experiment design.</p><p>In order to exploit fully both global statistical information and individual location information, Zhou et al. <ref type="bibr" target="#b63">[64]</ref> combined an estimation of distribution algorithm with computationally cheap and expensive local search (LS) methods.</p><p>Xiong et al. <ref type="bibr" target="#b64">[65]</ref> combined stochastic elements into a resource investment project scheduling problem (RIPSP), and proposed a stochastic extended RIPSPs. A knowledgebased multiobjective EA (K-MOEA) was proposed to solve the problem. In K-MOEA, the useful information in the obtained nondominated solutions (individuals) was extracted and then used to update the population periodically to guide subsequent search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Population/Swarm Information</head><p>Gao et al. <ref type="bibr" target="#b65">[66]</ref> proposed a novel ABC algorithm based on information learning, called ILABC. In ILABC, at each generation, the whole population was divided dynamically into several subpopulations by the clustering partition based on the previous search experience. Furthermore, the different individuals in one subpopulation and in different subpopulations exchanged information after all the individuals were updated. In this way, all the individuals would find the best solution cooperatively. In addition to ILABC, Gao et al. <ref type="bibr" target="#b66">[67]</ref> proposed another improved ABC algorithm using more informationbased search equations.</p><p>Inspired by the echo location behavior of bats in nature, BA was proposed for global optimization problems <ref type="bibr" target="#b46">[47]</ref>. The position of the bats was updated by the bats' frequency, velocity, and distance to food. Therefore, their position had no relationship with any kind of information reuse. Wang et al. <ref type="bibr" target="#b67">[68]</ref> proposed a multiswarm BA (MBA) for global optimization problems. In MBA, the information between different swarms was exchanged by an immigration operator with different parameter settings. Thus, this configuration was able to make a good tradeoff between global and LS.</p><p>With regard to DE, it is well accepted that two control parameters: 1) scale factor (F) and 2) crossover rate (Cr), have great influence on the performance of DE. Based on information from the population, Ghosh et al. <ref type="bibr" target="#b68">[69]</ref> proposed a simple yet useful adaptation technique for tuning F and Cr.</p><p>In order to boost the population diversity when addressing large-scale global problems, Ali et al. <ref type="bibr" target="#b69">[70]</ref> proposed a new, improved DE called mDE-bES. This version was a multipopulation algorithm, and the population was divided into independent subgroups, each with different mutation and update strategies. The information of the best individual was used to generate a novel mutation strategy that produced quality solutions with a balance between exploration and exploitation. At each generation, the individuals exchanged their information between the subgroups.</p><p>Cui et al. <ref type="bibr" target="#b70">[71]</ref> designed a novel adaptive multiple subpopulations-based DE named MPDE, in which the parent population was split into three subpopulations based on their fitness values. In MPDE, the useful information from the trial vectors and target vectors was exploited fully to form a replacement strategy that aimed to improve the search ability.</p><p>Inspired by team cooperation in the real world, Gao et al. <ref type="bibr" target="#b71">[72]</ref> proposed a dual-population DE (DPDE) with coevolution for constrained optimization problems (COPs). The COP was divided into two objectives that were solved by two subpopulations at each generation, respectively. In DPDE, an information-sharing strategy was used to exchange search information between the different subpopulations.</p><p>Wang et al. <ref type="bibr" target="#b72">[73]</ref> proposed a cooperative multiobjective DE (CMODE) with multiple populations for multiobjective optimization problems (MOPs), which included M singleobjective optimization subpopulations and an archive population for an M-objective optimization problem. These (M + 1) populations cooperated to optimize all objectives of MOPs by using adaptive DEs. The additional difference term was added to the proposed method with the aim of sharing information from the archive. In this way, an individual could use the search information not only from its own subpopulation but also from other populations. The individual was expected to search along the whole Pareto front (PF) by using the information of all the populations instead of being attracted to the margin or extreme point only by the search information of its own subpopulation. Hence, CMODE could approximate the whole PF quickly with the help of the archived information.</p><p>Dhal et al. <ref type="bibr" target="#b73">[74]</ref> proposed two variants of FA: 1) FA via Lévy flights and 2) FA via chaotic sequence. In these two algorithms, the information of population diversity was fully extracted to generate the individuals at each generation.</p><p>Pan et al. <ref type="bibr" target="#b74">[75]</ref> proposed a local-best HS algorithm with dynamic subpopulations (DLHS) for global optimization problems. In DLHS, the whole harmony memory (HM) was divided into a certain number of small-sized sub-HMs that exchanged information with each other by using a periodic regrouping schedule. Furthermore, the useful information in the local best harmony vector was used to generate a novel harmony improvisation scheme <ref type="bibr" target="#b74">[75]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Information From Dynamical Environments</head><p>Though many versions of multiobjective PSO (MOPSO) have been designed, few MOPSOs have been designed to adjust the balance between exploration and exploitation dynamically according to the feedback information detected from the evolutionary environment. Hu and Yen <ref type="bibr" target="#b75">[76]</ref> proposed a new algorithm, the parallel cell coordinate system (PCCS), according to the information about the evolutionary environment, including density, rank, and diversity indicators. PCCS was then incorporated into a self-adaptive MOPSO, and a new MOPSO was proposed: the pcc-sAMOPSO.</p><p>Foss investigated how a viable system, the honey bee swarm, gathered meaningful information about potential new nest sites in its problematic environment <ref type="bibr" target="#b76">[77]</ref>. This investigation used a cybernetic model of a self-organizing information network to analyze the findings from the last 60 years of published research about swarm behavior. Information gathering by a honey bee swarm was first modeled as a self-organizing information network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Neighborhood and Direction Information</head><p>In the basic DE, the base and difference vectors are always selected randomly from the whole population for the mutation operators, but the neighborhood and direction information fails to be used effectively <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b77">[78]</ref>, <ref type="bibr" target="#b78">[79]</ref>. In order to address this problem, several scholars have put forward improved strategies.</p><p>Peng et al. <ref type="bibr" target="#b79">[80]</ref> proposed a novel DE framework with distributed direction information-based mutation operators (DE-DDI) for dealing with complex problems in big data. In DE-DDI, the distributed topology was used to generate a neighborhood for each individual first. Then the direction information derived from the neighbors was introduced into the mutation operator of DE. Consequently, the neighborhood and direction information fully exploited the regions of better individuals, and guided the search to the promising area.</p><p>Liao et al. <ref type="bibr" target="#b80">[81]</ref> proposed another DE framework with a directional mutation based on cellular topology, called cellular direction information-based DE (DE-CDI). For each individual in DE-CDI, the cellular topology was formed to define a neighborhood. Next, the direction information based on the neighborhood was incorporated into the mutation operator. In this way, DE-CDI not only extracted the neighborhood information to exploit the regions of better individuals and accelerate convergence but also introduced the direction information to guide the search to the promising area.</p><p>In order to use the neighborhood and direction information fully, Cai et al. <ref type="bibr" target="#b81">[82]</ref> proposed a new DE framework with neighborhood and direction information (NDi-DE). Though NDi-DE had better performance than most of the DEs, its performance relied mainly on the selection of direction information. To overcome this disadvantage, the adaptive operator selection mechanism was incorporated into the NDi-DE, which was able to select adaptively the direction information for the specific DE mutation strategy. Accordingly, an improved NDi-DE called adaptive direction information-based NDi-DE (aNDi-DE) was proposed by Cai et al. <ref type="bibr" target="#b81">[82]</ref>, which performed much better than NDi-DE.</p><p>Fang et al. <ref type="bibr" target="#b82">[83]</ref> proposed a decentralized quantum-inspired PSO (QPSO) with cellular structured population called cQPSO. In cQPSO, the particles were located in a 2-D grid and allowed to get information only from their neighbors. The overlapping particles exchange the information among the nearest neighborhoods.</p><p>Wang et al. <ref type="bibr" target="#b83">[84]</ref> proposed an improved version of BA namely variable neighborhood bat algorithm (VNBA), is thus proposed. In VNBA, the bat individual can get useful information from their neighbors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Mutual Information</head><p>He et al. <ref type="bibr" target="#b84">[85]</ref> introduced the multiresolution analysis, MI, and PSO into artificial neural network models. They proposed a hybrid wavelet neural network model for forecasting monthly rainfall from antecedent monthly rainfall and climate indices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Other Information</head><p>ACO is one of the most representative metaheuristic algorithms for global optimization problems, especially, for discrete optimization <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b48">[49]</ref>. Because the ants are updated according to the pheromone, the previous information fails to be used in ACO.</p><p>Shang et al. <ref type="bibr" target="#b85">[86]</ref> introduced heuristic information into antdecision rules, and then proposed a new version of ACO named AntMiner for epistasis detection. In AntMiner, the heuristic information was used to guide ants during the search process with the aim of enhancing the computational efficiency and solution accuracy.</p><p>Wang and Tang <ref type="bibr" target="#b86">[87]</ref> proposed an adaptive DE based on analysis of search data for the MOPs. In this algorithm, first the useful information was derived from the search data during the evolution process by using clustering and statistical methods. Then the derived information was used to guide the generation of new population and the LS.</p><p>Park and Lee <ref type="bibr" target="#b87">[88]</ref> proposed a novel opposition-based learning method by using a beta distribution with partial dimensional change and selection switching. They combined this approach with DE to enhance the convergence speed and search ability. In the proposed method, the partial dimensional changing scheme was used to preserve useful information.</p><p>Simulated annealing (SA) is one of the oldest classical metaheuristic algorithms <ref type="bibr" target="#b88">[89]</ref> that is a trajectory-based optimization algorithm. Yang and Kumar <ref type="bibr" target="#b89">[90]</ref> proposed an information guided framework for SA. Information gathered from the exploration stage was used as feedback to drive the optimization procedure, leading to the rise of the annealing temperature during the optimization process. The resulting algorithm had two phases: phase I performed nearly unrestricted exploration, and phase II "re-heated" the annealing procedure and exploited information gathered during phase I.</p><p>Muñoz et al. <ref type="bibr" target="#b90">[91]</ref> proposed a robust information contentbased method for continuous fitness landscapes that generated four measures related to the landscape features. In addition, it could overcome the disadvantage of sampling the fitness landscape using random walks with variable step size.</p><p>From the descriptions above, we can see that for most metaheuristic algorithms, some useful information obtained from a surrogate, an individual, the whole population/swarm, dynamical environments, neighbor and direction, and/or mutual relationship is extracted and reused to a certain degree. However, few of them are based on a fitness function (except <ref type="bibr" target="#b51">[52]</ref>). Bingul <ref type="bibr" target="#b51">[52]</ref> transferred the MOP into some single-objective problems by using a fitness function as explained previously. Furthermore, while most of the studies above aimed to improve the performance of a certain metaheuristic algorithm by reusing the exploited information, they failed to form a general framework for reusing the obtained information.</p><p>In this paper, we present our research, based on a fitness function, in which we constructed a systematic information feedback model that reused the information from individuals in previous iterations. This proposed information feedback model was demonstrated to provide a general framework that could be used to improve the performance of most metaheuristic algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. IMPROVING METAHEURISTIC ALGORITHMS WITH INFORMATION FEEDBACK MODELS</head><p>In this section, we explain how metaheuristic algorithms have been improved based on information feedback models. First, we provide a brief outline of the basic optimization process, and then we give a description of the information feedback models. Finally, using PSO as an example, we demonstrate how to improve the algorithm using information feedback models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Optimization Process</head><p>Despite the fact that different metaheuristic algorithms have different updating strategies, their optimization processes can be summarized briefly by the following general steps.</p><p>1) Initialization: Initialization can be divided into population initialization and parameter initialization. The running environments for later search are set during this process.</p><p>2) Search: In general, metaheuristic algorithms first implement global search and then LS, i.e., exploration and then exploitation. These two searches perform in parallel, being adjusted by certain parameters. The search process is repeated until some termination condition is satisfied.</p><p>3) Output: Output the final best solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Information Feedback Models</head><p>In theory, for our model k(k ≥ 1) previous individuals can be selected, but using a substantial number of individuals might complicate the method. Therefore, in this paper, k ∈ {1, 2, 3}. As mentioned above, we will take PSO as an example to illustrate the framework of our proposed method. Some symbols are given before the information feedback models are described.</p><p>Suppose that x t i is the ith individual at iteration t, and x i and f t i are its position and fitness value, respectively. Here, IEEE TRANSACTIONS ON CYBERNETICS t is the current iteration, 1 ≤ i ≤ N P is an integer number, and N P is the population size. y t+1 i is the individual generated by the basic PSO, and f t+1 i is its fitness. The framework of the proposed method is given through the individuals at the (t -2)th, (t -1)th, tth, and (t + 1)th iterations.</p><p>1) Model F1 and Model R1: This is the simplest case. The ith individual x t+1 i can be generated as follows:</p><formula xml:id="formula_0">x t+1 i = αy t+1 i + βx t j (1)</formula><p>where x t j is the position for individual j(j ∈ {1, 2, . . . , N P }) at iteration t, and f t j is its fitness. α and β are weighting factors satisfying α + β = 1. They can be given as</p><formula xml:id="formula_1">α = f t j f t+1 i + f t j , β = f t+1 i f t+1 i + f t j . (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>Here, individual j can be determined in the following ways.</p><p>Definition 1: The model in ( <ref type="formula">1</ref>) is called model F1 when j = i.</p><p>The individuals in previous and current generations are used to generate the individual for the next generation.</p><p>Definition 2: The model in ( <ref type="formula">1</ref>) is called model R1 when j = r 1 , where r 1 is an integer randomly selected between 1 and N P .</p><p>The individual generated by Definition 2 has a higher population diversity than the one generated by Definition 1. We can see that if r 1 = i, the model R1 will be F1 with the probability of 1/N P . Their incorporation into the basic PSO results in PSOF1 and PSOR1, respectively.</p><p>2) Model F2 and Model R2: Two individuals at two previous iterations are collected and used to generate individual i. For this case, the ith individual x t+1 i can be generated as follows:</p><formula xml:id="formula_3">x t+1 i = αy t+1 i + β 1 x t j 1 + β 2 x t-1 j 2<label>(3)</label></formula><p>where x t j 1 and x t-1 j 2 are the position for individuals j 1 and j 2 (j 1 , j 2 ∈ {1, 2, . . . , N P }) at iteration t and t -1, and f t j 1 and f t-1 j 2 are their fitness values, respectively. α, β 1 , and β 2 are weighting factors satisfying α +β 1 +β 2 = 1. They can be provided as follows:</p><formula xml:id="formula_4">α = 1 2 • f t-1 j 2 + f t j 1 f t+1 i + f t-1 + f t j 1 β 1 = 1 2 • f t-1 j 2 + f t+1 i f t+1 i + f t-1 j 2 + f t j 1 β 2 = 1 2 • f t+1 i + f t j 1 f t+1 i + f t-1 j 2 + f t j 1 . (<label>4</label></formula><formula xml:id="formula_5">)</formula><p>Individuals j 1 and j 2 in (3) can be determined in several different ways. For this model, this paper focused on Definitions 3 and 4.</p><p>Definition 3: The model in ( <ref type="formula" target="#formula_3">3</ref>) is called model F2 when</p><formula xml:id="formula_6">j 1 = j 2 = i.</formula><p>The individuals at two previous and current generations are used to generate the individual for the next generation.</p><p>Definition 4: The model in ( <ref type="formula" target="#formula_3">3</ref>) is called model R2 when j 1 = r 1 , and j 2 = r 2 , where r 1 and r 2 are integers that are randomly selected between 1 and N P .</p><p>Similarly, the individual generated by Definition 4 has more diversity of population than the individual generated by Definition 3. Here, we can see, if r 1 = r 2 = i, the model R2 will be F2 with the probability of 1/N P . Their incorporation into the basic PSO results in PSOF2 and PSOR2, respectively.</p><p>3) Model F3 and Model R3: Three individuals at three previous iterations are collected and used to generate individual i. For this case, the ith individual x t+1 i can be generated as follows:</p><formula xml:id="formula_7">x t+1 i = αy t+1 i + β 1 x t j 1 + β 2 x t-1 j 2 + β 3 x t-2 j 3<label>(5)</label></formula><p>where x t j 1 , x t-1 j 2 , and x t-2 j 3 are the position of individuals j 1 , j 2 , and j 3 (j 1 , j 2 , j 3 ∈ {1, 2, . . . , N P }) at iteration t, t -1, and t -2, and f t j 1 , f t-1 j 2 , and f t-2 j 3</p><p>are their fitness values, respectively. Their weighting factors are α, β 1 , β 2 , and β 3 with α + β 1 + β 2 + β 3 = 1, which can be given as</p><formula xml:id="formula_8">α = 1 3 • f t j 1 + f t-1 j 2 + f t-2 j 3 f t+1 i + f t j 1 + f t-1 j 2 + f t-2 j 3 β 1 = 1 3 • f t+1 i + f t-1 j 2 + f t-2 j 3 f t+1 i + f t j 1 + f t-1 j 2 + f t-2 j 3 β 2 = 1 3 • f t+1 i + f t j 1 + f t-2 j 3 f t+1 i + f t j 1 + f t-1 j 2 + f t-2 j 3 β 3 = 1 3 • f t+1 i + f t j 1 + f t-1 j 2 f t+1 i + f t j 1 + f t-1 j 2 + f t-2 j 3 . (<label>6</label></formula><formula xml:id="formula_9">)</formula><p>Though j 1j 3 can be determined in many different ways, we adopted Definitions 5 and 6 for this model.</p><p>Definition 5: The model in ( <ref type="formula" target="#formula_7">5</ref>) is called model F3 when</p><formula xml:id="formula_10">j 1 = j 2 = j 3 = i.</formula><p>The individuals at two previous and current generations are used to generate the individual for the next generation.</p><p>Definition 6: The model in ( <ref type="formula" target="#formula_7">5</ref>) is called model R3 when j 1 = r 1 , j 2 = r 2 , and j 3 = r 3 , where r 1r 3 are integer numbers that are selected randomly between 1 and N P .</p><p>Similarly, the individual generated by Definition 6 has more population diversity. Here, we can see that if r 1 = r 2 = r 3 = i, model R3 will be F3 with the probability of 1/N P . Their incorporation into the basic PSO results in PSOF3and PSOR3, respectively.</p><p>By incorporating the information feedback model into the basic optimization process, we have a new updating optimization process as shown in Fig. <ref type="figure" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. PSO Using Model F1</head><p>We now take PSO and model F1 as an example to explain how to introduce information feedback into a metaheuristic algorithm.</p><p>PSO <ref type="bibr" target="#b38">[39]</ref> is one of the most representative swarm intelligence paradigms. The solutions (called particles) are located initially in the whole search region at random. Subsequently, the velocity and position of the particles are updated as <ref type="bibr" target="#b6">(7)</ref> and ( <ref type="formula" target="#formula_13">8</ref>), respectively.</p><formula xml:id="formula_11">v t+1 i = ωv t i + c 1 r 1 p i,best -x i + c 2 r 2 g i,best -x i (<label>7</label></formula><formula xml:id="formula_12">)</formula><formula xml:id="formula_13">x t+1 i = x t i + v t+1 i (<label>8</label></formula><formula xml:id="formula_14">)</formula><p>where x i and v i are the position and velocity of particle i, respectively; p i,best and g i,best are the position with the optimal objective value searched until now by particle i and the whole population, respectively; w is an inertia parameter controlling the dynamics of flying; r 1 and r 2 are random real numbers in [0, 1]; and c 1 and c 2 are factors controlling the related weighting of corresponding terms. After updating velocity and position for particle i, p i,best and g i,best will be updated. This process will be repeated until a certain stop condition is met.</p><p>Next, looking at the general outline of the optimization process, we can see the main steps for improving PSO by using the information feedback model (k = 1).</p><p>1) Initialization: The parameters used in PSO are set, and the particle population is initialized randomly with the predefined regions. This process is the same as performed in the basic PSO.</p><p>2) Search: This is the critical part for improving PSO. First, the velocity and position of particle i are updated according to <ref type="bibr" target="#b6">(7)</ref> and <ref type="bibr" target="#b7">(8)</ref>. The updated particle can be called y i . If the generation count t is bigger than 1, particle i will be further updated by <ref type="bibr" target="#b0">(1)</ref>, and the newly generated particle will be considered as Fig. <ref type="figure">2</ref>. Improving PSO with information feedback models (k = 1). the final particle for the next generation. The search process is repeated until some termination condition is satisfied.</p><p>3) Output: PSO returns the values of g best and f (g best ) as its final solution.</p><p>The detailed steps of the combination of PSO and the information feedback model (k = 1) can be seen in Fig. <ref type="figure">2</ref>. In Fig. <ref type="figure">2</ref>, G max is the maximum of the generation.</p><p>Similarly, the other five models (R1-3, F2-3) can be incorporated into the basic PSO. Given the limits on the length of this paper, we will not describe them in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. MATHEMATICAL ANALYSES</head><p>In this section, we provide a mathematical analysis to prove the convergence of the proposed method. We first prove the algorithm under model F3 and R3. Here, the following lemmas are provided, and they are true for any algorithm discussed in this paper.</p><p>Lemma 1: An algorithm A can reach its final solution x best all of the time.</p><p>Here, algorithm A can be any of the algorithms discussed in this paper, such as ACO <ref type="bibr" target="#b5">[6]</ref>, BA <ref type="bibr" target="#b46">[47]</ref>, BBO <ref type="bibr" target="#b28">[29]</ref>, CS <ref type="bibr" target="#b13">[14]</ref>, DE <ref type="bibr" target="#b9">[10]</ref>, ES <ref type="bibr" target="#b12">[13]</ref>, KH <ref type="bibr" target="#b20">[21]</ref>, MBO <ref type="bibr" target="#b35">[36]</ref>, PBIL <ref type="bibr" target="#b36">[37]</ref>, and PSO <ref type="bibr" target="#b38">[39]</ref>.</p><p>x best is the best solution for algorithm A, and its lower bound and upper bound are x min and x max , respectively. Lemma 1 indicates that algorithm A is able to find the final solution all of the time, if it can search for the given domain with enough time. Proof: Here, we only prove that the lower bound and upper bound of x t+1 i for algorithm A are x min and x max , respectively. For ease of description, (5) can be described in the following form:</p><formula xml:id="formula_15">x t+1 i = αy i + β 1 x 1 + β 2 x 2 + β 3 x 3 . (<label>9</label></formula><formula xml:id="formula_16">)</formula><p>It is clear that for algorithm A, the lower bound and upper bound of the solutions x 1 , x 2 , and x 3 are x min and x max , respectively. In other words, x min ≤ y i ≤ x max , x min ≤ x 1 ≤ x max , x min ≤ x 2 ≤ x max , and x min ≤ x 3 ≤ x max .</p><p>Next, we can get α ×</p><formula xml:id="formula_17">x min ≤ α × y i ≤ α × x max , β 1 × x min ≤ β 1 × x 1 ≤ β 1 × x max , β 2 × x min ≤ β 2 × x 2 ≤ β 2 ×</formula><p>x max , and</p><formula xml:id="formula_18">β 3 × x min ≤ β 3 × x 3 ≤ β 3 × x max . Therefore, we get (α + β 1 + β 2 + β 3 ) × x min ≤ x t+1 i = αy i + β 1 x 1 + β 2 x 2 + β 3 x 3 ≤ (α + β 1 + β 2 + β 3 ) × x max . (<label>10</label></formula><formula xml:id="formula_19">)</formula><p>According to the definition of α, β 1 , β 2 , and β 3 in (5), we know α + β 1 + β 2 + β 3 = 1. Therefore, (10) can be updated as</p><formula xml:id="formula_20">x min ≤ x t+1 i = αy i + β 1 x 1 + β 2 x 2 + β 3 x 3 ≤ x max . (11)</formula><p>We observe clearly that x min ≤x t+1 i ≤ x max . In other words, the newly generated solution x t+1 i via our proposed method is a feasible solution for algorithm A.</p><p>Theorem 3: A proposed algorithm A can reach its final solution x best all the time.</p><p>Proof: Here, A represents the proposed algorithm discussed in the previous section. Therefore, according to Lemmas 1 and 2, the proposed algorithm A is able to find the final solution x best if it can search for the given domain with enough time.</p><p>For Models F1-2 and R1-2, it is obvious that these models are special cases of Models F3 and R3. Therefore, any proposed algorithm A is similarly proven. We do not give them in detail in this paper.</p><p>In sum, for each information feedback model, where the model is Model F1-F3 or R1-R3, an algorithm A under these models can reach its final solution x best every time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. SIMULATION RESULTS</head><p>Section III gives six information feedback models, i.e., F1-F3 and R1-R3, each of which can be incorporated into a basic metaheuristic algorithm, thereby, yielding six variants of each basic method. For example, given PSO, we have PSOF1-3 and PSOR1-3. The basic PSO can be named as PSOF0. Simply, we can call them F0-F3, and R1-R3 for short.</p><p>We must point out that in order to investigate fully the superiority of different information feedback models, six variants were compared with each other only and with the corresponding basic algorithm. Through this comparison, we were able to look at the performance of six information feedback models and determine whether these models could improve the performance of the basic algorithm.</p><p>Six information feedback models were combined with the basic metaheuristic algorithms, and these newly combined methods were further benchmarked by 14 standard test functions as shown in Table <ref type="table">I</ref>  <ref type="bibr" target="#b28">[29]</ref>. Each function had 20 independent variables, that is, the dimension of each problem was 20. Some of functions were multimodal, which means that they had multiple local minima. Some were nonseparable, which means that they could not be written as a sum of functions of individual variables.</p><p>The benchmarks were compared by implementing the integer versions of all the metaheuristic algorithms in MATLAB <ref type="bibr" target="#b28">[29]</ref>. The granularity or precision of each benchmark function was 0.1, except for the Quartic function. Since the domain of each dimension of the Quartic function was only ±1.28, it was implemented with a granularity of 0.01 <ref type="bibr" target="#b28">[29]</ref>. More information about these functions can be seen by referring to <ref type="bibr" target="#b28">[29]</ref>.</p><p>First, we investigated the performance of PSO under Models F1-F3 and R1-R3, and then these six models were extended to be incorporated into more metaheuristic algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Performance of PSO With Models F1-F3 and R1-R3</head><p>In this section, we will look at the performance of PSO under Models F1-F3 and R1-R3 on 14 benchmarks in Table <ref type="table">I</ref>.</p><p>In order to get their representative statistical results, 50 independent runs were done for PSO. In addition, PSO had a population size of 50, an elitism parameter of 2, and was run for 50 generations. The results were recorded in Table <ref type="table" target="#tab_1">II</ref>.</p><p>In more detail, the best, average, and worst performances of each method were collected, as shown in Table <ref type="table" target="#tab_1">II</ref>. The results were highlighted in bold if PSO performed the best on a benchmark. The total numbers of the bold results were collected, as shown in the last row in Table <ref type="table" target="#tab_1">II</ref>. In order to investigate the influence of F1-3 and R1-3, the number of functions on which PSO performed the best was calculated, as shown in the last two columns of Table <ref type="table" target="#tab_1">II</ref>.</p><p>From Table <ref type="table" target="#tab_1">II</ref>, we see that R1 was the best information feedback model, having the greatest impact on PSO. F3 was inferior only to R1. In addition, for six information feedback models and F0, their average ranking from good to bad was as follows: R1 &gt; F3 &gt; R3 &gt; F2 &gt; F0 &gt; R1 &gt; F1 = R2. Models R1-3 have slightly greater impact than F1-3 for the PSO algorithm on 14 benchmarks <ref type="bibr">(21 versus 18)</ref>.</p><p>From Table <ref type="table" target="#tab_1">II</ref>, we can see that our six proposed models, especially R1 and F3, were able to improve significantly the performance of PSO by balancing the exploration and exploitation. Let us give the detailed analyses as follows.</p><p>In PSO, particle i learned mainly from the information of the global search and its own best position. On one hand, this situation meant that most particles would fly toward the promising area, and the PSO would have a fast convergence. That is to say, PSO would have a good exploration ability. On other hand, if the optimal were local, it would be hard to escape from it. R1 introduced diversity into the optimization process of PSO, which would enable the trapped particles to escape from the local positions. If the particles were not trapped into local positions, the addition of population diversity did no harm to PSO, because the global best particle was always memorized during the whole optimization process. This is why F3 performed better than other models except R1. In sum, the PSO combined with six proposed models (especially Models R1 and F3) performed better than or equally to the basic PSO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Performance of Six Information Feedback Models</head><p>In this section, we explain how six information feedback models were combined with other nine metaheuristic algorithms, i.e., ACO <ref type="bibr" target="#b5">[6]</ref>, BA <ref type="bibr" target="#b46">[47]</ref>, BBO <ref type="bibr" target="#b28">[29]</ref>, CS <ref type="bibr" target="#b13">[14]</ref>, DE <ref type="bibr" target="#b9">[10]</ref>, ES <ref type="bibr" target="#b12">[13]</ref>, KH <ref type="bibr" target="#b20">[21]</ref>, MBO <ref type="bibr" target="#b35">[36]</ref>, and PBIL <ref type="bibr" target="#b36">[37]</ref>. These newly combined methods were further benchmarked by 14 standard test functions, as shown in Table <ref type="table">I</ref>  <ref type="bibr" target="#b28">[29]</ref>.</p><p>For an algorithm, different parameter settings have a great impact on its performance. In order to compare fairly, their parameters were set as shown in Table <ref type="table" target="#tab_1">III</ref>. For ACO, BBO, DE, ES, PBIL, and PSO, their parameters were the same as in <ref type="bibr" target="#b28">[29]</ref>.</p><p>For most algorithms, different runs may generate different results. In order to get their representative statistical results, 50 independent runs were done for each method. In addition, each method had a population size of 50, an elitism parameter of 2, and were run for 50 generations. The best, average, and worst performances of each method were collected and summarized in Table <ref type="table">IV</ref>. The results were highlighted in bold if the algorithms performed the best for a benchmark. In order to investigate the influence of F1-3 and R1-3, the number of functions on which the metaheuristic algorithms performed the best was calculated, as shown in the last two columns of Table <ref type="table">IV</ref>  method on each benchmark. We must point out that PSO was also included in Tables IV and V in order to get more accurate statistical From Table <ref type="table">IV</ref>, we see that F2 was the best information feedback model, and had the greatest impact on the three algorithms: 1) BA; 2) CS; and 3) MBO. R1 is inferior only to F2 and had the greatest impact on three algorithms: 1) ES; 2) KH; and 3) PSO. F1 ranked third and had the greatest impact on two algorithms: 1) BBO and 2) DE. For R2 and R3, except ACO, they had the best impact on MBO and PBIL, respectively. Looking carefully at Table IV, for ACO, R2, and R3 had the same impact; for MBO, F2, and R2 had the same impact. In addition, for six information feedback models and F0, their average ranking from good to bad was as follows: F2 &gt; R1 &gt; F1 &gt; F3 = R3 &gt; F0 &gt; R2. Models F1-3 had a greater impact than R1-3 for ten metaheuristic algorithms on 14 benchmarks (230 versus 163).</p><p>From Table <ref type="table">V</ref>, we observed that, except BA, all the variants consumed more time than their respective basic algorithms. This result falls fully under the adage, "there is no free lunch" <ref type="bibr" target="#b91">[92]</ref>. The additional time was used mainly to evaluate the fitness values, and that action can be time consuming.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Comparisons Using t-Test</head><p>Based on the final results of 50 independent runs on 14 functions, Table VI presents the t values on every function of the two-tailed test, with the 5% level of significance between the basic method and improved methods with six information Boldface indicates that the corresponding method performed significantly better than the basic method. The best, equal, and worst VI indicate that the corresponding method performed better than, equal or worse than its basic one. In more detail, the best, equal, and worst performance of each method was collected and summarized, as shown in Table <ref type="table" target="#tab_5">VI</ref>. For instance, comparing ACO and six variants of ACO, ACOF1-3, and ACOR1-3 outperformed ACO significantly on ten, twelve, eleven, twelve, ten, and eleven functions, respectively, and performed as well as ACO on two, one, one, zero, two, and one functions, respectively. These results indicate that six variants of ACO generally performed better than ACO in terms of the solution accuracy. Though the performance of ACOF1-3 and ACOR1-3 was slightly weaker on some functions, Table VI also reveals that they outperformed ACO on most functions.</p><p>Similarly, Table <ref type="table" target="#tab_5">VI</ref> shows that most methods (ACO, BA, CS, DE, ES, MBO, PBIL, and PSO) had absolute advantage over their basic algorithms. The performance of BBO and KH was better than or equal to their basic ones on most benchmarks. In addition, as seen from the last three rows of Table VI, R1 was the best information model; F1, R1, and F2 were the three best models among the six different information feedback models. This conclusion coincides with results in Table <ref type="table">IV</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Real World Problems</head><p>In addition to the standard functions discussed in the section above, ten more real world problems (RWPs) (see Table <ref type="table" target="#tab_6">VII</ref>) were also used to validate the six information feedback models. More detailed information about ten RWPs can be found in <ref type="bibr" target="#b92">[93]</ref>.</p><p>Here, the parameters used in the ten approaches were the same as the above. The population size and generations were set to 50 and 50, respectively. The results obtained by 50 independent runs on ten RWPs were recorded in Table <ref type="table" target="#tab_6">VIII</ref>. The results were highlighted in bold if an algorithm performed the best on a benchmark. For each model, the total numbers of the bold results were collected, as shown in the last row.</p><p>From Table <ref type="table" target="#tab_6">VIII</ref>, we see that F1 was the best information feedback model, and had the greatest impact on the three metaheuristic algorithms: 1) BBO; 2) MBO; and 3) PSO. R1 was only slightly inferior to F1 and had the greatest impact on five metaheuristic algorithms: 1) ACO; 2) BA; 3) ES; 4) KH; and 5) PBIL. F2 ranked the third and had the greatest impact on three metaheuristic algorithms: 1) BA; 2) CS; and 3) KH. For the other three information feedback models (R2, F3, and R3), F3 had a greater influence on ten metaheuristic algorithms than R2 and R3. For KH, we can see, R1 and F2 had equal influence. Moreover, for BBO, F1 had the same performance as F0 (the basic BBO). For PBIL, R1 had the same performance as F0 (the basic PBIL). In addition, for six information feedback models and F0, their average ranking from good to bad was as follows: F1 &gt; R1 &gt; F0 &gt; F2 &gt; F3 &gt; R2 &gt; R3. Models F1-3 had a greater impact than R1-3 for ten metaheuristic algorithms on ten RWPs (155 versus 89). From the results on 14 standard functions and ten RWPs, F1, R1, and F2 performed the best among six information models.</p><p>Except RWPs studied here, there are many difficult issues deserving to be extensively studied, like cloud data <ref type="bibr" target="#b93">[94]</ref>, encrypted outsourced data <ref type="bibr" target="#b94">[95]</ref>, <ref type="bibr" target="#b95">[96]</ref>, and image copy detection <ref type="bibr" target="#b96">[97]</ref>. Shen et al. <ref type="bibr" target="#b93">[94]</ref> designed a new efficient and effective public auditing protocol with novel dynamic structure for cloud data with the aim of decreasing the computational and communication overheads. Devising a searchable and desirable encryption scheme cannot only support personalized search but also improve user search experience. For this purpose, Fu et al. <ref type="bibr" target="#b95">[96]</ref> handled the issue of personalized multikeyword ranked search over encrypted data while preserving privacy in cloud computing. Fu et al. <ref type="bibr" target="#b94">[95]</ref> presented a contentaware search scheme, which can make semantic search more smart. In addition, they verified the privacy and efficiency of their schemes in the experiments. Zhou et al. <ref type="bibr" target="#b96">[97]</ref> designed a global context verification scheme to filter false matches for copy detection. Concretely, the overlapping region-based global context descriptor was designed to verify these matches to filter false matches. Gu and Sheng <ref type="bibr" target="#b97">[98]</ref> proposed an equivalent dual formulation for v-SVC and a robust v-SvcPath based on lower upper decomposition with partial pivoting. Also, their robust regularization path algorithm can avoid the exceptions completely, and handling the singularities in the key matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. DISCUSSION</head><p>From the experiments conducted in the previous section, each of the ten algorithms was improved by a particular information feedback model. Here, KH is taken as an example to analyze why the information feedback model can improve the performance of all of the algorithms on 14 functions.</p><p>KH is a relatively new and promising algorithm proposed by Gandomi and Alavi in 2012 <ref type="bibr" target="#b20">[21]</ref>. R1 had the greatest impact on KH among six information feedback models, i.e., k = 1, and j = r 1 in (1). For krill i, the first and second movements are based mainly on the best krill <ref type="bibr" target="#b20">[21]</ref>. This will surely make most krill move toward the promising area. However, at the later search stage, the KH algorithm might be trapped into the local optimum. R1 added more diversity to the population for the optimization process at the later search stage. Meanwhile, the generated krill had a smaller possibility of surpassing the given range. So, the performance of KH was improved significantly.</p><p>In addition, different models were able to create a good balance between exploration and exploitation. When k was small, few of the previous individuals were used. In this way, the ability of exploration could be improved. Conversely, when k was big, as many of the previous individuals were used as possible. In this way, the ability of exploitation could be greatly improved. On other hand, the algorithms under models R1-3 had more population diversity and explorative ability than models F1-3. This could improve significantly the performance of the metaheuristic algorithms at the late stage.</p><p>After fully investigating the performance of the proposed methods, the following points should be highlighted in future.</p><p>First, the variants of a basic method (except BA) consume more CPU time than the basic one because of increased fitness evaluation. Methods to reduce CPU time are worthy of further study. Second, KH and PSO were taken as examples to explain the principle of our models. Further analysis using theories should be performed to ascertain the reasons why the models can improve the performance of their basic algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION</head><p>In the study of optimization, few metaheuristic algorithms reuse the previous information to guide the later updating process. In this paper, we extracted and used the previous information in the population to give feedback to the main optimization process. One, two, and three individuals in previous iterations were selected by either fixed or random method. Accordingly, six information feedback models were proposed, and they were then incorporated ten algorithms. The final individual at the current iteration updated based on the basic algorithm plus some selected previous individuals by using a simple fitness weighting method.</p><p>By incorporating six information feedback models into we constructed variants of each basic method. They were compared with each other as well as with their basic algorithms via 14 functions and ten CEC 2011 RWPs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Schematic flowchart of updating optimization process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II FUNCTION</head><label>II</label><figDesc>FITNESS OBTAINED BY PSO WITH SIX MODELS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>. TableVshows the average CPU time for each</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE VI COMPARISONS</head><label>VI</label><figDesc>BETWEEN THE BASIC METHOD AND SIX IMPROVED METHODS WITH INFORMATION FEEDBACK MODELS AT α=0.05 ON TWO-TAILED t-TESTS</figDesc><table /><note><p>feedback models. In the table, the value of t with 98 degrees of freedom was at α = 0.05 by two-tailed test.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VII TEN</head><label>VII</label><figDesc>REAL WORLD PROBLEMS SELECTED FROM CEC 2011</figDesc><table /></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the National Natural Science Foundation of China under Grant 61503165, Grant 61673025, Grant 61375119, and Grant 61673196, in part by the Natural Science Foundation of Jiangsu Province under Grant BK20150239, in part by the Beijing Natural Science Foundation under Grant 4162029, and in part by the National Key Basic Research Development Plan (973 Plan) Project of China under Grant 2015CB352302. This paper was recommended by Y. S. Ong.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Adaptive replacement strategies for MOEA/D</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="474" to="486" />
			<date type="published" when="2016-02">Feb. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Limited rationality and its quantification through the interval number judgments with permutations</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-G</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4025" to="4037" />
			<date type="published" when="2017-12">Dec. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">TOPSIS-based consensus model for group decision-making with incomplete interval fuzzy preference relations</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-G</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1283" to="1294" />
			<date type="published" when="2014-08">Aug. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A goal programming model for incomplete interval multiplicative preference relations and its application in group decision-making</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">218</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="747" to="754" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">High performance computing for cyber physical social systems by using evolutionary multi-objective optimization algorithm</title>
		<author>
			<persName><forename type="first">G.-G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1109/TETC.2017.2703784</idno>
		<ptr target="http://ieeexplore.ieee.org/document/7927724/" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Emerg. Topics Comput</title>
		<imprint/>
	</monogr>
	<note>to be published. [Online</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Ant Colony Optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Stutzle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Protein classification via an ant-inspired association rules-based classifier</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shahzad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Baig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Bio Inspired Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="65" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A powerful and efficient algorithm for numerical function optimization: Artificial bee colony (ABC) algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Basturk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Glob. Optim</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="459" to="471" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An improved artificial bee colony algorithm for solving hybrid flexible flowshop with dynamic operation skipping</title>
		<author>
			<persName><forename type="first">J.-Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q.-K</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-Y</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1311" to="1324" />
			<date type="published" when="2016-06">Jun. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Differential evolution-A simple and efficient heuristic for global optimization over continuous spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Glob. Optim</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Differential evolution with an evolution path: A DEEP evolutionary algorithm</title>
		<author>
			<persName><forename type="first">Y.-L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1798" to="1810" />
			<date type="published" when="2015-09">Sep. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Ensemble and arithmetic recombinationbased speciation differential evolution for multimodal optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="64" to="74" />
			<date type="published" when="2016-01">Jan. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schwefel</surname></persName>
		</author>
		<title level="m">Natural Computing</title>
		<meeting><address><addrLine>Dordrecht, Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer Acad</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Cuckoo search via Lévy flights</title>
		<author>
			<persName><forename type="first">X.-S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. World Congr</title>
		<meeting>World Congr<address><addrLine>Coimbatore, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="210" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Hybridizing harmony search algorithm with cuckoo search for global numerical optimization</title>
		<author>
			<persName><forename type="first">G.-G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Chu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Comput</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="273" to="285" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Orienting mutation based fireworks algorithm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1265" to="1271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An optimization algorithm based on brainstorming process</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Swarm Intell. Res</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="35" to="62" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multi-objective optimization based on brain storm optimization algorithm</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Swarm Intell. Res</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Earthworm optimization algorithm: A bio-inspired metaheuristic algorithm for global optimization problems</title>
		<author>
			<persName><forename type="first">G.-G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D S</forename><surname>Coelho</surname></persName>
		</author>
		<idno type="DOI">10.1504/IJBIC.2015.10004283</idno>
		<ptr target="http://www.inderscience.com/info/ingeneral/forthcoming.php?jcode=ijbic" />
	</analytic>
	<monogr>
		<title level="j">Int. J. Bio Inspired Comput</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A new metaheuristic optimisation algorithm motivated by elephant herding behaviour</title>
		<author>
			<persName><forename type="first">G.-G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D S</forename><surname>Coelho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Bio Inspired Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="394" to="409" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Krill herd: A new bio-inspired optimization algorithm</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Alavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. Nonlin. Sci. Numer. Simulat</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4831" to="4845" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Chaotic krill herd algorithm</title>
		<author>
			<persName><forename type="first">G.-G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-S</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">274</biblScope>
			<biblScope unit="page" from="17" to="34" />
			<date type="published" when="2014-08">Aug. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Incorporating mutation scheme into krill herd algorithm for global numerical optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="853" to="871" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Stud krill herd algorithm</title>
		<author>
			<persName><forename type="first">G.-G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Alavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="page" from="363" to="370" />
			<date type="published" when="2014-03">Mar. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An effective krill herd algorithm with migration operator in biogeography-based optimization</title>
		<author>
			<persName><forename type="first">G.-G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Alavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Model</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2454" to="2462" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Hybrid krill herd algorithm with differential evolution for global numerical optimization</title>
		<author>
			<persName><forename type="first">G.-G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Alavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-S</forename><surname>Hao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="297" to="308" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A hybrid method based on krill herd and quantum-behaved particle swarm optimization</title>
		<author>
			<persName><forename type="first">G.-G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Alavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="989" to="1006" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Oppositionbased krill herd algorithm with Cauchy mutation and position clamping</title>
		<author>
			<persName><forename type="first">G.-G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Alavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">177</biblScope>
			<biblScope unit="page" from="147" to="157" />
			<date type="published" when="2016-02">Feb. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Biogeography-based optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="702" to="713" />
			<date type="published" when="2008-12">Dec. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<title level="m">Genetic Algorithms in Search, Optimization and Machine Learning</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A new surrogate-assisted interactive genetic algorithm with weighted semisupervised learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="685" to="698" />
			<date type="published" when="2013-04">Apr. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Comparative study of diversity based parallel dual population genetic algorithm for unconstrained function optimisations</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Umbarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Bio Inspired Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="248" to="263" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A new heuristic optimization algorithm: Harmony search</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">W</forename><surname>Geem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">V</forename><surname>Loganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Simulation</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="60" to="68" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A self-adaptive harmony search combined with a stochastic local search for the 0-1 multidimensional knapsack problem</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rezoug</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Boughaci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Bio Inspired Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="234" to="239" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Optimal energy management of smart renewable micro-grids in the reconfigurable systems using adaptive harmony search algorithm</title>
		<author>
			<persName><forename type="first">T</forename><surname>Niknam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kavousi-Fard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Bio Inspired Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="184" to="194" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Monarch butterfly optimization</title>
		<author>
			<persName><forename type="first">G.-G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00521-015-1923-y</idno>
		<idno>doi: 10.1007/s00521-015-1923-y</idno>
		<ptr target="https://link.springer.com/article/10.1007/s00521-015-1923-y" />
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2015-05">May 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Population-based incremental learning: A method for integrating genetic search based function optimization and competitive learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Shumeet</surname></persName>
		</author>
		<idno>CMU-CS-94-163</idno>
		<imprint>
			<date type="published" when="1994">1994</date>
			<pubPlace>Pittsburgh, PA, USA, Rep</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon Univ.</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Moth search algorithm: A bio-inspired metaheuristic algorithm for global optimization problems</title>
		<author>
			<persName><forename type="first">G.-G</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12293-016-0212-3</idno>
		<idno>doi: 10.1007/s12293-016-0212-3</idno>
		<ptr target="https://link.springer.com/article/10.1007/s12293-016-0212-3" />
	</analytic>
	<monogr>
		<title level="m">Memetic Comput</title>
		<imprint>
			<date type="published" when="2016-09">Sep. 2016</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Neural Netw</title>
		<meeting>Int. Conf. Neural Netw</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Experimental analysis of bound handling techniques in particle swarm optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Helwig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mostaghim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="259" to="271" />
			<date type="published" when="2013-04">Apr. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Composite particle swarm optimizer with historical memory for function optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2350" to="2363" />
			<date type="published" when="2015-10">Oct. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Complex network clustering by multiobjective discrete particle swarm optimization based on decomposition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="82" to="97" />
			<date type="published" when="2014-02">Feb. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Prototype generation using multiobjective particle swarm optimization for nearest neighbor classification</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2719" to="2731" />
			<date type="published" when="2015-12">Dec. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">On the performance of particle swarm optimisation without some control parameters for global optimisation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">O</forename><surname>Adewumi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Arasomwan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Bio Inspired Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14" to="32" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A novel consensus-based particle swarm optimization-assisted trust-tech methodology for large-scale global optimization</title>
		<author>
			<persName><forename type="first">Y.-F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-D</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2717" to="2729" />
			<date type="published" when="2017-09">Sep. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Many-objective particle swarm optimization using two-stage strategy and parallel cell coordinate system</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1446" to="1459" />
			<date type="published" when="2017-06">Jun. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Bat algorithm: A novel approach for global engineering optimization</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eng. Comput</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="464" to="483" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Improved bat algorithm with optimal forage strategy and random disturbance strategy</title>
		<author>
			<persName><forename type="first">X</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Bio Inspired Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="205" to="214" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Hybrid ant colony-genetic algorithm (GAAPI) for global continuous optimization</title>
		<author>
			<persName><forename type="first">I</forename><surname>Ciornei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kyriakides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B, Cybern</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="234" to="245" />
			<date type="published" when="2012-02">Feb. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Markov models for biogeography-based optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ergezer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rarick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B, Cybern</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="299" to="306" />
			<date type="published" when="2011-02">Feb. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Fireworks Algorithm-A Novel Swarm Intelligence Optimization Method</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="page">323</biblScope>
			<pubPlace>Heidelberg, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Adaptive genetic algorithms applied to dynamic multiobjective problems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Bingul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="791" to="799" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A multioperator search strategy based on cheap surrogate models for evolutionary optimization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="746" to="758" />
			<date type="published" when="2015-10">Oct. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A Gaussian process surrogate model assisted evolutionary algorithm for medium scale expensive optimization problems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G E</forename><surname>Gielen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="180" to="192" />
			<date type="published" when="2014-04">Apr. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Data-driven surrogate-assisted multiobjective evolutionary optimization of a trauma system</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">O</forename><surname>Janson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="939" to="952" />
			<date type="published" when="2016-12">Dec. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A surrogate genetic programming based model to facilitate robust multiobjective optimization: A case study in magnetostatics</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H S</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Coulomb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Magn</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2065" to="2068" />
			<date type="published" when="2013-05">May 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Surrogate genetic programming: A semantic aware evolutionary search</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kattan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Ong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">296</biblScope>
			<biblScope unit="page" from="345" to="359" />
			<date type="published" when="2015-03">Mar. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Surrogate-assisted multi-objective model selection for support vector machines</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rosales-Pérez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Escalante</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Reyes-Garcia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">150</biblScope>
			<biblScope unit="page" from="163" to="172" />
			<date type="published" when="2015-02">Feb. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">On using surrogates with genetic programming</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hildebrandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="343" to="367" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A binary particle swarm optimization based on the surrogate information with proportional acceleration coefficients for the 0-1 multidimensional knapsack problem</title>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-S</forename><surname>Chern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Ind. Prod. Eng</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="77" to="102" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Bare bones artificial bee colony algorithm with parameter adaptation and fitness-based neighborhood</title>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T S</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">316</biblScope>
			<biblScope unit="page" from="180" to="200" />
			<date type="published" when="2015-09">Sep. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Genetic learning particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y.-J</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2277" to="2290" />
			<date type="published" when="2016-10">Oct. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Optimal experiment design for coevolutionary active learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Ly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lipson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="394" to="404" />
			<date type="published" when="2014-06">Jun. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">An estimation of distribution algorithm with cheap and expensive local search methods</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="807" to="822" />
			<date type="published" when="2015-12">Dec. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">A knowledge-based evolutionary multiobjective approach for stochastic extended resource investment project scheduling problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Abbass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="742" to="763" />
			<date type="published" when="2014-10">Oct. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Artificial bee colony algorithm based on information learning</title>
		<author>
			<persName><forename type="first">W.-F</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2827" to="2839" />
			<date type="published" when="2015-12">Dec. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Enhancing artificial bee colony algorithm using more information-based search equations</title>
		<author>
			<persName><forename type="first">W.-F</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-L</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">270</biblScope>
			<biblScope unit="page" from="112" to="133" />
			<date type="published" when="2014-06">Jun. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">A multi-swarm bat algorithm for global optimization</title>
		<author>
			<persName><forename type="first">G.-G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr<address><addrLine>Sendai, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="480" to="485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">An improved differential evolution algorithm with fitness-based adaptation of the control parameters</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Giri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="3749" to="3765" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Multi-population differential evolution with balanced ensemble of mutation strategies for largescale global optimization</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Z</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Awad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="304" to="327" />
			<date type="published" when="2015-08">Aug. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Adaptive differential evolution algorithm with novel mutation strategies in multiple sub-populations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="155" to="173" />
			<date type="published" when="2016-03">Mar. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">A dual-population differential evolution with coevolution for constrained optimization</title>
		<author>
			<persName><forename type="first">W.-F</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1108" to="1121" />
			<date type="published" when="2015-05">May 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Cooperative differential evolution with multiple populations for multiobjective optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2848" to="2861" />
			<date type="published" when="2016-12">Dec. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Development of firefly algorithm via chaotic sequence and population diversity to enhance the image contrast</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Dhal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Quraishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="307" to="318" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">A localbest harmony search algorithm with dynamic subpopulations</title>
		<author>
			<persName><forename type="first">Q.-K</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Tasgetiren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eng. Optim</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="101" to="117" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Adaptive multiobjective particle swarm optimization based on parallel cell coordinate system</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2015-02">Feb. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A self organising network model of information gathering by the honey bee swarm</title>
		<author>
			<persName><forename type="first">R</forename><surname>Foss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Kybernetes</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="353" to="367" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Differential evolution: A survey of the state-of-the-art</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="31" />
			<date type="published" when="2011-02">Feb. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Enhanced differential evolution with adaptive strategies for numerical optimization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">X</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B, Cybern</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="397" to="413" />
			<date type="published" when="2011-04">Apr. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Differential evolution with distributed direction information based mutation operators: An optimization technique for big data</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Ambient Intell. Humanized Comput</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="481" to="494" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Cellular direction information based differential evolution for numerical optimization: An empirical study</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Comput</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2801" to="2827" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Adaptive direction information in differential evolution for numerical optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Comput</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="465" to="494" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">A decentralized quantuminspired particle swarm optimization algorithm with cellular structured population</title>
		<author>
			<persName><forename type="first">W</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">330</biblScope>
			<biblScope unit="page" from="19" to="48" />
			<date type="published" when="2016-02">Feb. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">An improved bat algorithm with variable neighborhood search for global optimization</title>
		<author>
			<persName><forename type="first">G.-G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-J</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr<address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1773" to="1778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">A hybrid wavelet neural network model with mutual information and particle swarm optimization for forecasting monthly rainfall</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Hydrol</title>
		<imprint>
			<biblScope unit="volume">527</biblScope>
			<biblScope unit="page" from="88" to="100" />
			<date type="published" when="2015-08">Aug. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Incorporating heuristic information into ant colony optimization for epistasis detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genes Genomics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="321" to="327" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">An adaptive multi-population differential evolution algorithm for continuous multi-objective optimization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">348</biblScope>
			<biblScope unit="page" from="124" to="141" />
			<date type="published" when="2016-06">Jun. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Stochastic opposition-based learning using a beta distribution in differential evolution</title>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2184" to="2194" />
			<date type="published" when="2016-10">Oct. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Optimization by simulated annealing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Gelatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jr</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Vecchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">220</biblScope>
			<biblScope unit="issue">4598</biblScope>
			<biblScope unit="page" from="671" to="680" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">An information guided framework for simulated annealing</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Glob. Optim</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="131" to="154" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Exploratory landscape analysis of continuous space optimization problems using information content</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Muñoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kirley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Halgamuge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="74" to="87" />
			<date type="published" when="2015-02">Feb. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">No free lunch theorems for optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Wolpert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Macready</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="82" />
			<date type="published" when="1997-04">Apr. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">Problem Definitions and Evaluation Criteria for CEC 2011 Competition on Testing Evolutionary Algorithms on Real World Optimization Problems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suganthan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">An efficient public auditing protocol with novel dynamic structure for cloud data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Susilo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2402" to="2415" />
			<date type="published" when="2017-10">Oct. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Privacy-preserving smart semantic search based on conceptual graphs over encrypted outsourced data</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1874" to="1884" />
			<date type="published" when="2017-08">Aug. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Enabling personalized search over encrypted outsourced data with efficiency improvement</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Parallel Distrib. Syst</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2546" to="2559" />
			<date type="published" when="2016-09">Sep. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Effective and efficient global context verification for image copy detection</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">M J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="48" to="63" />
			<date type="published" when="2017-01">Jan. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">A robust regularization path Algorithm for v-support vector classification</title>
		<author>
			<persName><forename type="first">B</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Sheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1241" to="1248" />
			<date type="published" when="2017-05">May 2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
