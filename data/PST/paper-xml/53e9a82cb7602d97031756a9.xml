<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Performance Guarantees for Regularized Maximum Entropy Density Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Miroslav</forename><surname>Dudík</surname></persName>
							<email>mdudik@cs.princeton.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Princeton University</orgName>
								<address>
									<addrLine>35 Olden Street</addrLine>
									<postCode>08544</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Phillips</surname></persName>
							<email>phillips@research.att.com</email>
							<affiliation key="aff1">
								<orgName type="institution">AT&amp;T Labs -Research</orgName>
								<address>
									<addrLine>180 Park Avenue, Florham Park</addrLine>
									<postCode>07932</postCode>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
							<email>schapire@cs.princeton.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Princeton University</orgName>
								<address>
									<addrLine>35 Olden Street</addrLine>
									<postCode>08544</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Performance Guarantees for Regularized Maximum Entropy Density Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">773C053ADBFE6BDD3EAC7AAF1EF4A7A5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We consider the problem of estimating an unknown probability distribution from samples using the principle of maximum entropy (maxent). To alleviate overfitting with a very large number of features, we propose applying the maxent principle with relaxed constraints on the expectations of the features. By convex duality, this turns out to be equivalent to finding the Gibbs distribution minimizing a regularized version of the empirical log loss. We prove non-asymptotic bounds showing that, with respect to the true underlying distribution, this relaxed version of maxent produces density estimates that are almost as good as the best possible. These bounds are in terms of the deviation of the feature empirical averages relative to their true expectations, a number that can be bounded using standard uniform-convergence techniques. In particular, this leads to bounds that drop quickly with the number of samples, and that depend very moderately on the number or complexity of the features. We also derive and prove convergence for both sequential-update and parallel-update algorithms. Finally, we briefly describe experiments on data relevant to the modeling of species geographical distributions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The maximum entropy (maxent) approach to probability density estimation was first proposed by Jaynes <ref type="bibr" target="#b8">[9]</ref> in 1957, and has since been used in many areas of computer science and statistical learning, especially natural language processing <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b5">6]</ref>. In maxent, one is given a set of samples from a target distribution over some space, and a set of known constraints on the distribution. The distribution is then estimated by a distribution of maximum entropy satisfying the given constraints. The constraints are often represented using a set of features (real-valued functions) on the space, with the expectation of every feature being required to match its empirical average. By convex duality, this turns out to be the unique Gibbs distribution maximizing the likelihood of the samples, where a Gibbs distribution is one that is exponential in a linear combination of the features. (Maxent and its dual are described more rigorously in Section 2.)</p><p>The work in this paper was motivated by a new application of maxent to the problem of modeling the distribution of a plant or animal species, a critical problem in conservation biology. This application is explored in detail in a companion paper <ref type="bibr" target="#b12">[13]</ref>. Input data for species distribution modeling consists of occurrence locations of a particular species in a certain region and of environmental variables for that region. Environmental variables may include topological layers, such as elevation and aspect, meteorological layers, such as annual precipitation and average temperature, as well as categorical layers, such as vegetation and soil types. Occurrence locations are commonly derived from specimen collections in natural history museums and herbaria. In the context of maxent, the sample space is a map divided into a finite number of cells, the modeled distribution is the probability that a random specimen of the species occurs in a given cell, samples are occurrence records, and features are environmental variables or functions thereof.</p><p>It should not be surprising that maxent can severely overfit training data when the constraints on the output distribution are based on feature expectations, as described above, especially if there is a very large number of features. For instance, in our application, we sometimes consider threshold features for each environmental variable. These are binary features equal to one if an environmental variable is larger than a fixed threshold and zero otherwise. Thus, there is a continuum of features for each variable, and together they force the output distribution to be non-zero only at values achieved by the samples. The problem is that in general, the empirical averages of the features will almost never be equal to their true expectation, so that the target distribution itself does not satisfy the constraints imposed on the output distribution. On the other hand, we do expect that empirical averages will be close to their expectations. In addition, we often have bounds or estimates on deviations of empirical feature averages from their expectations (empirical error bounds). In this paper, we propose a relaxation of feature-based maxent constraints in which we seek the distribution of maximum entropy subject to the constraint that feature expectations be within empirical error bounds of their empirical averages (rather than exactly equal to them).</p><p>As was the case for the standard feature-based maxent, the convex dual of this relaxed problem has a natural interpretation. In particular, this problem turns out to be equivalent to minimizing the empirical log loss of the sample points plus an 1style regularization term. As we demonstrate, this form of regularization has numerous advantages, enabling the proof of meaningful bounds on the deviation between the density estimate and the true underlying distribution, as well as the derivation of simple algorithms for provably minimizing this regularized loss. Beginning with the former, we prove that the regularized (empirical) loss function itself gives an upper bound on the log loss with respect to the target distribution. This provides another sensible motivation for minimizing this function. More specifically, we prove a guarantee on the log loss over the target distribution in terms of empirical error bounds on features. Thus, to get exact bounds, it suffices to bound the empirical errors. For finite sets of features, we can use Chernoff bounds with a simple union bound; for infinite sets, we can choose from an array of uniform-convergence techniques. For instance, for a set of binary features with VC-dimension d, if given m samples, the log loss of the relaxed maxent solution on the target distribution will be worse by no more than O( λ * 1 d ln(m 2 /d)/m) compared to the log loss of any Gibbs distribution defined by weight vector λ * with 1 -norm λ * 1 . For a finite set of bounded, but not necessarily binary features, this difference is at most O( λ * 1 (ln n)/m) where n is the number of features. Thus, for a moderate number of samples, our method generates a density estimate that is almost as good as the best possible, and the difference can be bounded non-asymptotically. Moreover, these bounds are very moderate in terms of the number or complexity of the features, even admitting an extremely large number of features from a class of bounded VC-dimension.</p><p>Previous work on maxent regularization justified modified loss functions as either constraint relaxations <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b9">10]</ref>, or priors over Gibbs distributions <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b7">8]</ref>. Our regularized loss also admits these two interpretations. As a relaxed maxent, it has been studied by Kazama and Tsujii <ref type="bibr" target="#b9">[10]</ref> and as a Laplace prior by Goodman <ref type="bibr" target="#b7">[8]</ref>. These two works give experimental evidence showing benefits of 1 -style regularization (Laplace prior) over 2 2 -style regularization (Gaussian prior), but they do not provide any theoretical guarantees. In the context of neural nets, Laplace priors have been studied by Williams <ref type="bibr" target="#b19">[20]</ref>. A smoothened version of 1 -style regularization has been used by Dekel, Shalev-Shwartz and Singer <ref type="bibr" target="#b4">[5]</ref>.</p><p>Standard maxent algorithms such as iterative scaling <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6]</ref>, gradient descent, Newton and quasi-Newton methods <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b15">16]</ref> and their regularized versions <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b19">20]</ref> perform a sequence of feature weight updates until convergence. In each step, they update all feature weights. This is impractical when the number of features is very large. Instead, we propose a sequential update algorithm that updates only one feature weight in each iteration, along the lines of algorithms studied by Collins, Schapire and Singer <ref type="bibr" target="#b2">[3]</ref>. This leads to a boosting-like approach permitting the selection of the best feature from a very large class. For instance, the best threshold feature associated with a single variable can be found in a single linear pass through the (pre-sorted) data, even though conceptually we are selecting from an infinite class of features. In Section 4, we describe our sequentialupdate algorithm and give a proof of convergence. Other boosting-like approaches to density estimation have been proposed by Welling, Zemel and Hinton <ref type="bibr" target="#b18">[19]</ref> and Rosset and Segal <ref type="bibr" target="#b14">[15]</ref>.</p><p>For cases when the number of features is relatively small, yet we want to prevent overfitting on small sample sets, it might be more efficient to minimize the regularized log loss by parallel updates. In Section 5, we give the parallel-update version of our algorithm with a proof of convergence.</p><p>In the last section, we return to our application to species distribution modeling. We present learning curves for relaxed maxent for four species of birds with a varying number of occurrence records. We also explore the effects of regularization on the log loss over the test data. A more comprehensive set of experiments is evaluated in the companion paper <ref type="bibr" target="#b12">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Maximum Entropy with Relaxed Constraints</head><p>Our goal is to estimate an unknown probability distribution π over a sample space X which, for the purposes of this paper, we assume to be finite. We are given a set of samples x 1 , . . . , x m drawn independently at random according to π. The corresponding empirical distribution is denoted by π:</p><formula xml:id="formula_0">π(x) = 1 m {1 ≤ i ≤ m : x i = x} .</formula><p>We also are given a set of features f 1 , . . . , f n where f j : X → R. The vector of all n features is denoted by f . For a distribution π and function f , we write π[f ] to denote the expected value of f under distribution π (and sometimes use this notation even when π is not necessarily a probability distribution):</p><formula xml:id="formula_1">π[f ] = x∈X π(x)f (x).</formula><p>In general, π may be quite distant, under any reasonable measure, from π. On the other hand, for a given function f , we do expect π[f ], the empirical average of f , to be rather close to its true expectation π[f ]. It is quite natural, therefore, to seek an approximation p under which f j 's expectation is equal to π[f j ] for every f j . There will typically be many distributions satisfying these constraints. The maximum entropy principle suggests that, from among all distributions satisfying these constraints, we choose the one of maximum entropy, i.e., the one that is closest to uniform. Here, as usual, the entropy of a distribution p on X is defined to be</p><formula xml:id="formula_2">H(p) = -x∈X p(x) ln p(x).</formula><p>Alternatively, we can consider all Gibbs distributions of the form</p><formula xml:id="formula_3">q λ (x) = e λ•f (x) Z λ</formula><p>where</p><formula xml:id="formula_4">Z λ = x∈X e λ•f (x)</formula><p>is a normalizing constant, and λ ∈ R n . Then it can be proved <ref type="bibr" target="#b5">[6]</ref> that the maxent distribution described above is the same as the maximum likelihood Gibbs distribution, i.e., the distribution q λ that maximizes m i=1 q λ (x i ), or equivalently, minimizes the empirical log loss (negative normalized log likelihood)</p><formula xml:id="formula_5">L π (λ) = - 1 m m i=1 ln q λ (x i ) = -π[ln q λ ]<label>(1)</label></formula><p>A related measure is the relative entropy (or Kullback-Leibler divergence), defined as</p><formula xml:id="formula_6">RE(π q λ ) = π[ln(π/q λ )].</formula><p>The log loss and the relative entropy differ only by the constant H(π). We will use the two interchangeably as objective functions. Thus, the convex programs corresponding to the two optimization problems are</p><formula xml:id="formula_7">P : max p∈∆ H(p) subject to Q : min λ∈R n L π (λ) p[f j ] = π[f j ]</formula><p>where ∆ is the simplex of probability distributions over X.</p><p>This basic approach computes the maximum entropy distribution p for which p[f j ] = π[f j ]. However, we do not expect π[f j ] to be equal to π[f j ] but only close to it. Therefore, in keeping with the motivation above, we can soften these constraints to have the form</p><formula xml:id="formula_8">|p[f j ] -π[f j ]| ≤ β j (2)</formula><p>where β j is an estimated upper bound of how close π[f j ], being an empirical average, must be to its true expectation π[f j ]. Thus, the problem can be stated as follows:</p><formula xml:id="formula_9">max p∈∆ H(p) subject to ∀j : p[f j ] -π[f j ] ≤ β j</formula><p>This corresponds to the convex program:</p><formula xml:id="formula_10">P : max p∈(R + ) X H(p) subject to x∈X p(x) = 1 (λ 0 ) ∀j : π[f j ] -p[f j ] ≤ β j (λ + j ) ∀j : p[f j ] -π[f j ] ≤ β j (λ - j )</formula><p>To compute the convex dual, we form the Lagrangian (dual variables are indicated next to constraints) to obtain the dual program</p><formula xml:id="formula_11">min λ0∈R λ - j ,λ + j ∈R + max p∈(R + ) X H(p) -λ 0 x∈X p(x) -1 + j (λ + j -λ - j ) (p[f j ] -π[f j ]) + j β j (λ + j + λ - j ) .</formula><p>Note that we have retained use of the notation p[f ] and H(p), with the natural definitions, even though p is no longer necessarily a probability distribution. Without loss of generality we may assume that in the solution, at most one in each pair λ + j , λ - j is nonzero. Otherwise, we could decrease them both by a positive value, decreasing the value of the third sum while not affecting the remainder of the expression. Thus, if we set λ j = λ + jλ - j then we obtain a simpler program</p><formula xml:id="formula_12">min λ0,λj ∈R max p∈(R + ) X H(p)-λ 0 x∈X p(x) -1 + j λ j (p[f j ] -π[f j ])+ j β j λ j .</formula><p>The inner expression is differentiable and concave in p(x). Setting partial derivatives with respect to p(x) equal to zero yields that p must be a Gibbs distribution with parameters corresponding to dual variables λ j and ln Z λ = λ 0 + 1. Hence the program becomes</p><formula xml:id="formula_13">min λ∈R n H(q λ ) + λ • (q λ [f ] -π[f ]) + j β j λ j .<label>(3)</label></formula><p>Note that</p><formula xml:id="formula_14">H(q λ ) = -q λ [ln q λ ] = -q λ [λ • f -ln Z λ ] = -λ • q λ [f ] + ln Z λ .</formula><p>Hence, the inner expression of Eq. ( <ref type="formula" target="#formula_13">3</ref>) becomes</p><formula xml:id="formula_15">-λ • π[f ] + ln Z λ + j β j λ j = L π (λ) + j β j λ j .<label>(4)</label></formula><p>(See Eq. ( <ref type="formula" target="#formula_16">5</ref>) below.) Denoting this function by L β π (λ), we obtain the final version of the dual program Q : min λ L β π (λ). Thus, we have shown that maxent with relaxed constraints is equivalent to minimizing L β π (λ). This modified objective function consists of an empirical loss term L π (λ) plus an additional term j β j |λ j | that can be interpreted as a form of regularization limiting how large the weights λ j can become.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Bounding the Loss on the Target Distribution</head><p>In this section, we derive bounds on the performance of relaxed maxent relative to the true distribution π. That is, we are able to bound L π ( λ) in terms of L π (λ * ) when λ minimizes the regularized loss and q λ * is an arbitrary Gibbs distribution, in particular, the Gibbs distribution minimizing the true loss. Note that RE(π q λ ) differs from L π (λ) only by the constant term H(π), so analogous bounds also hold for RE(π q λ).</p><p>We begin with the following simple lemma on which all of the bounds in this section are based. The lemma states that the difference between the true and empirical loss of any Gibbs distribution can be bounded in terms of the magnitude of the weights λ j and the deviation of feature averages from their means. Lemma 1. Let q λ be a Gibbs distribution. Then</p><formula xml:id="formula_16">L π (λ) -L π (λ) ≤ n j=1 λ j π[f j ] -π[f j ] Proof. Note that L π (λ) = -π[ln q λ ] = -π[λ • f -ln Z λ ] = -λ • π[f ] + ln Z λ . (<label>5</label></formula><formula xml:id="formula_17">)</formula><p>Using an analogous identity for L π (λ), we obtain</p><formula xml:id="formula_18">L π (λ) -L π (λ) = -λ • π[f ] + ln Z λ + λ • π[f ] -ln Z λ = λ • (π[f ] -π[f ]) ≤ n j=1 λ j π[f j ] -π[f j ]</formula><p>This lemma yields an alternative motivation for minimizing L β π . For if we have bounds π[f j ]π[f j ] ≤ β j , then the lemma implies that L π (λ) ≤ L β π (λ). Thus, in minimizing L β π (λ), we also minimize an upper bound on L π (λ), the true log loss of λ. Next, we prove that the distribution produced using maxent cannot be much worse than the best Gibbs distribution (with bounded weight vector), assuming the empirical errors of the features are not too large.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 1. Assume that for each j, π[f</head><formula xml:id="formula_19">j ] -π[f j ] ≤ β j . Let λ minimize the regular- ized log loss L β π (λ).</formula><p>Then for an arbitrary Gibbs distribution</p><formula xml:id="formula_20">q λ * L π ( λ) ≤ L π (λ * ) + 2 n j=1 β j λ * j .</formula><p>Proof.</p><formula xml:id="formula_21">L π ( λ) ≤ L π ( λ) + j β j λj = L β π ( λ)<label>(6)</label></formula><formula xml:id="formula_22">≤ L β π (λ * ) = L π (λ * ) + j β j λ * j (7) ≤ L π (λ * ) + 2 j β j λ * j . (<label>8</label></formula><formula xml:id="formula_23">)</formula><p>Eqs. ( <ref type="formula" target="#formula_21">6</ref>) and ( <ref type="formula" target="#formula_22">8</ref>) follow from Lemma 1, Eq. ( <ref type="formula">7</ref>) follows from the optimality of λ.</p><p>Thus, if we can bound |π[f j ]-π[f j ]|, then we can use Theorem 1 to obtain a bound on the true loss L π ( λ). Fortunately, this is just a matter of bounding the difference between an empirical average and its expectation, a problem for which there exists a huge array of techniques. For instance, when the features are bounded, we can prove the following: Corollary 1. Assume that features f 1 , . . . , f n are bounded in [0, 1]. Let δ &gt; 0 and let λ minimize L β π (λ) with β j = β = ln(2n/δ)/(2m) for all j. Then with probability at least 1δ, for every Gibbs distribution q λ * ,</p><formula xml:id="formula_24">L π ( λ) ≤ L π (λ * ) + 2 λ * 1 ln(2n/δ) 2m .</formula><p>Proof. By Hoeffding's inequality, for a fixed j, the probability that</p><formula xml:id="formula_25">|π[f j ]-π[f j ]| exceeds β is at most e -2β 2 m = δ/n.</formula><p>By the union bound, the probability of this happening for any j is at most δ. The corollary now follows immediately from Theorem 1.</p><p>Similarly, when the f j 's are selected from a possibly larger class of binary features with VC-dimension d, we can prove the following corollary. This will be the case, for instance, when using threshold features on k variables, a class with VC-dimension O(ln k). Proof. In this case, a uniform-convergence result of Devroye <ref type="bibr" target="#b6">[7]</ref>, combined with Sauer's Lemma, can be used to argue that |π[f j ] -π[f j ]| ≤ β for all f j simultaneously, with probability at least 1δ.</p><p>As noted in the introduction, these corollaries show that the difference in performance between the density estimate computed by minimizing L β π and the best Gibbs distribution (of bounded norm), becomes small rapidly as the number of samples m increases. Moreover, the dependence of this difference on the number or complexity of the features is quite moderate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">A Sequential-Update Algorithm and Convergence Proof</head><p>There are a number of algorithms for finding the maxent distribution, especially iterative scaling and its variants <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6]</ref>. In this section, we describe and prove the convergence of a sequential-update algorithm that modifies one weight λ j at a time, as explored by Collins, Schapire and Singer <ref type="bibr" target="#b2">[3]</ref> in a similar setting. This style of coordinate-wise descent is convenient when working with a very large (or infinite) number of features.</p><p>As explained in Section 2, the goal of the algorithm is to find λ minimizing the objective function L β π (λ) given in Eq. ( <ref type="formula" target="#formula_15">4</ref>). Our algorithm works by iteratively adjusting </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fj(λt, δ)</head><p>where Fj(λ, δ) is the expression appearing in Eq. ( <ref type="formula" target="#formula_26">12</ref>)</p><p>-λ t+1,j = λt,j + δ if j = j λ t,j else Fig. <ref type="figure">1</ref>. A sequential-update algorithm for optimizing the regularized log loss.</p><p>the single weight λ j that will maximize (an approximation of) the change in L β π . To be more precise, suppose we add δ to λ j . Let λ be the resulting vector of weights, identical to λ except that λ j = λ j + δ. Then the change in L β π is</p><formula xml:id="formula_26">L β π (λ ) -L β π (λ) = λ • π[f ] -λ • π[f ] + ln Z λ -ln Z λ + β j (|λ j | -|λ j |) (9) = -δπ[f j ] + ln(q λ e δfj ) + β j (|λ j + δ| -|λ j |) (10) ≤ -δπ[f j ] + ln(q λ 1 + (e δ -1)f j ) + β j (|λ j + δ| -|λ j |) (11) = -δπ[f j ] + ln(1 + (e δ -1)q λ [f j ]) + β j (|λ j + δ| -|λ j |). (<label>12</label></formula><formula xml:id="formula_27">)</formula><p>Eq. ( <ref type="formula">9</ref>) follows from Eq. ( <ref type="formula" target="#formula_16">5</ref>). Eq. ( <ref type="formula">10</ref>) uses</p><formula xml:id="formula_28">Z λ = x∈X e λ•f (x)+δfj (x) = Z λ x∈X q λ (x)e δfj (x) . (<label>13</label></formula><formula xml:id="formula_29">)</formula><p>Eq. ( <ref type="formula">11</ref>) is because e δx ≤ 1 + (e δ -1)x for x ∈ [0, 1]. Let F j (λ, δ) denote the expression in Eq. ( <ref type="formula" target="#formula_26">12</ref>). This function can be minimized over all choices of δ ∈ R via a simple case analysis on the sign of λ j + δ. In particular, using calculus, we see that we only need consider the possibility that δ = -λ j or that δ is equal to</p><formula xml:id="formula_30">ln (π[f j ] -β j )(1 -q λ [f j ]) (1 -π[f j ] + β j )q λ [f j ] or ln (π[f j ] + β j )(1 -q λ [f j ]) (1 -π[f j ] -β j )q λ [f j ]</formula><p>where the first and second of these can be valid only if λ j + δ ≥ 0 and λ j + δ ≤ 0, respectively. This case analysis is repeated for all features f j . The pair (j, δ) minimizing F j (λ, δ) is then selected and δ is added to λ j . The complete algorithm is shown in Figure <ref type="figure">1</ref>.</p><p>The following theorem shows that this algorithm is guaranteed to produce a sequence of λ t 's minimizing the objective function L β π in the case of interest where all the β j 's are positive. A modified proof can be used in the unregularized case in which all the β j 's are zero.</p><p>Theorem 2. Assume all the β j 's are strictly positive. Then the algorithm of Figure <ref type="figure">1</ref> produces a sequence λ 1 , λ 2 , . . . for which</p><formula xml:id="formula_31">lim t→∞ L β π (λ t ) = min λ L β π (λ).</formula><p>Proof. Let us define the vectors λ + and λ -in terms of λ as follows: for each j, if λ j ≥ 0 then λ + j = λ j and λ - j = 0, and if λ j ≤ 0 then λ + j = 0 and λ - j = -λ j . Vectors λ+ , λ-, λ + t , λ - t , etc. are defined analogously. We begin by rewriting the function F j . For any λ, δ, we have that</p><formula xml:id="formula_32">|λ + δ| -|λ| = min{δ + + δ -| δ + ≥ -λ + , δ -≥ -λ -, δ + -δ -= δ}. (<label>14</label></formula><formula xml:id="formula_33">)</formula><p>This can be seen by a simple case analysis on the signs of λ and λ + δ. Plugging into the definition of F j gives</p><formula xml:id="formula_34">F j (λ, δ) = min{G j (λ, δ + , δ -) | δ + ≥ -λ + , δ -≥ -λ -, δ + -δ -= δ}</formula><p>where</p><formula xml:id="formula_35">G j (λ, δ + , δ -) = (δ --δ + )π[f j ] + ln 1 + (e (δ + -δ -) -1)q λ [f j ] + β j (δ + + δ -).</formula><p>Combined with Eq. ( <ref type="formula" target="#formula_26">12</ref>) and our choice of j and δ, this gives that</p><formula xml:id="formula_36">L β π (λ t+1 ) -L β π (λ t ) ≤ min j min δ F j (λ t , δ) = min j min{G j (λ t , δ + , δ -) | δ + ≥ -λ + t,j , δ -≥ -λ - t,j }(15)</formula><p>Let minG(λ t ) denote this last expression. Since G j (λ, 0, 0) = 0, it follows that minG(λ t ) is not positive and hence L β π (λ t ) is nonincreasing in t. Since log loss is nonnegative, this means that</p><formula xml:id="formula_37">j β j |λ t,j | ≤ L β π (λ 1 ) &lt; ∞.</formula><p>Therefore, using our assumption that the β j 's are strictly positive, we see that the λ t 's must belong to a compact space. Since λt 's come from a compact space, in Eq. ( <ref type="formula">15</ref>) it suffices to consider updates δ + and δ -that come from a compact space themselves. Functions G j are uniformly continuous over these compact spaces, hence the function minG is continuous.</p><p>The fact that λt 's come from a compact space also implies that they must have a subsequence converging to some vector λ. Clearly, L β π is nonnegative, and we already noted that L β π (λ t ) is nonincreasing. Therefore, lim t→∞ L β π (λ t ) exists and is equal, by continuity, to L β π ( λ). Moreover, the differences L β π (λ t+1 )-L β π (λ t ) must be converging to zero, so minG(λ t ), which is nonpositive, also must be converging to zero by Eq. <ref type="bibr" target="#b14">(15)</ref>. By continuity, this means that minG( λ) = 0. In particular, for each j, we have</p><formula xml:id="formula_38">min{G j ( λ, δ + , δ -) | δ + ≥ -λ+ j , δ -≥ -λ- j } = 0. (<label>16</label></formula><formula xml:id="formula_39">)</formula><p>We will complete the proof by showing that this equation implies that λ+ and λtogether with q λ satisfy the KKT (Kuhn-Tucker) conditions <ref type="bibr" target="#b13">[14]</ref> for the convex program P , and thus form a solution to this optimization problem as well as to its dual Q , the minimization of L β π . For p = q λ, these conditions work out to be the following for all j:</p><formula xml:id="formula_40">λ+ j ≥ 0, π[f j ] -q λ[f j ] ≤ β j , λ+ j (π[f j ] -q λ[f j ] -β j ) = 0 (17) λ- j ≥ 0, q λ[f j ] -π[f j ] ≤ β j , λ- j (q λ[f j ] -π[f j ] -β j ) = 0.<label>(18)</label></formula><p>Recall that G j ( λ, 0, 0) = 0. Thus, by Eq. ( <ref type="formula" target="#formula_38">16</ref>), if λ+ j &gt; 0 then G j ( λ, δ + , 0) is nonnegative in a neighborhood of δ + = 0, and so has a local minimum at this point. That is,</p><formula xml:id="formula_41">0 = ∂G j ( λ, δ + , 0) ∂δ + δ + =0 = -π[f j ] + q λ[f j ] + β j .</formula><p>If λ+ j = 0, then Eq. ( <ref type="formula" target="#formula_38">16</ref>) gives that G j ( λ, 0, 0) ≥ 0 for δ + ≥ 0. Thus, G j (λ, δ + , 0) cannot be decreasing at δ + = 0. Therefore, the partial derivative evaluated above must be nonnegative. Together, these arguments exactly prove Eq. ( <ref type="formula">17</ref>). Eq. ( <ref type="formula" target="#formula_40">18</ref>) is proved analgously.</p><p>Thus, we have proved that</p><formula xml:id="formula_42">lim t→∞ L β π (λ t ) = L β π ( λ) = min λ L β π (λ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">A Parallel-Update Algorithm</head><p>Much of this paper has tried to be relevant to the case in which we are faced with a very large number of features. However, when the number of features is relatively small, it may be reasonable to minimize the regularized loss L β π (λ) using an algorithm that updates all features simultaneously on every iteration. There are quite a few algorithms that do this for the unregularized case, such as iterative scaling <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6]</ref>, gradient descent, Newton and quasi-Newton methods <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b15">16]</ref>.</p><p>Williams <ref type="bibr" target="#b19">[20]</ref> outlines how to modify any gradient based search to include 1 -style regularization. Kazama and Tsujii <ref type="bibr" target="#b9">[10]</ref> use a gradient based method that imposes additional linear constraints to avoid discontinuities in the first derivative. Regularized variants of iterative scaling were proposed by Goodman <ref type="bibr" target="#b7">[8]</ref>, but without a complete proof of convergence. In this section, we describe a variant of iterative scaling with a proof of convergence. Note that the gradient based or Newton methods might be faster in practice.</p><p>Throughout this section, we make the assumption (without loss of generality) that, for all x ∈ X, f j (x) ≥ 0 and j f j (x) ≤ 1. Like the algorithm of Section 4, our parallel-update algorithm is based on an approximation of the change in the objective function L β π , in this case the following, where λ = λ + δ:</p><formula xml:id="formula_43">L β π (λ ) -L β π (λ) = λ • π[f ] -λ • π[f ] + ln Z λ -ln Z λ + j β j (|λ j | -|λ j |) = -δ • π[f ] + ln q λ [exp(δ • f )] + j β j (|λ j + δ j | -|λ j |) (19) ≤ j -δ j π[f j ] + q λ [f j ](e δj -1) + β j (|λ j + δ j | -|λ j |) . (<label>20</label></formula><formula xml:id="formula_44">)</formula><p>Eq. ( <ref type="formula">19</ref>) uses Eq. ( <ref type="formula" target="#formula_28">13</ref>). For Eq. ( <ref type="formula" target="#formula_43">20</ref>), note first that, if x j ∈ R and p j ≥ 0 with j p j ≤ 1 then</p><formula xml:id="formula_45">exp j p j x j -1 ≤ j p j (e xj -1).</formula><p>(See Collins, Schapire and Singer <ref type="bibr" target="#b2">[3]</ref> for a proof.) Thus, ln q λ exp j δ j f j ≤ ln q λ 1 + j f j (e δj -1)</p><p>= ln 1 + j q λ [f j ](e δj -1)</p><formula xml:id="formula_46">≤ j q λ [f j ](e δj -1) since ln(1 + x) ≤ x for all x &gt; -1.</formula><p>Our algorithm, on each iteration, minimizes Eq. ( <ref type="formula" target="#formula_43">20</ref>) over all choices of the δ j 's. With a case analysis on the sign of λ j + δ j , and some calculus, we see that the minimizing δ j must occur when δ j = -λ j , or when δ j is either</p><formula xml:id="formula_47">ln π[f j ] -β j q λ [f j ] or ln π[f j ] + β j q λ [f j ]</formula><p>where the first and second of these can be valid only if λ j + δ j ≥ 0 and λ j + δ j ≤ 0, respectively. The full algorithm is shown in Figure <ref type="figure" target="#fig_1">2</ref>. As before, we can prove the convergence of this algorithm when the β j 's are strictly positive.</p><p>Theorem 3. Assume all the β j 's are strictly positive. Then the algorithm of Figure <ref type="figure" target="#fig_1">2</ref> produces a sequence λ 1 , λ 2 , . . . for which</p><formula xml:id="formula_48">lim t→∞ L β π (λ t ) = min λ L β π (λ).</formula><p>Proof. The proof mostly follows the same lines as for Theorem 2. Here we sketch the main differences. Let us redefine F j and G j as follows:</p><formula xml:id="formula_49">F j (λ, δ) = -δπ[f j ] + q λ [f j ](e δ -1) + β j (|λ j + δ| -|λ j |)</formula><p>and Then by Eq. ( <ref type="formula" target="#formula_32">14</ref>),</p><formula xml:id="formula_50">G j (λ, δ + , δ -) = (δ --δ + )π[f j ] + q λ [f j ](e δ + -δ --1) + β j (δ + + δ -).</formula><formula xml:id="formula_51">F j (λ, δ) = min{G j (λ, δ + , δ -) | δ + ≥ -λ + j , δ -≥ -λ - j , δ = δ + -δ -}.</formula><p>So, by Eq. ( <ref type="formula" target="#formula_43">20</ref>),</p><formula xml:id="formula_52">L β π (λ t+1 ) -L β π (λ t ) ≤ min δ j F j (λ t , δ j ) = j min δj F j (λ t , δ j ) = j min{G j (λ t , δ + j , δ - j ) | δ + j ≥ -λ + j , δ - j ≥ -λ - j }.</formula><p>Note that G j (λ, 0, 0) = 0, so none of the terms in this sum can be positive. As in the proof of Theorem 2, the λ t 's have a convergent subsequence converging to some λ for which</p><formula xml:id="formula_53">j min{G j ( λ, δ + j , δ - j ) | δ + j ≥ -λ + j , δ - j ≥ -λ - j } = 0.</formula><p>This fact, in turn, implies that λ+ , λand q λ satisfy the KKT conditions for convex program P . This follows using the same arguments on the derivatives of G j as in Theorem 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>In order to evaluate the effect of regularization on real data, we used maxent to model the distribution of some bird species, based on occurrence records in the North American Breeding Bird Survey <ref type="bibr" target="#b16">[17]</ref>. Experiments described in this section overlap with the (much more extensive) experiments given in the companion paper <ref type="bibr" target="#b12">[13]</ref>.</p><p>We selected four species with a varying number of occurrence records: Hutton's Vireo (198 occurrences), Blue-headed Vireo (973 occurrences), Yellow-throated Vireo (1611 occurrences) and Loggerhead Shrike (1850 occurrences). The occurrence data of each species was divided into ten random partitions: in each partition, 50% of the occurrence localities were randomly selected for the training set, while the remaining 50% were set aside for testing. The environmental variables (coverages) use a North American grid with 0.2 degree square cells. We used seven coverages: elevation, aspect, slope, annual precipitation, number of wet days, average daily temperature and temperature range. The first three derive from a digital elevation model for North America <ref type="bibr" target="#b17">[18]</ref>, and the remaing four were interpolated from weather station readings <ref type="bibr" target="#b11">[12]</ref>. Each coverage is defined over a 386 × 286 grid, of which 58,065 points have data for all coverages.</p><p>In our experiments, we used threshold features derived from all environmental variables. We reduced the β j to a single regularization parameter β as follows. We expect</p><formula xml:id="formula_54">|π[f j ] -π[f j ]| ≈ σ[f j ]/ √ m, where σ[f j ]</formula><p>is the standard deviation of f j under π. We therefore approximated σ[f j ] by the sample deviation σ[f j ] and used β j = β σ[f j ]/ √ m. We believe that this method is more practical than the uniform convergence bounds from section 3, because it allows differentiation between features depending on empirical error estimates computed from the sample data. In order to analyze this method, we could, for instance, bound errors in standard deviation estimates using uniform convergence results.</p><p>We ran two types of experiments. First, we ran maxent on increasing subsets of the training data and evaluated log loss on the test data. We took an average over ten partitions and plotted the log loss as a function of the number of training examples. These plots are referred to as learning curves. Second, we also varied the regularization parameter β and plotted the log loss for fixed numbers of training examples as functions of β. These curves are referred to as sensitivity curves. In addition to these curves, we give examples of Gibbs distributions returned by maxent with and without regularization.</p><p>Fig. <ref type="figure" target="#fig_2">3</ref> shows learning curves for the four studied species. In all our runs we set β = 1.0. This choice is justified by the sensitivity curve experiments described below. In the absence of regularization, maxent would exactly fit the training data with delta functions around sample values of the environmental variables. This would result in severe overfitting even when the number of examples is large. As the learning curves show, the regularized maxent does not exhibit this behavior, and finds better and better distributions as the number of training examples increases.</p><p>In order to see how regularization facilitates learning, we examine the resulting distributions. In Fig. <ref type="figure" target="#fig_3">4</ref>, we show Gibbs distributions returned by a regularized and an insufficently regularized run of maxent on the first partition of theYellow-throated Vireo. To represent Gibbs distributions, we use feature profiles. For each environmental variable, we plot the contribution to the exponent by all the derived threshold features as  a function of the value of the environmental variable. This contribution is just the sum of step functions corresponding to threshold features weighted by the corresponding lambdas. As we can see, the value of β = 0.01 only prevents components of λ from becoming arbitrarily large, but it does little to prevent heavy overfitting with many peaks capturing single training examples. Raising β to 1.0 completely eliminates these peaks.</p><p>Fig. <ref type="figure" target="#fig_4">5</ref> shows the sensitivity of maxent to the regularization value β. Note that the minimum log loss is achieved consistently around β = 1.0 for all studied species. This suggests that for the purposes of maxent regularization, σ[f j ] are good estimates of π[f j ]π[f j ] and that the maxent criterion models the underlying distribution well, at least for threshold features. Log loss minima for other feature types may be less consistent accross different species <ref type="bibr" target="#b12">[13]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Corollary 2 . 1 d</head><label>21</label><figDesc>Assume that features are binary with VC-dimension d. Let δ &gt; 0 and let λ minimize L β π (λ) with β j = β = [d ln(em 2 /d) + ln(1/δ) + ln(4e 8 )]/(2m) for all j. Then with probability at least 1δ, for every Gibbs distribution q λ * , L π ( λ) ≤ L π (λ * ) + 2 λ * ln(em 2 /d) + ln(1/δ) + ln(4e 8 ) 2m .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Input:Fig. 2 .</head><label>2</label><figDesc>Fig. 2.A parallel-update algorithm for optimizing the regularized log loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Learning curves. Log loss averaged over 10 partitions as a function of the number of training examples. Numbers of training examples are plotted on a logarithmic scale.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig.4. Feature profiles learned on the first partition of the Yellow-throated Vireo. For every environmental variable, its additive contribution to the exponent of the Gibbs distribution is given as a function of its value. Profiles for the two values of β have been shifted for clarity -this corresponds to adding a constant in the exponent; it has, however, no effect on the resulting model since constants in the exponent cancel out with the normalization factor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Sensitivity curves. Log loss averaged over 10 partitions as a function of β for a varying number of training examples. For a fixed value of β, maxent finds better solutions (with smaller log loss) as the number of examples grows. We ran maxent with 10, 32, 100 and 316 training examples. Curves from top down correspond to these numbers; curves for higher numbers are missing where fewer training examples were available. Values of β are plotted on a log scale.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>J. Shawe-Taylor and Y. Singer (Eds.): COLT 2004, LNAI 3120, pp. 472-486, 2004. c Springer-Verlag Berlin Heidelberg 2004</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. R. Schapire and M. Dudík received support through NSF grant CCR-0325463. M. Dudík was also partially supported by a Gordon Wu fellowship.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A maximum entropy approach to natural language processing</title>
		<author>
			<persName><forename type="first">Adam</forename><forename type="middle">L</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">A</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><forename type="middle">J</forename><surname>Della</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietra</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="71" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A survey of smoothing techniques for ME models</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rosenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Speech and Audio Processing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="50" />
			<date type="published" when="2000-01">January 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Logistic regression, AdaBoost and Bregman distances</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="253" to="285" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Generalized iterative scaling for log-linear models</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Darroch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ratcliff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1470" to="1480" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Smooth -insensitive regression by loss symmetrization</title>
		<author>
			<persName><forename type="first">Ofer</forename><surname>Dekel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shai</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixteenth Annual Conference on Computational Learning Theory</title>
		<meeting>the Sixteenth Annual Conference on Computational Learning Theory</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="433" to="447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Inducing features of random fields</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Della</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietra</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Della</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietra</forename></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="1997-04">April 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Bounds for the uniform deviation of empirical measures</title>
		<author>
			<persName><forename type="first">Luc</forename><surname>Devroye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Multivariate Analysis</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="72" to="79" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Exponential priors for maximum entropy models</title>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Goodman</surname></persName>
		</author>
		<ptr target="http://research.microsoft.com/˜joshuago/longexpo-nentialprior.ps" />
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Microsoft Research</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Information theory and statistical mechanics</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Jaynes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics Reviews</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="620" to="630" />
			<date type="published" when="1957">1957</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Evaluation and extension of maximum entropy models with inequality constraints</title>
		<author>
			<persName><forename type="first">Jun'ichi</forename><surname>Kazama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun'ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="137" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A comparison of algorithms for maximum entropy parameter estimation</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Malouf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Conference on Natural Language Learning</title>
		<meeting>the Sixth Conference on Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="49" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Representing twentieth-century space-time climate variability. Part 1: Development of a 1961-90 mean monthly terrestrial climatology</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>New</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Hulme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Climate</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="829" to="856" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A maximum entropy approach to species distribution modeling</title>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miroslav</forename><surname>Dudík</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-First International Conference on Machine Learning</title>
		<meeting>the Twenty-First International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Tyrrell</forename><surname>Rockafellar</surname></persName>
		</author>
		<title level="m">Convex Analysis</title>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Boosting density estimation</title>
		<author>
			<persName><forename type="first">Saharon</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eran</forename><surname>Segal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="641" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On the convergence of bound optimization algorithms</title>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Uncertainty in Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="509" to="516" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">The North American breeding bird survey, results and analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Sauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Hines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fallon</surname></persName>
		</author>
		<ptr target="http://www.mbr-pwrc.usgs.gov/bbs/bbs.html" />
		<imprint>
			<date type="published" when="1966">1966-2000, Version 2001.2. 2001</date>
			<pubPlace>Laurel, MD</pubPlace>
		</imprint>
		<respStmt>
			<orgName>USGS Patuxent Wildlife Research Center</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">HYDRO 1k, elevation derivative database</title>
		<author>
			<persName><surname>Usgs</surname></persName>
		</author>
		<ptr target="http://edcdaac.usgs.gov/gtopo30/hydro/" />
	</analytic>
	<monogr>
		<title level="m">United States Geological Survey</title>
		<meeting><address><addrLine>Sioux Falls, South Dakota</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Self supervised boosting</title>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="665" to="672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bayesian regularization and pruning using a Laplace prior</title>
		<author>
			<persName><forename type="first">M</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="117" to="143" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
