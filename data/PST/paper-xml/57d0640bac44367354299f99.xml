<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TWORAM: Efficient Oblivious RAM in Two Rounds with Applications to Searchable Encryption</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sanjam</forename><surname>Garg</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Payman</forename><surname>Mohassel</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Visa Research</orgName>
								<address>
									<settlement>Foster City</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Charalampos</forename><surname>Papamanthou</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<settlement>College Park</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">TWORAM: Efficient Oblivious RAM in Two Rounds with Applications to Searchable Encryption</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3782ADEA026DA4EF62BCC582158F2C37</idno>
					<idno type="DOI">10.1007/978-3-662-53015-3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present TWORAM, an asymptotically efficient oblivious RAM (ORAM) protocol providing oblivious access (read and write) of a memory index y in exactly two rounds: The client prepares an encrypted query encapsulating y and sends it to the server. The server accesses memory M obliviously and returns encrypted information containing the desired value M[y]. The cost of TWORAM is only a multiplicative factor of security parameter higher than the tree-based ORAM schemes such as the path ORAM scheme of Stefanov et al. [34].</p><p>TWORAM gives rise to interesting applications, and in particular to a 4-round symmetric searchable encryption scheme where search is sublinear in the worst case and the search pattern is not leaked-the access pattern can also be concealed assuming the documents are stored in the obliviously accessed memory M.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Oblivious RAM (ORAM) is a cryptographic primitive for accessing a remote memory M of n entries in a way that memory accesses do not reveal anything about the accessed index y ∈ {1, . . . , n}. Goldreich and Ostrovsky <ref type="bibr" target="#b15">[16]</ref> were the first to show that ORAM can be built with poly(log n) bandwidth overhead <ref type="foot" target="#foot_0">1</ref> , and since then, there has been a fruitful line of research on substantially reducing this overhead <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b35">36]</ref>, in part motivated by the tree ORAM framework proposed by Shi et al. <ref type="bibr" target="#b30">[31]</ref>. However, most existing practical ORAM protocols are interactive, requiring the client to perform a "download-decrypt-computeencrypt-upload" operation several times (typically O(log n) rounds are involved). This can be a bottleneck for applications where low latency is important.</p><p>In this paper, we consider the problem of building an efficient round-optimal ORAM scheme. In particular, we propose TWORAM, an ORAM scheme enabling a client to obliviously access a memory location M[y] in two rounds, where the client sends an encrypted message to the server that encapsulates y, the server performs the oblivious computation, and sends a message back to the client, from which the client can retrieve the desired value M[y].</p><p>TWORAM's worst-case bandwidth overhead is O(κ • p) where p is the bandwidth overhead of a tree-based ORAM scheme and κ is the security parameter. For instance, in Path-ORAM <ref type="bibr" target="#b33">[34]</ref>, it is p = log 3 n for a block of size O(log n) bits. In other words, in order to obliviously read a data block of O(log n) bits using TWORAM, one needs to exchange, in the worst case, a O(κ • log 3 n) bits with the server, just in two rounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Existing Round-Optimal ORAM Protocols</head><p>Williams and Sion <ref type="bibr" target="#b36">[37]</ref> devised a round-optimal ORAM scheme based on a customized garbling scheme and Bloom filters. Lu and Ostrovsky also include an optimized construction for single-round oblivious RAM in their seminal garbled RAM paper <ref type="bibr" target="#b27">[28]</ref>. Subsequent to our work, Fletcher et al. <ref type="bibr" target="#b9">[10]</ref> also provide singleround ORAM by generalizing the approach of <ref type="bibr" target="#b36">[37]</ref> to use a garbling scheme for branching programs. All aforementioned approaches are symmetric-key and are built on top of the hierarchical ORAM framework as introduced by Goldreich and Ostrovsky <ref type="bibr" target="#b15">[16]</ref>. Our approach however is based on the tree-based ORAM framework as introduced by Shi et al. <ref type="bibr" target="#b30">[31]</ref>, yielding worst-case logarithmic costs by construction, thus avoiding involved deamortization procedures. Burst ORAM <ref type="bibr" target="#b20">[21]</ref> is also round-optimal, yet it requires linear storage at the client side.</p><p>Other less efficient approaches to construct round-optimal ORAM schemes are generic constructions based on garbled RAM <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b13">14]</ref>. However, such generic approaches are prohibitively inefficient. For instance, for the non-blackbox Garbled RAM approaches <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b13">14]</ref>, the bandwidth overhead grows with poly(log n, κ, |f |), where |f | is the size of the circuit for computing the one-way function f and κ is the security parameter. This leads to inefficient constructions, that are only of theoretical interest. Also, for the black-box Garbled RAM approach <ref type="bibr" target="#b10">[11]</ref> the bandwidth overhead grows with poly(log n, κ), and is independent of |f |. However, the construction itself is asymptotically very inefficient. Specifically in <ref type="bibr" target="#b10">[11]</ref> the authors do not provide details on how large the involved polynomials are, which will depend on the choice of various parameters. According to our back-of-the-envelope calculation, however, the polynomial is at least κ 5 •log 7 n. A key reason for this inefficiency is that they require certain expensive ORAM operations, specifically "eviction," to be performed inside a garbled circuit. We eliminate this source of inefficiency by moving these expensive ORAM operations outside of the garbled circuits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">TWORAM's Technical Highlights</head><p>Our construction is inspired by the ideas from the recent, black-box garbled RAM work by Garg et al. <ref type="bibr" target="#b10">[11]</ref>. We specifically use those ideas on top of the tree ORAM algorithms <ref type="bibr" target="#b30">[31]</ref>. Our new ideas help avoid certain inefficiencies involved in the original construction of <ref type="bibr" target="#b10">[11]</ref>, yielding an asymptotically better protocol.</p><p>Our first step is to abstract away certain details of eviction-based tree ORAM algorithms, such as Path-ORAM <ref type="bibr" target="#b33">[34]</ref>, circuit ORAM <ref type="bibr" target="#b35">[36]</ref> and Onion ORAM <ref type="bibr" target="#b8">[9]</ref>. These algorithms work as follows: The memory M that must be accessed obliviously is stored as a sequence of L trees T 1 , T 2 , . . . , T L . The actual data of M is stored encrypted in the tree T L , while the other trees store position map information (also encrypted). Only T 1 is stored on the client side. Roughly speaking, to access an index y in M, the client accesses T 1 and sends a path index p 2 to the server. The server then, successively accesses paths p 2 , p 3 , . . . , p L in T 2 , T 3 , . . . , T L . However the paths are accessed adaptively: in order to learn p i , one needs to first access p i-1 in T i- <ref type="bibr" target="#b0">1</ref> , and have all the information (also known as buckets) stored in its nodes decrypted. This is where existing approaches require O(L) rounds of interaction: decryption can only take place at the client side, which means all the information on the paths must be communicated back to the client.</p><p>TWORAM's Core Idea. In order to avoid the roundtrips described above, we do not use standard encryption. Instead, we hardcode the content of each bucket inside a garbled circuit <ref type="bibr" target="#b37">[38]</ref>. In other words, after the trees T 2 , T 3 , . . . , T L are produced, the client generates one garbled circuit per each internal node in each tree. The function of this garbled circuit is very simple: Informally, it takes as input an index x; loops through the blocks bucket[i] contained in the current bucket until it finds bucket[x], and returns the index π = bucket[x] of the next path to be followed. Note that the index π is returned in form of a garbled input for the next garbled circuit, so that the execution can proceed by the server until T L is reached, and the final desired value can be returned to the client (see Fig. <ref type="figure" target="#fig_1">3</ref> for a more formal description).</p><p>This simplified description ignores some technical hurdles. Firstly, security of the underlying ORAM scheme requires that the location where bucket[x] is found remains hidden. In particular, the garbled circuit which has the value bucket[x] inside should not be identifiable by the server. We resolve this issue as follows. For every bucket that the underlying ORAM needs to touch, all the corresponding garbled circuits are executed in a specific order and the value of interest is carried along the way and output only by the final evaluated circuit in that tree.</p><p>Secondly, the above approach only works well for a single memory access, since the garbled circuits can only be used once. Fortunately, as we show in the paper, only a logarithmic number of garbled circuits are touched for each access. These circuits can be downloaded by the client who decodes the hardcoded values, performs the eviction strategy locally (on plaintext data), and sends fresh garbled circuits back to the server. This step does not increase the number of rounds (from two to three), since sending the fresh garbled circuits to the server can be "piggybacked" onto the message the client prepares for the next memory access.</p><p>Finally, in order to ensure the desired efficiency, and to avoid a blowup of polynomial multiplicative factor in security parameter, we develop optimizations that help ensure that the sizes of the circuits garbled in our construction remain small and proportional to the underlying ORAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Application: 4-Round Searchable Encryption with No Search Pattern Leakage</head><p>An SSE scheme allows a client to outsource a database (defined as a set of document/keyword set pairs DB = (d i , W i ) N i=1 ) to a server in an encrypted format, where a search query for w returns d i where w ∈ W i .</p><p>Several recent works <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b38">39]</ref> demonstrate attacks against propertypreserving encryption schemes (which also enable search on encrypted data), by taking advantage of the leakage associated with these schemes. Thought these attacks do not lead to concrete attacks against existing SSE schemes, they underline the importance of examining the feasibility of solutions that avoid leakage. A natural building block for doing so is ORAM. We use TWORAM to obtain the first constant-round, and asymptotically efficient SSE that can hide search/access patterns.</p><p>Our construction combines TWORAM and a non-recursive Path-ORAM (whose position map of the first level is not outsourced) such that searching for w requires (i) a single access on TWORAM; (ii) |DB(w)| parallel accesses to the non-recursive Path-ORAM (note that an access to a non-recursive ORAM requires only two rounds).</p><p>In particular, we use TWORAM to store pairs of the form (w, (count w , access w )), where w is a keyword, count w is the number of documents containing w and access w is the number of times w has been accessed so far. The keyword/document pairs (w||i, d i ) (where d i is the i-th document containing w) are then stored in the non-recursive Path-ORAM where their position in the Path-ORAM tree (namely the random path they are mapped to) is determined on the fly by using a PRF F as F k (w||i, access w ) (therefore there is no need to store the position map locally). To search for keyword w, we first access TWORAM to obtain (count w , access w ) (and increment access w ), and then generate all positions to look up in the Path-ORAM using the PRF F . These lookups can be parallelized and updating the paths can be piggybacked to the next search.</p><p>The above yields a construction with 4 rounds of interaction. Note that naively using ORAM for SSE would incur |DB(w)| ORAM accesses which imply at least |DB(w)| roundtrips (depending on the number of rounds of the underlying ORAM). As we said before, our construction does not leak the search pattern, by providing randomly generated tokens every time a search is performed. If we choose to store all documents in the obliviously-accessed memory, the access pattern can also be concealed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Other Related Work</head><p>Oblivious RAM. ORAM protocols with a non-constant number of roundtrips can be categorized into hierarchical <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b26">27]</ref>, motivated by the seminal work of Goldreich and Ostrovsky <ref type="bibr" target="#b15">[16]</ref>, and tree-based <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b35">36]</ref>, motivated by the seminal work of Shi et al. <ref type="bibr" target="#b30">[31]</ref>. We note however, that, by picking the data block size to be big (e.g., √ n bits), the number of rounds in tree-based ORAMs can be made constant, yet bandwidth increases beyond polylogarithmic, so such a parameter selection is not interesting.</p><p>Searchable Encryption. Song et al. <ref type="bibr" target="#b31">[32]</ref> were the first to explore feasibility of searchable encryption. Since then, many follow-up works have designed new schemes for both static data <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8]</ref> and dynamic data <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b34">35]</ref>. The security definitions also evolved over time and were eventually established in the work of <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8]</ref>. Unlike our construction, all these approaches use deterministic tokens, an therefore leak the search patterns. The only proposed approaches that are constant-round and have randomized tokens (apart from constructing SSE through Garbled RAM) are the ones based on functional encryption <ref type="bibr" target="#b29">[30]</ref>. However, such approaches incur a linear search overhead. We also note that one can obtain SSE with no search pattern leakage by using interactive ORAMs such as Path-ORAM <ref type="bibr" target="#b33">[34]</ref>, or other variants optimized for binary search <ref type="bibr" target="#b12">[13]</ref>. Secure Computation for RAM Programs. A recent line of work studies efficient secure two-party computation of RAM programs based on garbled circuits <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b18">19]</ref>. These constructions can also be used to design SSE that hide the search pattern-yet these approaches do not lead to constant-round SSE schemes, requiring the client to perform computation proportional to the size of the search result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Definitions for Garbled Circuits and Oblivious RAM</head><p>In this section, we recall definitions and describe building blocks we use in this paper. We use the notation C , S ↔ Π C, S to indicate that a protocol Π is executed between a client with input C and a server with input S. After the execution of the protocol the client receives C and the server receives S . For non-interactive protocols, we just use the left arrow notation (←) instead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Garbled Circuits</head><p>Garbled circuits were first constructed by Yao <ref type="bibr" target="#b37">[38]</ref> (see Lindell and Pinkas <ref type="bibr" target="#b24">[25]</ref> and Bellare et al. <ref type="bibr" target="#b1">[2]</ref> for a detailed proof and further discussion). A circuit garbling scheme is a tuple of PPT algorithms (GCircuit, Eval), where GCircuit is the circuit garbling procedure and Eval the corresponding evaluation procedure. More formally:</p><p>-( C, lab) ← GCircuit (1 κ , C): GCircuit takes as input a security parameter κ, and a Boolean circuit C. This procedure outputs a garbled circuit C and input labels lab, which is a set of pairs of random strings. Each pair in lab corresponds to every input wire of C (and in particular each element in the pair represents either 0 or 1). -y ← Eval( C, lab x ): Given a garbled circuit C and garbled input lab x , Eval outputs y = C(x).</p><p>Input Labels and Garbled Inputs. For a specific input x, we denote with lab x the garbled inputs, a "projection" of x on the input labels. E.g., for a Boolean circuit of two input bits z and w, it is lab = {(z 0 , z 1 ), (w 0 , w 1 )}, lab 00 = {z 0 , w 0 }, lab 01 = {z 0 , w 1 }, etc.</p><p>Correctness. Let (GCircuit, Eval) be a circuit garbling scheme. For correctness, we require that for any circuit C and an input x for C, we have that that C(x) = Eval( C, lab x ), where ( C, lab) ← GCircuit (1 κ , C).</p><p>Security. Let (GCircuit, Eval) be a circuit garbling scheme. For security, we require that for any PPT adversary A, there is a PPT simulator Sim such that the following distributions are computationally indistinguishable:</p><p>-Real A (κ): A chooses a circuit C. Experiment runs ( C, lab) ← GCircuit (1 κ , C) and sends C to A. A then chooses an input x. The experiment uses lab and x to derive lab x and sends lab x to A. Then it outputs the output of the adversary.</p><formula xml:id="formula_0">-Ideal A,Sim (κ): A chooses a circuit C. Experiment runs ( C, σ) ← Sim(1 κ , |C|)</formula><p>and sends C to A. A then chooses an input x. The experiment runs lab x ← Sim(1 κ , σ) and sends lab x to A. Then it outputs the output of the adversary.</p><p>The above definition guarantees adaptive security, since the adversary gets to choose input x after seeing the garbled circuit C. We only know how to instantiate garbling schemes with adaptive security in the random oracle model. In the standard model, existing garbling schemes achieve a weaker static variant of the above definition where the adversary chooses both C and input x at the same time and before receiving C.</p><p>Concerning complexity, we note that if the cleartext circuit C has |C| gates, the respective garbled circuit has size O(|C|κ). This is because every gate in the circuit is typically replaced with a table of four rows, each row storing encryptions of labels (each encryption has κ bits).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Oblivious RAM</head><p>We recall Oblivious RAM (ORAM), a notion introduced and first studied by Goldreich and Ostrovsky <ref type="bibr" target="#b15">[16]</ref>. ORAM can be thought of as a compiler that encodes the memory into a special format such that accesses on the compiled memory do not reveal the underlying access patterns on the original memory. An ORAM scheme consists of protocols (Setup, ObliviousAccess).</p><p>-σ, EM ↔ Setup (1 κ , M), ⊥ : Setup takes as input the security parameter κ and a memory array M and outputs a secret state σ (for the client), and an encrypted memory EM (for the server). -(M[y], σ ), EM ↔ ObliviousAccess (σ, y, v), EM : ObliviousAccess is a protocol between the client and the server, where the client's input is the secret state σ, an index y and a value v which is set to null in case the access is a read operation (and not a write). Server's input is the encrypted memory EM. Client's output is M[y] and an updated secret state σ and the server's output is an updated encrypted memory EM where</p><formula xml:id="formula_1">M[y] = v, if v = null.</formula><p>Correctness. Consider the following correctness experiment. Adversary A chooses memory M 0 . Consider EM 0 generated with σ 0 , EM 0 ↔ Setup (1 κ , M 0 ), ⊥ ). The adversary then adaptively chooses memory locations to read and write. Denote the adversary's read/write queries by (y 1 , v 1 ), . . . , (y q , v q ) where v i = null for read operations. A wins in the correctness game if (M i-1 [y i ], σ i ), EM i are not the final outputs of the protocol ObliviousAccess (σ i-1 , y i , v i ), EM i-1 for any 1 ≤ i ≤ q, where M i , EM i , σ i are the memory array, the encrypted memory array and the secret state, respectively, after the i-th access operation, and ObliviousAccess is run between an honest client and server. The ORAM scheme is correct if the probability of A in winning the game is negligible in κ.</p><p>Security. An ORAM scheme is secure in the semi-honest model if for any PPT adversary A, there exists a PPT simulator Sim such that the following two distributions are computationally indistinguishable.</p><formula xml:id="formula_2">-Real A (κ): A chooses M 0 . Experiment then runs σ 0 , EM 0 ↔ Setup (1 κ , M 0 ), ⊥ . For i = 1, . . . , q, A makes adaptive read/write queries (y i , v i )</formula><p>where v i = null on reads, for which the experiment runs the protocol</p><formula xml:id="formula_3">(M i-1 [y i ], σ i ), EM i ↔ ObliviousAccess (σ i-1 , y i , v i ), EM i-1 .</formula><p>Denote the full transcript of the above protocol by t i . Eventually, the experiment outputs (EM q , t 1 , . . . , t q ) where q is the total number of read/write queries. -Ideal A,Sim (κ): The experiment outputs (EM q , t 1 , . . . , t q ) ↔ Sim(q, |M 0 |, 1 κ ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TWORAM Construction</head><p>Our TWORAM construction uses an abstraction of tree-based ORAM schemes, e.g., Path-ORAM <ref type="bibr" target="#b33">[34]</ref>. We start by describing this abstraction informally. Then we show how to turn the interactive Path-ORAM protocol (e.g., the one by Stefanov et al. <ref type="bibr" target="#b33">[34]</ref>) into a two-round ORAM protocol, using the abstraction that we present below. We now give some necessary notation that we need for understanding our abstraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Notation</head><p>Let n = 2 L be the size of the initial memory that we wish to access obliviously. This memory is denoted by</p><formula xml:id="formula_4">A L [1], A L [2], . . . , A L [n] where A L [i]</formula><p>is the i-th block of the memory. Given location y that we wish to access, let y L , y L-1 , . . . , y 1 be defined recursively as y L = y and y i = ceil(y i+1 /2), for all i = L -1, L-2, . . . , 1. For example, for L = 4 and y = 13, we have</p><formula xml:id="formula_5">-y 1 = ceil(ceil(ceil(y/2)/2)/2) = 2. -y 2 = ceil(ceil(y/2)/2) = 4. -y 3 = ceil(y/2) = 7. -y 4 = 13.</formula><p>Also define b i = 1y i %2 to be a bit (namely b i indicates if y i is even or not). Finally, on input a value x of 2 • L bits, select(x, 0) selects the first L bits of x, while select(x, 1) selects the last L bits of x. We note here that both y i and b i are functions of y, but we do not indicate this explicitly so that not to clutter notation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Path-ORAM Abstraction</head><p>We start by describing our abstraction of Path-ORAM construction. In Appendix A we describe formally how this abstraction can be used to implement the interactive Path-ORAM algorithm <ref type="bibr" target="#b33">[34]</ref> (with log n rounds of interaction). We note that the details in Appendix A are provided only for helping better understanding. Our construction can be understood based on just the abstraction defined below.</p><p>Roughly speaking, Path-ORAM algorithms encode the original memory A L in the form of L memories</p><formula xml:id="formula_6">A L , A L-1 , . . . , A 1 ,</formula><p>where A L stores the original data and the remaining memories A i store information required for accessing data in A L obliviously. Each A i has 2 i entries, each one storing blocks of 2 • L bits (for ease of presentation we assume the block size is Θ(log n) but our results apply with other block parameterizations as well). Memories A L , A L-1 , . . . , A 2 are stored in trees T L , T L-1 , . . . , T 2 respectively. The smallest memory A 1 is kept locally by the client. The invariant that is maintained is that any block A i [x] will reside in some leaf-to-root path of tree T i , and specifically on the path that starts from leaf x i in T i . The value x i itself can be retrieved by accessing A i-1 , as we detail in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reading a Value</head><formula xml:id="formula_7">A L [y]. To read a value A L [y], one first reads A 1 [y 1 ] from local storage and computes x 2 ← select(A 1 [y 1 ], b 1</formula><p>) (recall definitions of y 1 and b 1 from Sect. 3.1). Then one traverses the path starting from leaf x 2 in T 2 . This path is denoted with</p><formula xml:id="formula_8">T 2 (x 2 ). Block A 2 [y 2 ] is guaranteed to be on T 2 (x 2 ). Then one computes x 3 ← select(A 2 [y 2 ], b 2 )</formula><p>, and continues in this way. In the end, one will traverse path T L (x L ) and will eventually retrieve block A L [y]. See Fig. <ref type="figure" target="#fig_0">1</ref>. Updating the Paths. Once the above process finishes, we need to make sure that we do not access the same leaf-to-root paths in case we access A L [y] again in the future-this would violate obliviousness. Thus, for i = 2, . . . , L, we perform the following tasks:</p><p>1. We remove all blocks from T i (x i ) and copy them into a data structure C i called stash. In our abstraction, stash C i is viewed as an extension of the root of tree T i ; 2. In the stash</p><formula xml:id="formula_9">C i-1 , we set select(A i-1 [y i-1 ], b i-1 ) ← r i ,</formula><p>where r i is a fresh random number in [1, 2 i ] that replaces x i from above. This effectively means that block A i [y i ] should be reinserted on path T i (r i ), when eviction from stash C i takes place;</p><formula xml:id="formula_10">T 2 T 3 x 2 x 3 x L T L … A L [y L ] A 3 [y 3 ] A 2 [y 2 ] A 1 [y 1 ]</formula><p>val y y y y Repeating this process yields a path pL in TL, traversing which yields the final value</p><formula xml:id="formula_11">AL[yL] = AL[y].</formula><p>Note that y is passed from tree Ti-1 to tree Ti so that the index yi (and the bit bi) can be computed for searching for the right block on path pi.</p><p>3. We evict blocks from stash C i back to tree T i (x i ), respecting the new assignments made above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Syntax.</head><p>A Path-ORAM consists of three procedures (Initialize, Extract, Update) with syntax:</p><p>-T ← Initialize(1 κ , A L ): Given a security parameter κ and memory A L as input, Setup outputs a set of L -1 trees T = {T 2 , T 3 , . . . , T L } and an array of two entries A 1 . A 1 is stored locally with the client and T 2 , . . . , T L are stored with the server. -x i+1 ← Extract(i, y, T i (x i )) for i = 2, . . . , L. Given the tree number i, the final memory location of interest y and a leaf-to-root path T i (x i ) (that starts from leaf x i ) in tree T i , Extract outputs an index x i+1 to be read in the next tree T i+1 . The client can obtain x 2 from local storage as</p><formula xml:id="formula_12">x 2 ← select(A 1 [y 1 ], b 1</formula><p>). The obtained value x 2 is sent to the server in order for the server to continue execution. Finally, the server outputs x L+1 , which is the desired value A L [y].</p><p>ExtractBucket Algorithm. In Path-ORAM <ref type="bibr" target="#b33">[34]</ref>, internal nodes of the trees store more than one block (z, A i [z]), in the form of buckets. We note that Extract can be broken to work on individual buckets along a rootto-leaf path in a tree T i . In particular, we can define the algorithm π ← ExtractBucket(i, y, b) where i is the tree of interest, y is the memory location that needs to be accessed, and b is a bucket corresponding to a particular node on the leaf-to-root path. π will be found at one of the nodes on the leaf-to-root path. Note that the algorithm Extract can be implemented by repeatedly calling ExtractBucket for every b on</p><formula xml:id="formula_13">T i (x i ). -{A 1 , T 2 (x 2 ), . . . , T L (x L )} ← Update(y, op, val, A 1 , T 2 (x 2 ), . . . , T L (x L ). Pro-</formula><p>cedure Update takes as input the leaf-to-root paths (and local storage A 1 ) that were traversed during the access and accordingly updates these paths (and local storage A 1 ). Additionally, Update ensures the new value val is written to A L [y], if operation op is a "write" operation.</p><p>An implementation of the above abstractions, for Path-ORAM <ref type="bibr" target="#b33">[34]</ref>, is given in Algorithms 1, 2 and 3 in Appendix A.1. Note that the description of the Update procedure <ref type="bibr" target="#b33">[34]</ref> abstracts away the details of the eviction strategy. The Setup and ObliviousAccess protocols of the interactive Path-ORAM using these abstractions are given in Figs. <ref type="bibr" target="#b5">6</ref>  We recall that the bandwidth overhead for Path-ORAM <ref type="bibr" target="#b33">[34]</ref> is</p><formula xml:id="formula_14">O(log 3 n) bits and the client storage is O(log 2 n) • ω(1) bits, for a block size of 2 • L = 2 • log n bits.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">From log n Rounds to Two Rounds</head><p>Existing Path-ORAM protocols implementing our abstraction require log n rounds (see ObliviousAccess protocol in Fig. <ref type="figure">7</ref>). The main reason for that is the following: In order for the server to determine the index of leaf x i from which the next path traversal begins, the server needs to access A i-1 [y i-1 ], which is stored encrypted at some node on the path starting from leaf x i-1 in tree T i-1see Fig. <ref type="figure" target="#fig_0">1</ref>. Therefore the server has to return all encrypted nodes on T i-1 (x i-1 ) to the client, who performs the decryption locally, searches for A i-1 [y i-1 ] (via the ExtractBucket procedure) and returns the value x i to the server (see Line 10 of the ObliviousAccess protocol in Fig. <ref type="figure">7</ref>). Our Approach. To overcome this difficulty, we do not encrypt the blocks in the buckets. Instead, for each bucket stored at a tree node u, we prepare a garbled circuit that hardcodes, among other things, the blocks that are contained in the bucket. Subsequently, this garbled circuit executes the ExtractBucket algorithm on the hardcoded blocks and outputs either ⊥ or the next leaf index π, depending on whether the search performed by ExtractBucket was successful or not. The output, whatever that is, is fed as a garbled input to either the left child bucket or the right child bucket (depending on the currently traversed path) or the next root bucket (in case u is a leaf) of u. In this way, by the time the server has executed all the garbled circuits along the currently traversed Fig. <ref type="figure">2</ref>. Formal description of the naive bucket circuit. Notation: Given lab, the set of input labels for a garbled circuit, we let laba denote the garbled input labels (i.e., the labels taken from lab) corresponding to the input value a.</p><p>path, he will be able to pass the index π to the next tree as a garbled input, and continue the execution in the same way without having to interact with the client. Therefore the client can obliviously retrieve his value A L [y] in only two rounds of communication.</p><p>Unfortunately, once these garbled circuits have been consumed, they cannot be used again since this would violate security of garbled circuits. To avoid this problem, the client downloads all the data that was accessed before, decrypts them, runs the Update procedure locally, recomputes the garbled circuits that were consumed before, and stores the new garbled circuits locally. In the next access, these garbled circuits will be sent along with the query. Therefore the total number of communication rounds is equal to two (note that this approach requires permanent client storage-for transient storage, the client will have to send the garbled circuits immediately which would increase the rounds to three). We now continue with describing the bucket circuit that needs to be garbled for our construction. Naive Bucket Circuit. To help the reader, in Fig. <ref type="figure">2</ref> we describe a naive version of our bucket circuit that leads to an inefficient construction. Then we give the full-fledged description of our bucket circuit in Fig. <ref type="figure" target="#fig_1">3</ref>. The naive bucket circuit has inputs, outputs and hardcoded parameters, which we detail in the following. Inputs. The input of the circuit is a triplet consisting of the following information:</p><p>1. The index of the leaf p from which the currently explored path begins; 2. The final location to be accessed y; 3. The output from previous bucket π (can be the actual value of the next index to be explored or ⊥).</p><p>Outputs. The outputs of the circuit are the next node to be executed, along with its garbled inputs. For example, if the current node u is not a leaf (see Lines 4 and 5 in Fig. <ref type="figure">2</ref>), the circuit outputs the garbled inputs of either the left or the right child, whereas if the current node is a leaf (see Lines 6-8 in Fig. <ref type="figure">2</ref>), the circuit outputs the garbled inputs of the next root to be executed. Note that outputting the garbled inputs is easy, since the bucket circuit hardcodes the input labels of the required circuits. Finally we note that the ExtractBucket(i, y, bucket) algorithm used in Fig. <ref type="figure">2</ref> can be found in Appendix A.1-see Algorithm 2.</p><p>Hardcoded Parameters. The circuit for node u hardcodes:</p><p>1. The node identifier u that consists of a triplet (i, j, k) where -i ∈ {2, . . . , L} is the tree number where node u belongs to; -j ∈ {0, . . . , 2 i-1 } is the depth of node u; -k ∈ {0, . . . , 2 j -1} is the oder of node u in the specific level.</p><p>For example, the root of tree T 3 will be denoted (3, 0, 0), while its right child will be (3, 1, 1). 2. The bucket information bucket (i.e., blocks (x, A i [x], r) contained in node u-recall r is the path index in T i assigned to A i [x]); 3. The input labels leftLabels, rightLabels and nextRootLabels that are used to compute the garbled inputs for the next circuit to be executed. Note that leftLabels and rightLabels are used to prepare the next garbled inputs when node u is an internal node (to go either to the left or the right child), while nextRootLabels are used when node u is a leaf (to go to the next root).</p><p>Final Bucket Circuit. In the naive circuit presented before, we hardcode the input labels of the root node root of every tree T i into all the nodes/circuits of tree T i-1 . Unfortunately, in every oblivious access, the garbled circuits of all roots are consumed (and therefore root's circuit as well), hence all the garbled circuits of tree T i-1 will have to be recomputed from scratch. This cost is O(n), thus very inefficient. We would like to mimimize the number of circuits in T i-1 that need to be recomputed and ideally make this cost proportional to O(log n).</p><p>To achieve that, we observe that, instead of hardcoding input labels nextRootLabels in the garbled circuit of every node of tree T i-1 , we can just pass them as garbled inputs to the garbled circuit of every node of tree T i-1 . The final circuit is given in Fig. <ref type="figure" target="#fig_1">3</ref>. Note that the only difference of the new circuit from the naive circuit is in the computation of the garbled inputs leftNewLabels (p,y,π,nextRootLabels) and rightNewLabels (p,y,π,nextRootLabels) ,</p><p>where nextRootLabels is added in the subscript (see Line 5 of both Figs. <ref type="figure" target="#fig_1">3</ref> and<ref type="figure">2</ref>), to account for the new input of the new circuit. Note also that we indicate the change in the input format by using "leftNewLabels" instead of just "leftLabels" and "rightNewLabels" instead of just "rightLabels". nextRootLabels have the same meaning in both circuits. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Protocols SETUP and OBLIVIOUSACCESS of our construction</head><p>We now describe in detail the Setup and ObliviousAccess protocols of TWORAM.</p><p>SETUP. The Setup protocol is described in Fig. <ref type="figure" target="#fig_2">4</ref>. Just like the setup for the interactive ORAM protocol (see Fig. <ref type="figure">6</ref> in Appendix A.2), in TWORAM, the client does some computation locally in the beginning (using his secret key) and then outputs some "garbled information" that is being sent to the server. In particular:</p><p>1. After producing the trees T 2 , T 3 , . . . , T L using algorithm Initialize, the client prepares the garbled circuit of Fig. <ref type="figure" target="#fig_1">3</ref> for all the nodes u ∈ T i , for all trees T i .</p><p>It is important this computation takes place from the leaves towards the root (that is why we write j ∈ {i -1, . . . , 0} in Line 2 of Fig. <ref type="figure" target="#fig_2">4</ref>), since a garbled circuit of a node u hardcodes the input labels of the garbled circuits of its children-so these need to be readily available by the time u's garbled circuit is computed. 2. Apart from the garbled circuits, the client needs to prepare garbled inputs for the nextRootLabels inputs of all the roots of the trees T i . These are essentially the β i 's computed in Line 4 of Fig. <ref type="figure" target="#fig_2">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OBLIVIOUSACCESS.</head><p>The ObliviousAccess protocol of TWORAM is described in Fig. <ref type="figure" target="#fig_3">5</ref>. The first step of the protocol is similar to that of the interactive scheme (see Fig. <ref type="figure">7</ref> in Appendix), where the client accesses local storage A 1 to compute the path index x 2 that must be traversed in T 2 . However, the main difference is that, instead of sending x 2 directly, the client sends the garbled input that corresponds to x 2 for the root circuit of tree T 2 , denoted with α in Fig. <ref type="figure" target="#fig_3">5</ref>.</p><p>We note here that α is not enough for the first garbled circuit to start executing, and therefore the server complements this garbled input with β 2 (see Server Line 1), the other half that was sent by the client before and that represents the garbled inputs for the input labels of the next root. Subsequently, the server starts executing the garbled circuits one-by-one, using the outputs of the first circuit, as garbled inputs to the second one, and so on. Eventually, the clients reads and decrypts all paths T i (x i ), retrieving the desired value (see Client Line 2). Finally, the client runs the Update, re-garbles the circuits that got consumed and waits until the next query to send them back. We can now state the main result of our paper.</p><p>Theorem 1. The protocols Setup and ObliviousAccess from Figs. <ref type="figure" target="#fig_2">4</ref> and<ref type="figure" target="#fig_3">5</ref> respectively comprise a two-round secure ORAM scheme (as defined in Sect. 2.2), assuming the garbling scheme used is secure (as defined in Sect. 2.1) and the encryption scheme used is CPA-secure.</p><p>The proof of the above theorem can be found in Appendix A.3. Concerning complexity, it is clear that the only overhead that we are adding on Path-ORAM <ref type="bibr" target="#b33">[34]</ref> is a garbled circuit per bucket-this adds a multiplicative security parameter factor on all the complexity measures of Path-ORAM. E.g., the bandwidth overhead of our construction is O(κ•log 3 n) bits (for blocks of 2 log n bits).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Optimizations</head><p>Recall that in the garbling procedure of a circuit C, one has the following choices: (i) either to garble C in a way that during evaluation of the garbled circuit on x the output is the cleartext value C(x); (ii) or to garble C in a way that during evaluation of the garbled circuit on x the output is the garbled labels corresponding to the value C(x). We now describe an optimization for a specific circuit C that we will be using in our construction that uses the above observation. General Optimization. Consider a circuit that performs the following task: It hardcodes two k-bit strings s 0 and s 1 , takes an input a bit b and outputs s b . This cleartext circuit has size O(k), so the garbled circuit for that will have size O(k 2 ). To improve upon that we consider a circuit C that takes as input bit b and outputs the same bit b! This cleartext circuit has size O(1). However, to make sure that the output of the garbled version of C is always s b , we garble C by outputting the garbled label corresponding to b, namely s b (i.e., using (ii) from above). In particular, during the garbling procedure we use s 0 as the garbled label output for output b = 0 and we use s 1 as the garbled label output for the output b = 1. Note that the size of the new garbled circuit has size O(k), yet it has exactly the same I/O behavior with the garbling of C, which has size O(k 2 ).</p><p>-Improving cState -Not Hard-Coding Input Labels Inside the Bucket Circuit. In the construction we described, we include the input labels leftLabels, rightLabels in the circuit C[u, bucket, leftLabels, rightLabels]. Consequently, the size of the ungarbled version of this circuit grows with the size of leftLabels and rightLabels which is κ • |cState|. We can easily use the general optimization described above, for each bit of |cState|, to make the size of the ungarbled version of our circuit only grow with |cState|. -Improving nState -Input Labels Passing. In the construction described previously, for each tree, an input value nState is passed from the root to a leaf node in the tree. However this value is used only at the leaf node. Recall that the nState value passed from the root to a leaf garbled circuits in the tree T i is exactly the value cState i+1,0,0 , the input labels of the root garbled circuit of the tree T i+1 . Since each ungarbled circuit gets this value as input, therefore each of one of them needs to grow with κ • |cState|. <ref type="foot" target="#foot_1">2</ref> We will now describe an optimization such that the size of the garbled version, rather than the clear version, grows linearly in κ • |cState|. Note that in our construction the value cState i+1,0,0 is not used at all in the intermediate circuits as it gets passed along the garbled circuits for tree T i . In order to avoid this wastefulness, for all nodes i ∈ {1, . . . , L}, j ∈ [i], k ∈ [2 j ] we sample a value r (i,j,k) of length κ • |cState| and hardcode the values r (i,j,k) ⊕ r (i,j+1,2k) and r (i,j,k) ⊕ r (i,j+1,2k+1) inside the garbed circuit Ci,j,k which output the first of two values if the execution goes left and the second if the execution goes right. Note that a garbled circuits grows only additively in κ • |cState| because of this change. This follows by using the first optimization. Additionally, we include the value cState i+1,0,0 ⊕ r (i,0,0) with the root node of the tree T i . The leaf garbled circuit (i, i -1, k) in tree T i is constructed assuming r (i,i-1,k) is the sequence of input labels for the root garbled circuit of the tree T i+1 . <ref type="foot" target="#foot_2">3</ref> Let α 0 , . . . α i-1 be the strings output during the root to a leaf traversal in tree T i . Now observe that cState i+1,0,0 ⊕ r (i,0,0) ⊕ j∈[i] α j is precisely cState i+1,0,0 ⊕ r (i,i- 1,k) where k is the leaf node in the traversed path. At this point it is easy to see that given the output of the leaf grabled circuit for tree T i one can compute the required input labels for the root of tree T i+1 .</p><p>The update mechanism in our construction can be easily adapted to work with this change. Here note that we would now include the values r (i,j,k) , r (i,j+1,2k) and r (i,j+1,2k+1) in the ciphertext X (i,j,k) . Also note that we will use fresh r (•,•,•) values whenever a fresh garbled circuit for a node is generated. The security argument now additionally uses the fact that the outputs generated by garbled circuits in two separate root to leaf traversals depend on completely independent r (•,•,•) values.</p><p>Note that the above modification leaks what value is passed by the executed leaf garbled circuit in tree T i to the root garbled circuit in tree T i+1 . This can be deduced based on what bit values of cState i+1,0,0 ⊕ r (i,0,0) are revealed. This can be tackled by randomly permuting the labels in cState i+1,0,0 and passing the information on this permutations along with in the tree to leaf garbled circuits. Note that the size of this information is small. Taken together these two optimizations reduce the size of each garbled circuit to O(κ • (|bucket| + |cState|)). Since |bucket| &gt; |cState| this expression reduces to O(κ • |bucket|). This implies that the overhead of our construction is just κ times the overhead of the underlying Path ORAM scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Searchable Encryption Construction Using TWORAM</head><p>The natural way of designing an SSE scheme that does not leak the search and access patterns using an ORAM scheme is to first use a data structure for storing keyword-document pairs, setup the data structure in memory using an ORAM setup and then read/write from it using ORAM operations. Since ORAM hides the read/write access patterns, but it does not hide the number of memory accesses, one needs to ensure that the number of memory accesses for each operation is also data-independent. Fortunately, this can be achieved by not letting the key used for the hash table be the output of a pseudorandom function applied to the keyword w, and not the keyword w itself.</p><p>We start by giving some definitions and then describe constructions that can be instantiated using any ORAM scheme. We then show how to obtain a significantly more efficient instantiation using a combination of TWORAM and a non-recursive Path-ORAM scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Hash Table Definition</head><p>A hash table is a data structure commonly used for mapping keys to values <ref type="bibr" target="#b6">[7]</ref>. It often uses a hash function h that maps a key to an index (or a set of indices) in a memory array M where the value associated with the key may be found. In particular, h takes as input a keyword key and outputs a set of indices i 1 , . . . , i c where c is a parameter. The value associated with key is in one of the locations </p><formula xml:id="formula_15">M[i 1 ], . . . M[i c ].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Searchable Definition</head><p>A database D is a set of document/keyword-set pair</p><formula xml:id="formula_16">DB = (d i , W i ) N i=1 .</formula><p>Let W = ∪ N i=1 W i be the universe of keywords. A keyword search query for w should return all d i where w ∈ W i . We denote this subset of DB by DB(w). A searchable symmetric encryption scheme consists of protocols SSESetup, SSESearch and SSEAdd. The following formalization first appeared in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8]</ref>.</p><p>-σ, EDB ↔ SSESetup (1 κ , DB), ⊥ : SSESetup takes as client's input database DB and outputs a secret state σ (for the client), and an encrypted database EDB which is outsourced to the server. -(DB(w), σ ), EDB ↔ SSESearch (σ, w), EDB : SSESearch is a protocol between the client and the server, where client's input is the secret state σ and the keyword w he is searching for. Server's input is the encrypted database EDB. Client's output is the set of documents containing w, i.e. DB(w) as well an updated secret state σ and the server obtains an updated encrypted database EDB . -σ , EDB ↔ SSEAdd (σ, d), EDB : SSEAdd is a protocol between the client and the server, where client's input is the secret state σ and a document d to be inserted into the database. Server's input is the encrypted database EDB.</p><p>Client's output is an updated secret state σ and the server's output is an updated encrypted database EDB which now contains the new document d.</p><p>Correctness. Consider the following correctness experiment. An adversary A chooses a database DB 0 . Consider the encrypted database EDB 0 generated using SSESetup (i.e., σ 0 , EDB 0 ↔ SSESetup (1 κ , DB 0 ), ⊥ ). The adversary then adaptively chooses keywords to search and documents to add to the database, and the respective protocols SSESearch and SSEAdd are run between an honest client and server, outputting the updated EDB, DB and σ. Denote the operations chosen by the adversary with w 1 , . . . , w q . A wins in the correctness game if for some search query w i it is</p><formula xml:id="formula_17">(DB i (w i ), σ i ), EDB i = SSESearch (σ i-1 , w i ), EDB i-1 ,</formula><p>where DB i , EDB i are the database and encrypted database, respectively, after the i-th search. The SSE scheme is correct if the probability of A winning the game is negligible in κ.</p><p>Security. We discuss security in the semi-honest model. It is parametrized by a leakage function L, which explains what the adversary (the server) learns about the database and the search and update queries, while interacting with a secure SSE scheme. A SSE scheme is L-secure if for any PPT adversary A, there exist a simulator Sim such that the following two distributions are computationally indistinguishable.</p><p>-Real A (κ): A chooses DB 0 . The experiment then runs</p><formula xml:id="formula_18">σ 0 , EDB 0 ↔ SSESetup (1 κ , DB 0 ), ⊥ .</formula><p>A then adaptively makes search queries w i , which the experiment answers by running the protocol</p><formula xml:id="formula_19">DB i-1 (w i ), σ i ↔ SSESearch (σ i-1 , w i ), EDB i-1 .</formula><p>Denote the full transcripts of the protocol by t i and with EDB the final encrypted database. Add queries are handled in a similar way. Eventually, the experiment outputs (EDB, t 1 , . . . , t q ), where q is the total number of search/add queries made by A. -Ideal A,Sim,L (κ): A chooses DB 0 . The experiment runs</p><formula xml:id="formula_20">(st 0 , EDB 0 ) ↔ Sim(L(DB 0 )),</formula><p>where st 0 is the initial state of the simulator. On input any search query w i from A, the experiment adds (w i , search) to the history H, and on an add query d i it adds (d i , add) to H. It then runs (t i , st i ) ↔ Sim(st i-1 , L(DB i-1 , H)). Eventually, the experiment outputs (EDB , t 1 , . . . , t q ) where q is the total number of search/add queries made by A.</p><p>Leakage. The level of security one obtains from a SSE scheme depends on the leakage function L. Ideally L should only output the total number w∈W |DB(w)| of (w, d) pairs, the total number of unique keywords |W | and |DB(w)| for any searched keyword w. Achieving this level of security is only possible if the SSESearch operation outputs the documents themselves to the client. If instead (as is common for applications with large document sizes), it returns document identifiers which the client then uses to retrieve the actual documents, any SSE protocol would also leak the access pattern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">SSE from any ORAM</head><p>First Approach. The common way of storing a database of documents in a hash table is to insert a key-value pair (w, d) into the table for any keyword w in a document d. Searching for a document with keyword w then reduces to looking up w in the table. If there is more than one document containing a keyword w, a natural solution is to create a bucket B w storing all the documents containing w and storing the bucket in position pt w of an array A. One then inserts (w, pt w ) in a hash table. Now, to search for a keyword w, we first look up (w, pt w ), and then access A[pt w ] to obtain the bucket B w of all the desired documents. A subtle issue is that the distribution of bucket sizes would leak information about the database even before any keyword is searched. As a result, for this approach to be fully-secure, one needs to pad each bucket to an upperbound on the number of searchable documents per keyword.</p><p>Next we describe the SSE scheme more formally. Given a hash table H = (hsetup, hlookup, hwrite), and an ORAM scheme ORAM = (Setup, ObliviousAccess), we construct an SSE scheme (SSESetup, SSESearch, SSEAdd) as follows.</p><p>1. σ, ↔ SSESetup (1 κ , max, DB), ⊥ : Given an initial set of documents DB, client lets S be the set of key-value pairs (w, pt w ) where pt w is an index to an array of buckets A such that A[pt w ] stores the bucket of all documents in DB containing w. Each bucket is padded to the maximum size max with dummy documents. Client first runs hsetup(S, size) to obtain (h, M). size is the maximum size of hash table H. Then client and server run σ 1 , EM ↔ Setup (1 κ , M), ⊥ . Cleint and server also run σ 2 , EA ↔ Setup (1 κ , A), ⊥ Note that server's output is EDB = (EM, EA) and client's output is σ = (σ 1 , h, σ 2 ). 2. SSESearch (σ, w), EDB : Client computes i 1 , . . . , i c ← h(w). Then, client and server run ObliviousAccess ((σ 1 , i j , null), EM for j ∈ {1, . . . , c} for client to obtain M[i j ]. If client does not find (w, pt w ) in one of the retrieved locations it lets pt w = 0, corresponding to a dummy access to the index 0 in A.</p><p>Client and server then run ObliviousAccess (σ 2 , pt w , null), EA ) for client to obtain the bucket B w stored in A[pt w ]. Client outputs all the non-dummy documents in B w . 3. SSEAdd (σ, d), EDB : For every w in d, client computes i 1 , . . . , i c ← h(w) and client and server run ObliviousAccess (σ 1 , i j , null), EM for j ∈ {1, . . . , c} for client to obtain M[i j ]. If (w, pt w ) is in the retrieved locations let i * j be the location it was found at. If not, let pt w be the first empty location in A, and let i * j be the first empty location from the retrieved ones in M.</p><p>Client and server run ObliviousAccess (σ 1 , i * j , (w, pt w )), EM . Client and server run ObliviousAccess (σ 2 , pt w , null), EA to retrieve A[pt w ]. Let B w be the retrieved bucket. Client inserts d in the first dummy entry of B w , denoting the new bucket by B w . Client and server run ObliviousAccess (σ 2 , pt w , B w ), EA .</p><p>The main disadvantage of the above construction is that we need to anticipate an upper bound on the bucket sizes, and pad all buckets to that size. Given that in practice there are often keywords that appear in a large number of documents, and keywords that only appear in a few, the padding will lead to inefficiency. Our next solution addresses this issue but instead has a higher round complexity.</p><p>Second Approach. Instead of storing all documents matching a keyword w in one bucket, we store each of them separately in the hash table, using a different keyword. In particular, we can store the key-value pair (w||i, d) in the hash table for the ith document d containing w. This works fine except that it requires looking up w||count for an incremental counter count until the keyword is no longer found in the table.</p><p>To make this approach cleaner and the write operations more efficient, we maintain two hash tables, one for storing the counter representing the number of documents containing the keyword, and one storing the incremental key-value pairs as described above. To lookup a keyword w, one first looks up the counter count in the first table and then makes count lookup queries to the second table.</p><p>We now describe the above SSE scheme in more detail. Given a hash table H = (hsetup, hlookup, hwrite) and a scheme ORAM = (Setup, ObliviousAccess), we construct an SSE scheme (SSESetup, SSESearch, SSEAdd) as follows:</p><p>1. σ, EDB ↔ SSESetup (1 κ , DB), ⊥ : Given an initial set of documents DB.</p><p>Let S 1 be the set of (w, count w ) pairs and S 2 be the set of key-value pairs (w||i, d i ) for Client then computes i 1 , . . . , i c ← h 2 (w||count w + 1) and client and server run ObliviousAccess (σ 2 , i j , null), EM 2 to retrieve M 2 [i j ] for j ∈ {1, . . . , c}. Let i k be the first empty location among them. Client and server run ObliviousAccess (σ 2 , i k , (w||count + 1)), EM 2 .</p><p>The main disadvantage of our second approach is that for each search, it requires count w ORAM accesses to retrieve all matching documents. This means that the bandwidth/computation overhead of ORAM scheme is multiplied by count w which can be large for some keywords. More importantly, it would require O(count w ) rounds since the ORAM accesses cannot be parallelized in our constant-round ORAM construction. In particular, note that each memory garbled circuit in the construction can only be used once and needs to be replaced before the next memory access. Finally, the constant-round ORAM needs to store a memory array that is proportional to the number of (w, d) tuples associated with the database, which is significantly larger than the number of unique keywords, increasing the storage overhead of the resulting SSE scheme.</p><p>Next, we address all these efficiency concerns, showing a construction that only requires a single ORAM access using our constant-round construction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">SSE Path-ORAM</head><p>The idea is to not only store a per-keyword counter count w as before, but also to store a access w that represents the number of search/add queries performed on w so far. Similar to the previous approach, the tuple (w, (count w , access w )) is stored in a hash table that is implemented using our constant-round ORAM scheme TWORAM. The count w is incremented whenever a new document containing w is added and the access w is incremented after each search/add query for w.</p><p>The tuples (w||i, d i ) for all d i containing w are then stored in a one-level (non-recursive) Path-ORAM. In order to avoid storing a large client-side position map for this non-recursive Path-ORAM, we generate/update the positions pseudorandomly using a PRF F K (w||i||access w ). Since each document d i has a different index and each search/add query for w will increment access w , the pseudorandomness property of F ensures that this way of generating the position maps is indistinguishable from generating them at random. Now the client only needs to keep the secret key K. Note that since we are using a one-level Path-ORAM to store the documents, we can handle multiple parallel accesses without any problems, hence obtaining a constant-round search/add complexity. Furthermore, we only access TWORAM(which uses garbled circuits) once per keyword search to retrieve the tuple (w, (count w , access w )), so TWORAM's overhead is not multiplied by count w for each search/add query. Similarly, the storage overhead of TWORAMis only for a memory array of size |W | (number of unique keywords in documents) which is significantly smaller than the number of keyword-document pairs needed in the general approach.</p><p>We need to make a few small modifications to the syntax of the abstraction for Path-ORAM here. First, since we generate the position map on the fly using a PRF, it is convenient to modify the syntax of the Update procedure to take the new random position as input, instead of internally generating it in our original syntax. Also, since we are not extracting an index y from the Path-ORAM and instead are extracting a tuple of the form (w||i, d i ), we will pass w||i as input in place of y in the Extract and Update operations.</p><p>We now describe the SSE scheme. Given a hash table H = (hsetup, hlookup, hwrite), our constant-round ORAM scheme TWORAM = (Setup, ObliviousAccess), a single level Path-ORAM scheme with procedures (Initialize, Extract, Update), and a PRF function F , we build an SSE scheme (SSESetup, SSESearch, SSEAdd) as follows:</p><p>1. σ, EDB ↔ SSESetup (1 κ , DB), ⊥ : Given an initial set of documents DB, let S be the set of (w, (count w , access w = 0)) where count w is the number of documents containing w, and access w denotes the number of times the keyword w has been searched/added. Client runs hsetup(S, size) to obtain (h, M). size is the anticipated maximum size of the hash table H. Then client and server run σ s , EM ↔ Setup (1 κ , M), ⊥ .</p><p>Let A L be an initially empty memory array with a size that estimates an upper bound on total number of (w, d) pairs ind DB. Client runs T ← Initialize(1 κ , A L ), and only sends the tree T L for the last level to server, and discards the rest.</p><p>Client generates a PRF key K ← {0, 1} κ . For every item (w, (count w , access w )) in S, and for 1 ≤ i ≤ count w (in parallel): (a) Client lets val w,i = (w||i, d i ) where d i denotes the ith document in DB containing w. (b) Client lets x w,i = F K (w||i||access w ) and sends x w,i to server who returns the encrypted buckets on path T L (x w,i ) which client decrypts itself. (c) Client runs {T L (x w,i )} ← Update(w||i, write, val w,i , T L (x w,i ), x w,i ), where x w,i = F K (w||i||access w + 1), to insert val w,i into the path along its new path T L (x w,i ). Client then encrypts the updated path T L (x w,i ) and sends it to server who updates T L . Note that server's output is EDB = (EM, T L ) and client's output is σ = (σ s , h, K).   return A1, T2(x2), T3(x3), . . . , TL(xL); 10: end procedure Fig. <ref type="figure">6</ref>. description of the Setup protocol for the interactive ORAM <ref type="bibr" target="#b33">[34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Path ORAM Protocols with log n Rounds of Interaction Using the Abstraction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Proof of Security for TWORAM</head><p>Now we prove TWORAM is a secure realization of an oblivious RAM scheme as described in Sect. 2.2. We start by arguing correctness. Note that the garbled circuits implement the exact same procedures as are required in our abstraction. Therefore the correctness of our scheme follows directly from the correctness of the underlying Path ORAM scheme and garbled circuits construction. Next we argue security. In other words we need to argue that for any adversary A, there exists a simulator Sim for which the following two distributions are computationally indistinguishable.</p><p>-Real Π A (κ): A chooses M. The experiment then runs σ, EM ↔ Setup (1 κ , M), ⊥ . A then provides read/write queries (y i , v) where v = null on reads, for which the experiment runs the protocol (M[y i ], σ i ), EM i ↔ ObliviousAccess (σ i-1 , y i , v), EM i-1 .</p><p>Denote the full transcript of the protocol by t i . Eventually, the experiment outputs (EM, t 1 , . . . , t q ) where q is the total number of read/write queries.</p><p>-Ideal Π Sim (κ): The experiment outputs (EM, t 1 , . . . , t q ) ← Sim(q, |M|, 1 κ ).</p><p>Our Simulator. Note that the simulator needs to provide to the server, for all u Cu , X u and for all i ∈ {2, . . . , L} β i := nState (i,0,0) cState (i+1,0,0) . Furthermore replacement circuits need to be provided as read/write queries are implemented. Our simulator Sim generates these as follows:</p><p>-For each u = (i, j, k), let ( Cu , lab u ← GCircuit(1 κ , P[u, b u , lab (i,j+1,2k+b) 0 ]), where b u is random bit and P is a circuit that, if j = i outputs (nextRoot, lab   ) otherwise.</p><p>-Each X u is generated as as encryption of a zero-string, namely Enc s (0). Similarly for all i ∈ {2, . . . , L} β i := nState (i,0,0) 0 .</p><p>Note that as the provided garbled circuits are executed, replacements circuits need to be given and they are generated in the same manner as above.</p><p>Proof of Indistinguishability. The proof follows by a hybrid argument.</p><p>-H 0 : This hybrid corresponds to the honest execution Real Π A (κ) as done honestly.</p><p>-H 1 : This hybrid is same as H 0 except that we now generate all the X u values as encryptions of zero-strings of appropriate length. Specifically, for each u we set X u ← Enc s (0). The indistinguishability between H 0 and H 1 follows from the security of the encryption scheme (Enc, Dec). -H 2 : In this hybrid the simulator maintains the entire Path ORAM tree internally but does not include it in the provided garbled circuits. In other words garbled circuits are generated as follows:</p><p>• For each u = (i, j, k), let ( Cu , lab u ← GCircuit(1 κ , P[u, b u , lab (i,j+1,2k+b) 0 ]), where b u is 0 or 1 depending on whether the execution as per ORAM would go left or right and P is a circuit that, if j = i outputs (nextRoot, lab   ) otherwise.</p><p>• Each X u is generated as as encryption of a zero-string, namely Enc s (0).</p><p>Similarly for all i ∈ {2, . . . , L} β i := nState (i,0,0) 0 . Fig. <ref type="figure">7</ref>. Formal description of the OblviousAccess protocol for the interactive ORAM <ref type="bibr" target="#b33">[34]</ref>.</p><p>The indistinguishability between H 1 and H 2 follows by a sequence of hybrids where each garbled circuit is replaced by a simulated garbled circuit. Here these hybrids must be performed in sequence in which garbled circuits are consumed. Note that for the unconsumed garbled circuits the input labels aren't provided (or hardcoded inside any other circuit) and hence they can also be simulated. -H 3 : Same as H 2 , except that each b u is now chosen uniformly random, independent of the Path ORAM execution. Note that this is same as the simulator.</p><p>The indistinguishability between H 2 and H 3 from the security of the Path ORAM scheme.</p><p>This concludes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Proof of Security for the SSE scheme</head><p>We prove Theorem 2 on security of the SSE scheme next, Following the definition of Sect. 4, we first describe a simulator Sim who generates the transcripts for the ideal distribution Ideal Π A,Sim,L (κ). Sim takes as input L(DB, H), and does the following: To generate full transcripts of the constant round ORAM scheme for the adversary A, Sim runs Sim , the simulator that exists for that scheme</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Our Path-ORAM abstraction for reading a value val = AL[y]. A1[y1] is read from local storage and defines x2. x2 defines a path p2 in T2. By traversing p2 the algorithm will retrieve A2[y2], which will yield x3, which defines a path p3 in T3.Repeating this process yields a path pL in TL, traversing which yields the final value AL[yL] = AL[y]. Note that y is passed from tree Ti-1 to tree Ti so that the index yi (and the bit bi) can be computed for searching for the right block on path pi.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Formal description of the final bucket circuit.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Setup protocol for TWORAM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. ObliviousAccess protocol for TWORAM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Theorem 2 . 1 .</head><label>21</label><figDesc>The above SSE scheme is L-secure (cf. Definition of Sect. 4), if TWORAM is secure (cf. Definition in Sect. 2.2), F is a PRF, and the encryption used in the one-level Path-ORAM is CPA-secure. Efficiency. The setup cost for our SSE scheme is the sum of the setup cost for TWORAM for a memory of size |W |, and the setup for a one-level Path-ORAM of size n = w∈W |DB(w)| which is O(n log n loglog n). The bandwidth cost for each search/add query w is the cost of one ORAM read in TWORAMplus O(|DB(w)| * (log n loglog n)) for n = w∈W |DB(w)|. Acknowledgments. This work was done in part while the authors were visiting the Simons Institute for the Theory of Computing, supported by the Simons Foundation and by the DIMACS/Simons Collaboration in Cryptography through NSF grant #CNS-1523467. Sanjam Garg was supported in part from a DARPA/ARL SAFE-WARE award, AFOSR Award FA9550-15-1-0274, and NSF CRII Award 1464397. Charalampos Papamanthou was supported in part by NSF grants #1514261 and #1526950, by a NIST award, by a Google Faculty Research Award and by Yahoo! Labs through the Faculty Research Engagement Program (FREP). The views expressed are those of the authors and do not reflect the official policy or position of the Department of Defense, the National Science Foundation, or the U.S. Government. Setting up path ORAM data structures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>if b = 0 then it outputs (left, lab</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>if b = 0 then it outputs (left, lab</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>(i,j+1,2k+b) 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>and 7 respectively in the Appendix A.2. It is easy to see that the ObliviousAccess protocol has log n rounds of interactions.</figDesc><table /><note><p>By the proof of Stefanov et al. [34], we get the following: Corollary 1. The protocols Setup and ObliviousAccess from Figs. 6 and 7 respectively in Appendix A.2 comprise a secure ORAM scheme (as defined in Sect. 2.2) with O(log n) rounds, assuming the encryption scheme used is CPAsecure.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>The keyword is not in the table if it is not in one of those locations. Similarly, to write a new (key, value) pair into the table, (key, value) is written into the first empty location among i 1 , . . . , i c . More formally, we define a hash table H = (hsetup, hlookup, hwrite) using a tuple of algorithms and a parameter c denoting an upper bound on the number of locations to search. -(h, M) ← hsetup(S, size): hsetup takes as input an initial set S of keywordvalue pairs and a maximum table size size and outputs a hash function h and a memory array M. -value ← hlookup(key): hlookup computes {i 1 , . . . , i c } ← h(key), looks for a key-value pair (key, •) in M[i 1 ], . . . , M[i</figDesc><table /><note><p><p><p>c</p>]. If such a pair is found it returns the second component of the pair (i.e., the value), else it returns ⊥.</p>-M ← hwrite(key, value): hwrite computes i 1 , . . . , i c ↔ h(key), if (key, value) already exists in one of those indices in M it does nothing, else it stores (key, value) in the first empty index.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>1 ≤ i ≤ count w where count w is the number of documents containing w, and d i denotes the ith document in DB containing w.Cleint runs hsetup(S i , size i ) to obtain (h i , M i ). size i is the maximum size of the hash table H i . Then client and server run σ i ,EM i ↔ Setup (1 κ , M i ), ⊥ . Note that server's output is EDB = (EM 1 , EM 2 ) and client's output is σ = (σ 1 , σ 2 , h 1 , h 2 ). 2. SSESearch (σ, w), EDB : Client computes i 1 , . . . , i c ← h 1 (w)and client and server run ObliviousAccess (σ 1 , i j , null), EM 1 ) for j ∈ {1, . . . , c} for client to obtain (w, count w ) among the retrieved locations. If such a pair is not found, client lets count w = 0. For 1 ≤ k ≤ count w , client computes i k 1 , . . . , i k c ← h 2 (w||k) and client and server run ObliviousAccess (σ 2 , i k j , null), EM 2 ) for j ∈ {1, . . . , c} for client to obtain M 2 [i k j ]. Client outputs d for all d where (w||k, d) is in the retrieved locations from M 2 . 3. SSEAdd (σ, d), EDB : For every w in d, client computes i 1 , . . . , i c ← h 1 (w) and client and server run ObliviousAccess (σ 1 , i j , null), EM 1 for j ∈ {1, . . . , c} for client to obtain M 1 [i j ]. If (w, count w ) is in the retrieved locations let i * j be the location it was found at. If not, let count w = 0 and let i * j be the first empty location from the retrieved ones. Client and server run ObliviousAccess (σ 1 , i * j , (w, count w + 1)), EM 1 to increase the counter by one.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>2. SSESearch (σ, w), EDB : Client computes i 1 , . . . , i c ← h(w) and client and server run ObliviousAccess (σ s , i j , null), EM ) for j ∈ {1, . . . , c}. If client finds (w, (count w , access w )) in one of the retrieved locations, let i * j be the location it was found at. If such a pair is not found the search ends here. Client and server run ObliviousAccess (σ s , i * j , (w, count w , access w + 1)), EM to increase the access w by one. For 1 ≤ i ≤ count w (in parallel): (a) Client lets x w,i = F K (w||i||access w ) and sends x w,i to server who returns T L (x w,i ) which client decrypts. (b) Client runs (w||i, d i ) ← Extract(L, w||i, T L (x w,i )), and outputs d i .Client runs {T If client finds (w, (count w , access w )) in one of the retrieved locations, let i * j be the location it was found at. Else, it lets i * j be the first empty location among the retrieved ones. (b) Client and server run ObliviousAccess (σ s , i * j , (w, (count w + 1, access w + 1))), EM to increase count w and access w by one. (c) Client lets x w,countw = F K (w||count w ||acess w ) and sends x w,countw to server who returns encrypted T L (x w,countw ) back. Client decrypts the path. (d) Client lets x = F K (w||count w + 1||access w + 1) and runs {T L (x w,countw )} Before stating the security theorem for the above SSE scheme, we first need to make the leakage function associated with the scheme more precise. The leakage function L(DB, H) for our scheme outputs the following (DB is the database and H is the search/add history): |W |, number unique keywords in all documents; |DB(w)| for every w searched;w∈W |DB(w)| i.e. the number of (w, d) pairs where w is in d. See Appendix A.4 for the proof.</figDesc><table /><note><p><p>L (x w,i )} ← Update(w||i, read, (w||i, d i ), T L (x w,i ), x w,i = F K (w||i||access w + 1)) to update the location of (w||i, d i ) to x w,i . Client then encrypts the updated path and sends it to server to update T L . 3. SSEAdd (σ, d), EDB :</p>For every w in d: (a) Client computes i 1 , . . . , i c ← h(w) and client and server run ObliviousAccess (σ s , i j , null), EM ), for j ∈ {1, . . . , c}. ← Update(w||i, write, (w||count w + 1, d), T L (x w,countw ), x ) to update the path. Client then encrypts the updated path and sends it to server to update T L .</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>end procedure Algorithm 2.</head><label></label><figDesc>Extraction algorithm for buckets. Update algorithm. It takes as input L -1 paths and local storage A 1 and outputs new paths, based on the new assignments of positions. 1: procedure {A1, T2(x2), . . . , TL(xL)} ←Update(y, val, A1, T2(x2), . . . , TL(xL)) Ti.root ← Ti.root ∪ readPath(Ti(xi)); Ti.root serves as the stash Ci. 5: Update block (yi, Ai[yi], xi) to (yi, Ai[yi], ri) in Ti.root; 6: select(Ai[yi], bi) ← ri+1; if i = L do if val = null, AL[y] ← val, else NOOP.</figDesc><table><row><cell cols="3">1: procedure π ←ExtractBucket(i, y, b)</cell></row><row><cell>2:</cell><cell cols="2">Search bucket b to retrieve block (yi, Ai[yi], p);</cell></row><row><cell>3:</cell><cell>if found then</cell><cell></cell></row><row><cell>4:</cell><cell>return π ← select(Ai[yi], bi);</cell><cell>π is the index of the path to be explored</cell></row><row><cell></cell><cell>in Ti+1.</cell><cell></cell></row><row><cell>5:</cell><cell>else</cell><cell></cell></row><row><cell>6:</cell><cell>return ⊥;</cell><cell></cell></row><row><cell>7:</cell><cell>end if</cell><cell></cell></row><row><cell cols="2">8: end procedure</cell><cell></cell></row><row><cell cols="2">Algorithm 3. 2: select(A1[y1], b1) ← r2;</cell><cell>ri is random in [1, 2 i+1 ].</cell></row><row><cell>3:</cell><cell>for i = 2 to L do</cell><cell></cell></row><row><cell>4:</cell><cell></cell><cell></cell></row><row><cell>8:</cell><cell>end for</cell><cell></cell></row><row><cell>9:</cell><cell></cell><cell></cell></row><row><cell cols="2">1: procedure T ← Initialize(1 κ , AL)</cell><cell></cell></row><row><cell>2:</cell><cell cols="2">Let πL be a random permutation from [n] to [n];</cell></row><row><cell>3:</cell><cell cols="2">Store (x, AL[x], πL(x)) at leaf πL(x) of tree TL;</cell></row><row><cell>4:</cell><cell>for i = L down to 3 do</cell><cell></cell></row><row><cell>5:</cell><cell cols="2">Set Ai-1[x] = πi(2x -1)||πi(2x) for x = 1, . . . , 2 i-1 ;</cell></row><row><cell>6:</cell><cell cols="2">Let πi-1 be a random permutation from [2 i-1 ] to [2 i-1 ];</cell></row><row><cell>7:</cell><cell cols="2">Store (x, Ai-1[x], πi-1(x)) at leaf πi-1(x) of tree Ti-1;</cell></row><row><cell>8:</cell><cell>end for</cell><cell></cell></row><row><cell>9:</cell><cell></cell><cell></cell></row></table><note><p><p>Let A1 be an array of 2 entries such that A1[x] = π2(2x-1)||π2(2x) for x = 1, 2; 10: return {A1, T2, . . . , TL}; 11: 7:</p>[Ti.root, Ti(xi)] ← evictPath(Ti.root);</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We define bandwidth overhead as the number of bits transferred between the client and the server during a single memory access, including the data block.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>This efficiency is achieved when the first optimization is used.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Note that here the first optimization allows us to ensure that the size of the garbled leaf circuit, rather than the clear leaf circuit, grows with the length of r (i,i-1,k) as these hard-codings are performed.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>due its security (see definition of Sect. 2.2). That is, he runs (EM, t 1 , . . . , t q ) ← Sim (q, |M|, 1 κ ), where he drives |M| from |W |. To simulate the transcripts of the path-ORAM component, it generates a one-level path ORAM tree T L for a memory array of size w∈W |DB(w)| filled with all 0 values. For each read/add query, it replaces the PRF-genenerated paths by uniformly random paths, and generates freshly generated ciphertexts of 0 for updated paths. Sim knows the number of paths to retrieve/update for each query from the leakage function which outputs |DB(w)| for every query w. This completes the description of the simulator. We now need to show that Ideal Π A,Sim,L (κ) is indinstinguishable from Real Π A (κ), which constitutes the first in the sequence of our Hybrids:</p><p>Proof of Indistinguishability. The proof follows by a hybrid argument.</p><p>-H 0 : This hybrid corresponds to the honest execution Real Π A (κ) for the SSE scheme which we repeat here for completeness. A chooses DB. The experiment then runs EDB, σ ↔ SSESetup (1 κ , DB), ⊥ . A then adaptively makes search queries w i , which the experiment answers by running the protocol DB i-1 (w i ), σ i ↔ SSESearch (σ i-1 , w i ), EDB i-1 . Denote the full transcripts of the protocol by t i . Add queries are handled in a similar way. Eventually, the experiment outputs (EDB, t 1 , . . . , t q ) where q is the total number of search/add queries made by A.</p><p>-H 1 :Similar to H 0 , except that the portions of t i 's corresponding to the constant-round ORAM are instead generated by Sim (q, |M|, 1 κ ) where Sim is the simulator in the proof of the ORAM scheme.</p><p>The indistinguishability of H 0 and H 1 follows from security of the ORAM scheme. -H 2 : Similar to H 1 except that all ciphertexts in the path ORAM tree are replaced by encryptions of 0, and all updated ciphertexts will be fresh encryption of 0.</p><p>The indistinguishability of H 2 and H 1 follows from the semantic security of the encryption scheme used in the path ORAM. -H 3 : Similar to H 2 except that all PRF-generated positions are replaced by uniformly random positions. Note that H 3 is essentially Ideal Π A,Sim,L (κ). The indistinguishability of H 3 and H 2 follows from the pseudorandomness of the the PRF. This concludes the proof.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">How to efficiently evaluate RAM programs with malicious security</title>
		<author>
			<persName><forename type="first">A</forename><surname>Afshar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mohassel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rosulek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EUROCRYPT 2015</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Oswald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Fischlin</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9056</biblScope>
			<biblScope unit="page" from="702" to="729" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Foundations of garbled circuits</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bellare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">T</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rogaway</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="784" to="796" />
		</imprint>
		<respStmt>
			<orgName>CCS</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Leakage-abuse attacks against searchable encryption</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Grubbs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Perry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ristenpart</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="668" to="679" />
		</imprint>
		<respStmt>
			<orgName>CCS</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Highlyscalable searchable symmetric encryption with support for boolean queries</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jarecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jutla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Krawczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-C</forename><surname>Roşu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Steiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CRYPTO 2013, Part I</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Canetti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Garay</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">8042</biblScope>
			<biblScope unit="page" from="353" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Privacy preserving keyword searches on remote encrypted data</title>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mitzenmacher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACNS 2005</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Ioannidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Keromytis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Yung</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3531</biblScope>
			<biblScope unit="page" from="442" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Structured encryption and controlled disclosure</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kamara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASIACRYPT 2010</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Abe</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6477</biblScope>
			<biblScope unit="page" from="577" to="594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Introduction to Algorithms, 2nd edn</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Cormen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Rivest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Leiserson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>McGraw-Hill Higher Education</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Searchable symmetric encryption: improved definitions and efficient constructions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Curtmola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Garay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kamara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ostrovsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="79" to="88" />
		</imprint>
		<respStmt>
			<orgName>CCS</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Onion ORAM: a constant bandwidth blowup oblivious RAM</title>
		<author>
			<persName><forename type="first">S</forename><surname>Devadas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Dijk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wichs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="145" to="174" />
		</imprint>
		<respStmt>
			<orgName>TCC</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Bucket ORAM: single online roundtrip, constant bandwidth oblivious RAM</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naveed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Stefanov</surname></persName>
		</author>
		<ptr target="http://eprint.iacr.org/" />
	</analytic>
	<monogr>
		<title level="j">Cryptology ePrint Archive</title>
		<imprint>
			<biblScope unit="page">1065</biblScope>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Black-box garbled RAM</title>
		<author>
			<persName><forename type="first">S</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ostrovsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="210" to="229" />
		</imprint>
		<respStmt>
			<orgName>FOCS</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Garbled RAM from one-way functions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ostrovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Scafuro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="449" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Optimizing ORAM and using it efficiently for secure computation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gentry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Halevi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Julta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Raykova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wichs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PETS 2013</title>
		<editor>
			<persName><forename type="first">E</forename><surname>De Cristofaro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Wright</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">7981</biblScope>
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Garbled RAM revisited</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gentry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Halevi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ostrovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Raykova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wichs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EUROCRYPT 2014</title>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Oswald</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">8441</biblScope>
			<biblScope unit="page" from="405" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">E.-J</forename><surname>Goh</surname></persName>
		</author>
		<ptr target="http://eprint.iacr.org/2003/216/" />
		<title level="m">Secure indexes. Cryptology ePrint Archive</title>
		<imprint>
			<date type="published" when="2003">2003. 2003</date>
			<biblScope unit="page">216</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Software protection and simulation on oblivious RAMs</title>
		<author>
			<persName><forename type="first">O</forename><surname>Goldreich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ostrovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="431" to="473" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Privacy-preserving access of outsourced data via oblivious RAM simulation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Goodrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mitzenmacher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICALP 2011, Part II</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Aceto</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Henzinger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Sgall</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">6756</biblScope>
			<biblScope unit="page" from="576" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Privacypreserving group data access via stateless oblivious RAM simulation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Goodrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mitzenmacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ohrimenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tamassia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SODA</title>
		<imprint>
			<biblScope unit="page" from="157" to="167" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Secure two-party computation in sublinear (amortized) time</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Krell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Malkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Raykova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Vahlis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="513" to="524" />
		</imprint>
		<respStmt>
			<orgName>CCS</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Access pattern disclosure on searchable encryption ramification, attack and mitigation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kuzu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kantarcioglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NDSS</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Burst ORAM: minimizing ORAM response times for bursty access patterns</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Dautrich</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Stefanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Usenix Security</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="749" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Parallel and dynamic searchable symmetric encryption</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kamara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Papamanthou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="258" to="274" />
		</imprint>
		<respStmt>
			<orgName>FC</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Dynamic searchable symmetric encryption</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kamara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Papamanthou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Roeder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="965" to="976" />
		</imprint>
		<respStmt>
			<orgName>CCS</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On the (in)security of hash-based oblivious RAM and a new balancing scheme</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kushilevitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ostrovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SODA</title>
		<imprint>
			<biblScope unit="page" from="143" to="156" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A proof of security of Yao&apos;s protocol for two-party computation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lindell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pinkas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cryptol</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="161" to="188" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Search pattern leakage in searchable encryption: attacks and new construction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-A</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">265</biblScope>
			<biblScope unit="page" from="176" to="188" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Distributed oblivious RAM for secure two-party computation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ostrovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TCC 2013</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Sahai</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">7785</biblScope>
			<biblScope unit="page" from="377" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">How to garble RAM programs?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ostrovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EUROCRYPT 2013</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Johansson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">7881</biblScope>
			<biblScope unit="page" from="719" to="734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Constant communication ORAM with small blocksize</title>
		<author>
			<persName><forename type="first">T</forename><surname>Moataz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mayberry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E.-O</forename><surname>Blass</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="862" to="873" />
		</imprint>
		<respStmt>
			<orgName>CCS</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Predicate privacy in encryption systems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Waters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TCC 2009</title>
		<editor>
			<persName><forename type="first">O</forename><surname>Reingold</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5444</biblScope>
			<biblScope unit="page" from="457" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Oblivious RAM with O((logN ) 3 ) worst-case cost</title>
		<author>
			<persName><forename type="first">E</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-H</forename><forename type="middle">H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Stefanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASIACRYPT 2011</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">7073</biblScope>
			<biblScope unit="page" from="197" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Practical techniques for searches on encrypted data</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perrig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Security and Privacy</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="44" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Practical dynamic searchable encryption with small leakage</title>
		<author>
			<persName><forename type="first">E</forename><surname>Stefanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Papamanthou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NDSS</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Path ORAM: an extremely simple oblivious RAM protocol</title>
		<author>
			<persName><forename type="first">E</forename><surname>Stefanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Dijk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiangyao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Devadas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="299" to="310" />
		</imprint>
		<respStmt>
			<orgName>CCS</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Computationally efficient searchable symmetric encryption</title>
		<author>
			<persName><forename type="first">P</forename><surname>Van Liesdonk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sedghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Doumen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hartel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jonker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM 2010</title>
		<editor>
			<persName><forename type="first">W</forename><surname>Jonker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Petković</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6358</biblScope>
			<biblScope unit="page" from="87" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">On tightness of the Goldreich-Ostrovsky lower bound</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-H</forename><surname>Hubert Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Circuit</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="191" to="202" />
		</imprint>
		<respStmt>
			<orgName>CCS</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Single round access privacy on outsourced storage</title>
		<author>
			<persName><forename type="first">P</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sion</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="293" to="304" />
		</imprint>
		<respStmt>
			<orgName>CCS</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Protocols for secure computations (extended abstract)</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">FOCS</title>
		<imprint>
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">All your queries are belong to us: the power of file-injection attacks on searchable encryption</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Papamanthou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Usenix Security</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
