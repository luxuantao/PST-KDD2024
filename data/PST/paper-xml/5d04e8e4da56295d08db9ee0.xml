<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sequential Scenario-Specific Meta Learner for Online Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhengxiao</forename><surname>Du</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaowei</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">DAMO Academy, Alibaba Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">DAMO Academy, Alibaba Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jingren</forename><surname>Zhou</surname></persName>
							<email>jingren.zhou@alibaba-inc.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">DAMO Academy, Alibaba Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
							<email>jietang@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Sequential Scenario-Specific Meta Learner for Online Recommendation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3292500.3330726</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Recommender systems</term>
					<term>Personalized ranking</term>
					<term>Neural network</term>
					<term>Meta learning</term>
					<term>Few-shot learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Cold-start problems are long-standing challenges for practical recommendations. Most existing recommendation algorithms rely on extensive observed data and are brittle to recommendation scenarios with few interactions. This paper addresses such problems using few-shot learning and meta learning. Our approach is based on the insight that having a good generalization from a few examples relies on both a generic model initialization and an effective strategy for adapting this model to newly arising tasks. To accomplish this, we combine the scenario-specific learning with a model-agnostic sequential meta-learning and unify them into an integrated end-toend framework, namely Scenario-specific Sequential Meta learner (or s 2 Meta ). By doing so, our meta-learner produces a generic initial model through aggregating contextual information from a variety of prediction tasks while effectively adapting to specific tasks by leveraging learning-to-learn knowledge. Extensive experiments on various real-world datasets demonstrate that our proposed model can achieve significant gains over the state-of-the-arts for cold-start problems in online recommendation 1 . Deployment is at the Guess You Like session, the front page of the Mobile Taobao; and the illustration video can also be watched from the link 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>• Information systems → Recommender systems; • Computing methodologies → Neural networks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The personalized recommendation is an important method for information retrieval and content discovery in today's information-rich environment. Personalized recommender systems, where the recommendation is generated according to users' past behaviors or profiles, have been proven effective in domains including E-Commerce <ref type="bibr" target="#b28">[29]</ref>, social networking services <ref type="bibr" target="#b26">[27]</ref>, video-sharing websites <ref type="bibr" target="#b9">[10]</ref>, among many others. Traditionally, a personalized recommender system can be seen as a mapping U × I → R, where U is the user set and I is the item set. The mapping result can be a real value for explicit ratings or a binary value for implicit feedback <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b46">47]</ref>. This setting usually assumes that the behavior pattern of the same user is relatively stationary in different contexts, which is not true in many practical tasks <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b35">36]</ref>. For example, during the Singles Day Promotion (Double 11) period, the largest online shopping festival in China, consumers sometimes shop impulsively allured by the low discounts. In such scenarios, the contextual information of Double 11 is quite critical. It also has been shown that including contextual information leads to better predictive models and better quality of recommendations <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b34">35]</ref>.</p><p>Though context-aware recommender systems have been proven effective <ref type="bibr" target="#b2">[3]</ref>, they are facing several challenges. Firstly, a large portion of scenarios in a system is actually long-tailed, without enough user feedback. Moreover, the life cycle of a scenario can be quite short. In Taobao, most promotions end within a few days or even a few hours after being launched, without enough time to collect sufficient user feedback for training. Therefore, training scenario-specific recommenders with limited observations are practical requirements. Most existing recommendation algorithms rely on extensive observed data and are brittle to new products and/or consumers <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b52">53]</ref>. Although the cold-start problem can be tackled by cross-domain recommender systems with domain knowledge being transferred, they still require a large amount of shared samples across domains <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b42">43]</ref>. Secondly, when training a predictive model on a new scenario, the hyperparameters often have a great influence on the performance and optimal hyperparameters in different scenarios may differ significantly <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b49">50]</ref>. Finding a right combination of hyperparameters usually requires great human efforts along with sufficient observations. This paper addresses the problem of cold-start scenario recommendation with the recent progress on few-shot learning <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b54">55]</ref> and meta-learning <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b38">39]</ref>. Our approach is to build a meta learner that learns how to instantiate a recommender with good generalization capacity from limited training data. The framework, which generates a scenario-specific recommender by a sequential learning process, is called Scenario-specific Sequential Meta learner (or s 2 Meta ). The sequential process, which resembles the traditional machine learning process controlled by human experts, consists of three steps: the meta learner automatically initializes the recommender to be broadly suitable to many scenarios, finetunes its parameters with flexible updating strategy, and stops learning timely to avoid overfitting. The policy of meta learner is learned on a variety of existing scenarios in the system and can guide the quick acquisition of knowledge in new scenarios. By automating the learning process in each scenario, we can also reduce the human efforts needed to train the predictive model on new scenarios that continuously appear in the recommender systems. Organization. The remainder of this paper is organized as follows: in Section 2, we review related works. Section 3 introduces the problem definition and meta learning settings. Section 4 gives a detailed description of the proposed s 2 Meta framework. Experimental results on large-scale public datasets and the newly released Taobao theme recommendation dataset are shown in Section 5. At last, Section 6 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In this section, we go over the related works on context-aware recommendation, cross-domain recommendation, and meta learning respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Context-Aware Recommendation</head><p>The importance of contextual information has been recognized by researchers and practitioners in many disciplines, including E-Commerce personalization <ref type="bibr" target="#b34">[35]</ref>, information retrieval <ref type="bibr" target="#b22">[23]</ref>, data mining <ref type="bibr" target="#b5">[6]</ref> and marketing <ref type="bibr" target="#b35">[36]</ref>, among many others <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b45">46]</ref>. Relevant contextual information does matter in recommender systems, and it is important to take account of contextual information, such as time, location, or acquaintances' impacts <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b34">35]</ref>. Compared to traditional recommender systems that make predictions based on the information of users and items, context-aware recommender systems <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3]</ref> make predictions in the space of U × I × C, where C is the context space. The contextual information can be observable (e.g., time, location, etc), or unobservable (e.g., users' intention). The latter case is related to Session-based Recommendation <ref type="bibr" target="#b18">[19]</ref> or Sequence-aware Recommendation <ref type="bibr" target="#b37">[38]</ref>. Even if the contextual information is fully-observable, the weight of different types of information is entirely domain-dependent and quite tricky to be tuned for cold-start scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Cross-Domain Recommendation</head><p>Traditional recommender systems suggest items belonging to a single domain and this is not perceived as a limitation, but as a focus on a particular market <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27]</ref>. However, nowadays, users provide feedback for items of different types, express their opinions on different social media and different providers. Providers also wish to cross-sell various categories of products and services, especially to new users. Unlike traditional recommender systems that work on homogeneous users and items, cross-domain recommender systems <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b12">13]</ref>, closely related to Transfer Learning <ref type="bibr" target="#b48">[49]</ref>, try to combine the information from heterogeneous users and/or items. In <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b42">43]</ref>, they extend the traditional matrix factorization <ref type="bibr" target="#b25">[26]</ref> or factorization machines <ref type="bibr" target="#b39">[40]</ref> with interacted information from an auxiliary domain to inform recommendations in a target domain. In <ref type="bibr" target="#b31">[32]</ref>, a multi-layer perceptron is used to capture the nonlinear mapping function across different domains. In <ref type="bibr" target="#b20">[21]</ref>, they propose a novel neural network CoNet, with architecture designed for knowledge transfer across domains. However, all these methods require a large amount of interacted data of the shared users or items between the source and target domains. In <ref type="bibr" target="#b55">[56]</ref>, they propose to align the different features in two domains without shared users or items with semantic relatedness. However, they assume that the relatedness of features in the source and target domains can be inferred from domain prior knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Meta Learning</head><p>Meta learning <ref type="bibr" target="#b6">[7]</ref>, or Learning to learn, which aims to learn a learner that can efficiently complete different learning tasks, has gained great success in few-shot learning settings <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b51">52]</ref>. The information learned across all tasks guides the quick acquisition of knowledge within each separate learning task. Previous work on meta learning can be divided into two groups. One is the metric method that learns a similarity metric between new instances and instances in the training set. Examples include Siamese Network <ref type="bibr" target="#b24">[25]</ref>, Matching Network <ref type="bibr" target="#b51">[52]</ref>, and Prototypical Network <ref type="bibr" target="#b43">[44]</ref>. The other is the parameter method that directly predicts or updates the parameters of the classifier according to the training data. Examples include MAML <ref type="bibr" target="#b13">[14]</ref>, Meta-LSTM <ref type="bibr" target="#b38">[39]</ref> and Meta Network <ref type="bibr" target="#b32">[33]</ref>. Most methods follow the framework in <ref type="bibr" target="#b51">[52]</ref>, trying to solve a group of learning tasks of the same pattern, e.g., learning to recognize the objects of different categories with only one example per category given <ref type="bibr" target="#b27">[28]</ref>. Previous works on the application of learning to learn in recommender systems mainly focus on the algorithm selection <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref>, leaving other parts of the learning process less explored. In <ref type="bibr" target="#b50">[51]</ref>, they propose to use meta learning to solve the user cold-start problem in the Tweet recommendation. However, they use a neural network to directly output parameters of the recommender, which limits the representation ability of their model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARY</head><p>In this section, we formally define the problem of scenario-aware recommendation and introduce the meta learning settings. We summarize the notations in Table <ref type="table">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Formulation</head><p>A scenario-based recommender system is represented as {U, I, C}, where U is the user set, I is the item set and C is the scenario set. A scenario c ∈ C is defined as a common context in which users interact with items and (u, i) ∈ H c represents that user u interacted with item i in the scenario c. Each scenario c is connected with a recommender function f c : U × I → R, where f c (u, i) is the ranking score of item i for user u in scenario c. For each scenario c, we have access to a training set ! S &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; ! u &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; ! R &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; N Y  </p><formula xml:id="formula_0">D train c = {(u k , i k ) N c k =1 } where (u k , i k ) ∈ H c .</formula><formula xml:id="formula_1">f (0) travel &lt; l a t e x i t s h a _ b a s e = " B b F C m E B H b v t g G a K X D k S S E = " &gt; A A A C A H i c b V A S w N B E N z M a v U w s L m M g x C b c q a B l M Y y g v m A A x m l k y d H u P B c F z j X G x U M T W n H n v G T X K G J D w Y e w M + L B V d o / G v L K t p Y a O u b W s v u T d U l E g G d R a J S L Y q k D w E O r I U U A r l k A D T D T G M / O Y I p O J R e I / j G N y A k P u c Z R S z H I y / Z p k C I + Y o q Q j E F n W N U t x Z C W i R O T k o k R r f n V E U s C C J E J q l T b s W N U y q R M w F Z s Z M o i C k b j N Q p A M p N p w k o l W e p Y f S V h W l P R K A X G g a c A o D N e N x P + d o L + l Z v y M E Q Q j Z b C f C w s i a p G H u A S G Y q w J Z Z L r W y o J I y J k V d Q j O / M u L p H F W c c r t F q X q d x E g R + S Y l I l D L k m V J I a q R N G M v J M X s m b W S G O / G x x y c h n D s g f G J / M / q W z g = = &lt; / l a t e x i t &gt; f (0) party &lt; l a t e x i t s h a _ b a s e = " V C B o Y J W g s c z t u c A u + i G D U S E = " &gt; A A A B / i c b V D L S s N A F J r P U V F d y C R a h b k q i g i L b l x W s A o Y h M J + Q y S T M I g h Z u G v u H G h i F t / w / T N Q l s P X D i c c + / M v c e P O V N g / G w u L S s p q a a v r G t W u L Z U l E h C m y T i k e z W F H O B G C A s a Q D l t + O r s d + + p K x S N x C G l M x A P B A k Y w a M k z O r G o f W A / o A W Y w l p H n u m R W Z k g z R O n I B V U o O G Z X + R J K Q C i A c K V B j c T L / G C K d u Z c o G m M y w g P a V T g k C o m + y f W d a V t B J H U J s C b q k M h q l o a Q w x D N e u N x f + b g L B h Z s x E S d A B Z l + F C T c g s g a h H m a Q E e K o J J p L p X S y x B I T J G V d Q j O M n z p H V S c r s Z p X Z x F F C B + g Q V Z G D z l E d X a M G a i K C H t E z e k V v x p P x Y r w b H P W B a O Y U N / Y H z + A H e S l m Y = &lt; / l a t e x i t &gt; f (0) baby &lt; l a t e x i t s h a _ b a s e = " B X j a C B Y n N l c O N q X t k h D z G n m = " &gt; A A A B / n i c b V D L S s N A F J U V v q L h y E y x C Z R E B V W b i s Y B / Q x j C Z T t q h k w c z N I Y A v K G x e K u P U P k T t s s t P X A h c M L v P X C m Q T b / j Z K S s r q v l c r G t b j r m Z x K g h t k Z j H o u t j S T m L a A s Y c N p N B M W h z n H H P / M D F Z L F R k C X V D P I x Y w A g G L X n m Q X C v a v Z J q k + E d Q P v a z P P f M q l p A W i V O Q K i r Q M y v / i A m a U g j I B x L X P s B F y F B T D C a V p p I m m I z x k P Y j X B I p a u m + f W s V Y G V h A L X R F Y U / X h M K h l F n o Q w j O e x P x P + X Q n D p K h Y l K d C I z B Y F K b c g t i Z Z W A M m K A G e a Y K J Y P p W i y w w A R Y h U d g j P / i J p n a d s p e t X B V x l N E h O k I K A L E A q I l a i C C F n t E r e j O e j B f j f i Y t Z a M Y m Y f / Y H x + Q N s S J X K &lt; / l a t e x i t &gt; f (t) baby &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " U 0 / x 2 Q f N 5 s t E W / F a i A H B I z G 9 0 n U = " &gt; A A A B / n i c b V D L S s N A F J 3 U V 6 2 v q L h y E y x C 3 Z R E B V 0 W 3 b i s Y B / Q x j C Z T t q h k w c z N 2 I Y A v 6 K G x</formula><formula xml:id="formula_2">V J p 6 O v O E M N Q z X p j 8 T + v m 0 B w 4 W Z M x A l Q Q a Y f B Q m 3 I L L G Y V h 9 J i k B n m q C i W R 6 V 4 s M s c Q E d G R l H Y I z e / I 8 a Z 3 U n N O a f X N W q V 8 W c Z T Q A T p E V e S g c 1 R H 1 6 i B m o i g R / S M X t G b 8 W S 8 G O / G x 7 R 1 w S h m 9 t A f G J 8 / 4 y a W q g = = &lt; / l a t e x i t &gt; f (t 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>) party</head><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B x j P J 9 L P U 6 S a r l 9 </p><formula xml:id="formula_3">O B j B x Q O / q R u w = " &gt; A A A C A X i c b V D L S s N A F J 3 U V 6 2 v q B v B T b A I d W F J V N B l 0 Y 3 L C v Y B b Q y T 6 a Q d O p m E m R u x h L j x V 9 y 4 U M S t f + H O v 3 H a Z q G t B</formula><formula xml:id="formula_4">l U L B K 3 M I q p G + K + Y A E j G L T k m X v B X V q B Y + c o 8 9 I u 0 A d I Y y x h l G W e W b a r 9 g T W P H F y U k Y 5 6 p 7 5 1 e 1 F J A m p A M K x U h 3 H j s F N 9 W u M c J q V u o m i M S Z D 3 K c d T Q U O q X L T y Q W Z d a i V n h V E U p c A a 6 L + n k h x q N Q o 9 H V n i G G g Z r 2 x + J / X S S C 4 c F M m 4 g S o I N O P g o R b E F n j O K w e k 5 Q A H 2 m C i W R 6 V 4 s M s M Q E d G g l H Y I z e / I 8 a Z 5 U n d O q f X N W r l 3 m c R T R P j p A F e S g c 1 R D 1 6 i O G o i g R / S M X t G b 8 W S 8 G O / G x 7 S 1 Y O Q z u + g P j M 8 f x i q X H A = = &lt; / l a t e x i t &gt; f (t 1) baby &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " D M x Q p R R 0 h A b L 2 d / N E R Z N + r c j C J Y = " &gt; A A A C A H i c b V D L S s N A F J 3 U V 6 2 v q A s X b g a L U B e W R A V d F t 2 4 r G A f 0 M Y w m U 7 a o Z M H M z d i C N n 4 K 2 5 c K O L W z 3 D n 3 z h t s 9 D q g Q u H c + 7 l 3 n u 8 W H A F l v V l l B Y W l 5 Z X y q u V t f W N z S 1 z e 6 e t o k R S 1 q K R i G T X I 4 o J H r I W c B C s G 0 t G A k + w j j e + m v i d e y Y V j 8 J b S G P m B G Q Y c p 9 T A l p y z T 3 / L q v B s X 2 U u 1 k f 2 A N k H v H S P H f N q l W 3 p s B / i V 2 Q K i r Q d M 3 P / i C i S c B C o I I o 1 b O t G J y M S O B U s L z S T x S L C R 2 T I e t p G p K A K S e b P p D j Q 6 0 M s B 9 J X S H g q f p z I i O B U m n g 6 c 6 A w E j N e x P x P 6 + X g H / h Z D y M E 2 A h n S 3 y E 4 E h w p M 0 8 I B L R k G k m h A q u b 4 V 0 x G R h I L O r K J D s O d f / k v a J 3 X 7 t G 7 d n F U b l 0 U c Z b S P D l A N 2 e g c N d A 1 a q I W o i h H T + g F v R q P x r P x Z r z P W k t G M b O L f s H 4 + A a 6 O p a A &lt; / l a t e x i t &gt; f travel &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N l c q B k F G E x b d k U d M P V V F p K + G L Y U = " &gt; A A A B + n i c b V B N S 8 N A E N 3 4 W e t X q k c v w S J 4 K o k K e i x 6 8 V j B f k A b w m Y 7 a Z d u P t i d V E v M T / H i Q R G v / h J v / h u 3 b Q 7 a + m D g 8 d 4 M M / P 8 R H C F t v 1 t r K y u r W 9 s l r b K 2 z u 7 e / t m 5 a C l 4 l Q y a L J Y x L L j U w W C R 9 B E j g I 6 i Q Q a + g L a / u h m 6 r f H I B W P o 3 u c J O C G d B D x g D O K W v L M S u B l P Y R H z F D S M Y g 8 9 8 y q X b N n s J a J U 5 A q K d D w z K 9 e P 2 Z p C B E y Q Z X q O n a C b k Y l c i Y g L / d S B Q l l I z q A r q Y R D U G 5 2 e z 0 3 D r R S t 8 K Y q k r Q m u m / p 7 I a K j U J P R 1 Z 0 h x q B a 9 q f i f 1 0 0 x u H I z H i U p Q s T m i 4 J U W B h b 0 x y s P p f A U E w 0 o U x y f a v F h l R S h j q t s g 7 B W X x 5 m b T O a s 5 5 z b 6 7 q N a v i z h K 5 I g c k 1 P i k E t S J 7 e k Q Z q E k Q f y T F 7 J m / F k v B j v x s e 8 d c U o Z g 7 J H x i f P 2 Z b l L s = &lt; / l a t e x i t &gt; ✓ (t)</formula><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " d 8 g</p><formula xml:id="formula_5">T g T h Y + s z Q d m H D t g 7 m p g + V g D 4 = " &gt; A A A C A n i c b V D L S s N A F J 3 U V 6 2 v q C t x E y x C 3 Z R E B V 0 W 3 b i s Y B / Q x D K Z T N u h k 0 m Y u R F K C G 7 8 F T c u F H H r V 7 j z b 5 y 0 W W j r g W E O 5 9 z L v f f 4 M W c K b P v b K C 0 t r 6 y u l d c r G 5 t b 2 z v m 7 l 5 b R Y k k t E U i H s m u j x X l T N A W M O C 0 G 0 u K Q 5 / T j j + + z v 3 O A 5 W K R e I O J j H 1 Q j w U b M A I B i 3 1 z Q P X j 3 i g J q H + U h d G F H B 2 n 9 b g J O u b V b t u T 2 E t E q c g V V S g 2 T e / 3 C A i S U g F E I 6 V 6 j l 2 D F 6 K J T D C a V Z x E 0 V j T M Z 4 S H u a C h x S 5 a X T E z L r W C u B N Y i k f g K s q f q 7 I 8 W h y r f U l S G G k Z r 3 c v E / r 5 f A 4 N J L m Y g T o I L M B g 0 S b k F k 5 X l Y A Z O U A J 9 o g o l k e l e L j L D E B H R q F R 2 C M 3 / y I m m f 1 p 2 z u n 1 7 X m 1 c F X G U 0 S E 6 Q j X k o A v U Q D e o i V q I o E f 0 j F 7 R m / F k v B j v x s e s t G Q U P f v o D 4 z P H + s Q l 7 8 = &lt; / l a t e x i t &gt; ✓ (t)</formula><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " d 8 g     shared initial parameters for f c ω u , ω s parameters of update and stop controllers α , β input gate and forget gate p (t )  stop probability at step t</p><formula xml:id="formula_6">T g T h Y + s z Q d m H D t g 7 m p g + V g D 4 = " &gt; A A A C A n i c b V D L S s N A F J 3 U V 6 2 v q C t x E y x C 3 Z R E B V 0 W 3 b i s Y B / Q x D K Z T N u h k 0 m Y u R F K C G 7 8 F T c u F H H r V 7 j z b 5 y 0 W W j r g W E O 5 9 z L v f f 4 M W c K b P v b K C 0 t r 6 y u l d c r G 5 t b 2 z v m 7 l 5 b R Y k k t E U i H s m u j x X l T N A W M O C 0 G 0 u K Q 5 / T j j + + z v 3 O A 5 W K R e I O J j H 1 Q j w U b M A I B i 3 1 z Q P X j 3 i g J q H + U h d G F H B 2 n 9 b g J O u b V b t u T 2 E t E q c g V V S g 2 T e / 3 C A i S U g F E I 6 V 6 j l 2 D F 6 K J T D C a V Z x E 0 V j T M Z 4 S H u a C h x S 5 a X T E z L r W C u B N Y i k f g K s q f q 7 I 8 W h y r f U l S G G k Z r 3 c v E / r 5 f A 4 N J L m Y g T o I L M B g 0 S b k F k 5 X l Y A Z O U A J 9 o g o l k e l e L j L D E B H R q F R 2 C M 3 / y I m m f 1 p 2 z u n 1 7 X m 1 c F X G U 0 S E 6 Q j X k o A v U Q D e o i V q I o E f 0 j F 7 R m / F k v B j v x s e s t G Q U P f v o D 4 z P H + s Q l 7 8 = &lt; / l a t e x i t &gt; f party &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B B k / + e n b W T Z U E T r 5 s K r v / d X L B l 8 = " &gt; A A A B + X i c b V D L S s N A F J 3 U V 6 2 v q E s 3 g 0 V w V R I V d F l 0 4 7 K C f U A b w m Q 6 a Y d O J m H m p h h C / s S N C 0 X c + i f u / B u n b R b a e u D C 4 Z x 7 Z + 4 9 Q S K 4 B s f 5 t i p r 6 x u b W 9 X t 2 s 7 u 3 v 6 B f X j U 0 X G q K G v T W M S q F x D N B J e s D R w E 6 y W K k S g Q r B t M 7 m Z + d 8 q U 5 r F 8 h C x h X k R G k o e c E j C S b 9 u h n w + A P U G e E A V Z U f h 2 3 W k 4 c + B V 4 p a k j k q 0 f P t r M I x p G j E J V B C t + 6 6 T g J e b 1 z g V r K g N U s 0 S Q i d k x P q G S h I x 7 e X z z Q t 8 Z p Q h D m N l S g K e q 7 8 n c h J p n U W B 6 Y w I j P W y N x P / 8 / o p h D d e z m W S A p N 0 8 V G Y C g w x n s W A h 1 w x C i I z h F D F z a 6 Y j o k i F E x Y N R O C u 3 z y K u l c N N z L h v N w V W / e l n F U 0 Q k 6 R e f I R d e o i e 5 R C 7 U R R V P 0 j F 7 R m 5 V b L 9 a 7 9 b F o r V j l z D H 6 A + v z B 6 v W l F M = &lt; / l a t e x i t &gt; f baby &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v r v V E 3 Y g n A S L V D 1 p z i y O 1 b m Q X k c = " &gt; A A A B + H i c b V B N S 8 N A E N 3 4 W e t H o x 6 9 L B b B U 0 l U 0 G P R i 8 c K 9 g P a E D b b T b t 0 s w m 7 E z G G / B I v H h T x 6 k / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A T X 4 D j f 1 s r q 2 v r G Z m W r u r 2 z u 1 e z 9 w 8 6 O k 4 V Z W 0 a i 1 j 1 A q K Z 4 J K 1 g Y N g v U Q x E g W C d Y P J z d T v P j C l e S z v I U u Y F 5 G R 5 C G n B I z k 2 7 X Q z w f A H i E P S J A V h W / X n Y Y z A 1 4 m b k n q q E T L t 7 8 G w 5 i m E Z N A B d G 6 7 z o J e D l R w K l g R X W Q a p Y Q O i E j 1 j d U k o h p L 5 8 d X u A T o w x x G C t T E v B M / T 2 R k 0 j r L A p M Z 0 R g r B e 9 q f i f 1 0 8 h v P J y L p M U m K T z R W E q M M R 4 m g I e c s U o i M w Q Q h U 3 t 2 I 6 J o p Q M F l V T Q j u 4 s v L p H P W c M 8 b z t 1 F v X l d x l F B R + g Y n S I X X a I m u k U t 1 E Y U p e g Z v</formula><formula xml:id="formula_7">= " &gt; A A A C A n i c b V D L S s N A F J 3 U V 6 2 v q C t x E y x C 3 Z R E B V 0 W 3 b i s Y B / Q x D K Z T N u h k 0 m Y u R F K C G 7 8 F T c u F H H r V 7 j z b 5 y 0 W W j r g W E O 5 9 z L v f f 4 M W c K b P v b K C 0 t r 6 y u l d c r G 5 t b 2 z v m 7 l 5 b R Y k k t E U i H s m u j x X l T N A W M O C 0 G 0 u K Q 5 / T j j + + z v 3 O A 5 W K R e I O J j H 1 Q j w U b M A I B i 3 1 z Q P X j 3 i g J q H + U h d G F H B 2 n 9 b s k 6 x v V u 2 6 P Y W 1 S J y C V F G B Z t / 8 c o O I J C E V Q D h W q u f Y M X g p l s A I p 1 n F T R S N M R n j I e 1 p K n B I l Z d O T 8 i s Y 6 0 E 1 i C S + g m w p u r v j h S H K t 9 S V 4 Y Y R m r e y 8 X / v F 4 C g 0 s v Z S J O g A o y G z R I u A W R l e d h B U x S A n y i C S a S 6 V 0 t M s I S E 9 C p V X Q I z v z J i 6 R 9 W n f O 6 v b t e b V x V c R R R o f o C N W Q g y 5 Q A 9</formula><formula xml:id="formula_8">8 G H u / N M D M v S K Q w 6 L r f z s r q 2 v r G Z m G r u L 2 z u 7 d f O j h s m j j V j D d Y L G P d D q j h U i j e Q I G S t x P N a R R I 3 g p G t 1 O / 9 c S 1 E b F 6 w H H C / Y g O l A g F o 2 i l V v K Y V f B s 0 i u V 3 a o 7 A 1 k m X k 7 K k K P e K 3 1 1 + z F L I 6 6 Q S W p M x 3 M T 9 D O q U T D J J 8 V u a n h C 2 Y g O e M d S</formula><formula xml:id="formula_9">8 G H u / N M D M v S K Q w 6 L r f z s r q 2 v r G Z m G r u L 2 z u 7 d f O j h s m j j V j D d Y L G P d D q j h U i j e Q I G S t x P N a R R I 3 g p G t 1 O / 9 c S 1 E b F 6 w H H C / Y g O l A g F o 2 i l V v K Y V f B s 0 i u V 3 a o 7 A 1 k m X k 7 K k K P e K 3 1 1 + z F L I 6 6 Q S W p M x 3 M T 9 D O q U T D J J 8 V u a n h C 2 Y g O e M d S</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Scenario-Specific Meta Learning Settings</head><p>The recommendation task in the scenario c can be considered as a learning task, whose training set is D train </p><formula xml:id="formula_10">min ω E T c L ω (D test c |D train c ) ,<label>(1)</label></formula><p>where</p><formula xml:id="formula_11">L ω (D test c |D train c</formula><p>) is the loss on the testing set D test c given the training set D train c and meta learner parameters ω. Specifically, we use the hinge loss as the loss function:</p><formula xml:id="formula_12">L ω (D test c |D train c ) = (u k ,i k ,i − k )∈D test c ℓ(u k , i k , i − k ; θ c ) |D test c | ,<label>(2)</label></formula><formula xml:id="formula_13">ℓ(u, i, i − ; θ c ) = max 0, γ − f (u, i; θ c ) + f (u, i − ; θ c ) ,<label>(3)</label></formula><p>where the margin γ is set to 1 and θ c = M(D train c ; ω). θ c is generated via a sequential process, which we call scenario-specific learning. During the scenario-specific learning, the meta learner initializes θ c and updates it via gradient descent of flexible steps. After the learning, we will dump the training set and use the recommender f c for further tasks in the scenario c. During the evaluation, a different set of learning tasks is used, called meta-testing set T meta-test , whose scenarios are unseen during meta-training, i.e. T meta-train ∩ T meta-test = ∅.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THE PROPOSED FRAMEWORK</head><p>In this section, we detail the modules of the recommender network and meta learner for scenario-specific learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Recommender Network</head><p>We apply a feedforward neural network as the recommender f c , which consists of three modules, to take inputs (u, i) and generate corresponding outputs f c (u, i).</p><p>Embedding Module (u, i → e u , e i ): This module consists of two embedding matrices U ∈ R m×d and I ∈ R n×d for users and items respectively. The embeddings can be generated from user/item attributes and/or general interactions without contextual information, with methods in collaborative filtering <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b40">41]</ref> or network embedding <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b36">37]</ref>. The user u and item i are first mapped to one-hot vectors x u ∈ {0, 1} m and x i ∈ {0, 1} n , where only the element corresponding to the user/item id is 1 and all others are 0. The one-hot vectors are then transformed into continuous representations by embedding matrices: e u = U x u and e i = Ix i .</p><p>Hidden Layer Module (e u , e i → z ui ): This module is the central part of the recommender. Similar to deep recommendation models in <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>, the user and item embeddings are concatenated as e ui = [e u , e i ]. e ui is then mapped by L hidden layers to a continuous representation of user-item interaction</p><formula xml:id="formula_14">z ui = ϕ L (• • • (ϕ 1 (e ui )) • • • ).</formula><p>The l-th layer can be represented as:</p><formula xml:id="formula_15">ϕ l (z) = ReLU(W l z + b l ),<label>(4)</label></formula><p>where W l and b l are the weight matrix and the bias vector of the l-th layer.</p><p>Output Module z ui → f c (u, i): This module computes the recommendation score f c (u, i) based on the mapped representation of user-item interaction from the last hidden layer. This is achieved by a linear layer as f c (u, i) = w T z ui , where w is the weight of output layer.</p><p>The recommender parameters θ c , include {(W l , b l ) L l =1 , w }, are learned during scenario-specific learning. Note that the embedding matrices U and I are not included, to improve the recommender's generalization ability for unobserved users and items in D train c . In other words, embedding matrices are shared across different scenarios and kept fixed in scenario-specific learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">s 2 Meta</head><p>In the scenario-specific learning, the recommender parameters θ c are learned from the training set D train c . We summarize the following three challenges in the learning:</p><p>• How should the parameters θ c be initialized? Randomly initialized parameters can take a long time to converge and often lead to overfitting in the few-shot setting. • How should the parameters θ c be updated w.r.t the loss function? Traditional optimization algorithms rely on carefully tuned hyperparameters to converge to a good solution. Optimal hyperparameters on different scenarios may vary a lot.   </p><formula xml:id="formula_16">L (t ) ← L(B (t ) ; θ (t −1) c ) 8: p (t ) ← M s (L (t ) , ||∇ θ (t −1) c L (t</formula><formula xml:id="formula_17">θ (t ) c ← Update θ (t −1) c</formula><p>according to Equations ( <ref type="formula" target="#formula_28">7</ref>) and ( <ref type="formula" target="#formula_29">8</ref>)</p><p>14:</p><formula xml:id="formula_18">T ← T + 1 15:</formula><p>end for 16:</p><formula xml:id="formula_19">L test ← L(D test c ; θ (T ) c ) 17: Update ω u , ω R using ∇ ω u L test , ∇ ω R L test 18:</formula><p>dω s ← 0 19:</p><p>for j ← 1,T do 20:</p><formula xml:id="formula_20">dω s ← dω s + L test − L(D test c ; θ (j) c ) ∇ ω s ln(1 − p (j) ) 21:</formula><p>end for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>22:</head><p>Update ω s using dω s ▷ Equation ( <ref type="formula" target="#formula_37">11</ref>) 23: end for • When should the learning process stop? In few-shot setting, learning too much from a small training set can lead to overfitting and hurt the generalization performance.</p><p>These challenges are often solved by experts manually in traditional machine learning settings. Instead, we propose s 2 Meta which can automatically learn to control the learning process from end to end, including parameter initialization, update strategy and early-stop policy. In the following part, we will introduce how the meta learner controls the three parts of scenario-specific learning and how the meta learner is trained on the meta-training set T meta-train .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Parameter Initialization.</head><p>At the beginning of scenariospecific learning, the recommender parameters are initialized as θ (0) c . Traditionally, the parameters of a neural network are initialized by randomly sampling from a normal distribution or uniform distribution. Given enough training data, the randomly initialized parameters can usually converge to a good local optimum but may take a long time. In the few-shot setting, however, random initialization combined with limited training data can lead to serious overfitting, which hurts the ability of the trained recommender to generalize well. Instead, following <ref type="bibr" target="#b13">[14]</ref>, we initialize the recommender parameters from the global initial values shared across different scenarios. These initial values are considered as one of meta learner's parameters, denoted as ω R . Suitable initial parameters may not perform well on a specific scenario, but can adapt quickly to new scenarios given a small amount of training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Update Strategy. At each step t, a batch</head><formula xml:id="formula_21">B (t ) = {u k , i k , i − k } N k =1 with the fixed size N is sampled from D train c</formula><p>, where</p><formula xml:id="formula_22">(u k , i k ) ∈ D train c and i − k is sampled from I such that (u k , i − k ) D train c</formula><p>. Then the previous parameters θ</p><formula xml:id="formula_23">(t −1) c are updated to θ (t ) c</formula><p>according to L (t ) , the loss on B (t ) :</p><formula xml:id="formula_24">L (t ) = (u k ,i k ,i − k ∈B (t ) ) ℓ(u k , i k , i − k ; θ (t −1) c ) |B (t ) | , (<label>5</label></formula><formula xml:id="formula_25">)</formula><p>where ℓ is the loss function in Equation ( <ref type="formula" target="#formula_13">3</ref>). The most common method to update parameters of a neural network is stochastic gradient descent (SGD) <ref type="bibr" target="#b41">[42]</ref>. In SGD, the parameters θ c are updated as:</p><formula xml:id="formula_26">θ (t ) c = θ (t −1) c − α ∇ θ (t −1) c L (t ) , (<label>6</label></formula><formula xml:id="formula_27">)</formula><p>where α is the learning rate. There are many variations based on SGD, such as Adam <ref type="bibr" target="#b23">[24]</ref> and RMSprop <ref type="bibr" target="#b47">[48]</ref>, both of which adjust the learning rate dynamically.</p><p>Although hand-crafted optimization algorithms have gained success in training deep networks, they rely on a large amount of training data and carefully selected hyperparameters to converge to a good solution. In few-shot learning, the inappropriate learning rate can easily lead to being stuck in a poor local optimum. Moreover, optimal learning rates in different scenarios can differ significantly. Instead, we extend the idea of learning the optimization algorithm in <ref type="bibr" target="#b38">[39]</ref> to learn an update controller for parameters in θ c , implementing a more flexible update strategy than hand-crafted algorithms. The update strategy for θ c is:</p><formula xml:id="formula_28">θ (t ) c = β (t ) ⊙ θ (t −1) c − α (t ) ⊙ ∇ θ (t −1) c L (t ) ,<label>(7)</label></formula><p>where α (t ) is the input gate, similar to the learning rate in SGD; and β (t ) is the forget gate, which can help the meta learner quickly "forget" the previous parameters to leave a poor local optimum. Since the optimization process is a sequential process, in which the historical information matters, we use LSTM <ref type="bibr" target="#b19">[20]</ref> to encode historical information and issue input gates and forget gates:</p><formula xml:id="formula_29">h (t ) u , c (t ) u = LSTM([∇ θ (t −1) c L (t ) , L (t ) , θ (t −1) c ], h (t −1) u , c (t −1) u ), β (t ) = σ (W F h (t ) u + b F ), α (t ) = σ (W I h (t ) u + b I ),<label>(8)</label></formula><p>where LSTM(•, •, •) represents one-step forward in standard LSTM, h </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Early-Stop Policy.</head><p>In machine learning, overfitting is one of the critical problems that restrict the performance of models. When the model's representation ability exceeds the complexity of the problem, which is often the case for neural networks, the model might fit the sampling variance and random noise in the training data and get poor performance on the testing set. Regularization tricks like L 2 regularizer or dropout <ref type="bibr" target="#b44">[45]</ref> are often applied to limit the model's complexity. Another common trick is early-stop: the learning process is stopped when the training loss stops descending or the performance on the validation set begins to drop.</p><p>In few-shot setting, as we found, regularizers cannot prevent overfitting to the small training set. Also, as the size of the training set is too small, the validation set divided from the training set cannot provide a precise estimation of generalization ability. To overcome the drawback of hand-crafted stop rules, we propose to learn the stop policy with a neural network, which we call stop controller M s . To balance exploitation and exploration, we apply a stochastic stop policy, in which at step t, the learning process stops with probability p (t ) , which is predicted by M s . Similar to the update controller, M s is an LSTM that can encode historical information:</p><formula xml:id="formula_30">h (t ) s , c (t ) s = LSTM([L (t ) , ||∇ θ (t −1) c L (t ) || 2 ], h (t −1) s , c (t −1) s ), p (t ) = σ (W s h (t ) s + b s ),<label>(9)</label></formula><p>where s are the hidden state and the cell state of the stop controller at step t. The parameters of the stop controller, denoted as ω s , include {W s , b s } as well as LSTM related parameters.</p><formula xml:id="formula_31">||∇ θ (t −1) c L (t ) || 2 is L 2 -norm</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.2.4</head><p>Training of Meta Learner. The objective of the meta learner is to minimize the expected loss on the testing set after scenariospecific learning on the training set, as is described in Equations ( <ref type="formula" target="#formula_10">1</ref>) to <ref type="bibr" target="#b2">(3)</ref>. The parameters ω of the meta learner include shared initial parameters ω R , parameters of the update controllers ω u and parameters of the stop controller ω s .</p><p>The gradients of ω R and ω u with respect to the meta-testing loss</p><formula xml:id="formula_32">L ω (D test c |D train c</formula><p>), which we call meta-gradient, can be computed with back-propagation. However, the meta-gradient may involve higher-order derivatives, which are quite expensive to compute when T is large. Therefore in MAML <ref type="bibr" target="#b13">[14]</ref>, they only take one-step gradient descent. Instead, our model can benefit from flexible multistep gradient descent. We ignore higher-order derivatives in the meta-gradient by taking the gradient of the recommender parameters, ∇ θ (t −1) c L (t ) , as independent of ω R and ω u . With the gradients, we can optimize ω R and ω u with normal SGD.</p><p>Since the relation between ω s and θ c is discrete and stochastic, it is impossible to take direct gradient descent on ω s . We use stochastic policy gradient to optimize ω s . Given one learning trajectory based on stop controller parameters ω s : θ</p><formula xml:id="formula_33">(0) c , θ<label>(1)</label></formula><formula xml:id="formula_34">c , θ (2) c , • • • , θ (T ) c ,</formula><p>We define the immediate reward at step t as the loss decrease of one-step update:</p><formula xml:id="formula_35">r (t ) = L(D test c ; θ (t −1) c ) − L(D test c ; θ (t ) c ).</formula><p>Then the accumulative reward at t is:</p><formula xml:id="formula_36">Q (t ) = T i=t r (t ) = L(D test ; θ (t −1) c ) − L(D test ; θ (T ) c ),<label>(10)</label></formula><p>which is the loss decrease from step t to the end of learning . According to the REINFORCE algorithm <ref type="bibr" target="#b53">[54]</ref>, we can update ω s as:</p><formula xml:id="formula_37">ω s ← ω s + γ T t =1 Q (t ) ∇ ω s lnM s (L (t ) , ||∇ θ (t −1) c L (t ) || 2 ; ω s ), (<label>11</label></formula><formula xml:id="formula_38">)</formula><p>where γ is the learning rate for ω s . The detailed training algorithm for the s 2 Meta learner is described in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENT</head><p>In this section, we detail the experiments to evaluate the proposed s 2 Meta in the few-shot scenario-aware recommendation, including details of the datasets, competitors, experimental settings and comparison results. We will also delve deeper to analyze how s 2 Meta helps the recommender network achieves better results with process sensitivity analyses. Finally, we analyze how the architecture of the recommender influences performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Settings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Datasets.</head><p>Current available open datasets for context-aware recommender systems are mostly of small scale with very sparse contextual information <ref type="bibr" target="#b21">[22]</ref>. We evaluate our method on two public datasets and one newly released large scenario-based dataset from Taobao 3 . The first dataset is the Amazon Review dataset <ref type="bibr" target="#b16">[17]</ref>, which contains product reviews and metadata from Amazon. We keep the reviews with ratings no less than three as the positive useritem interactions and take interactions in different categories as different scenarios. Our second dataset is the Movielens-20M <ref type="bibr" target="#b15">[16]</ref> dataset, with rating scores from the movie recommendation service Movielens. Following <ref type="bibr" target="#b17">[18]</ref>, we transform the explicit ratings into implicit data, where all the movies the user has rated are taken as positive items for the user. The tags of movies are used as scenarios.</p><p>In each dataset, we select scenarios with less than 1,000 but more than 100 items/movies as few-shot tasks with enough interactions for evaluation. Our third dataset is from the click log of Cloud Theme, which is a crutial recommendation procedure in the Taobao app. Different themes correspond to different scenarios of purchase, e.g., "what to take when traveling" "how to dress up yourself on a party" "things to prepare when a baby is coming". In each scenario, a collection of items in related categories is displayed, according to the scenario as well as the user's interests. The dataset includes more than 1.4 million clicks from 355 different scenarios in a 6-days promotion season, with one-month purchase history of users before the promotion started. Table <ref type="table" target="#tab_3">2</ref> summarizes the statistics of three datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Baselines.</head><p>We select state-of-the-art baselines in item recommendation in the same domain or cross-domains which can be broadly divided into the following categories:</p><p>Heuristic: ItemPop: Items are ranked according to their popularity in specific scenarios, judged by the number of interactions in corresponding training sets. This is a non-personalized baseline in item recommendation <ref type="bibr" target="#b40">[41]</ref>. General Domain: NeuMF: The Neural Collaborative Filtering <ref type="bibr" target="#b17">[18]</ref> is a state-of-the-art item recommendation method. It combines the traditional MF and MLP in neural networks to predict user-item interactions. This method is not proposed for cross-domain recommendation, and we train a single model on all the scenarios. More details in experimental settings can be found in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Performance Comparison</head><p>In this subsection, we report comparison results and summarize insights. Table <ref type="table" target="#tab_4">3</ref> shows the results on the three datasets concerning top-N recalls <ref type="bibr" target="#b46">[47]</ref>. We can see that s 2 Meta achieves the best results throughout three datasets, compared to both shallow cross-domain models (CMF and CDCF) and deep cross-domain models (EMCDR and CoNet). Involving the extracted scenario information, s 2 Meta also performs better compared to the general recommendation (NeuMF) and the heuristic method ItemPop.</p><p>For the Amazon dataset, s 2 Meta gives 9.41% improvements on average compared with the best baseline (EMCDR), and achieves 16.47% improvements in terms of Recall@50 compared to the nonscenario-aware NeuMF, which demonstrates the benefits of combining scenario information. Among the cross-domain baselines, neural cross-domain methods are slightly better than the shallow cross-domain methods.</p><p>For the Movielens dataset, s 2 Meta achieves 2.87% improvements on average compared to the best baseline (CoNet). It is a phenomenon common in Amazon and Movielens that domain-specific methods can perform better than the left competitors, showing that the For the Taobao dataset, s 2 Meta achieves 3.95% performance lifts on average. For this dataset, NeuMF performs best among all the baselines. The reason might be that this dataset is from the click log in the real-world recommendation and clicks often contain more noise than purchase or ratings. The performances of baselines that adapt to the scenario in a naive way might be detrimental by overfitting in the few-shot setting. Above all, s 2 Meta can still outperform NeuMF with a flexible learning strategy learned by the proposed meta learner.</p><p>Note that the relative improvements by taking account of scenario information vary among three datasets. For Amazon, most scenario-specific baselines can perform better than the general domain baseline, while for the Taobao dataset, most scenario-specific baselines cannot outperform NeuMF. It implies that the usefulness of scenario information varies, and s 2 Meta can dynamically adapt to different datasets' requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Process Sensitivity Analysis</head><p>In this subsection, we analyze how the s 2 Meta works to control the scenario-specific learning process. Due to the space limit, we only illustrate results from Amazon and performance patterns are the same from the other two datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Impact of Different</head><p>Parts. First, we analyze the contributions of three parts of meta learner described in Section 4.2. Specifically, we compare the performances of the following variations:</p><p>• Complete: The complete meta learner that controls parameter initialization, update strategy, and early-stop policy. • RandInit: Parameters of the recommender are randomly initialized. The update strategy and early-stop policy remain unchanged. • FixedLr: Parameters of the recommender are updated by standard SGD, with fixed learning rate 0.01. Parameter initialization and early-stop policy remain unchanged.</p><p>• FixedStep: The step of scenario-specific learning is fixed at 20, while parameter initialization and update strategy remain consistent with the complete method.</p><p>The performance comparison is listed in Table <ref type="table" target="#tab_5">4</ref>. We can see that the complete model can significantly outperform the three weakened variations, indicating that three parts of the meta learner all help to improve the final performance. Among the three variations, the random initialization hurts the performance most. When the parameters are randomly initialized, the recommender has to learn from a random point each time and the learning will take more steps and more easily be stuck in a local optimum. The effect of removing early-stop policy is relatively small. The reason might be that when the learning process is too long, the update controller can still give low input gates to avoid overfitting.   remain stable during training. Among different parameters, the weight matrices mainly change at the beginning, and the bias vectors mainly change at the end. This strategy might help to quickly adjust the parameters by updating a part of the parameters at a time. Also, updating the bias vectors can be a minor complement to the updated weight matrices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Analysis of Recommender Architecture</head><p>In this subsection, we analyze how the architecture of the recommender influences the performance. We compare the following two architectures for the recommender:</p><p>• Mapping Module: The user and item embeddings are mapped by two multilayer perceptrons respectively, and the final score is computed as the dot product of the mapped user and item embeddings. This is the architecuture of EMCDR. • Interaction Module: User and item embeddings are concatenated and a multilayer perceptron computes the final score from the concatenated vector. This is the architecture used by NeuMF and CoNet.</p><p>We compare the performance of two architectures with the same meta learner. The results on three datasets are shown in Figure <ref type="figure" target="#fig_13">3</ref>. In general, we can see that in general the interaction module can perform better than the mapping module, because the interaction module can represent the complicated interactions between users and items, while the mapping module only maps the user and item embeddings independently. On Taobao, the relative improvement of interaction modules can reach 6.71%. However, on Amazon, the mapping module slightly outperforms the interaction module. This implies that the optimal recommender architecture may differ among datasets. It's also noted that in practice the mapping module can be more efficient because given the recommender, the mapped embeddings can be pre-computed and the matching can be optimized with advanced data structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this work, we explored few-shot learning for recommendation in the scenario-specific setting. We proposed a novel sequential scenario-specific framework for recommender systems using meta learning, to solve the cold-start problem in some recommendation scenarios. s 2 Meta can automatically control the learning process to converge to a good solution and avoid overfitting, which has been the critical issue of few-shot learning. Experiments on real-world datasets demonstrate the effectiveness of the proposed method, by comparing with shallow/deep, general/scenario-specific baselines. In the future, we will automate the architecture design of recommenders. In our experiments, we found that the performance of the same architecture might differ in different datasets. By learning to choose the optimal recommender architecture, the performance of s 2 Meta can be further improved. Scholar (61825602), Tsinghua University Initiative Scientific Research Program, and a research fund supported by Alibaba. difference between the source domain and the target domain and fully evaluate the model's ability to learn user behaviors in new scenarios, we select the leaf categories in different first-order categories as the source domain, meta-training set and meta-testing set. The specific split of first-order categories is displayed in Table <ref type="table" target="#tab_6">5</ref>.</p><p>On the Movielens-20M 10 dataset, we take the movie tags in the Tag Genome included in the dataset as scenarios. The tag genome is a data structure that contains tag relevance scores for movies that are computed based on user-contributed content. Tags with relevance scores higher than 0.8 to a movie are considered as tags of the movie. We use the movies without tags as the source domain, and randomly divide the tags into the meta-training set and metatesting set.</p><p>On both datasets, we select the scenarios with 100-1000 items/movies as the few-shot tasks with enough interactions for evaluation. Unlike traditional cross-domain settings in which the interactions on different domains are simply concatenated, we are more interested in the cold-start scenarios, on which most users have no previous interactions. Therefore on each scenario, 64 interactions of shared users are used as D train c and all others are used for evaluation. We use all the interactions on the source domain to generate the user embeddings and the interactions of the users only appearing on the scenario to generate the item embeddings, with Matrix Factorization <ref type="bibr" target="#b25">[26]</ref>. For cross-domain baselines, each scenario is considered as a target domain. The training data is all the interactions on the source domain, the few-shot interactions of shared users D train c , and all the interactions of the users only appearing on the target domain. Therefore, all the comparative methods use the same training data and evaluation set, and the fairness of comparison is guaranteed.</p><p>On the Taobao Themes 11 dataset, we take the different themes as different scenarios and all the clicks are considered as positive user-item interactions. We use the one-month purchase history of users before the click log as the source domain and randomly divide the scenarios into the meta-training set and meta-testing set. As this dataset is quite sparse, we use the general user and item embeddings generated from attributes and interactions in Taobao by GraphSage <ref type="bibr" target="#b14">[15]</ref>. This embeddings are also used by NeuMF, EMCDR and CoNet. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Our task is to recommend top-n items for each user u in scenario c and maximize the probability of the user's followup behaviors, e.g., clicks or conversions. Notice that, compared to previous works in cross-domain recommender systems that require a large amount of training samples on each domain, our work studies the case where the size of D train c is limited. The latter usually</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>e K u P U 7 3 P k 3 T t s s t P X A h c M 5 9 3 L v P X 7 C m Q T b / j Z K S 8 s r q 2 v l 9 c r G 5 t b 2 j r m 71 5 Z x K g h t k Z j H o u t j S T m L a A s Y c N p N B M W h z 2 n H H 1 9 P / M 4 D F Z L F 0 R 1 k C X V D P I x Y w A g G L X n m Q X C v a n C S e 6 o P 9 B G U j / 0 s z z 2 z a t f t K a x F 4 h S k i g o 0 P f O r P 4 h J G t I I C M d S 9 h w 7 A V d h A Y x w m l f 6 q a Q J J m M 8 p D 1 N I x x S 6 a r p + b l 1 r J W B F c R C V w T W V P 0 9 o X A o Z R b 6 u j P E M J L z 3 k T 8 z + u l E F y 6 i k V J C j Q i s 0 V B y i 2 I r U k W 1 o A J S o B n m m A i m L 7 V I i M s M A G d W E W H 4 M y / v E j a p 3 X n r G 7 f n l c b V 0 U cZ X S I j l A N O e g C N d A N a q I W I k i h Z / S K 3 o w n 4 8 V 4 N z 5 m r S W j m N l H f 2 B 8 / g D X m J Y O &lt; / l a t e x i t &gt; f (t) party &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e L v D Z p F L F T I V Q 4 + z g i D Z g / 2 K h P c = " &gt; A A A B / 3 i c b V D L S s N A F J 3 4 r P U V F d y 4 C R a h b k q i g i 6 L b l x W s A 9 o Y 5 h M J + 3 Q y S T M 3 I g h Z u G v u H G h i F t / w 5 1 / 4 7 T N Q l s P X D i c c + / M v c e P O V N g 2 9 / G w u L S 8 s p q a a 2 8 v r G 5 t W 3 u 7 L Z U l E h C m y T i k e z 4 W F H O B G 0 C A 0 4 7 s a Q 4 9 D l t + 6 O r s d + + p 1 K x S N x C G l M 3 x A P B A k Y w a M k z 9 4 O 7 r A r H u Z f 1 g D 5 A F m M J a Z 5 7 Z s W u 2 R N Y 8 8 Q p S A U V a H j m V 6 8 f k S S k A g j H S n U d O w Y 3 0 6 8 x w m l e 7 i W K x p i M 8 I B 2 N R U 4 p M r N J v v n 1 p F W + l Y Q S V 0 C r I n 6 e y L D o</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>y 4 c z r l 3 5 t 7 j x 5 w p s O 1 v o 7 C w u L S 8 U l w t r a 1 v b G 6 Z 2 z t N F S W S 0 A a J e C T b P l a U M 0 E b w I D T d i w p D n 1 O W / 7 w a u y 3 7 q</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>a I 3 6 8 l 6 s d 6 t j 3 n r i l X O H K I / s D 5 / A K J v k 7 c = &lt; / l a t e x i t &gt; ✓ (0) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " c h e Z N C g b s M s r / H 8 4 z W Z D 7 q s 5 9 C Q</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>2 g J m o h g h 7 R M 3 p F b 8 a T 8 W K 8 G x + z 0 p J R 9 O y j P z A + f w C D e J d 7 &lt; / l a t e x i t &gt; p (t) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " T b w x F y N e T u + n M H W n M w F l 5 P S s a B M = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S L U S 0 l U 0 G P R i 8 c K 9 g P a W D b b T b t 0 s w m 7 E 6 G E / g g v H h T x 6 u / x 5 r 9 x 2 + a g r Q</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>R S N u / G x 2 7 o S c W q V P w l j b U k h m 6 u + J j E b G j K P A d k Y U h 2 b R m 4 r / e Z 0 U w 2 s / E y p J k S s 2 X x S m k m B M p r + T v t C c o R x b Q p k W 9 l b C h l R T h j a h o g 3 B W 3 x 5 m T T P q 9 5 F 1 b 2 / L N d u 8 j g K c A w n U A E P r q A G d 1 C H B j A Y w T O 8 w p u T O C / O u / M x b 1 1 x 8 p k j + A P n 8 w f x T I 9 N &lt; / l a t e x i t &gt; p (t) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " T b w x F y N e T u + n M H W n M w F l 5 P S s a B M = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S L U S 0 l U 0 G P R i 8 c K 9 g P a W D b b T b t 0 s w m 7 E 6 G E / g g v H h T x 6 u / x 5 r 9 x 2 + a g r Q</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: The framework of meta learner and recommender. In each scenario, the recommender is initialized by the initializer and updated by the update controller. After the learning process is stopped by the stop controller, the loss of the final recommender on the test set is computed, and the parameters of meta learner are updated by the meta-gradient.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>the user set, item set and scenario set m = |U|, n = |I| numbers of users and items c a recommendation scenario H c ⊂ U × I the interaction set of c T c the learning task connected with c D train c , D test c the training set and testing set of T c f c : U × I → R the recommender function for c θ c parameters of f c U , I embedding matrices for users and items M meta learner T meta-train , T meta-test meta-training set and meta-testing set ω = {ω R , ω u , ω s } parameters of the meta learner ω R</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>c.</head><label></label><figDesc>Our goal is to learn a meta learner M that, given D train c , predicts parameters of f c , θ c . Similar to the standard few-shot learning settings [39, 52], we assume access to a set of training tasks as the meta-training set, denoted as T meta-train . Each training task T c ∈ T meta-train corresponds to a scenario c and has its training/testing pairs: T c = {D train c , D test c }. D test c is the set of pairwise testing instances: D test c := {(u, i, i − )|(u, i) ∈ H c ∧ (u, i) D train c ∧ (u, i − ) H c }. The meta-training set can be easily built with the previous scenarios in the recommender system, by randomly dividing the user-item interactions in each scenario into the training set and testing set. The parameters ω of the meta learner is optimized w.r.t. the metatraining objective:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Algorithm 1 for t ← 1 ,T max do 6 :</head><label>116</label><figDesc>Training Algorithm of Meta Learner Input: Meta-training set T meta-train , Loss function L 1: ω u , ω s , ω R ← Random Initialization 2: for d ← 1, K do ▷ K is the number of meta-training steps 3: B (t ) ← Random batch from D train</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>u</head><label></label><figDesc>are hidden state and cell state of the update controller at step t, and σ (•) is the sigmoid function. The parameters of the updated controller, denoted as ω u , include {W F , b F ,W I , b I } as well as LSTM related parameters. Different parameters in θ c correspond to different update controllers. In this way, different learning strategies can be applied.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The visualization of the learning process. Left most is the training loss, stop probability and recall on the testing set during the learning process. The other four figures are average input gates and forget gates of weights and biases in the hidden layers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Impact of the recommender architecture on the Amazon(left), Movielens(middle) and Taobao(right) datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>of gradients at step t, and h</figDesc><table><row><cell></cell><cell>(t ) s and</cell></row><row><cell>c</cell><cell>(t )</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Statistics of the Datasets. #Inter. denotes the number of user-item interactions and #Scen. denotes the number of scenarios we use as few-shot tasks.</figDesc><table><row><cell cols="5">Shallow Cross-Domain: (1) CDCF: The Cross-Domain Collab-</cell></row><row><cell cols="5">orative Filtering[30] is a simple method based on Factor-</cell></row><row><cell cols="5">ization Machines [40] for cross-domain recommendation.</cell></row><row><cell cols="5">By factorizing the interaction data of shared users in the</cell></row><row><cell cols="5">source domain, it allows extra information to improve rec-</cell></row><row><cell cols="5">ommendation in a target domain; (2) CMF: Collective Matrix</cell></row><row><cell cols="5">Factorization[43] is a matrix factorization method for cross-</cell></row><row><cell cols="5">domain recommendation. It jointly learns low-rank repre-</cell></row><row><cell cols="5">sentations for a collection of matrices by sharing common</cell></row><row><cell cols="5">entity factors, which enables the knowledge transfer across</cell></row><row><cell cols="5">domains. We use it as a shallow cross-domain baseline, with</cell></row><row><cell cols="5">users partially overlapping in different domains.</cell></row><row><cell cols="5">Deep Cross-Domain: (1) EMCDR: The Embedding and Mapping</cell></row><row><cell cols="5">framework for Cross-Domain Recommendation [32] con-</cell></row><row><cell cols="5">sists of two steps. Step 1 is to learn the user and item embed-</cell></row><row><cell cols="5">dings in each domain with latent factor models. Step 2 is to</cell></row><row><cell cols="5">learn the embedding mapping between two domains with</cell></row><row><cell cols="5">a multilayer perceptron from the shared users/items in two</cell></row><row><cell cols="5">domains; (2) CoNet: The Collaborative Cross Networks[21]</cell></row><row><cell cols="5">enables dual knowledge transfer across domains by intro-</cell></row><row><cell cols="5">ducing cross connections from one base network to another</cell></row><row><cell cols="2">and vice versa.</cell><cell></cell><cell></cell></row><row><cell>Dataset</cell><cell>#Users</cell><cell>#Items</cell><cell cols="2">#Inter. #Scen.</cell></row><row><cell>Amazon</cell><cell>766,337</cell><cell cols="2">492,505 17,523,124</cell><cell>1,289</cell></row><row><cell cols="2">Movielens 138,493</cell><cell cols="2">27,278 20,000,263</cell><cell>306</cell></row><row><cell>Taobao</cell><cell cols="2">775,603 1,452,525</cell><cell>5,717,835</cell><cell>355</cell></row></table><note>3 Downloadable from https://tianchi.aliyun.com/dataset/dataDetail?dataId=9716.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>The top-N recall results on test scenarios.</figDesc><table><row><cell></cell><cell></cell><cell>Amazon</cell><cell></cell><cell></cell><cell>Movielens</cell><cell></cell><cell></cell><cell>Taobao</cell><cell></cell></row><row><cell cols="10">Method Recall@10 Recall@20 Recall@50 Recall@10 Recall@20 Recall@50 Recall@20 Recall@50 Recall@100</cell></row><row><cell>NeuMF</cell><cell>24.55</cell><cell>35.65</cell><cell>55.19</cell><cell>31.67</cell><cell>51.30</cell><cell>84.98</cell><cell>25.64</cell><cell>42.31</cell><cell>58.84</cell></row><row><cell>ItemPop</cell><cell>26.86</cell><cell>32.65</cell><cell>50.42</cell><cell>39.65</cell><cell>54.32</cell><cell>78.12</cell><cell>18.25</cell><cell>28.57</cell><cell>32.44</cell></row><row><cell>CDCF</cell><cell>10.27</cell><cell>16.72</cell><cell>32.79</cell><cell>29.19</cell><cell>41.04</cell><cell>65.75</cell><cell>9.81</cell><cell>20.93</cell><cell>32.14</cell></row><row><cell>CMF</cell><cell>27.64</cell><cell>38.31</cell><cell>55.24</cell><cell>29.80</cell><cell>46.91</cell><cell>74.37</cell><cell>9.16</cell><cell>16.47</cell><cell>29.31</cell></row><row><cell>EMCDR</cell><cell>31.71</cell><cell>42.14</cell><cell>58.73</cell><cell>43.55</cell><cell>60.89</cell><cell>83.54</cell><cell>20.43</cell><cell>31.52</cell><cell>45.67</cell></row><row><cell>CoNet</cell><cell>30.17</cell><cell>41.57</cell><cell>56.06</cell><cell>46.62</cell><cell>63.61</cell><cell>87.06</cell><cell>20.27</cell><cell>31.48</cell><cell>44.53</cell></row><row><cell>s 2 Meta</cell><cell>34.39</cell><cell>46.53</cell><cell>64.28</cell><cell>47.79</cell><cell>66.02</cell><cell>89.07</cell><cell>27.11</cell><cell>44.10</cell><cell>59.98</cell></row><row><cell>Improve</cell><cell>8.35</cell><cell>10.42</cell><cell>9.45</cell><cell>2.51</cell><cell>3.79</cell><cell>2.31</cell><cell>5.73</cell><cell>4.23</cell><cell>1.90</cell></row><row><cell cols="5">user interests relatively concentrate in a specific scenario. Also,</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">we can find that the deep cross-domain methods can outperform</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">shallow cross-domain methods by improvements over 10%. The</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">performance of NeuMF, which is not designed for cross-domain</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">recommendation, is also superior to CMF and CDCF, showing the</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">power of deep learning in recommendation.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Impact of different parts in meta learner on Amazon dataset Case Study: the learning process learned by the meta learner.To further analyze the learning process the meta learner learned automatically, we select a typical scenario on Amazon and visualize its learning process. Figure2shows the training loss, stop probability(predicted by the stop controller), recall on the test set(not visible to the meta learner) and the input and forget gates(predicted by the update controller). From the leftmost figure, we can see that as the training loss ceases to drop, the stop probability rises dramatically, finally leading to the end of the learning process. In fact we can find that the recall on the test set has been stable and further training might lead to overfitting. From the visualization of input gates and forget gates, different update strategies are applied for different layers and different parameters. For different layers, we can find that for the last hidden layer, the input gates remain low and the forget gates remain high, which indicates its parameters</figDesc><table><row><cell>Method</cell><cell cols="3">Recall@10 Recall@20 Recall@50</cell></row><row><cell>RandInit</cell><cell>33.12</cell><cell>45.44</cell><cell>63.35</cell></row><row><cell>FixedLr</cell><cell>33.56</cell><cell>45.90</cell><cell>63.86</cell></row><row><cell>FixedStep</cell><cell>33.84</cell><cell>46.13</cell><cell>64.02</cell></row><row><cell>Complete</cell><cell>34.39</cell><cell>46.53</cell><cell>64.28</cell></row><row><cell>5.3.2</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Dataset split on Amazon Cell Phones and Accessories Baby, Automotive, Office Products Amazon Instant Video, Patio, Lawn and Garden 10 https://grouplens.org/datasets/movielens/ 11 https://tianchi.aliyun.com/dataset/dataDetail?dataId=9716.</figDesc><table><row><cell>Domain</cell><cell>First-order Category</cell></row><row><cell></cell><cell>Books, Electronics, Movies and TV</cell></row><row><cell></cell><cell>Clothing, Shoes and Jewelry, Home and Kitchen</cell></row><row><cell>Source Domain</cell><cell>Sports and Outdoors, Health and Personal Care</cell></row><row><cell></cell><cell>Toys and Games, Apps for Android</cell></row><row><cell></cell><cell>Grocery and Gourmet Food</cell></row><row><cell>Meta-training</cell><cell>Beauty, CDs and Vinyl, Kindle Store Tools and Home Improvement, Pet Supplies</cell></row><row><cell></cell><cell>Digital Music, Musical Instruments</cell></row><row><cell>Meta-testing</cell><cell>Video Games,</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0">https://youtu.be/TNHLZqWnQwc</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1">https://pytorch.org/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2">http://github.com/hexiangnan/neural_collaborative_filtering</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3">https://www.csie.ntu.edu.tw/~cjlin/libmf/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_4">http://www.libfm.org</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_5">http://jmcauley.ucsd.edu/data/amazon</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>Jie Tang and Hongxia Yang are the corresponding authors of this paper. The work is supported by the NSFC for Distinguished Young</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A APPENDIX</head><p>In this section, we first give the deployment description and implementation notes of our proposed models. The implementation notes and parameter configurations of compared methods are then given. Finally, we introduce the experiment settings in three datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Deployment</head><p>Deployment is at the Guess You Like session, the front page of the Mobile Taobao; and the illustration video can also be watched from the link 4 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Implementation Notes</head><p>The architecture of the recommender network is designed as three hidden layers and one output layer. The embedding size is set to 128 on Amazon and Alibaba Theme and 64 on Movielens. The number of hidden units in each layer is half of that in the last layer. The hidden size of the update LSTM is set to 16. The hidden size of the stop LSTM is set to 18. For the input of the update controllers and stop controller, we use the preprocessing trick in <ref type="bibr" target="#b3">[4]</ref>:</p><p>where p = 10 in our experiment. s 2 Meta is trained by standard SGD with learning rate 0.0001 and weight decay 1e-5, implemented with PyTorch 5 1.0 in Python 3.6 and runs on a single Linux server with 8 NVIDIA GeForce GTX 1080.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Compared Methods</head><p>A.3.1 Code. The code of NeuMF is provided by the author 6 . We simply adapt the input and evaluation modules to our experimental settings. For CMF, we adpot the implementation of LIBMF 7 . For CDCF, we dapot the official libFM implementation 8  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Experiment Setting</head><p>As we mention in Section 5.1.1, it is challenging to find large-scale public datasets to evaluate context-aware recommender systems. Therefore we evaluate our method on two public datasets in the cross-domain setting. We also use one scenario-based dataset in Taobao.</p><p>On the Amazon Review 9 dataset, we take user purchases in different leaf categories as different scenarios. To maximize the</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Incorporating contextual information in recommender systems using a multidimensional approach</title>
		<author>
			<persName><forename type="first">Gediminas</forename><surname>Adomavicius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shahana</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Tuzhilin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="103" to="145" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Toward the Next Generation of Recommender Systems: A Survey of the State-of-the-Art and Possible Extensions</title>
		<author>
			<persName><forename type="first">Gediminas</forename><surname>Adomavicius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Tuzhilin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="734" to="749" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Context-Aware Recommender Systems</title>
		<author>
			<persName><forename type="first">Gediminas</forename><surname>Adomavicius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Tuzhilin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recommender Systems Handbook</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="191" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning to learn by gradient descent by gradient descent</title>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Andrychowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Misha</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergio</forename><forename type="middle">Gomez</forename><surname>Colmenarejo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">W</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nando</forename><surname>De Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3981" to="3989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The importance of hyperparameters selection within small datasets</title>
		<author>
			<persName><forename type="first">Parivash</forename><surname>Ashrafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Davey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rod</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Prapopoulou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gary</forename><forename type="middle">P</forename><surname>Moss</surname></persName>
		</author>
		<idno>IJCNN. 1-8</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Data mining techniques -for marketing, sales, and customer support</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gordon</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName><surname>Linoff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Pavel</forename><surname>Brazdil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christophe</forename><surname>Giraud-Carrier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Vilalta</surname></persName>
		</author>
		<title level="m">Metalearning: Applications to Data Mining</title>
				<imprint>
			<publisher>Springer Publishing Company</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>Incorporated</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cross-Domain Recommender Systems</title>
		<author>
			<persName><forename type="first">Iván</forename><surname>Cantador</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ignacio</forename><surname>Fernández-Tobías</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shlomo</forename><surname>Berkovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Cremonesi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recommender Systems Handbook</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="919" to="959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Wide &amp; Deep Learning for Recommender Systems</title>
		<author>
			<persName><forename type="first">Heng-Tze</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Levent</forename><surname>Koc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremiah</forename><surname>Harmsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hrishi</forename><surname>Aradhye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Glen</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mustafa</forename><surname>Ispir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rohan</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zakaria</forename><surname>Haque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lichan</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vihan</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaobing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hemal</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys Workshop</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="7" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep Neural Networks for YouTube Recommendations</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Covington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emre</forename><surname>Sargin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="191" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Metalearning and Recommender Systems</title>
		<author>
			<persName><forename type="first">Tiago</forename><surname>Cunha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P L F</forename><surname>Andr</surname></persName>
		</author>
		<author>
			<persName><surname>De Carvalho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">423</biblScope>
			<biblScope unit="page" from="128" to="144" />
			<date type="published" when="2018-01">2018. Jan. 2018</date>
		</imprint>
	</monogr>
	<note>C</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Selecting Collaborative Filtering Algorithms Using Metalearning</title>
		<author>
			<persName><forename type="first">Tiago</forename><surname>Cunha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P L F</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName><surname>De Carvalho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML/PKDD</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="393" to="409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">When recommenders fail: predicting recommender failure for algorithm selection and combination</title>
		<author>
			<persName><forename type="first">D</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Ekstrand</surname></persName>
		</author>
		<author>
			<persName><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="233" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</title>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<idno>ICML. 1126-1135</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Inductive Representation Learning on Large Graphs</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1025" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">The MovieLens Datasets: History and Context. TiiS</title>
		<author>
			<persName><forename type="first">F</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Harper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">19</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Ups and Downs: Modeling the Visual Evolution of Fashion Trends with One-Class Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="507" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Neural Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
		<idno>WWW. 173-182</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Recurrent Neural Networks with Top-k Gains for Session-based Recommendations</title>
		<author>
			<persName><forename type="first">Balázs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="843" to="852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Long Short-Term Memory</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">CoNet: Collaborative Cross Networks for Cross-Domain Recommendation</title>
		<author>
			<persName><forename type="first">Guangneng</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="667" to="676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Datasets for Context-Aware Recommender Systems: Current Context and Possible Directions</title>
		<author>
			<persName><forename type="first">Sergio</forename><surname>Ilarri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raquel</forename><forename type="middle">Trillo</forename><surname>Lado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramón</forename><surname>Hermoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE Workshops</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="25" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Information Retrieval in Context: IRiX</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Ingwersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalervo</forename><surname>Järvelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="31" to="39" />
			<date type="published" when="2005-12">2005. Dec. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Deep Learning Workshop</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Matrix Factorization Techniques for Recommender Systems</title>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">M</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A Survey of Recommender Systems in Twitter</title>
		<author>
			<persName><forename type="first">Ee-Peng</forename><surname>Su Mon Kywe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feida</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SocInfo</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="420" to="433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">One-Shot Learning of Object Categories</title>
		<author>
			<persName><forename type="first">Fei-Fei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="594" to="611" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Amazon.com Recommendations: Item-to-Item Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Greg</forename><surname>Linden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brent</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>York</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet Computing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="76" to="80" />
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Cross-Domain Collaborative Filtering with Factorization Machines</title>
		<author>
			<persName><forename type="first">Babak</forename><surname>Loni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Hanjalic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECIR</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="656" to="661" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Task Complexity and Contingent Processing in Brand Choice</title>
		<author>
			<persName><forename type="first">Denis</forename><forename type="middle">A</forename><surname>Lussier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">W</forename><surname>Olshavsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Consumer Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="154" to="165" />
			<date type="published" when="1979">1979. 1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Cross-Domain Recommendation: An Embedding and Mapping Approach</title>
		<author>
			<persName><forename type="first">Huawei</forename><surname>Tong Man</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqi</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><surname>Cheng</surname></persName>
		</author>
		<idno>IJCAI. 2464-2470</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Tsendsuren</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Yu</surname></persName>
		</author>
		<title level="m">Meta Networks. In ICML</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2554" to="2563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">On First-Order Meta-Learning Algorithms</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<idno>CoRR abs/1803.02999</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Using Context to Improve Predictive Modeling of Customers in Personalization Applications</title>
		<author>
			<persName><forename type="first">Cosimo</forename><surname>Palmisano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Tuzhilin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Gorgoglione</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1535" to="1549" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A constructive process view of decision making: Multiple strategies in judgment and choice</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">W</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">R</forename><surname>Bettman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eloise</forename><surname>Coupey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Psychologica</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="107" to="141" />
			<date type="published" when="1992">1992. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">DeepWalk: online learning of social representations</title>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Sequenceaware Recommender Systems</title>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Quadrana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Cremonesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dietmar</forename><surname>Jannach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UMAP</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="373" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Factorization Machines</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="995" to="1000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">BPR: Bayesian Personalized Ranking from Implicit Feedback</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
				<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A Stochastic Approximation Method</title>
		<author>
			<persName><forename type="first">Herbert</forename><surname>Robbins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sutton</forename><surname>Monro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Math. Statist</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="400" to="407" />
			<date type="published" when="1951-09">1951. 09 1951</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Relational learning via collective matrix factorization</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Ajit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">J</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
				<meeting>the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>Las Vegas, Nevada, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-08-24">2008. August 24-27, 2008</date>
			<biblScope unit="page" from="650" to="658" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Prototypical Networks for Few-shot Learning</title>
		<author>
			<persName><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4080" to="4090" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</title>
		<author>
			<persName><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014-01">2014. Jan. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A context-aware preference database system</title>
		<author>
			<persName><forename type="first">Kostas</forename><surname>Stefanidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evaggelia</forename><surname>Pitoura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panos</forename><surname>Vassiliadis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Pervasive Computing and Communications</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="439" to="460" />
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding</title>
		<author>
			<persName><forename type="first">Jiaxi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="565" to="573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude</title>
		<author>
			<persName><forename type="first">Tijmen</forename><surname>Tieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Lisa</forename><surname>Torrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jude</forename><surname>Shavlik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>Transfer Learning</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Hyperparameter Importance Across Datasets</title>
		<author>
			<persName><forename type="first">Jan</forename><forename type="middle">N</forename><surname>Van Rijn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2367" to="2376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A Meta-Learning Perspective on Cold-Start Recommendations for Items</title>
		<author>
			<persName><forename type="first">Manasi</forename><surname>Vartak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Thiagarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Conrado</forename><surname>Miranda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeshua</forename><surname>Bratman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6907" to="6917" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Matching Networks for One Shot Learning</title>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">DropoutNet: Addressing Cold Start in Recommender Systems</title>
		<author>
			<persName><forename type="first">Maksims</forename><surname>Volkovs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guang</forename><forename type="middle">Wei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomi</forename><surname>Poutanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4964" to="4973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning</title>
		<author>
			<persName><forename type="first">Ronald</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992">1992. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">One-Shot Relational Learning for Knowledge Graphs</title>
		<author>
			<persName><forename type="first">Wenhan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="1980">2018. 1980-1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A Graph-based Recommendation across Heterogeneous Domains</title>
		<author>
			<persName><forename type="first">Deqing</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingrui</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huazheng</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanghua</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="463" to="472" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
