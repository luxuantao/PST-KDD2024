<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Discriminative Learning for Minimum Error Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Biing-Hwang</forename><surname>Juang</surname></persName>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Shigeru</forename><surname>Katagiri</surname></persName>
						</author>
						<title level="a" type="main">Discriminative Learning for Minimum Error Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B5CB02B441DEA8BD8ADE4738BC36922F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T10:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recently, due to the advent of artificial neural networks and learning vector quantizers, there is a resurgent interest in reexamining the classical techniques of discriminant analysis to suit the new classifier structures. One of the particular problems of interest is minimum error classification in which the misclassification probability is to be minimized based on a given set of training samples. In this paper, we propose a new formulation for the minimum error classification problem, together with a fundamental technique for designing a classifier that approaches the objective of minimum classification error in a more direct manner than traditional methods. We contrast the new method to several traditional classifier designs in typical experiments to demonstrate the superiority of the new learning formulation. The method can be applied to other classifier structures as well. Experimental results pertaining to a speech recognition task are also provided to show the effectiveness of the new technique.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>ATTERN classification, particularly in the area of P linear discriminant analysis, is a very well-studied topic with most of the original developments completed in the 1960's (see [1]- <ref type="bibr" target="#b4">[5]</ref>). Recently, due to the advent of artificial neural networks (ANN) <ref type="bibr" target="#b5">[6]</ref> and learning vector quantizers (LVQ) <ref type="bibr" target="#b6">[7]</ref>, there is a resurgent interest in reexamining the classical techniques to suit the new classifier structures. In this paper, therefore, we address specifically the problem of minimum error classification, propose a fundamental technique for designing a classifier that achieves minimum classification error, and contrast it to popular classifier structures, such as the perceptron <ref type="bibr" target="#b7">[8]</ref>, so that the new classifiers can be better utilized.</p><p>Consider a set of observations C = {xl, x2, x3, * , xN } , where each xi is a K-dimensional vector and is known to belong to one of M classes Ci, i = 1, 2, * * , M. A classifier normally consists of a set of parameters and a decision rule. The task of minimum error classifier design is to find the classifier parameter set, denoted by A, and the accompanying decision rule, based on the given sample set C , such that the probability of misclassifying any x is minimized. Probability of misclassification is often empirically approximated by the recognition error rate, defined as the number of recognition errors incurred in classifying C , normalized by the size of C. When there is a penalty or cost associated with a misclassification, the objective is then to minimize the expected cost accordingly. Bayes decision theory [l] is a fundamental statistical approach to the classification problem and is often the basis of many pattern classification techniques. Suppose we have full knowledge of the a posteriori probability PA (C; Ix), which is defined by the parameter set A as denoted by the subscript. (Note that this assumption also implies that the true a posteriori probability can be parametrized by A). The Bayes decision rule</p><formula xml:id="formula_0">C(x) = C; if P A ( C j ( x ) = max PA(Cj(x) (1)</formula><p>where C(*) denotes a classification operation, is known to lead to minimum misclassification probability. The rule is often written in terms of the a priori and the conditional probabilities as j c(x) = c; ifpA(xICj)PA(Ci)</p><p>Since the exact probability measure is rarely known in real situations, the problem of optimal classifier design thus becomes that of estimating the a priori and the conditional probabilities, defined by the parameter set A, using the design samples C. This empirical approach has been widely followed in the past because the subject of distribution estimation is a well-treated topic in statistics.</p><p>The fundamental assumption in this approach is that the form of the distributions as functions of the parameter set A is known and that given a sufficient design sample set there is a good method to estimate correctly the unknown parameters A. An alternative to the Bayes decision approach is to use discriminant functions in lieu of the probabilities. This requires a set of discriminant functions, gi(x; A), i = 1, 2, * * . , M , defined by the parameter set A, instead of explicit knowledge of the probability distributions. Unlike the Bayes approach, the problem of "optimal" classifier design becomes that of finding the right parameter set for the discriminant functions to minimize the "sample risk" [l], which is defined as the average cost incurred in classifying the design sample C. The cost is usually defined on a pair of class indices (i, j ) where i and j are the correct class index and the identifiedkecognized class index, respectively, indicating the penalty in mis-1053-587X/92$3.00 0 1992 IEEE classifying a Ci class observation as a Cj class observation. Note that, as mentioned previously, the sample risk is not the expected cost (or cost expectation, see (24)) because the size of the design sample is usually finite; it can be considered an empirical estimate of the expected cost, however. While suboptimality may still occur because of improper choice of the discriminant functions, as in the case of incorrect distribution assumption in the Bayes approach, the discriminant function based method usually offers implementational simplicity [ 11 and with the advent of new classifier structure, it may be possible to circumvent the data consistency issue (see Section V). In this paper, we shall primarily focus on the design algorithms.</p><p>The difficulty associated with the discriminant approach lies in the derivation of a minimum-cost discriminant. A proper discriminant needs to be suitable for incorporation in an objective function for optimization. The sample risk, of which the number of classification errors is one of the simplest cases with a zero-one function as the misclassification cost [ 11, is obviously a piecewise constant function of the classifier parameter A and thus a poor candidate for optimization by a numerical search method. Traditionally, the discriminant based classifier design is formulated as an optimization problem aiming at minimization of some criterion functions that are analytically more tractable than the sample risk. Popular choices of these criterion functions include the perceptron criterion function and sum of squared errors (or minimum squared error (MSE)), for example. These criterion functions, as will be elaborated in Section 11, do not generally lead to a minimum error probability classifier, although one can vigorously discuss the convergence properties of the solution as obtained by numerical search algorithms.</p><p>In this paper, we propose a new way of deriving the discriminant such that the result of the optimization procedure will be controllably consistent with the minimum sample risk objective. The new discriminant makes proper use of the Lp norm and is a continuous function of the classifier parameters, suitable for gradient-type numerical search. We shall also propose a descent search algorithm for optimizing the minimum error objective. This combination of a new discriminant, directly related to the minimum error objective, and the descent algorithm would then allow us to circumvent the difficulties encountered in most of the traditional techniques and address the optimal classifier design problem in a straightforward manner. We shall further point out that the algorithm can be shown to produce asymptotically a solution consistent with the minimum error result, one important step beyond the minimum sample risk objective. However, the proof of this asymptotic result will be provided in a separate paper <ref type="bibr" target="#b8">[9]</ref> for clarity of presentation. In addition, we shall discuss how the new discriminant can be incorporated in new classifier structures, in particular, a multilayer perceptron, for an expanded application prospect.</p><p>The paper is organized as follows. In the next section, to provide a necessary analytical background, we sum-marize conventional criterion functions, particularly those related to linear discriminant, that have been extensively studied in the past. We then propose a new discriminant and formulate the minimum classification error problem in a manner suitable for optimization in Section 111. In Section IV, we present a gradient search algorithm for solving the optimization problem, generalize the algorithm so that expected cost minimization, rather than sample risk minimization, can be addressed, and further discuss optimality as well as consistency issues associated with the algorithm. We then suggest in Section V how the error back-propagation technique can be revised for multilayer perceptron (MLP) training in order to accomplish the minimum classification error objective. In Section VI, we compare experimentally the new discriminant and the cost functions with traditional criterion functions and the associated classifier solutions in typical pattern recognition tasks. We show in particular the effect of minimum classification error criterion in contrast to the usual minimum squared error (MSE) and perceptron criteria. These comparisons are helpful in gaining insights on how classifiers can be better constructed for minimum classification error performance. In Section VII, we report a speech recognition experiment in which perceptrons with nonlinearity are compared with the new discriminative learning technique in real applications. We finally conclude the paper in Section VIII.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">DISCRIMINANT FUNCTIONS</head><p>We provide a general analytic background in this section using linear discriminant functions for simplicity. A linear discriminant function of a K-dimensional feature vector x has the form w *x + wo where * denotes matrix transpose. The weight vector and the threshold, w and wo, respectively, are defined for each class, resulting in M discriminant functions and a parameter set A = { w l , wol , w2, wO2, --, wy, w O M } which constitute the classifier.</p><p>Each discriminant function can be written as Since the discriminant functions are linear, the decision boundaries are hyperplanes. The linear discriminant function of (3) can be generalized by augmenting the feature vector x with higher order nonlinear terms such that gi (x; A) becomes a polynomial in terms of the elements of x. However, this generalization does not change the basic structure of the discriminant function. We shall stay with the expression of (3) in the following without loss of generality.</p><p>The classifier parameters are to be determined based on a given sample set 6: of N observations. The correct class labeling/association for each observation in the set is as-</p><formula xml:id="formula_1">C(x) = Ci</formula><p>if g i ( x ; A) = max gj(x; A). j sumed to be known. If there exist a set of weight vectors and thresholds such that classification based on the above discriminant functions and the decision rule produces no error at all, the sample set is called linearly separable. Otherwise, it is linearly nonseparable. For the simplest two-category case, by recognizing that X*yi &lt; 0 is identical to X* ( -y i ) &gt; 0, we are equivalently seeking a vector X, normal to the separating plane, such that X*y; &gt; 0 for all i where y l = y i if xi E C 1 , and y / = -yi if xi E C,.</p><p>Linear separability thus means the existence of such a separating plane. Determination of the classifier parameters is usually formulated as a problem of minimizing some analytically tractable scalar criterion functions, instead of the sample risk, such that the linear inequalities h*y &gt; 0 can be readily solved by a gradient descent procedure. In the following, we summarize three essential criterion functions and discuss properties of the corresponding solutions as obtained by appropriate descent algorithms. Also, for brevity, we shall limit our discussion to two-category cases in this section. For multicategory considerations, Kesler's construction of the equivalent problem [4], of course, is advisable. Details can be found in [ 13.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. The Perceptron Criterion Function</head><p>The perceptron criterion function is defined as</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J,(X) = c (-X*y)</head><p>YEY where the summation is over the set 'y of observations that are misclassified by A. The function is proportional to the sum of the distances from the misclassified observations to the separating plane. Note that the gradient of .Ip is not continuous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Selective Squared Distance Criterion ceptron criterion and is defined as</head><p>The squared distance criterion is very similar to the per-</p><formula xml:id="formula_2">J,(X) = c (X*y)2 YEY or (X*y -b)' J p ) = ; c Y G Y '</formula><p>II Yll' <ref type="bibr" target="#b6">(7)</ref> where the summation is also over the set of misclassified observations. (For J ; of (7), 'y ' is the set of observations for which X*y 5 b.) This criterion function leads to a descent algorithm known as the relaxation rule [ 111.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. The Minimum Squared Error Criterion</head><p>Unlike the above two criterion functions which consider only the misclassified observations, the minimum squared error (MSE) criterion takes into account the entire design sample and is defined as</p><formula xml:id="formula_3">N J,(X) = (X*yi -bi)' (8) r = l</formula><p>where the margin bi is an arbitrarily specified vector with positive elements (and may be irrelevant to the observation index i ) . Many solution procedures are available for this well-studied criterion. In terms of classification, however, the solution depends on the choice of the margin vector b.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Properties of the Solution</head><p>Without making explicit all the related solution procedures, we shall attempt to discuss key properties of the solution to the optimization problem for the above three essential criterion functions. These properties are convergence, nonseparable behavior, and consistency with the minimum error objective.</p><p>It can be shown [ 11 that there exist gradient search procedures that converge to the right solution for the perceptron and the selective squared distance criterion functions when the design sample set is linearly separable. It is intuitively clear that the solution procedures for these criteria aim at correcting the errors, since the summation in ( <ref type="formula">5</ref>)-( <ref type="formula">7</ref>) is over misclassified observations. If the design sample set is linearly separable, a relentless search would reach an error-free solution. Note that the error free solution here is in reference to the design sample only, but not to an independent test data set. When the design sample set is not linearly separable, no vector can perfectly separate the design sample and these procedures can never stop, yielding only a sequence of weight parameters, any of which may or may not be a useful solution to the classification problem.</p><p>Minimization of the squared error criterion is a better understood problem and many well-known procedures will lead to a solution that minimizes Js, regardless of the linear separability of the design sample. The problem with the MSE procedures is that minimization of MSE does not necessarily lead to minimum classification error. Even if the design sample set is linearly separable, there is no guarantee that the solution corresponds to a separating plane for error-free classification, unless the margin vector b is carefully chosen. The celebrated Ho-Kashyap procedure [ 121 that includes adjustment rules for the margin vector b has been shown to be able to converge to a solution corresponding to a separating plane when the design sample set is linearly separable. For nonseparable cases, the inconsistency between the MSE solution and a minimum error classifier remains.</p><p>One interesting insight pertaining to the MSE solution is that with a fixed, properly chosen margin vector b, the discriminant approaches a minimum mean-squared-error approximation to the Bayes discriminant function go@) = P(CI(X) -P(C2lX) <ref type="bibr" target="#b8">(9)</ref> asymptotically as the number of design observations grows [l], <ref type="bibr" target="#b15">[13]</ref>. The quality of the approximation depends on the form of the generalized linear discriminant function which is a polynomial in the elements of the feature vector x. While this property has a certain theoretical appeal, the fact remains that the discriminant function of a prescribed form that best approximates the Bayes discriminant of (9) at a finite set of sample points does not necessarily minimize the misclassification rate or error probability. For multiclass cases where M &gt; 2, as will be pointed out shortly, there was a clear difficulty in defining a reasonable ''Bayes" discriminant that combines the a posteriori probabilities into a well-behaved function and thus the above approximation interpretation of the MSE solution is of little significance. Since our objective is to find a classifier that achieves minimum error probability, the inadequacy of these traditional methods and criterion functions thus becomes clear.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="111.">MINIMUM CLASSIFICATION ERROR DISCRIMINANT</head><p>The traditional discriminant formulation above can be stated in two steps: definition of the discriminant function and incorporation of the discriminant function in a scalar criterion suitable for a gradient-type search procedure to find a solution, if the procedure does converge. The inadequacy of this traditional formulation lies in the fact that the decision rule does not appear in a functional form in the overall criterion function for easy optimization and that there is an inconsistency between the chosen scalar criterion function and the desired minimum error probability objective. Here, we propose a new way of deriving the objective criterion for a discriminant based approach to mend the above shortcomings.</p><p>We use a three-step procedure to derive the objective criterion. As with the traditional approaches, the form of the discriminant functions gi(x; A) are first prescribed. The classifier makes its decision for each input x by choosing the largest of the discriminants evaluated on x. This decision process needs to be expressed in a functional form such that further optimization can be easily accomplished. We thus in the second step introduce a misclassification measure which allows us to embed the decision process in the overall minimum classification error formulation.</p><p>The simplest form of a misclassification measure appears to be the Bayes discriminant defined for the twocategory classification case:</p><formula xml:id="formula_4">d ( x ) = P(C2 1x1 -P(CI 1x1 (10)</formula><p>where P(Ci 1 ~) ' s are the a posteriori probabilities and are assumed to be known. Intuitively, this enumerates how likely a class 1 observation is misclassified as a class 2 observation and the optimal decision boundary is accomplished by a solution to the equation d ( x ) = 0. For multicategory cases (M &gt; 2) with unknown distributions, it is not as straightforward to define a misclassification measure as the above two-category Bayes discriminant. One proposal by Amari [14] is to define the misclassification measure by where S k = { i 1 gi (x; A) &gt; g k (x; A)}, the set of "confusing classes," and mk is the number of confusing classes in sk. This misclassification measure apparently is motivated by the Bayes discriminant of (10). However, since s k is not a fixed set, i.e., it varies with the parameter set A and x , the misclassification measure of (1 1) is discontinuous in A and is not differentiable. For gradient algorithms, this is not very desirable.</p><p>There are many ways to define a misclassification measure that is continuous with respect to the classifier parameters. One reasonable possibility is as follows:</p><formula xml:id="formula_5">1 / 9 d,(X) = -g k ( X ; A) + [ ~ 2 gj(x; A)'] (12) M -1 j , j + k</formula><p>where 7 is a positive number. (In most applications, g j ' s are assumed to be positive.) This misclassification measure resembles the measure of (11) in that the decision rule is being enumerated. The measure of (12), however, is continuous and offers a fair amount of flexibility. By varying the value of 7, one can take all the potential classes into consideration, to a various degree, in the search of the classifier parameter A. One extreme case is when 7 approaches 00, the misclassification measure becomes</p><formula xml:id="formula_6">(13)</formula><p>where Ci is the class with the largest discriminant value among those classes other than ck, because (Ml ) ' / = z 1 . Obviously in this case, dk (x) &gt; 0 implies misclassification and dk(x) I 0 means correct decision. In this way, the decision rule becomes a judgement on a scalar value.</p><p>To complete the definition of the objective criterion, the above misclassification measure is used in the third step where the minimum error objective is formulated. A general form of the cost function can be defined as </p><formula xml:id="formula_7">E &gt; 0.</formula><p>Both functions are smoothed zero-one cost functions suitable for gradient algorithms. Clearly, when dk(x) &lt; 0 which implies correct classification, virtually no cost is incurred. On the other hand, a positive dk(x) leads to a penalty which becomes essentially a count of classification error if a zero-one cost function or any of the above smoothed zero-one functions is used. Finally, for any unknown x, the classifier performance is measured by</p><formula xml:id="formula_8">M e(X; A) = c tk(x; A) 1 (X E ck) (<label>17</label></formula><formula xml:id="formula_9">) k = 1</formula><p>where 1( ) is an indicator function:</p><p>1, if a is true <ref type="bibr" target="#b20">(18)</ref> i 0, otherwise</p><formula xml:id="formula_10">l ( a ) =</formula><p>and c k is used to denote both the class and the data set.</p><p>This three-step definition emulates the classification operation and approximates the performance evaluation in terms of classification errors in a smooth functional form. To see how this formulation relates to the minimum classification error, let us assume the discriminant function is properly chosen to have the correct form as the true a posteriori probability p A (Ci Ix), where the subscript A denotes the fact that the probabilities are defined by the parameter set A. The Bayes minimum risk (minimum classification error) resulting from the maximum a posteriori (MAP) rule can be written as</p><formula xml:id="formula_11">M &amp; = c 1 ck) 1 (X E Ck)dX. (19) k = l</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Xn</head><p>The integration in ( <ref type="formula">19</ref>) is over part of the entire observation space 'X that causes classification error according to the MAP rule, i.e.,</p><formula xml:id="formula_12">' X k = {x E xlPA(Cklx) f maxPA(CjIx)}. (<label>20</label></formula><formula xml:id="formula_13">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1</head><p>The classification error can be rewritten as IV. DESCENT METHODS The cost function of ( <ref type="formula" target="#formula_8">17</ref>) is defined for each input pattern x i . This cost function is the basis of the objective that we shall optimize with descent methods. Given a set of labeled training patterns d: = { x l , x2, -* * , XN } , there are two ways of defining the performance objective; one is the empirical average cost and the other the expected cost. Although algorithmic difference between the two is minimal, optimization of these two conceptually different objectives leads to gradient search solutions with different convergence properties.</p><formula xml:id="formula_14">M = c j PA(x, ck) l ( x E ck) k = l 3c 1 [ P A (ck Ix) f max P A (ci Ix)l dX 1 M c P A (x, ck) 1 (x E ck) ek (dk(x)) h-(<label>2</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Empirical Average Cost and Gradient Descent Algorithm</head><p>xN } , we can define an empirical average cost as Given a set of design observations d: = { x l , x2, --,</p><formula xml:id="formula_15">l N &amp;(A) = -c ! k ( X i ; A)l(x; E ck). (<label>22</label></formula><formula xml:id="formula_16">) N i = l k = l</formula><p>This well-defined cost function can be conveniently minimized by a gradient descent algorithm, using the following adaptation rule:</p><formula xml:id="formula_17">1 1 , + 1 = 4 -EVLo(A,)<label>(23)</label></formula><p>where At denotes the parameter set at the tth iteration. The usual care and considerations associated with the gradient descent algorithm, e.g., the choice of e , of course apply here. Furthermore, the adaptation schedule can be defined arbitrarily. One extreme is that the classifier parameters are adjusted upon presentation of each training pattern x, E C, and the gradient is taken as Vfk (x,; A) as the indicator function in (22) dictates. Another extreme is to adjust the parameters after the entire training set d: is classified. In this case, the gradient in (23) becomes proportional to the average gradient according to (22). The latter case is expected to produce a much smoother learning curve than the former case. Other adaptation "schedules" that operate sequentially on subsets of the design sample 6: are obviously possible. Note that the minimization is only for the (approximate) classification cost incurred in classifying the design sample {xl, x2, ---, x N ) , although we can use empirical arguments to infer that &amp; is asymptotically the expected performance as N -+ 00. This point is one of the fundamental differences between the new method and the classical distribution estimation approach to pattern recognition, in that the asymptotic results are with regard to the classification error instead of the distribution estimates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Expected Cost and Probabilistic Descent Algorithm</head><p>The expected cost can be expressed as</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L(A) = E{e(x; A)) = k p ( c k ) j ek(x; A)P(xlck) dX (24)</head><p>where P(ck) and p (x 1 ck) are the class a priori and conditional probabilities, respectively. Obviously, the expectation operator in (24) indicates that the minimization is for the true expected error, not just the errors incurred for the finite design sample set d: . However, since both the a priori and conditional distributions are unknown, the expected cost cannot be directly minimized. Fortunately as suggested by the theorem below, we still can seek to minimize L by adaptively adjusting A in response to the incurred cost each time a training pattern x is presented. The adjustment of A is again according to (25)</p><p>where the "correction" term 6At is a function of the input pattern x, its class label Ci , and the current parameter state A,, i.e., 611, = SA(x, ck, A,). The magnitude of the correction term is small such that the first-order approximation</p><formula xml:id="formula_18">L(At+i) L(&amp;) + WVL(A)IA=A,<label>(26)</label></formula><p>holds. As will be shown below, this allows us to address</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E [ L ( A , + -L(A,)] = E[6L(A,)] directly rather than L(Af+l) -L(A,) = 6L(Af). Note that</head><formula xml:id="formula_19">A t + l = A, + &amp;Af E[6L (4)l = E[6A (x, ck, At)] V L (AI). (<label>27</label></formula><formula xml:id="formula_20">)</formula><p>Therefore, the goal is to find an adaptation rule such that E[6L(A,)] &lt; 0 and such that A, converges at least to a locally optimum solution A*. The probabilistic descent algorithm can be summarized in the following theorem Probabilistic Descent Theorem:</p><formula xml:id="formula_21">Given x E c k if the classifier parameter adjustment 6A(x, ck, A) is specified (28)</formula><p>where U is a positive-definite matrix and E is a smalkpositive real number, then </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>converges with probability one to a A* which results in a local minimum of L ( A ) .</head><p>As can be seen, the difference between the two adaptation rules (23) and (28) is minimal, but the probabilistic descent algorithms provides what can be considered the basis of adaptive learning in which as more data are presented, the classifier is further refined in the sense of reducing the expected misclassification cost. The empirical average cost and the associated gradient descent algo-rithm, on the other hand, are important for pragmatic reasons. For example, when the a posteriori probabilities are used in the discriminant function, and thus in the class cost function l?,, the expected cost of (24) becomes unwieldy for optimization because the expectation would also be a function of the classifier parameters, i.e., p ( x , ck) = p a @ , C,) in (24). This particular difficulty is avoided in the empirical average cost of (22).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. MINIMUM CLASSIFICATION ERROR MULTILAYER</head><p>FEEDFORWARD NETWORKS The above minimum classification error formulation can be applied to many new classifier structures such as the multilayer perceptron (MLP) <ref type="bibr" target="#b7">[8]</ref>, learning vector quantizer (LVQ) [7], and distance network <ref type="bibr">[16]</ref>. The formulation has a profound effect on these new classifier structures and leads to improved learning rules for a better pattern recognition performance. We discuss in this section how the new minimum classification error criterion can be incorporated in a multilayer perceptron. The relationship among these new classifiers under the common criterion of minimum misclassification probability will be addressed in a separate paper [ 171.</p><p>A multilayer perceptron is a feedforward network, as illustrated in Fig. <ref type="figure">1</ref> for a two-layer perceptron (or threelayer if the input layer is also counted as one), that has been widely considered in pattern recognition applications. Let m be the total number of layers, nj the number of nodes in the j th layer (n, = M) and zjj the activation output of the ith node in the j t h layer, with x * = (xl, x2, . . . , x K ) = ( z l o , z20, * * * , zKO) = z; being the input.</p><p>The activation output zi, is obtained according to</p><formula xml:id="formula_22">zjj = f(W$Zj-1 + WOij) (<label>33</label></formula><formula xml:id="formula_23">)</formula><p>where w: = (wljj, wZ0, . * is the weight vector connecting the nj -nodes in the ( j -1)th layer to the i th node in the j t h layer and f is the activation function, an example of which is the sigmoid function of (16). Without loss of generality, we shall neglect the bias term and denote yii = w:zj-I such that zjj = f( y j j ) . The set of weights W = { w0 } and the prescribed activation function thus define an MLP classifier.</p><p>To train an MLP classifier, one employs the error backpropagation (EBP) algorithm <ref type="bibr" target="#b7">[8]</ref> which is a supervised learning scheme based on a training vector x and its corresponding target (or teaching) vector t . The target vector t* = ( t l , t2, * , t M ) associated with a given training vector x E Ci for an M-class classification task typically is binary valued with , wn,-1,</p><formula xml:id="formula_24">j = i 0, otherwise. tj = [ (<label>34</label></formula><formula xml:id="formula_25">)</formula><p>The classifier is so trained as to reduce the difference be- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E = P;(d;(x))</head><p>(40</p><formula xml:id="formula_26">)</formula><p>where 4 is defined by ( <ref type="formula">14</ref>)-( <ref type="formula">16</ref>), di (x) is expressed in terms of y, as</p><formula xml:id="formula_27">di(x) = -Yim + [ ~-l . . . Y/?, ]'" (41)</formula><p>and 9 is a large positive number. The usual nonlinearity in the final layer is no longer strictly necessary. (In case yjm's need to maintain nonnegativeness, a supplementary nonlinearity such as efim can be used.) Without nonlinearity, the chain rule that led to the error back-propagation formula of (37)-(39) remain the same, i.e., </p><formula xml:id="formula_28">h, = 2(zU -t i ) f ' ( y U ) , f o r j = m (38) f o r j = 1, 2, * , m -1. (<label>39</label></formula><formula xml:id="formula_29">)</formula><p>It is important to note that use of a target vector as defined by (34), or variations thereof, is required for the formulation of a sum-squared error function for optimization by descent methods. It, however, does not necessarily lead to minimum classification error; that is, the solution W that minimizes E,,, or expectation of E,,, may not coincide with the solution that minimizes the misclassification probability, as argued previously. One way to make the error back-propagation algorithm consistent with the minimum classification error objective is to use the cost of (21) in lieu of E,,. In particular, following the above three-step formulation procedure, we propose, for according to the definition of di (x) in (4 1). Note that for large 9 ,</p><formula xml:id="formula_30">-1 fork # i. (45)</formula><p>Therefore, with a modification in the error criterion, a multilayer perceptron can be trained for minimum classification error.</p><p>An advantage with the modified multilayer perceptron is related to the consistency issue raised in the Introduction. In the distribution estimation approach to the classification problem, optimality of the solution cannot be addressed when the form of the data distribution is unknown and, as usually is the case, incorrectly assumed. Similarly, in the discriminant based approach, the choice of the discriminant function is crucial to the classifier performance, even though the optimization objective has been correctly defined as the minimum misclassification probability. It should be understood that our definition of minimum misclassification probability has two meanings: One that is conditioned on the prescribed choice of the discriminant function, g i , and the other that is the absolute minimum Bayes risk which occurs only when full knowledge of the a posteriori probabilities is correctly used in classification. These two meanings become identical when the approximation in (21) becomes exact, a case requiring that the loss function P(dk) approach the error counts, 1 (PA(Ck Ix) f maxiPA(Ci Ix)). Since a multilayer perceptron has been shown to be able to define an arbitrary real function [ 181, with a flexible architecture in terms of the number of hidden units, it thus offers the potential of automatically converging to the true minimum Bayes risk, particularly when the training objective is correctly chosen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CLASSIFICATION EXPERIMENT</head><p>Several classification experiments were conducted to study the characteristics of the minimum classification error criterion, and the difference in classification performances as compared to traditional criteria as well as classifier architectures. We report two sets of experimental results here: one involves a set of artificially generated data with mixture distributions and the other pertains to the Fisher's iris data, well known to the pattern recognition community.</p><p>The artificially generated data set consists of two classes. The distributions are of Gaussian mixture types with two components in each class. Each token is of two dimensions. For class 1, 700 tokens with mean (-5. 0.)' and covariance matrix and another 500 tokens with mean (1.0 0.0)' and covariance Fig. <ref type="figure">2</ref> shows a scatter plot of the 2000 training tokens generated for the two classes. Note that for the two-class case, the misclassification measure of (12) reduces to only two terms, a situation similar to Amari's formulation.</p><p>These training tokens (2000 in total) were used to train three linear classifiers (LC) with three different criterion functions: the perceptron criterion of ( 5 ) , the minimum squared error criterion of (8) and the minimum classification error of (12), (14), and (16). For brevity, we denote these criterion functions by PE (perceptron error), MSE (minimum squared error), and MCE (minimum classification error), respectively. We further generated an independent set of 2000 tokens according to the same distributions for testing purposes. The classification results in terms of the recognition error (averaged over four independent runs) for both the training set and the test set are listed in Table <ref type="table" target="#tab_1">I</ref> for comparison. We have run similar experiments on a number of artificially generated data sets with various distributions. The superior performance of LC + MCE was consistently observed in the experiments. The classification performances of LC + PE and LC + MSE, while being consistently inferior to that of LC + MCE, did not show a conclusive pattern in terms of the relative merit between the two. (In the table, the results pertaining to the independent test set are slightly better than that of the training set. This can be attributed to the fact that the training data and the test data are generated according to the same, simple distributions, ensuring data consistency.) It is probably more important to examine how the error (or loss) function is minimized in relation to the classification error rate in the present, well-controlled case than a simple comparison on the final classification performance. We plot in Figs. <ref type="figure" target="#fig_0">3(a)-(c</ref>) the learning (error minimization) curves of the four experiment runs for the three error criteria respectively. These curves were obtained for the training data but the curves for the test data are essentially the same. In each figure, we show two sets of plots: the upper part displays the criterion function as it is being minimized in terms of data epochs (an epoch represents a completion of processing on the entire training data set) and the lower part is the recognition rate evaluated at each training epoch. Of particular significance is Fig. <ref type="figure" target="#fig_0">3(c</ref>) for Anderson on 150 samples of three species of iris. The four measurements are the calyx length, the calyx width, the petal length and the petal width. Fifty tokens are available for each of the three species. The task is to classify these measured tokens into the three individual species. (This three-class problem thus has an increased sophistication in the misclassification measure, compared to the above two-class problem.) Fisher used the data in his classic paper on discriminant analysis [ 101. Many clustering experiments were studied in the past using this data set. In our current experiment, all the tokens were used for training the classifiers and the classification results in the following are restricted to the training data. This thus allows us to compare different error criteria in a well-defined classifier setup. (This is a scenario where one is interested in classi$cation of the given data rather than recognition of future data.)</p><p>We investigated two types of classifiers for the classification task. One, similar to the above mixture data case, is a linear classifier according to (3) with the corresponding decision rule of (4). The other is a three-layer perceptron according to (33). For the linear classifier case, we again investigated the three error criterion functions, PE, MSE, and MCE.</p><p>The three-layer perceptron structure requires further explanation as it involves nonlinearity. The sum-squared error function of (35) with nonlinearity at the output layer is the prevalent choice in most of the traditional MLP classifiers. The minimum classification error criterion as defined in (40) and (41) does not require a nonlinearity at the output. These two criteria can thus be directly compared based on the same feedforward structure. To provide additional insights, we also implemented a three-layer perceptron using the sum-squared error function but without the nonlinearity at the output layer. Since the error back-propagation algorithm is also to minimize the sum-   To account for the intrinsic characteristics of stochastic training, we performed four runs of classification experiments for each classifier training, using different orders of training data presentation. Fig. <ref type="figure">4</ref> shows the four learning curves in terms of the classification error rate for the LC + MCE case. The learning behavior for the MCE criterion is seen to be quite steady and effective. The average classification error rate is 4 % (i.e., 96% correct) when MCE was used as the criterion. Table <ref type="table" target="#tab_2">I1</ref> lists the average error rates of the four runs for the three linear classifier cases, PE, MSE, and MCE, respectively for performance comparison. Obviously, the MCE criterion led to a performance far better than the other two criterion functions.</p><p>With three-layer feedforward networks or MLP's, the classification performance in general improves. The only exception is the case of 3PNET + MSE without a nonlinearity at the output layer. We list again the average error rates of the four experiment runs in Table <ref type="table" target="#tab_2">I11</ref> for the three 3PNET cases, MSE, MSE + N and MCE, respectively, for comparison. The multiple layer structure and the nonlinearity indeed led to performance improvements over the linear classifier case. The three-layer network trained by the MCE criterion gave again the best result of 2.2% error rate. The performance advantage of MCE is clearly seen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. SPEECH RECOGNITION EXPERIMENTS</head><p>Another set of experiments were conducted to examine the characteristic differences between the traditional minimum sum-squared error and the minimum classification error when applied to a layered perceptron structure for speech recognition. The experiments involved recognition of the highly confusible English i.E-set alphabet, namely, b, c, d, e, g, p, t, v, and z. The speech signal was recorded from 100 native Americans, including 50 male and 50 female, through local dial-up telephone lines. The sampling rate was 6.67 kHz and the bandwidth of the antialiasing filter was from 100 to 3200 Hz for a digital implementation of analysis processing. Each talker spoke each word twice, producing two sets of data bases. One was used as the training set and the other as the test set. (Other parameters include: a 300-sample analysis window, a 200-sample overlap between adjacent analysis windows, an eighth-order linear prediction analysis and a 24 cepstral coefficient (cepstrum and delta cepstrum) representation [ 191, <ref type="bibr" target="#b22">[20]</ref> .)</p><p>To normalize the speaking rate variation inherent in the spoken utterances, a conventional speech recognizer with dynamic time warping (DTW) was used as the baseline classifier. Fig. <ref type="figure">5</ref> shows a block diagram of the conventional DTW recognizer. The unknown input utterance is first analyzed and then matched to each of the reference templates, resulting in sequences of spectral distortions. Let us denote these distortion sequences by DJ = { d J ( i ) , i = 1 , 2 , * . . , m,} wherej is the template index and mJ is the length of t h e j t h template. Each vocabulary word may be represented by a multiplicity of reference templates although in this paper we report only the simplest case where we use one reference template for each word.</p><p>These distortion sequences { D J } ,</p><formula xml:id="formula_31">j = 1, 2,</formula><p>, M (M = 9 in the present case), are thus the input to the classifier to be designed. Note that the total dimension of the input is MT = C J = l m J .</p><p>Traditionally, the classification decision is made based on a simple average distortion</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M</head><p>The recognized word k is the one that satisfies Yk = min y j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I s j s M (47)</head><p>A more general discriminant function of the distortion sequences is thus m 8 y j = ;gl W j j d j ( i ) + WJO.</p><p>As in most linear discriminant cases, the function of (48) can be implemented in a particular perceptron structure as shown in Fig. <ref type="figure">6</ref>. An expanded architecture of the scaled perceptron of Fig. <ref type="figure">6</ref> is of course the original, unscaled, fully connected perceptron, taking the entire set of distortion sequences { D j } as the input. The output value before nonlinearity operation in this case is are of different dimensions and thus the classical vector space approach to classifier design may not be directly applicable. This particular problem is addressed in [ 151. In this paper, we present a new formulation of the pattern recognition problem, aiming at achieving a minimum error rate classification. The classical discriminant analysis methodology is blended with the classification rule (traditionally expressed in an operational form) in a new functional form and is used as the design objective criterion to be optimized by numerical search algorithms. The new formulation results in a smooth error function which approximates the empirical error rate for the design sample set arbitrarily closely. We have applied the minimum error formulation to several recognition tasks and demonstrated the advantages of the new method. The minimum classification error formulation can also be incorporated in new classifier structures such as the multi-layer perceptron. We further suggest how the error back-propagation algorithm can work with the new error criterion and achieve the minimum error result. In a speech recognition experiment involving the English E-set vocabulary, it was demonstrated that the new minimum error method achieves the best recognition performance. The proposed learning method and formulation provides a solid analytical ground for the long-standing minimum error classifier design problem. Note that the error back-propagation algorithm for training works the same way in the scaled perceptron and the fully connected network. The only difference is that the broken connections in the -scaled perceptron represent a constant zero weight in the fully connected network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. SUMMARY</head><p>The recognition rates (% correct) pertaining to these various methods are summarized in Fig. <ref type="figure">7</ref> with reference to the traditional simple uniform weighting method (46). The traditional method yielded a result of 59.8% accuracy rate which was improved to 62.7% and 63.9% by the scaled perceptron and the fully connected perceptron with the sum-squared error criterion, respectively. The minimum classification error criterion, optimized by the gen-</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>( 3 )</head><label>3</label><figDesc>where A,*, = [w: , woi] and y * = [x* 11. The classifier uses the following decision rule:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>dk(x) = -gk(x; A) + gi(x; A)which is expressed as a function of the misclassification measure. (The formulation of (14) was also introduced by Amari [14].) Note that the cost function e, and the misclassification measure dk can be defined individually for each class k for generality. For minimum error classification, the following cost functions are merely two of several possibilities: a) Exponential [14]: where c &gt; 0 and + 0; b) Translated sigmoid:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>CcThe approximation in (21) can be made arbitrarily close by varying the values of 11 and { or 5 . Note that even if the discriminant function differs from the true a posteriori probability, &amp; of (21) still represents the classification error criterion conditioned on the choice of g, suitable for minimization via descent algorithms. The advantage of the formulation is immediately clear when the solution procedure employs gradient-type descent methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>an infinite sequence of random observations xt are presented for training and the parameter adjustment rule of (28) is utilized with a corresponding step size sequence E , which satisfies sequence A, according to A t + , = AI + sA(xf, ck, Ai)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Fig. 1. A three-layer perceptron.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>azim-l,,,-l ayim-I,m-l a ~i , + z , j + 2 aYi,, i , j + I azij c -.--i, I = 1 az,+ + I azij aWkU (42)where the recursion of Ci(ayi,j+ ,/az,) (&amp;,,/ayij) f o r j = M -1, M -2, * is obvious as in (39). The only difference is in the first derivative of E with respect to Zkm. Specifically, is often chosen as the cost function for optimization.The error back-propagation algorithm is a gradient de-(43) scent algorithm that adjusts the weights to minimize E,, = 2 ad. (or Cb: E,,) according to aykm aykm W"+ ') = W'" -pVwE,, I w= W w (36) and k = i weight values are recordedladjusted. More specifically, where superscript T indicates the time instance when the the adjustment for w g , A w g , is adi -I + 1/11 , k # i , phi$,, j -I (37) AwQ = -p -8 4 , = -aWkij (44) where p is a positive number,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>:::). and 300 tokens with mean (0. O.)* and covariance were generated. Similarly, for class 2, we generated 500 tokens with mean (1 .O 5 .O)' and covariance</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>4 XFig. 2 .</head><label>42</label><figDesc>Fig. 2. A scatter plot of 2000 two-dimensional tokens generated by twocomponent mixture distribution sources; class 1 with mean ( -5 0)', covariance ( o.o ,o), mixture weight 0.7 and mean (0 O)', covariance 1.0 0.0 (::: :::1), mixture weight 0.3; class 2 with mean (1.0 5.0)', covari-0.1 0.0 ance (o,o</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 3 .EPOCHFig. 4 .</head><label>34</label><figDesc>Fig. 4. Learning curves in terms of the classification error rate as a function of training epochs for a linear classifier based on the minimum classification error criterion designed for the iris data set. (Four runs.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>MT ( 49 )</head><label>49</label><figDesc>where ( d ( i ) } , with index i = 1 to M T , is the concatenated distortion sequence of ioj}, j = 1, 2, , M .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 5 .Y2Fig. 6 .Fig. 7 .</head><label>567</label><figDesc>Fig. 5. A block diagram of the conventional dynamic time warping based speech recognition system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>terion, (40)-(45). The nonlinearity in each node is identically the sigmoid function 1/(1 + C y ) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I CLASSIFICATION PERFORMANCE COMPARISON FOR 3 LINEAR CLASSIFIER DISTRIBUTION DATA DESIGN CRITERIA USING 2-CLASS 2-COMPONENT MIXTURE Recognition</head><label>I</label><figDesc></figDesc><table><row><cell>Error</cell><cell>LC + PE</cell><cell>LC + MSE</cell><cell>LC + MCE</cell></row><row><cell>(%)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Training set</cell><cell>12.24</cell><cell>15.25</cell><cell>10.00</cell></row><row><cell>Test set</cell><cell>11.18</cell><cell>14.91</cell><cell>9.85</cell></row><row><cell cols="4">the MCE case. It is clearly seen that the minimized error</cell></row><row><cell cols="4">criterion closely approximates the actual classification er-</cell></row><row><cell cols="4">ror rate, thus accomplishing the original objective of min-</cell></row><row><cell cols="4">imizing the classification error. This phenomenon is not</cell></row><row><cell cols="4">observed in either the PE case or the MSE case. For ex-</cell></row><row><cell cols="4">ample, in Fig. 3(a), the perceptron error is fluctuating near</cell></row><row><cell cols="4">0 while the classification rate is varying around 80%.</cell></row><row><cell cols="4">The other set of experiments involves Fisher's iris data.</cell></row><row><cell cols="4">The iris data consists of four measurements made by E.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I1 CLASSIFICATION</head><label>I1</label><figDesc></figDesc><table><row><cell></cell><cell cols="3">PERFORMANCE COMPARISON FOR 3 LINEAR CLASSIFIER</cell></row><row><cell></cell><cell cols="2">DESIGN CRITERIA USING FISHER'S IRIS DATA</cell><cell></cell></row><row><cell></cell><cell>LC + PE</cell><cell>LC + MSE</cell><cell>LC + MCE</cell></row><row><cell>Classification</cell><cell></cell><cell></cell><cell></cell></row><row><cell>error</cell><cell>14</cell><cell>15.1</cell><cell>4</cell></row><row><cell>(%)</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 111 CLASSIFICATION PERFORMANCE COMPARISON FOR 3 FEEDFORWARD NETWORK CLASSIFIER DESIGN CRITERIA USING FISHER'S IRIS DATA</head><label>111</label><figDesc></figDesc><table><row><cell></cell><cell>3PNET + MSE</cell><cell>3PNET + MSE + N</cell><cell>3PNET + MCE</cell></row><row><cell>Classification</cell><cell></cell><cell></cell><cell></cell></row><row><cell>error</cell><cell>19.8</cell><cell>12.3</cell><cell>2.2</cell></row><row><cell>(%)</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank P. C. Chang of Telecommunication Laboratories, Taiwan, for conducting the speech recognition experiment reported in Section VII. The weight functions in these perceptron structures can be trained, as explained in the previous sections, by the error back-propagation algorithm <ref type="bibr" target="#b7">[8]</ref> with the usual sumsquared error criterion (37)-(39), or by the generalized descent algorithm with a minimum classification error cri-</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Biing-Hwang Juang (S'79-M'8O-SM'87-F'92) received the B.Sc. degree in electrical engineering from National Taiwan University, Taipei, in 1973 and the M.Sc. and Ph.D. degrees in electrical and computer engineering from the University of California, Santa Barbara, in 1979 and 1981, respectively.</p><p>In </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">0</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<title level="m">Pattern Classifcarion and Scene Andysis</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Linear decision functions with application to pattern recognition</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Highleyman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IRE</title>
		<meeting>IRE</meeting>
		<imprint>
			<date type="published" when="1962-06">June 1962</date>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="1501" to="1514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The perceptron-a perceiving and recognizing automation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Rosenblatt</surname></persName>
		</author>
		<idno>Rep. 85-460-1</idno>
	</analytic>
	<monogr>
		<title level="j">Cornell Aeronautical Lab</title>
		<imprint>
			<date type="published" when="1957-01">Jan. 1957</date>
			<pubPlace>Ithaca, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Nilsson</surname></persName>
		</author>
		<title level="m">Learning Machines: Foundations of Trainable Pattern-Classifying Systems</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Self-organizing systems-a review and commentary</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Hawkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IRE</title>
		<meeting>IRE</meeting>
		<imprint>
			<date type="published" when="1961-01">Jan. 1961</date>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="31" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An introduction to computing with neural nets</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Lippmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEEASSP Mag</title>
		<imprint>
			<biblScope unit="page" from="4" to="22" />
			<date type="published" when="1987-04">Apr. 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Statistical pattern recognition with neural networks: Benchmarking studies</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kohonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Barna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chrisley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Proc</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning internal representation by error propagation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Distributed Processing</title>
		<editor>
			<persName><forename type="first">Rumelhart</forename><surname>Mcclelland</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Adaptive discriminative learning in pat</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Juang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1965">1965</date>
			<publisher>McGraw-Hill</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName><surname>Icnn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988-07">July 1988</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="61" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I T</forename><surname>Press</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="318" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">eralized descent algorithm, achieved a recognition rate of Besides demonstrating the effectiveness of the minimum classification error formulation, the above experipertains to the classifier design problem where the inputs tern recognition</title>
		<imprint/>
	</monogr>
	<note>in preparation</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The use of multiple measurements in taxonomic prob-[I 11 S . Agmon</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Fisher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1954">1954</date>
			<biblScope unit="page" from="382" to="392" />
			<pubPlace>Cana-6, PP</pubPlace>
		</imprint>
	</monogr>
	<note>The relaxation method for linear inequalities</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An algorithm for linear inequalities and its applications</title>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Kashyap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Elec. Cornput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">* merit is Of interest from a very specific point Of This 683-688</title>
	</analytic>
	<monogr>
		<title level="j">Ann. Eugenics, part</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="179" to="188" />
			<date type="published" when="1936-10">1936. Oct. 1965</date>
		</imprint>
	</monogr>
	<note>the highest among all the competing methods. lems</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An adaptive pattern classification system</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">F</forename><surname>Womack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Sysr., Sri., Cybern</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="62" to="67" />
			<date type="published" when="1966-08">Aug. 1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A theory of adaptive pattern classifiers</title>
		<author>
			<persName><forename type="first">S</forename><surname>Amari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Elec. Compur</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="299" to="307" />
			<date type="published" when="1967-06">June 1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">New discriminative training algorithm based on the generalized probabilistic descent method</title>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Juang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1991 IEEE Workshop Neural Networks for Signal Processing</title>
		<meeting>1991 IEEE Workshop Neural Networks for Signal essing<address><addrLine>Piscataway, NJ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991-08">Aug. 1991</date>
			<biblScope unit="page" from="299" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Systematic explanation of learning vector quantization and multilayer perceptron-proposition of distance network</title>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
		<idno>MBE 88-72</idno>
		<imprint>
			<date type="published" when="1988-10">Oct. 1988</date>
			<publisher>IEICE</publisher>
		</imprint>
	</monogr>
	<note>in Japanese</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Discriminative multilayer feedfonvard networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Juang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1991 IEEE Workshop Neural Networks for Signal Processing</title>
		<meeting>1991 IEEE Workshop Neural Networks for Signal essing<address><addrLine>Piscataway, NJ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991-08">Aug. 1991</date>
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On the approximate realization of continuous mapping by neural networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Funahashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="183" to="192" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On the use of bandpass liftering in speech recognition</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Juang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Rabiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Wilpon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust., Speech, Signal Processing</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="947" to="954" />
			<date type="published" when="1987-07">July 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On the use of instantaneous and transitional spectral information in speaker recognition</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">K</forename><surname>Soong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Rosenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust., Speech, Signal Processing</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="871" to="879" />
			<date type="published" when="1988-06">June 1988</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
