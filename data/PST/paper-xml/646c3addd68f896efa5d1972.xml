<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Coarse-to-Fine: a Hierarchical Diffusion Model for Molecule Generation in 3D</title>
				<funder ref="#_ArsBPvm">
					<orgName type="full">National Key R&amp;D Program of China</orgName>
				</funder>
				<funder ref="#_TmvVp2W">
					<orgName type="full">Tsinghua University</orgName>
				</funder>
				<funder ref="#_dkNpjF2">
					<orgName type="full">Vanke Special Fund for Public Health and Health Discipline Development, and Beijing Academy of Artificial Intelligence</orgName>
					<orgName type="abbreviated">BAAI</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Bo</forename><surname>Qiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Pharmaceutical Science</orgName>
								<address>
									<country>Peking University</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuxuan</forename><surname>Song</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute for AI Industry Research (AIR)</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Minkai</forename><surname>Xu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jingjing</forename><surname>Gong</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute for AI Industry Research (AIR)</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bowen</forename><surname>Gao</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute for AI Industry Research (AIR)</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hao</forename><surname>Zhou</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute for AI Industry Research (AIR)</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Weiying</forename><surname>Ma</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute for AI Industry Research (AIR)</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
							<email>&lt;lanyanyan@tsinghua.edu.cn&gt;.</email>
							<affiliation key="aff1">
								<orgName type="department">Institute for AI Industry Research (AIR)</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Coarse-to-Fine: a Hierarchical Diffusion Model for Molecule Generation in 3D</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Generating desirable molecular structures in 3D is a fundamental problem for drug discovery. Despite the considerable progress we have achieved, existing methods usually generate molecules in atom resolution and ignore intrinsic local structures such as rings, which leads to poor quality in generated structures, especially when generating large molecules. Fragment-based molecule generation is a promising strategy, however, it is nontrivial to be adapted for 3D non-autoregressive generations because of the combinational optimization problems. In this paper, we utilize a coarse-to-fine strategy to tackle this problem, in which a Hierarchical Diffusion-based model (i.e. HierDiff) is proposed to preserve the validity of local segments without relying on autoregressive modeling. Specifically, HierDiff first generates coarse-grained molecule geometries via an equivariant diffusion process, where each coarse-grained node reflects a fragment in a molecule. Then the coarse-grained nodes are decoded into fine-grained fragments by a messagepassing process and a newly designed iterative refined sampling module. Lastly, the fine-grained fragments are then assembled to derive a complete atomic molecular structure. Extensive experiments demonstrate that HierDiff consistently improves the quality of molecule generation over existing methods 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>tures, ranging from generating molecular atom-bond graphs <ref type="bibr">(Li et al., 2018a;</ref><ref type="bibr" target="#b31">Liu et al., 2018;</ref><ref type="bibr">Jin et al., 2018a)</ref> to generating molecular conformations from graphs <ref type="bibr" target="#b56">(Xu et al., 2022;</ref><ref type="bibr" target="#b21">Jing et al., 2022)</ref>. Despite the significant progress achieved, a remaining but vital research direction in this track is de novo design of drug molecules in 3D space. Integrating the 3D information into the molecule design process enjoys several advantages over only involving topological information in many important applications, e.g., structurebased drug design <ref type="bibr">(Zhang et al., 2023;</ref><ref type="bibr" target="#b36">Peng et al., 2022;</ref><ref type="bibr" target="#b32">Luo et al., 2021)</ref>, molecular dynamic simulation <ref type="bibr" target="#b12">(Hansson et al., 2002)</ref>, 3D similarity searching <ref type="bibr" target="#b45">(Shin et al., 2015)</ref>. Some early studies on 3D molecule generation usually adopt an autoregressive approach <ref type="bibr" target="#b11">(Gebauer et al., 2019;</ref><ref type="bibr" target="#b32">Luo et al., 2021;</ref><ref type="bibr" target="#b30">Li et al., 2021)</ref>, which introduces an artificial order on the atoms and generates the atoms one by one in a language generation way. However, molecules have a natural geometric structure in 3D. Besides, these models suffer from the scale and error accumulation problem <ref type="bibr" target="#b39">(Roney et al., 2022;</ref><ref type="bibr" target="#b33">Luo &amp; Ji, 2022)</ref>. To tackle these problems, nonautoregressive models have been introduced in this area and gain impressive results. For example, inspired by the successful diffusion model in text and image generation, <ref type="bibr" target="#b16">Hoogeboom et al. (2022)</ref> proposed the first diffusion model for molecule generation and significantly improves the validity of generated molecules.</p><p>Nevertheless, the atom-level generation manner in these works, though enjoys higher flexibility to place each atom, lacks the necessary constraints to obtain reliable molecule structures, especially when generating large molecules. As shown in Figure <ref type="figure" target="#fig_0">1</ref>, without imposing Euclidean geometric constraints on the modeling process, the generated 3D aromatic rings could seriously violate basic chemical rules. In this paper, we propose a coarse-to-fine approach to tackle the above problems. The basic idea is that we first generate the coarse-grained structure of the molecule, where each node represents a cluster of fragments, and then the coarsegrained structure is decoded into fine-grained fragments to assemble atomic molecule structure. In this way, valid local structures will be preserved by replacing the computation unit from atoms with fragments. However, such a process is non-trivial since generated neighborhood fragments may suffer from atom-bonds conflicts, preventing them to be connected.</p><p>To tackle the problem, we treat 3D molecule generation as a constraint generation problem and propose a novel Hierarchical Diffusion-based model (HierDiff). In the coarsegrained phase, our method generates the fragment representation instead of deterministic fragment. Specifically, we introduce two different ways to obtain chemically interpretable features for representing fragments. Then we propose a geometric diffusion model to generate these fragment representations and their Cartesian coordinates in an efficient non-autoregressive manner. In the fine-grained phase, we utilize an equivariant message-passing network to guarantee connectivity and an iterative refinement module to correct the bias. At last, we construct atom-level 3D structure based on the decoded 3D fragment graph.</p><p>The proposed coarse-to-fine approach nicely mimics the chemistry expert's drug design process by combining fragments from a pre-defined functional group database. In this way, important inductive biases in this area are encoded in our model.Furthermore, from machine learning's perspective, the fragment-based representation of molecules significantly reduces unnecessary degrees of freedom in the atom-based methods, thus will lead to global optimum convergence and better generalization ability.</p><p>Extensive experiments are conducted to test our model on the challenging task of generating drug-size molecules. Compared to the baseline model, HierDiff can generate both realistic molecules with better drug-like properties and conformations that are much closer to the ground truth conformations. Visualized results also demonstrate HierDiff is capable of generating high-quality molecules with more stable substructures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Molecule generation is one of the fundamental problems in drug discovery. In earlier works, molecule generation tasks are tackled by generating sequential representations of molecules, i.e. SMILES e.g. <ref type="bibr" target="#b24">(Kusner et al., 2017;</ref><ref type="bibr" target="#b5">Dai et al., 2018;</ref><ref type="bibr" target="#b44">Segler et al., 2018)</ref>. With the development of graph neural networks, researchers begin to utilize the graph-based generative model to generate molecular topological structures and gain great progress <ref type="bibr" target="#b18">(Jin et al., 2018b;</ref><ref type="bibr">a;</ref><ref type="bibr">Li et al., 2018b)</ref> However, neither sequence nor graph-based models capture the 3D geometric information, which is crucial for various molecule applications, such as molecule property prediction and protein-ligand docking. Recently, 3D molecule generation has become an emerging hot topic in this area, and different deep generative models have been proposed to tackle this problem. For example, Gschnet <ref type="bibr" target="#b11">(Gebauer et al., 2019)</ref> employs an autoregressive process equipped with Schnet <ref type="bibr" target="#b43">(Sch?tt et al., 2017)</ref> to sample atoms and bonds iteratively. G-spherenet <ref type="bibr" target="#b33">(Luo &amp; Ji, 2022)</ref> applied discrete flows to autoregressively generate invariant geometric features. EnFlow <ref type="bibr" target="#b41">(Satorras et al., 2022)</ref> utilizes continuous time normalizing flows to sample valid molecules. EDM <ref type="bibr" target="#b16">(Hoogeboom et al., 2022)</ref> is the first to apply the powerful diffusion model to this area and gains further improvements. However, EDM always generates unrealistic ring systems and broken molecules, when training on large molecules.</p><p>A related branch of molecule generation is hierarchical graph generation. Most previous works derive the hierarchical structure based on some intrinsic rules. For example, some work uses different granularity levels, such as atommotif <ref type="bibr" target="#b20">(Jin et al., 2020;</ref><ref type="bibr" target="#b42">2019)</ref>, or node-edge <ref type="bibr" target="#b53">(Xianduo et al., 2022)</ref>, to construct different hierarchies. <ref type="bibr" target="#b60">(Zhou et al., 2019)</ref> and <ref type="bibr" target="#b4">(Chauhan et al., 2019)</ref> use predefined rules to distinguish different nodes to different levels. <ref type="bibr" target="#b34">(Mi et al., 2021)</ref> employs the natural graphical topology to define the hierarchy. <ref type="bibr">(Geng et al., 2023)</ref> collects connection information to form a hierarchical structure. <ref type="bibr" target="#b25">(Kuznetsov &amp; Polykovskiy, 2021)</ref> obtain the hierarchy by adding latent variables to different layers of the model. While in our method, we use the learnable decoding module to approximate a semanticguided hierarchy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Backgrounds</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Denoising Diffusion Probabilistic Model</head><p>Denoising diffusion probabilistic model (DDPM) <ref type="bibr">(Yang et al., 2022b;</ref><ref type="bibr" target="#b47">Sohl-Dickstein et al., 2015)</ref> provides a powerful generative modeling tool by reversing a diffusion process. More specifically, the diffusion process projects the noise into the ground truth data and the generative process learns to reverse the process. The two processes imply a latent variable model, where x 1 , ? ? ? , x t-1 are the latent variables. The forward process could be seen as a fixed approximate posterior distribution:</p><formula xml:id="formula_0">q ( x 1:T |x 0 ) = T t=1 q(x t |x t-1 ) q (x t | x t-1 ) = N x t ; 1 -? t x t-1 , ? t I (1)</formula><p>Here ? 1 , ? ? ? , ? T corresponds to a fixed variance schedule. For simplicity, we let ? t = 1 -? t and ?t = t i=1 ? i , the</p><formula xml:id="formula_1">O C C N C HN NH N O N O N O N O N O C C C C N O Conflict Free One-hop Conflict Two-hop Conflict (a) Conflict Free O C C N C HN NH N O N O N O N O N O C C C C N O Conflict Free One-hop Conflict Two-hop Conflict (b) One-hop O C C N C HN NH N O N O N O N O N O C C C C N O Conflict Free One-hop Conflict Two-hop Conflict (c) Two-hop Figure 2</formula><p>. An illustration of fragment conflicts. One-hop conflict means the two linked fragments do not share any elements to form a valid edge. Two-hop conflict represents that though linked fragments can form edges by sharing the same atom/bond, conflicts occur when the valence is violated forward pass for arbitrary time step has an analytic form, i.e., q</p><formula xml:id="formula_2">(x t | x 0 ) = N (x t ; ? ?t x 0 , (1 -?t ) I).</formula><p>The generative process parameterized the transition kernel P ? (x t-1 |x t ) of the Markov chains, the corresponding likelihood function could be derived as:</p><formula xml:id="formula_3">P ? (x t-1 | x t ) = N x t-1 ; ? ? (x t , t) , ? 2 t I P ? (x 0 ) = p (x T ) P ? (x 0:T -1 | x T ) dx 1:T (2)</formula><p>Here the ? ? refers to parameterized means function and the ? 2 t is the predefined variance. For the initial distribution P ? (x T ), we select invariant base distribution for equivariant coordinates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Equivariance and SE(3)-invariant Density Estimation</head><p>Equivariance widely exists in the physical world, especially in atomic systems. For example, the vector fields of atomic forces should rotate or translate correspondingly with the 3D positions of the molecule. Thus integrating such inductive bias into the function modeling has appealing properties and has been widely explored <ref type="bibr" target="#b52">(Wu et al., 2018;</ref><ref type="bibr" target="#b43">Sch?tt et al., 2017;</ref><ref type="bibr" target="#b40">Satorras et al., 2021)</ref>. More specifically, given two transformation T g and S g acting on the space X and Y, a function f is considered as equivariant with respect to the group G if the following is satisfied:</p><formula xml:id="formula_4">f ? T g (x) = S g ? f (x)</formula><p>(3) In this task, we mainly focus on the SE(3) group, i.e., the group of rotation and translation in the 3D space. For generative modeling of 3D molecule graph, the density function of the model distribution P ? (.) should be SE(3)-invariant, i.e., P ? (x) = P ? (T g (x)). To this end, previous methods either directly model the invariant components, e.g., bond angles, or use some invariant base distribution and model the transformation by the equivariant neural network <ref type="bibr" target="#b21">(Jing et al., 2022;</ref><ref type="bibr" target="#b41">Satorras et al., 2022)</ref>. HierDiff extends the latter one to an equivariant hierarchical framework to model fragment coordinates and fit bond lengths to predefined rules, which will be discussed in Sec. 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Coarse-to-Fine Approach</head><p>In this section, we introduce our coarse-to-fine approach, including problem formulation and coarse-to-fine definition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Problem Formulation and Notations</head><p>Let G be the space of 3D graphs, where each 3D graph G consists of the fragment set V and the edge set E. More specifically, every fragment V ? V represents a combination of several atoms and bonds, e.g., a benzene ring could be a fragment that includes six carbon atoms and aromatic bonds. Instead of using edges to represent chemical bonds as in previous works, we use edge E ij ? E to indicate that there is a bond/atom shared by two fragments V i and V j . This kind of definition enables us to model molecule geometry using tangent condition on fragment sphere, as Fig. <ref type="figure">5</ref>, with a reasonable size fragment vocabulary. Therefore, the target of a 3D generation model is to learn a probabilistic model P ? (V, E) to model the empirical distribution of 3D molecule graphs, which could also be used to sample new molecules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Coarse-to-Fine Framework</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">CHALLENGES OF NON-AUTOREGRESSIVE METHODS</head><p>Compared with the autoregressive approach, nonautoregressive generative models are more promising for 3D molecule generation, due to their natural advantages of global modeling ability <ref type="bibr" target="#b6">(De Cao &amp; Kipf, 2018;</ref><ref type="bibr" target="#b26">Kwon et al., 2019;</ref><ref type="bibr" target="#b41">Satorras et al., 2022)</ref>. Empirically, previous work has shown consistent observations <ref type="bibr" target="#b16">(Hoogeboom et al., 2022)</ref>.</p><p>Though there are several appealing properties, the nonautoregressive model at the fragment level indeed implies the following structure generation procedure under hard constraints.</p><formula xml:id="formula_5">G ? P ? (V, E), s.t. G s (V i ) ? W, ?i = 1, ? ? ? n,<label>(4)</label></formula><p>where G s (V i ) stands for the substructure which consists of V i and its neighbors, W stands for the set of all valid substructures. Intuitively, the valid substructures satisfy the following conditions: the neighbors should hold matched components(atoms/bonds) to get ensembled; for the cases where a node has multiple neighbors there should also be enough matched components in this node to match all its neighbors. We provide Fig. <ref type="figure">2</ref> to better illustrate the constraints in Eq. (4). Limited chemical valency makes conflicts really common in fragment generation. Note that the problem of avoiding fragment conflict has high complexity and brings the so-called "combinatorial exploding" issues <ref type="bibr" target="#b20">(Jin et al., 2020)</ref> because of the multi-hop conflicts.</p><p>For non-autoregressive modeling fashion, the complexity in-  creases exponentially with the structure size. This problem is also discovered in other tasks, for example, Dispatching Route Generation <ref type="bibr" target="#b8">(Ding et al., 2021)</ref>, Optimal Experiment Design (Le <ref type="bibr" target="#b27">Bras et al., 2012)</ref>, and Protein Alignment Generation <ref type="bibr" target="#b55">(Xu et al., 2015)</ref>. In fragment-based molecule generation, it is challenging to generate realistic drug-size molecules in an ordering-agnostic way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">SOLUTIONS FOR AVOIDING CONFLICTS</head><p>It is difficult to sample from the distribution with hard constraints. One direct solution that was adopted in previous work <ref type="bibr" target="#b37">(Popova et al., 2019)</ref>  </p><formula xml:id="formula_6">(V i |N (V i )),</formula><p>to approximate the hard constraint, where N (V i ) stands for the neighbors of V i . Correspondingly, the generative distribution P ?,? (V, E) could be written as another target distribution P ? (V, E) 1?i?n P ? (V i |N (V i )). Unfortunately, Markov chain Monte Carlo (MCMC) sampling is needed, such as Gibbs Sampling, to conduct sampling from such distribution, which still suffers from efficiency issues.</p><p>Instead of making generated samples satisfy the constraint through filter or refinement, we try to decompose and embed the constraint directly into the model phase within a hierarchical fashion. More specifically, we design the variable (H) as the latent variable and the probabilistic model could be expressed as P ?,? (V, E) = P ? (H)P ? (V, E|H). Consequently, we could obtain a lower bound of the maximum likelihood objective by the concavity of the logarithm, as follows:</p><formula xml:id="formula_7">E (V,E)?P data log H?H P ? (H)P ? (V, E|H) ? E (V,E)?P data E H?Q(H|V,E) log P ? (H)</formula><p>Coarse-grained Diffusion</p><formula xml:id="formula_8">+ log P ? (V, E|H) Fine-Grained Generation -log Q(H|V, E) Constant Term (5)</formula><p>where H stands for the possible support of H. Formally, Q(H|V, E) in Eq. ( <ref type="formula">5</ref>) is implemented by extracting chemical features and averaging the atom coordinates. As Q(H|V, E) is set to a constant term, the objective will include only the former two terms, i.e. log P ? (H) and log P ? (V, E|H). The first objective log P ? (H) could be approximated by a coarse-grained fragment diffusion model and the second objective log P ? (V, E|H) is modeled by equivariant message passing networks and iterative refinement process. Intuitively, the coarse-to-fine process is like first determining the position and the function of each component, then finding the connectable fragments from small subsets, and assembling them. Therefore, HierDiff could maintain the global modeling property of non-autoregressive methods and also significantly reduce the complexity of finding the connectable fragments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">HierDiff: hierarchical diffusion-based model</head><p>In this section, we introduce the proposed HierDiff model in detail, as illustrated in Fig. <ref type="figure" target="#fig_1">3</ref>, including coarse-grained fragment generation, fine-grained fragment generation, and atom conformation assembling which also correspond to the parameterized terms in Eq. (5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Coarse-Grained Fragment Diffusion</head><p>We define H = [H f , H p ] as the representation of the coarse nodes, where H f stands for the invariant chemical features and H p stands for the equivariant positional features. Formally, Q(H|V, E) in Eq. ( <ref type="formula">5</ref>) is implemented by extracting chemical features to obtain H f and averaging all the atom coordinates to obtain H p . Specifically, the property-based features could depend on both fragment V and the attachment E, i.e. the connection to neighbor fragments.</p><p>In the coarse-grained phase, a diffusion model is proposed to approximate log P ? (H). Note that, when sampling from the diffusion model, we first sample the number of coarse nodes from the histogram we calculated on the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1.">CHEMICAL FEATURE</head><p>We carefully design the features to be discriminative enough for fragments and molecules with different chemical and geometrical properties, which allows us to easily integrate our domain knowledge as inductive bias into the model. And we specifically employ two kinds of features: Property-based Coarse Feature: We summarize some important properties which are widely used in drug discovery into an 8-dimension vector, including the number of hydrogen bonds and rings, the area of different surfaces, etc.</p><p>Element-based Coarse Feature: We also include the histogram of element frequency, i.e., a 3-dimension vector, to the feature representation, inspired by the fact that elements with the same number of valence electrons usually share the same properties.</p><p>Please refer to Fig. <ref type="figure" target="#fig_2">4</ref>, Table <ref type="table" target="#tab_5">3</ref> and<ref type="table" target="#tab_6">Table 4</ref> for the detailed implementations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2.">POSITIONAL FEATURE</head><p>There are several possible ways to represent the 3D conformation systems in fragment level, e.g., the dihedral angle between neighbor fragments, and the distance matrix. In this paper, we simply use the center coordinates as the positional feature of the coarse node, since we found that this information is enough to determine the conformation at atom resolution, with a predefined vocabulary of bond length and bond angles from the RDkit ETKDG module. Please note that the center position of the coarse node could be seen as the center of the conformation sphere which includes all possible conformations generated from the degree of freedom on rotation. The connected fragments correspond to the tangent condition which actually eliminates the degree of freedom, which is illustrated in Fig. <ref type="figure">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3.">DIFFUSION PROCESS</head><p>Then, we introduce the modeling of H f and H p individually.</p><p>H f could be modeled by a typical diffusion model with Gaussian noise for step t &gt; 0. However, we find that the 0th term for continuous feature H int f and H cont f , i.e. L 0 , should be designed carefully, as observed similarly in <ref type="bibr" target="#b16">(Hoogeboom et al., 2022)</ref>. In this paper, we use the following form, which The spheres of all coarse-grained nodes will be determined since the radius of coarse-grained nodes could be directly determined by basic chemical rules. Conversely, the full atom conformation can be reconstructed, by sampling positions on the tangent of intersecting spheres. Therefore, the center coordinate is a good representation.</p><p>has shown a better empirical performance.</p><formula xml:id="formula_9">L 0 (H int f , H cont f ) = -log[ H int f + 1 2 H int f -1 2 N u | x (H int f ) 0 , ? 0 du] -log N H cont f | x (H cont f ) 0 ? 0 - ? 0 ? 0 ? 0 , ? 2 0 ? 2 0 I .</formula><p>Next, we describe the generation for H p . To make the likelihood function in Eq. ( <ref type="formula">2</ref>) to be SE(3)-invariant, we set the initial distribution under the zero center of mass (CoM) systems <ref type="bibr" target="#b23">(K?hler et al., 2020)</ref>, i.e., applying a CoM-free Gaussian:</p><formula xml:id="formula_10">N H p | 0, ? 2 I = ( ? 2??) -(M -1)?n exp - 1 2? 2 H p 2 .</formula><p>Here H p belongs to the space R M ?n , where M is the number of fragment nodes and n equals the coordinate dimension. Besides, an equivariant Markov transition kernel is constructed under the widely applied noise parameterization <ref type="bibr" target="#b14">(Ho et al., 2020)</ref>:</p><formula xml:id="formula_11">? ? H t p , t = 1 ? ? t H t p - ? t ? 1 -?t ? H t p , t .</formula><p>If ? is parameterized by SE(3)-equivariant networks, the transitional kernel <ref type="bibr" target="#b56">(Xu et al., 2022)</ref>.</p><formula xml:id="formula_12">P ? (H t-1 p |H t-1 p ) is also SE(3)-equivariant, i.e., P ? H t-1 p | H t p = P ? T g H t-1 p | T g H t p</formula><p>We leave the detailed proof in Appendix A.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Fine-Grained Fragment Generation</head><p>After [H f , H p ] were generated by the diffusion model, a set of coarse-grained nodes in 3D space is obtained, illustrated in Fig. <ref type="figure" target="#fig_1">3</ref>. Now we introduce the detailed process of generating fine-grained fragment types and edges, conditioned on the coarse-grained nodes, which correspond to the term P ? (V, E|H).</p><p>We first briefly introduce the decoding logic here. In each decoding step, the fine-grained generation process contains  four stages. Firstly, we select a focal node from all the existing fine-grained nodes with a parameterized neural network module ? focal . Next, we utilize a link prediction network, i.e. ? edge , to identify a new node that could be linked to the focal node from all the remaining coarse-grained nodes. Then we obtain the fine-grained fragment type of the above newly linked coarse-grained node with the help of another network ? node . At last, an iterative refinement process is conducted to correct the bias in fine-grained nodes, based on the newly determined fragment type. It should be noted that in the beginning, all the nodes are coarse-grained, so we randomly select a node and directly use ? node to predict its fragment type. The above procedure is illustrated in Fig. <ref type="figure" target="#fig_5">6</ref>. We emphasize several key elements of our assembling module in the following:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1.">ITERATIVE REFINEMENT</head><p>Now we delve into the details of the iterative refinement process. The motivation for introducing this iterative refinement process is to correct the bias in the existing finegrained nodes, to enhance the ability to generate more realistic molecules from a global view. Specifically, we design a mask prediction model ? refine to approximate the probability of each decoded fine-grained fragment conditioned on all coarse-grained nodes and the other fine-grained nodes. The target is to maximize the joint probability of fine-grained nodes as follows:</p><formula xml:id="formula_13">P target = Vi?T f P ?refine (f (V i ) | T c , T f \ V i ),<label>(6)</label></formula><p>where T f is the set of all existing fine-grained nodes, T c is the set of coarse-grained nodes, and f is a function to return the fragment type for a specific node. To sample from the above target distribution, we defined a Markov Chain, in which node type replacement is defined as the state transition, and an early-stopping Monte Carlo sampling strategy is adopted to conduct the sampling process. The detailed algorithm is illustrated in Appendix A.4. We also conduct an ablation study to prove the effectiveness of the proposed iterative refinement process, as shown in Appendix C.7</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2.">MESSAGE PASSING NEURAL NETWORKS</head><p>Here we introduce the aforementioned models in the finegrained process, i.e. ? focal , ? edge , ? node and ? refine . In order to avoid the disconnectivity problem as Fig. <ref type="figure">2</ref>, we need to elaborately design these models.</p><p>Specifically, the input is a set of 3D fragments, represented by both chemical and positional features. In addition, we add one-hot vectors to indicate the fragment types for all fine-grained nodes. At the initial stage, the input is treated as a fully connected 3D graph and a vanilla EGNN <ref type="bibr" target="#b40">(Satorras et al., 2021)</ref> extracts the initial embeddings for all links and nodes. According to the fine-grained generation process, ? focal simply passes information among fine-grained nodes. ? edge then aggregates information of all fine-grained nodes to the focal node by a tree bottom-up pattern, in which the focal node is treated as the root of the tree structure. After the new edge is predicted, the network broadcasts the addition of the new edge to all fine-grained nodes in a tree top-down pattern. Finally, ? node aggregates the information from all fine-grained nodes in the bottom-up pattern to the new node for decoding the fine-grained fragment type. For mask prediction module ? refine , we utilize a bottom-up EGNN similar to ? node . The information is aggregated from all fine-grained nodes to the masked nodes, to compute the target distribution as in Eq. ( <ref type="formula" target="#formula_13">6</ref>). The illustration of the message-passing process could be found in Fig. <ref type="figure" target="#fig_5">6</ref>. We discussed model-level modification of EGNN in Appendix A.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3.">TRAINING</head><p>During training, we start by first randomly sampling a connected subgraph at each step. Then a random leaf node is picked, and we simulate the fine-grained generation of this node All the fine-grained nodes and edges of the subgraph except the selected one are kept. For the other nodes, we only maintain the coarse features and their position. Then ? focal is trained based on the above feature to maximize the probability of the parent of the selected node among the nodes in the fine-grained subgraph. ? edge is trained to maximize the probability of the edge link between the focal node and the selected node among all other coarse-grained nodes. ? node is trained to output the fine-grained fragment type of the selected node. For the iterative refinement part, we just randomly mask a node's fine-grained feature on the subgraph, and ? refine is trained to reconstruct its masked fragment type. Detailed implementations and objectives could be found in Appendix A.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Assembling to Atom Conformation</head><p>Given all fine-grained nodes and link relations determined in the fine-grained generation process, we have to decide which atoms within two linked fragments could be merged to construct the atom-level conformation. To conduct this process, we first randomly choose a fragment, enumerate all possible attachments for its neighbor fragments, and select the one that has the closest fragment center geometric as our generated positional features in the coarse-grained fragment generation. Specifically, we use RDkit to generate the local conformation for each candidate attachment following <ref type="bibr" target="#b51">(Wang et al., 2022)</ref> and apply the root-mean-square deviation (RMSD) to measure the difference between fragment center coordinates. The above process will be continued following the neighboring structure until all the local connections are determined. Then we generate the coordinates of each atom. To plug the local conformations into each molecule coordinate system, we need to determine the rotation matrix (R) and translation vector (t). Here we compute R and t between generated local coordinates and RDkit predicted local coordinates using Kabsch Algorithm <ref type="bibr" target="#b22">(Kabsch, 1976)</ref> at the fragment level. Then we applied the obtained R, t on the RDkit generated atom level coordinates to align the RDkit generated local geometry to our sampled center positions. This process starts from the subgraph constructed by a randomly selected fragment and its neighbors and is conducted successively until the full atom conformation is derived. Noted that, RDkit is only utilized for generating local geometry in conformation generation. The full detailed algorithm is introduced in Appendix A.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experiments</head><p>In this work, we mainly focus on generating druglike molecules. So our main experiments are conducted on the dataset of GEOM DRUG <ref type="bibr" target="#b0">(Axelrod &amp; Gomez-Bombarelli, 2022)</ref> and CrossDocked2020 <ref type="bibr" target="#b9">(Francoeur et al., 2020)</ref>. Specifically, GEOM DRUG includes 304k drug-like molecules, and CrossDocked2020 <ref type="bibr" target="#b9">(Francoeur et al., 2020)</ref> contains 100k 3D ligand structures extracted from proteinligand complexes, respectively. As compared with two wellknown 3D molecular generation models, i.e. EDM <ref type="bibr" target="#b16">(Hoogeboom et al., 2022)</ref> and G-SphereNet <ref type="bibr" target="#b33">(Luo &amp; Ji, 2022)</ref>, both versions of HierDiff achieve superior results, where HierDiff-E and HierDiff-P denotes the implementation us-ing the element-based feature and property-based feature as representation, respectively. Though our model is not designed for generating small molecules, we also compare HierDiff with several existing models on QM9 <ref type="bibr" target="#b0">(Axelrod &amp; Gomez-Bombarelli, 2022)</ref>, a popular benchmark for 3D molecule generation evaluation, which the results are shown in Table <ref type="table" target="#tab_7">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Drug-Likeness Evaluation</head><p>The purpose of our proposed generation method is to fabricate molecules that are similar to authentic drug molecules from scratch, thus it is important to measure how drug-likely are those fabricated molecules to true drug molecules.</p><p>6.1.1. EVALUATION METRICS Specifically, we mainly measure the drug-likeliness of a molecule from 6 aspects. Quantitative estimate of druglikeness (QED), one of the most widely used metrics for virtual screening, is built on a series of carefully selected molecular properties to evaluate drug-likeness. Retrosynthetic accessibility (RA) is a machine learning based scoring function based on retrosynthesis protocol that evaluates synthetical accessibilities. Medicinal chemistry filter (MCF) is the rate of sampled molecules that do not contain any undruggable substructures <ref type="bibr" target="#b2">(Brown et al., 2019)</ref>. Synthetic accessibility score (SAS) is a ruled-based scoring function that evaluates the complexity of synthesizing a structure by organic reactions. LogP is the octanol-water partition coefficient which is the main factor that determines the distribution of the drug molecules, and ? LogP indicates the difference between the computed LogP and the ground-truth one on the training distribution. Molecular weight (MW) is a measure of the sum of the atomic weight values of the atoms in a molecule. An ideal model will sample molecules from the same weight distribution as the training set, denoted as ground-truth MW. In practice, ? MW is usually adopted to measure the difference between the computed MW and the ground-truth one.  compared with EDM. We speculate that this is mainly due to the error accumulation problem in the autoregressive approach in G-SphereNet, which is proven by our ablation study in Table <ref type="table" target="#tab_4">12</ref> of Appendix. Considering the poor performance of G-SphereNet on generating large molecules, we exclude it in the following conformation experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2.">EXPERIMENTAL RESULTS</head><p>We also carry out an ablation study on HierDiff w.r.t. the drug-likeliness. Specifically, we remove the iterative refining step and compare the obtained model with the original HierDiff. From the results shown in Appendix C.7, the model without iterative refining generates less complicated molecules, as compared with the original HierDiff, in terms of both QED and MCF. Though it has the ability to generate large molecules, such results are far from satisfactory in real applications. Through our analysis, the reason is that, without iterative refinement, HierDiff tends to choose fragments that are easier to assemble, indicating the importance of iterative refinement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Conformation Quality Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1.">EVALUATION METRICS</head><p>However, since all generated molecules are new, i.e. not existing in training data, we cannot directly use ground-truth conformations from the database for evaluation. To obtain corresponding ground-truth conformation, we adopted the same experimental procedure as in <ref type="bibr" target="#b0">(Axelrod &amp; Gomez-Bombarelli, 2022)</ref>. which has been proven to be suitable for evaluating the conformation quality 3D conformation generation in several previous work <ref type="bibr" target="#b56">(Xu et al., 2022;</ref><ref type="bibr" target="#b21">Jing et al., 2022)</ref>. Specifically, a computational costly molecular dynamic simulation<ref type="foot" target="#foot_0">2</ref> is carried out for all generated molecule graphs to return the set of MD simulated conformations. Then the coverage metric and matching metric denoted as Cov and Mat, are computed to measure the quality of generated conformations. The precise definitions are given as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COV (C, C</head><formula xml:id="formula_14">* ) = 1 |C * | C * ?C * 1(RMSD(C, C * ) ? ?) , MAT (C, C * ) = min C * ?C * RMSD(C, C * ),</formula><p>where C denotes the generated conformation, C * represents the ground truth set of conformations sampled with MD simulation, C * denotes a ground truth instance from C * , 1(?) is the indicator function which evaluates to 1 when the input is true otherwise 0, ? is the similarity threshold, which is set to 2 ? in practice. From the above definition, the coverage metric describes the rate of ground truth conformations that are similar to the generated conformation, reflecting how likely the generated molecule is in a low energy state. The matching value is the minimum RMSD value between the generated molecule and the conformations in the ground truth set, indicating the similarity between the generated molecule and ground-truth conformations. In our experiments, we compute the coverage and matching metrics on both atom and fragment coordinates, to measure conformations quality at different levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2.">EXPERIMENTAL RESULTS</head><p>The experimental results listed in Table <ref type="table" target="#tab_4">2</ref> show that HierDiff outperforms EDM consistently on all the evaluation metrics. Though HierDiff only generates center coordinates in the coarse phase, it is able to achieve impressive results on both levels, indicating the great power of HierDiff in capturing We also demonstrate some visualization results in Fig. <ref type="figure" target="#fig_6">7</ref>. We can see that the structures generated from EDM are more chaotic, with clear distorted rings and unexpected broken substructures. On the contrary, our model generates much more stable molecular scaffolds, by utilizing the coarse-to-fine approach. We also provide force field based experiments on sampled conformation to prove that our model generates more low-energy conformations, shown in Appendix C.4 for space limitation. We discuss the choice of high-level features in Appendix C.9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>This paper is concerned with 3D molecule generation. To address the irrational molecule structure problems, a hierarchical diffusion probabilistic model is proposed. We carefully design our method so that it can solve the combinatorially constrained structure generation problem introduced by non-autoregressive fragment generation modeling. To our knowledge, our work is the first attempt to get the best of both the globalization of the non-autoregressive model and the effectiveness of the fragment-based generation. Hi-erDiff generates better drug-like molecules, in terms of several widely used evaluation metrics. We believe that the proposed framework could inspire general solutions for other constrained structure generation tasks, such as protein alignment generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Supplemented Details for the Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Implementation for Fragmentizing the Molecule</head><p>To decrease the freedom in modeling large-size molecules, many models adopt fragment-based generation instead of building a model directly on atoms <ref type="bibr">(Yang et al., 2022a)</ref>. A number of methods are developed to break a molecule into a set of fragments. A good decomposing algorithm should satisfy that the derived fragment vocabulary needs to cover most of the molecular structures and also maintains a reasonable vocabulary size.</p><p>JT-VAE <ref type="bibr">(Jin et al., 2018a)</ref> is the first deep-learning method that generates molecule graphs at the fragment level. It derived fragments by applying the minimum spanning tree algorithm to keep all chemical bond information while avoiding cycles. JT-VAE <ref type="bibr">(Jin et al., 2018a)</ref> succeed to cover all buyable structures with a vocabulary size of less than 800. Recent works like MARS <ref type="bibr" target="#b54">(Xie et al., 2021)</ref>, FREED <ref type="bibr" target="#b59">(Yang et al., 2021)</ref>, MIMOSA <ref type="bibr" target="#b10">(Fu et al., 2021)</ref>, FragSBDD <ref type="bibr" target="#b38">(Powers et al., 2022)</ref> though applied different criterion on breaking bonds to generate fragment vocabulary, fragments of low frequency need to be removed from the vocabulary to keep the vocabulary size reasonable.</p><p>The chemical space of drug-like molecules is enormous. Leaving out fragments of low frequency is undesirable. Therefore, we adopt the tree decomposition algorithm from <ref type="bibr">(Jin et al., 2018a)</ref> in a 3D space. The procedure of processing the molecules into fragment graphs is a four-step process. Extract components We extract the set of chemical bonds which do not belongs to any rings and the set of simple rings which only represent a single topological cycle from the molecules. Merging The Bridged ring is a cluster of important chemical structures. They possess uncommon 3D conformation. Therefore, all pairs of rings are merged if the ring pair has more than two overlapping atoms. Edge linking Cycles in the fragment graph will cause problematic modeling since the decomposition for a molecule is not unique. To avoid cycles, the intersecting atom which connects more than 3 bonds is added to the graph as a fragment. Edges are linked between all fragment pairs that have overlapping atoms. The minimum spanning tree algorithm is run on this graph to remove overlapping edges. 3D coarse set At last, we assign 3D geometric information using the center of mass of the atoms within the fragment and coarse features for each fragment.</p><p>However, there are still other methods that can be applied for the fragmentation of molecules. Hence, an experiment is conducted to prove that our fragmentation strategy has advantages and the results are show in Appendix C.7</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Implementation of Coarse-Grained Fragment Diffusion Model</head><p>In this section, we describe the non-autoregressive high-level feature generative model and its likelihood computation. Though diffusion models have been receiving outstanding results in computer vision <ref type="bibr">(Yang et al., 2022b;</ref><ref type="bibr" target="#b14">Ho et al., 2020;</ref><ref type="bibr" target="#b49">Vahdat et al., 2021)</ref>, it was nontrivial to apply directly on molecule fragment graphs. The graph features include integer features, continuous features, and continuous coordinates. These different vectors require different likelihood computations <ref type="bibr" target="#b56">(Xu et al., 2022;</ref><ref type="bibr" target="#b16">Hoogeboom et al., 2022)</ref>.</p><p>The diffusion model adds noise sequentially to the feature and coordinates like Eq. 1. At the time t, the data distribution of invariant features is expected to approximate the prior distribution N (0, I). However, in order to guarantee equivariance, the prior distribution for coordinates needs to be invariance in SE(3) group. It has been proven that when the prior distribution is invariant and the transformations are equivariant the diffusion model estimates a SE(3)-invariant data distribution <ref type="bibr" target="#b56">(Xu et al., 2022)</ref>:</p><formula xml:id="formula_15">p ? (T g (x 0 )) = p (T g (x T )) p ? (T g (x 0:T -1 ) | T g (x T )) dx 1:T = p (T g (x T )) ? T t=1 p ? (T g (x t-1 ) | T g (x t )) dx 1:T = p (x T ) ? T t=1 p ? (T g (x t-1 ) | T g (x t )) dx 1:T (invariant prior p (x T )) = p (x T ) ? T t=1 p ? (x t-1 | x t ) dx 1:T (equivariant kernels p (x t-1 | x t )) = p (x T ) p ? (x 0:T -1 | x T ) dx 1:T = p ? (x 0 ) (7)</formula><p>As a result, we move the prior distribution for coordinates to a linear subspace where</p><formula xml:id="formula_16">i=3 i H pi = 0</formula><p>The model minimizes the lower bound of the log-likelihood:</p><formula xml:id="formula_17">log P (H) ? L 0 + L base + T t=1 L t (8)</formula><p>where:</p><formula xml:id="formula_18">L 0 = log P (H | x 0 ) (9) L base = -KL (q (x T | H) | P (x T )) (10) L t = -KL (q (x s | H, x t ) | P (x s | x t ))<label>(11)</label></formula><p>L t and L base can be computed easily by estimating the KL divergence between the estimated distribution and the target distribution. However, L 0 needs special treatment. Following the previous works <ref type="bibr" target="#b16">(Hoogeboom et al., 2022;</ref><ref type="bibr">2021)</ref>, we define the L 0 as follows:</p><formula xml:id="formula_19">P H int f | x (H) 0 = H int f + 1 2 H int f -1 2 N u | x (H int f ) 0 ? 0 du P H cont f | x 0 = N H cont f | x (H cont f ) 0 /? 0 -? 0 /? 0 ? 0 , ? 2 0 /? 2 0 I P (H p | x 0 ) = N H cont f | x (Hp) 0 /? 0 -? 0 /? 0 ? 0 , ? 2 0 /? 2 0 I (12)</formula><p>For integer features, we centered the distribution to h int and integrate from -1/2 to 1/2. While for continuous features and coordinates, the variance of the distribution is still approximated by the network. During sampling, our model used a regular reverse diffusion to generate features and coordinates. The only difference is that the integer feature dimensions are normalized using the round function. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. Implementation of Equivariant Neural Network</head><p>Improved EGNN In the node/edge sampling process, our nodes are endowed with a set of invariant features and equivariant coordinates. Inspired by the recent equivariant neural networks <ref type="bibr" target="#b48">(Thomas et al., 2018;</ref><ref type="bibr" target="#b1">Brandstetter et al., 2021)</ref>, we propose an improved version of EGNN <ref type="bibr" target="#b40">(Satorras et al., 2021)</ref>. Each layer is formulated as:</p><formula xml:id="formula_20">m uv = ? m n l u , n l v , x l u -x l v 2 , e l uv x l+1 u = x l u + c tanh ? ? v?N (u) x l u -x l v ? x (m uv ) ? ? n l+1 u = ? n ? ? n l u , v?N<label>(u)</label></formula><formula xml:id="formula_21">(m uv ) ? ? e l+1 uv = ? e e l uv , m uv , x l u -x l v 2</formula><p>n and e stands for the node/ edge embedding, while c is a distance constant. x stands for node coordination. All ? are classic MLPs. Previous works explore various kinds of techniques to maintain the equivariance of node features, however, the edge features are always ignored to encode into the latent variables. It has been proven that including edge feature updated in neural networks help improve performance <ref type="bibr" target="#b7">(Diao &amp; Loynd, 2022;</ref><ref type="bibr" target="#b61">Zhou et al., 2023)</ref>. Edge latent variables are also needed for edge prediction in our methods. As a result, instead of carrying out the message passing on fully connected graphs with unified edges, we assigned edge features for sampling tasks. ? f ocal , ? edge , ? node uses this improved network for message passing.  end for 29: until ? n?T , n is fine-grained node A.5. Algorithm for Atom-level Conformation Sampling Algorithm 3 Algorithm for Conformation Alignment</p><formula xml:id="formula_22">T ? T ? G, s.t. T is connected subgraph 18: n ? n ? T , s.t. n is leaf node 19: m ? m ? T , s.t. m is single node 20: T = T \ n, V = G \ T 21: T = T \ m 22: context = (F( T ), C(V ? n)) 23: L sample = -log P ?focal (n.parent | context) -log P ?edge ({n, n.parent} | context) -log P ?node (FRAG(n) | context,</formula><formula xml:id="formula_23">Input: Fragment center coordinate: F out , Molecule fragment graph: G Output: C out 1: function KABSCH(X ? R 3 , X ? R 3 ) 2: X c = n i=1 X i , Xc = n i=1 Xi 3: X = X -X c , X = X -Xc 4: H = n i=1 X XT 5: H = U ?V T 6: R = U V T T 7: t = Xc -RX c 8:</formula><p>return R, t 9: end function Although our model is designed to generate drug-like molecules with relatively large molecule sizes, it can be applied for smaller organic molecule (QM9) generation tasks without effort. We also measure the validity and uniqueness metric from previous works <ref type="bibr" target="#b16">(Hoogeboom et al., 2022)</ref> on 10000 generated small organic molecules and compared them with various baselines by using RDkit.</p><p>Baselines Our method is compared with previous methods. Both graph-based and coordinate-based models are included here. Graph-based methods like Graph VAE <ref type="bibr" target="#b46">(Simonovsky &amp; Komodakis, 2018)</ref>, GTVAE <ref type="bibr" target="#b35">(Mitton et al., 2021)</ref>, and Set2GraphVAE <ref type="bibr" target="#b50">(Vignac &amp; Frossard, 2021)</ref>, do not explicitly define the coordinates, so they need cheminformatic software to generate conformers. On the other hand, 3D coordinate-based models like E-NF <ref type="bibr" target="#b41">(Satorras et al., 2022)</ref>, G-Schnet <ref type="bibr" target="#b11">(Gebauer et al., 2019)</ref>, and EDM <ref type="bibr" target="#b16">(Hoogeboom et al., 2022)</ref>, need cheminformatic software to derive chemical bonds. This indicates that our model generates not only accurate conformations of drug-like molecules but also enjoys great sampling efficiency. As shown in Table <ref type="table" target="#tab_7">5</ref>, our method performs comparable results in both validity and uniqueness. Though EDM <ref type="bibr" target="#b16">(Hoogeboom et al., 2022)</ref> achieved better performance, our method still outperforms all other models. The slight performance drop compared to EDM could be due to the information loss ratio during fragmentization on the tiny graphs. Besides, our model is the only 3D method that does not depend on any chemical bond linking software, like Openbabel. Hydrogen atoms can be added by counting the valency for each atom in our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3. Additional evaluation of drug-like properties</head><p>Ring Size Ring Systems with the size of 5-6 are stable chemical groups in organic chemical theories. HeteroAtom</p><p>The number of heteroatoms represents area of the polar surface in the organic molecules, which highly determines the distribution of the drug molecules in the human body, e.g., the drug molecules that can cross the blood-brain barrier always has fewer heteroatoms. AromaticRing The Number of aromatic rings in the molecules indicates the ability to form ? -? interaction with proteins or other biomolecules. Aromatic rings also stabilize the molecule into lower energy conformations.</p><p>AliphaticRing The Number of aliphatic rings in the molecules indicates the rigidity of the molecules. Instead of lying in a plane as aromatic rings, aliphatic rings constrained the conformation by contributing a specific torsion angle to the molecule conformation. Radius The mean radius of the fragment. A higher radius than the GEOM DRUG indicates too many rings are generated by the model. A smaller radius indicates the model is not able to construct valid ring systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Result and Discussion</head><p>In addition to the evaluation of properties on the molecule level, we also break all the sampled molecules into fragments and test their performance on additional properties As expected, our method chooses fragments that are similar to that of ground truth statistics. We plotted the distribution of ring size in Fig. <ref type="figure">8</ref>, the number of our method conforms best with ground truth. It is obvious that ring sizes 5 and 6 are most commonly seen in drug datasets and our sampled results, which are stable. However, on the contrary, the atom-based method such as EDM <ref type="bibr" target="#b16">(Hoogeboom et al., 2022)</ref> has failed to capture this basic chemical rule. Refer to Table <ref type="table" target="#tab_9">7</ref> for additional property evaluation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4. Conformation Energy Experiments</head><p>Besides conformation quality evaluation, we also want to verify that our model generates conformation with realistic energy terms. We compared our model with two baseline methods, EDM <ref type="bibr" target="#b16">(Hoogeboom et al., 2022)</ref> and JT-VAE <ref type="bibr">(Jin et al., 2018a)</ref>. JT-VAE is a 2D fragment-based molecule generation model, so we used the RDkit ETKDG module to generate the 3D conformation for the sampled 2D molecules. Similar to the conformation quality experiments, we trained all models on GEOM DRUG dataset and sampled 100 conformations with each method to carry out our experiments. We compute the energy using Merck Force Field(MFF). MMD distance with the Gaussian kernel is applied here to measure the difference between generated distributions and the original distribution. Result and Disscussion According to Fig. <ref type="figure" target="#fig_10">9</ref>, HierDiff generates conformations with the closest energy distribution with the original dataset. Though EDM is outperformed by our method, it still beats JT-VAE(ETKDG) in generating more stable conformations. We can conclude that in this task, 3D methods have advantages over using RDkit conformation sampling along with a 2D method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5. Evaluation of Uniqueness and Diversity on GEOM DRUG</head><p>To prove that our method does not occur the issue of mode collapse, we tested the uniqueness of generated molecules and evaluate the similarity of generated molecules with the GEOM DRUG test set. Similarity which measures the average similarity between generated molecules with the most similar molecule in the test set. We use the Tanimoto score between ECFP4 fingerprints to measure the similarity between two molecules. High similarity indicates that the method lack generalization. Unique is the proportion of unrepeated structures in generated molecules. Both metrics are tested on molecule level and Murko Scaffold level. Numeric results are listed in Table <ref type="table" target="#tab_11">8</ref> It is quite clear that our model generates more diverse molecules.</p><p>Result and Disscussion HierDiff outperforms EDM <ref type="bibr" target="#b16">(Hoogeboom et al., 2022)</ref>   In the field of AI-guided drug discovery, one of the most essential directions is to generate 3D molecules according to desirable properties. Though previous works <ref type="bibr" target="#b11">(Gebauer et al., 2019;</ref><ref type="bibr" target="#b16">Hoogeboom et al., 2022)</ref> have tested their abilities to generate molecules conditioned on simulated energy, to our knowledge, we are the first to carry out practical drug discovery-related property-conditional generation experiments using the 3D molecule generative model. We include the properties as an additional atom feature dimension in our dual-phase generation process. We tested the difference using mean squared error (MSE) and mean absolute error (MAE) between the input properties and the real properties of the generated 3D molecules. The diversity of the generated molecules is also evaluated using mean fingerprint similarity as defined in <ref type="bibr" target="#b54">Xie et al. (2021)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Asphericity</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.7. Ablation Study</head><p>We remove the iterative refinement step in each fragment sampling process when using the model training on GEOM DRUG to carry out the ablation study. The results are shown in Tab. 9. The experiment results illustrate that the hierarchical diffusion-based model samples molecules with higher molecular weight and lower SAS score, however, the drug-likeness score QED and safety score MCF decreased.</p><p>Besides, we also replaced the minimum spanning tree algorithm with the 'High-frequency Fragments' strategy and 'Single Rings and Bonds' strategy for an ablation study. The 'High-frequency Fragment' is a common strategy applied in previous works <ref type="bibr" target="#b54">(Xie et al., 2021;</ref><ref type="bibr" target="#b38">Powers et al., 2022)</ref> in which all fragments are collected from the training datasets using basic predefined rules. Only the high-frequency fragments are kept in the vocabulary in this method. 'Single Rings and Bonds' is another simple fragmentation strategy in that the fragments are limited to all single bonds and single rings. Bridge rings and multiple-ring systems are broken into single rings to reduce fragment complexity. The results are listed in Tab. 10, which illustrate that without using a complicated fragmentation strategy our method still outperforms the baseline model in most metrics. We chose the minimum spanning tree-based strategy because it offers a more balanced performance in all drug-like properties.  We conduct an experiment on the computation cost(sampling speed). It is true that the decoding models ? f ocal , ? node and ? edge indeed bring some computational cost. While these modules are not the key bottleneck as only a few forward passes need to be conducted during sampling. As shown in Tab. 11, the diffusion phase is actually the main computational overhead as there are many forward passes, e.g. thousands of steps, that need to be conducted during a single sampling process. Besides, we also noted the fact that our model is capable of using a larger batch size for parallel on a GPU since our diffusion space is smaller. Your question actually inspires us to train our model in a new setting with fewer diffusion steps, for example, 500 steps or 250 steps. We leave this direction as future exploration.</p><p>C.9. Disscusion on the Choice of high-level feature</p><p>From the above experiments, we can see that both the property-based coarse feature and the element-based coarse feature outperform the baseline models in generating more drug-like molecules and sample stable conformations. However, these two kinds of features reveal different strengths.</p><p>In the Drug-likeness evaluation, HierDiff-P outperforms HierDiff-E in most metrics when training on GEOM DRUG . HierDiff-E achieves the highest score on MCF. The reason is that property-based features provide more chemical semantic information than element-based features. HierDiff-E achieves better results on chemical safety because the element histogram helps the model avoid generating combinations of elements that can form unstable subgraphs. On the contrary, when training on CrossDock, HierDiff-E performs better, because CrossDock is a smaller dataset. It's easier to approximate the true distribution with a simpler representation as the latent variable.</p><p>In the conformation quality evaluation, HierDiff-E achieves better results on the atom level RMSD and HierDiff-P achieves better results on the fragment level RMSD. Since element-based features directly model on the atom level and property-based features include connection information, surface information on a global view, this result agrees with the motivation that inspires us to design these features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.10. Experimental Proof of Error Accumulation</head><p>One of our motivations for developing a hierarchical method for molecule generation is that we discovered the error accumulation in molecule generative models. This means that when the molecule size increase, the error from the previous steps of generation influences later steps which leads to unrealistic results. This issue has been discussed in the field of natural language modeling <ref type="bibr" target="#b42">(Schmidt, 2019;</ref><ref type="bibr" target="#b13">He et al., 2019;</ref><ref type="bibr" target="#b3">Caccia et al., 2018)</ref>. To prove this issue exists, we trained our method which represents the non-autoregressive method, and G-Spherenet which represents the autoregressive method on QM9. Both methods are set to generate molecules with the given molecule size. We test the validity of the generated molecules. We also do the same test on GEOM DRUG , however, the validity of the autoregressive model drops so fast that it cannot generate molecules with more than 20 heavy atoms. Numeric results on QM9 are listed in Table <ref type="table" target="#tab_4">12</ref>. Visualized results of GEOM DRUG can be found in Figure <ref type="figure" target="#fig_12">10</ref>.</p><p>Table <ref type="table" target="#tab_4">12</ref>. Validity of sampled molecules with different sizes trained on QM9 <ref type="bibr" target="#b0">(Axelrod &amp; Gomez-Bombarelli, 2022)</ref>. All molecules that are broken or marked as invalid in RDkit package are regarded as invalid samples. AR stands for the autoregressive model in G-SphereNet <ref type="bibr" target="#b33">(Luo &amp; Ji, 2022)</ref>. non-AR stands for our method.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Visualization results of 3D conformations generated by atom-based methods.</figDesc><graphic url="image-3.png" coords="1,302.55,595.01,58.32,60.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. An overview of the hierarchical diffusion model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Illustration of the featurization of 3D Benzaldehyde using two kinds of features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure5. The spheres of all coarse-grained nodes will be determined since the radius of coarse-grained nodes could be directly determined by basic chemical rules. Conversely, the full atom conformation can be reconstructed, by sampling positions on the tangent of intersecting spheres. Therefore, the center coordinate is a good representation.</figDesc><graphic url="image-36.png" coords="5,307.97,44.17,105.84,105.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Figure6. Illustration of the fine-grained atom generation process, including (1) choosing a focal node among fine-grained nodes using vanilla EGNN, (2) predicting the link from all candidate new edges marked with dashed lines using bottom-up or top-down EGNN, (3) generating the exact fragment type using bottom-up EGNN, (4) iterative refining the previous fine-grained node via sampling from distribution parameterized by bottom-up EGNN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Visualization of 3D conformations and 2D molecular graph generated by HierDiff and EDM, where unstable or broken substructures generated by EDM are marked with red boxes or red lines.</figDesc><graphic url="image-54.png" coords="8,237.42,96.52,63.13,57.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>A. 4 .</head><label>4</label><figDesc>Algorithm for Training and Sampling of fragments Algorithm 1 Training Algorithm for Node/edge decoding Input: 3D molecules set: {G}, EGNN networks: ? focal , ? edge , ? node , ? refine Output: EGNN networks: ? focal , ? edge , ? node , ? refine 1: function C(S, E: subgraph) Fine-grained feature of n, n ? S 8: coord ? Position of n, n ? S 9: edge ? {i, j}, {i, j} ? E 10: return feat, coord, edge 11: end function 12: function FRAG(n: node) 13: feat ? Fine-grained feature of n 14: return feat 15: end function 16: for G in {G} do 17:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>{n, n.parent}) 24: Update ? focal , ? edge , ? node ? Optimize(L sample ) 25: L refine = -log P ?refine (FRAG(m) | [(F( T ), C(m)])26: Update ? refine ? Optimize(L refine ) 27: end for Algorithm 2 Sampling Algorithm for Node/edge decoding Input: Nodes with coarse-grained feature and positions: N Refine step limit: max steps, EGNN networks: ? focal , ? edge , ? node , ? refine Output: Fine-grained Graph T 1: function GENERATE STEP(T) 2: n focal ? P ?focal (n focal | T ) 3: {n focal , n new } ? P ?edge ({n focal , n new } | T ) 4: T ? T + {n focal , n new } 5: fragment ? P ?node (f ragment | T ) refine = arg min n (P ?refine (FRAG(n) | T fine \ n, T coarse ), n ? T ) 12: fragment ? P ?refine (fragment | T fine \ n, T coarse ) 13: FRAG(n refine ) ? fragment 14: end function 15: function PROB(T) 16: return n?T (log P ?refine (FRAG(n) | T \ n)) 17: end function 18:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>10: C in , F in ? RDkit random conformation and fragment positions 11: C out ? C in 12: for n ? BF S(G) do et al., 2021).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. MFF Energy distribution of the generated 3D molecules. Lower Energy MMD means the model is able to generate more stable conformation.</figDesc><graphic url="image-57.png" coords="19,78.76,517.25,140.15,98.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 10 .</head><label>10</label><figDesc>Figure 10. Visualized 3D conformations generated by G-SphereNet</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Random Noise Coarse-grained Diffusion Fine-grained Generation Conformation Assembling High-level Feature + Coordinates Fragment 3D Graph Drug-like 3D Molecules</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table . 1</head><label>.</label><figDesc>shows the experimental results on GEOM DRUG and CrossDocked2020. From the results, it is obvious that HierDiff significantly outperforms EDM and G-SphereNet in terms of all the concerned evaluation metrics.</figDesc><table><row><cell>Graph</cell><cell>Specifically, the RA comparison results indicate that with all the sub-graphs derived from a predefined vocabulary, HierDiff generates molecules that are easier to synthesize in wet labs, without dangerous substructures. Since ? HierDiff EDM Conformation Graph Conformation</cell></row></table><note><p><p>MW</p>shows how close the distribution of generated molecules is to the training data, we can see that G-SphereNet is unable to generate large molecules, while HierDiff generates molecules with more similar size as the training data, as</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 .</head><label>1</label><figDesc>Drug-likeliness evaluation results of the generated molecules on GEOMDRUG and CrossDocked2020, with the last column standing for the results on training data. GSNet is short for G-SphereNet. Experiments that report errors due to low validity are marked as '-'.</figDesc><table><row><cell></cell><cell cols="4">GSNet EDM HierDiff-E HierDiff-P</cell><cell>GEOM DRUG</cell></row><row><cell>QED?</cell><cell cols="2">0.382 0.608</cell><cell>0.632</cell><cell>0.639</cell><cell>0.658</cell></row><row><cell>RA?</cell><cell>-</cell><cell>0.441</cell><cell>0.548</cell><cell>0.639</cell><cell>0.915</cell></row><row><cell>MCF?</cell><cell cols="2">0.489 0.621</cell><cell>0.727</cell><cell>0.659</cell><cell>0.774</cell></row><row><cell>SAS?</cell><cell>-</cell><cell>4.054</cell><cell>3.859</cell><cell>3.547</cell><cell>4.018</cell></row><row><cell cols="3">? LogP ? 2.306 0.566</cell><cell>0.653</cell><cell>0.128</cell><cell>0.000</cell></row><row><cell>? MW ?</cell><cell cols="2">170.7 23.71</cell><cell>30.33</cell><cell>13.33</cell><cell>0.00</cell></row><row><cell></cell><cell cols="4">GSNet EDM HierDiff-E HierDiff-P</cell><cell>Cross Dock</cell></row><row><cell>QED?</cell><cell cols="2">0.442 0.499</cell><cell>0.614</cell><cell>0.585</cell><cell>0.619</cell></row><row><cell>RA?</cell><cell>-</cell><cell>0.332</cell><cell>0.574</cell><cell>0.262</cell><cell>0.912</cell></row><row><cell>MCF?</cell><cell cols="2">0.449 0.613</cell><cell>0.759</cell><cell>0.687</cell><cell>0.746</cell></row><row><cell>SAS?</cell><cell>-</cell><cell>7.056</cell><cell>4.051</cell><cell>5.397</cell><cell>2.564</cell></row><row><cell cols="3">? LogP ? 3.359 2.840</cell><cell>1.872</cell><cell>1.176</cell><cell>0.000</cell></row><row><cell cols="3">? MW ? 200.95 28.40</cell><cell>44.56</cell><cell>1.15</cell><cell>0.00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 .</head><label>2</label><figDesc>Evaluation results of generated conformations where 'atom' and 'frag' indicates the atom and fragment level coordinate metrics used for comparison.</figDesc><table><row><cell></cell><cell>COV?</cell><cell>MAT?</cell><cell>COV?</cell><cell>MAT?</cell></row><row><cell></cell><cell>(atom)</cell><cell>(atom)</cell><cell>(frag)</cell><cell>(frag)</cell></row><row><cell>EDM</cell><cell>0.489</cell><cell>1.349</cell><cell>0.097</cell><cell>3.234</cell></row><row><cell>HierDiff-E</cell><cell>0.546</cell><cell>1.121</cell><cell>0.153</cell><cell>2.583</cell></row><row><cell>HierDiff-P</cell><cell>0.490</cell><cell>1.166</cell><cell>0.202</cell><cell>2.431</cell></row><row><cell cols="2">GEOM DRUG 0.589</cell><cell>0.494</cell><cell>0.435</cell><cell>1.494</cell></row><row><cell cols="4">both global and local geometric information.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 .</head><label>3</label><figDesc>Property-Based high-level feature</figDesc><table><row><cell>Property</cell><cell>Description</cell><cell>Type</cell></row><row><cell>HBA</cell><cell>Numbers of hydrogen bond acceptor</cell><cell>integer</cell></row><row><cell>HBD</cell><cell>Numbers of hydrogen bond donor</cell><cell>integer</cell></row><row><cell>Charge</cell><cell>Numbers of explicit electric charge</cell><cell>integer</cell></row><row><cell cols="2">Aromaticity The size of aromatic ring</cell><cell>integer</cell></row><row><cell cols="2">Alicyclicity The size of alicyclic ring</cell><cell>integer</cell></row><row><cell>Radius</cell><cell>The radius of the force filed optimized conformation</cell><cell>continuous</cell></row><row><cell>PSA</cell><cell>Polar surface area contribution to the conformation</cell><cell>continuous</cell></row><row><cell>ASA</cell><cell cols="2">Accessible surface area contribution to the conformation continuous</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 .</head><label>4</label><figDesc>Element-Based high-level feature</figDesc><table><row><cell>Property</cell><cell>Description</cell><cell>Type</cell></row><row><cell>Hydrophobicity</cell><cell>Numbers of C element</cell><cell>integer</cell></row><row><cell cols="3">Hydrogen Bond Center Numbers of O, N, S, P element integer</cell></row><row><cell cols="3">Negative Charge Center Numbers of F, Cl, Br, I element integer</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 .</head><label>5</label><figDesc>Molecule stability metrics on QM9. 3D: model generation in 3D space. Bond: model chemical bonds.</figDesc><table><row><cell>Method</cell><cell cols="2">3D Bond Valid (%) Unique (%)</cell></row><row><cell>GraphVAE</cell><cell>55.7</cell><cell>75.9</cell></row><row><cell>GTVAE</cell><cell>74.6</cell><cell>22.5</cell></row><row><cell>Set2Graph</cell><cell>59.9</cell><cell>93.8</cell></row><row><cell>E-NF</cell><cell>40.2</cell><cell>98.0</cell></row><row><cell>G-Schnet</cell><cell>85.5</cell><cell>93.9</cell></row><row><cell>EDM</cell><cell>91.9</cell><cell>98.7</cell></row><row><cell>HierDiff E (ours)</cell><cell>87.8</cell><cell>97.9</cell></row><row><cell>HierDiff P (ours)</cell><cell>83.6</cell><cell>98.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 .</head><label>6</label><figDesc>Molecule stability metrics on GEOMDRUGResults When testing the stability metrics on GEOM DRUG , our methods outperform EDM in stability, validity, and diversity.</figDesc><table><row><cell>Method</cell><cell cols="4">Mol Stability Unique Validity Diversity</cell></row><row><cell>EDM (without H)</cell><cell>0.970</cell><cell>1.000</cell><cell>0.835</cell><cell>0.824</cell></row><row><cell>HierDiff E (ours)</cell><cell>1.000</cell><cell>1.000</cell><cell>0.940</cell><cell>0.836</cell></row><row><cell>HierDiff P (ours)</cell><cell>1.000</cell><cell>0.995</cell><cell>0.904</cell><cell>0.832</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 .</head><label>7</label><figDesc>Properties of the fragments. All molecules are decomposed into fragments for statistical analysis. The model performs better if the generated fragments have more similar properties to GEOMDRUG.</figDesc><table><row><cell></cell><cell cols="5">Ring Size HeteroAtom AromaticRing AliphaticRing Radius</cell></row><row><cell>EDM</cell><cell>6.038</cell><cell>0.605</cell><cell>0.065</cell><cell>0.101</cell><cell>1.265</cell></row><row><cell>HierDiff E</cell><cell>5.749</cell><cell>0.630</cell><cell>0.104</cell><cell>0.083</cell><cell>1.295</cell></row><row><cell>HierDiff P</cell><cell>5.714</cell><cell>0.660</cell><cell>0.132</cell><cell>0.082</cell><cell>1.360</cell></row><row><cell cols="2">GEOM DRUG 5.747</cell><cell>0.677</cell><cell>0.134</cell><cell>0.066</cell><cell>1.351</cell></row></table><note><p>Figure 8. Histogram of the sampled molecules' ring size frequency of our model, EDM, and GEOMDRUG</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>on this uniqueness and diversity test. It should be noted that both our method and EDM generate mostly unique molecules when training on GEOM DRUG . These methods succeed to generate diverse 3D molecules. Combining to results from Table1, our method is able to generate 3D molecules that are drug-like and diverse.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 .</head><label>8</label><figDesc>Diversity metrics computed on 1000 drug-like molecules generated by our method with two types of coarse feature and EDM<ref type="bibr" target="#b16">(Hoogeboom et al., 2022)</ref>.</figDesc><table><row><cell cols="5">Similarity-atom ? Unique-atom ? Similarity-scaffold ? Unique-scaffold ?</cell></row><row><cell>EDM</cell><cell>0.176</cell><cell>1.000</cell><cell>0.189</cell><cell>0.930</cell></row><row><cell>HierDiff E</cell><cell>0.164</cell><cell>1.000</cell><cell>0.171</cell><cell>0.957</cell></row><row><cell>HierDiff P</cell><cell>0.168</cell><cell>1.000</cell><cell>0.169</cell><cell>0.946</cell></row><row><cell>C.6. Conditional generation</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>Results and Disscusions To make fair comparison, we excluded HierDiff-P for property-conditional generation since it already implies fragment properties. For example, aromatic rings and topological surfaces are related to logP and SAS. The results illustrate that our model outperforms EDM on Asphericity, SAS, and LogP in generating 3D molecules with accurate properties. EDM outperforms HierDiff in the accuracy of the QED conditioned generation task and the diversity in other metrics by an almost negligible margin.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>QED</cell><cell></cell><cell>SAS</cell><cell></cell><cell>log P</cell><cell></cell></row><row><cell>.</cell><cell>MSE</cell><cell>MAE</cell><cell>Div</cell><cell>MSE MAE</cell><cell>Div</cell><cell>MSE MAE</cell><cell>Div</cell><cell>MSE MAE</cell><cell>Div</cell></row><row><cell>EDM</cell><cell>0.626</cell><cell>0.455</cell><cell cols="7">0.895 0.113 0.285 0.883 0.074 0.193 0.897 6.054 2.019 0.883</cell></row><row><cell cols="2">HierDiff-E 0.176</cell><cell>0.406</cell><cell cols="7">0.894 0.120 0.289 0.885 0.051 0.184 0.881 1.405 0.976 0.882</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 9 .</head><label>9</label><figDesc>Properties of the generated molecules. ? indicates that the evaluated metrics are computed as the difference between sampled molecules and the ground truth and the absolute values are listed in the (). '-r' is the notation that this model sample molecule without any iterative refinement.QED? RA? MCF? SAS? ? LogP ? (logP) ? MW ? (MW)</figDesc><table><row><cell cols="2">HierDiff E (-r) 0.628 0.626 0.681 3.669</cell><cell>0.638 (2.291)</cell><cell>27.33 (332.8)</cell></row><row><cell cols="2">HierDiff P (-r) 0.635 0.638 0.656 3.512</cell><cell>0.185 (2.744)</cell><cell>10.33 (349.8)</cell></row><row><cell>HierDiff E</cell><cell>0.632 0.548 0.727 3.859</cell><cell>0.653 (2.276)</cell><cell>30.33 (329.8)</cell></row><row><cell>HierDiff P</cell><cell>0.639 0.643 0.659 3.547</cell><cell>0.128 (2.801)</cell><cell>13.33 (346.8)</cell></row><row><cell>GEOM DRUG</cell><cell>0.658 0.915 0.774 4.018</cell><cell>0.000 (2.929)</cell><cell>0.000 (360.1)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 10 .</head><label>10</label><figDesc>Properties of the generated molecules generated by different fragmentation strategies. ? indicates that the evaluated metrics are computed as the difference between sampled molecules and the ground truth and the absolute values are listed in the ().</figDesc><table><row><cell>EDM</cell><cell>0.608 0.441</cell><cell>0.621</cell><cell>4.054</cell><cell>0.566</cell><cell>23.71</cell><cell>0.835</cell></row><row><cell>Minimum Spanning Tree</cell><cell>0.639 0.639</cell><cell>0.659</cell><cell>3.574</cell><cell>0.128</cell><cell>13.33</cell><cell>0.904</cell></row><row><cell cols="2">High-frequency Fragments 0.609 0.632</cell><cell>0.662</cell><cell>3.638</cell><cell>0.228</cell><cell>9.80</cell><cell>0.853</cell></row><row><cell>Single Rings and Bonds</cell><cell>0.621 0.600</cell><cell>0.745</cell><cell>3.756</cell><cell>0.680</cell><cell>7.81</cell><cell>0.932</cell></row><row><cell cols="2">C.8. Discussion on Sampling Efficiency</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p>Fragmentize Methods</p>QED ? RA ? MCF ? SAS ? ? Log ? ? MW ? Validity ?</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 11 .</head><label>11</label><figDesc>Computational time for sampling 3D molecules using different models</figDesc><table><row><cell>Sample time per sample (s)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>The detailed experimental procedure is described in Appendix C.1.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was supported by the <rs type="funder">National Key R&amp;D Program of China</rs> (No. <rs type="grantNumber">2021YFF1201600</rs>), <rs type="funder">Tsinghua University</rs> (NO.<rs type="grantNumber">20221080053</rs>), <rs type="funder">Vanke Special Fund for Public Health and Health Discipline Development, and Beijing Academy of Artificial Intelligence(BAAI)</rs>. <rs type="person">Minkai Xu</rs> thanks the generous support of <rs type="grantName">Sequoia Capital Stanford Graduate Fellowship</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_ArsBPvm">
					<idno type="grant-number">2021YFF1201600</idno>
				</org>
				<org type="funding" xml:id="_TmvVp2W">
					<idno type="grant-number">20221080053</idno>
				</org>
				<org type="funding" xml:id="_dkNpjF2">
					<orgName type="grant-name">Sequoia Capital Stanford Graduate Fellowship</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Discussion on potential negative societal impact</head><p>Incorporating 3D information into molecule generation could have the potential to bring a significant impact on the drug discovery industry. One key limitation of applying machine learning/ generative model approaches to the area lies in the data bias, i.e., how the 3D conformation is obtained. Such limitations could make the model difficult to generalize in practical applications. Besides, to involve human feedback, it would be ideal for the model to be model interpretable. It could be hard to obtain interpretable knowledge from the proposed generative model. The safety issues should be well taken care of towards AI-guided drug discovery. The generalization ability of such methods is a lack of exploration. More consistent and comprehensive tests are needed before the clinical tests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Additional Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1. Experimental configuration</head><p>Both our model and the baseline model are trained on the GEOM DRUG <ref type="bibr" target="#b0">(Axelrod &amp; Gomez-Bombarelli, 2022)</ref>, Cross-Docked2020 <ref type="bibr" target="#b9">(Francoeur et al., 2020)</ref> and QM9 <ref type="bibr" target="#b0">(Axelrod &amp; Gomez-Bombarelli, 2022)</ref>. In GEOM DRUG experiments, we randomly selected 4 conformations of each molecule to train our model. To test EDM <ref type="bibr" target="#b16">(Hoogeboom et al., 2022)</ref>, we removed hydrogen atoms from the conformations and retrained the EDM model. The implicit hydrogen atoms are reconstructed using RDkit after all other heavy atoms are generated. Because EDM only generates atom types and coordinates, a proportion of sampled molecules are not fully connected. The broken fragments were removed for numerical evaluation. In all non-autoregressive methods, the number of nodes used for sampling is drawn from the size distribution histogram calculated on the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conformation Generation</head><p>In this paragraph, we introduce the way to generate ground truth conformation using MD simulation. Firstly, 50 initial conformations are generated for each molecule graph using RDkit and optimized by MMF field. Then, these conformations are further optimized by MD software XTB, while the energy terms are computed for each conformation. At last, we choose the conformation with the minimum energy to sample the ground truth conformations using MD software CREST. To balance efficiency and accuracy, we set the level of optimization to 'normal' in the software for both energy computing and conformation sampling. It took approximately 16 days to generate conformations for 400 different molecules on a 128-core server.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2. Stability and Validity Evaluation</head><p>MetricsTo illustrate our model's capacity to generate chemically valid molecule structures, we conduct experiments to compare the validity and stability with baseline models. Since the baseline EDM model is not able to generate any valid molecule with full Hydrogen coordinates on GEOM DRUG , we compared our model with the EDM model that needs to sample Hydrogen coordinates with the help of RDkit. The mol stability is defined as the proportion of molecules that can be interpreted as valid molecules with all bonds and coordinates explicitly defined in RDkit. The validity is defined as the proportion of molecules that are connected rather than individual fragments in 3D space. Diversity measures the diversity of the generated molecules by calculating the average pairwise Tanimoto Morgan Fingerprint, following previous work <ref type="bibr">(Xie</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Geom, energyannotated molecular conformations for property prediction and molecular generation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Axelrod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gomez-Bombarelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific Data</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Geometric and physical quantities improve e(3) equivariant message passing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Brandstetter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hesselink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Van Der Pol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Bekkers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2110.02905" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Guacamol: benchmarking models for de novo molecular design</title>
		<author>
			<persName><forename type="first">N</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fiscato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Segler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Vaucher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and modeling</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1096" to="1108" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Caccia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Caccia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Charlin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.02549</idno>
		<title level="m">Language gans falling short</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multiscale planar graph generation</title>
		<author>
			<persName><forename type="first">V</forename><surname>Chauhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gutfraind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Safro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Network Science</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.08786</idno>
		<title level="m">Syntaxdirected variational autoencoder for structured data</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Molgan: An implicit generative model for small molecular graphs</title>
		<author>
			<persName><forename type="first">N</forename><surname>De Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kipf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.11973</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Relational attention: Generalizing transformers for graph-structured tasks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Diao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Loynd</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.05062</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Xor-cd: Linearly convergent constrained structure generation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xue</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2728" to="2738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Three-dimensional convolutional neural networks and a cross-docked data set for structure-based drug design</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Francoeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Masuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sunseri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Iovanisci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Koes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and modeling</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4200" to="4215" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multi-constraint molecule sampling for molecule optimization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><surname>Mimosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="125" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Symmetryadapted generation of 3d point sets for the targeted discovery of molecules</title>
		<author>
			<persName><forename type="first">N</forename><surname>Gebauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gastegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sch?tt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2302.01129</idno>
		<ptr target="https://proceedings.neurips.cc/paper/2019/file" />
	</analytic>
	<monogr>
		<title level="m">Curran Associates, Coarse-to-Fine: a Hierarchical Diffusion Model for Molecule Generation in 3D Inc</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Alch?-Buc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2019">2019. 2023</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>De novo molecular generation via connection-aware motif mining</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Molecular dynamics simulations</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Oostenbrink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Van Gunsteren</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0959-440X(02)00308-1</idno>
		<ptr target="https://www.sciencedirect.com/science/article/pii/S0959440X02003081" />
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Structural Biology</title>
		<idno type="ISSN">0959-440</idno>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="190" to="196" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Exposure bias versus self-recovery: Are distortions really incremental for autoregressive text generation</title>
		<author>
			<persName><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Glass</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.10617</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6840" to="6851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Argmax flows and multinomial diffusion: Learning categorical distributions</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hoogeboom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jaini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Forr?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2102.05379" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Hoogeboom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">G</forename><surname>Satorras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vignac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<title level="m">Equivariant diffusion for molecule generation in 3d</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Junction tree variational autoencoder for molecular graph generation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2323" to="2332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Learning multimodal graph-to-graph translation for molecular optimization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.01070</idno>
		<imprint>
			<date type="published" when="2018">2018b</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Hierarchical graph-to-graph translation for molecules</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11223</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Hierarchical generation of molecular graphs using structural motifs</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4839" to="4848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Torsional diffusion for molecular conformer generation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2206.01729" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A solution for the best rotation to relate two sets of vectors</title>
		<author>
			<persName><forename type="first">W</forename><surname>Kabsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Diffraction, Theoretical and General Crystallography</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="922" to="923" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
	<note>Acta Crystallographica Section A: Crystal Physics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Equivariant flows: exact likelihood generative learning for symmetric densities</title>
		<author>
			<persName><forename type="first">J</forename><surname>K?hler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>No?</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5361" to="5370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Grammar variational autoencoder</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Kusner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Paige</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hern?ndez-Lobato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1945" to="1954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Molgrow: A graph normalizing flow for hierarchical molecular generation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kuznetsov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Polykovskiy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="8226" to="8234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Efficient learning of non-autoregressive graph variational autoencoders for molecular graph generation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-J</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cheminformatics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">From streamlined combinatorial search to efficient constructive procedures</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Selman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="499" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Learning deep generative models of graphs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.03324</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multi-objective de novo drug design with conditional graph generative model</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of cheminformatics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Structure-based de novo drug design using 3d deep generative models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemical science</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">41</biblScope>
			<biblScope unit="page" from="13664" to="13675" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Constrained graph variational autoencoders for molecule design</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Allamanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gaunt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A 3d generative model for structure-based drug design</title>
		<author>
			<persName><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="6229" to="6239" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An autoregressive flow model for 3d molecular geometry generation from scratch</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=C03Ajc-NS5W" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Hdmapgen: A hierarchical graph generative model of high definition maps</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shavit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4227" to="4236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">A graph vae and graph transformer approach to generating molecular graphs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mitton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Senn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wynne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Murray-Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.04345</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Pocket2mol: Efficient molecular sampling based on 3d protein pockets</title>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.07249</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Popova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shvets</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Isayev</surname></persName>
		</author>
		<author>
			<persName><surname>Molecularrnn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.13372</idno>
		<title level="m">Generating realistic molecular graphs with optimized properties</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Fragmentbased ligand generation guided by geometric deep learning on protein-ligand structure</title>
		<author>
			<persName><forename type="first">A</forename><surname>Powers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suriana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dror</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Generating realistic 3d molecules with an equivariant conditional likelihood model</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Roney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maragakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Skopp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Shaw</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=Snqhqz4LdK" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">E(n) equivariant graph neural networks</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">G</forename><surname>Satorras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hoogeboom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2102.09844" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">G</forename><surname>Satorras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hoogeboom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">B</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Posner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Generalization in generation: A closer look at exposure bias</title>
		<author>
			<persName><forename type="first">F</forename><surname>Schmidt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.00292</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">A continuousfilter convolutional neural network for modeling quantum interactions</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Sch?tt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-J</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Sauceda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chmiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tkatchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName><surname>Schnet</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1706.08566</idno>
		<ptr target="https://arxiv.org/abs/1706.08566" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Generating focused molecule libraries for drug discovery with recurrent neural networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Segler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kogej</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tyrchan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Waller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACS central science</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="120" to="131" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Threedimensional compound comparison methods and their application in drug discovery</title>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Bures</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kihara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Molecules</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="12841" to="12862" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Graphvae: Towards generation of small graphs using variational autoencoders</title>
		<author>
			<persName><forename type="first">M</forename><surname>Simonovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on artificial neural networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="412" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Deep unsupervised learning using nonequilibrium thermodynamics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Maheswaranathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1503.03585" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds</title>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Smidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kohlhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Riley</surname></persName>
		</author>
		<idno>CoRR, abs/1802.08219</idno>
		<ptr target="http://arxiv.org/abs/1802.08219" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Score-based generative modeling in latent space</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kreis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="11287" to="11302" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Top-n: Equivariant set and graph generation without exchangeability</title>
		<author>
			<persName><forename type="first">C</forename><surname>Vignac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.02096</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Regularized molecular conformation fields</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fuxin</surname></persName>
		</author>
		<author>
			<persName><surname>Pointconv</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1811.07246" />
		<title level="m">Deep convolutional networks on 3d point clouds</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Hierarchical recurrent neural networks for graph generation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Xianduo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yuyuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xianglin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ying</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">589</biblScope>
			<biblScope unit="page" from="250" to="264" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Mars</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.10432</idno>
		<title level="m">Markov molecular sampling for multi-objective drug discovery</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Protein homology detection through alignment of markov random fields: using MR-Falign</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><surname>Geodiff</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.02923</idno>
		<title level="m">A geometric diffusion model for molecular conformation generation</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Molecule generation for drug design: a graph learning perspective</title>
		<author>
			<persName><forename type="first">N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.09212</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Diffusion probabilistic modeling for video generation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mandt</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2203.09481" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Hit and lead discovery with explorative rl and fragment-based molecule generation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Vaughan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2021/file/41" />
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">W</forename></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2021">2021. 2023</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="7924" to="7936" />
		</imprint>
	</monogr>
	<note>Advances in Neural Information Processing Systems</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Misc-gan: A multiscale generative model for graphs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in big Data</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Uni-mol: A universal 3d molecular representation learning framework</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
