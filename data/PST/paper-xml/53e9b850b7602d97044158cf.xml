<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fast image deconvolution using closed-form thresholding formulas of L q ðq ¼ 1 2 ; 2 3 Þ regularization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2012-11-05">5 November 2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Wenfei</forename><surname>Cao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematics and Statistics</orgName>
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
								<address>
									<postCode>710049</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
							<email>jiansun@mail.xjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematics and Statistics</orgName>
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
								<address>
									<postCode>710049</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zongben</forename><surname>Xu</surname></persName>
							<email>zbxu@mail.xjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematics and Statistics</orgName>
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
								<address>
									<postCode>710049</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Fast image deconvolution using closed-form thresholding formulas of L q ðq ¼ 1 2 ; 2 3 Þ regularization</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2012-11-05">5 November 2012</date>
						</imprint>
					</monogr>
					<idno type="MD5">5550AC24EB0B61CC9F783CF7C65AA3D7</idno>
					<idno type="DOI">10.1016/j.jvcir.2012.10.006</idno>
					<note type="submission">Received 3 April 2012 Accepted 29 October 2012</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T04:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Sparsity L1 2 regularization L2 3 regularization Variable splitting Image deconvolution L 0 regularization L 1 regularization Thresholding formula</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we focus on the research of fast deconvolution algorithm based on the non-convex L q ðq ¼ 1 2 ; 2 3 Þ sparse regularization. Recently, we have deduced the closed-form thresholding formula for L1 2 regularization model (Xu (2010) <ref type="bibr" target="#b1">[1]</ref>). In this work, we further deduce the closed-form thresholding formula for the L2 3 non-convex regularization problem. Based on the closed-form formulas for L q ðq ¼ 1 2 ; 2 3 Þ regularization, we propose a fast algorithm to solve the image deconvolution problem using half-quadratic splitting method. Extensive experiments for image deconvolution demonstrate that our algorithm has a significant acceleration over Krishnan et al.'s algorithm (Krishnan et al. (2009) [3]). Moreover, the simulated experiments further indicate that L2 3 regularization is more effective than L 0 ; L1 2 or L 1 regularization in image deconvolution, andL1 2 regularization is competitive to L 1 regularization and better than L 0 regularization.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Image blur is a common artifact in digital photography caused by camera shake or object movement. Recovering the un-blurred sharp image from the blurry image, which is generally called image deconvolution, has been a fundamental research problem in image processing and computational photography. Image deconvolution algorithms <ref type="bibr" target="#b4">[4]</ref><ref type="bibr" target="#b5">[5]</ref><ref type="bibr" target="#b6">[6]</ref> can be categorized to blind deconvolution and non-blind deblurring, in which the blur kernel is unknown and known respectively. Tremendous methods have been proposed to estimate the blur kernel. In this work, we focus on the non-blind deblurring problem, i.e., recovering the sharp image from a blurry image given the blur kernel.</p><p>Mathematically, blurry image can be modeled as the convolution of an ideal sharp image with a blur kernel and then adding zero mean Gaussian white noise. The degraded process can be modeled as</p><formula xml:id="formula_0">Y ¼ X k þ n ð1:1Þ</formula><p>where X is the sharp image, k is a blur kernel and n is the noise. Image deconvolution aims to recover a high quality image X, given a blurry image Y.</p><p>The ill-posed nature of this problem implies that additional assumption on X should be introduced. Recently, many kinds of image priors are discovered and utilized to regularize this ill-posed inverse problem, such as the total variation <ref type="bibr" target="#b7">[7]</ref>, nonlocal self-similarity <ref type="bibr" target="#b8">[8]</ref><ref type="bibr" target="#b9">[9]</ref><ref type="bibr" target="#b10">[10]</ref>, sparse prior <ref type="bibr" target="#b11">[11]</ref><ref type="bibr" target="#b12">[12]</ref><ref type="bibr" target="#b13">[13]</ref> and so on. Especially, the sparsity induced by nonconvex non-convex regularization or the hyper-Laplacian distribution from probabilistic point of view attracts a lot of attention in the community of computer vision <ref type="bibr" target="#b14">[14]</ref>, machining learning and compressive sensing <ref type="bibr" target="#b15">[15]</ref><ref type="bibr" target="#b16">[16]</ref><ref type="bibr">[17]</ref>. These prior models give rise to surprising results. For example, Chartrand <ref type="bibr">[17,</ref><ref type="bibr" target="#b18">18]</ref> applies non-convex regularization to the Magnetic Resonance Imaging (MRI) reconstruction task, bringing about promising results that only few samples in K-data space can effectively reconstruct the MRI image.</p><p>In this paper, we work on the fast image deconvolution algorithm with non-convex regularization to suppress ringing artifacts and noises. The idea is motivated by Krishnan's work in <ref type="bibr" target="#b3">[3]</ref>, in which hyper-Laplacian prior of natural image is imposed on the image non-blind deconvolution algorithm, which is equivalent to solving an inverse linear optimization problem with L q -norm (0 &lt; q &lt; 1) non-convex regularization. Using quadratic splitting framework, one sub-problem is to optimize the non-convex regularization problem:</p><p>x Ã ¼ argmin x fðx À aÞ 2 þ kjxj q g: ð1:2Þ</p><p>This sub-problem actually is a very special case of the problem proposed by Elad <ref type="bibr" target="#b25">[25]</ref> in the context of sparse representation and by Chartrand <ref type="bibr" target="#b15">[15]</ref><ref type="bibr" target="#b16">[16]</ref><ref type="bibr">[17]</ref> in the setting of compressive sensing. According to their work, from the geometric point of view, this solution is just the intersection point between a hyperplane and a L q ð0 &lt; q &lt; 1Þ ball, and when q goes closer to zero, the solution of this problem , Krishnan et al. <ref type="bibr" target="#b3">[3]</ref> proposed to solve the above problem by presenting some clever discriminate conditions to compare and select optimal solution from the multiple roots of the first-order derivative equation of the cost function. Although this method makes this problem undertake a major breakthrough, multiple roots should be computed and compared to produce the final solution. A natural question is whether we could derive the closed-form thresholding formulas for non-convex regularization with q ¼ 1 2 or 2 3 in 0 &lt; q &lt; 1, in parallel to the well-known hard/soft thresholding formulas for q ¼ 0 or 1.</p><p>In this work, we will present the closed-form thresholding formulas for non-convex regularization problem in Eq. (1.2) with q ¼ 2 3 or 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>, and apply them to solve the image deconvolution problem. It has been found that the gradients of natural images are distributed as heavy-tailed hyper-Laplacian distribution pðxÞ / e Àkjxj q with 0:5 6 q 6 0:8. In the Bayesian framework, this prior will impose the L q norm non-convex regularization for the inverse problem with the formulation in Eq. (1.2). Therefore, developing a fast algorithm for L1 2 or L2 3 regularization problem in the range of 0:5 6 q 6 0:8 can be expected to be promising in image deconvolution task. The contribution of this work can be summarized as:</p><p>We deduce the closed-form thresholding formula for linear inverse model with L2 We believe that the closed-form thresholding formulas for L2 3 or L1 2 non-convex regularization are important to machine learning and computer vision communities beyond the application of image deconvolution. That is because this linear inverse problem with non-convex regularization is a general model with wide applications for compressive sensing <ref type="bibr" target="#b16">[16,</ref><ref type="bibr">17]</ref>, image demosaicing <ref type="bibr" target="#b14">[14]</ref>, image super-resolution <ref type="bibr" target="#b14">[14]</ref>, etc. Moreover, theoretically, the closedform formulas make the theoretical analysis of the non-convex regularization problem possible or easier, which deserves to be investigated in our future work.</p><p>The remainder of this paper can be organized as follows. Section 2 will describe the image deconvolution model based on non-convex regularization and its optimization using half-quadratic splitting scheme; In Section 3, we will deduce the thresholding formula for L q q ¼ 2 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>À</head><p>Á regularization problem and also introduce our previously proposed thresholding formula for L q q ¼ 1 2 À Á regularization problem. Then we will present our deconvolution algorithm with L q ðq ¼ 1 2 ; 2 3 Þ regularization; In Section 4, we will report the experimental results in both speed and quality; Finally, this paper is concluded in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Image deconvolution based on non-convex regularization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Formulation</head><p>Assuming that X is the original uncorrupted grayscale image with N pixels; Y is an image degraded by blur kernel k and noise n:</p><formula xml:id="formula_1">Y ¼ X k þ n ð2:<label>1Þ</label></formula><p>Non-blind deconvolution aims to restore the real image X given the known or estimated blur kernel k. Due to the ill-posedness of this task, prior information of natural images should be utilized to regularize the inverse problem <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b3">3]</ref>. In this work, we utilize the sparse hyper-Laplacian distribution prior of nature image in the gradient domain <ref type="bibr" target="#b3">[3]</ref>, i.e.,</p><p>pðXÞ / e Às X 2 j¼1 jjXf j jj q q ; ð2:2Þ</p><p>where jjzjj q ¼ ð P i ðzÞ q i Þ 1 q ; denotes convolution, f 1 ¼ ½1; À1 and f 2 ¼ ½1; À1 T are two first-order derivative filters and 0 &lt; q &lt; 1. From the probabilistic perspective, we seek the MAP (maximum-a posteriori) estimate of X in Bayesian framework: pðXjY; kÞ / pðYjX; kÞPðXÞ, the first term is the Gaussian likelihood and the second term is the hyper-Laplacian image prior. Maximizing pðXjY; kÞ is equivalent to minimizing</p><formula xml:id="formula_2">X Ã ¼ argmin X k 2 jjX k À Yjj 2 F þ X 2 j¼1 jjX f j jj q q ( ) ð2:3Þ where jjAjj F ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi P M i¼1 P N j¼1 a 2 ij q</formula><p>indicates the Frobenious norm. If assume that x and y are vectors stretched from X and Y column by column, and K; F 1 and F 2 are the matrix form of the filters k; f 1 and f 2 for image convolution, then problem (2.3)can be equivalently represented as</p><formula xml:id="formula_3">x Ã ¼ argmin x k 2 jjKx À yjj 2 2 þ jjF 1 xjj q q þ jjF 2 xjj q q &amp; ' ð2:4Þ</formula><p>where k makes a trade-off between the fidelity term and the regularization term. When 0 6 q &lt; 1; jjFxjj q ¼ P i ðFxÞ q i À Á 1 q imposes nonconvex regularization on the image gradients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Half-quadratic splitting algorithm</head><p>Using the half-quadratic splitting method, Krishnan et al., <ref type="bibr" target="#b3">[3]</ref> introduced two auxiliary variables u 1 and u 2 and the problem (2.4) can be converted to the following optimization problem</p><formula xml:id="formula_4">x Ã ¼ argmin x k 2 jjKx À yjj 2 2 þ b 2 jjF 1 x À u 1 jj 2 2 þ b 2 jjF 2 x À u 2 jj 2 2 &amp; þ jju 1 jj q q þ jju 2 jj q q o ð2:5Þ</formula><p>where b is a control parameter. As b ! 1, the solution of problem(2.5) converges to that of Eq. (2.4). Minimizing Eqn. (2.5) for a fixed b can be performed by alternating two steps: one sub-problem is to solve x, given u 1 and u 2 , which is called x-subproblem; the other sub-problem is to solve u 1 ; u 2 , given x, which is called u-subproblem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1.">x-Subproblem</head><p>Given u 1 and u 2 , the x-subproblem aims to obtain the optimal x by optimizing the energy function Eq. (2.5), which is to optimize:</p><formula xml:id="formula_5">x Ã ¼ argmin x fkjjKx À yjj 2 2 þ bjjF 1 x À u 1 jj 2 2 þ bjjF 2 x À u 2 jj 2 2 g</formula><p>The subproblem can be optimized by setting the first derivative of the cost function to zero:</p><formula xml:id="formula_6">F T 1 F 1 þ F T 2 F2 þ k b K T K x ¼ F T 1 u 1 þ F T 2 u 2 þ k b K T y ð2:6Þ</formula><p>where Kx ¼ X k. Assuming circular boundary conditions, we can apply 2D FFT to efficiently obtain the optimal solution x as:</p><formula xml:id="formula_7">IFFT FFTðF 1 Þ Ã FFTðu 1 Þ þ FFTðF 2 Þ Ã FFTðu 2 Þ þ k b FFTðKÞ Ã FFTðyÞ FFTðF 1 Þ Ã FFTðF 1 Þ þ FFTðF 2 Þ Ã FFTðF2Þ þ k b FFTðKÞ Ã FFTðKÞ ! ð2:7Þ</formula><p>where Ã denotes the complex conjugate, denotes the componentwise multiplication, and the division is also performed in component-wise fashion. The fast fourier transform of F 1 ; F 2 ; K can be pre-computed, therefore solving Eq. (2.7) only requires 3 FFTs at each iteration, i.e., FFTðu 1 Þ, FFTðu 2 Þ; IFFTðÃÞ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2.">u-Subproblem</head><p>Given a fixed x, finding the optimal u 1 ; u 2 can be achieved by optimizing</p><formula xml:id="formula_8">u Ã i ¼ argmin u i b 2 jjF i x À u i jj 2 2 þ jju i jj q q &amp; '</formula><p>where i ¼ 1; 2. This optimization problem can be decomposed into 2N independent one-dimension L q regularization problems:</p><formula xml:id="formula_9">ðu Ã i Þ j ¼ argmin u juj q þ b 2 ðu À ðF i xÞ j Þ 2 &amp; ' ð2:8Þ</formula><p>where ðÁÞ j (j ¼ 1; . . . ; N) denotes the j-th component of a vector. It has been derived that the formulation of the closed-form solutions of the above problem are hard thresholding and soft-thresholding when q ¼ 0 and 1 respectively. For 0 &lt; q &lt; 1, it is challenging to derive the closed-form solution of this optimization problem. Krishnan et al. <ref type="bibr" target="#b3">[3]</ref> utilized Newton-Raphson method to optimize this problem for 0 &lt; q &lt; 1. Especially for q ¼ 1 2 or 2 3 cases, some discriminant rules are proposed to find global optimal solution by comparing and selecting from roots of the first order derivative of the cost function in Eq. (2.8). Although it accelerated the optimization procedure without the need of numerous iterations as done by Newton-Raphson method, it still needs to compute and compare multiple roots using some discriminant rules.</p><p>In the next section, we will present the closed-form thresholding formulas for the global optimal solution of Eq. (2.8) with q ¼ 1 2 ; 2 3 . These formulas not only further speed up the deconvolution algorithm, but also can be easily extended to other applications in signal/image processing, e.g., denoising or superresolution, since Eq. (2.8) is a general non-convex regularization model in these applications. We first review our previous work on the closed-form thresholding formula for L1 2 regularization problem <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b2">2]</ref>, i.e., to solve:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Image deconvolution based on closed-form thresholding formulas of L1</head><formula xml:id="formula_10">x Ã ¼ argmin x fðx À aÞ 2 þ kjxj 1 2 g ð 3:1Þ</formula><p>where the variables is scalar values instead of vectors. This optimization problem has the closed-form thresholding formula: Next, we will derive the closed-form thresholding formula for the L2 3 regularization problem.</p><formula xml:id="formula_11">x Ã ¼ 2 3 jaj 1 þ cos 2p 3 À 2u k ðaÞ 3 if a &gt; pðkÞ 0 i f jaj 6 pðkÞ À 2 3 jaj 1 þ cos 2p 3 À 2u k ðaÞ 3 if a &lt; ÀpðkÞ 8 &gt; &gt; &gt; &lt; &gt; &gt; &gt; :<label>ð3</label></formula><p>3.1. The thresholding formula for L2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">regularization</head><p>The L2</p><formula xml:id="formula_12">3 regularization model is x Ã ¼ argmin x f ðxÞ ¼ ðx À aÞ 2 þ kjxj 2 3</formula><p>n o ð3:3Þ</p><p>Our aim is to seek the minimum point of f ðxÞ, denoted as x Ã . In the following, we will first present two lemmas, Lemma 3.1 and Lemma 3.2; And then, based on the two lemmas, we derive the minimum point of f ðxÞ when x -0 in Lemma 3.3; Finally, by the Lemma 3.1 and Lemma 3.3, we derive the minimum point of f ðxÞ when x 2 R in Theorem 3.4.</p><p>Lemma 3.1. The minimum point x Ã of f ðxÞ in Eq. (3.3) satisfies the following properties:</p><formula xml:id="formula_13">1. If a P0, then x Ã 2 [0, a]; 2. If a &lt; 0, then x Ã 2 [a, 0).</formula><p>Proof. We only prove the case (1), and case (2) can be proved in the same way. If assuming x Ã &lt; 0, without the loss of generality, let x Ã ¼ ÀMðM &gt; 0Þ, then we have</p><formula xml:id="formula_14">f ðx Ã Þ ¼ f ðÀMÞ ¼ ðÀM À aÞ 2 þ kðj À Mj 2 3 Þ ¼ ðM þ aÞ 2 þ kjMj 2 3 &gt; a 2 ¼ f<label>ð0Þ</label></formula><p>. This obviously contradicts the fact that x Ã is a minimum point. On the other hand, if assuming x Ã &gt; a and let x Ã ¼ a+4 (4&gt;0), then we have This also leads to contradiction with the fact that x Ã is a minimum point. Hence, x Ã 2 [0, a] for case <ref type="bibr" target="#b1">(1)</ref>. Proof. The proof of d 1 Ã d 2 &lt;0 is equivalent to the proof of A 6 &lt; 4a 2 . We now prove that A 6 &lt; 4a 2 . Let sðtÞ ¼ t 1=3 ðt P 0Þ. It is easy to verify that sðtÞ is concave, then we can obtain the inequality where k &gt;0 and a2 R, if x -0, then the minimum point of f ðxÞ can be represented as: </p><formula xml:id="formula_15">f ðx Ã Þ ¼ f ða þ 4Þ ¼ 4 2 þ kja þ 4j 2 3 &gt; kjaj 2 3 ¼ f ðaÞ: -1 -0.5 0 0.5 1 -1 -0.</formula><formula xml:id="formula_16">h Lemma 3.2. Assume that d 1 ¼ À A 2 þ 2 a A and d 2 ¼ À A 2 À 2 a A , where jAj ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi a 2 2 þ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi a 4 4 À 4 3 27 2 k 3 s 0 @ 1 A 1 3 þ a 2 2 À ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi a 4 4 À 4 3 27 2 k 3 s 0 @ 1 A 1 3 v u u u t and jaj &gt; 4 ffiffiffiffi 27 p k 3 4 , then d 1 Ã d 2 &lt; 0.</formula><formula xml:id="formula_17">sð t 1 þt 2 2 Þ &gt; sðt 1 Þþsðt 2 Þ 2 . By setting t 1 ¼ a 2 2 þ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi a 4 4 À 4 3 27 2 k 3 q , t 2 ¼ a 2 2 À ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi a 4 4 À 4 3 27 2 k 3 q (obviously,</formula><formula xml:id="formula_18">x ¼ jAjþ ffiffiffiffiffiffiffiffiffiffiffiffi 2jaj jAj ÀjAj 2 q 2 0 @ 1 A 3 if a &gt; sðkÞ À jAjþ ffiffiffiffiffiffiffiffiffiffiffiffi 2jaj jAj ÀjAj 2 q 2 0 @ 1 A 3 if a &lt; ÀsðkÞ 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : where jAj ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi a 2 2 þ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi a 4 4 À 4 3 27 2 k 3 s 0 @ 1 A 1 3 þ a 2 2 À ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi a 4 4 À 4 3 27 2 k 3 s 0 @ 1 A 1 3 v u u u t ; sðkÞ ¼ 4 ffiffiffiffiffiffi 27 p k</formula><formula xml:id="formula_19">x Ã ¼ jAjþ ffiffiffiffiffiffiffiffiffiffiffiffi 2jaj jAj ÀjAj 2 q 2 0 @ 1 A 3 if a &gt; pðkÞ 0 i f jaj 6 pðkÞ À jAjþ ffiffiffiffiffiffiffiffiffiffiffiffi 2jaj jAj ÀjAj 2 q 2 0 @ 1 A 3 if a &lt; ÀpðkÞ 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : ð3:4Þ where jAj ¼ 2 ffiffiffi 3 p k 1 4 cosh / 3 1 2 ; / ¼ arccosh 27a 2 16 k À 3 2 ; pðkÞ ¼ 2 3 ð3k 3 Þ 1 4 :</formula><p>Proof. Please refer to Appendix B for the proof. h In Fig. <ref type="figure" target="#fig_3">1</ref>, we plot the closed-form thresholding formulas for the optimal solutions of L q regularization problem x Ã ¼ argmin x fðxÀ aÞ 2 þ kjxj q g when q ¼ 0; 1 2 ; 2 3 ; 1 respectively. The x-coordinate and y-coordinate in these sub-figures correspond to a and x Ã respectively. We can observe that the thresholding curves of L1 2 ; L2 3 regularization problems lie between the curves of the traditional soft thresholding (L 1 regularization) and hard thresholding (L 0 regularization).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Image deconvolution algorithm</head><p>Given the closed-form thresholding formulas for L1 2 ; L2 3 regularization problems, the optimal solutions of Eq. (2.8) with q ¼ 1 2 ; 2 3 in u-subproblem can be efficiently computed by the thresholding formulas in Eqs. (3.2) and (3.4) with x ¼ u; k ¼ 2 b ; a ¼ ðF i xÞ j . Now both the x-subproblem and u-subproblem in the quadratic splitting algorithm in Section 2.2 can be efficiently computed in  closed-form formulation, then the final algorithm for image deconvolution is shown in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we will conduct several groups of experiments to demonstrate that the proposed deconvolution algorithm enables significantly faster speed over Krishnan et al's algorithm <ref type="bibr" target="#b3">[3]</ref>. Moreover, by extensive experiments, we will show that L2 3 regularization is more effective for image deconvolution than L 0 ; L1 2 or L 1 regularization, and L1 2 regularization is competitive to L 1 regularization and better than L 0 regularization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experiment setting</head><p>Our test natural images are collected from two sources: (1) the standard test images for image processing with size of 521 Â 512;</p><p>(2) the high-resolution images from web site of http://www.flickr.com/. The images from the second source are commonly with larger resolutions to test the ability for our algorithm to handle large images. We list all the test images in Fig. <ref type="figure" target="#fig_4">2</ref>. All the test images are blurred by real-world camera shake kernels from <ref type="bibr" target="#b22">[22]</ref>, and the blur kernels are shown in Fig. <ref type="figure" target="#fig_0">3</ref> (the images are scaled for better illustration). To better simulate the real-captured blurry image, we also add Gaussian noises with standard deviation of 0.01 to the blurry image and followed by quantization to 255 discrete values. The PSNR defined as 10log 10 255 2   MSEðxÞ is employed to evaluate the deconvolution performance, where x is the deconvolution result and MSEðxÞ denotes the mean square error between x and the ground-truth high quality image. In our implementation, edge tapering operation is utilized to reduce the possible boundary artifacts. To compare the best potential performance of different regularization algorithms, we set b inc ¼ ffiffiffi 2 p and k ¼ 2 b to the optimal value in a range of values with best PSNR performance as in <ref type="bibr" target="#b3">[3]</ref>. Our experiments are executed using Matlab software on desktop computer with 2.51 GHz AMD CPU (dual core) and 1.87 GB RAM.</p><p>Algorithm 1. Fast Image Deconvolution Using Closed-Form Thresholding Formulas of L q ðq ¼ 1 2 ; 2 3 Þ Regularization Input: Blurred image y; blur kernel k; regularization weight k; q= 1 2 or 2 3 ;b 0 ; b Inc ; b M ; maximal number of outer iterations T; number of inner iterations J.</p><p>Step 1: Initialize iter = 0, x ¼ y and b ¼ b 0 , pre-compute constant terms in Eq. (2.7).</p><p>Step 2: repeat iter = iter + 1. for i = 1 to J do x-subproblem: optimize x according to Eq. (2.7). u-subproblem: optimize u 1 ; u 2 according to Eq. (3.2) or (3.4) when q= 1 2 or 2 3 . </p><formula xml:id="formula_20">endfor b ¼ b inc Ã b. until b &gt; b M or iter &gt; T. Output: x.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Comparison for speed</head><p>In this experiment, we will evaluate the speed of our algorithm compared to the Krishnan's algorithm (without the look-up table technique) <ref type="bibr" target="#b3">[3]</ref>. It has been shown in <ref type="bibr" target="#b3">[3]</ref> that the speed of other methods such as re-weighted method is slower than Krishnan's algorithm. We test the algorithms on images with varying resolutions. Our proposed deconvolution algorithms using L1 3 respectively whereas the corresponding algorithms proposed in <ref type="bibr" target="#b3">[3]</ref>   <ref type="table" target="#tab_1">1</ref> and<ref type="table" target="#tab_10">Table 2</ref>, the small standard deviations and the similar acceleration results for two different sizes of kernels manifest that the acceleration speed is stable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Evaluation for different regularization</head><p>To compare the performance of different regularization algorithms, we conduct eight groups of experiments for different kernels. For each kernel, we evaluate the deconvolution performance over the 20 test images shown in Fig. <ref type="figure" target="#fig_4">2</ref>. Because of the space restriction, we only list two groups of recovery results, as showed in Table <ref type="table">3</ref> and<ref type="table">Table 4</ref>. From Table <ref type="table">3</ref> and Table <ref type="table">4</ref>, we find that, first, the deconvolution results using L2   the L1 2 regularization is competitive to L 1 regularization and better than L 0 regularization for image deconvolution. We also present the average PSNR results over all the test images for each kernel in Table <ref type="table" target="#tab_4">5</ref>. From Table <ref type="table" target="#tab_4">5</ref>, we can also draw the consistent conclusions though the blur kernels are different in both shape and resolution.</p><p>To further test the performance of our algorithm, we evaluate the deconvolution results for each image over eight different kernels. Similarly, we only list two groups of experiment over two test images o and p, the results are shown in Table <ref type="table" target="#tab_5">6</ref> and Table <ref type="table" target="#tab_6">7</ref>. From Table <ref type="table" target="#tab_5">6</ref> and Table <ref type="table" target="#tab_6">7</ref>, we can derive the same conclusions. We show two of the deconvolution results in Fig. <ref type="figure" target="#fig_9">4</ref> and Fig. <ref type="figure" target="#fig_12">5</ref>, it is shown that the deblurred images using L q ðq ¼ 1 2 ; 2 3 Þ regularization algorithm is clearly with higher visual quality with less noises/ringing artifacts compared to L 0 or L 1 regularization algorithm.</p><p>In summary, extensive experiments demonstrate that our deconvolution algorithm with L q ðq ¼ 1 2 ; 2 3 Þ regularization enables significantly faster speed over Krishnan's algorithm <ref type="bibr" target="#b3">[3]</ref>, while L2 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and future work</head><p>In this paper, we derived the closed-form thresholding formula for L2 3 regularization problem. Based on this thresholding formula together with our previously derived thresholding formula for L1 2 regularization problem, we proposed a fast deconvolution algorithm using half quadratic splitting strategy. Extensive experiments demonstrate that our algorithm significantly speeds up the previous deconvolution algorithm in the same framework. And we also justified that L2 3 regularization is more powerful than L 1 ; L1 2 or L 0 regularization, and L1 2 regularization is competitive to L 1 regularization and better than L 0 regularization for image deconvolution.</p><p>The derived thresholding formula in this work provides an effective way to optimize the non-convex regularization problem using closed-form formulation. The L2 3 regularization problem has wide applications beyond the image deconvolution, e.g., compressive sensing, super-resolution, denoising, etc. On the other hand, the derived thresholding formula can be extended to solve more complex regularization problem</p><formula xml:id="formula_21">xÃ ¼ argmin x fjjAx À ỹjj 2 þ kjjxjj q q g ð 5:1Þ</formula><p>where A is a matrix commonly composed of a set of basis in its columns, and x and ỹ are vectors of variables. This optimization problem is different to the problem in Eq. (1.2) that matrix A is introduced which makes vector of variables in x dependent on each other. This optimization problem has wide applications in image/signal processing such as dictionary learning <ref type="bibr" target="#b23">[23]</ref>, image restoration <ref type="bibr" target="#b12">[12]</ref>, etc. It can be fast optimized by iterative thresholding algorithm: xkþ1 ¼ T kt ðx k À 2tA T ðAx k À ỹÞÞ; t is an appropriate stepsize, T is the hard, soft and half thresolding operator when q ¼ 0; 1; 1 2 respectively <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b21">21,</ref><ref type="bibr" target="#b1">1,</ref><ref type="bibr" target="#b2">2]</ref>. Obviously, the proposed thresholding formula for L2  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 8</head><p>The triangle and hyperbolic expression for the roots of cubic equation</p><formula xml:id="formula_22">x 3 þ 3px þ 2q ¼ 0; p -0. let r ¼ sgnðqÞ ffiffiffiffiffi ffi jpj p p &lt; 0 p &gt; 0 q 2 þ p 3 &lt; 0 q 2 þ p 3 &gt; 0 cos u ¼ q r 3 cosh u ¼ q r 3 sinh u ¼ q r 3 x 1 ¼ À2r cos u 3 x 1 ¼ À2r cosh u 3 x 1 ¼ À2r sinh u 3 x 2 ¼ 2r cosð p 3 À u 3 Þ x 2 ¼ r cosh u 3 þ i ffiffiffi 3 p r sinh u 3 x 2 ¼ r sinh u 3 þ i ffiffiffi 3 p r cosh u 3 x 3 ¼ 2r cosð p 3 þ u 3 Þ x 3 ¼ r cosh u 3 À i ffiffiffi 3 p r sinh u 3 x 3 ¼ r sinh u 3 À i ffiffiffi 3 p r cosh u</formula><p>In the future work, we are interested in the analysis of the convergence of our deconvolution algorithm and plan to extend the applications of the thresholding formulas of L1 . In this case, h 1 ðyÞ has two different roots y 1 ; y 2 (y 1 &lt; y 2 ), and only y 2 satisfies Eq. (A.2) that corresponds to minimum point of f ðxÞ. In the following, we will seek y 2 by method of undetermined coefficients. Assume that  </p><formula xml:id="formula_23">h 1 ðyÞ ¼ y 4 À ay þ k 3 ¼ ðy 2 þ Ay þ BÞðy 2 þ Cy þ</formula><formula xml:id="formula_24">A þ C ¼ 0 ðA:4Þ B þ D þ AC ¼ 0 ðA:5Þ AD þ BC ¼</formula><formula xml:id="formula_25">(ii) when A -0, B þ D ¼ A 2 ðA:10Þ À B þ D ¼ À a A ðA:11Þ</formula><p>we can further obtain that,</p><formula xml:id="formula_26">B ¼ ðA 2 þ a A Þ 2 ðA:12Þ D ¼ ðA 2 À a A Þ<label>2</label></formula><p>ðA:13Þ</p><p>By substituting (A.12), (A.13) to (A.7), we get</p><formula xml:id="formula_27">ðA 2 þ a A Þ 2 Ã ðA 2 À a A Þ 2 ¼ k 3 .</formula><p>And still, by reduction and rearrangement, we obtain</p><formula xml:id="formula_28">A 6 À 4 3 kA 2 À a 2 ¼ 0. Let M ¼ A 2 , we get M 3 À 4 3 kM À a 2 ¼ 0 ðA:14Þ</formula><p>From the root discriminant formula of the triple equation, we get</p><formula xml:id="formula_29">D ¼ q 2 2 þ p 3 3 ¼ À a 2 2 2 þ À 4 9 k 3 ¼ a 4 4 À 4 3 9 3 k 3 !</formula><p>where q ¼ Àa 2 ; p ¼ À </p><formula xml:id="formula_30">¼ A 2 ¼ a 2 2 þ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi a 4 4 À 4 3 27 2 k 3 q 1 3 þ a 2 2 À ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi a 4 4 À 4 3 27 2 k 3 q 1 3</formula><p>. Right now, by (A.3), (A.4), (A.12), (A.13) and h 1 ðyÞ ¼ 0, we get</p><formula xml:id="formula_31">y 2 þ Ay þ ðA 2 þ a A Þ 2 ¼ 0 ðA:15Þ y 2 À Ay þ ðA 2 À a A Þ 2 ¼ 0 ðA:16Þ</formula><p>From the root discriminant formula of the quadratic equation, we get</p><formula xml:id="formula_32">d 1 ¼ ÀðA 2 þ 2 a A Þ ð A:17Þ d 2 ¼ ÀðA 2 À 2 a A Þ ð A:18Þ</formula><p>The following is to seek the real root of equation (A. </p><formula xml:id="formula_33">¼ ÀAÀ ffiffiffiffiffiffiffiffiffiffiffiffi À 2a A ÀA 2 p 2 , y 4 ¼ ÀAþ ffiffiffiffiffiffiffiffiffiffiffiffi À 2a A ÀA 2 p 2</formula><p>. What we need is the maximal root, so y 4 is kept and y 3 is discarded.</p><p>In both cases, the obtained roots y 2 and y 4 can be unified as: 4 ). Hence, the minimum point of f ðxÞ on 4 ). II. For case 2, we give a simple argumentation by symmetry. Our goal is to seek the minimum point of f ðxÞ on x &lt; 0. Due to gðxÞ ¼ gðÀy 3 Þ ¼ Àh 2 ðyÞ for x &lt; 0, we need to seek the root ŷ of h 2 ðyÞ satisfying: h 2 ðŷÞ ¼ 0; h 2 ðyÞ &gt; 0 when y &lt; ŷ; h 2 ðyÞ &lt; 0 when y &gt; ŷ:</p><formula xml:id="formula_34">ŷ ¼ jAjþ ffiffiffiffiffiffiffiffiffi ffi 2a jAj ÀA 2 p 2 (a &gt; 4 ffiffiffiffi 27 p k<label>3</label></formula><formula xml:id="formula_35">x &gt; 0 is x ¼ ŷ3 (a &gt; 4 ffiffiffiffi 27 p k<label>3</label></formula><p>ðA:19Þ</p><p>where y is near to ŷ. Actually we can seek the required root of h 2 ðyÞ in the similar way as case 1. However, the deductions in case 2 can be simplified by the symmetry between h 2 ðyÞ and h 1 ðyÞ.  4 ). In summary, the minimal point of f ðxÞ for x -0 is: Proof. Note that we have already derived the minimum point x of f ðxÞ when x -0 in Lemma 3.3. We now derive the minimum point x Ã of f ðxÞ when x 2 R. From the previous analysis, we can easily get  The triangle and hyperbolic expressions for the roots of cubic equation are presented in Table 8 <ref type="bibr" target="#b24">[24]</ref>. According to the second column of Table <ref type="table">8</ref>, we can derive the hyperbolic expression for the unique real root of our cubic Eq. (A.14), i.e.,</p><formula xml:id="formula_36">on x &lt; 0 is x ¼ Àŷ 3 (a &lt; À 4 ffiffiffiffi 27 p k<label>3</label></formula><formula xml:id="formula_37">x ¼ jAjþ ffiffiffiffiffiffiffiffiffiffiffiffi 2jaj jAj ÀjAj 2 q 2 0 @ 1 A 3 if a &gt; sðkÞ À jAjþ ffiffiffiffiffiffiffiffiffiffiffiffi 2jaj jAj ÀjAj 2 q 2 0 @ 1 A 3 if a &lt; ÀsðkÞ 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : where jAj ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi a 2 2 þ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi a 4 4 À 4 3 27 2 k 3 s 0 @ 1 A 1 3 þ a 2 2 À ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi a 4 4 À 4 3 27 2 k 3 s 0 @ 1 A 1 3 v u u u t ; sðkÞ ¼ 4 ffiffiffiffiffiffi 27 p k</formula><formula xml:id="formula_38">x Ã ¼ x fðxÞ &lt; f<label>ð0Þ</label></formula><formula xml:id="formula_39">jaj P jm k ðaÞj 2 þ k 2jm k ðaÞj 1=3 ¼ jm k ðaÞj 2 þ k 2 Ã 3 Ã jm k ðaÞj 1=3 þ k 2 Ã 3 Ã jm k ðaÞj 1=3 þ k 2 Ã 3 Ã jm k ðaÞj 1=3</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>3 regularization</head><label>3</label><figDesc>by deeply analyzing the distribution of roots of the first-order derivative equation of the cost function. Together with our previous work on the close-form thresholding formula for L1 2 regularization in [1,2], these thresholding formulas enable fast and efficient image deconvolution algorithm in the framework of half-quadratic splitting strategy. We conduct extensive experiments over a set natural images blurred by eight real blur kernels. The results demonstrate that our algorithm enables a significantly faster speed over Krishnan et al.'s method; Moreover, L2 3 regularization is more effective over L 0 ; L1 2 or L 1 regularization for image deconvolution, and L1 2 regularization is competitive to L 1 regularization and better than L 0 regularization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>2 ; 3 regularization 2 ; 3 regularization</head><label>2323</label><figDesc>L2In this section, we will firstly present the thresholding formulas for L1 L2 problems. And then, by combining the thresholding formulas and half-quadratic splitting strategy, we propose a fast algorithm for image deconvolution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. The plots of the different threshold formulas.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Test images.</figDesc><graphic coords="4,83.74,67.92,414.74,595.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>3 4 :</head><label>34</label><figDesc>Proof. Please refer to Appendix A for the proof. h Theorem 3.4. The minimum point of f ðxÞ in Eq. (3.3) has the following closed-form thresholding formula when x 2 R:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Test blur kernels.</figDesc><graphic coords="5,144.74,67.92,316.02,178.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>those by L 0 ; L1 2 or L 1 regularization in terms of PSNR values; Second,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. The deconvolution results by different regularization algorithms for image o.</figDesc><graphic coords="7,132.44,599.75,110.58,139.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>3 regularization</head><label>3</label><figDesc>outperforms over L 0 ; L1 2 or L 1 regularization and L1 2 regularization is competitive to L 1 regularization and better than L1 2 regularization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>incorporated to the iterative threholding algorithm as the threholding operator to solve the Eq. (5.1) when q ¼</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The deconvolution results by different regularization algorithms for image p.</figDesc><graphic coords="8,122.66,210.23,109.77,137.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>4 3 k. Since a &gt; 4 ffiffiffiffi 27 p k 3 4;</head><label>3</label><figDesc>D &gt; 0. Hence, Eq. (A.14) only have one real root. According to the Cardan formula for cubic equation, we get the root of Eq. (A.14) as M</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>The proof ofTheorem 3.4    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>p 2 ¼k 3 4, 2 3 ; x 2 2 :</head><label>23222</label><figDesc>From above inequality, we can learn that when jm k ðaÞj 2Ã3Ãjm k ðaÞj 1=3 , i.e., jm k ðaÞj ¼ ð k 3 Þ the equality holds, i.e., jaj ¼ the minimum point off ðxÞ ¼ ðx À aÞ 2 þ kjxj &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; :By utilizing the triangle and hyperbolic expression for the roots of cubic equation, jAj can be reduced as Thus, the proof of Theorem 3.4 is complete. hAppendix C. The triangle and hyperbolic expression for the roots of cubic equation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc>Comparison for running time with kernel 4(19 Â 19).</figDesc><table><row><cell>Size</cell><cell>DL1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>256 Â 256</cell><cell>0.7269/0.0340</cell><cell>0.1452/0.0134</cell><cell>5.0062</cell><cell>0.9009/0.0464</cell><cell>0.2278/0.0192</cell><cell>3.9548</cell></row><row><cell>512 Â 512</cell><cell>3.5615/0.0084</cell><cell>0.6923/0.0061</cell><cell>5.1444</cell><cell>4.2966/0.0048</cell><cell>1.1865/0.0077</cell><cell>3.6212</cell></row><row><cell>1024 Â 1024</cell><cell>14.1109/0.0168</cell><cell>2.5477/0.0166</cell><cell>5.5387</cell><cell>17.0178/0.0085</cell><cell>4.4434/0.0110</cell><cell>3.8299</cell></row><row><cell>2048 Â 2048</cell><cell>55.0141/0.0503</cell><cell>9.6791/0.0284</cell><cell>5.6838</cell><cell>66.9524/0.0730</cell><cell>17.0195/0.0485</cell><cell>3.9339</cell></row><row><cell>3000 Â 3000</cell><cell>109.8524/0.1082</cell><cell>18.7584/0.0948</cell><cell>5.8562</cell><cell>126.5699/0.2687</cell><cell>34.4123/0.1194</cell><cell>3.6766</cell></row><row><cell>3500 Â 3500</cell><cell>150.1106/0.3826</cell><cell>25.9526/0.2777</cell><cell>5.7840</cell><cell>172.3184/0.3806</cell><cell>46.8686/0.0987</cell><cell>3.9304</cell></row><row><cell>4000 Â 4000</cell><cell>196.3966/0.3407</cell><cell>33.5712/0.1605</cell><cell>5.8502</cell><cell>225.7459/1.0865</cell><cell>60.7211/0.1459</cell><cell>3.7178</cell></row><row><cell>Ave.</cell><cell>75.6819/0.1344</cell><cell>13.0495/0.0854</cell><cell>5:5519</cell><cell>87.6860/0.2669</cell><cell>23.5542/0.0643</cell><cell>3:7732</cell></row></table><note><p>2 (Ave./Std.) OurL1 2 (Ave./Std.) Ratio DL2 3 (Ave./Std.) OurL2 3 (Ave./Std.) Ratio Note: Bold value indicates a ratio for the average consuming time of different methods.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>Comparison for running time with kernel 8(27 Â 27). Bold value indicates a ratio for the average consuming time of different methods.</figDesc><table><row><cell>Size</cell><cell>DL1 2</cell><cell cols="2">(Ave./Std.)</cell><cell></cell><cell>OurL1 2</cell><cell>(Ave./Std.)</cell><cell>Ratio</cell><cell>DL2 3</cell><cell>(Ave./Std.)</cell><cell>OurL2 3</cell><cell>(Ave./Std.)</cell><cell>Ratio</cell></row><row><cell>256 Â 256</cell><cell cols="3">0.7264/0.0389</cell><cell></cell><cell cols="2">0.1365/0.0118</cell><cell>5.3216</cell><cell cols="2">0.9096/0.0369</cell><cell cols="2">0.2350/0.0233</cell><cell>3.8706</cell></row><row><cell>512 Â 512</cell><cell cols="3">3.5751/0.0033</cell><cell></cell><cell cols="2">0.6935/0.0043</cell><cell>5.1552</cell><cell cols="2">4.3552/0.0551</cell><cell cols="2">1.1877/0.0024</cell><cell>3.6669</cell></row><row><cell>1024 Â 1024</cell><cell cols="3">14.1563/0.0165</cell><cell></cell><cell cols="2">2.5433/0.0124</cell><cell>5.5661</cell><cell cols="2">17.0849/0.0377</cell><cell cols="2">4.4553/0.0134</cell><cell>3.8347</cell></row><row><cell>2048 Â 2048</cell><cell cols="3">55.2309/0.0637</cell><cell></cell><cell cols="2">9.6818/0.0253</cell><cell>5.7046</cell><cell cols="2">67.1039/0.0482</cell><cell cols="2">17.0219/0.0325</cell><cell>3.9422</cell></row><row><cell>3000 Â 3000</cell><cell cols="3">110.3661/0.1105</cell><cell></cell><cell cols="2">18.7466/0.0501</cell><cell>5.8873</cell><cell cols="2">126.8374/0.1049</cell><cell cols="2">34.5268/0.1721</cell><cell>3.6736</cell></row><row><cell>3500 Â 3500</cell><cell cols="3">150.4214/0.2632</cell><cell></cell><cell cols="2">25.8423/0.0951</cell><cell>5.8207</cell><cell cols="2">172.8680/0.2739</cell><cell cols="2">47.0590/0.0900</cell><cell>3.6734</cell></row><row><cell>4000 Â 4000</cell><cell cols="3">196.7216/0.3144</cell><cell></cell><cell cols="2">33.5025/0.1168</cell><cell>5.8718</cell><cell cols="2">225.7242/0.7428</cell><cell cols="2">61.1651/0.1594</cell><cell>3.6904</cell></row><row><cell>Ave.</cell><cell cols="3">75.8854/0.0704</cell><cell></cell><cell cols="2">13.0209/0.0451</cell><cell>5:6182</cell><cell cols="2">87.8405/0.1856</cell><cell cols="2">23.6644/0.0704</cell><cell>3:7646</cell></row><row><cell>Note: Table 3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Comparison for different images with kernel 7.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Images</cell><cell cols="2">Blurry</cell><cell>L 1</cell><cell>L2 3</cell><cell cols="2">L1 2</cell><cell>L 0</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>table technique) respectively. Table 1 exhibits for kernel 4 the average result and the standard deviation of ten times experiment with different resolutions, and Table 2 for kernel 8. From Table 1 and Table 2, we find that our L1 Of course, we can further exploit other engineering technologies like look-up table or high performance computing platform like GPU (Graphic Processing Units) to further accelerate our algorithm. Moreover, from Table</figDesc><table><row><cell>are denoted</cell></row><row><cell>DL1 2 look-up 2 (without the look-up table technique) and DL2 3 algorithm is roughly 5.5 times (without the faster than Krishnan's L1 2 algorithm, and our L2 algorithm is roughly 3 3.7 times faster than Krishnan's L2 algorithm in average, indicating 3 that the closed-form thresholding formula significantly speed up</cell></row><row><cell>the deconvolution algorithm in the framework of splitting qua-</cell></row><row><cell>dratic algorithm.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5</head><label>5</label><figDesc>Average results for different regularization.</figDesc><table><row><cell>Ave.</cell><cell>Blurry</cell><cell>L 1</cell><cell>L2 3</cell><cell>L1 2</cell><cell>L 0</cell></row><row><cell>ker1(13 Â 13)</cell><cell>22.5621</cell><cell>30.5138</cell><cell>30:5250</cell><cell>30.3146</cell><cell>28.2054</cell></row><row><cell>ker2(15 Â 15)</cell><cell>22.2905</cell><cell>29.1895</cell><cell>29:3143</cell><cell>29.1567</cell><cell>26.9743</cell></row><row><cell>ker3(17 Â 17)</cell><cell>21.7455</cell><cell>29.0075</cell><cell>29:2680</cell><cell>29.1865</cell><cell>26.6380</cell></row><row><cell>ker4(19 Â 19)</cell><cell>22.2555</cell><cell>29.3000</cell><cell>29:6125</cell><cell>29.5735</cell><cell>26.7215</cell></row><row><cell>ker5(21 Â 21)</cell><cell>18.8620</cell><cell>30.6030</cell><cell>30:7085</cell><cell>30.5335</cell><cell>28.0740</cell></row><row><cell>ker6(23 Â 23)</cell><cell>19.7125</cell><cell>29.4790</cell><cell>29:5740</cell><cell>29.4305</cell><cell>27.4645</cell></row><row><cell>ker7(23 Â 23)</cell><cell>19.6490</cell><cell>28.8050</cell><cell>28:9955</cell><cell>28.8810</cell><cell>26.6085</cell></row><row><cell>ker8(27 Â 27)</cell><cell>18.5515</cell><cell>28.2445</cell><cell>28:5470</cell><cell>28.5040</cell><cell>25.9325</cell></row><row><cell cols="4">Note: Bold values indicate the highest PSNR value.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6</head><label>6</label><figDesc>Comparison for 8 kernels with image o.</figDesc><table><row><cell>Image o</cell><cell>Blurry</cell><cell>L 1</cell><cell>L2 3</cell><cell>L1 2</cell><cell>L 0</cell></row><row><cell>ker1(13 Â 13)</cell><cell>23.97</cell><cell>33.38</cell><cell>33:41</cell><cell>33.10</cell><cell>30.47</cell></row><row><cell>ker2(15 Â 15)</cell><cell>23.39</cell><cell>31.57</cell><cell>31:83</cell><cell>31.62</cell><cell>28.96</cell></row><row><cell>ker3(17 Â 17)</cell><cell>22.26</cell><cell>30.87</cell><cell>31:21</cell><cell>31.08</cell><cell>28.34</cell></row><row><cell>ker4(19 Â 19)</cell><cell>23.34</cell><cell>30.87</cell><cell>31:37</cell><cell>31.34</cell><cell>28.03</cell></row><row><cell>ker5(21 Â 21)</cell><cell>19.57</cell><cell>33.14</cell><cell>33:31</cell><cell>33.04</cell><cell>30.12</cell></row><row><cell>ker6(23 Â 23)</cell><cell>20.51</cell><cell>31.21</cell><cell>31:51</cell><cell>31.38</cell><cell>28.86</cell></row><row><cell>ker7(23 Â 23)</cell><cell>20.38</cell><cell>30.82</cell><cell>31:13</cell><cell>30.98</cell><cell>28.31</cell></row><row><cell>ker8(27 Â 27)</cell><cell>19.54</cell><cell>29.59</cell><cell>30:10</cell><cell>30.08</cell><cell>27.08</cell></row><row><cell cols="4">Note: Bold values indicate the highest PSNR value.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7</head><label>7</label><figDesc>Comparison for 8 kernels with image p.</figDesc><table><row><cell>Image p</cell><cell>Blurry</cell><cell>L 1</cell><cell>L2 3</cell><cell>L1 2</cell><cell>L 0</cell></row><row><cell>ker1(13 Â 13)</cell><cell>23.64</cell><cell>34:23</cell><cell>34.09</cell><cell>33.66</cell><cell>30.76</cell></row><row><cell>ker2(15 Â 15)</cell><cell>22.87</cell><cell>32.19</cell><cell>32:36</cell><cell>32.07</cell><cell>28.94</cell></row><row><cell>ker3(17 Â 17)</cell><cell>21.63</cell><cell>30.97</cell><cell>31:44</cell><cell>31.33</cell><cell>27.84</cell></row><row><cell>ker4(19 Â 19)</cell><cell>22.60</cell><cell>31.23</cell><cell>31:81</cell><cell>31.78</cell><cell>27.73</cell></row><row><cell>ker5(21 Â 21)</cell><cell>17.91</cell><cell>33.56</cell><cell>33:71</cell><cell>33.38</cell><cell>29.91</cell></row><row><cell>ker6(23 Â 23)</cell><cell>19.07</cell><cell>32.39</cell><cell>32:56</cell><cell>32.29</cell><cell>29.38</cell></row><row><cell>ker7(23 Â 23)</cell><cell>18.94</cell><cell>31.62</cell><cell>31:89</cell><cell>31.63</cell><cell>28.23</cell></row><row><cell>ker8(27 Â 27)</cell><cell>17.59</cell><cell>30.14</cell><cell>30:72</cell><cell>30.66</cell><cell>26.96</cell></row><row><cell></cell><cell></cell><cell>Original</cell><cell></cell><cell></cell><cell>Blurry image</cell><cell>recovery</cell></row><row><cell></cell><cell></cell><cell>image</cell><cell></cell><cell></cell><cell>PSNR=19.54</cell><cell>PSNR=29.59</cell></row><row><cell></cell><cell></cell><cell>recovery</cell><cell></cell><cell></cell><cell>recovery</cell><cell>recovery</cell></row><row><cell></cell><cell></cell><cell>PSNR=30.10</cell><cell></cell><cell></cell><cell>PSNR=30.08</cell><cell>PSNR=27.08</cell></row></table><note><p>Note: Bold values indicate the highest PSNR value.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>ðyÞ ¼ 12y 2 P 0; h 1 ðyÞ is a convex function. The root distribution for h 1 ðyÞ has three cases: caseðaÞ: h 1 ðyÞ ¼ 0 has no root. This means that h 1 ð ffiffi a</figDesc><table><row><cell cols="6">2 tion to other related problems in image processing and machine and L2 regulariza-3</cell></row><row><cell cols="2">learning.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">we can get ð</cell><cell>ffiffi a 4 p 3 Þ 4 À að</cell><cell>3 p</cell><cell>ffiffi a 4 Þ þ k 3 &gt; 0, i.e., a &lt; 4 ffiffiffiffi 27 p k 3 4 ;</cell><cell>4 p 3 Þ &gt; 0, then</cell></row><row><cell cols="6">caseðbÞ: h 1 ðyÞ ¼ 0 has one unique real root. This means that ffiffi a 4 3 p Þ ¼ 0, therefore a ¼ 4 ffiffiffiffi 27 p k 3 4 . In this case, however, ŷ ¼ ffiffi a 4 3 p does not satisfy Eq. (A.2), so ŷ ¼ h 1 ð ffiffi a 4 3 p is a saddle point rather than a</cell></row><row><cell cols="3">minimum point;</cell><cell></cell><cell></cell></row><row><cell>h 1 ð</cell><cell cols="5">caseðcÞ: h 1 ðyÞ ¼ 0 has two real roots. This means that ffiffi a 4 3 p Þ &lt; 0, therefore a &gt; 4 ffiffiffiffi 27 3 p k 4</cell></row></table><note><p>1</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>p 2 .</head><label>2</label><figDesc>Because we need the root of h 1 ðyÞ that satisfies Eq. (A.2), y 2 is the root what we seek and y 1 is discarded.When A &lt; 0, due to a &gt; 4 ffiffiffiffi can obtain d 2 &lt; 0. since d 1 Ã d 2 &lt; 0, hence d 1 &gt; 0. In this case, (A.16) has no real roots, and (A.15) has two different real roots, y 3</figDesc><table><row><cell>15), (A.16) by</cell></row><row><cell>Lemma 3.2.</cell></row><row><cell>When A &gt; 0, due to a &gt; 4 ffiffiffiffi p k 3 4 , we can obtain d 1 &lt; 0. By Lemma 27 3.2, d 1 Ã d 2 &lt; 0, hence, d 2 &gt; 0. Therefore, (A.15) has no real roots, and (A.16) has two different real roots: y 1 ¼ AÀ ffiffiffiffiffiffiffiffiffi 2a p A ÀA 2 2 , y 2 ¼ Aþ ffiffiffiffiffiffiffiffiffi 2a A ÀA 2</cell></row><row><cell>27 p k 3 4 , we</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>Since h 2 ðyÞ ¼ h 1 ðÀyÞ, therefore h 2 ðyÞ and h 1 ðyÞ are symmetric with respect to the vertical axis. Thus the minimal root of h 2 ðyÞ corresponds to the minus of the maximal root of h 1 ðyÞ : ŷ ¼ Hence the minimum root of h 2 ðyÞ, i.e., the minimum point of f ðxÞ</figDesc><table><row><cell>jAjþ p ffiffiffiffiffiffiffiffiffi 2a jAj ÀA 2 2</cell><cell>.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>However, our aim is not to seek x Ã by comparison between f ðxÞ and f ð0Þ, but to seek x Ã in a closed-form thresholding formula, i.e., Next our task is to explicitly compute the expression of t Ã ðkÞ. When f ðxÞ 6 a 2 , we get ðx À aÞ 2 þ kjxj &lt; 0, by Lemma 3.1, x 2 ða; 0Þ, (B.1) can be reduced as Àa P k ðaÞ 2 þkjm k ðaÞj2 3 2jm k ðaÞj. Obviously, the threshold t Ã ðkÞ can be computed from the roots of uðaÞ. Since m k ðaÞ is the minimum point of the equationf ðxÞ ¼ ðx À aÞ 2 þ kjxj 2 3 ðx -0Þ; m k satisfies: jm k ðaÞj À a þ k 3 signðjm k ðaÞjÞ jm k ðaÞj 1=3 ¼ 0.According to the equation, we can obtain jm k ðaÞj 2 ¼ ajjm k ðaÞj À From (B.4), we can learn that uðaÞ ¼ uðÀaÞ, so uðaÞ is symmetric with respect to the vertical axis. In a 2 ½ 4 ffiffiffiffi 27 p k 3=4 ; 1Þ; uðaÞ is monotonically increasing. Moreover, lim a! 4 ffiffiffi 27 p k 3=4 uðaÞ ¼ 8 ffiffiffiffi 3=4 Þ &lt; 0 and lim a!þ1 uðaÞ ¼ þ1. Therefore, uðaÞ on ½ 4 ffiffiffiffi 1Þ has a unique root t Ã ðkÞ. By the symmetry of uðaÞ, it has another unique root Àt Ã ðkÞ on ðÀ1; À 4 ffiffiffiffi 27 p k 3=4 . Thus, we have f ðxÞ &lt; a 2 ¼ f ð0Þ () jaj &gt; t Ã ðkÞ And still, from inequality (B.2), we obtain</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>where</cell><cell>x ¼ m k ðaÞ :¼ ð</cell><cell>jAjþ</cell><cell>ffiffiffiffiffiffiffiffiffiffiffiffi 2jaj q jAj ÀjAj 2 2</cell><cell>Þ 3 signðaÞ.</cell><cell>Let</cell><cell>uðaÞ ¼ jajÀ</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>k 3</cell><cell>m k ðaÞj 2 3</cell><cell>ðB:3Þ</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>we substitute (B.3) into uðaÞ; uðaÞ can be further reduced as</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>uðaÞ ¼</cell><cell>jaj 2</cell><cell>À</cell><cell>k 3jm k ðaÞj 1=3</cell><cell>ðB:4Þ</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>27 p k 3=4 À 2 3 p k 27 k m k ð 4 ffiffiffi 27 p k 3 4 ;</cell></row><row><cell>x Ã ¼</cell><cell>&amp;</cell><cell cols="3">0 jaj 6 t Ã ðkÞ x jaj &gt; t Ã ðkÞ</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">2 3 6 a 2 . By reducing the equation, we</cell></row><row><cell cols="3">further get</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">2ax P x2 þ kjxj</cell><cell>2 3</cell><cell></cell><cell></cell><cell>ðB:1Þ</cell></row><row><cell cols="6">When a &gt; 0, by Lemma 3.1, x 2 ð0; aÞ; a P</cell><cell cols="2">2 x2 þkjxj 3 2x ; when a x2 þkjxj 2 3 À2x . Hence</cell></row><row><cell cols="6">we unify these two cases as follows</cell><cell></cell></row><row><cell>jaj P</cell><cell cols="2">x2 þ kjxj 2jxj</cell><cell>2 3</cell><cell>or jaj P</cell><cell cols="2">2 3 m k ðaÞ 2 þ kjm k ðaÞj 2jm k ðaÞj</cell><cell>ðjaj</cell></row><row><cell>&gt;</cell><cell cols="2">4 ffiffiffiffiffiffi 27 p k 3 4 Þ</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ð B:2Þ</cell></row></table><note><p>¼ a 2 0 f ðxÞ P f ð0Þ ¼ a 2 ( m</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank Doctor J. X. Jia and Q. Zhao for many helpful suggestions. This work was supported by the National 973 Programming (2013CB329404), the Key Program of National Natural Science Foundation of China (Grant No. 11131006), and the National Natural Science Foundations of China (Grant No. 61075054).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Appendix A. The proof of <ref type="bibr">Lemma 3.3</ref> Proof. We will find the minimum point of f ðxÞ on x -0 by seeking and analyzing the roots of equation f 0 ðxÞ ¼ 0 on x -0. Since</p><p>, we obtain that:</p><p>Assuming that jxj ¼ y 3 , (A.1) can be reduced as the following two cases:</p><p>In the following, for case 1, we seek the positive minimum point of f ðxÞ by exploring the zero point distribution of h 1 ðyÞ. And for case 2, we seek the negative minimum point of f ðxÞ by the symmetry relationship of h 2 ðyÞ and h 1 ðyÞ, i.e., h 2 ðyÞ ¼ h 1 ðÀyÞ.</p><p>I. We first analyze case 1. By Lemma 3.1, in order to seek the minimum point of f ðxÞ on x &gt; 0, it suffices to consider the case of a P 0. Since for x &gt; 0; gðxÞ ¼ gðy 3 Þ ¼ h 1 ðyÞ, we just need to seek the positive root ŷ of h 1 ðyÞ satisfying: h 1 ðŷÞ ¼ 0; h 1 ðyÞ &lt; 0 when y &lt; ŷ; h 1 ðyÞ &gt; 0 when y &gt; ŷ:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ðA:2Þ</head><p>where y is near to ŷ. We next investigate the root distribution of h 1 ðyÞ by analyzing its derivative. Since h 0 1 ðyÞ ¼ 4y 3  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Note: Bold values indicate the highest PSNR value</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Data modeling: visual psychology approach and L1 2 regularization theory</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">B</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Congress of Mathematicians</title>
		<meeting>the International Congress of Mathematicians</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">L1 2 regularization: an iterative half thresholding algorithm</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks Learning Syst</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1013" to="1027" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fast image deconvolution using hyper-Laplacian priors</title>
		<author>
			<persName><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Removing camera shake from a single photograph</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="787" to="794" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fast motion deblurring</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Progressive inter-scale and intra-scale nonblind image deconvolution</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Esedoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Models Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Non-local Algorithm for Image Denoising</title>
		<author>
			<persName><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="60" to="65" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>IEE</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Image denoising by sparse 3-D transform-domain collaborative filtering</title>
		<author>
			<persName><forename type="first">K</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2080" to="2095" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Non-local sparse models for image restoration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="2272" to="2279" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Image denoising via sparse and redundant representations over learned dictionaries</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3736" to="3745" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sparse representation for color image restoration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="69" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Image deblurring and super-resolution by adaptive sparse domain selection and adaptive regularization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1838" to="1857" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Exploiting the sparse derivative prior for super-resolution and image demosaicing</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Tappen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third International Workshop on Statistical and Computational Theories of Vision at ICCV</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Exact reconstruction of sparse signals via nonconvex minimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chartrand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Lett</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="707" to="710" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Restricted isometry properties and nonconvex compressive sensing, Inverse Prob</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chartrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Staneva</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Iteratively reweighted algorithms for compressive sensing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chartrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="3869" to="3872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fast algorithms for nonconvex compressive sensing: MRI reconstruction from very few data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chartrand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Biomedical Imaging: From Nano to Macro</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="262" to="265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<author>
			<persName><forename type="first">T</forename><surname>Blumensath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yaghoobi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Davies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Iterative hard thresholding and L 0 regularisation</title>
		<title level="s">IEE Trans. Acoust. Speech Signal Process</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Denoising by soft thresholding</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="613" to="627" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An iterative thresholding algorithm for linear inverse problems with a sparsity constraint</title>
		<author>
			<persName><forename type="first">I</forename><surname>Daubechies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Defrise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">De</forename><surname>Mol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. Pure and Appl. Math</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1413" to="1457" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Understanding and evaluating blind deconvolution algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>CVPR</publisher>
			<biblScope unit="page" from="1964" to="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Image super-resolution via sparse representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2861" to="2873" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Investigation on solutions of cubic equations with one unknown</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Central Univ. Nationalities (Natural Sciences Edition)</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="207" to="218" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<title level="m">Sparse and Redundant Representations: From Theory to Applications in Signal and Image Processing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
