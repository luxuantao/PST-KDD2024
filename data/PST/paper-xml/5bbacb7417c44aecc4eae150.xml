<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Tensor Factorization Method based on Review Text Semantic Similarity for Rating Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">James</forename><surname>Chambua</surname></persName>
							<email>jchambua@bit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<postCode>100081</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Computer Science and Engineering Department</orgName>
								<orgName type="institution">University of Dar-es-Salaam</orgName>
								<address>
									<postBox>P.O. Box 35091</postBox>
									<settlement>Dar-es-Salaam</settlement>
									<country key="TZ">Tanzania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhendong</forename><surname>Niu</surname></persName>
							<email>zniu@bit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<postCode>100081</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Abdallah</forename><surname>Yousif</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<postCode>100081</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jimmy</forename><surname>Mbelwa</surname></persName>
							<email>jmbelwa@yahoo.co.uk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<postCode>100081</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Computer Science and Engineering Department</orgName>
								<orgName type="institution">University of Dar-es-Salaam</orgName>
								<address>
									<postBox>P.O. Box 35091</postBox>
									<settlement>Dar-es-Salaam</settlement>
									<country key="TZ">Tanzania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<postCode>100081</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Tensor Factorization Method based on Review Text Semantic Similarity for Rating Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1016/j.eswa.2018.07.059</idno>
					<note type="submission">Received date: 4 February 2018 Revised date: 21 June 2018 Accepted date: 29 July 2018</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T14:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Expert Systems With Applications Tensor Factorization</term>
					<term>Semantic Similarity</term>
					<term>User Reviews</term>
					<term>Rating Prediction</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recommendation methods have been proved to be successful in eliminating the information overload problem. However, they are still insufficient as far as data sparsity and cold start issues are concerned. Some approaches have attempted to resolve these issues by utilizing relevant information contained in user review text, although, the type of information extracted from the review text and the way such recommendation methods utilize the information affect recommendation accuracy of the models. In this paper, we address such challenges through considering linguistic similarity between review texts and employ it as additional factor in rating prediction, and we propose a recommendation method based on tensor factorization which involves review text semantic similarity. The proposed tensor factorization model supplements the central task of factorization methods of finding similar users, uncovering underlying characteristics of the data and predicting user preferences by introducing text semantic similarity. The proposed method is carried out in two main phases; first phase, by computing semantic similarity between review texts and assigning a similarity score, and second phase by introducing the similarity score as an additional factor in the probabilistic matrix factorization (PMF) model. To evaluate the performance of the proposed approach, several Amazon datasets were experimented and the results verify that the semantic similarity of review texts not only successfully portray user preferences, and extend PMF to include review texts similarities but also increases prediction influence which results in improved performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p> A Tensor factorization method based on review texts semantic similarity.  Review texts helps to accurately classify users with most similar preferences.  Text similarity well reflects preferences compared to review topics, opinion.  Experimental results show that our model achieves better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Most media corporations, e-commerce sites and related micro-blogs employ recommendation methods to reduce the information overload problem for their users. Recommendation methods provide personalized suggestions of items that are predicted to be highly preferred by users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>However, these systems are still suffering from data sparsity and cold start issues which affect their performance. Data sparsity issue refers to the situation where the amount of information (ratings) of a target user is not sufficient enough to generate reliable related users (i.e. the number of common rated items among users is very small) while Cold start refers to the situation where a Recommender System (RS) encounters new users or items, with no ratings <ref type="bibr" target="#b8">(Guo, 2013)</ref>. Recent studies have considered utilizing user review texts <ref type="bibr" target="#b4">(Chen et al., 2015)</ref> to solve data sparsity and cold start issues. Such reviews were used as a complimentary source of information, after being properly modeled, to aid recommendation algorithms in predicting unknown ratings <ref type="bibr">(Esparza et al., 2011a)</ref>. However, the type of information extracted from the user reviews and the way such recommendation methods utilize the information influence recommendation accuracy of the models.</p><p>Accurate prediction of users" preferences by recommendation methods depends on how effective and successful the methods are at understanding each user"s past preferences, the reasons behind their preferences, pair-wise and overall users" preferences interaction. Generally, users express their overall consent towards items through review text; most users provide their reviews on items to express their satisfaction or frustration on item features as well as the extent of their preferences and reasons behind such interests. User review text have great impact on how people make decisions <ref type="bibr" target="#b3">(Chen et al., 2016)</ref>. Taking into consideration user preferences as expressed in reviews and since Collaborative Filtering (CF) and Content Based (CB) recommender systems predict user preferences on unrated items based on similarity between user preferences as characterized by historical ratings <ref type="bibr" target="#b2">(Breese et al., 1998)</ref> and similarity between preferred items as represented by item descriptions <ref type="bibr" target="#b18">(Pazzani &amp; Billsus, 2007)</ref>, then it"s necessary to exploit vital information contained in review texts to support preference prediction. Some existing works by <ref type="bibr" target="#b13">Leung et al., (2006)</ref> and <ref type="bibr" target="#b37">Zhang et al., (2013)</ref> have utilized review texts by conducting user sentiment analysis as perceived from their review texts, to enhance personalized recommendations. However, we argue that for effective exploitation of CF and CB approaches, semantic similarity between user"s review text should be used instead of sentiment because the reasons behind users" preferences are well reflected in the semantic similarity as opposed to sentiment analysis of the review texts. Sentiment provides the extent of users" preferences in three basic classes, positive, negative and neutral, it only reveals how much a user preferred an item without providing any reasons behind his/her preference. People are really concerned with recommendation method"s ability to provide recommendations that match their interests and not whether the method can accurately predict rating scores <ref type="bibr" target="#b40">(Zhao et al., 2015)</ref>.</p><p>The work of <ref type="bibr" target="#b38">Zhao et al.(2013a)</ref> argued that relevance of user ratings is good for similarity function but using only ratings for the correlation in finding a set of most similar users is not so good. The idea behind computing semantic similarities between review text focuses on generating a set of users with semantically similar review texts on same items and a set of users who provide similar item descriptions in their reviews, which is the central task of collaborative</p><formula xml:id="formula_0">A C C E P T E D M A N U S C R I P T</formula><p>filtering and content-based approaches. Review texts semantic similarity provides a proper way of understanding, comparing and analyzing concepts underlying each term in review texts. Same words or word forms on two different review texts may not necessarily refer to same concepts. Proper word concept mapping and word sense disambiguation is necessary <ref type="bibr" target="#b12">(Leacock &amp; Chodorow, 1998)</ref> as far as utilizing review texts in rating prediction is concerned.</p><p>This study proposes a preference prediction approach that utilizes user review texts by computing semantic similarities between review texts and extend Probabilistic Matrix Factorization (PMF) algorithm to include the semantic similarity as an additional factor. Furthermore, complete Bayesian treatment is applied to the extended PMF to avoid over fitting, as the treatment establish priors on parameters, and thus proper averaging over different models and eventually guarantees fine tuning of parameters <ref type="bibr" target="#b27">(Salakhutdinov &amp; Mnih, 2007)</ref>. The Bayesian Probabilistic Tensor Factorization based on Review Text Semantic Similarity method (Review Text Tensor Factorization-RTTF) is proposed and applied to predict user preferences on unrated items.</p><p>The contribution of this study can be perceived in three key facets. Firstly, proposing a method of computing semantic similarity between user review texts to ensure complete reflection of user"s preferences is obtained. Semantic similarity between review texts expresses different user preferences, which is one of the essential factors for accurate prediction of unknown ratings with CF based approaches. Secondly, employing semantic similarity between review texts in predicting missing ratings. The numerical representation of the review provides insights to the extent of the influence imposed by a particular user review semantically compared to others. Thirdly, incorporating the quantified review texts in PMF as an additional factor to assist rating prediction. As far as authors" knowledge is concerned, this is the first study to introduce review texts semantic similarity and apply it as an additional factor in factorization methods to increase prediction influence of the method which results in improved performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>Numerous works have utilized user review texts and their associated valuable information such as review topics, review opinion and aspect opinion, to influence recommendation methods ability to predict missing ratings. Such works differ from one another on how they utilize the review texts either to infer user preferences or infer feature preference or otherwise. This section provides a detailed review of works which incorporate user review texts and how review texts are differently used to assist rating prediction in contrast to the proposed model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Methods based on User Review Texts</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Methods based on Frequent Terms and Review Topics</head><p>User-Generated Content (UGC) approach, in the form of micro reviews proposed by <ref type="bibr">Esparza et al.(2011b)</ref> and <ref type="bibr">Esparza et al.(2011a)</ref> use review texts as complimentary source of knowledge to be used by recommender systems in rating predictions. Their works rely on Term Frequency -Inverse Document Frequency (TF-IDF) weight measure to determine how representative each term is in the review. The frequent weighted terms are then used to control the content-based approach for improved recommendations. <ref type="bibr" target="#b30">Seroussi et al.(2011)</ref> considered user demographic attributes that were explicitly supplied by the users and implicit attributes that are learned from user-generated texts by extending Matrix Factorization (MF) in generating personalized rating predictions. They employed Principal Component Analysis (PCA) and Latent Dirichlet Allocation (LDA) dimensionality reduction techniques to get compact set of user attributes for the demographic attributes and textual attributes, respectively.</p><p>The work by <ref type="bibr" target="#b17">McAuley &amp; Leskovec (2013)</ref> combined latent dimensions in rating data with topics in review text to improve actual ratings in CF based recommendation approaches. They claimed that their proposed Hidden Factors as Topics (HFT) model is beneficial in terms of being able to explain the variation present in ratings and reviews as well as predicting ratings more accurately than approaches that consider either ratings only or reviews only. <ref type="bibr" target="#b5">Chen et al.( 2017)</ref> fused user historical ratings with user latent topics as inferred from user reviews. Their approach constituted a combined model, the probabilistic model (Gaussian distribution) applied on the historical ratings and the LDA model for various topics contained in the reviews. The review topics were used as necessary weights which reflected relative preference the user placed on each topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Methods based on Review"s Opinion</head><p>Several works have focused on user"s sentiment orientation as inferred from the textual reviews to represent user"s overall positive or negative opinion. Such works use the sentimental polarities of reviews or review feature polarities as one kind of resources for recommendation. The work by <ref type="bibr" target="#b37">Zhang et al.(2013)</ref> based their approach on generating virtual ratings from Chinese reviews to augment online recommendations. They developed review-aware recommender algorithm which exploits sentiment classification results to automatically derive virtual ratings, and then fuse them into item-based and user-based CF algorithms by which the User-Item Rating Matrix can be inferred by decomposing item reviews that users gave to the items. <ref type="bibr" target="#b21">Poirier et al. (2010)</ref> proposed a recommendation method which relies on textual data only without the use of explicit ratings. The method involves labeling subjective texts according to their expressed opinion in order to build a user-item-rating matrix and then the matrix is used to establish recommendations based on collaborative filtering techniques. They basically provided ratings inferred from opinion texts to feed a recommender system. The work by <ref type="bibr" target="#b39">(Zhao et al., 2013b)</ref> proposed an Opinion-based CF method that recommends items to users after checking whether the items are</p><formula xml:id="formula_1">A C C E P T E D M A N U S C R I P T 6</formula><p>related to user"s preferences. Their method utilizes weighting functions which regulate the influence that items have according to their popularities. Such weighting functions are used to measure user similarities in the employed CF method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Methods based on Features Opinion</head><p>Wu &amp; Ester ( <ref type="formula">2015</ref>) proposed a probabilistic model known as FLAME, to infer users" ratings on different item features. They extended the PMF model by assuming that from each review, a user expresses his implicit preference (rating) on different item features. Hence, they predicted user"s sentiment on each feature of a particular item by taking a dot product of user latent vectors and item features latent vector as extracted from the reviews. <ref type="bibr">Liu et al. (2013)</ref> proposed a recommendation algorithm that extracts user opinion towards item features as expressed in reviews. Their model evaluates the difference between users" historical ratings and feature opinion to predict preferences. They extracted item features and their associated opinions by using association rule mining based on Part-of-Speech tagging and developed the preference and opinion-based recommendation (PORE) algorithm which is based on two assumptions (measures): a) concern -If a user comments on a feature more frequently than on average, he (or she) cares about this feature more; b) If a user rates a feature frequently lower than other users for different restaurants, his requirement for this feature is higher.</p><p>The work by <ref type="bibr" target="#b11">Jakob &amp; Weber (2009)</ref> illustrated that extraction of opinions from review texts can improve the accuracy of movie recommendations. They presented three approaches which involved extracting two types of vital information: 1) The correlation of the overall star rating with the individual aspect-related opinions shows the influence on the star rating that a given movie aspect has for a user, and 2) the overall number of opinions regarding a certain movie aspect cluster reveals how important that aspect is to a user, as opinion targets and use them as features for the collaborative filtering. <ref type="bibr" target="#b33">Wang et al., (2012)</ref> proposed a framework that is able to capture users" opinions on different aspects from the review texts, and use that information to improve the effectiveness of CF. They proposed a tensor factorization approach, for the rating prediction, which is based on CANDECOMP/PARAFAC -Weighted OPTimization (CP-WOPT) <ref type="bibr" target="#b0">(Acar et al., 2011)</ref> method that uses a first-order optimization approach to solve the weighted least squares problem in decomposing a high-order tensor to a sum of rank-one tensors in a scalable fashion. <ref type="bibr" target="#b36">Yu et al. (2017)</ref> proposed Ratings are Sentiments (RAS) model which combines latent factors, hidden topics and aspect sentiments to learn latent factors of users and items. They associate the rating scores with the discovered aspect sentiments to identify a clear explanation towards user ratings and eventually their preferences.</p><p>The described related works present different techniques of using review texts to enhance rating prediction in recommender systems. The most similar works to our approach are the work by <ref type="bibr" target="#b33">Wang et al. (2012)</ref>, <ref type="bibr" target="#b17">McAuley &amp; Leskovec (2013)</ref> and <ref type="bibr" target="#b36">Yu et al.(2017)</ref>. The method proposed by <ref type="bibr" target="#b33">Wang et al. (2012)</ref> is different from our approach in two aspects 1) the way they compute factorization (as there are multiple ways of computing factorization, they opted to CP-WOPT</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T method) and 2) they focused on user"s opinion. While the work by <ref type="bibr" target="#b17">McAuley &amp; Leskovec (2013)</ref> and <ref type="bibr" target="#b36">Yu et al.(2017)</ref> focuses on aspect sentiments to improve latent factors model combined with hidden topics, our work focuses on tensor factorization based on review texts semantic similarity as a way to enhance factor models. To the best of our knowledge our proposed work is the first to introduce semantic similarity (language similarity aspect) of the textual review as an additional factor to enhance rating inference as well as considering probabilistic models to account for randomness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The Proposed Method</head><p>The main task of recommendation methods is to predict user preferences towards unknown or unrated items and generate a ranked list of most preferred items to be recommended to users. With collaborative methods, the assumption is that users with similar known preferences (ratings) on several items are likely to have similar preference on unrated items. Hence, the proposed model focuses on proper understanding and representation of user preferences as perceived from their review text for more accurate prediction of user ratings on items. Semantic similarity of review texts is established as a quantifiable factor that can be used along with factor based methods to enhance rating prediction. The proposed model utilizes the computed review text semantic similarity along with historical user ratings in predicting missing ratings. As such the model involves two stages; review text semantic similarity computation as first stage and missing rating prediction using tensor factorization as second stage, as described in subsections 3.1 and 3.3, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Modeling Users Review Texts</head><p>Semantic similarity between pairs of user review texts is introduced to establish appropriate weight/influence to be used in the prediction of user preferences on unrated items. Several semantic similarity measures can be applied but in this study we have considered information content and lin measures as described in subsection 3.1.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Semantic Similarity between User Review Texts</head><p>The similarity of two review texts from two different users can be computed to assess the semantic associations between them. The review text for a user towards an item can be represented as a set *( ) ( ) +. The set holds the review of a user on item . Hence, the similarity between the contents of two users can be computed by defining a similarity function of their review texts. Such function will measure the association between different terms, phrases and sentences contained in users" review texts as described in the following equation (similarity range from 0 to 1):</p><formula xml:id="formula_2">| | ∑ ( ) ( ) A C C E P T E D M A N U S C R I P T</formula><p>Where represents the items reviewed by both users , and ( ) is the function to calculate the semantic similarity measure between review text of user and review text of user .</p><p>The function computes similarity based on two aspects: semantically and lexically. Two terms are semantically similar if they have the same thing, are opposite of each other, used in the same way, and if one is a type of another and are lexically similar if they have a similar character sequence <ref type="bibr">(Gomaa &amp; Fahmy, 2013)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Semantic Similarity Measures</head><p>Semantic similarity is usually established through knowledge based approaches and corpusbased methods which determines the degree of similarity between words using information derived from semantic networks and according to information gained from large corpora respectively (H. <ref type="bibr">Gomaa &amp; A. Fahmy, 2013)</ref>. Similarity measures can be categorized in three measure aspects; simple words overlap measure, measures based on the path or path based on SEMILAR corpus <ref type="bibr" target="#b25">(Rus et al., 2012)</ref>, depth of the two words <ref type="bibr" target="#b35">(Wu &amp; Palmer, 1994)</ref> and measures based on use of information content (IC) of a word <ref type="bibr" target="#b24">(Rus et al., 2013)</ref>.</p><p>The applied semantic similarity measures in the proposed method, is based on information content as defined by <ref type="bibr" target="#b24">Rus et al.(2013)</ref>. Information Content (IC) is computed based on frequency counts of concepts as found in a corpus of text. The frequency associated with a concept is incremented in a corpus each time that concept is observed, as are the counts of the ancestor concepts in the corpus hierarchy <ref type="bibr" target="#b19">(Pedersen, 2010)</ref>. IC is computed as the inverse of the appearance probability of a concept in a corpus:</p><formula xml:id="formula_3">( ) ( ) ( )</formula><p>Formally the probability is defined as follows:</p><formula xml:id="formula_4">( ) ∑ ( ) ( ) ( )</formula><p>Where ( ) is the set of terms in the corpus whose senses are subsumed by and is the total number of corpus terms <ref type="bibr" target="#b29">(Sánchez &amp; Batet, 2013)</ref>.</p><p>Specifically <ref type="bibr" target="#b23">(Resnik, 1995)</ref> proposed evaluating the IC of the least common subsumer of the compared concepts (LCS(c1, c2)) as the representative of this shared information:</p><formula xml:id="formula_5">( ) ( ( )) ( )</formula><p>With Resnik"s metric, any pair of concepts with the same LCS will result in exactly the same similarity value <ref type="bibr" target="#b29">(Sánchez &amp; Batet, 2013)</ref>. Lin (1998) extended Resnik"s measure by adding normalization factor consisting of IC of the two input words:</p><formula xml:id="formula_6">A C C E P T E D M A N U S C R I P T ( ) ( ( )) ( ) ( ) ( )</formula><p>Equation ( <ref type="formula">5</ref>) presents the core similarity measure applied in the proposed method. The lin similarity measure determines the semantic similarity between a pair of review text by comparing and matching their word tokens as well as the syntactic dependencies them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Text-to-Text Semantic Similarity</head><p>Semantic similarity methods can be categorized depending on the semantic similarity measures they consider, as described in subsection 3.1.2, and as such we have path-based (feature-based) methods, depth-based methods, information content methods and Hybrid methods. Hybrid methods are generated by any combination of path based measures, depth based and/or information content measures to form a more effective and powerful semantic similarity method such as X-similarity proposed by <ref type="bibr" target="#b20">Petrakis et al., (2006)</ref>. One of the main advantages of such hybrid methods is highlighted by the diversity of datasets and shared tasks evaluation campaigns (STECs) which have been proposed for SemEval workshops as stipulated by <ref type="bibr" target="#b1">Agirre et al., (2012)</ref>. Hybrid methods focus on identifying and quantifying the presence of semantic relations between any two text from different application areas (ontologies). Given two texts, A and B, respectively, semantic similarity methods assess whether text A has the same meaning as text B by identifying and quantifying any semantic associations between the terms in the two texts. This is the basic semantic similarity problem.</p><p>Text-to-text semantic similarity involves assessing text of either same size e.g. word-to-word similarity, phrase-to-phrase, sentence-to-sentence, paragraph-to-paragraph and document-todocument or mixed e.g. word-to-sentence, sentence-to-paragraph etc. Mixed combinations are very useful in different applications such in summarization, they can be used to assess how well a sentence summarizes a paragraph <ref type="bibr" target="#b24">(Rus et al., 2013)</ref>. Semantic similarity methods such as Xsimilarity by <ref type="bibr" target="#b20">Petrakis et al., (2006)</ref> and WordNet similarity library handle word-to-word similarity only as opposed to SEMILAR toolkit <ref type="bibr" target="#b24">(Rus et al., 2013)</ref> which can handle both same size text and mixed size i.e. from word-to-word similarity up to word-to-sentence or sentence-toparagraph. For this reason, the similar toolkit is an ideal solution to assess the similarity between review texts as different users provide they reviews in several sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Probabilistic Matrix Factorization</head><p>Factorization methods such as MF and PMF utilizes historical ratings in predicting missing/unknown user ratings. Formerly consider a user who rated an item with a rating . The rating matrix which is a sparse matrix representing some ratings of users on items and hence it is the task of CF algorithm to predict the unknown (missing) ratings. With the Probabilistic Matrix Factorization (PMF) approach <ref type="bibr" target="#b27">(Salakhutdinov &amp; Mnih, 2007)</ref>, the conditional probability of observed rating matrix is modeled as:</p><formula xml:id="formula_7">A C C E P T E D M A N U S C R I P T ( | ) ∏ ∏[ ( | )] ( )</formula><p>Where ( | ) is the probability density function of the Gaussian distribution with mean µ and variance is the indicator, which equals 1 if user rated item and 0 otherwise. From this the prior distributions of user and item vectors respectively are given with the following:</p><formula xml:id="formula_8">( | ) ∏ ( | ) ( ) ( | ) ∏ ( | ) ( )</formula><p>The PMF model is learned by maximizing posterior probability of latent matrices and , which is equivalent to minimizing sum-of-squares of factorization error with quadratic regularization terms <ref type="bibr" target="#b31">(Shan &amp; Banerjee, 2010)</ref>. Even though PMF is one of the very successful CF methods, it also has some limitations. PMF assumes that user vectors and item vectors are independent and identically distributed <ref type="bibr">(Liu et al., 2013)</ref> and does not consider the contribution that can be brought by proper modeling of user review texts. It is believed that user review texts can enhance ratings and benefit recommender systems <ref type="bibr" target="#b4">(Chen et al., 2015)</ref> in eliminating the data sparsity problem, and improve recommendation accuracy. This study focuses on leveraging PMF model by extending it to include semantic similarity of the user"s review texts in order to improve preference prediction accuracy and ultimately improve personalized recommendations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Bayesian Probabilistic Tensor Factorization for User Review Texts</head><p>In order to extend the PMF model to tensor factorization and take into account the influence of user review texts, the quantified user review texts as explained in section 3.1, were introduced as an additional factor. Extending PMF model to include review texts, the following tensor notation will be applied: the rating , from user who rated an item and review text semantic similarity as compared to other user review texts who rated item . In our study, each user review text on a particular item is compared with other user review texts concerning the same item. The computed similarity scores between reviews on an item are averaged for each user and then organized in twenty classes which span between 0 and 1 by 0.05 margin. Hence the rating matrix can be arranged in a three-dimensional tensor whose three dimensions correspond to user, item, and review text semantic similarity class with sizes M, N, and K, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Tensor Factorization</head><p>Adding the review texts semantic similarity classes in PMF to extend it to tensor factorization allows the inner product of the three associated factors (user preference, item features and review texts semantic similarity class) to be expressed as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>∑ ( )</head><p>Where is rating from user on item and is the added factor for review text semantic similarity class. Such matrix factorization implies that user ratings on items are characterized by three factors which are user preferences (matrix U), item features (matrix V) and semantic similarity between review texts (matrix T). This means that we can express the dependence of a rating for an item not only on how similar user ratings and item features are but also on how similar, the user review text on an item is, compared to other review texts by other users on same item.</p><p>Tensor factorization was implemented by computing best approximations of the ratings using the CANDECOMP/PARAFIC (CP) decomposition of vector representation (rows) of the user, item and review texts matrix. Equation ( <ref type="formula">9</ref>) can be defined as tensor product of the vectors as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>∑ ( )</head><p>Where is a user rating, , and represents the i th row of user matrix U, item matrix V and review text matrix T, respectively while denotes the vector outer product.</p><p>Hence, the interpretation of the tensor PMF given in equation ( <ref type="formula">9</ref>) is that a rating also depends on how much user preferences and item features matches the semantic and lexical similarity as expressed in the actual review texts. For example, if a user likes a "neck warmer" to keep him warm when riding a motorbike but the overall/general experience of users is very similar to this review "feels like i am being choked to death but does keep my neck warm.", then probably this particular user will not purchase the neck-warmer. It"s our assumption that user review texts offer more clues on why users preferred certain items as well as which item features they liked. Hence, the semantic similarity measure on user review texts is assumed to complement user ratings and item features in factorization approaches in predicting missing ratings.</p><p>To overcome the randomness issue in ratings the probabilistic model is illustrated in equation ( <ref type="formula">11</ref>) is considered:</p><formula xml:id="formula_9">| ( ) ( ) A C C E P T E D M A N U S C R I P T ∑ ∑ ∑ ( | ) ∑ ( ) ∑ ( ) ∑ ( | ) ∑ ∑ ∑ ( ) ∑ ‖ ‖ ∑ ‖ ‖ ∑ ‖ ‖ ( )</formula><p>Where if and zero otherwise, is the total number of ratings and C is a constant. Fixing parameters and maximizing the log-posterior with respect to is equivalent to minimizing equation (15).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Complete Bayesian Treatment</head><p>Efficiency in training tensor PMF model comes from finding only point estimates of the model parameters and hyper parameters, instead of inferring the full posterior distribution over them <ref type="bibr" target="#b27">(Salakhutdinov &amp; Mnih, 2007)</ref>. This means that the model performance and such point estimates which are computed by the maximum a posteriori (MAP) scheme are exposed to overfitting when the manual setting of the hyper parameters is not done properly, and such a scenario is more likely when a dataset is large and sparse. The difference between the MAP scheme and the Bayesian treatment is on how they find and use parameter estimates. MAP finds a point estimate for the parameters that maximizes the posteriori probability. With a dataset it finds parameter estimates that maximizes the ( | ), and eventually the model uses the parameter to make predictions about unseen data. But such outcome of the parameter estimate is very sensitive to random variations in data which leads to overfitting. The Bayesian model comes up with a distribution of possible parameters using Bayes' rule. Then, uses the parameter distribution to make predictions about future observations by integrating it over possible values of θ.</p><p>Hence, a complete Bayesian treatment is applied to the extended PMF to avoid over fitting, as the treatment establish priors on parameters, and thus proper averaging over different models and eventually guarantees fine tuning of parameters. This is achieved by applying sampling-based approximation methods, such as Markov Chain Monte Carlo (MCMC) instead of integrating over the distribution of parameter estimates. Similarly to the works of <ref type="bibr" target="#b28">Salakhutdinov &amp; Mnih (2008)</ref> who used MCMC in their Bayesian treatments, we extend PMF to Bayesian Probabilistic Matrix Factorization (BPMF) approach, and refer to the extended model as Review Text Tensor Factorization (RTTF).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Several experiments were conducted in order to evaluate the performance of the proposed methods and consequently assess the influence introduced by review texts semantic similarity on PMF model. This section provides a description of the dataset used, experimental design and the evaluation metric that was used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>Experimental evaluation was carried out on real world datasets from Amazon.com provided by <ref type="bibr" target="#b10">(He &amp; McAuley, 2016)</ref> which consisted ratings between 500,176 to 3,447,249 and reviews between 10, 261 to 346, 355. Amazon.com is an online Mall which sells numerous products such as books, electronics, office products, clothing, shoes, jewelry, cell phones and accessories etc. It widely employs recommender systems to recommend products to users based on the user"s purchase and rating history <ref type="bibr" target="#b22">(Raghavan et al., 2012)</ref>. The data consisted of user IDs, product IDs, associated ratings and the review texts from users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Design</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Data Preprocessing</head><p>The review texts from the dataset were preprocessed to obtain information such as lemmas, parts of speech and syntactic dependencies which are very useful in computing semantic similarities between the reviews. The task consisted four steps as described by the SEMILAR toolkit <ref type="bibr" target="#b24">(Rus et al., 2013)</ref>; Tokenization -Stanford standard tokenizer was used, Extraction of word's base form -Porter stemmer was applied, Part of speech tagging -Stanford part of speech tagger was used, and Syntactic parsing -Stanford parsing was applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Computing Semantic Similarity</head><p>The SEMILAR toolkit was used to calculate how similar two review texts are in the scale of 0 to 1, 0 being that the two reviews in question are completely different, and 1 being the two reviews are equivalent. Lexical overlap method was set to compute semantic similarity between reviews as well as lin method for token similarity, and Quadratic Assignment (QAP) technique to compare and match words between any two review texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Baseline and Evaluation Metric</head><p>PMF model together with the proposed RTTF model were implemented using MATLAB, and the results of the proposed model were evaluated and compared with two baseline models. The results of PMF model served to initialize the proposed model. The PMF model was trained using stochastic gradient descent with a fixed learning rate of 0.001 to learn it"s parameters. The parameters of the PMF model were manually tuned to ensure best results are achieved. To train RTTF models Gibbs sampling was applied. Since Gibbs sampling requires to be initialized with</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T some prior knowledge, the results from the PMF model were used to initialize the sampling and for the prior parameters for the models we followed the work by <ref type="bibr" target="#b28">Salakhutdinov &amp; Mnih, (2008)</ref>, which were the user bias and item bias for PMF model and the Wishart ̃ for RTTF model.</p><p>Several latent factors and different number of samples were experimented to evaluate model behavior. PMF model relies on latent factors to determine user"s preferences <ref type="bibr" target="#b27">(Salakhutdinov &amp; Mnih, 2007)</ref>, in this study we consider Bayesian PMF based on review text semantic similarity.</p><p>Hence, the study investigated the impact of adding user review texts semantic similarity to the probabilistic model, to check if it supplements the idea behind PMF model and check whether rating prediction improves. To evaluate the performance of the methods, the commonly used Mean Squared Error (MSE) was computed. We evaluated and compared the proposed model with HFT and RAS models presented by <ref type="bibr" target="#b17">McAuley &amp; Leskovec (2013)</ref> and <ref type="bibr" target="#b36">Yu et al.(2017)</ref>, respectively, which use review texts together with latent models in rating prediction as described in subsections 2.1.1 and 2.1.3, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results and Discussions</head><p>The results obtained from our experiments indicate that Bayesian Probabilistic Tensor Factorization based on Review Text (RTTF) approach performs consistently and significantly better than BPMF, HFT and RAS. This is illustrated in table 1 in terms of the MSE. Similar experimental conditions were set compared to the works by <ref type="bibr" target="#b17">McAuley &amp; Leskovec (2013)</ref> and <ref type="bibr" target="#b36">Yu et al.(2017)</ref>, this involved setting the number of latent factors D = 5, and 50 samples for BPMF and RTTF models. Table <ref type="table" target="#tab_0">1</ref> illustrates the performance of our proposed model in terms of the MSE as compared HFT and RAS models. Figure <ref type="figure">1</ref> shows the variation of the MSE for 50 samples while varying the number of factors from 5 to 35 for RTTF method. From the figures, the MSE drops as the number of factors are increased and best results are obtained at D=25 or D=30 number of factors, after which the error slightly increases.</p><p>The two baseline models, HFT and RAS, consider modeling of topics and aspect sentiment expressed in review texts to improve rating prediction. The variation between topics in user review texts and historical ratings which the HFT model considers, is assumed to be a subset in our proposed model since the semantic and lexical similarity involves checking not only the semantic association between topical words but also the lexical similarity resulting to discovering insights behind preferences, and hence we argue that computing semantic similarities between review texts and leveraging factorization methods like PMF is the key to generating a set of most similar users with semantically similar review texts and historical ratings. From the results, the proposed RTTF model verifies our belief that semantic similarity between review texts successful portray user preferences as it obtains better predictions. With the RAS model, latent factors, hidden topics and aspect sentiments are combined to learn latent user</p><formula xml:id="formula_10">A C C E P T E D M A N U S C R I P T</formula><p>and item factors, and it associates the historical ratings with aspect sentiment to find an explanation towards user preferences. But we argue that the reasons behind users" preferences are well reflected in the semantic similarity as opposed to sentiment analysis of the review texts as verified by the experimental results. The results suggest that inclusion of review texts semantic similarity as an additional factor in the factorization models specifically BPMF, not only works well with real world data but also improves the performance in rating prediction.  Our results suggest that vital information contained in users" review texts can aid preference prediction in CF based approaches by quantifying the reviews through computation of semantic similarity between reviews on same items. This is crucial complimentary to the central task of CF approaches that relies only on similar historical ratings between users to predict users" preferences. The results verify our initial belief that review texts semantic similarity provide insights regarding user preferences, and can assist CF approaches in rating prediction.</p><p>Bayesian extension to PMF model was employed to avoid the overfitting problem as it uses a distribution of possible model parameters to make predictions about unobserved data. However, recent advances in deep learning allows setting up of basic parameters about the data and let the model learn on its own by using many layers of processing as opposed to BPMF and other similar models which organizes data and make predictions through predefined equations. Despite the fact that deep learning models have shown to achieve state-of-the art results, it seems that the large part of the semantic information is in the entire space of activation as rather than the individual units for visual and speech recognition problems. A similar, but even stronger conclusion was reached for word (text) representations where the various directions in the vector space representing the words are shown to give rise to a surprisingly rich semantic encoding of relations and analogies. At the same time the vector representations are stable, so the individual units of the vector representations are unlikely to contain semantic information <ref type="bibr" target="#b32">(Szegedy et al., 2013)</ref>. This puts into question the way deep learning models separates variation of factors and its suitability in preference predictions involving review texts since preference prediction relies on associated user factors, item features and semantic similarity found in review texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this study, we have considered user review texts as an important source of knowledge to assist collaborative filtering approaches in rating prediction. We established a mechanism of quantifying the review texts on same items by computing semantic similarities between them.</p><p>Our findings indicate that semantic similarities between user reviews on same item characterize well user preferences and when incorporated in rating prediction methods, they provide significant performance improvement. This was verified with our experiments on Bayesian PMF model, which was extended to include semantic similarities between user review texts as an additional factor in preference prediction. Future work will explore more ways of exploiting and representing users" review texts and come up with an effective approach on how to incorporate the acquired knowledge for improved ratings prediction. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .Fig. 2 .</head><label>12</label><figDesc>Fig. 1. MSE for different number of factorsWe also provide how the MSE of the proposed method vary when different numbers of samples are taken. As illustrated in figure2, RTTF MSE fluctuates as the number of samples increase. With 50 number of samples the model produces best results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>MSE for Different methods with D=5 number of factors used, best results are highlighted</figDesc><table><row><cell>Dataset</cell><cell>MF</cell><cell>HFT</cell><cell>HFT</cell><cell>RAS</cell><cell>RAS</cell><cell>RTTF</cell></row><row><cell></cell><cell></cell><cell>(user)</cell><cell>(item)</cell><cell>(user)</cell><cell>(item)</cell><cell></cell></row><row><cell>Cell Phones &amp; Access.</cell><cell cols="6">2.230 2.132 2.135 2.131 2.118 2.238</cell></row><row><cell>Music Instruments</cell><cell cols="6">1.506 1.397 1.396 1.424 1.420 1.207</cell></row><row><cell>Gourmet Food</cell><cell cols="6">1.515 1.434 1.431 1.450 1.439 1.806</cell></row><row><cell>Office Products</cell><cell cols="6">1.814 1.670 1.680 1.651 1.622 1.210</cell></row><row><cell>Automotive</cell><cell cols="6">1.570 1.428 1.428 1.418 1.409 1.228</cell></row><row><cell>Baby</cell><cell cols="6">1.615 1.439 1.442 1.440 1.429 1.462</cell></row><row><cell>Patio</cell><cell cols="6">1.771 1.681 1.698 1.699 1.683 1.621</cell></row><row><cell>Pet Supplies</cell><cell cols="6">1.700 1.592 1.582 1.584 1.552 1.536</cell></row><row><cell>Beauty</cell><cell cols="6">1.399 1.358 1.347 1.370 1.336 1.364</cell></row><row><cell>Health</cell><cell cols="6">1.613 1.544 1.528 1.528 1.507 1.377</cell></row><row><cell>Toys and Games</cell><cell cols="6">1.467 1.370 1.366 1.382 1.385 1.054</cell></row><row><cell>Tools &amp; Home Imp.</cell><cell cols="6">1.600 1.505 1.499 1.487 1.480 1.406</cell></row><row><cell>Sports and Outdoors</cell><cell cols="6">1.219 1.139 1.136 1.146 1.133 1.129</cell></row><row><cell>Amazon Instant Video</cell><cell cols="6">1.330 1.256 1.260 1.257 1.240 1.173</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T 12</head><p>The conditional distribution given is a Gaussian distribution with mean and variance</p><p>. If it happens that the user review texts are all similar, i.e. in equation ( <ref type="formula">11</ref>) is all-one vector then the model reduces to the basic PMF model. Given the fact that the rating matrix is very sparse (many entries are missing), estimation based on tensor factorization model as expressed in equation ( <ref type="formula">11</ref>) may overfit the observed ratings and fail to predict the missing ratings properly. To avoid the overfitting issue of the rating matrix R, Bayesian treatment is applied to the PMF model based on review text semantic similarity, as the rating matrix is very sparse. This is achieved by imposing zero mean, independent Gaussian priors on user and feature vectors, as implemented by <ref type="bibr" target="#b28">Salakhutdinov &amp; Mnih, (2008)</ref>:</p><p>Where is D-by-D identity matrix.</p><p>With the semantic similarity between review texts as additional factor, it is assumed that different semantic similarity scores offer different influence on rating predictions, hence appropriate prior beliefs were imposed depending on the similarity score. With this, we assumed each semantic similarity of a particular user review as compared to other reviews on same items is conditioned on that similarity given the similarity of the remaining reviews on the same item excluding it. The applied conditional prior is as follows:</p><p>Where is the semantic similarity of review texts excluding the k th review.</p><p>In this study, all model parameters are learned using stochastic gradient descent with regularization and combining with the sparse observations to estimate unknown ratings by maximizing the logarithm of posterior distribution. This is equivalent to minimizing the objective function given as follows:</p><p>Equation ( <ref type="formula">16</ref>) provides similar results to maximizing the logarithm of posterior distribution as follows: </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Scalable tensor factorizations for incomplete data</title>
		<author>
			<persName><forename type="first">E</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Dunlavy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Kolda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mørup</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chemolab.2010.08.004</idno>
		<ptr target="https://doi.org/10.1016/j.chemolab.2010.08.004" />
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="41" to="56" />
		</imprint>
		<respStmt>
			<orgName>Chemometrics and Intelligent Laboratory Systems</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">SemEval-2012 Task 6 : A Pilot on Semantic Textual Similarity</title>
		<author>
			<persName><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/S/S12/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Workshop on Semantic Evaluation, SemEval@NAACL-HLT 2012</title>
				<meeting>the 6th International Workshop on Semantic Evaluation, SemEval@NAACL-HLT 2012<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-06-07">2012. June 7-8, 2012</date>
			<biblScope unit="page" from="385" to="393" />
		</imprint>
	</monogr>
	<note>Montreal: The Association for Computer Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Empirical analysis of predictive algorithms for collaborative filtering</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Breese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kadie</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1553-2712.2011.01172.x</idno>
		<ptr target="https://doi.org/10.1111/j.1553-2712.2011.01172.x" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Annual Conference on Uncertainty in Artificial Intelligence</title>
				<meeting>the 14th Annual Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="43" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Identifying helpful online reviews with word embedding features</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Niu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-47650-6_10</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-47650-6_10" />
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9983</biblScope>
			<biblScope unit="page" from="123" to="133" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Recommender systems based on user reviews: the state of the art</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11257-015-9155-5</idno>
		<ptr target="https://doi.org/10.1007/s11257-015-9155-5" />
	</analytic>
	<monogr>
		<title level="j">User Modeling and User-Adapted Interaction</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="154" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Incorporating User Preferences across Multiple</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-63579-8_44</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-63579-8_44" />
	</analytic>
	<monogr>
		<title level="m">Asia-Pacific Web (APWeb) and Web-Age Information Management (WAIM) Joint Conference on Web and Big Data</title>
				<meeting><address><addrLine>Beijing; Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="575" to="590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Multi-Criteria Evaluation Of A User-Generated Content Based Recommender System</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Esparza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>O" Mahony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Smyth</surname></persName>
		</author>
		<ptr target="http://expert.knowledgetransferireland.com/publications/21655%5Cnhttp://www.dcs.warwick.ac.uk/~ssanand/RSWeb11/9Esparza.pdf%5Cnhttps://www.researchgate.net/publication/251423302_A_Multi-Criteria_Evaluation_of_a_User-Generated_Content_Based_Recommender_Sys" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd ACM RecSys&apos;10Workshop on Recommender Systems and the Social Web</title>
				<meeting>the 3rd ACM RecSys&apos;10Workshop on Recommender Systems and the Social Web</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Effective product recommendation using the real-time web</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Esparza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>O"mahony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Smyth</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-0-85729-130-1-1</idno>
		<ptr target="https://doi.org/10.1007/978-0-85729-130-1-1" />
	</analytic>
	<monogr>
		<title level="m">Incorporating Applications and Innovations in Intel. Sys. XVIII -AI 2010, 30th SGAI Int. Conf. on Innovative Techniques and Applications of Artificial Intel</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">XXVII</biblScope>
			<biblScope unit="page" from="5" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improving the performance of recommender systems by alleviating the data sparsity and cold start problems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI International Joint Conference on Artificial Intelligence</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3217" to="3218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A Survey of Text Similarity Approaches</title>
		<author>
			<persName><forename type="first">H</forename><surname>Gomaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fahmy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
		<idno type="DOI">10.5120/11638-7118</idno>
		<ptr target="https://doi.org/10.5120/11638-7118" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Applications</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="13" to="18" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Ups and Downs: Modeling the Visual Evolution of Fashion Trends with One-Class Collaborative Filtering</title>
		<author>
			<persName><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
		<idno type="DOI">10.1145/2872427.2883037</idno>
		<ptr target="https://doi.org/10.1145/2872427.2883037" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Beyond the stars: exploiting free-text user reviews to improve the accuracy of movie recommendations</title>
		<author>
			<persName><forename type="first">N</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Weber</surname></persName>
		</author>
		<idno type="DOI">10.1145/1651461.1651473</idno>
		<ptr target="https://doi.org/10.1145/1651461.1651473" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st International CIKM Workshop on Topic-Sentiment Analysis for Mass Opinion</title>
				<meeting>the 1st International CIKM Workshop on Topic-Sentiment Analysis for Mass Opinion</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Combining Local Context and WordNet Similarity for Word Sense Identification</title>
		<author>
			<persName><forename type="first">C</forename><surname>Leacock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chodorow</surname></persName>
		</author>
		<ptr target="https://doi.org/citeulike-article-id:1259480" />
		<imprint>
			<date type="published" when="1998">1998. JANUARY 1998</date>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
	<note>WordNet: An Electronic Lexical Database</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chung</surname></persName>
		</author>
		<ptr target="https://doi.org/10.1.1.69.1870" />
		<title level="m">Integrating Collaborative Filtering and Sentiment Analysis : A Rating Inference Approach. ECAI 2006 Workshop on Recommender Systems</title>
				<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="62" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An Information-Theoretic Definition of Similarity</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="https://doi.org/10.1.1.55.1832" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
				<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="296" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Combining user preferences and user opinions for accurate recommendation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Du</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.elerap.2012.05.002</idno>
		<ptr target="https://doi.org/10.1016/j.elerap.2012.05.002" />
	</analytic>
	<monogr>
		<title level="j">Electronic Commerce Research and Applications</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14" to="23" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bayesian probabilistic matrix factorization with social relations and item contents for recommendation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.dss.2013.04.002</idno>
		<ptr target="https://doi.org/10.1016/j.dss.2013.04.002" />
	</analytic>
	<monogr>
		<title level="j">Decision Support Systems</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="838" to="850" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Hidden factors and hidden topics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="DOI">10.1145/2507157.2507163</idno>
		<ptr target="https://doi.org/10.1145/2507157.2507163" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM conference on Recommender systems -RecSys &apos;13</title>
				<meeting>the 7th ACM conference on Recommender systems -RecSys &apos;13</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="165" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Content-Based Recommendation Systems The Adaptive Web</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pazzani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Billsus</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-540-72079-9_10</idno>
		<ptr target="https://doi.org/10.1007/978-3-540-72079-9_10" />
	</analytic>
	<monogr>
		<title level="m">The Adaptive Web</title>
				<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4321</biblScope>
			<biblScope unit="page" from="325" to="341" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Information content measures of semantic similarity perform better without sense-tagged text</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pedersen</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=1858046%5Cnpapers3://publication/uuid/F477B778-472F-4A7C-AB6D-0688DBC20E06" />
		<imprint>
			<date type="published" when="2010-06">2010. June</date>
			<biblScope unit="page" from="329" to="332" />
		</imprint>
	</monogr>
	<note>Human Language Technologies: The 2010 Annual …</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">X-Similarity : Computing Semantic Similarity between Concepts from Different Ontologies object instrumentality</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G M</forename><surname>Petrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varelas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hliaoutakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Raftopoulou</surname></persName>
		</author>
		<ptr target="http://www.dirf.org/jdim/abstractv4i4.htm#v4n4a5" />
	</analytic>
	<monogr>
		<title level="j">JDIM</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="233" to="237" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Towards Text-Based Recommendations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Poirier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fessant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Tellier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schluth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th international conference on Adaptivity, Personalization and Fusion of Heterogeneous Information</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="9" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Review quality aware collaborative filtering</title>
		<author>
			<persName><forename type="first">S</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gunasekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ghosh</surname></persName>
		</author>
		<idno type="DOI">10.1145/2365952.2365978</idno>
		<ptr target="https://doi.org/10.1145/2365952.2365978" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th ACM Conference on Recommender Systems -RecSys &apos;12</title>
				<meeting>the 6th ACM Conference on Recommender Systems -RecSys &apos;12</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">123</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Using information content to evaluate seantic similarity in a taxonomy</title>
		<author>
			<persName><forename type="first">P</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Joint Conference on Artificial Intelligence (IJCAI)</title>
				<meeting>the 14th International Joint Conference on Artificial Intelligence (IJCAI)</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">SEMILAR : The Semantic Similarity Toolkit</title>
		<author>
			<persName><forename type="first">V</forename><surname>Rus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lintean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Banjade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Niraula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stefanescu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="163" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The SIMILAR Corpus: A Resource to Foster the Qualitative Understanding of Semantic Similarity of Texts</title>
		<author>
			<persName><forename type="first">V</forename><surname>Rus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lintean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Moldovan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Baggett</surname></persName>
		</author>
		<ptr target="http://scholar.google.ca/scholar?hl=en&amp;q=SIMILAR+Corpus:+A++resource+to+foster+the+qualitative+understanding+of+semantic+similarity+of+texts&amp;btnG=&amp;as_sdt=1" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of Semantic Relations-II. Enhancing Resources and Applications. The 8th Language Resources and Evaluation Conference (LREC 2012</title>
				<meeting>Semantic Relations-II. Enhancing Resources and Applications. The 8th Language Resources and Evaluation Conference (LREC 2012</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName><surname>=#0</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Probabilistic Matrix Factorization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<idno type="DOI">10.1145/1390156.1390267</idno>
		<ptr target="https://doi.org/10.1145/1390156.1390267" />
	</analytic>
	<monogr>
		<title level="m">Proc. Advances in Neural Information Processing Systems 20 (NIPS 07)</title>
				<meeting>Advances in Neural Information essing Systems 20 (NIPS 07)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1257" to="1264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Bayesian probabilistic matrix factorization using Markov chain Monte Carlo</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<idno type="DOI">10.1145/1390156.1390267</idno>
		<ptr target="https://doi.org/10.1145/1390156.1390267" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Machine Learning</title>
				<meeting>the 25th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2005">2008. 2008. 2005</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="880" to="887" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A semantic similarity method based on information content exploiting multiple ontologies</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Batet</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.eswa.2012.08.049</idno>
		<ptr target="https://doi.org/10.1016/j.eswa.2012.08.049" />
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1393" to="1399" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Personalised Rating Prediction for New Users Using Latent Factor Models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Seroussi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bohnert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Zukerman</surname></persName>
		</author>
		<idno type="DOI">10.1145/1995966.1995976</idno>
		<ptr target="https://doi.org/10.1145/1995966.1995976" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22Nd ACM Conference on Hypertext and Hypermedia</title>
				<meeting>the 22Nd ACM Conference on Hypertext and Hypermedia</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="47" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Generalized probabilistic matrix factorizations for collaborative filtering</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDM.2010.116</idno>
		<ptr target="https://doi.org/10.1109/ICDM.2010.116" />
	</analytic>
	<monogr>
		<title level="m">Proceedings -IEEE International Conference on Data Mining, ICDM</title>
				<meeting>-IEEE International Conference on Data Mining, ICDM</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1025" to="1030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Intriguing properties of neural networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<idno>CoRR, abs/1312</idno>
		<ptr target="http://arxiv.org/abs/1312.6199" />
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Collaborative filtering with aspect-based opinion mining: A tensor factorization approach</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDM.2012.76</idno>
		<ptr target="https://doi.org/10.1109/ICDM.2012.76" />
	</analytic>
	<monogr>
		<title level="m">Proceedings -IEEE International Conference on Data Mining, ICDM</title>
				<meeting>-IEEE International Conference on Data Mining, ICDM</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1152" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">FLAME: A Probabilistic Model Combining Aspect Based Opinion Mining and Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
		<idno type="DOI">10.1145/2684822.2685291</idno>
		<ptr target="https://doi.org/10.1145/2684822.2685291" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth ACM International Conference on Web Search and Data Mining -WSDM &apos;15</title>
				<meeting>the Eighth ACM International Conference on Web Search and Data Mining -WSDM &apos;15</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="199" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">VERB SEMANTICS AND LEXICAL</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
				<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="133" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Rating prediction using review texts with underlying sentiments</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ipl.2016.08.002</idno>
		<ptr target="https://doi.org/10.1016/j.ipl.2016.08.002" />
	</analytic>
	<monogr>
		<title level="j">Information Processing Letters</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="10" to="18" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Generating virtual ratings from chinese reviews to augment online recommendations</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1145/2414425.2414434</idno>
		<ptr target="https://doi.org/10.1145/2414425.2414434" />
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Interest before liking: Two-step recommendation approaches. Knowledge-Based Systems</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.knosys.2013.04.009</idno>
		<ptr target="https://doi.org/10.1016/j.knosys.2013.04.009" />
		<imprint>
			<date type="published" when="2013">2013a</date>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="46" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Opinion-based collaborative filtering to solve popularity bias in recommender systems</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-40173-2_35</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-40173-2_35" />
	</analytic>
	<monogr>
		<title level="j">LNCS</title>
		<imprint>
			<biblScope unit="volume">8056</biblScope>
			<biblScope unit="page" from="426" to="433" />
			<date type="published" when="2013">2013b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A hybrid approach of topic model and matrix factorization based on two-step recommendation framework</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10844-014-0334-3</idno>
		<ptr target="https://doi.org/10.1007/s10844-014-0334-3" />
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Information Systems</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="335" to="353" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
