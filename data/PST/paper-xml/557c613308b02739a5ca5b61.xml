<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jie</forename><forename type="middle">S R</forename><surname>Yang</surname></persName>
						</author>
						<author>
							<persName><surname>Arashloo</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Engineering</orgName>
								<orgName type="institution">Urmia University</orgName>
								<address>
									<postCode>57135</postCode>
									<settlement>Urmia</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Electronic Engineering</orgName>
								<orgName type="institution">University of Surrey</orgName>
								<address>
									<postCode>GU2 7XH</postCode>
									<settlement>Surrey</settlement>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7C1A0CBD7B9B8A25EEFD4872E59216A3</idno>
					<idno type="DOI">10.1109/TIFS.2014.2359587</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Class-Specific Kernel Fusion of Multiple Descriptors for Face Verification Using Multiscale Binarised Statistical Image Features</head><p>Shervin Rahimzadeh Arashloo and Josef Kittler, Member, IEEE Abstract-This paper addresses face verification in unconstrained settings. For this purpose, first, a nonlinear binary class-specific kernel discriminant analysis classifier (CS-KDA) based on spectral regression kernel discriminant analysis is proposed. By virtue of the two-class formulation, the proposed CS-KDA approach offers a number of desirable properties such as specificity of the transformation for each subject, computational efficiency, simplicity of training, isolation of the enrolment of each client from others and increased speed in probe testing. Using the proposed CS-KDA approach, a regional discriminative face image representation based on a multiscale variant of the binarized statistical image features is proposed next. The proposed component-based representation when coupled with the dense pixel-wise alignments provided by a symmetric MRF matching model reduces the sensitivity to misalignments and pose variations, gauging the similarity more effectively. Finally, the discriminative representation is combined with two other effective image descriptors, namely the multiscale local binary patterns and the multiscale local phase quantization histograms via a kernel fusion approach to further enhance system accuracy. The experimental evaluation of the proposed methodology on challenging databases demonstrates its advantage over other methods. Index Terms-Face verification, class-specific kernel discriminant analysis, binarized statistical image features, descriptor fusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>W ITH the saturation of performance of face recognition systems on controlled data, the recent focus of research in this area has been directed more towards recognizing faces in challenging conditions of real life photos. In these situations, imaging conditions previously kept under control in laboratory settings such as pose, illumination, expression, occlusion, low resolution, etc. may vary uncontrollably, perturbing image data and subsequently leading to classification errors. From a pattern classification point of view, the problem has been approached in a variety of ways with different levels of success. A line of research in this respect is focused on designing classifiers which can better cope with the nonlinearities of face manifold <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b3">[4]</ref>. Complementary to the design of more effective classifiers in dealing with image degradations are the attempts to develop or combine robust low level image representations <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b6">[7]</ref>. The current work follows both avenues by proposing a new kernel space regional face image representation and a class-specific nonlinear classifier which combines multiple representations in a discriminative subspace.</p><p>The algorithms based on subspace techniques are the most widely employed methods in face recognition. These methods usually represent facial images by vectors and then try to find a projection function by optimising some criterion over these vectors. PCA <ref type="bibr" target="#b7">[8]</ref> and LDA <ref type="bibr" target="#b8">[9]</ref> are two prominent examples of the methods in this category. As LDA seeks to find an optimal projection such that the separation between different classes is maximised, it is generally believed that it performs better than its PCA-based counterpart. However, the performances of linear classifiers drop as soon as the data to be classified is highly complex and nonlinear. A suitable alternative in such cases is offered by nonlinear classification techniques such as kernel discriminant analysis. In this framework, the data are implicitly mapped into a very high dimensional space (possibly infinite dimensional) with the hope that they become linearly separable in this new space <ref type="bibr" target="#b9">[10]</ref>- <ref type="bibr" target="#b11">[12]</ref>. Nevertheless, a drawback of these methods is their high computational complexity which often requires eigen-analysis of dense matrices. Recently, a spectral regression based kernel discriminant analysis (SR-KDA) has been proposed which uses spectral regression instead of costly eigen-analysis computation <ref type="bibr" target="#b12">[13]</ref>. The method has been shown to be orders of magnitude faster than the ordinary KDA. Drawing on this approach and motivated by similar works <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, in this paper a client-specific spectral regression-based KDA approach (CS-KDA) is proposed which casts a multi-class classification task into a binary-class problem. Using a spectral regression framework, in contrast to other class-specific KDA projections, the eigen-analysis computation in the proposed approach is avoided. In addition, by virtue of the two-class formulation, the individual patterns mapped onto the feature space are represented as one dimensional data compared to the C -1 dimensional vectors obtained in the multi-class scenario (C being the number of classes). This has significant implications on training, enrolment and testing stages of a verification system as follows. First of all, as each client class is represented by a distinct transforma-tion, the mapping onto the feature space is subject-specific. As a result, personal facial characteristics of each subject are embedded in the transformation function which in turn enhances system accuracy. Moreover, as the enrolment of each subject into the verification system is isolated from the enrolment of others, registering a new user into the system does not alter the transformation functions of the subjects previously enrolled. In addition, the proposed CS-KDA approach is computationally more efficient than the conventional multiclass SR-KDA in various stages of a face recognition system. An appealing characteristic of the proposed approach is the operability in a single sample framework, thus providing a suitable solution for various applications including image pair matching <ref type="bibr" target="#b15">[16]</ref>, passport check, etc.</p><p>The CS-KDA method is used to construct a discriminative face image descriptor using the binarised statistical image features (BSIF) <ref type="bibr" target="#b16">[17]</ref>. Similar to MLBP <ref type="bibr" target="#b17">[18]</ref> and MLPQ <ref type="bibr" target="#b18">[19]</ref> representations, the binarised statistical image features encode local micro-structures of image content into a string of binary codes. But unlike these approaches, it employs statistics of images to learn its filters which improves its representational capacity. Moreover, the employed descriptor is be able to capture image content at multiple resolutions using filters of different spatial scales. Motivated by the works in <ref type="bibr" target="#b19">[20]</ref>- <ref type="bibr" target="#b22">[23]</ref>, for reduced sensitivity of the proposed system to misalignments and out-of-plane head rotations, two techniques are employed here. First, the multiscale BSIF filter responses are summarised regionally as histograms. Second, an MRF image matching model is employed at the image level to provide dense pixelwise correspondences between a pair of images. By symmetrising the MRF matching process, the similarity of a pair of images in the kernel space is captured more effectively in two directions. Finally, the MLBP, MLPQ and MBSIF representations are combined via a kernel fusion approach to further increase system accuracy.</p><p>In summary, the main contributions of the current work include:</p><p>• A class-specific kernel discriminant analysis approach (CS-KDA) based on spectral regression; • A kernelised regional discriminative face image descriptor (kernel MBSIF); • Combination of the MBSIF, MLBP and MLPQ representations via the CS-KDA approach; • Symmetric comparison of a pair of face images in the kernel space.</p><p>The rest of the paper is organised as follows: In Section II, we review the literature with an emphasis on KDA-based methods in face recognition. In Section III, after a short overview of the SR-KDA method of <ref type="bibr" target="#b12">[13]</ref>, the proposed CS-KDA approach is introduced. In Section IV, the proposed discriminative face descriptor based on the CS-KDA approach and the multiscale BSIF features is discussed. The discussion is then followed by a component based approach for kernel fusion of multiple descriptors. An experimental evaluation of the proposed methodology along with a comparison to other approaches is provided in Section V. Finally, the paper is drawn to conclusion in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>There are numerous attempts to deal with the complex patterns of faces employing different variants of kernel discriminant analysis. While in <ref type="bibr" target="#b23">[24]</ref> a kernel discriminant analysis method is utilised for the classification of faces under difficult facial expression changes, the authors in <ref type="bibr" target="#b24">[25]</ref> propose a null space-based KDA method. In this approach, samples are first mapped onto the kernel space through the so-called cosine kernel. Next, a truncated null space KDA is used which requires only a single eigenvalue analysis. In <ref type="bibr" target="#b13">[14]</ref>, the problem of face verification is cast as a two-class problem and a class-specific transformation providing a multi-dimensional projection is derived. The optimisation criterion is defined so as to maximise the similarities of genuine claims while minimising the similarity of imposter claims to the mean of each claimed class. The eigenproblem solution and the transformation function obtained include more than one kernel fisher face per class.</p><p>In <ref type="bibr" target="#b25">[26]</ref>, the authors propose to use a bagging technique to decrease the computational cost of kernel fisher discriminant analysis in the training phase by dividing the training data into several subsets and training a different classifier for each subset. A multiple kernel construction method for kernel based fisher discriminant analysis is proposed in <ref type="bibr" target="#b26">[27]</ref>. The proposed kernel is constructed as a linear combination of several base kernels with a constraint on their weights which is then used for face recognition. In <ref type="bibr" target="#b27">[28]</ref>, using the minimum squared error criterion a new kernel-based nonlinear discriminant analysis algorithm is proposed. Once the data is mapped onto a higher-dimensional feature space, the minimum squared errors criterion is employed as the discriminant rule and the corresponding transformation is derived. As this solution does not require the scatter matrices to be nonsingular, the proposed method is applicable to the under-sampled multi-class problems. In order to improve the heterogeneous face recognition performance, a coupled discriminant analysis method is proposed in <ref type="bibr" target="#b28">[29]</ref>. The upside of the method is that all samples from different modalities are employed to represent the coupled projections. In addition, the locality information in the kernel space is incorporated into the coupled discriminant analysis as a constraint to improve the generalization capability. The authors in <ref type="bibr" target="#b29">[30]</ref> proposed a multi-view dynamic face model to extract the shape-and-pose-free facial texture patterns. A kernel discriminant analysis approach is then developed to extract the significant nonlinear features maximising the between-class variance while minimising the within-class variance. In <ref type="bibr" target="#b30">[31]</ref>, a new kernel fisher discriminant analysis called complete KFD is developed where the problem formulation is divided into two phases as the kernel PCA and Fisher linear discriminant analysis. In <ref type="bibr" target="#b31">[32]</ref>, authors proposed an algorithm called KDA/QR, which extends the LDA/QR algorithm to deal with nonlinear data by using the kernel operator. Then an efficient approximation of KDA/QR called AKDA/QR is proposed. In <ref type="bibr" target="#b32">[33]</ref>, a new kernel direct discriminant analysis based on the direct linear discriminant analysis (DLDA) algorithm <ref type="bibr" target="#b33">[34]</ref> is proposed. A robust kernel model with statistical local features for face recognition is proposed in <ref type="bibr" target="#b34">[35]</ref>. In this approach, first, multi-partition max pooling is used to enhance the method's invariance to image alignment errors. Next, a kernel based representation is proposed to exploit the discriminative information available in the statistical local features. In <ref type="bibr" target="#b35">[36]</ref>, a kernel direct discriminant analysis approach is proposed. The motivating idea is that the null space of within class scatter can include discriminant information if the projection of the between-class scatter in that direction is not zero and that no significant information is lost if the null space of between class scatter is removed. In <ref type="bibr" target="#b3">[4]</ref>, a KDA fusion approach is proposed to combine MLBP and MLPQ histograms for face recognition. The method is reported to achieve good performance in challenging conditions on a number of different databases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. KERNEL DISCRIMINANT ANALYSIS (KDA)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overview</head><p>Let us assume that there exist m samples x 1 , x 2 , . . . x m ∈ R n , which belong to C classes and F is a feature space induced by a nonlinear mapping φ : R n → F . For a suitably chosen mapping, an inner product ., . on F may be represented as φ(x i ), φ(x j ) = κ(x i , x j ), where κ(., .) is a positive semi-definite kernel function. Let S φ b , S φ w and S φ t denote respectively the between-class, within-class and total scatter matrices in the feature space F . Then we have</p><formula xml:id="formula_0">S φ b = C k=1 m k (μ k φ -μ φ )(μ k φ -μ φ )<label>(1)</label></formula><formula xml:id="formula_1">S φ w = C k=1 m k i=1 (φ(x k i ) -μ k φ )(φ(x k i ) -μ k φ ) (2) S φ t = S φ b + S φ w = m i=1 φ(x i ) -μ φ φ(x i ) -μ φ (<label>3</label></formula><formula xml:id="formula_2">)</formula><p>where μ k φ and μ φ are the centroid of the k th class and the global centroid in the feature space, respectively. m k is the number of samples in the k th class and x k i denotes the i th sample in the k th class. KDA seeks to find an optimal projection function V opt in the feature space by solving the following optimisation problem</p><formula xml:id="formula_3">V opt = arg max V V S φ b V V S φ w V (4)</formula><p>which is equivalent to <ref type="bibr" target="#b36">[37]</ref> </p><formula xml:id="formula_4">V opt = arg max V V S φ b V V S φ t V (5)</formula><p>The columns of V opt (ν s) are the generalized eigenvectors satisfying</p><formula xml:id="formula_5">S φ b ν = λS φ t ν (6)</formula><p>It is known that ν s satisfying the preceding problem can be expressed as linear combinations of all samples <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>. Thus, there exists coefficients α i such that each eigenvector ν can be represented as ν = m i=1 α i φ(x i ).</p><p>In <ref type="bibr" target="#b10">[11]</ref>, it is shown that Eq. 5 is equivalent to</p><formula xml:id="formula_6">U opt = arg max U U K W K U U K K U (7)</formula><p>where K is the kernel matrix (K i j = κ(x i , x j )) and W is a matrix reflecting the number of samples in each class, defined as</p><formula xml:id="formula_7">W i j = 1/m k if x k and x j both belong to the k th class; 0 otherwise.<label>(8)</label></formula><p>In this case, the columns of U opt (α s) are given by the eigenvectors corresponding to the non-zero eigenvalues satisfying</p><formula xml:id="formula_8">K W K α = λK K α (9)</formula><p>The number of α s satisfying Eq. 9 is bounded by C -1 as the rank of S φ b is at most C -1. Once α s are found, the projection of a new sample (x) onto the feature space using each eigenvector ν (hereafter referred to as kernel fisher face) is given by</p><formula xml:id="formula_9">ν, φ(x) = m i=1 α i φ(x i ), φ(x) = m i=1 α i κ(x i , x) = α K (:, x) (10)</formula><p>where</p><formula xml:id="formula_10">K (:, x) = [κ(x 1 , x), . . . , κ(x m , x)] .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Spectral Regression KDA (SR-KDA)</head><p>In <ref type="bibr" target="#b12">[13]</ref>, an efficient method to solve the eigen-problem in Eq. 9 via spectral regression is proposed which avoids costly eigen-analysis computations. The method uses the following theorem:</p><p>Theorem 1: Let y be the eigenvector of the eigen-problem W y = λy <ref type="bibr" target="#b10">(11)</ref> with the eigenvalue λ. If Kα = y, then α is the eigenvector of the eigen-problem in Eq. 9 with the same eigenvalue λ. See <ref type="bibr" target="#b12">[13]</ref> for a proof.</p><p>Using Theorem 1, one may, instead of solving the eigenproblem in Eq. 9 directly, use a two step approach to solve for α s as follows:</p><p>1) Solve W y = λy for y;</p><p>2) Find α satisfying K α = y. If K is positive-definite, then there exists a unique solution for α. If K is singular, it may be approximated by the positive definite matrix K + δ I where I is the identity matrix and δ &gt; 0 is a regularisation parameter. In this paper, a Gaussian RBF is used for the kernel function, i.e. K i j = κ(x i , x j ) = exp(-x ix j 2 /M), resulting in a positive definite kernel matrix <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>. Solving for α may then be performed using the Cholesky factorisation and forward-back substitution as follows. If K = R R, then α may be found by first solving R θ = y for θ using forward substitution and then solving Rα = θ for α using back substitution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Incremental SR-KDA</head><p>As the Cholesky decomposition has the largest computational cost in the SR-KDA method, in <ref type="bibr" target="#b12">[13]</ref> it is proposed to perform this step more efficiently using an incremental approach. In the incremental scheme, the goal is to find the Cholesky decomposition of an m × m matrix given the Cholesky decomposition of its (m -1) × (m -1) submatrix. Hence, given the Cholesky decomposition of the kernel matrix K m-1 of m -1 samples we want to compute the Cholesky factorisation of the kernel matrix K m for the augmented training set where a single sample (x m ) is injected into the system. The incremental Cholesky decomposition technique may be applied via the Sherman's March algorithm <ref type="bibr" target="#b37">[38]</ref> for K m as</p><formula xml:id="formula_11">K m = K m-1 k 1m k 1m k mm = R m-1 0 r 1m r mm R m-1 r 1m 0 r mm (<label>12</label></formula><formula xml:id="formula_12">)</formula><p>where k 1m is an (m -1) × 1 vector given by k 1m = [κ(x 1 , x m ), . . . , κ(x m-1 , x m )] and k mm = κ(x m , x m ). Eq. 12 reads</p><formula xml:id="formula_13">K m-1 = R m-1 R m-1 k 1m = R m-1 r 1m r mm = k mm -r 1m r 1m<label>(13)</label></formula><p>Thus, one first solves k 1m = R m-1 r 1m for r 1m using forward substitution and then computes r mm . The employed incremental technique reduces the computational cost of the SR-KDA approach from cubic in number of training samples in the batch mode to quadratic in the incremental mode <ref type="bibr" target="#b12">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Class-Specific SR-KDA (CS-KDA)</head><p>Class-specific projections have been considered previously for face recognition and shown to provide advantages over their multi-class alternatives. Inspired by similar approaches in LDA <ref type="bibr" target="#b14">[15]</ref> and KDA <ref type="bibr" target="#b13">[14]</ref>, in this section a class-specific kernel discriminant analysis based on the SR-KDA approach is proposed. In the proposed framework, a C-class classification problem is recast into a set of two-class problems, i.e. a probe either belongs to a claimed genuine class or to a fixed class represented by imposters. The new CS-KDA approach contrasts with the conventional KDA representation involving multiple shared kernel fisher faces in having only one classspecific kernel fisher face per class. Hence, a distinguishing characteristic of the proposed technique is the specificity of the transformation for each subject. Some other features of the proposed approach are simplicity of training, isolation of the enrolment of each client from others and computational efficiency discussed next.</p><p>Let us assume that there is one sample of the client class ω (x m ∈ ω) and a fixed set of m -1 imposter samples {x i |i = 1, . . . , m -1} (the extension to the case where more than one instance of each client are available is straightforward). The approach in this two-class problem starts by building the m × m matrix W as</p><formula xml:id="formula_14">W = ⎛ ⎜ ⎜ ⎜ ⎝ 1 m-1 . . . 1 m-1 0 . . . . . . . . . . . . 1 m-1 . . . 1 m-1 0 0 . . . 0 1 ⎞ ⎟ ⎟ ⎟ ⎠<label>(14)</label></formula><p>Since the imposter set is fixed and the number of training samples for each client is assumed to be one, matrix W would be common to all classes. Moreover, matrix W would have exactly two eigenvectors corresponding to the same eigenvalue of 1 <ref type="bibr" target="#b37">[38]</ref> as</p><formula xml:id="formula_15">y 1 = [ m-1 1, . . . , 1, 0] y 2 = [ m-1 0, . . . , 0, 1] (<label>15</label></formula><formula xml:id="formula_16">)</formula><p>As 1 is a repeated eigenvalue of W , any linear combination of the corresponding eigenvectors is also an eigenvector of W .</p><p>A vector of all ones of size m (e) would clearly be an eigenvector. Hence, following <ref type="bibr" target="#b12">[13]</ref>, we consider e as the first eigenvector and the second eigenvector (y 2 ) is orthogonalised with respect to e using the Gram-Schmidt process <ref type="bibr" target="#b37">[38]</ref> to produce y . The Gram-Schmidt process to orthogonalise y 2 with respect to e is as follows:</p><formula xml:id="formula_17">y = y 2 - e y 2 e e e = y 2 - 1 m e = [ m-1 -1 m , . . . , -1 m , m -1 m ]<label>(16)</label></formula><p>In order to obtain a unit norm eigenvector, y is divided by its norm:</p><formula xml:id="formula_18">y = y y y = y m-1 m = [ m-1 -1 √ m(m -1) , . . . , -1 √ m(m -1) , m -1 m ]<label>(17)</label></formula><p>Discarding vector e, we are left with only a single eigenvector, i.e. y . After computing K m using the new sample x m ∈ ω, the next step is to find α ω satisfying K m α ω = y . A procedure that performs this task can be summarised as follows. Given the kernel matrix K m-1 of the fixed imposter set, its Cholesky decomposition is computed offline. For the enrolment of a new sample, after computing the augmented kernel matrix K m , the Cholesky factorisation of K m only includes the computation of the vector r 1m and scalar r mm . Once the Cholesky decomposition of K m is obtained, α ω can be found using the forward-back substitution. Note that since in the proposed CS-KDA approach there is only one eigenvector associated with the equation K m α ω = y , only a single vector of size m, i.e. α ω , should be computed. This is in contrast to the multi-class scenario where a projection matrix of size m × (C -1) should be estimated each time a single sample is injected into the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Decision Strategy for CS-KDA</head><p>If a probe subject asserts class ω as his/her identity, the features of that person (z) is mapped onto the subspace represented by ν ω to form a discriminative representation as</p><formula xml:id="formula_19">p z = ν ω , φ(z) = m i=1 α ωi φ(x i ), φ(z) (18)</formula><p>where ν ω is the kernel fisherface for class ω. For decision making, p z can be compared against the mean of the imposter set (η) in the same discriminative subspace of ν ω . The projection of η onto ν ω is obtained as</p><formula xml:id="formula_20">p η = ν ω , φ(η) = m i=1 α ωi φ(x i ), φ(η)<label>(19)</label></formula><p>In this case, one would expect the projected probe of a genuine claimant to be far from the projected imposter mean, resulting in the following decision criterion:</p><formula xml:id="formula_21">| p z -p η | ≤ t ω reject claim | p z -p η | &gt; t ω accept claim</formula><p>where t ω is the threshold for class ω to accept/reject a claim.</p><p>| p zp η | can be rewritten as</p><formula xml:id="formula_22">| p z -p η | = | ν ω , φ(z) -ν ω , φ(η) | = | m i=1 α ωi φ(x i ), φ(z) - m i=1 α ωi φ(x i ), φ(η) | = | m i=1 α ωi κ(x i , z)- m i=1 α ωi κ(x i , η)| = | m i=1 α ωi [κ(x i , z)-κ(x i , η)]| = |α ω K - ω |<label>(20)</label></formula><formula xml:id="formula_23">K - ω = [κ(x 1 , z) -κ(x 1 , η), . . . , κ(x m , z) -κ(x m , η)]</formula><p>. Since, the imposter set and as a result the mean is fixed, the terms κ(x i , η) (for i = 1, . . . , m) can be computed during training and enrolment phases and used in the verification phase to speed up probe testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Discussion</head><p>Let us assume that the verification system is in the operation phase (after training and enrolment of C -1 users) and an additional user is to be enrolled into the system. In this case, in the common multi-class SR-KDA approach, matrix W should be updated and its C -1 eigenvectors would have to be found using the Gram-Schmidt method. In contrast, in the CS-KDA approach as W remains constant and common to all classes, the requirement to resolve for its eigenvectors is circumvented. As the main computational cost in this step is the cost of Gram-Schmidt process, the proposed CS-KDA approach saves mC 2 -1 3 C 3 compound arithmetic operations (flams) each consisting of one multiplication and one addition compared to the multi-class approach. Next, in the multi-class scenario, after computing the Cholesky decomposition of the new augmented kernel matrix (K m ), C -1 linear equations of the form K m α = y need to be solved to form the new transformation function. In contrast, in the proposed CS-KDA approach only one linear equation corresponding to the new</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Training</head><p>Offline computations 1: procedure</p><formula xml:id="formula_24">2: Set y = [ m-1 -1 √ m(m -1) , . . . , -1 √ m(m -1) , m-1 m ] 3:</formula><p>Calculate the kernel matrix K m-1</p><formula xml:id="formula_25">4: Find R m-1 satisfying K m-1 = R m-1 R m-1 5:</formula><p>Estimate mean of the imposter set (η) 6:</p><p>Calculate κ(x i , η) for i = 1, . . . , m -1</p><p>Save R m-1 , κ(x i , η) s and y 8: end procedure</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 Enrolling Class ω by Sample x m</head><p>Online computations 1: procedure</p><formula xml:id="formula_27">2: Calculate k 1m = [κ(x 1 , x m ), . . . , κ(x m-1 , x m )] and k mm = κ(x m , x m ) 3:</formula><p>Find r 1m satisfying k 1m = R m-1 r 1m 4:</p><p>Calculate r mm = k mmr 1m r 1m 5:</p><p>Form the Cholesky decomposition of K m as</p><formula xml:id="formula_28">K m = R m R m = R m-1 0 r 1m r mm R m-1 r 1m 0 r mm 6:</formula><p>Solve R m θ = y for θ 7:</p><p>Solve R m α ω = θ for α ω 8:</p><p>Calculate κ(x m , η)</p><formula xml:id="formula_29">9:</formula><p>Save α ω and κ(x m , η) 10: end procedure user should be solved and the projection functions of the classes previously enrolled remains unaltered. This results in a computational saving of Cm 2 flams.</p><p>During the verification (test) phase, the computational advantages of the proposed CS-KDA approach are as follows. Commonly, in a multi-class scenario, the KDA representation spans a subspace of the order of C -1 dimensions. The employed one dimensional representation in the proposed CS-KDA approach in this case results in a computational saving of mC flams compared with the multidimensional representation often employed.</p><p>An interesting property of the proposed CS-KDA approach is the operability in an unseen pair matching paradigm <ref type="bibr" target="#b15">[16]</ref>. In this scenario, two images which were not available before are presented to the system and a decision must be made whether they belong to the same subject or not. In this case, one can construct a binary classifier using a fixed imposter set and one of the images and then measure the likelihood of the second image belonging to the first class and not to the class represented by imposters. The general procedures for training (offline), enrolment (online) and testing (online) stages of the CS-KDA approach are summarised in the Algorithms 1, 2 and 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3 Testing Probe z for Class ω</head><p>Online computations 1: procedure</p><formula xml:id="formula_30">2: Set K - ω = [κ(x 1 , z) -κ(x 1 , η), . . . , κ(x m , z) - κ(x m , η)] 3: if |α ω K - ω | ≤ t ω then 4:</formula><p>Reject claim end if 8: end procedure</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. FACE REPRESENTATION USING MULTISCALE BSIF IN THE KERNEL SPACE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Multiscale BSIF Image Representation</head><p>The underlying principle of the binarised statistical image features in <ref type="bibr" target="#b16">[17]</ref> is to model the local micro-structures of image content using a set of linear filters in a neighbourhood of a pixel. The BSIF filters are applied to individual patches of an image centred at a pixel. Given an image patch p of size d × d pixels and a linear filter f n of the same size, the filter response r n is given by</p><formula xml:id="formula_31">r n = j,k f n ( j, k) p( j, k) = f n p<label>(21)</label></formula><p>where vectors f n and p include elements of f n and pixels of p, respectively. The operation of applying N different linear filters to the same patch can be represented by stacking all f n filters into a single matrix F of size N ×d 2 which generates the responses by a single matrix multiplication as r = Fp <ref type="bibr" target="#b21">(22)</ref> In the BSIF representation, the statistical dependencies of r n s are minimised via independent component analysis (ICA). For this purpose, the filter matrix F is decomposed into two parts as</p><formula xml:id="formula_32">r = Fp = UVp = Uz (<label>23</label></formula><formula xml:id="formula_33">)</formula><p>where z = Vp, and U is an N × N square matrix which is estimated using ICA. Matrix V applies a whitening transformation to the data. The dimensionality of each patch in this step is reduced using N &lt; d 2 principal eigenvectors of the covariance matrix of randomly chosen image patches. Next, given the whitened data samples z, the independent component analysis is employed to estimate an orthogonal matrix U. The filter matrix F is then derived as</p><formula xml:id="formula_34">F = UV (24)</formula><p>Finally, the response of each filter is binarised via thresholding at zero to produce a binarised feature b</p><formula xml:id="formula_35">n b n = 1 r n &gt; 0, 0 otherwise. (<label>25</label></formula><formula xml:id="formula_36">)</formula><p>The number of BSIF filters in each scale is controlled by the number of the eigenvectors retained after the whitening transform. In this work, the first 8 principal eigenvectors of the whitening transformation are used, giving rise to eight filters in each scale. Moreover, the sizes of the filters can be varied in order to capture image content at multiple resolutions.</p><p>While larger filters can better handle low frequency content and blurring effects, smaller filters are able to capture high frequency variations of image texture. By varying the filter sizes and combining BSIF descriptors in different scales, a multiresolution representation (MBSIF) is derived. The number of scales we use for the multi-scale BSIF is eight. As such, in total 64 filters are learned. Finally, the responses of filters are summarised regionally via histograms. The construction of MBSIF descriptors may be described as follows. We first apply MBSIF operators at Z scales to each face image after photometric normalisation using the method of <ref type="bibr" target="#b38">[39]</ref>. The result is a grey level code for each pixel at each resolution, Fig. <ref type="figure" target="#fig_1">1</ref>. After cropping the resultant code images to the same size, they are divided into non-overlapping rectangular regions G 0 ,G 1 ,. . . ,G J ×J -1 . The BSIF pattern histogram for region j in the scale of s, h j,s , is computed as</p><formula xml:id="formula_37">h j,s = [h 0 j,s , h 1 j,s , . . . , h L-1 j,s ] h i j,s = p c ∈G j ½{BSIF s ( p c ) = i } j ∈ [0, 1, . . . , J × J -1], s ∈ [1, 2, . . . , Z ], L = 256<label>(26)</label></formula><p>where ½{.} is an indicator function indicating whether its argument is true/false. L represents the number of histogram bins and p c denotes the centre pixel where the filter is applied. The size of the BSIF filter at scale s is set to d × d where d = 2 × s + 1. By concatenating all the histograms for each region computed at different scales into a single vector, the multiresolution MBSIF regional descriptor is formed</p><formula xml:id="formula_38">q j = [h j,1 , h j,2 , . . . , h j,Z ]<label>(27)</label></formula><p>Experimentally it has been found that eight scales (Z = 8) are enough to capture a wide range of image frequency content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. MBSIF in the Kernel Space</head><p>Once the MBSIF histograms are extracted from each region, a regional kernel matrix (K j ) is constructed using a fixed set of imposters and an instance of the subject to be recognised. Following the preceding method, a class-specific regional kernel fisherface may be estimated and used to project an MBSIF histogram onto a discriminative subspace to form the MBSIF representation in the kernel space. In order to fuse all regional information we follow the approach advocated in <ref type="bibr" target="#b3">[4]</ref> and form a combined kernel matrix G as</p><formula xml:id="formula_39">G = j K j (28)</formula><p>G can be used to estimate a kernel fisherface for the whole face. In order to boost the efficacy of the system, one may combine the MLBP, MLPQ and MBSIF representations in the kernel space. When multiple image representations are employed, the information from different channels is fused in the CS-KDA approach by adding all regional kernels K j,r corresponding to different regions j = 0, . . . , J × J -1 and different image representations r ∈ {MLBP, MLPQ, MBSIF}</p><formula xml:id="formula_40">K c = j,r K j,r<label>(29)</label></formula><p>As a result, in order to find the class-specific multiple kernel fisher face for class ω, the equation K c α ω = y is solved for α ω with the K c given by Eq. 29 and y by Eq. 17. In the test phase, the vector K - ω is formed as</p><formula xml:id="formula_41">K - ω = j [κ(x j 1 , z j ) - κ(x j 1 , η j ), . . . , κ(x j m , z j ) -κ(x j m , η j )]</formula><p>, where x j i denotes the j th region of i th training sample and z j stands for the j th region of the probe.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Symmetric Image Matching</head><p>In order to reduce the sensitivity of the system to misalignment and out of plane head rotations, we employ the dense MRF matching approach proposed in <ref type="bibr" target="#b19">[20]</ref>. In <ref type="bibr" target="#b19">[20]</ref>, an efficient MRF-based method for dense image registration based on <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b39">[40]</ref>, and <ref type="bibr" target="#b40">[41]</ref> is proposed. The method matches a block of pixels of the template to a block of pixels in the target image. The correspondences are achieved in a multiresolution framework down to the pixel level. In order to symmetrise the process, following <ref type="bibr" target="#b19">[20]</ref>, we initially match the template to the target and then exchange the roles of the two images. We repeat the procedure for the horizontally mirrored versions of both images. The regional histograms are finally constructed using the correspondences thus obtained. Once the similarity between each pair of images is computed, the final similarity score is formed by averaging the similarity scores of all pairs of matches. This way, the similarity between a pair of images is gauged symmetrically in the kernel space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experiments in Unseen Pair Matching: LFW</head><p>The labelled faces in the wild (LFW) dataset is a large database including real world variations of facial images such as pose, illumination, expression, occlusion, low resolution, blur, etc. It contains 13,233 images of 5,749 subjects. Evaluation of a method on this dataset is performed by determining whether a pair of images belongs to the same person or not. We evaluate the proposed approach on the "View 2" of the dataset consisting of 3,000 matched and 3,000 mismatched pairs divided into 10 sets. The evaluation is performed in a leave-one-out cross validation scheme on the entire test sets. The overall performance of the method over ten folds is then reported as the mean accuracy and the standard error of the mean. Different evaluation settings on this database are the image "restricted", "unrestricted" and "unsupervised" settings. The restricted setting provides training data for the image pairs as "same" or "not same". The image unrestricted setting in addition provides the identities of the subjects in each pair. In the "unsupervised" setting, no training data in the form of same/not same pairs is provided. We evaluate the proposed approach on the most "restricted" protocol where strictly LFW data is used, i.e. without any outside training data. In addition, as we do not use any training data in the form of "same" or "not same", our method is "unsupervised" and is equally comparable with the results in this setting. In an ideal case, the imposter set should not contain images of the subjects in a pair being compared. This might cause the false intuition that the method is operating in a supervised mode. However, if the number of images in the imposter set (m) is sufficiently large then inclusion of a few samples of either one of the subjects in a pair being compared in the imposter set has negligible effects. Similar observations have been made in <ref type="bibr" target="#b14">[15]</ref> in the case of linear discriminant analysis. As the inclusion of a few samples of either one of the subjects in a pair in the imposter set does affect the model, the imposter set can be considered as a random collection of face images and as a result the method is unsupervised since neither class labels nor pair labels (same/not same) are used in the construction of the model or its training data. In each of the ten experiments on the LFW data set, one out of ten subsets is used as the test set and the remaining as the training data. We use one of the 9 training subsets as the imposter set. Two separate subsets are used to learn filters for the MBSIF descriptor. Filters are learned in eight scales and in each scale eight filters are learned giving rise to an 8-bit BSIF code for a pixel in each scale. The remaining training subsets are used to set a global acceptance/rejection threshold. We use the funnelled version of the LFW data set and after computing the MLBP, the MLPQ or MBSIF code images, crop the images and keep an area of 80 × 96 pixels in the centre of the coded image. The number of regions is set to 64 (J = 8). The kernel function κ(x i , x j ) is defined as κ(x i , x j ) = exp(-x ix j 2 /M). Following <ref type="bibr" target="#b41">[42]</ref>, M is set to the average squared Euclidean distance between all training samples. In all experiments, once the MRF correspondences are established, the template image is considered as the model and a CS-KDA space is constructed using the model image and the fixed imposter set. Eight systems are evaluated in this experiment:  The results obtained in the most restricted protocol are reported in Table <ref type="table" target="#tab_0">I</ref>. We have tested four variants of the CS-KDA approach. These are the CS-KDA approach on the MLBP, MLPQ, MBSIF histograms and a combined kernel using all three descriptors. Reported in the table are also the systems employing a linear discriminant analysis rather than a kernel approach. When using linear discriminant analysis, the similarities of two corresponding regions in a pair of images are measured in the LDA space using cosine similarity and all the regional similarities obtained using different descriptors are combined via a sum rule. A number of observations from the table are in order. First of all, the proposed MBSIF descriptor is shown to perform better than the two other commonly used texture representations, namely the MLBP <ref type="bibr" target="#b17">[18]</ref> and MLPQ <ref type="bibr" target="#b18">[19]</ref>. This is illustrated both in the kernel and LDA subspaces. The improved representational capacity achieved in the new descriptor can be attributed to different facts. First, the filters employed in the construction of the MBSIF descriptor are based on statistical analysis of facial images in contrast to other ad hoc design schemes such as those used in LBP. Second, the redundancy in the input data is minimised via a whitening transform before applying the filters. Finally, by using an independent component analysis in the BSIF filter design, the filter responses become statistically independent, thus suitable for further processing under independence assumptions. Another observation is that the CS-KDA versions of all four systems consistently perform better than their LDA variants, thanks to the nonlinear nature of the CS-KDA method. In comparison to other approaches, our single descriptor system using MBSIF in the CS-KDA space (MRF-MBSIF-CSKDA) achieves an impressive performance of 93.63%, more than 6% better than the previous best result in this setting. Combination of the three different descriptors results in an improved accuracy both in the kernel and linear subspaces. Comparing our best performing system (MRF-Fusion-CSKDA) against other approaches in this setting, it can be observed that the proposed approach outperforms the previous best result by 8.42% on average. As mentioned earlier, our method is unsupervised and hence it can be compared to other methods under this protocol. The results are provided in Table <ref type="table" target="#tab_1">II</ref>. It can be observed that the proposed system improves the best result in this setting by more than 8% margin on average. The proposed system is even comparable to other approaches in the "unrestricted" protocol. The results in this setting are provided in Table <ref type="table" target="#tab_1">III</ref>. It can be observed that the MRF-Fusion-CSKDA approach achieves the best performance in this protocol despite following a restricted protocol.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experiments in Verification: XM2VTS</head><p>Next, we evaluate the proposed system on the rotation shots of the XM2VTS database <ref type="bibr" target="#b57">[58]</ref> in a verification scenario. This experiment is designed to explore the capabilities of the proposed approach subject to severe head rotations. The XM2VTS rotation data set <ref type="bibr" target="#b57">[58]</ref> is comprised of 295 subjects consisting of 200 clients, 25 evaluation imposters and 70 test imposters. The performance of the system is stated in Equal Error Rate (EER) where the False Acceptance and False Rejection rates are equal and the threshold for acceptance or rejection of a claimant is set using the true identities of test subjects. We crop the frontal training images using manually annotated eye coordinates to a size of 128 × 144 pixels so that the distance between the eyes is 70 pixels. The parameter J is set to 8 as before. The test images are detected using the Viola-Jones face detection method <ref type="bibr" target="#b58">[59]</ref>. It has been observed that the detection method failed to detect faces in ∼ 2% of the images where there were a severe head rotation. In these cases, we roughly crop out the face area from the image manually. After detection, each face image is scaled in a way that the face area corresponds roughly to an area of 128 × 144 pixels. As a result, the system is evaluated in the presence of misalignment and moderate scale deviations in addition to pose changes. In this experiment, we compare the proposed method to other pose-invariant approaches on this data set. The results are reported in Table <ref type="table" target="#tab_2">IV</ref>. From the table, it can be observed that the MRF-Fusion-CSKDA approach outperforms the MRF-Fusion-LDA and other competitors on this data set. It can be concluded that when dense pixelwise correspondences are available, the combination of the MLBP, MLPQ and MBSIF descriptors via the CS-KDA approach can provide a robust representation for face recognition across pose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>Face verification in unconstrained settings was addressed in this paper. In order to cope better with the complex nonlinear face patterns, first, a nonlinear binary class-specific classifier (CS-KDA) based on spectral regression kernel discriminant analysis was proposed. The proposed approach offered a number of desirable characteristics such as specificity of the transformation for each subject, computational efficiency, simplicity of training, isolation of the enrolment of each client from others. Using the proposed nonlinear method, a regional discriminative face image descriptor using the multiscale binarised statistical image features (MBSIF) in the kernel space was proposed next. The component-based representation was coupled with the dense pixelwise alignments provided by an MRF matching model in order to reduce the sensitivity to misalignments and pose variations. Finally, the descriptor was combined with the multiscale local binary patterns (MLBP) and the multiscale local phase quantisation (MLPQ) histograms via a kernel fusion approach which resulted in improved performance. In conclusion, the main contributions of the current work can be summarised as follows:</p><p>• a class-specific kernel discriminant analysis approach based on spectral regression was proposed which avoided costly eigen-analysis computation and high dimensional feature projections; • An effective multiscale regional discriminative face image descriptor (kernel MBSIF) in the kernel space was proposed. The descriptor enjoyed better representational capacity by employing filters learnt via statistical analysis of images and the nonlinear nature of the projection function; • A class-specific KDA fusion approach for the combination of MBSIF, MLBP and MLPQ representations was proposed. The combination was demonstrated to enhance system performance compared to either one of the single descriptor systems; • The sensitivity to pose variations was minimised by employing an MRF model at the heart of the system to provide dense symmetric alignment between a pair of face images; • The similarity between a pair of images was gauged more effectively via a symmetric approach in the kernel space.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (a) Original image, (b) normalised and cropped image, (c)-(j) BSIF images at different scales.</figDesc><graphic coords="6,381.47,58.49,111.98,132.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 )</head><label>1</label><figDesc>MRF-MLBP-LDA 2) MRF-MLPQ-LDA 3) MRF-MBSIF-LDA 4) MRF-Fusion-LDA 5) MRF-MLBP-CSKDA 6) MRF-MLPQ-CSKDA 7) MRF-MBSIF-CSKDA 8) MRF-Fusion-CSKDA</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I COMPARISON</head><label>I</label><figDesc>OF THE PERFORMANCE OF THE PROPOSED APPROACH TO THE STATE-OF-THE-ART METHODS ON THE LFW DATABASE IN THE MOST RESTRICTED SETTING (STRICT LFW, NO OUTSIDE TRAINING DATA USED)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II COMPARISON</head><label>II</label><figDesc>OF THE PERFORMANCE OF THE PROPOSED APPROACH TO THE STATE-OF-THE-ART METHODS ON THE LFW DATABASE</figDesc><table><row><cell>IN THE UNSUPERVISED SETTING</cell></row><row><cell>TABLE III</cell></row><row><cell>COMPARISON OF THE PERFORMANCE OF THE MRF-FUSION-CSKDA</cell></row><row><cell>APPROACH TO THE STATE-OF-THE-ART METHODS ON THE LFW</cell></row><row><cell>DATABASE IN THE UNRESTRICTED SETTING</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE IV COMPARISON</head><label>IV</label><figDesc>OF THE PERFORMANCE OF THE PROPOSED METHOD TO THE STATE-OF-THE-ART METHODS ON THE XM2VTS DATABASE</figDesc><table /></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was carried out as part of EPSRC project Signal Processing in a Networked Battlespace under Contract EP/K014307/1, and the European Union project Beat. The associate editor coordinating the review of this manuscript and approving it for publication was Prof.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Probabilistic elastic matching for pose variant face verification</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2013-06">Jun. 2013</date>
			<biblScope unit="page" from="3499" to="3506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cosine similarity metric learning for face verification</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Kimmel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Klette</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Sugimoto</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6493</biblScope>
			<biblScope unit="page" from="709" to="720" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Attribute and simile classifiers for face verification</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Nayar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICCV</title>
		<meeting>IEEE ICCV</meeting>
		<imprint>
			<date type="published" when="2009-10">Oct. 2009</date>
			<biblScope unit="page" from="365" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multiscale local phase quantization for robust component-based face recognition using kernel fusion of multiple descriptors</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Tahir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1164" to="1177" />
			<date type="published" when="2013-05">May 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Blessing of dimensionality: Highdimensional feature and its efficient compression for face verification</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2013-06">Jun. 2013</date>
			<biblScope unit="page" from="3025" to="3032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Face verification using the LARK representation</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1275" to="1286" />
			<date type="published" when="2011-12">Dec. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning discriminant face descriptor</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="289" to="302" />
			<date type="published" when="2014-02">Feb. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Face recognition using eigenfaces</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Turk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit</title>
		<imprint>
			<biblScope unit="page" from="586" to="591" />
			<date type="published" when="1991-06">Jun. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Eigenfaces vs. Fisherfaces: Recognition using class specific linear projection</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Hespanha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="711" to="720" />
			<date type="published" when="1997-07">Jul. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fisher discriminant analysis with kernels</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ratsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mullers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 9th IEEE Signal Process</title>
		<title level="s">Soc. Workshop Neural Netw. Signal Process.</title>
		<meeting>9th IEEE Signal ess</meeting>
		<imprint>
			<date type="published" when="1999-08">Aug. 1999</date>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Generalized discriminant analysis using a kernel approach</title>
		<author>
			<persName><forename type="first">G</forename><surname>Baudat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Anouar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2385" to="2404" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Learning With Kernels: Support Vector Machines, Regularization, Optimization, and Beyond</title>
		<author>
			<persName><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Speed up kernel discriminant analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB J</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="33" />
			<date type="published" when="2011-02">Feb. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Class-specific kerneldiscriminant analysis for face verification</title>
		<author>
			<persName><forename type="first">G</forename><surname>Goudelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tefas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Pitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="570" to="587" />
			<date type="published" when="2007-09">Sep. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Face verification using client specific fisher faces</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Statistics of Directions, Shapes and Images, Leeds Annual Statistical Reserach</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Labeled faces in the wild: A database for studying face recognition in unconstrained environments</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">School Comput. Sci., Univ. Massachusetts</title>
		<imprint>
			<biblScope unit="page" from="7" to="49" />
			<date type="published" when="2007-10">Oct. 2007</date>
			<pubPlace>Amherst, MA, USA, Tech</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">BSIF: Binarized statistical image features</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rahtu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 21st Int. Conf. Pattern Recognit. (ICPR)</title>
		<meeting>21st Int. Conf. Pattern Recognit. (ICPR)<address><addrLine>Tsukuba, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-11">Nov. 2012</date>
			<biblScope unit="page" from="1363" to="1366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multi-scale local binary pattern histograms for face recognition</title>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Messer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf</title>
		<meeting>Int. Conf</meeting>
		<imprint>
			<date type="published" when="2007-08">Aug. 2007</date>
			<biblScope unit="page" from="809" to="818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Face recognition using multi-scale local phase quantisation and linear regression classifier</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Tahir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bouridane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 18th IEEE ICIP</title>
		<meeting>18th IEEE ICIP</meeting>
		<imprint>
			<date type="published" when="2011-09">Sep. 2011</date>
			<biblScope unit="page" from="765" to="768" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Efficient processing of MRFs for unconstrained-pose face recognition</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Arashloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 6th Int. Conf</title>
		<meeting>IEEE 6th Int. Conf</meeting>
		<imprint>
			<date type="published" when="2013-10">Sep./Oct. 2013</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Facial feature localization using graph matching with higher order statistical shape priors and global optimization</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Arashloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Christmas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th IEEE Int. Conf</title>
		<meeting>4th IEEE Int. Conf</meeting>
		<imprint>
			<date type="published" when="2010-09">Sep. 2010</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Pose-invariant face matching using MRF energy minimization framework</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Arashloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Energy Minimization Methods in Computer Vision and Pattern Recognition</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Cremers</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Schmidt</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5681</biblScope>
			<biblScope unit="page" from="56" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Pose-invariant face recognition by matching on multi-resolution MRFs linked by supercoupling transform</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Arashloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Understand</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1073" to="1083" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Kernel-based subspace analysis for face recognition</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hintz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Joint Conf. Neural Netw. (IJCNN)</title>
		<meeting>Int. Joint Conf. Neural Netw. (IJCNN)</meeting>
		<imprint>
			<date type="published" when="2007-08">Aug. 2007</date>
			<biblScope unit="page" from="1127" to="1132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Null space-based kernel Fisher discriminant analysis for face recognition</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th Int Conf. Autom. FGR</title>
		<meeting>6th Int Conf. Autom. FGR</meeting>
		<imprint>
			<date type="published" when="2004-05">May 2004</date>
			<biblScope unit="page" from="369" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Bagging based efficient kernel fisher discriminant analysis for face recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 18th Int. Conf. Pattern Recognit. (ICPR)</title>
		<meeting>18th Int. Conf. Pattern Recognit. (ICPR)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="523" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multiple kernel learning in fisher discriminant analysis for face recognition</title>
		<author>
			<persName><forename type="first">X.-Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-C</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Adv. Robot. Syst</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Kernel-based nonlinear discriminant analysis using minimum squared errors criterion for multiclass and undersampled problems</title>
		<author>
			<persName><forename type="first">W.-J</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2333" to="2343" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Coupled discriminant analysis for heterogeneous face recognition</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1707" to="1716" />
			<date type="published" when="2012-12">Dec. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Recognising trajectories of facial identities using kernel discriminant analysis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liddell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Brit. Mach. Vis. Conf</title>
		<meeting>Brit. Mach. Vis. Conf</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page">2003</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A new kernel Fisher discriminant algorithm with application to face recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">0</biblScope>
			<biblScope unit="page" from="415" to="421" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Efficient kernel discriminant analysis via QR decomposition</title>
		<author>
			<persName><forename type="first">T</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Janardan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Cherkassky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran &amp; Associates Inc</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A new kernel direct discriminant analysis (KDDA) algorithm for face recognition</title>
		<author>
			<persName><forename type="first">X.-J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Messer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-T</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Brit. Mach. Vis. Conf</title>
		<meeting>Brit. Mach. Vis. Conf</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A direct LDA algorithm for high-dimensional data-With application to face recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2067" to="2070" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Robust kernel representation with statistical local features for face recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-K</forename><surname>Shiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="900" to="912" />
			<date type="published" when="2013-06">Jun. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Face recognition using kernel direct discriminant analysis algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Plataniotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Venetsanopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="117" to="126" />
			<date type="published" when="2003-01">Jan. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Fukunaga</surname></persName>
		</author>
		<title level="m">Introduction to Statistical Pattern Recognition (Computer Science &amp; Scientific Computing)</title>
		<meeting><address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Academic</publisher>
			<date type="published" when="1990-10">Oct. 1990</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>nd ed</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Stewart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Matrix Algorithms: Basic Decompositions</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2001">2001</date>
			<publisher>SIAM</publisher>
			<pubPlace>Philadelphia, PA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Enhanced local texture feature sets for face recognition under difficult lighting conditions</title>
		<author>
			<persName><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd Int. Workshop AMFG</title>
		<meeting>3rd Int. Workshop AMFG</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="168" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Energy normalization for pose-invariant face recognition based on MRF model image matching</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Arashloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1274" to="1280" />
			<date type="published" when="2011-06">Jun. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Efficient MRF deformation model for non-rigid image matching</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shekhovtsov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kovtun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Hlavac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2007-06">Jun. 2007</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Local features and kernels for classification of texture and object categories: A comprehensive study</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marszałek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="213" to="238" />
			<date type="published" when="2007-06">Jun. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning visual similarity measures for comparing never seen objects</title>
		<author>
			<persName><forename type="first">E</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2007-06">Jun. 2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Descriptor based methods in the wild</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hassner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Taigman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Faces Real-Life Images Workshop ECCV</title>
		<meeting>Faces Real-Life Images Workshop ECCV</meeting>
		<imprint>
			<date type="published" when="2008-10">Oct. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Multi-region probabilistic histograms for robust and scalable identity inference</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Lovell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Biometrics</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Nixon</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5558</biblScope>
			<biblScope unit="page" from="199" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">How far can you get with a modern face recognition test set using only simple features?</title>
		<author>
			<persName><forename type="first">N</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Dicarlo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2009-06">Jun. 2009</date>
			<biblScope unit="page" from="2591" to="2598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Probabilistic elastic matching for pose variant face verification</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis</title>
		<meeting>IEEE Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2013-06">Jun. 2013</date>
			<biblScope unit="page" from="3499" to="3506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Fisher vector faces in the wild</title>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Parkhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Brit. Mach. Vis. Conf. (BMVC)</title>
		<meeting>Brit. Mach. Vis. Conf. (BMVC)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="8" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Recognition of faces in unconstrained environments: A comparative study</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ruiz-Del-Solar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Verschae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Correa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP J. Adv. Signal Process</title>
		<imprint>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2009-04">2009. Apr. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Local higher-order statistics (LHS) for texture categorization and facial analysis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 12th Eur. Conf. Comput. Vis</title>
		<meeting>12th Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Towards pose robust face recognition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3539" to="3545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Is that you? Metric learning approaches for face identification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Guillaumin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Verbeek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<ptr target="http://lear.inrialpes.fr/pubs/2009/GVS09" />
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 12th Int. Conf. Comput. Vis</title>
		<meeting>IEEE 12th Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2009-09">Sep. 2009</date>
			<biblScope unit="page" from="498" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Multiple one-shots for utilizing class label information</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Taigman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hassner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. BMVC</title>
		<meeting>BMVC</meeting>
		<imprint>
			<date type="published" when="2009-09">Sep. 2009</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Probabilistic models for inference about identity</title>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Prince</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Elder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="144" to="157" />
			<date type="published" when="2012-01">Jan. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Bayesian face revisited: A joint formulation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Fitzgibbon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Sato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">7574</biblScope>
			<biblScope unit="page" from="566" to="579" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Similarity metric learning for face recognition</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. (ICCV)</title>
		<meeting>IEEE Int. Conf. Comput. Vis. (ICCV)</meeting>
		<imprint>
			<date type="published" when="2013-12">Dec. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Fast high dimensional vector multiplication face recognition</title>
		<author>
			<persName><forename type="first">O</forename><surname>Barkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Aronowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. (ICCV)</title>
		<meeting>IEEE Int. Conf. Comput. Vis. (ICCV)</meeting>
		<imprint>
			<date type="published" when="2013-12">Dec. 2013</date>
			<biblScope unit="page" from="1960" to="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">XM2VTSDB: The extended M2VTS database</title>
		<author>
			<persName><forename type="first">K</forename><surname>Messer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jonsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd Int. Conf. Audio Video-Based Biometric Person Authentication</title>
		<meeting>2nd Int. Conf. Audio Video-Based Biometric Person Authentication</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="72" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Robust real-time face detection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="154" />
			<date type="published" when="2004-05">May 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">2D face pose normalisation using a 3D morphable model</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Tena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hamouz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Illingworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Adv. Video Signal Based Surveill</title>
		<meeting>IEEE Conf. Adv. Video Signal Based Surveill</meeting>
		<imprint>
			<date type="published" when="2007-09">Sep. 2007</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
