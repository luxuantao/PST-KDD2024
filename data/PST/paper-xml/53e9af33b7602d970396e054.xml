<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">S</forename><surname>Soatto</surname></persName>
						</author>
						<author>
							<persName><forename type="first">R</forename><surname>Frezza</surname></persName>
						</author>
						<author>
							<persName><forename type="first">P</forename><surname>Perona</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">California Institute of Technology</orgName>
								<address>
									<postCode>91 125</postCode>
									<settlement>Pasadena</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Dipartimento d i Elettronica ed Informatica</orgName>
								<orgName type="institution">UniversitA di Padova</orgName>
								<address>
									<settlement>Padova</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">California Institute of Technology</orgName>
								<address>
									<postCode>91125</postCode>
									<settlement>Pasadena</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Dipartimento di Elettronica e d Informatica</orgName>
								<orgName type="institution">Universith di Padova</orgName>
								<address>
									<settlement>Padova</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2C60135B0C544B1B03586A208E9AB2D1</idno>
					<note type="submission">received February 17, 1995.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Motion Estimation via Dynamic Vision</head><p>Stefano Soatto, Student Member, IEEE, Ruggero Frezza, Member, IEEE, and Pietro Perona, Member, IEEE Abstruct-Zstimating the three-dimensional motion of an object from a sequence of projections is of paramount importance in a variety of applications in control and robotics, such as autonomous navigation, manipulation, servo, tracking, docking, planning, and surveillance. Although "visual motion estimation" is an old problem (the first formulations date back to the beginning of the century), only recently have tools from nonlinear systems estimation theory hinted at acceptable solutions.</p><p>In this paper we formulate the visual motion estimation lproblem in terms of identification of nonlinear implicit systems with parameters on a topological manifold and propose a dynamic solution either in the local coordinates or in the embedding space of the parameter manifold. Such a formulation has structural advantages over previous recursive schemes, since the estimation of motion is decoupled from the estimation of the structure of the object being viewed, and therefore it is possible to handle occlusions in a principled way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUC~ON NDERSTANDING the geometry and kinematics of the</head><p>U envizonment is a basic requirement for humans to successfully accomplish tasks such as walking, driving, and recognizing and grasping objects, It has been one of the principal goals of artificial intelligence, starting from the early 1970's, to build machines that recognize the shape and motion of objects within the environment. The goal is far from being reached and, indeed, it opens a new and exciting avenue of research in nonlinear systems theory.</p><p>Although the first formulations of the visual motion estimation problem date back to the beginning of the century <ref type="bibr" target="#b22">[31]</ref>, <ref type="bibr" target="#b64">[77]</ref>, only within recent years have tools from control and estimation theory been applied 131, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b19">[28]</ref>, <ref type="bibr">[291, [351, 1521, [56]</ref>, <ref type="bibr">[60]</ref>, <ref type="bibr">[66]</ref> with rather encouraging results in traditionally difficult applications, such as autonomous vehicle navigation [18]- <ref type="bibr" target="#b12">[20]</ref>, vision-based tracking and servo <ref type="bibr">[12]</ref>, 1211, 1421, [44], vision-based manipulation [SI, <ref type="bibr" target="#b13">[21]</ref>, <ref type="bibr" target="#b33">[42]</ref>, docking [ 191, <ref type="bibr" target="#b28">[37]</ref>, vision-based planning [ 141, and active sensing <ref type="bibr">[69]</ref>.</p><p>As the reliability and the performance of the algorithms improves, vision starts being acknowledged in the automatic control community as a powerful and versatile sensor to measure motion, position, and structure of the environment, and the appropriate tools from nonlinear estimationhdentification theory start being exploited <ref type="bibr">[161, [301, 1-59</ref>], [601. The implementation of sophisticated vision algorithms running in real time is not too far from becoming reality and, due also to the evolution of computer hardware, vision will be soon included "in the loop" of many control systems.</p><p>"Vision in the loop" raises new and interesting problems of system theoretic flavor, ranging from distributed filtering and processing of large amounts of sensory data to the analysis and control of new classes of dynamical systems. Crucial issues in the use of vision as a sensor in control systems are, for example, nonlinear observability and identifiability in a projective geometric framework as well as estimation and control on peculiar topological manifolds.</p><p>In this paper we will be mainly concerned with the "visual motion estimation" problem: Given a sequence of images taken from a moving camera, reconstruct the relative threedimensional <ref type="bibr">(3-D)</ref> motion between the camera and the environment (or scene).</p><p>Since our goal is that of posing the visual motion estimation problem within a system-theoretical framework, we nced to specify a "description" of the environment and of the motion of the viewer. We will restrict our attention to "static" scenes or, equivalently, to portions of it which are moving rigidly relative to the viewer.</p><p>The existing methods for motion estimation may be classified, depending on the scene descriptors employed, as pointbased, line-based, curve-based, or model-based. We will focus on the simplest case when the scene is described by a number of point-features in the Euclidean 3-D space. For line-based schemes, see <ref type="bibr">[72]</ref> and <ref type="bibr" target="#b68">[81]</ref> and the references therein. The curve-based approach has been addressed in <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr">[13]</ref>, and <ref type="bibr">[71]</ref>.</p><p>The point-based methods may be further classified in terms of the camera model in question. The simplest cases assume either parallel projection [581, [73]- <ref type="bibr" target="#b62">[75]</ref> or ideal perspective projection (pinhole model, see <ref type="bibr" target="#b15">[23]</ref>). More articulated camera models in terms of projective transformations allow parallel and perspective projection as a subcase <ref type="bibr" target="#b2">[3]</ref>, 1251, [61], [701. We will be concerned mainly with the classical pinhole model; however, our schemes generalize to other camera representations and may estimate the camera model along with visual motion (camera self-calibration, see 1251 and <ref type="bibr">[611)</ref>. Other schemes recover projective, nonmetric structure, independent of the camera parameters [221, [541, [W.</p><p>Motion reconstruction methods may be further classified in terms of the data processing technique as two-frames schemes (see for example [38], [49], and <ref type="bibr" target="#b65">[78]</ref>), multiframebatch methods [70], [75], or recursive algorithms.</p><p>In the last decade, a variety of schemes has been proposed for recursively reconstructing structure for known motion [521, 0018-9286/96$05.00 0 1996 IEEE motion for known structure <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b19">[28]</ref>, <ref type="bibr" target="#b20">[29]</ref>, or both structure and motion <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b26">[35]</ref>, [%I, <ref type="bibr">[60]</ref>, <ref type="bibr">[66]</ref>. In general, given either the relative motion or the shape of the object being viewed, the other can be recovered easily since the problem can be reduced to a linear estimation task. When neither the motion nor the shape of the scene is known, the problem of estimating both of them from visual information becomes a remarkably difficult one. We find that a crucial step in tackling such an estimation task consists in being able to decouple the estimation of motion from the estimation of structure. This decoupling has dramatic consequences also from the practical standpoint, since it allows integrating motion information in the presence of occlusions in the image plane, whereas previous structure and motion estimation schemes could integrate motion information only to the extent in which all initial feature points were still visible (as in <ref type="bibr" target="#b2">[3]</ref> and <ref type="bibr">[361)</ref>.</p><p>In this paper we present a framework for estimating rigid motion independent of the structure (shape) of the scene. The estimates of motion can later be fed to any recursive "structure from known motion" module to estimate scene structure [52], [56l, [661.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Organization of the Paper</head><p>The next section of this paper has introductory purpose: we establish the notation and review some basic concepts in the representation of rigid motion. Section II-B describes an alternative representation based upon the so-called "essential matrices" which were introduced in [49]. In Section 111, we introduce a novel nonlinear implicit dynamical model with motion coded as a vector of parameters constrained onto the space of essential matrices.</p><p>We show in Section IV how to carry out the identification of the model introduced. There we propose two methods, one based upon a dynamic model in the local coordinates of the parameter manifold and the other based upon a dynamic model in its embedding space, projected onto the parameter manifold. The formulation makes use of the results contained in the appendixes. An alternative iteration for identifying the model in local coordinates is described in Appendix A and tested in the experimental Section VI. There we discuss benchmark experiments that highlight the peculiarity of each scheme. Extensive experiments in real-world scenes have been conducted by the authors as well as by other researchers <ref type="bibr" target="#b6">[7]</ref> and show consistent performance in situations where previously proposed techniques fail.</p><p>The methods introduced have some degree of generality, as a number of other problems in computational vision may be cast in the same framework, as discussed in Section V.</p><p>Finally, conclusions are drawn in Section VII.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">BACKGROUND AND NOTATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Representation of Rigid Motion</head><p>A transformation g: IR3 -IR3 of the 3-D Euclidean space is a rigid motion if it preserves the Euclidean distance between points p , and the cross product between vectors q, [68], <ref type="bibr" target="#b63">[76]</ref>. We write the action of a rigid motion on IR3 as</p><formula xml:id="formula_0">g = ( T , R ) with T E R3 and R E S 0 ( 3 ) , such that<label>(1)</label></formula><p>The set of rigid motions has the structure of a Lie group of dimension six and is called S E ( 3 ) (special Euclidean transformations of R3). It is sometimes useful to embed SE(3) in the linear group GC(4) (the general linear group of nonsingular 4 x 4 matrices) using homogeneous coordinates</p><p>x [X* 1IT E IR4. Each rigid motion g is then represented as a matrix</p><formula xml:id="formula_1">g ( X ) = R X + T . G = [o R T I ] 17' E Et3, R E SO(3).</formula><p>We will use the notation g ( t ) A ( T ( t ) , R ( t ) )</p><p>when emphasizing the time-dependence of g . The group ophations in SE(3) coincide with the group operations of GL(4), so that the composition of rigid motions may be represented as a matrix multiplication: g1 o g2 = GlG2. The price we pay for such a simplification is that we have to embed S E <ref type="bibr" target="#b2">( 3 )</ref> , which is a six-dimensional manifold, into which has dimension 16. The tangent space at the origin of SE <ref type="bibr" target="#b2">(3)</ref> has the structure of a Lie algebra and is called se <ref type="bibr" target="#b2">(3)</ref>. Elements of se(3) are called "twists" in the robotics literature <ref type="bibr">[55]</ref> and may be represented in so-called "Plucker coordinates" as where V E R3 and 1-wz w1 0 1</p><p>belongs to the Lie algebra of the skew-symmetric matrices</p><formula xml:id="formula_2">so(3) = {SIST = -S} which is isomorphic to R3 via R A H R = [wl w2 w3IT E R3.</formula><p>We will use the same symbol v for an element of se <ref type="bibr" target="#b2">(3)</ref> and its Plucker coordinates. The reader interested in a complete treatment of the concepts sketched here may consult for instance [61, <ref type="bibr">[41, E451, 1551</ref>, and [681.</p><p>The reason why the representation introduced above is appealing is that all (compact) one-parameter subgroups of a matrix Lie group can be characterized using the exponential map. For instance, VI J E se(3),g(t) = e(wA)t is a oneparameter subgroup of SE <ref type="bibr" target="#b2">(3)</ref>. An explicit expression for the exponential map on S E ( 3 ) is given by RA v</p><formula xml:id="formula_3">[ : : : ] = -p ( 0 0 ) where (2) T 7 ( R ) V<label>( 3 ) (4)</label></formula><p>The exponential map may be inverted locally for computing V and R from R and T , since the matrix 7 ( R ) is invertible when IlRll E (0,w). In the case llRll = 0, the exponential map is defined simply by</p><formula xml:id="formula_4">R &amp; e ( f l A ) 1 7(n) A -[(I -e(OA))(RA) + ROT]. llflll R -I T = V</formula><p>Note that the exponential map, together with the isomorphism of so <ref type="bibr" target="#b2">(3)</ref>  </p><formula xml:id="formula_5">d ( t ) = j ( t ) p ( t o ) = W g -l ( t ) g ( t ) P ( t o ) = 4 t &gt; A P ( t ) X ( t ) = R ( t ) A X ( t ) + V ( t )</formula><p>and, in coordinates <ref type="bibr" target="#b6">(7)</ref> where V and R represent the translational and rotational velocities of the viewer's moving frame <ref type="bibr">[55]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. The "Essential Manifold"</head><p>A rigid motion may be represented as a point in the Lie group SE(3) which can be embedded in the linear space GL(4) (and hence exploit the matrix product as composition rule) and is in local correspondence with Et6 via the exponential coordinates and the isomorphism between so(3) and R3, as seen in the previous section. We now discuss an alternative matrix representation of rigid motion which is more "compact" in the sense that it can be embedded in a space of smaller dimensions. Such a representation is derived from the so-called "essential matrices" introduced by Longuet-Higgins <ref type="bibr">[49]</ref>. <ref type="formula" target="#formula_3">3</ref>) is a skew-symmetric matrix. Now define the space of "essential matrices" as</p><formula xml:id="formula_6">Consider a point g = ( T , R) E SE(3), then T A E so(</formula><formula xml:id="formula_7">E {SRIR E S 0 ( 3 ) , S = ( T A ) E so(3)) C (8)</formula><p>Clearly the essential space does not inherit the group structure from the sum of matrices in since Q1, Q2 E E does not imply Q1 + Q2 E E . One possible way of imposing the group structure is by forcing a group morphism with S E ( 3 ) , for which it is necessary to "unfold" T , R from Q = ( T A ) R E E , perform the group operation on SE(3), and then collapse the result into E . We will see later in this section a way of unfolding an essential matrix into its rotation and translation components.</p><p>The essential space has many interesting geometrical properties: it is an algebraic variety 1531 and a topological manifold of dimension six. Later on we will provide a characterization of a local coordinate chart. The essential space may also be identified with T S 0 ( 3 ) , the tangent bundle of the rotation group, defined as TSO(3) A URESO(3) T ~s o <ref type="bibr" target="#b2">( 3 )</ref> 1631. The following theorem, due to Huang and Faugeras and reported by Maybank 1531, gives a simple characterizing property of the space of essential matrices.</p><p>Theorem 2.1 (Huang and <ref type="bibr">Faugeras, 1989)</ref>: Let Q = UC VT be the singular value decomposition (SVD) <ref type="bibr" target="#b23">[32]</ref> of a matrix in</p><p>Then</p><formula xml:id="formula_8">Q E E U C = CO = diag{X X 0)lX E RS Pro03 (+) let Q = SRIR E S 0 ( 3 ) , S E so(S);n(Q), the set of singular values of Q , is such that o ( Q ) = d a . Next observe that QQT = SST = -S2.</formula><p>Also  Q.E.D. Remark 2.1: Note that, since Q A UCVT E E U C = diag{X X O}, there is one degree-of-freedom in defining the basis components of the subspaces (V.3)' and which corresponds to rotating the orthogonal bases (V.1, V.2) and (U.1, U.2) about their orthogonal complements. However, the effects cancel out in the multiplications when defining R and S as in the proof above.</p><formula xml:id="formula_9">VS E so(3)3!T E R31S = ( T A ) ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Local Coordinates of the Essential Manifold</head><p>For any given rigid motion (T, R) E S E ( 3 ) , there exists an essential matrix Q defined by Q = ( T A ) R . We are interested now in the inverse problem: Given an essential matrix Q , can we extract its rotational and translational components? Is the correspondence Q ++ ( T , R ) unique?</p><p>Consider the following map, defined locally between E and R6</p><formula xml:id="formula_10">@: E t IR3 x SO(3) -+ Et3 x lR3</formula><p>where U , V are defined by the SVD 1321 of Q = U C V T ; U. <ref type="bibr" target="#b2">3</ref> denotes the third column of U , and R~(7rl2) is a rotation of 7r/2 about the axis [0 0 1]*. Note that the map Q, defines the local coordinates of the essential manifold modulo two signs; therefore, the map associates to each element of the essential space four distinct points in local coordinates. This ambiguity may be resolved in the context of the visual motion estimation problem by imposing the "positive depth constraint" which means that each visible point lies in front of the viewer. In a case like this, we will be able to identify a unique local coordinates homeomorphism, as discussed in Section III-C. The inverse map is simply cp-l: IR3 x IR3 -+E D. Projection Onto the Essential Manifold Theorem 2.1 suggests a simple "projection" of a generic 3 x 3 matrix onto the essential manifold: Let us define p T ( E ) :</p><formula xml:id="formula_11">-+ E M U diag{/\, A, O } V ~ (10)</formula><p>where U , V are defined by the SVD of M = U diag{ 01, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="111.">STRUCTURE-INDEPENDENT MOTION ESTIMA~ON MODELED AS THE RECURSIVE IDENTIFICATION</head><p>OF NONLINEAR IMPLICIT SYSTEMS In this section we begin with the constraints of rigid motion and perspective projection which define a "natural" nonlinear dynamical model for the 3-D coordinates of each visible feature point (structure). Motion is an unknown parameter of the model which is constrained on SE <ref type="bibr" target="#b2">(3)</ref>. If we represent motion on the essential manifold, instead, it is possible to remove the 3-D structure of the scene from the model, ending up with a nonlinear and implicit dynamical model for the (measured) projective coordinates of the visible features with motion as an unknown parameter constrained on E . This allows us to decouple the estimation of motion from the 3-D structure of the scene, which has many advantages, for it allows dealing with occlusions of feature points and crossing regions of motion-space which render the "natural" model unobservable <ref type="bibr">[59]</ref>.</p><p>Consider the position of a rigid set of feature points in 3-D space. We call X = [X Y ZIT E R3 the coordinates of a generic point with respect to an orthonormal reference frame centered in the center of projection with 2 along the optical axis and X , Y , parallel to the image plane and arranged to form a right-handed frame (see Fig. <ref type="figure">1</ref>).</p><p>The relative motion between the camera and the object (or scene) is described by a rigid motion</p><formula xml:id="formula_12">g ( t ) = ( T ( t ) , R ( t ) ) E SE(3) which induces an instantaneous velocity ( V ( t ) , R(t))</formula><p>such that</p><formula xml:id="formula_13">X ( t ) = O ( t ) A X ( t ) + V(t&gt;. (<label>11</label></formula><formula xml:id="formula_14">) / Fig. 1. frame.</formula><p>Point-based visual motion estimation; the viewer-centered reference</p><p>If we assume the velocity to be constant between samples, so that Q(t) and V ( t ) represent the local coordinates of the rigid motion of the camera between time t and t + 1, then we can write</p><formula xml:id="formula_15">X ( t + 1) = R ( I ) X ( I ) + T ( t ) (12)</formula><p>where (T, E ) are related to (V, R) via the exponential map.</p><p>What we are able to measure is the perspective projection 7r of the point-features onto the image plane which, for simplicity, we represent as the real projective plane. The projection map 7r associates to each p # 0 its projective coordinates as an element of IRP2 (see Fig. <ref type="figure">1</ref>)</p><formula xml:id="formula_16">7l-: R3 -{O} --f IRP2 x H Z = [ [ r c y 1 1 T ' = n ( X ) -I -</formula><p>We usually measure x up to some error n which is well modeled as a white, zero-mean, and normally distributed process with covariance R,</p><formula xml:id="formula_17">y = r c + n 7LEN(O,R,).</formula><p>In summary, when we represent the scene structure using points in the Euclidean 3-D space, the visual motion estimation problem is defined by the constraints of rigid motion and perspective projection</p><p>The above is a nonlinear dynamical model having the 3-D structure of the scene in the state. Estimating motion amounts to identifying the above model with the parameters T , R constrained on SE <ref type="bibr" target="#b2">(3)</ref>. However, we do not know Xzo, so that we end up with a mixed estimationlidentification task which proves extremely difficult <ref type="bibr">[59]</ref>.</p><p>In the next section we will show how representing motion on the essential manifold allows us to decouple the estimation of motion from the structure parameters X,.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. The "Essential Filter"</head><p>Since the essential constraint is a homogeneous equation, and hence defined only up to a scale factor, we may restrict Q to belong to Ss instead of Etg. It is customary to set the norm of translation to be unitary; this can be done without loss of generality as long as translation is not zero. The zeronorm translation case can be dealt with separately, and we discuss it in Section 111-E. For simplicity, we now assume</p><formula xml:id="formula_18">11Q112 = llTll = 1. At each time instant we have a set of N constraints in the f o R P 0 X f X' timet T t time t+dt d R Fig. 2.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The coplanarity constraint,</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Structure-Independent Models for Motion Estimation</head><p>When a rigid object is moving between two time instants t and t + 1, the coordinates X of a point at time t , their correspondent X' at time t + 1 and the translation vector T are coplanar (Fig. <ref type="figure">2</ref>). Their triple product is therefore zero. This is true of course also for X,X' and T , since x is the projective coordinate of X , and therefore the two identify the same direction in R3, interpreted as the "ray-space'' model of RP2 <ref type="bibr">[57]</ref>. When expressed with respect to a common reference frame, for example that at time t , we may write the triple product as (15)</p><p>As it turns out, the above constraint is not only a consequence of rigid motion, but also suffices to characterize it once five or more such constraints are given [53], <ref type="bibr">[49]</ref>. Let us define Q A (TA)R, so that the above coplanarity constraint, which is known as the "essential constraint" or the "epipolar constraint," becomes (16)</p><formula xml:id="formula_19">X I T ( T A ( R E , ) ) = 0 Vi = 1 : N . 'T X, Qx, = 0 V i = 1 .. . N.</formula><p>Estimating motion corresponds to identifying the model</p><formula xml:id="formula_20">( Q x , ) ~x : = 0 Q E E y, =z, + 72, V i = 1 . N , 72% E N(0, %%). (17)</formula><p>Since ( <ref type="formula">16</ref>) is linear in Q, we use the improper notation</p><formula xml:id="formula_21">~( t + l)Q(t) ~z l ( t ) , z ( t ) Q ( t ) = 0 x E R N x g</formula><p>where x is an N x 9 matrix combining x , , x : and Q is interpreted as a nine-dimensional vector obtained by stacking the columns of the 3 x 3 matrix Q on top of each other. In the following we will not distinguish between Q interpreted as a matrix in and a nine-dimensional column vector. The generic row of x has the form [zz', yz', z', zy', yy', y', z, y, 11.</p><p>We will use the notation ~( t )</p><p>when emphasizing the timedependence, while we will write x X t (t),X(t) when highlighting which vectors are used for constructing x. therefore, Q lies at the intersection between the essential manifold and the linear variety X G , ! ( ~) , ~( ~) <ref type="bibr">( O )</ref> (see Fig. <ref type="figure" target="#fig_1">3</ref>). Note that, even after imposing unit norm, there is still a sign indeterminacy in Q which accounts for the two possible solutions Q1 = +Q and Qz = -Q of the essential constraint. These become four after being transformed to local coordinates. This ambiguity can be overcome by imposing the positive depth constraint as it will be done in Section 111-C.</p><p>As time progresses, the point Q ( t ) , corresponding to the actual motion, describes a trajectory on E (and a corresponding one in local coordinates) according to</p><p>The last equation is indeed just a definition of the right-hand side, as we do not know n ~( t ) .</p><p>The identity of n ~( t ) and the sign + in the above equation will be unraveled in Section IV-B. For now, we will consider the previous equation to be a discrete-time dynamical model for Q on the essential manifold with n~ as unknown input. If we accompany it with the essential constraint, we get</p><formula xml:id="formula_22">Q(t + 1) =Q(t) + n ~( t ) Q E E 0 = ~z r ( t ) , ~( t ) Q ( t ) y, =2, + 72, YZ = 1 . . . N . (<label>18</label></formula><formula xml:id="formula_23">)</formula><p>Now the visual motion estimation problem is characterized as the estimation of the state of the above model which is defined on the essential manifold. It can be seen that the system is "linear" (both the state equation and the essential constraint are linear in Q). E , however, is not a linear space. We will see how to solve the estimation task in Section IV.</p><p>The observability/identifiability of the essential models is addressed in <ref type="bibr">[59]</ref>. It is proven that the model is globally observable under general position conditions. Such conditions are satisfied if the viewer's path and the visible objects cannot be embedded in a (proper) quadric surface of R3 and if all the visible points cannot be embedded on a plane 1501, 1591.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Choosing the Local Coordinates for the Essential Manifold</head><p>The map @ introduced in (9) defines the local coordinates of the essential space modulo a sign in the direction of translation and in the rotation angle of Rz. Therefore, the map @ associates to each element of the essential space four distinct points in local coordinates. This ambiguity can be resolved by imposing the "positive depth constraint," i.e., that each visible </p><formula xml:id="formula_24">E + IR1+l with d x , d ( Q ) = [2,Z'IT</formula><p>which gives the depth of each point as a function of the projection and the motion parameters (it is just the intersection of corresponding projection rays, see Fig. <ref type="figure">2</ref>). Note that it is locally smooth away from zero translation. Therefore, given any N point-matches with projective coordinates x 2 , x ' ~, we may use @ as a local coordinate chart for the following set, which we call the "normalized essential manifold:" <ref type="figure">(( l,</ref><ref type="figure">d,</ref><ref type="figure">,</ref><ref type="figure">,</ref><ref type="figure">,</ref><ref type="figure">r,</ref><ref type="figure">(Q</ref></p><formula xml:id="formula_25">E + E n d-l (R:)~ n ss x , x f = {Q = SRlR E S 0 ( 3 ) , S 2 T A E so(3) (IT</formula><formula xml:id="formula_26">) &gt; Ob'i = l . . . N ) (19)</formula><p>has been estimated with a normalized translational velocity, it can be used to estimate the "normalized structure" X , via triangulation <ref type="bibr">[66]</ref>. By matching the distance between the reference points in the normalized structure with its reference value, we can rescale both the depth of each point and the direction of translation simply by llXrl -XT211 = pl/TII.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Dealing with Zero-Translation</head><p>So far we have assumed that IlTll # 0, and we have defined the normalized essential manifold based upon the constraint</p><formula xml:id="formula_27">IlTll = 1.</formula><p>It is easy to see that the condition ((TI1 = 0 defines a "thin-set" in the parameter space. Due to the noise in the measurements, there is always a translation which is least-squares compatible with the observations. However,, one where R+ is the positive open-half space of IR, <ref type="figure"></ref>and<ref type="figure">d-'</ref> ask what when the system close to such</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X,X'</head><p>denotes the preimage of d x , x f . Consider @ restricted to E . It and, furthermore, bijective. The normalized essential manifold thus defined is a topological manifold of dimension five, since we have imposed the metric constraint ((T(1 = 1. a configuration. When the translation is almost zero, there is little parallax in the projected coordinates of the visible the direction of translation ill-conditioned~ Luckily enough, we do not need to worry about the structure of the scene, since it does not enter our dynamic model, or follOws from the properties Of the SVD that @ is continuous objects which fhe estimates of the depth and those of</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Propagating Scale Information</head><p>It is well known [49] that from visual information it is only possible to recover the structure and the motion modulo a scale factor multiplying the translational velocity and the depth of the visible points. In fact, we cannot distinguish between a car moving on a street and a car which is "twice as big, twice as far, and moving twice as fast." Such a scale ambiguity is captured by the homogeneous nature of the essential constraint (16). However, as soon as we are given some scaling information about the scene at one time instant-for example the size of the car-we can rescale the scene and the estimated velocity to its appropriate values.</p><p>Suppose we are given the distance between two visible "reference" points in space IIXT1-XT211 = p . Once the motion about the direction of translation, since its estimate will be weighted by the scale, which is exactly llT(l E 0. However, we would still like to estimate the correct rotational velocity.</p><p>Here the definition of the normalized essential manifold comes at hand. In fact, the estimation scheme will estimate some direction of translation T such that (IT11 = 1 regardless the scale of T , so that the correct rotational component of the local coordinates can be computed. In the experimental section we will show an experiment in which the system crosses a region in the parameter space where T = 0 and Q # 0. Embedding space estimator consists in solving at each step a linear estimation problem in the linear embedding space and then "projecting" the estimate onto the essential manifold (Fig. <ref type="figure">4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>bottom).</head><p>It is very important to understand that these are modeling assumptions about motion which can be validated only a posteriori. In general, we observe that the first method solves a strongly nonlinear problem with techniques which are based upon the linearization of the system about the current reference trajectory so that the linearization error may be relevant. The second method does not involve any linearization, whereas it imposes the constraint of belonging to the essential manifold in a weaker way. Note that each method produces, together with the motion estimates, the variance of the estimation error which is to be used by the subsequent modules of the structure from motion estimation scheme [66].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Estimation in Local Coordinates</head><p>Consider composing (18) with the map defined in <ref type="bibr" target="#b8">(9)</ref> restricted to the normalized essential manifold E</p><formula xml:id="formula_28">@: E +s2 x IR3 4 R5</formula><p>where T is expressed in spherical coordinates of radius one.</p><p>Then the system in local coordinates becomes</p><formula xml:id="formula_29">[ ( t + 1) = [ ( t ) + ng(t); &lt;(to) = Eo 0 = Xy(t),yl(t)Q(&lt;(t)) + %(t). (<label>20</label></formula><formula xml:id="formula_30">)</formula><p>Motion may be modeled as a first-order random walk E N(0, R E ) for some RE which is referred to as the variance of the model error. While the above assumption is somewhat arbitrary and can be validated only a posteriori, it is often safe to assume that the noise in the measurements y(t),y'(t) are white, zero-mean Gaussian processes with variance R,. The second-order statistics of the induced noise 6 are a somewhat delicate issue that is discussed in Appendix A.</p><p>The estimation scheme for the model above, which takes into account the correlation of the error 6 , is reported in Appendix A. A simplified version is obtained by approximating fi with a white process (note that fi is correlated only within one time step). The resulting scheme is based upon an implicit extended Kalman filter (IEKF) which is derived in Appendix B. We summarize here the equations of the estimator. Call C = (axQ/a&lt;) and D (aZQ/az), then we have the following: </p><formula xml:id="formula_31">Prediction Step: Prediction Step: i(t + Ilt) =&lt;@It); E"(Ol0) = t o (21) s(t + Ilt) = Q(tlt); Q(Ol0) = QO (<label>30</label></formula><formula xml:id="formula_32">((t + llt + 1) = ((t + lit) -L(t + 1)X(t + 1) . Q(i(t + 1lt))<label>(23)</label></formula><p>~( t <ref type="formula">24</ref>)</p><formula xml:id="formula_33">+ ilt + 1) =r(t + i ) ~( t + ilt)r*(t + 1) + L(t + 1)R,(t + l)LT(t + 1). (</formula><formula xml:id="formula_34">Gain: L(t + I) = P ( t + Ilt)CT(t + l)A-'(t + 1) h(t + 1) = C(t + 1)P(t + l / t ) C T ( t + 1)<label>(25)</label></formula><p>+ R,(t + 1)</p><formula xml:id="formula_35">(26) (27) r(t + 1) = I -~( t + i ) q t + 1).</formula><p>Residual Variance: </p><formula xml:id="formula_36">Rc(t + 1) = D ( t + l)R,DT(t + 1).<label>(28</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Estimation in the Embedding Space</head><p>Suppose that motion, instead of being a random walk in R5, is represented in the essential manifold as the "projection" of a random walk through Et9 (Fig. <ref type="figure">4</ref> top).</p><p>sums them, and then projects the result onto the essential manifold</p><p>We define the operator @ that takes two elements in</p><formula xml:id="formula_37">$: R3x3 x JR,3x3 + E Mi,M2 H Q = P T ( E ) ( M I + M 2 )</formula><p>where the symbol "+" is the usual sum in above definitions, our model for motion becomes simply With the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Update</head><p>Step:</p><formula xml:id="formula_38">Q(t + llt + 1) = Q(t + llt) G3 L(t + 1)X(t + 1)Q(t + lit) (32)<label>(33)</label></formula><p>~( t</p><formula xml:id="formula_39">+ 11t + 1) = r(t + i ) ~( t + Ilt)rT(t + 1) + L(t + l)R,(t + l)LT(t + I).</formula><p>Gain: </p><formula xml:id="formula_40">(34)<label>(35)</label></formula><formula xml:id="formula_41">L(t + 1) = -P(t + l(t)XT(t + l)A-l(t + 1) A(t + 1) = x ( t + 1)P(t + lIt)XT(t + 1) + R,(t + 1) r(t + 1) = I -L(t + i)x(t + 1). V. FURTHER PROBLEMS m DYNAMIC VISION WHICH</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MAY BE FORMULATED AS IDENTIFICATION</head><p>OF NONLINEAR IMPLICIT MODELS In this section we show that (17) has some degree of generality in the context of dynamic vision. In fact, there are other problems that fall within the identification of the same class of nonlinear implicit models with parameters on a topological manifold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dynamic Self-Calibration</head><p>So far, we have taken the camera to be an ideal perspective projection of unit focal length. When the camera model is a more general affine transformation in Et2, (16) does not hold.</p><p>However, a similar constraint may be derived based on the epipolar geometry <ref type="bibr" target="#b15">[23]</ref> as </p><formula xml:id="formula_42">x:*Fx, = 0 V i = 1 . . . N .</formula><formula xml:id="formula_43">Q(t + 1) = &amp;(t) @ n ~( t )</formula><p>where no(t) E N(O,R,,) is a white, zero-mean Gaussian <ref type="bibr" target="#b20">(29)</ref> is an essential matrix.</p><p>The Fundamental matrix has been originally introduced by Faugeras. In [25], the matrix F i s estimated from the (linear) constraint <ref type="bibr" target="#b28">(37)</ref>, and then its structure <ref type="bibr" target="#b29">(38)</ref> is imposed a posteriori by solving a set of polynomial equations known as Kruppa equations. Such equations are, unfortunately, poorly conditioned, and the scheme is extremely sensitive to noise. between the optical axis and the image plane, and ( s z , sY) the pixel sizes along the image plane coordinates. The deviation from 90' of the angle between the optical axis and the CCD surface is usually on the order of lo, and we may therefore neglect it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scheme TX TY</head><p>Local M: .0002 Std:.0004 M:-.0015 Std: .0048 Essential M: 3.97543-5 Std: .0001 M: .0017 Std: .0013 2-D M: .3763-3 "+!d: .0009 M: -.08353-3 Std: .0071  </p><formula xml:id="formula_44">Ai = A(Zi, V) = ( A -~Q A -~~, ) ~~: = o Q E E 3, = 2, + n2 vz = 1 . . . N .</formula><p>Estimating the camera parameters along with rigid motion may then be formulated as identification of the above model, where the parameters are on the manifold E x AF, and AF is the set of affine transformations of R2 represented in homogeneous coordinates. This formulation has been derived in [61].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Motion from Weak-Perspective</head><p>Alternative camera models may be employed in the same framework, for example the so-called "weak" or "affine" perspective, consisting of a parallel projection onto a plane followed by a perspective projection of the plane onto the image. In such a case, the fundamental matrix has the simple form [25], <ref type="bibr" target="#b34">[43]</ref> </p><formula xml:id="formula_45">F = 0 0 b [ I I : I ] where a = -R23 b = R13 c = ~R23Rli -SR13R21 d = ~R23R12 -~R13R22 e = R23Tz -R23TY</formula><p>and s is a scale factor. The state manifold in this case is S4 r 621.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Subspace Motion Factorization for Estimating Direction of Heading version of the basic model (14)</head><p>Consider the derivative of the output of the differential r l i and V E S2 is represented in local coordinates as V(O,$).</p><p>Observing N points, one may write where C(V,..) A Under the usual rank conditions, we may compute the leastsquares approximation of d as</p><formula xml:id="formula_46">d d t [ ? ] A c t , X N</formula><p>where t indicates the pseudo-inverse. Therefore, the motion field specifies the constraint [34]   x</p><formula xml:id="formula_47">= cc'x =3 cyv, 2)k = 0</formula><p>where C L A I -CCt indicates the orthogonal complement of the range space of C. Heeger and Jepson <ref type="bibr" target="#b25">[34]</ref> proposed to estimate the direction of translation by minimizing the two norm of the above constraint over V E S 2 . They minimize by extensive search over all possible directions ( @ , 4 ) .</p><p>Indeed, it is immediate to see [65] that the problem of estimating the direction of translation can be rephrased as the problem of identifying the following exterior differential system <ref type="bibr">[lo]</ref>, with parameters V on a sphere, embedded in R3</p><formula xml:id="formula_48">C'(V,Z)k = o v E s2 y, =2, f n , VZ = 1 . . . N .</formula><p>The "projection" onto the manifold is defined, in this case, simply as prs2(V)</p><p>V/llV\l, and the same techniques described in the previous section can be used for carrying on the estimation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EXPERIMENTS</head><p>In this section we describe two experiments on real image sequences and one simulation experiment to reveal the different features of each scheme and their behavior when close to singular configurations in the motion space (e.g., pure rotation about the projection center).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Simulation Experiments</head><p>We have generated a cloud of 20 feature points at random within a cubic volume of side 1 m, placed 1.5 m ahead of the viewer. The scene was viewed under perspective projection onto an image plane of 500 x 500 pixels with a focal length of one, corresponding to a visual field of approximately 50". Gaussian noise with 1 pixel std was added to the measured projections according to the performance of the most current feature-tracking schemes <ref type="bibr" target="#b3">[4]</ref>. The viewer was then made to navigate around the cloud with constant velocity for 50 time instants (frames), after which the viewer stopped translating and only rotated about its center of projection for 25 frames, inverting the direction after 15 of them. Finally, the viewer resumed its roto-translational motion to return to the initial configuration.</p><p>This experiment is interesting from many extents: first of all, for part of the sequence the model is in a singular configuration, since the translational velocity is zero. Indeed, as we have discussed in Section 111-E, the schemes proposed still recover some normalized direction of translation and the correct rotational velocity. Once the appropriate scaling information has been inserted, full translation is correctly estimated. Second, in the first and the last part of the experiment, the motion is designed such that the effects of translation and rotation produce the same variation, up to first order, in the Note also that wch spikes do not affect convergence, since they do not occur in the estimation process, but while transferring to local coordinates. The switching can be avoided by a higher level control on the continuity of the singular values of the estimated state. There is a significant error in the local coordinates near frame 260, when the translation is zero and the direction of rotation is inverted. The smoothness imposed by the dynamics of the parameters is responsible for the transient in the estimates of the rotation which propagates onto the estimate of translation, causing a visible spike with a significant transient. Fig. <ref type="figure">8</ref>. spikes due to the local coordinate transformation. Note also that there is no transient to recover since they do not occur in the estimation process.</p><p>Components of rotational velocity as estimated by the local coordinate estimator (radframe). The ground truth is shown in dotted lines. Note the derivative of the observations. This is a well-known ambiguous stimulus in which it is difficult to distinguish locally the effects of rotation from those of translation.</p><p>We have systematically varied the conditions of the experiments, by changing the distance in space from the cloud of dots between 1 m and 5 m, the initial conditions between 0% and 1000% off the true value, the level of measurement noise between 0 and 2 pixels, and the number of visible points between 1 and 100.</p><p>It is interesting to notice that, while previous schemes based upon the essential matrix needed at least eight <ref type="bibr">[49]</ref> or five <ref type="bibr" target="#b29">[38]</ref> visible points at each time instant, here we can allow any number of points even below the threshold of five, since we integrate over time the motion information.</p><p>The behavior of the different filters was consistent with a graceful degradation of the estimates as the noise level increases and a need for more precise initial conditions as the noise increases and the number of visible points diminishes. The performance of the filter saturates as the number of visible points increases beyond 20. The performance also degrades as the points move far away from the viewer and as the structure approaches a plane. Under these conditions, in fact, the matrix x approaches rank six rather than its normal rank of eight</p><p>We have tested the essential filter in local coordinates, both implemented using the IEKF and the two-dimensional (2-D) iteration described in Appendix A and the essential filter in the embedding space. We now comment on the performance of 1241, ~6 1 . each filter on the reference simulation experiment, highlighting some of the features peculiar to each scheme. The performance of the filters is compared in Table <ref type="table">I</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. The Local Coordinate Estimator</head><p>In Figs. <ref type="figure">5</ref> and<ref type="figure">6</ref> we show the six components of translational and rotational velocity as estimated by the local coordinates estimator. Ground truth is plotted in dotted lines. Convergence is reached in less than 20 steps from an initial condition within 20% the true state. Initialization is performed using one step of the traditional Longuet-Higgins' algorithm [49]. Tuning of the filter has been performed, as with the other schemes, within an order of magnitude. It must be pointed out that we have observed a better behavior by increasing the variance of the pseudo-innovation. This is due to the fact that the EKF relies :E TRANSACTIONS ON AUTOMATIC CONTROL, VOL. 41, NO. 3, MARCH 1996 on the hypothesis that the measurement noise is white and the linearization error is negligible, while this is often not the case. An increase in the variance of the measurement noise accounts for the residual of the linearization. The computational cost of one iteration is of about 100 Kflops for 20 points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. The Estimator in the Embedding Space</head><p>In Fig. <ref type="figure" target="#fig_13">9</ref> we show the nine components of the essential matrix as estimated by the essential estimator in the embedding space. Since convergence is about four times slower than the local coordinate version and each step requires four times less computation, we have sampled the measurements four times faster, ending up with a 400 frames-long sequence.</p><p>Note first that between the frames 200 and 300, the true value of the state is zero. The estimates of the filter drift off to nonzero values, since the essential matrices are defined as to have unit norm. Such nonzero values are those that allow estimating correctly the rotational velocity and a dummy direction of translation even in the case of pure rotation about the optical axis, as discussed in Section 111-E. By transforming the state into local coordinates and inserting the appropriate scale, it is possible to recover the correct rotational and translational components of motion, as shown in Figs. <ref type="figure" target="#fig_11">7</ref> and<ref type="figure">8</ref>. defined in ( <ref type="formula">9</ref>) may have singularities due to noise when the last eigenspace is exchanged with one of the other two. In fact, due to the presence of noise, the third singular value of the estimated essential matrix is nonzero, and occasionally may even become bigger than the other two. Since the SVD sorts the singular values in decreasing order, the eigenvectors-which encode the motion information-may be interchanged. This causes the spikes observed in the estimates of motion. However, there is no transient to recover, since the errors do not occur in the estimation step but only in transferring to local coordinates. The switching can be avoided by a higher level control on the continuity of the singular values. The only significant error in the local coordinates occurs at around frame 260, when the translation is zero and the direction of rotation is inverted. The smoothness imposed by the dynamics of the parameters is responsible for the transient in the estimates of the rotation which propagates onto the estimates of translation, causing a visible spike with a significant transient. Note that a much less relevant spike was also present in the estimate of the filter in local coordinates (Fig. <ref type="figure">5</ref>).</p><p>The computational cost of our current implementation of the filter in the embedding space amounts to circa 41 Kflops per each step for 20 points. Initialization was performed within 20%, as in the previous case, using one step of the algorithm of Longuet-Higgins [491.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The homeomorphism</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. The 2 -0 Iteration</head><p>The essential filter in local coordinates has been implemented using the double iteration described in Appendix A. The results are reported in Figs. 10 and 11. This scheme reaches similar accuracy to the local filter after proper initialization, even though the error analysis used for calculating the variance of the estimates at each fixed time was only  approximate. Speed may be adjusted by varying the number of iterations at each fixed time. We have noticed that a number of steps between three and seven is sufficient. The cost of the scheme for seven iterations and 20 points is 100 Kflops. The simulations reported were performed using a constant variance of the error of the kiteration.</p><p>We summarize the performance of the three schemes in Table <ref type="table">I</ref>: mean (M) and standard deviation (Std) of the estimation error are computed in steady state between frame 30 and 50 for the local coordinate scheme and the 2-D iteration while between time 180 and 260 for the estimator in the embedding space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Experiments on Real Image Sequences</head><p>In the first experiment, we have tested our schemes on a sequence of 10 images taken at the University of Massachusetts at Amherst (see Fig. <ref type="figure" target="#fig_16">12</ref>). There are 22 feature points visible; ground truth and feature tracking have been provided. Due to the limited length of the sequence, we have run it on the local coordinates estimator which has a transient of about 10-20 steps to converge from arbitrary initial condition. Hence we have run the local estimator on the 10 images starting from zero initial condition, and we have used the final estimate as initial condition for a new run whose results we report in Figs. 13-15. We did not perform any ad hoc tuning, and the setting was the same used in the simulations described in the previous paragraphs. In Fig. <ref type="figure" target="#fig_3">13</ref> we report the six motion components as estimated by the local coordinate estimator and the corresponding ground truth (in dotted lines). The estimation error is plotted in Fig. <ref type="figure">14</ref>. As it can be seen, the estimates are within a 5% error, and the final estimate is less than 1% off the true motion. Finally, in Fig. <ref type="figure">15</ref> we display the norm of the pseudo-innovation of the filter which converges to a value of about in less than 10 + 5 steps. In this experiment, we have used the true given norm of translation as the scale factor.</p><p>In a second experiment we have taken a box, attached some texture to it, and generated a sequence of images by rotating the box on top of a revolving chair placed in front of the camera. We have selected and tracked automatically feature points using a multiscale implementation of a standard scheme proposed by <ref type="bibr">Lucas and Kanade [51]</ref> which gave us a number of good features as well as a number of spurious one (like the "T"-junctions between the chair and the horizontal lines in the background wall) and points in the background (Fig. <ref type="figure">16</ref> top). A simple on-line statistical analysis on the innovation process of the filter allows us to easily reject these points as outliers <ref type="bibr">[64]</ref>. The motion components of the remaining points, the ones attached to either the box or the chair, are estimated and plotted in Fig. <ref type="figure">16</ref>  Benchmark experiments on the scheme's performance on real-life situations have been conducted also by other researchers. For instance, Bouguet [7j considered a sequence of over 4000 frames taken from a camera mounted on a cart which moved inside a building, eventually returning to its initial position. The aim of the experiment was to assess how accurate the reconstruction of the trajectory was by integrating over time the v'elocity (or relative instantaneous configuration) through the sequence. Individual features, tracked using standard feature tracking schemes [4j, have a relatively short lifetime (on the order of 10 frames for that particular experiment). Therefore, traditional motion estimation schemes, having structure encoded in the state of the filter, would have discontinuities in the states corresponding to the structure parameters whenever a feature appears or disappears which affects the estimates of motion through the coupling present in the model ( <ref type="formula">14</ref>). On the contrary, the velocity of the cart is of course continuous, and only by decoupling motion from the estimation of structure it is possible to integrate information throughout the sequence without having to deal with a variable number of discontinuous states.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSIONS</head><p>The problem of estimating 3-D motion from a sequence of images can be naturally set in the framework of dynamic estimation and identification. Under the assumption of a static scene, the rigid motion constraint and the perspective projection map define in a natural way a nonlinear dynamical model, and estimating motion is equivalent to a mixed estimatiodidentification task.</p><p>Motivated by the structural limitations of the natural model (see [59j), we have proposed a new formulation for structureindependent motion estimation based upon the representation of motion via the "essential matrices," introduced by Longuet-Higgins <ref type="bibr">[49]</ref>. Motion estimation is equivalent to the identification of a nonlinear implicit model with parameters on the essential manifold. Other problems in computer vision may be cast as the identification of a nonlinear implicit model, as for example dynamic self-calibration, subspace motion factorization, and partial motion reconstruction rom weak perspective.</p><p>We have proposed an algorithm which solves the identification task by estimating the state of a model defined on the parameter manifold. We perform the estimation either in the local coordinates or in the embedding space of the parameter manifold.</p><p>We are now in the process of implementing the proposed schemes on real-time hardware. We believe that the simplicity and robustness of the methods proposed, along with the power of modem architectures, will soon allow us to insert them into the control loop of mechanical systems. The flexibility of vision as a sensor, once brought to real-time operation, opens up a number of applications ranging from visuallyguided navigation, manipulation, surveillance, active sensing, and recognition. APPENDIX A &amp;CURSIVE LOCAL IDENTIFICATION OF IMPLICIT SYSTEMS USING PREDICTION ERROR CRITERIA Suppose {x(t)&gt; E I R ~ is a trajectory on a linear state space which is subject to an implicit dynamic constraint of the form</p><formula xml:id="formula_49">h[z(t), dz(t), a] = 0 z(0) = 5 0 a E M (<label>39</label></formula><formula xml:id="formula_50">)</formula><p>where a are some unknown parameters which may move (slowly) on some topological manifold M . Call 01 A $ ( a ) E IR" the local coordinates correspondent of a. Suppose we are able to measure n: up to some white, zero-mean Gaussian noise y(t) = 5 ( t ) + n(t) n E N(0, Rn).</p><p>We are interested in identifying the parameters a recursively from the measurements {y(t)} based on the minimization of some cost function of the prediction error (for a classical treatment of prediction error methods (PEM) for linear explicit models, see for example, [67], [48j, and [47]).</p><p>A common paradigm for PEM identification consists in forcing a Kalman filter to work as a parameter estimator. The state of the filter is augmented with the unknown parameters which are described using a random walk model. In this section we will extend this paradigm to nonlinear implicit dynamics and parameters living on a topological manifold. We will restrict our attention to discrete time dynamics, although the same analysis may be carried out for continuous time models. First we proceed in analogy with the linear-explicit case: we describe the local coordinates of the parameters as first-order random walk and use the dynamic constraint as an implicit measurement constraint a(t + 1) = a(t) + n,(t) a(0) =a0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>h [ ~( t )</head><p>n ( t ) , y ( t -1) -n(tl),$-'(a(t))] = O (40) where we have substituted the index t with t -1 in the measurements {y} (or equivalently the estimator runs with one step delay). We assume n,, the noise driving the random walk, to be white, zero-mean and Gaussian; its variance R, may be regarded as a tuning parameter. The noise process {n(t)} induces a residual in the measurement equation: If we approximate x ( t ) with y ( t ) , in general we will observe h[y(t), y(tl), a] = fi # 0, where iz depends on { n } , {y} and U . This residual-as we will see-is the prediction error (or pseudo-innovation) when choosing a least-squares criterion in the PEM.</p><p>Let us collect the measurements into a vector g ( t ) = [yT(t) yT(tl)lT and, similarly, with n ( t ) = [nT(t) nT(t -1)IT. Our task is to estimate a from the model</p><formula xml:id="formula_51">a(t + 1) = a(t) + n&amp;) a(0) = a0 h[jj(t) -n(t), $-l(a(t))] = 0. (41)</formula><p>To follow the course of the linear-explicit case, we have to solve a number of problems:</p><p>1) The noise Ti is not white</p><formula xml:id="formula_52">I RnS(t -S)</formula><p>RnS(ts + 1)</p><formula xml:id="formula_53">RnS(t -s -1) R,S(t -S ) E [n( t )ET ( s ) ] =</formula><p>2) The error E does not appear additively in the measure- [17], <ref type="bibr" target="#b27">[36]</ref>, and <ref type="bibr">[26]</ref>. The derivation is based on the simple fact that the variational model about the current trajectory is linear and explicit, so that the a pseudo-innovation process may be defined analogously to the explicit case.</p><p>The derivation of the IEKF in Appendix B does not address the fact that the noise 5, is correlated (see point 2) above). The residual of the measurement equation fi, which is in fact the pseudo-innovation of the filter, is characterized in terms of E , provided that the last is white, zero-mean, and uncorrelated with n,. In the following section, we will show how to whiten and therefore reduce the problem to a form suitable for using the IEKF as derived in Appendix B. Later on we will see how the problem simplifies by assuming that E is white.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Uncorrelating the Model from the Measurements tion about the point jj(t), a ( t )</head><p>Consider a first-order expansion of the measurement equa-</p><formula xml:id="formula_54">h [ m $ -l ( a ( t ) ) I -D+(t)n(t) -D-(t)n(t -1) = O((lZ112) E 0</formula><p>where the limit implicit in 0 is intended in the mean-square sense, and where we have defined  (44)   where we have defined w ( t ) = -D+(t)n(t). Now the measurement error w is white; however, it is correlated with the model error U</p><formula xml:id="formula_55">a(t + 1) = a(t) + na(t) a ( 0 ) = a0 z ( t + 1) =n(t) z ( 0 ) = 0 0 = h[r/(t),$-l(a(t))] -D-(t).(t) + w ( t )</formula><p>[n:,nTlT. We may therefore project the model error onto the orthagonal span of the measurement error, H ( w ) , to make the two uncorrelated. We define G(t) A</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>v ( t ) -k [ v ( t ) ( H ( w ) ] .</head><p>Since w ( t ) , n ( t ) and n,.(t) are white, scene viewed from the top (the horizontal axis is a slice of the image plane, and the vertical axis is the depth of each feature point in cm).</p><formula xml:id="formula_56">it is easily seen that fi[4t)IH(w)l = a 4 t ) l w ( t ) l = E [U ( t ) W T ( t ) ] ( E [ w ( t ) W T ( t ) ] ) -1 w ( t ) = C,,C,lw(t).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>If we define</head><p>it is easy to see that E,, = S(t)R-l(t); furthermore</p><formula xml:id="formula_57">Ca = Q(t) = Q(t)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>+S(t)R-'(t)ST(t). NOW V e v-SR-lw</head><p>is by construction orthogonal (uncorrelated) to w.</p><p>where we have defined Furthermore, if we expect a large number of measurements, the cost in updating a large state and tuning a large number of model-variance parameters may be relevant. In practical applications, the approximation E as white noise are often better behaved. In the following section we show how the structure of the filter simplifies under such an approximation.</p><formula xml:id="formula_58">K ( t ) = R</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. A Simplijied Version: Approximate</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Least-Squares PEM Identijcation</head><p>In this section we report the equations of the parameter estimator which are obtained supposing that the residual ii is white. This corresponds to applying the results of Appendix B directly to the model of <ref type="bibr" target="#b32">(41)</ref> where the quantities L(t+1), h(t+l), and r ( t + l ) are defined according to Appendix B. Note that we have reduced the size of the state from n + m down to m.</p><p>Detecting Outliers: Note that each component of the pseudo-innovation is a measure of the consistency of each datum with the current parameter estimates. This proves useful when applied to the motion problem because it allows us to detect outliers and also segment the scene into a number of independently moving objects [64].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. An Iterative Scheme for Computing the Update</head><p>The E K F update seen in the previous section may be substituted with a Gauss-Newton iteration, as it is customary in recursive ID of linear models</p><formula xml:id="formula_59">&amp;(k + 1) = &amp; ( k ) -L N R ( k ) h ( &amp; ( k ) )</formula><p>where LNR = J;'(&amp;(k)), and Jh is the Jacobian of h. Note that at each fixed time we could perform a Newton-Raphson iteration on the function h(?J, a ) , for which local convergence results can be derived as well as bounds on the convergence rate. This suggests, as an alternative to the IEKF, fixing t and performing a Newton-Raphson iteration along the k coordinate. Once this is done, we propagate the estimate across time with an iteration which now is linear and has all the desirable asymptotic properties.</p><p>Iteration at Each Fixed Time: At each time instant, a new set of measurements ?J(t) becomes available. The constraint imposes h[?J(t),a] = 0 Y t .</p><p>Define T, h: Et" 4 IR" to be the derivative of the map h and 3h(a) the Jacobian matrix calculated at the point a. Suppose that there exists some a* such that h(?J(t),a*) = 0 for our particular (fixed) t. Then we may write a first-order expansion around the point a*, starting from some point QO (we neglect time indexes for the remainder of this section); the resulting iteration which is obtained by neglecting the second-order term of the expansion is defined by h[QkI + Jh(Qk)[Qk+l -4 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J h ( Q k ) Y = h[%]</head><p>At each iteration we solve for Y the linear problem and then define a k + l a k + Y. In general, also due to noise, we can expect h[Qk] $ ! Im( Jh ( a k ) ) , so that we will be seeking for Y such that J h ( a k ) Y is the projection of h[ak] onto the range space of J h ( a k )</p><formula xml:id="formula_60">Q k + l = Q k -L N R ( k ) h [ Q k ] where L N</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R ( ~) = ( J ~( a k ) J h ( a k ) ) -' J ~( a k ) .</head><p>The map defined by the right-hand side of the above equation is contractive as long as J h ( a k ) has full rank, in which case the scheme is guaranteed to converge to some (possibly local) minimum.</p><p>At each time the scheme will converge to some a* which best explains the noisy measurements ylZ(t), ~~( t -1); hence we have a* = a + na, where n, is an error term and can be interpreted as a white noise whose variance can be inferred from the variance of n and the linearization of the scheme about zero-noise. The estimate obtained at each fixed time, together with its variance, is fed to a time-integration step which we describe next.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>4 P l , P 2 ) = d ( g ( p d , g ( p 2 ) ) VP1,PZ E R39*(41 A q 2 ) =9*(41) A 9*(92) Vq1, q2 E T R 3 R3 where g* is the transformation induced on vectors q A PZ -P I * g*(q) A g ( p z ) -g(p1) and TIR3 is the tangent space to R3. If we represent the points p z in coordinates X , A [Xz Y , &amp; I T relative to some orthonormal reference frame, we may characterize a rigid motion as a translation of the origin and a rotation of the reference frame. The matrices which represent the change of basis induced by a rotation of the reference are orthogonal with unit determinant; such matrices form a Lie group of dimension three, called SO<ref type="bibr" target="#b2">(3)</ref> (special orthogonal group of transformations of R3) [l],<ref type="bibr" target="#b5">[6]</ref>,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>( 5&gt; ( 3</head><label>3</label><figDesc>(e) let Q = U&amp;VT be an SVD. Furthermore, let 0 of w/2 about the axis [0 0 1IT, then Q=UCoVT=UCoRE f-UTURz f-V T . Now call R = URz(&amp;(7r/2))VT and S = U C o B z ( f (7r/2)) U T ; it is immediate to see that RRT = R T R = I and ST = -S. From the uniqueness of the SVD, it follows that this decomposition is unique, modulo the sign in RZ (f (7r/2)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>k T , and X (01 + 5 2 ) / 2 . It follows from the properties of the SVD [32] that p ~( ~) (Ad) minimizes the Frobenius distance of M from the essential manifold 1331, [53].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>- 1 XFig. 3 .</head><label>13</label><figDesc>Fig. 3. Structure of the motion problem on the essential space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Remark 3 . 1 :</head><label>31</label><figDesc>The one just described is a crucial feature of the method proposed. In fact, schemes based upon simultaneous structure and motion estimation [3l, [52l, 1561 become ill-conditioned when close to zero-norm translation, since it is a nonobservable configuration for the model (14), -Iv. SOLVING THE ESTIMATION TASK At this point we are ready to address the problem of recursively estimating motion from an image sequence. There 9 R</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>)</head><label></label><figDesc>Note that P(tlt) is the variance of the motion estimation error which is used as variance of measurement error from subsequent modules of the structure from motion estimation scheme[66]. A similar formulation of the IEKF was used by Di Bernard0 et al.[17]. Similar expressions were also used before in the literature on specific applications; the first instance to our knowledge was in the recursive computation of the Hough transform[15].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>( 37 )</head><label>37</label><figDesc>The matrix F is called "fundamental matrix." It specifies the relation between each point and its corresponding epipolar line[25]. If the camera is represented as a 3 x 4 matrix [AI01 wheref s , 0 -i ois the internal parameter matrix,' then it can be shown that ATFA E E<ref type="bibr" target="#b29">(38)</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Y</head><label></label><figDesc>noise in IR9. If we substitute the above equation into (18), we have again a dynamical model on a Euclidean space (in our case Etg) driven by white noise. The essential estimator is the least variance filter for the above model and corresponds to a linear Kalman filter uDdate in the embedding mace. followed f is the focal length, ( i n , i o ) are the coordinates of the intersection -* -~ -"., by a projection onto the essential manifold. In principle, an approximate gain ' "I d be precomputed Offline for each possible configuration of motion and feature positions:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>D I M: .21563-3 Std: ,0034 I M: .22613-3 Std: .0006 I Mz.00733-3 Std:.0006 Furthermore, temporal coherence of the camera model is not where v, -xivs exploited. If we substitute<ref type="bibr" target="#b29">(38)</ref> into<ref type="bibr" target="#b28">(37)</ref>, we get a dynamic model lv2 -YiV3 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>$- 5 Fig 5 Fig. 6 .</head><label>556</label><figDesc>Fig 5 Components of translational velocity as estimated by the local coordlnate estimator (&amp;frame) The ground truth 1s shown in dotted lines</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 7 .</head><label>7</label><figDesc>Fig.7. Components of translational velocity as estimated by the essential estimator (&amp;frame). Note the spikes due to the local coordinate transformation. Note also that wch spikes do not affect convergence, since they do not occur in the estimation process, but while transferring to local coordinates. The switching can be avoided by a higher level control on the continuity of the singular values of the estimated state. There is a significant error in the local coordinates near frame 260, when the translation is zero and the direction of rotation is inverted. The smoothness imposed by the dynamics of the parameters is responsible for the transient in the estimates of the rotation which propagates onto the estimate of translation, causing a visible spike with a significant transient.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 9 .</head><label>9</label><figDesc>Fig.9. Components of the essential matrix as estimated by the essential estimator. There are no spikes. The estimates between time 200 and 300 are nonzero, despite the ground truth (dotted line), since the essential space is normalized to unit-norm. The value of the components of the estimates of Q in the singular region T = 0 allow us to recover correctly the rotational velocity, once transformed to local coordinates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Components of translational velocity as estimated by the double iteration estimator (dframe).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Components of rotational velocity as estimated by the double iteration estimator (radframe)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. One image of the rocket scene.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>(bottom left; error bars indicate twice the variance of the estimates) along with the top-view of the structure as estimated by a simple EKF using the estimated motion, in the lines of [66] (Fig. 16, bottom right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>2 Fig. 13 .</head><label>213</label><figDesc>Fig. 13. Motion estimates for the rocket sequence: The six components of motion as estimated by the local coordinate estimator are showed in solid lines. The corresponding ground truth is in dotted lines. Units are d f r a m e for the components of translational velocity. Rotational velocity, expressed in rad/frame, is approximately zero</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Motion error camponents for the rocket sequence 5 Fig. 14 .Fig. 15 .</head><label>51415</label><figDesc>Fig. 14. Error in the motion estimates for the rocket sequence. All components are within 5% of the true motion</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>5 Fig. 16 .</head><label>516</label><figDesc>Fig. 16. (top) One frame of the original sequence with the feature points highlighted. (bottom left) five components of the estimated motion (vertical units are rad for the rotational velocity and rad for the components of the direction of translation, the horizontal axis is the frame number). (bottom right) Reconstructed</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>)</head><label></label><figDesc>P(t + Ilt) = P ( t ( t ) + RE; P(O(0) = Po. (22) P(t + l ( t ) = P ( t ( t ) + RQ; P(O(0) = Po. (31)</figDesc><table><row><cell>Update Step:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE I Tz M</head><label>IM</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>: .0002 Std: ,0004</cell></row><row><cell></cell><cell></cell><cell></cell><cell>M: .0002 Std: .0001</cell></row><row><cell></cell><cell></cell><cell></cell><cell>M: .28513-3 Std: .0009</cell></row><row><cell cols="2">Scheme Rx</cell><cell></cell><cell>RY</cell></row><row><cell>Local</cell><cell>M:.0008 SL,</cell><cell>L</cell><cell>M:.0002 Std:.0002</cell></row><row><cell cols="3">Essential M:-.0008 Std: .0004</cell><cell>M: 3.99493-6 Std: .0002</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>A Model for PEM Identification of Nonlinear Implicit Models In</head><label></label><figDesc>the Previous Paragraph we have derived an extended model (up to first order) with the model error uncorrelated from the measurement error By applying the results of Appendix B, we can derive a pseudo-optimal PEM identification scheme described by the following iteration: D-(t + 1)qt + lit))P(t + lit + 1) = r(t + t ) ~( t + ilt)rT(t + 1) + ~( t + 1).D+(t + 1)R,(t + l)D;(t + l ) L T ( t + 1) (52) where L(t + 1) + P ( t + llt)CT(t + l)h-'(t + 1) h(t + 1) = C(t + 1)P(t + llt)CT(t + 1)</figDesc><table><row><cell>(53)</cell><cell></cell></row><row><cell>(54)</cell><cell></cell></row><row><cell>(55)</cell><cell></cell></row><row><cell></cell><cell>(49)</cell></row><row><cell>w ( t ) A -D+(t)n(t).</cell><cell>(50)</cell></row><row><cell>Prediction Step:</cell><cell></cell></row></table><note><p><p><p><p><p>, (t)D? (t) (D+ (t)R, (tp: ( t ) )</p>B.</p>a(t + 1) = a ( t ) + na(t) a(0) = a0 Z ( t f I) = K(t)(h[V(t), V ( a ( t ) ) ] -D -( t ) z ( t ) ) + n(t) z ( 0 ) = 0 &amp;(t + llt) = &amp;(tlt) ir(010) = a0 q t + llt) = K(t)(h[3(t), &amp;(tlt)] -D -( t ) i ( t l t ) ) q o p ) = 0 0 = h[g(t</p>),$-l(a(t))] -D -( t ) z ( t ) + w ( t ) (48) P(t + llt) = F ( t ) P ( t ( t ) F T ( t l t )</p>+ Q(t) P(O(0) = PO (51) where and -+ D+(t + 1)R,(t + l ) D T ( t + 1) r(t + 1) = I -~( t + qc(t + 1). Note that we are trying to estimate a process { ~( t ) } which is nearly white noise (n(t) is correlated only within one step).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>, assuming that { E } is a white process:Prediction Step:8(t + llt) = &amp;(tlt) S(Ol0) = a0 P(t + lit) =P(tlt) + R,(t) P(OI0) = Po. (56)</figDesc><table><row><cell>Update Step:</cell></row><row><cell>&amp;(t + 1Jt + 1) = &amp;(t + llt) + L(t + l ) h [ ? J ( t ) , ? p ( &amp; ( t + lit)] P ( t + llt + 1) = r(t + t ) ~( t + ilt)rT(t + 1) + ~( t + I)</cell></row><row><cell>(57)</cell></row></table><note><p><p>.</p>D+(t + 1)R,(t + l ) D T ( t + l ) L T ( t + 1)</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors wish to thank Prof. G. Picci for his advice and encouragement, Prof. K. Astrom for his discussions on implicit Kalman filtering, Prof. R. Murray, and Prof. S. Sastry for observations and useful suggestions. Finally, the authors thank J. Oliensis and I. Thomas for providing the rocket sequence.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recommended by Associate Editor, A. J. van der Schaft. This work was supported in part by the California Institute of Technology, a fellowship from the University of Padova, a fellowship from the "A. Gini" Foundation, an AT&amp;T Foundation Special Purpose grant, ONR Grant N0014-93-1-0990, and grant ASI-RS-103 from the Italian Space Agency.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Propagation Along Time: Suppose at each fixed time the iteration along IC described above converges to a fixed point The linearization of the measurement equation about the point ( Z ( t ) , y(t)) is which realizes a linear Kalman filter based upon the model a(t + 1) = a(t) + na(t) a*(t) = a(t) + no(t) <ref type="bibr">(58)</ref> where n, is the noise driving the random walk model for the parameters, which we assume to be white, zero-mean and Gaussian, and no is the error made by the fixed-time iteration. L(t) is the usual linear Kalman gain [40], [391. The above model has all the desirable properties, as it satisfies the conditions of the asymptotic theorem of Kalman filtering. Suppose now that the k-iteration has converged to a local minimum which is compatible with the current observations. At the next step the t-iteration will predict an estimate which is, in general, no longer compatible with the current observations. This should help to disambiguate local minima as the measurements accumulate in time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX B MEASUREMENT CONSTRAINTS</head><p>We are interested in building an estimator for a process { a } which is described by a stochastic difference equation of the form</p><p>where ~( t ) E N(0, Q v ) is a white, zero-mean Gaussian noise with variance Qu. Suppose there is a measurable quantity x ( t ) which is linked to Q by the constraint h[a(t),z(t)] = 0 vt.</p><p>(59)</p><p>We will assume throughout f , h E C';r 2 1. Usually I(: is known via some noisy measurement (60)</p><p>where the variancekovariance matrix R, is derived from knowledge of the measurement device. The model we consider is hence of the form</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Construction of the Variational Model About the Reference</head><p>Trajectory: Consider at each time sample t a reference trajectory Z ( t ) which solves the difference equation</p><p>and the jacobian matrix</p><p>where E 2 {Ita -all2, 1 1 5 -Y1l21 and the limit implicit in 0 is intended in the mean-square sense. Exploiting the fact that h[a,z] = 0, calling Sa(t) k a(t) -&amp;(t), and neglecting the arguments in C and D , we have up to second-order terms</p><p>Prediction Step: Suppose at some time t we have available the best estimate &amp;(tlt); we may write the variational model about the trajectory Z ( t ) defined such that</p><p>For small displacements we may write</p><p>where the noise term a(t) may include a linearization error component.</p><p>Note that with such a choice, we have S&amp;(tlt) = 0 and</p><p>The variance of the prediction error S&amp;(t + llt) is ( <ref type="formula">63</ref>)</p><p>where Q = var <ref type="bibr" target="#b5">(6)</ref> </p><p>[15] F. Darmon, "A recurs;ve metcod to apply the hough transform to a set of moving objects," Proc. IEEE, 1982.</p><p>[16] W. Dayawansa, B. Ghosh, C. Martin, and X. Wang, "A necessary and</p><p>sufficient condition for the perspective observability problem," Syst.</p><p>Contr. Lett., 1994.</p><p>Since S&amp;(t + llt) = 0 and S8(t + llt + 1) = &amp;(t + llt + 1) -8(t + llt), we may write the update equation for the original model</p><p>In this formulation, the quantity h[h(t + lit), y(t + l)] plays the role of the pseudo-innovation. The noise n defined in (65) has a variance which is calculated from its definition</p><p>The update of the variance P(t + llt + 1) is computed from the standard equations of the linear Kalman filter. The implicit Kalman filter was used by other researchers such as Darmon</p><p>[15], Faugeras [26], [46], <ref type="bibr" target="#b67">[80]</ref>, and Heel <ref type="bibr" target="#b27">[36]</ref>, although in slightly different formulations and always without a consistent derivation of the form of the update. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Marsden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ratiu</surname></persName>
		</author>
		<author>
			<persName><surname>Manifolds</surname></persName>
		</author>
		<title level="m">Tensor Analysis and Applications</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>nd ed</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An ego-motion algorithm based on the tracking of arbitrary curves</title>
		<author>
			<persName><forename type="first">E</forename><surname>Arbogast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mohr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd European Con$ Computer Visiou</title>
		<meeting>2nd European Con$ Computer Visiou</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Recursive estimation of structure and motion using relative orientation constraints</title>
		<author>
			<persName><forename type="first">A</forename><surname>Azarbayejani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conj! Computer Vision</title>
		<meeting>IEEE Int. Conj! Computer Vision<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Performance of optical flow techniques</title>
		<author>
			<persName><forename type="first">J</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Beauchemin</surname></persName>
		</author>
		<idno>RPL-TR 9107</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR 1992</title>
		<meeting>CVPR 1992<address><addrLine>Kingston, . Ontario</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="236" to="242" />
		</imprint>
		<respStmt>
			<orgName>Robotics and Perception Laboratory</orgName>
		</respStmt>
	</monogr>
	<note>Queen&apos;s Univ</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Grasping visual symmetry</title>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Con$ Computer Vision</title>
		<meeting>IEEE Int. Con$ Computer Vision</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Boothby</surname></persName>
		</author>
		<title level="m">Introduction to Differentiable Manifolds and Riemannian Geometry</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic</publisher>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A visual odometer and gyroscope</title>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Bouguet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Con$ Computer Vision</title>
		<meeting>IEEE Int. Con$ Computer Vision</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Estimating the kinematics and structure of a rigid object from a sequence of monocular frames</title>
		<author>
			<persName><forename type="first">T</forename><surname>Broida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">199</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Estimation of object motion parameters from noisy images</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<date type="published" when="1986-01">Jan. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Exterior Differential Systems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Bryant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Chem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Goldshmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Griffith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Bucy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">L</forename><surname>Toniutti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Frezza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Picci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Stima del moto dell&apos;osservatore e della struttura della scena mediante visione monoculare</title>
		<meeting><address><addrLine>New York; New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1965">1991. 1965. 1988. 1993</date>
		</imprint>
		<respStmt>
			<orgName>Tesi di Laurea-, Univ. Padova</orgName>
		</respStmt>
	</monogr>
	<note>AC-IO. I71 E. Di-Bemardo</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Relative 3-D-state estimation for autonomous visual guidance of road vehicles</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Dickmanns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Christians</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Intelligent Autonomous Syst</title>
		<meeting>Intelligent Autonomous Syst<address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989-11-14">Dec. 11-14, 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Applications of dynamic monocular machine vision</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Dickmanns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Graefe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Vision Appl</title>
		<imprint>
			<biblScope unit="page" from="241" to="261" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dynamic monocular machine vision</title>
	</analytic>
	<monogr>
		<title level="j">Machine Vision Appl</title>
		<imprint>
			<biblScope unit="page" from="223" to="240" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Image-based dynamic visual servo for a hand-eye manipulator</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ebine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kimura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recent Advances in Mathematical Theory of Systems, Control, Networks, and Signal Processing</title>
		<editor>
			<persName><surname>Mita</surname></persName>
		</editor>
		<imprint>
			<publisher>Kodama Kimura</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="609" to="614" />
		</imprint>
	</monogr>
	<note>Proc. Int. Symp. MTNS</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">What can be seen in three dimensions with an uncalibrated stereo rig</title>
		<author>
			<persName><forename type="first">D</forename><surname>Faugeras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd ECCV</title>
		<meeting>2nd ECCV</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Three Dimensional Vision, A Geometric Viewpoint</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>MIT</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Building visual maps by combining noisy stereo images</title>
		<author>
			<persName><forename type="first">D</forename><surname>Faugeras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Faverjon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Faugeras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Maybank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Con$ Robotics Automat</title>
		<meeting>Int. Con$ Robotics Automat</meeting>
		<imprint>
			<publisher>New York Springer-Verlag</publisher>
			<date type="published" when="1986">1986. 1992</date>
			<biblScope unit="volume">588</biblScope>
			<biblScope unit="page">1251</biblScope>
		</imprint>
	</monogr>
	<note>Proc. ECCV</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Motion and structure from point and line matches</title>
		<author>
			<persName><forename type="first">D</forename><surname>Faugeras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lustman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Toscani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Con$ ICCV</title>
		<meeting>IEEE Con$ ICCV</meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Motion from point matches: Multiplicity of solutions</title>
		<author>
			<persName><forename type="first">D</forename><surname>Faugeras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Maybank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Computer Vision</title>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Tracking known 3-dimensional objects</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Gennery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAA1 2nd Nut. Conf: Artif: Intell</title>
		<meeting>AAA1 2nd Nut. Conf: Artif: Intell<address><addrLine>Pittsburgh, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1982">1982</date>
			<biblScope unit="page" from="13" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Visual tracking of known 3-dimensional objects</title>
	</analytic>
	<monogr>
		<title level="j">Int. J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="243" to="270" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Perspective problems in systems theory and its application in machine vision</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jankovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Syst., Est. Contr</title>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Motion parallax as a determinant of perceived depth</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">W</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Flock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Psych</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<date type="published" when="1959">1959</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Matrix Computations, 2nd ed</title>
		<author>
			<persName><forename type="first">G</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Van Loan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Johns Hopkins Univ</publisher>
			<pubPlace>Baltimore, MD</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Estimation of relative camera positions for uncalibrated cameras</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd Europ. Conj! Comput. Vision, G. Sandhi</title>
		<meeting>2nd Europ. Conj! Comput. Vision, G. Sandhi</meeting>
		<imprint>
			<biblScope unit="volume">588</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Subspace methods for recovering rigid motion: Algorithm and implementation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Heeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jepson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comp. Vision</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Direct estimation of structure and motion from multiple frames</title>
		<author>
			<persName><forename type="first">J</forename><surname>Heel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MIT AI Lab., AI Memo 1190</title>
		<imprint>
			<date type="published" when="1990-03">Mar. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Temporal integration of 3-d surface reconstruction</title>
		<author>
			<persName><surname>___</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattem Anal. Machine Intell</title>
		<imprint/>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Autonomous spacecraft docking using a computer vision system</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Mcclamrock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 31st Con$ Decision Contr</title>
		<meeting>31st Con$ Decision Contr<address><addrLine>Tucson, AZ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Relative orientation</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K P</forename><surname>Hom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="59" to="78" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Jazwinski</surname></persName>
		</author>
		<title level="m">Stochastic Processes and Filtering Theory</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic</publisher>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A new approach to linear filtering and prediction problems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kalman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. ASME-J. Basic Eng</title>
		<imprint>
			<biblScope unit="page" from="35" to="45" />
			<date type="published" when="1960">1960</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Karger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Novak</surname></persName>
		</author>
		<title level="m">Space Kinematics and Lie Groups</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Gordon and Breach</publisher>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Manipulator control with image-based visual servo</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ebine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kimura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Con$ Robotics Automat</title>
		<meeting>IEEE Int. Con$ Robotics Automat</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="2267" to="2272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Affine structure from motion</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Koenderink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Van Doorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Opt. Soc. Amer</title>
		<imprint>
			<date type="published" when="1991">1991. 1992</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A new nonlinear feedback controller for visually-guided robotic motion tracking</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECC</title>
		<meeting>ECC</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Libermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Mark</surname></persName>
		</author>
		<title level="m">Symplectic Geometry and Analytical Mechanics. Reidel: Dordrecht</title>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Determination of camera location from 2-D to 3-D line and point correspondences</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">D</forename><surname>Faugeras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="28" to="37" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Theory and Practice of Recursive Identijication</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ljung</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>MIT</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">System Identijication: Theory for the User</title>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A computer algorithm for reconstructing a scene from two projections</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Longuet-Higgins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mental Processes: Studies in Cognitive Science</title>
		<imprint>
			<date type="published" when="1981">1981</date>
			<biblScope unit="volume">293</biblScope>
			<biblScope unit="page" from="133" to="135" />
		</imprint>
	</monogr>
	<note>Configurations that defeat the eight-point algorithm</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">An iterative image registration technique with an application to stereo vision</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th Int. Joint Con$ Art$ Intell</title>
		<meeting>7th Int. Joint Con$ Art$ Intell</meeting>
		<imprint>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Kalman filter-based algorithms for estimating depth from image sequences</title>
		<author>
			<persName><forename type="first">L</forename><surname>Matthies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory of Reconstruction from Image Motion</title>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Maybank</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1989">1989. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Relative positioning with uncalibrated cameras</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mohr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Geometric Invariance in Computer Vision</title>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A Mathematical Introduction to Robotic Manipulation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CRC</title>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Recursive multi-frame structure from motion incorporating motion error</title>
		<author>
			<persName><forename type="first">J</forename><surname>Oliensis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Inigo-Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. DARPA Image Understanding Workshop</title>
		<meeting>DARPA Image Understanding Workshop</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Algebraic Projective Geometry</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Semple</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Kneebone</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1952">1952</date>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">On geometric and algebraic aspects of 3-D affine and projective structure from perspective 2-D views</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shashua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MIT AI Lab., AI Memo 1405</title>
		<imprint>
			<date type="published" when="1993-03">Mar. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Observability/identifiability of rigid motion under perspective projection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 33rd IEEE Con$ Decision Contr</title>
		<meeting>33rd IEEE Con$ Decision Contr</meeting>
		<imprint>
			<date type="published" when="1994-12">Dec. 1994</date>
			<biblScope unit="page" from="3235" to="3240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Motion estimation on the essential manifold</title>
		<author>
			<persName><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Frezza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd Europ</title>
		<editor>
			<persName><forename type="first">Con</forename><forename type="middle">$</forename><surname>Comput</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J.-0</forename><surname>Vision</surname></persName>
		</editor>
		<editor>
			<persName><surname>Eklundh</surname></persName>
		</editor>
		<meeting>3rd Europ</meeting>
		<imprint>
			<biblScope unit="page" from="800" to="801" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Recursive estimation of camera motion from uncalibrated image sequences</title>
		<author>
			<persName><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st IEEE Int. Con$ Image Processing</title>
		<meeting>1st IEEE Int. Con$ Image essing<address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-11">Nov. 1994</date>
			<biblScope unit="page" from="111" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Structure-independent visual motion control on the essential manifold</title>
		<author>
			<persName><surname>__</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Con$ Computer Vision</title>
		<meeting>IEEE Int. Con$ Computer Vision<address><addrLine>Boston, MA; Capri, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-09">June 1995. Sept. 1994</date>
			<biblScope unit="page" from="869" to="876" />
		</imprint>
	</monogr>
	<note>Proc. IFAC Symp. Robot Contr</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Three dimensional transparent structure segmentation and multiple 3d motion estimation from monocular perspective image sequences</title>
		<author>
			<persName><surname>___</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Workshop Motion Nonrigid Articulated Objects</title>
		<meeting><address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-11">Nov. 1994</date>
			<biblScope unit="page" from="228" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Visual motion estimation from subspace constraints</title>
		<author>
			<persName><surname>__</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st IEEE Int. Con$ Image Processing</title>
		<meeting>1st IEEE Int. Con$ Image essing<address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-11">Nov. 1994</date>
			<biblScope unit="page" from="1" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Recursive motion and structure estimation with complete error characterization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Frezza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Picci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision Pattern Recognition<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993-06">June 1993</date>
			<biblScope unit="page">428433</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">System Identijication</title>
		<author>
			<persName><forename type="first">T</forename><surname>Soderstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stoica</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Spivak</surname></persName>
		</author>
		<title level="m">A Comprehensive Introduction to Differential Geometry</title>
		<imprint>
			<biblScope unit="page" from="1970" to="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Promising directions in active vision</title>
		<author>
			<persName><forename type="first">M</forename><surname>Swain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stricker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Univ. Chicago, Tech. Rep. T.R. CS</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">27</biblScope>
			<date type="published" when="1991-11">Nov. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Estimation of planar curves, surfaces and nonplanar space curves defined by implicit equations</title>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Taubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Visual Communic. Image Representation</title>
		<imprint>
			<date type="published" when="1991">1994. 1991</date>
		</imprint>
	</monogr>
	<note>IEEE Trans. Pattern Anal. Mach. Intell.</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Structure and motion from line segments in multiple views</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Yale Univ., Tech. Rep</title>
		<imprint>
			<biblScope unit="volume">9402</biblScope>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Shape and motion from image streams: A factorization method-3. Detection and tracking of point features</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MIT</title>
		<imprint>
			<date type="published" when="1987">Apr. 1991. 1987</date>
			<publisher>School of CS-CMU</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Shape and motion from image streams: a factorization method-2. Point features in 3d motion</title>
		<imprint>
			<date type="published" when="1991">1994. Jan. 1991</date>
			<publisher>School of CS-CMU</publisher>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="11" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Shape and motion from image streams: a factorization method-1. Planar motion</title>
		<imprint>
			<date type="published" when="1990-09">Sept. 1990</date>
			<publisher>School of CS-CMU</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Lie Groups, Lie Algebras and Their Representation</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Varadarajan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<publisher>New York Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">H</forename><surname>Helmholtz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1910">1910</date>
		</imprint>
	</monogr>
	<note>Treatise on Physiological Optics</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Motion and structure from two perspective views: Algorithms, error analysis and error estimation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">451476</biblScope>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Motion and structure from line correspondences: Closedform solution, uniqueness and optimization</title>
		<author>
			<persName><surname>__</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="318" to="336" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">3 0 Dynamic Scene Analysis</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Faugeras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Sciences</title>
		<imprint>
			<publisher>New York Springer-Verlag</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">He received the D.Ing. degree cum laude in electrical engineering from the University of Padova in 1992 and the M.S. degree from the California Institute of Technology, Pasadena, in 1993, both in electrical engineering. He is currently a Ph.D. candidate at the California Institute of Technology and has been a Ricercatore with the University of Udine, Italy, since 1996. His research interests include nonlinear geometric control and estimation theory applied to vision</title>
	</analytic>
	<monogr>
		<title level="m">TR 144O-INRIA</title>
		<imprint>
			<date type="published" when="1968">1991. 1968</date>
		</imprint>
	</monogr>
	<note>Estimation of displacement from two 3d frames obtained form stereo. He has worked in feature tracking, visual-based motion control, structure estimation, and segmentation</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
