<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CODA: Toward Automatically Identifying and Scheduling COflows in the DArk</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hong</forename><surname>Zhang</surname></persName>
							<email>hzhangan@cse.ust.hk</email>
							<affiliation key="aff0">
								<orgName type="laboratory">SING Group</orgName>
								<orgName type="institution">Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Li</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">SING Group</orgName>
								<orgName type="institution">Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bairen</forename><surname>Yi</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">SING Group</orgName>
								<orgName type="institution">Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
							<email>kaichen@cse.ust.hk</email>
						</author>
						<author>
							<persName><forename type="first">Mosharaf</forename><surname>Chowdhury</surname></persName>
							<email>mosharaf@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">SING Group</orgName>
								<orgName type="institution">Hong Kong University of Science and Technology</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Michigan</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yanhui</forename><surname>Geng</surname></persName>
							<email>geng.yanhui@huawei.com</email>
							<affiliation key="aff2">
								<address>
									<settlement>Huawei</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CODA: Toward Automatically Identifying and Scheduling COflows in the DArk</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D9A2A1699A1B264C301109649147308D</idno>
					<idno type="DOI">10.1145/2934872.2934880</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Coflow</term>
					<term>data-intensive applications</term>
					<term>datacenter networks</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Leveraging application-level requirements using coflows has recently been shown to improve application-level communication performance in data-parallel clusters. However, existing coflow-based solutions rely on modifying applications to extract coflows, making them inapplicable to many practical scenarios.</p><p>In this paper, we present CODA, a first attempt at automatically identifying and scheduling coflows without any application modifications. We employ an incremental clustering algorithm to perform fast, application-transparent coflow identification and complement it by proposing an error-tolerant coflow scheduler to mitigate occasional identification errors. Testbed experiments and large-scale simulations with production workloads show that CODA can identify coflows with over 90% accuracy, and its scheduler is robust to inaccuracies, enabling communication stages to complete 2.4⇥ (5.1⇥) faster on average (95-th percentile) compared to per-flow mechanisms. Overall, CODA's performance is comparable to that of solutions requiring application modifications.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A growing body of recent work <ref type="bibr" target="#b19">[21,</ref><ref type="bibr" target="#b21">23,</ref><ref type="bibr" target="#b22">24,</ref><ref type="bibr" target="#b28">30,</ref><ref type="bibr" target="#b36">38,</ref><ref type="bibr" target="#b66">68]</ref> has demonstrated that leveraging application-level information us-Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. ing coflows <ref type="bibr" target="#b20">[22]</ref> can significantly improve the communication performance of distributed data-parallel applications. <ref type="foot" target="#foot_0">1</ref>Unlike the traditional flow abstraction, a coflow captures a collection of flows between two groups of machines in successive computation stages, where the communication stage finishes only after all the flows have completed <ref type="bibr" target="#b21">[23,</ref><ref type="bibr" target="#b24">26]</ref>. A typical example of coflow is the shuffle between the mappers and the reducers in MapReduce <ref type="bibr" target="#b26">[28]</ref>. By taking a holistic, application-level view, coflows avoid stragglers and yield benefits in terms of scheduling <ref type="bibr" target="#b19">[21,</ref><ref type="bibr" target="#b21">23,</ref><ref type="bibr" target="#b22">24,</ref><ref type="bibr" target="#b28">30]</ref>, routing <ref type="bibr" target="#b66">[68]</ref>, and placement <ref type="bibr" target="#b36">[38]</ref>.</p><p>However, extracting these benefits in practice hinges on one major assumption: all distributed data-parallel applications in a shared cluster -be it a platform-as-a-service (PaaS) environment or a shared private cluster -have been modified to correctly use the same coflow API.</p><p>Unfortunately, enforcing this requirement is infeasible in many cases. As a first-hand exercise, we have attempted to update Apache Hadoop 2.7 <ref type="bibr" target="#b56">[58]</ref> and Apache Spark 1.6 <ref type="bibr" target="#b63">[65]</ref> to use Aalo's coflow API <ref type="bibr" target="#b22">[24]</ref> and faced multiple roadblocks in three broad categories ( §5): the need for intrusive refactoring, mismatch between blocking and non-blocking I/O APIs, and involvement of third-party communication libraries.</p><p>Given that users on a shared cluster run a wide variety of data analytics tools for SQL queries <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b13">15,</ref><ref type="bibr" target="#b39">41,</ref><ref type="bibr" target="#b61">63]</ref>, log analysis <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b26">28,</ref><ref type="bibr" target="#b63">65]</ref>, machine learning <ref type="bibr" target="#b31">[33,</ref><ref type="bibr" target="#b41">43,</ref><ref type="bibr" target="#b46">48]</ref>, graph processing <ref type="bibr" target="#b32">[34,</ref><ref type="bibr" target="#b42">44,</ref><ref type="bibr" target="#b44">46]</ref>, approximation queries <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b10">12]</ref>, stream processing <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">11,</ref><ref type="bibr" target="#b11">13,</ref><ref type="bibr" target="#b48">50,</ref><ref type="bibr" target="#b64">66]</ref>, or interactive analytics <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b63">65]</ref>, updating one application at a time is impractical. To make things worse, most coflow-based solutions propose their own API <ref type="bibr" target="#b21">[23,</ref><ref type="bibr" target="#b22">24,</ref><ref type="bibr" target="#b28">30]</ref>. Porting applications back and forth between environments and keeping them up-to-date with evolving libraries is error-prone and infeasible <ref type="bibr" target="#b52">[54,</ref><ref type="bibr" target="#b55">57]</ref>.</p><p>Therefore, we ponder a fundemantal question: can we automatically identify and schedule coflows without manually updating any data-parallel applications? It translates to three key design goals:</p><p>• Application-Transparent Coflow Identification We must be able to identify coflows without modifying applications.</p><p>• Error-Tolerant Coflow Scheduling Coflow identification cannot guarantee 100% accuracy. The coflow scheduler must be robust to some identification errors.</p><p>• Readily Deployable The solution must be compatible with existing technologies in datacenter environments.</p><p>In this paper, we provide a cautiously optimistic answer via CODA. At the heart of CODA is an application-transparent coflow identification mechanism and an error-tolerant coflow scheduling design.</p><p>For coflow identification, we apply machine learning techniques over multi-level attributes without manually modifying any applications ( §3). Besides explicit attributes directly retrieved from flows (e.g., arrival times and packet headers), we further explore implicit attributes that reflect communication patterns and data-parallel framework designs. As to the identification algorithm, we find that traditional traffic classification methods <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b17">19,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b38">40,</ref><ref type="bibr" target="#b45">47,</ref><ref type="bibr" target="#b47">49,</ref><ref type="bibr" target="#b49">51,</ref><ref type="bibr" target="#b53">55,</ref><ref type="bibr" target="#b65">67]</ref> do not directly apply in our case. This is because coflows capture a one-off, mutual relationship among some flows that cannot be pre-labeled and need timely identification. To this end, we first identify DBSCAN <ref type="bibr" target="#b29">[31]</ref> as the base algorithm that fits our requirements, and then we develop an incremental version of Rough-DBSCAN <ref type="bibr" target="#b57">[59]</ref> that provides fast identification with high accuracy.</p><p>Despite its high accuracy, CODA's identifier is not perfect, and identification errors are unavoidable in practice. Such errors, if present, may greatly affect the performance of existing coflow schedulers. Consider Figure <ref type="figure">1</ref> as an example: a misclassified flow can significantly affect the coflow completion time (CCT) of its parent coflow.</p><p>The key to CODA's effectiveness lies in developing a robust scheduler that can tolerate such errors ( §4). For errortolerant coflow scheduling, we start by studying how identification errors would influence scheduling results. Our analysis reveals that stragglers significantly affect CCT, and recent coflow schedulers <ref type="bibr" target="#b21">[23,</ref><ref type="bibr" target="#b22">24]</ref> suffer performance degradation in the presence of errors. Thus, CODA employs late binding to delay the assignment of flows to particular coflows until they must be scheduled to minimize the impact of stragglers. Furthermore, we find that intra-coflow prioritization <ref type="bibr" target="#b12">[14,</ref><ref type="bibr" target="#b14">16,</ref><ref type="bibr" target="#b35">37,</ref><ref type="bibr" target="#b60">62]</ref> can play a crucial role in the presence of identification errors. Hence, unlike existing coflow schedulers <ref type="bibr" target="#b19">[21,</ref><ref type="bibr" target="#b21">23,</ref><ref type="bibr" target="#b22">24,</ref><ref type="bibr" target="#b28">30]</ref>, CODA combines per-flow (intra-coflow) prioritization with inter-coflow scheduling.</p><p>We have implemented a CODA prototype ( §5) and built a small-scale testbed with 40 servers to evaluate its performance ( §6.2). Our implementation experience shows that CODA can be readily deployed in today's commodity datacenters with no modifications to switch hardware or application software. By replaying a coflow benchmark based on Facebook traces <ref type="bibr" target="#b4">[5]</ref>, we show that CODA achieves over 95% accuracy in identification, improves the average and 95-th percentile CCT by 2.4⇥ and 5.1⇥ compared to per-flow fairness, and performs almost as well as Aalo <ref type="bibr" target="#b22">[24]</ref>, which requires correct, manual coflow identification. Moreover, CODA can scale up to 40,000 agents with small performance loss.</p><p>We further perform large-scale trace-driven simulations to</p><formula xml:id="formula_0">C 2 C 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Misidentified flow</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Time</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C 2 C 1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Misidentified flow</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Identification Scheduling</head><p>Figure <ref type="figure">1</ref>: Motivating example: a coflow scheduler (e.g., Aalo <ref type="bibr" target="#b22">[24]</ref>) tends to optimize the CCT by prioritizing the small coflow C1 over the large coflow C2. However, a misidentified flow of C1 will be scheduled together with C2, significantly affecting the CCT of its parent coflow C1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CODA Master</head><p>Error-  inspect CODA ( §6.3 and §6.4). CODA's identifier achieves over 90% accuracy for Spark, Hadoop, and mixed workloads, and provides significant speedup over vanilla DBSCAN. In terms of error-tolerant scheduling, we show that CODA can effectively tolerate misidentifications over a wide range of scenarios. For example, in a challenging case with less than 60% identification accuracy, CODA's error-tolerant design brings up to 1.16⇥ speedup in CCT, reducing the impact of errors by 40%. Overall, CODA achieves the performance comparable to that of prior solutions using manual annotations in many cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">CODA Overview</head><p>The goal of CODA is to design an identifier-scheduler joint solution that works "in the dark", relying only on externally observable coflow attributes that can be collected from the network without modifying applications/frameworks.</p><p>Figure <ref type="figure" target="#fig_1">2</ref> presents an overview of CODA system architecture. At a high level, it contains a central CODA master that performs the primary role of coflow identification and scheduling every 4 interval (e.g., 10 100ms), as well as a CODA agent on each end host that collects aggregated flow-level information to feed the master and enforces scheduling decisions made by the master. Information Gathering and Pruning Each CODA agent monitors flow-level attributes and IP/port information of all flows in the corresponding host and periodically forwards them to the master. Before sending out the records, each agent prunes the records of all finished flows, non-TCP flows <ref type="foot" target="#foot_1">2</ref> and flows with sent size less than a threshold (e.g., 100KB). This reduces identification time and avoids extra traffic (e.g., control flows) not useful to the identification process. Application-Transparent Coflow Identification Given periodic flow records, CODA master invokes a coflow identifier to identify coflow relationships using machine learning ( §3). To achieve high accuracy, the identifier explores useful attributes on multiple levels and learns an appropriate distance metric to reflect coflow relations. For timely identification, it trades off a small amount of accuracy for significantly higher speed and relies on the coflow scheduler to amend the errors. Error-tolerant Coflow Scheduling Next, the master runs a coflow scheduler on the identified coflows. The scheduler tries to minimize coflow completion times (CCT) in the presence of possible identification errors ( §4). Specifically, the error-tolerant design integrates the following two design principles. First, we observe that stragglers may heavily affect CCTs. We apply late binding to the identification resultsi.e., delaying the assignment of a flow to a particular coflow until we must schedule -to decrease the number of stragglers. Second, we notice that intra-coflow scheduling affects CCT under identification errors, and we introduce intra-coflow prioritization to reduce the impact of errors. Finally, the master sends out updated schedules to relevant end hosts to complete the identification-scheduling cycle.</p><p>CODA's centralized architecture is inspired by the success of many large-scale infrastructure deployments such as <ref type="bibr" target="#b26">[28,</ref><ref type="bibr" target="#b30">32,</ref><ref type="bibr" target="#b33">35,</ref><ref type="bibr" target="#b63">65</ref>] that employ a central controller at the scale of tens to hundreds of thousands of machines. Because CODA master must serve a large number of CODA agents, it must be scalable and fault-tolerant. Scalability The faster CODA agents can coordinate, the better CODA performs. The number of messages is linear with the number of agents and independent of the number of flows or coflows, and it is not a bottleneck in our testbed. Our evaluation suggests that CODA can scale up to 40,000 machines with small performance loss ( §6.2). Because many coflows are tiny <ref type="bibr" target="#b21">[23]</ref> and can effectively be scheduled through local decisions <ref type="bibr" target="#b22">[24]</ref>, they do not face coordination overheads. Fault Tolerance CODA fails silently from an application's perspective, as it is application-transparent by design. CODA handles master/ agent failures by restarting them. A restarted CODA master can rebuild its state from the next wave of updates from the agents. Restarted CODA agents remain inconsistent only until the next schedule arrives from the master.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Coflow Identification</head><p>CODA identifier aims to meet three practical objectives:</p><p>• Transparency: It should not require any modification to applications.</p><p>• Accuracy: It should identify accurate coflow relationships to enable correct scheduling.</p><p>• Speed: It should be fast enough for timely scheduling.</p><p>To achieve these goals, CODA identifier relies on the following three steps: 1. Attribute Exploration A flow can be characterized by a tuple of attributes, and searching for useful attributes is a key first step for coflow identification. Instead of taking a black-box approach, CODA explores explicit and implicit attributes and heuristics on multiple levels ( §3.1). 2. Distance Calculation Given the attributes, CODA calculates distances between flows to capture coflow relationships -flows belonging to the same coflow will have smaller distances. The key here is having a good metric to reflect the importance of each attribute. CODA employs distance metric learning <ref type="bibr" target="#b62">[64]</ref> to learn such a metric ( §3.2). 3. Identifying Coflows via Clustering Finally, CODA employs unsupervised clustering to identify coflow relationships. We use unsupervised learning because coflows cannot be labeled by predefined categories -mutual relationships among flows captured by a particular coflow do not recur once its parent job is over. CODA leverages an incremental Rough-DBSCAN algorithm to achieve fast yet accurate coflow identification by clustering flows with small distances ( §3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Multi-Level Attributes</head><p>We first explore a set of flow, community, and application level attributes that might be useful in coflow identification.</p><p>We prune this set in §3. IPs and ports have application-specific meanings, which we exploit later when considering application structures and communication patterns. We ignore flow size and duration as they cannot be acquired until a flow finishes; at that time, they would be useless. Community-Level Attributes Recent studies on datacenter traffic show that the traffic matrix is sparse and most bytes stay within a stable set of nodes <ref type="bibr" target="#b16">[18,</ref><ref type="bibr" target="#b54">56]</ref>. This suggests a community attribute; i.e., the datacenter can be separated into service groups where intra-group communication is frequent while inter-group communication is rare. With this, we can have a useful heuristic: two flows belonging to different communities are less likely to be inside one coflow. We define the community distance D com (f i , f j ) to be 0 if flow f i , f j are in the same community, and 1 otherwise. To calculate D com , we develop a community detection module, which uses spectral clustering <ref type="bibr" target="#b58">[60]</ref> to segment machines into communities while minimizing inter-community traffic.</p><p>Community-level attributes can be very helpful in differentiating coflows across services that show stable and isolated patterns, e.g., service groups within private datacenters or tenants in public clouds. However, it may not work under uniformly distributed traffic across the entire cluster <ref type="bibr" target="#b54">[56]</ref>.</p><p>Application-Level Attributes We seek more useful attributes by taking advantage of application designs. We investigate two use cases -Spark and Hadoop <ref type="foot" target="#foot_2">3</ref> -to observe their data transfer design by delving into the source code.</p><p>Port assignment in Spark: The port assignment rule in Spark reveals that data transmission to the same executor <ref type="bibr" target="#b7">[8]</ref> will have the same destination IP and port (the port of the reducer's ConnectionManager). If we denote all flows to the same IP/port as a flow aggregation, then all flows within a flow aggregation are likely to be within a coflow. Hence, we define port distance D prt (f i , f j ) for two flows f i and f j to be 0 if they are in one flow aggregation, and 1 otherwise.</p><p>Port assignment in Hadoop: Unlike Spark, shuffle traffic from different Hadoop jobs are likely to share the same source port of ShuffleHandler (13562 by default) and random destination ports. Consequently, port assignments do not provide distinctive information for Hadoop. OS-level Attributes OS-level knowledge can also be helpful for coflow identification. For example, for each flow one can trace the corresponding process ID (PID) of the mapper, and flows sharing the same PID are likely to be in one coflow. Currently we have not included OS-level attributes due to their unavailability in public clouds. <ref type="foot" target="#foot_3">4</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Distance Calculation</head><p>Given multiple attributes, a naive distance metric between two flows f i and f j can be defined as the Euclidean distance between them. However, equally weighing all attributes is not effective because different attributes may contribute differently -using irrelevant or redundant attributes may degrade identification accuracy.</p><p>Thus we need a good distance metric that can effectively reflect coflow relationships -one that assigns smaller distances between flows within the same coflow and larger distances between flows belonging to different coflows. Problem Formulation Consider a flow set {f } and a dis-</p><formula xml:id="formula_1">tance metric d(f i , f j ) = ||f i f j || A = p (f i f j ) T A(f i f j ). Suppose (f i , f j ) 2 S if f</formula><p>i and f j belong to the same coflow, and (f i , f j ) 2 D otherwise. Here, A is the distance matrix reflecting the weight of different attributes, and setting A = I gives Euclidean distance. We desire a metric where any pairs of flows in S have small distances, while any pairs of flows in D have distances larger than some threshold. This leads to the following optimization problem similar to <ref type="bibr" target="#b62">[64]</ref>:</p><formula xml:id="formula_2">min A X (f i ,f j )2S ||fi fj|| 2 A s. t. X (f i ,f j )2D ||fi fj||A 1, A ⌫ 0 (1)</formula><p>We simplify the problem by restricting A to be diagonal and solve it using Newton-Raphson method <ref type="bibr" target="#b62">[64]</ref>. Learning Results We divide our testbed into two equal-sized communities with 10 servers each and run some typical benchmarks (e.g., Wikipedia-PageRank, WordCount) in Spark and Hadoop. We collect the trace, and the ground-truth coflow information is annotated by applications for metric learning. We use the attributes in §3.1, and run the above distance learning algorithm to see how they contribute to coflow identification. The resulting diagonal elements of matrices for Spark (A s ) and Hadoop (A h ) traffic are:</p><formula xml:id="formula_3">As =  S time M size V size M int V int</formula><p>Dcom Dprt 3.825 0.000 0.000 0.000 0.000 5.431 0.217</p><formula xml:id="formula_4">A h =  S time M size V size M int V int</formula><p>Dcom Dprt 3.472 0.000 0.000 0.000 0.000 3.207 0.000</p><p>We observe three high-level characteristics: 1. Flow-level attributes other than the flow start time are not useful. This is because coflows may demonstrate similar packet-level characteristics regardless of their parent jobs; 2. Community-level attributes are distinctive; and 3. While port information is not useful for Hadoop as expected, it turns out to be of little use (with a small weight of only 0.217) for Spark as well, which is unexpected. One possible reason is that although flows within the same flow aggregation are likely to belong to one coflow in Spark, flows in one coflow may belong to different flow aggregations (and thus have D prt = 1). This makes D prt less distinctive compared to S time and D com . We note that our procedure of identifying important attributes is critical for CODA's identification, especially under generic frameworks. Simulation results show that useless attributes greatly hamper identification accuracy, and distance metric learning brings significant improvement ( §6.3). In our clustering algorithm below, we prune the useless attributes with near zero weights to simplify the distance calculation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Identifying Coflows via Clustering</head><p>CODA leverages a fast and accurate unsupervised clustering algorithm to identify coflows. We choose DBSCAN <ref type="bibr" target="#b29">[31]</ref> as the basis of our solution for two primary reasons. First, because the number of coflows changes dynamically over time, it is hard to timely and accurately estimate the number of clusters a priori. Unlike k-means <ref type="bibr" target="#b43">[45]</ref> and many alternatives, DBSCAN can automatically determine the number of clusters given a radius parameter ✏. Second, a typical workload consists of a mix of small coflows (or single flows) with large coflow groups. Such imbalance prevents clustering algorithms that try to balance the size of clusters -e.g., spectral clustering <ref type="bibr" target="#b58">[60]</ref> -from accurately identifying the singletons. DBCSAN does not impose such preference.</p><p>However, DBSCAN has one major drawback -its O(n 2 ) worst-case time complexity, where n is the number of flows. We address this drawback in two steps. First, we consider Rough-DBSCAN <ref type="bibr" target="#b57">[59]</ref> (R-DBSCAN) -a variant of DBSCAN -instead, which trades off small accuracy for significantly faster speed. Second, we further improve R-DBSCAN to perform incremental classification, accounting for dynamic flow arrival/departure. R-DBSCAN for Clustering The idea of R-DBSCAN is sim- Find its leader l 13: Run DBSCAN (L, ✏, 1) and get C 0 (cluster of leaders) 20:</p><formula xml:id="formula_5">Algorithm 1 Incremental R-DBSCAN</formula><formula xml:id="formula_6">if f = l then 14: Delete l from L if l.f ollowers = {l} . A</formula><p>Obtain C by replacing each leader by its followers 21:</p><p>return cluster of flows C 22: end procedure ple -to perform DBSCAN only on a selected group of representative nodes (i.e., leaders). More specifically, a leader is a representative of flows within a distance range ⌧ (i.e., followers of the leader). R-DBSCAN works in three steps: 1. Scan the dataset to derive leaders and their followers; 2. Run an algorithm similar to DBSCAN (with the same radius ✏ as in DBSCAN), but use only the set of leaders in deriving the clusters; 3. Derive the cluster of flows from the identified cluster of leaders, based on leader-follower relationships. The complexity of R-DBSCAN is O(nk + k 2 ), where k is the number of leaders. In many cases, k is much smaller than n, and it is proved that k can be further bounded by a constant given the range ⌧ <ref type="bibr" target="#b57">[59]</ref>. More importantly, R-DBSCAN introduces very small accuracy loss compared to DBSCAN. Incremental R-DBSCAN Recall that CODA master performs periodic identification and scheduling. When the set of active flows barely changes between intervals, a complete reclustering over all flows is unnecessary. To this end, we develop an incremental R-DBSCAN (Algorithm 1) for further speedup, by considering dynamic flow arrival/departure. In each interval, it first updates the leader-follower relation based on last round information and flow dynamics (lines 1-18), and then applies R-DBSCAN on the updated leader-follower relations (lines <ref type="bibr" target="#b17">[19]</ref><ref type="bibr" target="#b18">[20]</ref><ref type="bibr" target="#b19">[21]</ref><ref type="bibr" target="#b20">[22]</ref>. The incremental R-DBSCAN has a complexity of only O(mk + k 2 ), where m is the number of newly arrived/left flows. Since most intervals do not experience a big change in active flows, the incremental design can effectively improve the identification time ( §6.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Discussion and Caveat</head><p>Our study in this paper currently centers around Spark and Hadoop -two of the most popular frameworks used in pro-     duction datacenters today. While different frameworks may have different sets of useful attributes, we note that our approach toward attribute exploration, distance metric learning, and coflow identification via clustering is generally applicable. In future work, we are particularly interested in a comprehensive study on more attributes across more frameworks, their effectiveness and commonality. Another observation is that, for a framework, the optimal weights of attributes may vary depending on workloads. However, such variations do not significantly affect identification accuracy as long as they clearly separate the distinctive attributes from the useless ones. As a result, to apply CODA to different frameworks and dynamic workloads, one possible way is to learn the weights of each framework offline and fix the setting for online identification. For example, we applied the weights learned above with our testbed workload ( §3.2) to the Facebook workload ( §6.1), achieving over 90% identification accuracy in many cases ( §6.3). However, evaluating the robustness of this method and exploring the optimal weight settings of CODA under a variety of real-world workloads is another important future work beyond the scope of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Error-Tolerant Scheduling</head><p>Despite its accuracy, the proposed coflow identification procedure ( §3) can sometimes misidentify flows from one coflow into another. Unfortunately, such mistakes can have a drastic impact on existing schedulers' performance. In this section, we categorize different types of errors and their impacts on performance ( §4.1) and design an error-tolerant coflow scheduler that is robust to misidentifications ( §4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Identification Errors and Their Impacts</head><p>To assess how identification errors affect scheduling performance, we first divide misidentified flows into two categories based on when they are scheduled: 1. Pioneers: Flows that are misidentified into a coflow that is scheduled earlier than the parent coflow; 2. Stragglers: Flows that are misidentified into a coflow that is scheduled later than the parent coflow. These two types of errors affect the average CCT differently. To illustrate this, we consider a simple scenario in Figure <ref type="figure" target="#fig_3">3</ref>, where two identical coflows (C 1 and C 2 ) sharing the same bottleneck link arrive at the same time, and each contains 10 identical flows. We further assume that the scheduler assigns C 1 with higher priority, and each coflow takes one time unit to finish. When there is no identifications error, this schedule leads to an optimal CCT of 1.5 time units. However, in Figure <ref type="figure" target="#fig_6">3a</ref>, a pioneer increases both the CCT of C 1 (1.1⇥) and the average CCT (1.03⇥). A straggler hurts even more -in Figure <ref type="figure" target="#fig_6">3b</ref>, it doubles the CCT of C 1 and increases the average CCT by 1.33⇥.</p><p>Observation 1 In the presence of misidentifications, stragglers are likely to more negatively affect the average CCT than pioneers. ⇤</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Impacts of Identification Errors</head><p>Existing coflow schedulers assume prior coflow knowledge <ref type="bibr" target="#b19">[21,</ref><ref type="bibr" target="#b21">23,</ref><ref type="bibr" target="#b22">24,</ref><ref type="bibr" target="#b28">30]</ref> for efficient scheduling. However, they can be highly inefficient in the presence of identification errors.</p><p>Clairvoyant Schedulers Consider Minimum-Allocation-for-Desired-Duration (MADD), the optimal algorithm used in Varys <ref type="bibr" target="#b21">[23]</ref> for intra-coflow scheduling when flow sizes are known a priori. MADD slows down all the flows in a coflow to match the completion time of the flow that will take the longest to finish. Because all flows finish together using MADD, a misidentified flow (especially for stragglers) can significantly impact the CCT (e.g., in Figure <ref type="figure" target="#fig_6">3b</ref>). Non-Clairvoyant Schedulers Unlike Varys, Aalo <ref type="bibr" target="#b22">[24]</ref> uses Discretized Coflow-Aware Least-Attained Service (D-CLAS) -that divides coflows into multiple priority queues and schedules in the FIFO order within each queue -to minimize average CCT without any prior knowledge of flow sizes. However, Aalo can perform even worse in the presence of identification errors. This is because a misidentified flow can drop to a low-priority queue together with another large coflow and can become a "super" straggler. Figure <ref type="figure">4</ref> illustrates such an example. This is not a corner case. Because only 17% coflows create 99% traffic <ref type="bibr" target="#b21">[23]</ref>, flows from the 83% small coflows can easily be misidentified into the larger ones and suffer performance loss. Possible Remedies In both sets of solutions, intra-coflow scheduling -MADD or per-flow fairness -elongates flows until the end of the entire coflow. However, if we prioritize flows <ref type="bibr" target="#b12">[14,</ref><ref type="bibr" target="#b14">16,</ref><ref type="bibr" target="#b35">37,</ref><ref type="bibr" target="#b60">62]</ref> within each coflow, a misidentified flow might have a higher chance of finishing earlier. This can  decrease the impact of identification errors. For example, in Figure <ref type="figure" target="#fig_6">3b</ref>, the expected average CCT would have been 1.75 time units <ref type="foot" target="#foot_4">5</ref> instead of 2 if we performed per-flow prioritization within C 1 .</p><p>Observation 2 Intra-coflow prioritization can matter in the presence of identification errors. ⇤</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Error-Tolerant Coflow Scheduling</head><p>Based on the observations in §4.1, in this section, we present the key principles behind designing an error-tolerant coflow scheduler and discuss its components. Our proposed scheduler extends the general structure of a non-clairvoyant coflow scheduler described in Aalo <ref type="bibr" target="#b22">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Design Principles</head><p>We rely on two key design principles to mitigate the impacts of stragglers and intra-coflow scheduling in the presence of identification errors:</p><p>1. Late binding errs on the side of caution to reduce the number of stragglers; 2. Intra-coflow prioritization leverages per-flow prioritization <ref type="bibr" target="#b12">[14,</ref><ref type="bibr" target="#b14">16,</ref><ref type="bibr" target="#b35">37,</ref><ref type="bibr" target="#b60">62]</ref> in the context of coflows.</p><p>Design Principle 1: Late Binding Observation 1 indicates that avoiding stragglers is key to error-tolerant scheduling. To this end, we take a late binding approach toward the coflow relationships identified in the clustering process. For example, consider a flow that can potentially belong to either coflow C 1 or coflow C 2 -i.e., it lies on the boundary between the two during clustering (Figure <ref type="figure" target="#fig_9">5</ref>). Instead of arbitrarily assigning it to either C 1 or C 2 , we delay the decision and consider it to be in both C 1 and C 2 for the time being. Only during scheduling, we assign it to the higher priority coflow in C 1 and C 2 . Consequently, this flow does not become a straggler to its parent coflow, no matter whether it belongs to C 1 or C 2 .</p><p>There can be two outcomes from our decision: (i) if the original classification is correct, we introduce one pioneer in the worst case; (ii) if the original classification is wrong, we effectively prevent this flow from becoming a straggler. Essentially, we try to reduce the number of stragglers at the risk of increasing the number of pioneers. To stop all flows from becoming pioneers, we restrict late binding only to flows that straddle classification boundaries. For example, in Figure <ref type="figure">4</ref>, instead of creating stragglers for C 1 , we would instead cause pioneers of C 2 that have lower impact on the average CCT (Figure <ref type="figure" target="#fig_10">6a</ref>). Our evaluation ( §6.4) suggests that this principle contributes to more than 10% CCT improvements in the presence of identification errors, reducing the impact of errors by more than 30%. Design Principle 2: Intra-Coflow Prioritization Although late binding helps, some flows may still be misidentified. An even more troublesome case is when C 1 and C 2 are clustered as one coflow. To reduce the impact of errors in such cases, we leverage Observation 2, which suggests that intracoflow prioritization can be more effective in error-tolerant inter-coflow scheduling than in the absence of errors.</p><formula xml:id="formula_7">… Q K Q 2 Q 1 FIFO FIFO FIFO C 2 's pioneer(s) with C 1 … Q K Q 2 Q 1 FIFO FIFO FIFO C 1 's leftover straggler(s) with C 2 C 2 's pioneer(s) with C 1 (a) Late binding Q K Q 2 Q 1 FIFO FIFO FIFO s pioneer(s) with C 1 … Q K Q 2 Q 1 FIFO FIFO FIFO C 1 's leftover straggler(s) with C 2 C 2 's pioneer(s) with C 1 (b) Intra-coflow prioritization</formula><p>To this end, we use per-flow prioritization based on bytes sent (similar to <ref type="bibr" target="#b14">[16]</ref>) within each identified coflow without any prior knowledge. This is especially effective for flows from small coflows that become stragglers with large coflows -the most likely case given the prevalence of small coflows <ref type="bibr" target="#b21">[23]</ref>. For example, instead of the straggler of C 1 taking the same amount of time as longer flows in C 2 (Figure <ref type="figure">4</ref>), it will finish much earlier due to its small size (Figure <ref type="figure" target="#fig_10">6b</ref>). This scheme also takes effect in the reverse scenario -i.e., when a flow from the larger coflow C 2 becomes a pioneer with smaller coflow C 1 . By preferring smaller flows, C 1 's flows are likely to finish earlier than the pioneer from C 2 . Evaluation in §6.4 suggests that this principle brings up to 30% speedup for small coflows under low identification accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">CODA Scheduler</head><p>Putting everything together, Algorithm 2 describes CODA's error-tolerant scheduler, which has the following three components working cooperatively to minimize the impact of stragglers and pioneers during identification as well as to perform intra-and inter-coflow scheduling. 1. Late Binding In COFLOWEXTENSION(•), for each identified coflow C, we create a corresponding extended coflow C ⇤ by extending its boundary by a diameter d (line 4). Meaning, C ⇤ further includes all flows whose distances to C are smaller than d. 6 Note that a flow might belong 6 The distance between a flow f and a coflow group C is defined as the Algorithm 2 CODA's Error-Tolerant Scheduler C ⇤ = ;</p><p>. Set of extended coflows to be returned end for 24: end procedure</p><formula xml:id="formula_8">25: procedure CODASCHEDULER(C, Q C , Q F , d) 26: C ⇤ = CoflowExtension(C, d) 27:</formula><p>InterCoflow(C ⇤ , Q C ) 28: end procedure to two or more extended coflows simultaneously after this step. Later, the flow belonging to multiple coflows will be bound into the coflow with the highest priority when it is scheduled for the first time (line 20).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Inter-Coflow Prioritization</head><p>In INTERCOFLOW(•), we adopt D-CLAS <ref type="bibr" target="#b22">[24]</ref> to prioritize across these extended coflows. Basically, we dynamically place coflows into different coflow queues of Q C , and among the queues we enforce prioritization (line 10). Within each queue, we use FIFO among coflows (line 11) so that a coflow will proceed until it reaches queue threshold or completes. Using FIFO minimizes interleaving between coflows in the same queue which minimizes CCTs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Intra-Coflow Prioritization In INTRACOFLOW(•), we ap-</head><p>ply smallest-first heuristic <ref type="bibr" target="#b14">[16]</ref> to prioritize flows within each coflow. For this purpose, we implement multi-level feedback queue scheduling (MLFQ) among flow queues of Q F with exponentially increasing thresholds. Such scheme prioritizes short flows over larger ones with no prior knowledge of flow sizes <ref type="bibr" target="#b14">[16]</ref>. Flows within each flow queue use max-min fairness (line 19). tween stragglers and pioneers. The optimal value of d in terms of average CCT is closely related to the choice of radius ✏ in identification, and it varies under different traffic patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Choice of</head><p>There is no doubt that an extreme value of d (e.g., infinity) will lead to poor CCT. However, as mentioned earlier ( §4.1), the impact of stragglers is much bigger than that of pioneers, making late binding beneficial under a wide range of d ( §6.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Implementation</head><p>In this section, we discuss the difficulties we have faced implementing an existing coflow API in Hadoop 2.7 &amp; Spark 1.6, and describe the implementation of CODA prototype.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Implementing Coflow API</head><p>In order to validate CODA, we implemented Aalo's coflow API in Hadoop 2.7 and Spark 1.6 to collect ground truth coflow information. We faced several challenges, including intrusive refactoring of framework code, interactions with thirdparty libraries to collect coflow information, and Java bytecode instrumentation to support non-blocking I/O APIs.</p><p>Coflow Information Collection Modern applications are built on top of high-level abstractions such as Remote Procedure Call (RPC) or message passing, rather than directly using low-level BSD socket APIs or equivalent coflow primitives. As a result, matching the high-level coflow information with the low-level flow information requires refactoring across multiple abstraction layers and third-party libraries.</p><p>In our implementation of collecting coflows in Hadoop, which implements its own RPC submodule, we: (i) changed the message formats of RPC requests and responses to embed coflow information; (ii) modified the networking library to associate individual TCP connections to the coflow information in the RPC messages; and (iii) added an extra parsing step to look up coflow information in binary messages, since RPC messages are often serialized into byte stream before being passed into the networking level.</p><p>To make things worse, there is no universal interface for messaging or RPC. For example, unlike Hadoop, Spark uses third-party libraries: Akka <ref type="bibr" target="#b0">[1]</ref> and Netty <ref type="bibr" target="#b5">[6]</ref>. Hence, collecting coflow information in Spark almost doubled our effort. Supporting Non-blocking I/O Current coflow implementations <ref type="bibr" target="#b21">[23,</ref><ref type="bibr" target="#b22">24]</ref> emulate blocking behavior in the user space, effectively forcing threads sending unscheduled flows to sleep. As a result, each CPU thread can send at most one flow at any time, which does not scale. To let each thread serve multiple I/O operations, the common practice is to employ I/O multiplexing primitives provided by the OS (e.g., "select" and "poll" in POSIX, and "IOCP" in Windows). Both Hadoop and Spark uses "java.nio" for low-level non-blocking I/O. Since many popular frameworks (including Hadoop and Spark) are compiled against JVM, we seek an implementation that can support "java.nio" as well as a variety of third party libraries on JVM. To this end, we employed Java bytecode instrumentation -partially inspired by Trickle [10]to dynamically change the runtime behavior of these applications, collect coflow information, and intercept I/O operations based on scheduling results. Similar to the dynamic linker in Trickle, during the JVM boot, our instrumentation agent is pre-loaded. Upon the first I/O operation, the agent detects the loading of the original bytecode and modifies it to record job IDs in Hadoop and Spark shuffles at runtime, so that coflow information can be collected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">CODA Prototype</head><p>Our prototype implements the master-slave architecture shown in Figure <ref type="figure" target="#fig_1">2</ref>. The error-tolerant scheduler runs in the master with the information collected from CODA agents. The decisions of the master are enforced by the agents. CODA agent thus has the following two main functions: collection (of flow information) and enforcement (of scheduling decisions).</p><p>Flow information collection can be done with a kernel module <ref type="bibr" target="#b14">[16]</ref>, which does not require any knowledge of how the application is constructed, complying with our goal of application transparency. In prototype implementation, we build upon our coflow API integration, and reuse the same technique (bytecode instrumentation). Instead of job ID, we collect the information for identification: source and destination IPs and ports, as well as the start time of flow.</p><p>To enforce the scheduling decisions in each agent, we leverage Hierarchical Token Bucket (HTB) in tc for rate limiting. More specifically, we use the two-level HTB: the leaf nodes enforce per-flow rates and the root node classifies outgoing packets to their corresponding leaf nodes. Implementation Overhead of CODA Agent To measure the CPU overheads of CODA agents, we saturated the NIC of a Dell PowerEdge R320 server with 8GB of memory and a quad-core Intel E5-1410 2.8GHz CPU with more than 100 flows. The extra CPU overhead introduced is around 1% compared with the case where CODA agent is not used. The throughput remained the same in both cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation</head><p>Our evaluation seeks to answer the following 3 questions: How does CODA Perform in Practice? Testbed experiments ( §6.2) with realistic workloads show that CODA achieves over 95% accuracy in identification, improves the average and 95-th percentile CCT by 2.4⇥ and 5.1⇥ compared to per-flow fair sharing, and performs almost as well as Aalo with prior coflow knowledge. Furthermore, CODA can scale up to 40,000 agents with small performance loss. How Effective is CODA's Identification? Large-scale tracedriven simulations show that CODA achieves over 90% accuracy under normal production workloads, and degrades to around 60% under contrived challenging workloads. Furthermore, CODA's distance metric learning ( §3.2) is critical, contributing 40% improvement on identification accuracy; CODA's identification speedup design ( §3.3) is effective, providing 600⇥ and 5⇥ speedup over DBSCAN and R-DBSCAN respectively with negligible accuracy loss ( §6.3). How Effective is CODA's Error-Tolerant Scheduling? Under normal workloads with over 90% identification accuracy, CODA effectively tolerates the errors and achieves comparable CCT to Aalo (with prior coflow information), while  outperforming per-flow fair sharing by 2.7⇥. Under challenging scenarios, CODA degrades gradually from 1.3⇥ to 1.8⇥ compared to Aalo when accuracy decreases from 85% to 56%, but still maintaining over 1.5⇥ better CCT over perflow fair sharing. Moreover, CODA's error-tolerant design brings up to 1.16⇥ speedup in CCT, reducing the impact of errors by 40%. Additionally, both late binding and intracoflow prioritization are indispensable to CODA-the former brings 10% overall CCT improvement, while the latter one brings 30% improvement on CCT of small coflows ( §6.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Evaluation Settings</head><p>Testbed We built a testbed that consists of 40 servers connected to a Pronto 3295 48-port Gigabit Ethernet switch. Each server is a Dell PowerEdge R320 with a 4-core Intel E5-1410 2.8GHz CPU, 8G memory, a 500GB hard disk, and a Broadcom BCM5719 NetXtreme Gigabit Ethernet NIC. Each server runs Debian 8.2-64bit with Linux 3.16.0.4 kernel. We adopted the same compute engine used in both Varys <ref type="bibr" target="#b21">[23]</ref> and Aalo <ref type="bibr" target="#b22">[24]</ref>. We set coordination interval 4 = 100ms, and set ✏ = 100 and d = 150 as default.</p><p>Simulator For large-scale simulations, we use a trace-driven flow-level simulator that performs a detailed task-level replay of the coflow traces. It preserves input-to-output ratios of tasks, locality constraints, and inter-arrival times between jobs, and it runs at 1s decision intervals. Workload We use a realistic workload based on a one-hour Hive/MapReduce trace collected from a 3000-machine, 150rack Facebook production cluster <ref type="bibr" target="#b4">[5]</ref>. The trace contains over 500 coflows (7 ⇥ 10 5 flows). The coflow size (1MB 10TB) and the number of flows within one coflow (1 2⇥10 4 ) follow a heavy-tailed distribution.   <ref type="table">2</ref> of Aalo <ref type="bibr" target="#b22">[24]</ref>. • Spark Traffic: Flows inside each coflow are generated within 100ms following a uniform distribution,</p><p>• Hadoop Traffic: Flows inside each coflow are generated within 1000ms following a uniform distribution, and we add an extra exponential delay with a mean of 100ms. As to port assignments, they follow the rules described in §3.1 for Spark and Hadoop respectively. Metrics As for identification, we use precision and recall to measure CODA's accuracy: precision is the proportion of the flows which are truly in coflow C i among all flows classified as in C i , and recall is the proportion of flows in C i which are correctly classified. Finally, the identification accuracy is defined as the average of recall and precision.</p><p>As for scheduling, we measure the coflow completion time (CCT), and compare CODA against Aalo <ref type="bibr" target="#b22">[24]</ref> (the state-ofthe-art coflow scheduler with manually annotated coflows) and per-flow fair sharing. For easy comparison, we normalize the results by CODA's CCT, i.e., Normalized Comp. Time =</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Compared Duration CODA's Duration</head><p>Smaller values indicate better performance, and if the normalized completion time of a scheme is greater (smaller) than 1, CODA is faster (slower).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Testbed Experiments</head><p>Performance For identification, Figure <ref type="figure" target="#fig_15">8a</ref> shows that we achieve 99% precision and 97% recall in testbed experiments with the Facebook workload. As for scheduling, shows that CODA reduced the average and 95-th percentile coflow completion times by 2.4⇥ and 5.1⇥ respectively in comparison to TCP-based per-flow fairness. The corresponding improvements in the average job completion time are 1.4⇥ and 2.5⇥. Also, we can see that Aalo has the normalized job and coflow completion times close to 1, meaning that CODA performs almost as well as Aalo.</p><note type="other">Figure 8b</note><p>Additionally, in our testbed, we also ran the SWIM workloads <ref type="bibr" target="#b18">[20]</ref> using CODA prototype in Hadoop. A 97% precision and 88% recall is observed, validating the effectiveness of our identifier design. However, due to the disk I/Ointensive nature of the workload and the inherent bottlenecks introduced in the current software implementation of Hadoop, the network is hardly saturated most of the time and scheduling does not provide obvious improvement to CCT. Scalability To evaluate CODA's scalability, we emulated running up to 40,000 agents on our testbed. Figure <ref type="figure">9a</ref> shows the time to complete a coordination round averaged over 500 rounds for varying number of emulated agents (e.g., 40,000 emulated agents refer to each machine emulating 1000 agents). During each experiment, the coordinator transferred scheduling information for 100 concurrent coflows on average to each of the emulated agents.</p><p>As expected, CODA's scalability is not as good as Aalo <ref type="bibr" target="#b22">[24]</ref> because of its identification procedure, which does not exist in Aalo. However, we note that our identification speedup already brings big improvement -DBSCAN takes minutes with only 400 agents.</p><p>Even though we might be able to coordinate 40,000 agents in 6954ms, the coordination period (4) must be increased. To understand the impact of 4 on performance, we re-ran the earlier experiments with increasingly higher 4 (Figure <ref type="figure">9b</ref>). Note that, to reduce the impact of the long coordination period for small flows, CODA adopts the same method as Aalo -the first 10MB of a flow will go without waiting for coordination. We observe that similar to Aalo, CODA worsens with increasing 4, and the performance plummeted at 4 &gt; 100s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Inspecting Identification</head><p>Results under Normal Workloads We first look at the identification results of CODA under normal workloads. As shown in Figure <ref type="figure" target="#fig_17">10a</ref>, we find that CODA achieves high accuracy overall -e.g., it achieves around 97% precision and 98% recall under the Spark traffic, 94% precision and 84% recall for Hadoop. In addition, we observe 97% precision and 92% recall under the mixed traffic (Hadoop/ Spark each accounts for 50%). Comparatively, CODA obtains a higher accuracy in recall for the Spark traffic than that for the Hadoop traffic, which is probably due to its closer inter-flow arrival times (inside one coflow). Results under Challenging Scenarios We observe that time plays a key role in the high accuracy of CODA in the earlier experiment. Specifically, when flows within a coflow come in batches, which usually has a much smaller inter-flow arrival time than the inter-coflow arrival time, they are easier to differentiate. In order to stress CODA, we intentionally increase concurrency by overlapping coflows in two ways: 1. Batch arrival decreases inter-coflows arrival time. Basically, we create the case where coflows arrive in batch. We set the batch interval to be 10s, 50s and 100s, and all the coflows in one batch will be condensed with very close arrival times (100-300ms). In this way, coflows come in bursts with increased overlaps in each batch. In this way, flows inside one coflow will spread out over time and overlap more with other coflows. Such scenario represents cases where machines have poor coordination, or when some workers experience late start up. Figure <ref type="figure" target="#fig_17">10b</ref> shows the identification results under batch arrival. Here we only focus on the Hadoop traffic, as the exponential delay makes identification more difficult. As expected, we observe an obvious degradation in precision as batch interval increases. For example, the precision decreases from 85% to 56% as the batch interval increases from 10s to 100s. This is because when the traffic becomes more bursty, the number of concurrent coflows increases, making CODA more likely to misclassify unrelated flows into a coflow.</p><p>Figures <ref type="figure" target="#fig_17">10c</ref> shows the identification results under stretched arrival. We observe that CODA's recall drops to around 60% for both Hadoop and Spark traffic. Due to the large delay added to inter-flow arrival times, flows inside one coflow may have inter-arrival times as large as tens of seconds, which makes it more difficult to classify them to the same coflow. The Hadoop traffic suffers from a lower accuracy due to the 1000ms exponential delay.</p><p>In addition, we find that the Facebook trace exhibits a unified community. As a result, the community attribute has little   effect. But we envision that concurrent coflows generated by different applications or tenants may be effectively identified via communities even with very close start times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effectiveness of Distance Metric Learning (DML)</head><p>To evaluate the effectiveness of DML in §3.2, we run the identification procedure with the same weight assigned to each of the attributes in §3.1. Figure <ref type="figure" target="#fig_17">10d</ref> shows the average recall and precision in such case. Compared to CODA, over 40% degraded identification accuracy is clearly observed. This suggests that different attributes contribute differently to the final result, and our DML can effectively distinguish them. Impact of Parameter ✏ ( §3.</p><p>3) The radius parameter ✏ is key for CODA (i.e., incremental R-DBSCAN) to determine the number of clusters. Figure <ref type="figure" target="#fig_17">10e</ref> shows CODA's performance under varying ✏. 7 While CODA maintains a high accuracy under a wide range of ✏, it is not perfect: too small a diameter can misidentify coflows into several small clusters, leading to low recall, while too large a diameter tends to misidentify many coflows into one big cluster, leading to low precision.</p><p>As time plays a key role in identification, the best choice of ✏ is closely related to flow and coflow arrival patterns. In general, we believe that an ideal ✏ should be larger than the average inter-flow arrival time inside one coflow and smaller than the average inter-coflow arrival time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effectiveness of Identification Speedup</head><p>We evaluate our design for identification speedup ( §3.3) and show the results in Table <ref type="table" target="#tab_6">1</ref>. Compared to DBSCAN, with up to 30 concurrent coflows (1 ⇥ 10 5 flows), CODA provides around 600⇥ speedup at the cost of 2% accuracy. Compared to R-DBSCAN, CODA achieves 5⇥ speedup with negligible accuracy loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Inspecting Scheduling</head><p>Results under Normal Workloads We first inspect CODA scheduler under normal workloads. Figure <ref type="figure" target="#fig_20">11a</ref> shows the performance of different scheduling algorithms in terms of normalized CCT. It is evident that CODA effectively tolerates certain identification errors and performs as well as Aalo with correct coflow information, and significantly outperforms perflow fair sharing. For example, for the Spark traffic, with 7 We normalized the value of S time to 1 in As and A h ( §3.2).   For the Hadoop traffic, with around 90% accuracy, CODA is slightly worse than Aalo (about 1.1⇥ worse), but still 2.3⇥ better than per-flow fair sharing. To better visualize the result, Figure <ref type="figure" target="#fig_20">11b</ref> show the CDF of CCT for the Spark traffic, we can see that CODA almost coincides with Aalo. Results under Challenging Scenarios We next check CODA scheduler under the two challenging scenarios -batch arrival and stretched arrival -described above, where the identification is not as accurate as the normal case.</p><p>Figure <ref type="figure" target="#fig_22">12a</ref> compares different scheduling algorithms under the batch arrival case using Hadoop traffic. As expected, we observe that with more identification errors introduced, the performance of CODA scheduler degrades gradually. For example, we find that CODA performs around 1.3⇥ to 1.8⇥ worse compared to Aalo with correct information when batch interval equals 10s (85% precision in Figure <ref type="figure" target="#fig_17">10b</ref>)) to 100s (56% precision) respectively. In the meanwhile, CODA is still around 2⇥ to 1.5⇥ better than fair sharing.</p><p>Figure <ref type="figure" target="#fig_22">12b</ref> shows the performance of different scheduling algorithms under the stretched arrival case. We observe that for both Spark and Hadoop traffic, even under 60% recall (Figure <ref type="figure" target="#fig_17">10c</ref>), CODA performs only around 1.3⇥ worse than Aalo, while outperforming fair sharing by 2⇥. Effectiveness of Error-Tolerant Design We proceed to check the effectiveness of CODA's error-tolerant design in Figure <ref type="figure" target="#fig_23">13</ref>. Note that CODA without both late binding and intra coflow prioritization is equivalent to directly adopting Aalo for scheduling with inaccurate identification input. Figure <ref type="figure" target="#fig_23">13a</ref> shows that, for batch arrival, the error-tolerant design brings 3-5% overall improvement in CCT, and especially, it brings 10-20% improvement in CCT for small coflows (shown later in Figure <ref type="figure" target="#fig_9">15a</ref>). Furthermore, we observe a bigger improvement in Figure <ref type="figure" target="#fig_23">13b</ref> for stretched arrival, where the errortolerant design provides an overall 1.16⇥ and 1.14⇥ speedup for Hadoop and Spark traffic. Given that CODA is around 1.3⇥ slower than Aalo in this case (Figure <ref type="figure" target="#fig_22">12b</ref>), the 1.16⇥ speedup means it reduces the impact of errors by 40%. <ref type="foot" target="#foot_5">8</ref>Next, we look into independent benefits of late binding and intra-coflow prioritization. We observe that late binding brings non-trivial improvements under stretched arrivalmore than 10% for both Hadoop and Spark. Comparatively, intra-coflow prioritization introduces less improvement -7% for Hadoop under stretched arrival, and 1-5% under other cases. However, we show later that intra-coflow prioritization does bring up to 30% improvement on CCT of small coflows. Why does Late Binding Work? To understand why late binding brings big improvement on CCT, we plot the identification accuracy before/after we extend the identified coflows by a diameter d (i.e., the extended coflow C ⇤ in §4.2.2) in Figure <ref type="figure">14a</ref>. We observe a 10% improvement in recall at the cost of 4% reduction in precision. Note that a higher recall indicates that more flows in a coflow are successfully classified into one group, which means that coflow extension successfully identifies some stragglers. These identified stragglers will no longer be stragglers after they are bound to the coflow with the highest priority. As a result, late binding can effectively reduce the number of stragglers, thus improving CCT. Impact of Parameter d ( §4.2.2) We study how d affects the performance of late binding. In Figure <ref type="figure">14b</ref>, the blue line refers to the stretched arrival case <ref type="bibr">(Hadoop)</ref>, where late bind-  ing brings obvious improvement. We see that the normalized CCT improves with d at the beginning. This indicates that more stragglers are successfully identified, thereby reducing the CCT of the corresponding coflows. However, as d keeps increasing, late binding introduces too many pioneers, leading to a longer CCT. Moreover, the red line shows the results for the normal workloads (Spark). As the identification is already very accurate, late binding does not provide obvious improvement, and CODA's performance degrades slowly with an increasing d. In general, we observe that CODA is stable under a wide range of d, and we consider setting d to be a multiple of ✏ (discussed in §6.3) is a feasible choice. How does Intra-Coflow Prioritization Help? To answer this question, we first categorize coflows based on their lengths and widths. Specifically, we consider a coflow to be short if its longest flow is less than 5MB and narrow if it has at most 50 flows. We find that around 50% of coflows are short &amp; narrow (SN) coflows. However, their performance cannot be clearly reflected by the overall CCT, as they contribute to less than 0.1% of the total traffic load. Figure <ref type="figure" target="#fig_9">15a</ref> shows the normalized CCT of SN coflows in batch arrival. We see that intra-coflow prioritization brings up to 16% improvement. One possible reason is that when many coflows come in batch, CODA is likely to misclassify many coflows as a "super" coflow. Intra-coflow prioritization can effectively speed up SN coflows in such misclassified coflows.</p><p>Figure <ref type="figure" target="#fig_9">15b</ref> shows the normalized CCT of SN coflows in stretched arrival. The stretched arrival pattern tends to generate many stragglers, and intra-coflow prioritization can effectively speed up stragglers of SN coflows by up to 30%. What if Identification is Totally Unavailable? Finally, we study one extreme case where the entire identification procedure is unavailable (Figure <ref type="figure" target="#fig_26">16a</ref>). As we can no longer distinguish coflows, neither inter-coflow prioritization nor late binding takes effect. In such case, intra-coflow prioritization alone still improves coflow completion time by around 8%. Figure <ref type="figure" target="#fig_26">16b</ref> further shows that for SN coflows, the improvement can be as large as 7.4⇥. One important reason for such big improvement is that the Facebook workload is heavytailed in terms of coflow sizes. <ref type="foot" target="#foot_6">9</ref> As a consequence, prioritizing small flows can effectively benefit average CCT (especially for SN coflows) as well. Remark We note that our evaluation is restricted by the workload available to us. Thus, we synthesize start times and perturb arrival times to create different workloads to learn under which workloads CODA works well and under which it does not. First, CODA achieves high accuracy and nearoptimal CCT under the normal case, which generally applies to workloads, where the average inter-coflow arrival time is much larger than the inter-flow arrival time inside one coflow. Second, the results under the stretch case indicate that CODA can still achieve comparable CCT to Aalo when workers have poor coordination or experience slow start up. Third, the results under the batch arrival case indicate that CODA does not perform well when coflows have very close start times. We hope that these observations could be helpful in bridging the gap between synthetic workloads and real-world workloads and in providing guidelines for further improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>CODA with DAG Information The DAG representation of each job and information about the physical location of each task can be useful for coflow identification. However, such information may not always be available. For example, a public cloud operator typically does not communicate with the application masters of tenants. Furthermore, even with the DAG and location information, matching the high-level coflow information with the low-level flow information is non-trivial ( §5.1).</p><p>However, we believe that coflow identification and scheduling in the presence of such information is an important problem. Particularly, the DAG information can be viewed as an extra attribute, and combining the DAG information with other attributes can potentially increase the identification accuracy, especially for the batched arrival case and for multi-stage jobs. Moreover, as many datacenter workloads are repetitive, it is possible to learn the DAG information instead of directly retrieving it from the master. We consider this as a promising future direction. CODA Speedup Although we spent a lot of efforts in speeding up CODA ( §3.3), CODA's scalability is not as good as Aalo due to its identification procedure. To deploy CODA in large datacenters with hundreds of thousands of machines, further speedup is important. We note that one possible way is to parallelize the identification procedure. For example, we would like to see if CODA can benefit from recent proposals on parallel DBSCAN algorithms <ref type="bibr" target="#b34">[36,</ref><ref type="bibr" target="#b51">53]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Related Work</head><p>Coflow Scheduling The coflow abstraction is gaining increasingly more attention in recent years. However, all existing coflow-aware solutions, e.g., <ref type="bibr" target="#b19">[21,</ref><ref type="bibr" target="#b21">23,</ref><ref type="bibr" target="#b22">24,</ref><ref type="bibr" target="#b23">25,</ref><ref type="bibr" target="#b24">26,</ref><ref type="bibr" target="#b28">30,</ref><ref type="bibr" target="#b36">38,</ref><ref type="bibr" target="#b66">68]</ref>, require developers to make changes to their applications and manually annotate coflows. CODA challenges this assumption via a combination of application-transparent coflow identification and error-tolerant coflow scheduling. Internet Traffic Classification (ITC) Despite the rich literature in ITC <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b17">19,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b38">40,</ref><ref type="bibr" target="#b45">47,</ref><ref type="bibr" target="#b47">49,</ref><ref type="bibr" target="#b49">51,</ref><ref type="bibr" target="#b50">52,</ref><ref type="bibr" target="#b53">55,</ref><ref type="bibr" target="#b65">67]</ref>, some intrinsic differences prevent us from directly adopting them for coflow identification. First, mutual relations among flows captured by a particular coflow do not recur once its parent job is over; hence, coflows cannot be labeled by predefined categories. In contrast, in traditional traffic classification, traffic typically correspond to stable categories <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b38">40,</ref><ref type="bibr" target="#b45">47,</ref><ref type="bibr" target="#b45">47,</ref><ref type="bibr" target="#b47">49,</ref><ref type="bibr" target="#b53">55,</ref><ref type="bibr" target="#b65">67]</ref>. Second, timeliness is paramount in coflow identification because its result is the input for scheduling. In contrast, belated identification is still useful in many traditional ITC tasks (e.g., intrusion detection). Robust Scheduling We also notice that a similar topic, robust scheduling, has been explored in operations research <ref type="bibr" target="#b25">[27,</ref><ref type="bibr" target="#b37">39,</ref><ref type="bibr" target="#b40">42,</ref><ref type="bibr" target="#b59">61]</ref>. However, robust scheduling primarily deals with unexpected events happening during a pre-computed schedule, while error-tolerant scheduling in CODA attempts to schedule task with possibly erroneous input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Concluding Remarks</head><p>We have presented CODA to automatically identify and schedule coflows without any application modifications. CODA employs an incremental clustering algorithm to perform fast, application-transparent coflow identification, and complements it by proposing an error-tolerant coflow scheduling to tolerate identification errors. Testbed experiments and trace-driven simulations show that CODA achieves over 90% identification accuracy, and its scheduler effectively masks remaining identification errors. CODA's overall performance is comparable to Aalo and 2.4⇥ better than per-flow fairness.</p><p>In conclusion, this work takes a natural step toward making coflows more practical and usable by removing the need for manual annotations in applications. It also opens up exciting research challenges, including generalization of the identification mechanism beyond data-intensive workloads, decentralization for better scalability, online parameter tuning, handling coflow dependencies, and extending error-tolerant scheduling and allocation algorithms to other resources.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>SIGCOMM ' 16 ,</head><label>16</label><figDesc>August 22-26, 2016, Florianopolis, Brazil c 2016 ACM. ISBN 978-1-4503-4193-6/16/08. . . $15.00 DOI: http://dx.doi.org/10.1145/2934872.2934880</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: CODA architecture: CODA agents collect flow-level information, and CODA master periodically updates coflow schedules using application-transparent identification and error-tolerant scheduling mechanisms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure. 2 :</head><label>2</label><figDesc>Figure. 2: Impact of stragglers. Stragglers (b) are likely to more negatively affect the CCT compared with pioneers (a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure. 3 :</head><label>3</label><figDesc>Figure. 3: Intra coflow prioritization matters. MADD is not error tolerant as flows inside one coflow are likely to finish until the very end of the entire coflow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure. 2 :</head><label>2</label><figDesc>Figure. 2: Impact of stragglers. Stragglers (b) are likely to more negatively affect the CCT compared with pioneers (a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure. 3 :</head><label>3</label><figDesc>Figure. 3: Intra coflow prioritization matters. MADD is not error tolerant as flows inside one coflow are likely to finish until the very end of the entire coflow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Impact of misidentifications. C1 in light/orange is scheduled before C2 (dark/blue); without errors, each completes in one time unit for an average CCT of 1.5 time units.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>2 Figure 4 :</head><label>24</label><figDesc>Figure 4: Impact of misidentifications on Aalo. Stragglers of highpriority C1 (light/orange) can get stuck with C2 (dark/blue) in a lowpriority queue, while other lower-priority coflows (black) compared to C1 complete earlier.</figDesc><graphic coords="6,298.66,102.93,84.21,51.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Flows falling within multiple coflow clusters during identification can become stragglers if misidentified.</figDesc><graphic coords="6,368.47,100.45,57.75,55.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Impact of CODA's design principles: (a) minimize stragglers by increasing pioneers; and (b) complete individual flows fast to handle leftover stragglers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>Diameter d Diameter d reflects the tradeoff besmallest distance between f and flows in C.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>No. of concurrent coflows</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Time-related characteristics of the workload.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 7</head><label>7</label><figDesc>plots the distribution of inter-coflow arrival time and the number of concurrent coflows. In our testbed experiments, we scale down jobs accordingly to match the maximum possible 40 Gbps bisection bandwidth of our deployment while preserving their communication characteristics.However, the Facebook trace does not contain detailed flowlevel information such as flow start times and port numbers. To perform a reasonable replay in our simulations, we first run typical benchmarks (e.g., WordCount and PageRank) on Spark and Hadoop in our testbed. Based on the flow arrival time pattern within one coflow we learned from our testbed, we add the start time information back to the Facebook workload to emulate Spark and Hadoop traffic:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: [Testbed] CODA's performance in terms of (a) identification accuracy, and (b) coflow and corresponding job completion times (JCT) compared to Aalo and per-flow fairness. The fraction of JCT jobs spent in communication follows the same distribution shown in Table2of Aalo<ref type="bibr" target="#b22">[24]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>4 Figure 9 :</head><label>49</label><figDesc>Figure 9: [Testbed] CODA scalability: (a) more agents require longer coordination periods (Y-axis is in log scale), and (b) delayed coordination hurts overall performance (measured as sum of CCT).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: [Simulation] Inspecting CODA's identifier. Here DML refers to distance metric learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>2 .</head><label>2</label><figDesc>Stretched arrival increases inter-flow arrival times between flows in one coflow. Specifically, for both Spark and Hadoop traffic, flows are generated with a delay of 5000ms following a uniform distribution, and for Hadoop traffic we add an extra exponential delay with a mean of 1000ms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: [Simulation] CODA's scheduler under normal workload.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: [Simulation] CODA's scheduler under challenging scenarios.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: [Simulation] Effectiveness of CODA's error-tolerant scheduler. Here "both" refers to late binding (L.B.) and intra-coflow prioritization (I.P.). around 95% identification accuracy (corresponding to Figure 10a), it is not a surprise that CODA performs almost the same as Aalo, and outperforms per-flow fair sharing by 2.7⇥.For the Hadoop traffic, with around 90% accuracy, CODA is slightly worse than Aalo (about 1.1⇥ worse), but still 2.3⇥ better than per-flow fair sharing. To better visualize the result, Figure11bshow the CDF of CCT for the Spark traffic, we can see that CODA almost coincides with Aalo. Results under Challenging Scenarios We next check CODA scheduler under the two challenging scenarios -batch arrival and stretched arrival -described above, where the identification is not as accurate as the normal case.Figure12acompares different scheduling algorithms under the batch arrival case using Hadoop traffic. As expected, we observe that with more identification errors introduced, the performance of CODA scheduler degrades gradually. For example, we find that CODA performs around 1.3⇥ to 1.8⇥ worse compared to Aalo with correct information when batch interval equals 10s (85% precision in Figure10b)) to 100s (56% precision) respectively. In the meanwhile, CODA is still around 2⇥ to 1.5⇥ better than fair sharing.Figure12bshows the performance of different scheduling algorithms under the stretched arrival case. We observe that for both Spark and Hadoop traffic, even under 60% recall (Figure10c), CODA performs only around 1.3⇥ worse than Aalo, while outperforming fair sharing by 2⇥. Effectiveness of Error-Tolerant Design We proceed to check the effectiveness of CODA's error-tolerant design in Figure13. Note that CODA without both late binding and intra coflow prioritization is equivalent to directly adopting Aalo for scheduling with inaccurate identification input. Figure13ashows that, for batch arrival, the error-tolerant design brings 3-5%</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 14 :Figure 15 :</head><label>1415</label><figDesc>Figure 14: [Simulation] Understanding Late binding (L.B.) ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Figure 16 :</head><label>16</label><figDesc>Figure 16: [Simulation] CODA's performance w/o identification step.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>leader is deleted only when it has no other followers</figDesc><table><row><cell>15:</cell><cell>else</cell></row><row><cell>16: 17:</cell><cell>l.f ollowers = l.f ollowers \ {f } end if</cell></row><row><cell>18:</cell><cell>end for</cell></row><row><cell>19:</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 1 :</head><label>1</label><figDesc>[Simulation] Effectiveness of CODA's speedup design</figDesc><table><row><cell>Algorithm</cell><cell>DBSCAN</cell><cell>R-DBSCAN</cell><cell>CODA</cell></row><row><cell>Average Identification Time (ms)</cell><cell>3217.27</cell><cell>27.50</cell><cell>5.23</cell></row><row><cell>Identification Accuracy (%)</cell><cell>98.21%</cell><cell>96.47%</cell><cell>96.41%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We use the terms application and framework interchangeably in this paper. Users can submit multiple jobs to each framework.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Currently most data-parallel computing frameworks leverage TCP for reliable data transfer.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>We used Spark-1.6 and Hadoop-2.7.1 for this study.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>Cloud providers usually do not have access to customer VMs, and hence, cannot introduce any identification mechanism that hinges on OS-level information.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>CCT of C 1 can be between 1 and 2 time units based on when its straggler flow is scheduled, with an expected CCT of 1.5 time units.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5"><p>Calculated as: CCT(CODA w/o both) -CCT(CODA) CCT(CODA w/o both) -CCT(Aalo) = 1.3⇥1.16 1.3   1.3⇥1.16 1 = 40%.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_6"><p>Less than 20% coflows contribute to about 99% of the traffic.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work is supported in part by the Hong Kong RGC ECS-26200014, GRF-16203715, GRF-613113, CRF-C703615G, and the China 973 Program No.2014CB340303. We thank our shepherd, Nandita Dukkipati, and the anonymous NSDI and SIGCOMM reviewers for their valuable feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="http://akka.io" />
		<title level="m">Akka</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Apache</forename><surname>Hadoop</surname></persName>
		</author>
		<ptr target="http://hadoop.apache.org" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Apache</forename><surname>Hive</surname></persName>
		</author>
		<ptr target="http://hive.apache.org" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Apache</forename><surname>Tez</surname></persName>
		</author>
		<ptr target="http://tez.apache.org" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<ptr target="https://github.com/coflow/coflow-benchmark" />
		<title level="m">Coflow Benchmark Based on Facebook Traces</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Netty</forename></persName>
		</author>
		<ptr target="http://netty.io" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName><surname>Presto</surname></persName>
		</author>
		<ptr target="https://prestodb.io" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<ptr target="https://spark.apache.org/docs/latest/cluster-overview.html" />
		<title level="m">Spark 1.4.1 cluster mode overview</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Distributed and fault-tolerant realtime computation</title>
		<author>
			<persName><surname>Storm</surname></persName>
		</author>
		<ptr target="http://storm-project.net" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<ptr target="http://storm.apache.org/documentation/Trident-tutorial.html" />
		<title level="m">Trident: Stateful stream processing on Storm</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">BlinkDB: Queries with bounded errors and bounded response times on very large data</title>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EuroSys</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">MillWheel: Fault-tolerant stream processing at Internet scale</title>
		<author>
			<persName><forename type="first">T</forename><surname>Akidau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">pFabric: Minimal near-optimal datacenter transport</title>
		<author>
			<persName><forename type="first">M</forename><surname>Alizadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGCOMM</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Spark SQL: Relational data processing in Spark</title>
		<author>
			<persName><forename type="first">M</forename><surname>Armbrust</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Information-agnostic flow scheduling for commodity data centers</title>
		<author>
			<persName><forename type="first">W</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSDI</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Traffic classification on the fly</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bernaille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGCOMM CCR</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="23" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Surviving failures in bandwidth-constrained datacenters</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bodík</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGCOMM</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Bayesian classification (AutoClass): Theory and results</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cheeseman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The case for evaluating mapreduce performance using workload suites</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MASCOTS</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="390" to="399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Managing data transfers in computer clusters with Orchestra</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chowdhury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGCOMM</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Coflow: An application layer abstraction for cluster networking</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chowdhury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Hotnets</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Efficient coflow scheduling with Varys</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chowdhury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGCOMM</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Efficient coflow scheduling without prior knowledge</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chowdhury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGCOMM</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">HUG: Multi-resource fairness for correlated and elastic demands</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chowdhury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSDI</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Coflow: A Networking Abstraction for Distributed Data-Parallel Applications</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M M K</forename><surname>Chowdhury</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
		<respStmt>
			<orgName>University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Robust scheduling to hedge against processing time uncertainty in single-stage production</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Daniels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="363" to="376" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Mapreduce: Simplified data processing on large clusters</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<imprint>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Decentralized task-aware scheduling for data center networks</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Dogar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGCOMM</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A density-based algorithm for discovering clusters in large spatial databases with noise</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The google file system</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SOSP</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">SystemML: Declarative machine learning on mapreduce</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghoting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">GraphX: Graph processing in a distributed dataflow framework</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Pingmesh: A large-scale system for data center network latency measurement and analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIG-COMM</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Mr-dbscan: an efficient parallel density-based clustering algorithm using mapreduce</title>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel and Distributed Systems (ICPADS), 2011 IEEE 17th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="473" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Finishing flows quickly with preemptive scheduling</title>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGCOMM</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Network-aware scheduling for data-parallel jobs: Plan when you can</title>
		<author>
			<persName><forename type="first">V</forename><surname>Jalaparti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGCOMM</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Robustness measures and robust scheduling for job shops</title>
		<author>
			<persName><forename type="first">V</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jorge</forename><surname>Leon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IIE transactions</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="32" to="43" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">BLINC: multilevel traffic classification in the dark</title>
		<author>
			<persName><forename type="first">T</forename><surname>Karagiannis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGCOMM</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Impala: A modern, open-source SQL engine for Hadoop</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kornacker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Robust scheduling of a two-machine flow shop with uncertain processing times</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kouvelis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Iie Transactions</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="421" to="432" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">MLbase: A distributed machine-learning system</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kraska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">GraphLab: A new framework for parallel machine learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Low</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Some methods for classification and analysis of multivariate observations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Macqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability</title>
		<meeting>the Fifth Berkeley Symposium on Mathematical Statistics and Probability</meeting>
		<imprint>
			<date type="published" when="1967">1967</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="281" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Pregel: A system for large-scale graph processing</title>
		<author>
			<persName><forename type="first">G</forename><surname>Malewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Flow clustering using machine learning techniques</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mcgregor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PAM</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">MLlib: Machine learning in Apache Spark</title>
		<author>
			<persName><forename type="first">X</forename><surname>Meng</surname></persName>
		</author>
		<idno>CoRR, abs/1505.06807</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Internet traffic classification using Bayesian analysis techniques</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Moore</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="50" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Naiad: A timely dataflow system</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SOSP</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Training on multiple sub-flows to optimize the use of machine learning classifiers in real-world IP networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LCN</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A survey of techniques for Internet traffic classification using machine learning</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="56" to="76" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A new scalable parallel dbscan algorithm using the disjoint-set data structure</title>
		<author>
			<persName><forename type="first">M</forename><surname>Patwary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">High Performance Computing, Networking, Storage and Analysis (SC), 2012 International Conference for</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">What makes APIs hard to learn? answers from developers</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Robillard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Software</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="27" to="34" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Class-of-service mapping for QoS: a statistical signature-based approach to IP traffic classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Roughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IMC</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Inside the social network&apos;s (datacenter) network</title>
		<author>
			<persName><forename type="first">A</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGCOMM</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Why are APIs difficult to learn and use? Crossroads</title>
		<author>
			<persName><forename type="first">C</forename><surname>Scaffidi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="4" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Apache Hadoop YARN: Yet another resource negotiator</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">K</forename><surname>Vavilapalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SoCC</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Rough-DBSCAN: A fast hybrid density based clustering method for large data sets</title>
		<author>
			<persName><forename type="first">P</forename><surname>Viswanath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="1477" to="1488" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A tutorial on spectral clustering</title>
		<author>
			<persName><forename type="first">U</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Von</forename><surname>Luxburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="395" to="416" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A fuzzy robust scheduling approach for product development projects</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">152</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="180" to="194" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Better never than late: meeting deadlines in datacenter networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGCOMM</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Shark: SQL and rich analytics at scale</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Xin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Distance metric learning with application to clustering with side-information</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Resilient distributed datasets: A fault-tolerant abstraction for in-memory cluster computing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSDI</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Discretized streams: Fault-tolerant stream computation at scale</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SOSP</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Automated traffic classification and application identification using machine learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LCN</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">RAPIER: Integrating routing and scheduling for coflow-aware data center networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INFOCOM</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
