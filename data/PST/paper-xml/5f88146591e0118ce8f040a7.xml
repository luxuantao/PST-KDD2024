<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Are all negatives created equal in contrastive instance discrimination?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-10-13">13 Oct 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tiffany</forename><forename type="middle">(</forename><surname>Tianhui</surname></persName>
						</author>
						<author>
							<persName><forename type="first">)</forename><surname>Cai</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jonathan</forename><surname>Frankle</surname></persName>
							<email>frankle@mit.edu</email>
						</author>
						<author>
							<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Schwab</surname></persName>
							<email>dschwab@fb.com</email>
						</author>
						<author>
							<persName><forename type="first">Ari</forename><forename type="middle">S</forename><surname>Morcos</surname></persName>
							<email>arimorcos@fb.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research</orgName>
								<orgName type="institution">Columbia University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">ITS</orgName>
								<orgName type="institution">CUNY Graduate Center Facebook AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Are all negatives created equal in contrastive instance discrimination?</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-10-13">13 Oct 2020</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2010.06682v1[cs.CV]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Self-supervised learning has recently begun to rival supervised learning on computer vision tasks. Many of the recent approaches have been based on contrastive instance discrimination (CID), in which the network is trained to recognize two augmented versions of the same instance (a query and positive) while discriminating against a pool of other instances (negatives). Using MoCo v2 (Chen et al., 2020c) as our testbed, we divided negatives by their difficulty for a given query and studied which difficulty ranges were most important for learning useful representations. We found that a small minority of negatives-just the hardest 5%-were both necessary and sufficient for the downstream task to reach full accuracy. Conversely, the easiest 95% of negatives were unnecessary and insufficient. Moreover, we found that the very hardest 0.1% of negatives were not only unnecessary but also detrimental. Finally, we studied the properties of negatives that affect their hardness, and found that hard negatives were more semantically similar to the query, and that some negatives were more consistently easy or hard than we would expect by chance. Together, our results indicate that negatives play heterogeneous roles and that CID may benefit from more intelligent negative treatment. * Work performed as part of the Facebook AI Residency program.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years, there has been tremendous progress on self-supervised learning (SSL), a paradigm in which representations are learned via a pre-training task that uses unlabeled data. These representations are subsequently used on downstream tasks, such as classification or object detection. Since SSL pre-training does not require labels, it can leverage unlabeled data, which is generally more abundant and cheaper to obtain than labeled data. In computer vision, representations learned from unlabeled data have historically underperformed representations learned directly from labeled data. Recently, however, newly proposed SSL methods such as MoCo <ref type="bibr" target="#b18">(He et al., 2019;</ref><ref type="bibr" target="#b11">Chen et al., 2020c)</ref>, SimCLR <ref type="bibr">(Chen et al., 2020a,b)</ref>, SwAV <ref type="bibr" target="#b8">(Caron et al., 2020)</ref>, and BYOL <ref type="bibr" target="#b16">(Grill et al., 2020)</ref> have dramatically reduced this performance gap.</p><p>The MoCo and SimCLR pre-training tasks learn representations using a paradigm called contrastive instance discrimination (CID). In CID, a network is trained to recognize different augmented views of the same image (sometimes called the query and the positive) and discriminate between the query and the augmented views of other random images from the dataset (called negatives).</p><p>Despite the empirical successes of CID, the mechanisms underlying its strong performance remain unclear. Recent theoretical and empirical works have investigated the role of mutual information between augmentations <ref type="bibr" target="#b26">(Tian et al., 2020)</ref>, analyzed properties of the learned representations such as alignment and uniformity <ref type="bibr" target="#b30">(Wang &amp; Isola, 2020)</ref>, and proposed a theoretical framework <ref type="bibr" target="#b0">(Arora et al., 2019)</ref>, among others. However, existing works on CID have not investigated the relative importance or semantic properties of different neg-atives, even though negatives play a central role in CID. In other areas, work on hard negative mining in metric learning <ref type="bibr" target="#b19">(Kaya &amp; Bilge, 2019)</ref> and on the impact of different training examples in supervised learning <ref type="bibr" target="#b4">(Birodkar et al., 2019)</ref> suggests that understanding the relative importance of different training data can be fruitful.</p><p>In this work, we empirically investigate how the difficulty of negatives affects learning. We measure difficulty using the dot product between the normalized contrastive-space embeddings of the query and the negative; this is also how the negatives factor into the contrastive loss. A dot product closer to 1 suggests a negative that is more difficult to distinguish from the query. We ask how different negatives, by difficulty, affect training. Are some negatives more important than others for downstream accuracy? If so, we ask: Which ones? To what extent? And what makes them different?</p><p>We focus on MoCo v2 <ref type="bibr" target="#b11">(Chen et al., 2020c)</ref> and the downstream task of linear classification on ImageNet <ref type="bibr" target="#b13">(Deng et al., 2009)</ref>. We make the following contributions (see Figure <ref type="figure">1</ref> for summary):</p><p>• The easiest 95% of negatives are unnecessary and insufficient, while the top 5% hardest negatives are necessary and sufficient: We reached within 0.7 percentage points of full accuracy by training on the 5% of hardest negatives for each query, suggesting that the 95% easiest negatives are unnecessary. In contrast, the easiest negatives are insufficient (and, therefore, the hardest negatives are necessary): accuracy drops substantially when training only on the easiest 95% of negatives.</p><p>The hardest 5% of negatives are especially important: training on only the next hardest 5% lowers accuracy by 15 percentage points. • The hardest 0.1% of negatives are unnecessary and sometimes detrimental: Downstream accuracy is the same or, in some cases, higher when we remove these hardest negatives. These negatives are predominately in the same ImageNet class as the query, suggesting that semantically identical (but superficially dissimilar) negatives are unhelpful or detrimental to contrastive learning on this task. • Properties of negatives: Based on our observations that the importance of a negative varies with its difficulty, we investigate the properties of negatives that affect their difficulty.</p><p>-We found that the hard negatives are more semantically similar (in terms of ImageNet classes) to the query than easier negatives, suggesting that negatives that are more semantically similar may tend to be more helpful for learning for this task. -We also observed that the pattern is reversed for the ≈50% of easier negatives: there, the easier the negative, the more semantically similar it is to the query. -There exist negatives that are more consistently hard across queries than would be expected by random chance.</p><p>We emphasize that our primary aim is to better understand the differences between negatives and the impact of these differences on existing methods rather than to propose a new method. However, our results suggest that there may be unexploited opportunities to reduce the cost of modern CID methods <ref type="bibr" target="#b11">(Chen et al., 2020c)</ref>. For any particular query, only a small fraction of the negatives are necessary. Although MoCo itself is not designed such that ignoring easy negatives will improve performance, we believe this observation can serve as a valuable building block for future contrastive learning methods. It also suggests that there may be further room to choose specific examples for training-for example hard negative mining and curriculum learning <ref type="bibr" target="#b9">(Chen et al., 2020a;</ref><ref type="bibr" target="#b12">Chuang et al., 2020;</ref><ref type="bibr" target="#b19">Kaya &amp; Bilge, 2019)</ref>-to reduce costs and improve performance per data sample.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods and Preliminaries</head><p>Contrastive instance discrimination and momentum contrast. Momentum Contrast (MoCo v2) is a CID method that reaches accuracy within 6 percentage points of supervised accuracy on ImageNet with ResNet-50 <ref type="bibr" target="#b11">(Chen et al., 2020c)</ref>. In MoCo, the task is to learn a representation that succeeds at the following: given a query (an augmented view of an image), correctly pick a positive (a different augmented view of the same image) from a large set of negatives (augmented views of randomly chosen images). Our experiments focus on aspects that are common between CID methods rather than those specific to MoCo. We discuss implementation details that may be specific to MoCo v2 here.</p><p>The MoCo v2 encoder is a ResNet-50 network. For pre-training, the outputs of this base network are fed into a multi-layer perceptron (MLP) head; we refer to the normalized output from the MLP head as the Figure <ref type="figure">1</ref>: Schematic summary of main results. Easy negatives are unnecessary and insufficient (green) and also tend to be semantically dissimilar (i.e., in unrelated ImageNet classes) to the query (light blue). Hard (but not the very hardest) negatives are necessary and sufficient (orange) and also tend to be semantically similar to the query. The very hardest negatives are unnecessary and sometimes detrimental and also tend to be in the same class as the query (red). This is an illustrative schematic; images and trees are not from ImageNet.</p><p>contrastive-space embedding. For downstream tasks, the MLP head is discarded and only the base network is used; we refer to the output of the base network as the learned representation. A distinguishing feature of MoCo is that it has two encoders, one of which is actively trained (used for the query) and the other which is a moving average of the trained encoder (used for the positive and negatives). MoCo stores the embeddings of each batch of positives in a large queue and uses them as negatives for future batches, enabling the use of more negatives than can fit in a batch.</p><p>MoCo uses the InfoNCE loss <ref type="bibr" target="#b17">(Gutmann &amp; Hyvärinen, 2010;</ref><ref type="bibr" target="#b28">van den Oord et al., 2018)</ref>:</p><formula xml:id="formula_0">L q = − log exp(q • k + /τ ) K i=1 exp(q • k i /τ</formula><p>) where q is the embedding of a query (using the learned encoder), k + is the embedding of a positive (using the momentum encoder), and k i are the embeddings of the negatives in the queue (added using previous states of the momentum encoder). τ is a temperature hyperparameter.</p><p>Difficulty of negatives. To compute the difficulty for a set of negatives given a particular query, we calculate the dot product between the normalized contrastive-space embedding of each negative with the normalized contrastive-space embedding of the query. We then sort the dot products and consider the negatives with dot products closer to 1 to be harder negatives and those with smaller dot products to be easier negatives. We use this terminology because it fits intuition: all else being equal, harder negatives increase the loss. Since embeddings are normalized, the dot product is the cosine of the angle between the embeddings of the instances and ranges from -1 to 1.</p><p>Note that difficulty is defined per query and that it is a function of the current state of the network. Thus, a negative can be easy for some queries and hard for others, and the hardness of a negative for a given query can vary over training epochs and across different training runs and configurations.</p><p>Experimental setting. Our experiments focus on MoCo v2 <ref type="bibr" target="#b11">(Chen et al., 2020c)</ref>, an improved version of MoCo which combines MoCo v1 <ref type="bibr" target="#b18">(He et al., 2019)</ref> with several features of SimCLR <ref type="bibr" target="#b9">(Chen et al., 2020a)</ref>. We use ImageNet for pre-training and evaluate performance using linear classification on ImageNet from the representation learned in the pre-training CID task. The network used, as in MoCo v2, is a ResNet-50 with MLP head, and trained for 200 epochs. Unless otherwise noted, we use three replicates for all experiments; error bars represent mean ± standard deviation.</p><p>3 Which Negatives are Necessary or Sufficient?</p><p>In this section, we examine which negatives, by difficulty, are necessary or sufficient for producing representations during pretraining that lead to strong downstream performance. Outside of CID, there are varying  99.0% 99.9% 100.0% Most difficult negatives included (percentile)  perspectives on the value of easy negatives. Research on hard negative mining suggests that harder negatives can be more important than easier negatives for relevant tasks <ref type="bibr" target="#b19">(Kaya &amp; Bilge, 2019)</ref>. However, in some supervised contexts, much or all training data seems important for reaching the highest accuracy <ref type="bibr" target="#b4">(Birodkar et al., 2019)</ref>. We aim to experimentally assess which of these perspectives applies when pre-training MoCo v2 with CID.</p><p>To determine whether a set of negatives was necessary, we removed the corresponding negatives on each pre-training step; if the resulting representations still led to accuracy close to baseline on the downstream task, then we considered those negatives to have been unnecessary. To determine whether a set of negatives was sufficient, we removed all negatives except those in that range on each pre-training step; if the resulting representations still led to strong accuracy on the downstream task, then we considered the negatives in that range to have been sufficient.<ref type="foot" target="#foot_0">2</ref> </p><p>The easy negatives are unnecessary; the hard negatives are sufficient. First, we asked whether the easy negatives were necessary (or equivalently, whether the hard negatives were sufficient). That is, does the network maintain downstream accuracy when it is pre-trained without the easy negatives? To test this, we evaluated how accuracy changed as different subsets of negatives were removed. Interestingly, we found that using only the hardest 5% of negatives was largely sufficient to recover baseline accuracy (Figure <ref type="figure" target="#fig_0">2a</ref>-b, 95-100%), suggesting that the overwhelming majority of the easier negatives were unnecessary. Moreover, the hardest 5% (95-100%) were substantially more informative than the next 5% (90-95%): top-1 accuracy dropped by only ∼ 0.7 percentage points when trained on only the hardest 5% vs. 15 percentage points for the next hardest 5% (90-95%) and 47 percentage points for the third 5% (85-90%; Figure <ref type="figure" target="#fig_0">2a-b</ref>). Going forward, we use 5% as a cutoff, calling the negatives harder than this cutoff hard and those easier than this cutoff easy.</p><p>The easy negatives are largely insufficient; the hard negatives are necessary. We next asked whether the easy negatives were sufficient (or, equivalently, whether the hard negatives were necessary). Although we found in the previous section that the easy negatives were unnecessary, that does not necessarily mean they are insufficient. For example, it could be that the easy negatives, while individually less important, collectively provide sufficient signal for learning good representations on the downstream task. Alternatively, it is possible that the information contained in the easy negatives is fundamentally lacking learning signals required to drive CID; in this case, the easy negatives, even when combined together, would still be insufficient. We found that even when the easiest 95% of negatives were combined together, accuracy was ∼5% below baseline (Figure <ref type="figure" target="#fig_0">2c-d</ref>). In contrast, recall that using only the hardest 5% of negatives (19x fewer) achieved top-1 performance within 0.7% of baseline (Figure <ref type="figure" target="#fig_0">2a</ref>). Using the easiest 90% of negatives harms accuracy even further (0-90%; Figure <ref type="figure" target="#fig_0">2c-d</ref>). Together, these results demonstrate that the easiest negatives, even when they comprise the vast majority of negatives, are still insufficient.</p><p>The very hardest negatives are harmful at lower temperatures. We have found that the hard negatives, i.e. the 5% hardest, are largely necessary and sufficient for CID. However, accuracy actually improved slightly when we removed the very hardest 0.1% of negatives (p = 0.0003 for an unpaired t-test).<ref type="foot" target="#foot_1">3</ref> This effect was most pronounced at lower temperatures (Figure <ref type="figure" target="#fig_1">3</ref>); for example, at temperature 0.1, training without the hardest 0.1% of negatives improved downstream top-1 accuracy by 0.23% and top-5 accuracy by 0.67%. Interestingly, the effect was larger for top-5 accuracy than top-1 accuracy (compare Figure <ref type="figure" target="#fig_1">3b</ref> with 3a). One plausible explanation for why this improvement was sensitive to temperature is because, at lower temperatures, the hardest negatives constituted a larger fraction of the loss.</p><p>One hypothesis for why the hardest negatives hurt is that some negatives are very similar to the query. Because negatives are randomly sampled, they can included augmented views of images that are near-duplicates of the query or simply visually very similar to the query. Since the images contain identical semantic content, the contrastive objective is effectively pushing representations of examples that are semantically identical but superficially dissimilar apart, which would force the network to emphasize, rather than ignore, these superficial dissimilarities (Figure <ref type="figure">1</ref>). These same-class negatives may thus be harmful to learning representations for downstream linear classification.</p><p>If this is the case, we would expect that removing same class negatives would improve performance, perhaps even more than removing the hardest 0.1% of negatives overall. As shown in Table <ref type="table" target="#tab_3">1</ref>, removing same-class negatives indeed leads to slightly higher accuracy than removing the hardest 0.1% of negatives. Removing only the subset of the hardest 0.1% of negatives with the same class as the query accounts for all of the improvement from removing the hardest 0.1% of negatives. Alternatively, removing only the subset of the 0.1% hardest negatives with different classes shows no improvement over baseline and in fact decreases top 1 performance at low temperature.</p><p>These results demonstrate that the accuracy benefit of removing the 0.1% hardest negatives can entirely be accounted for by the fact that it removes many elements of the same class as the query, approximating the impact of removing the same-class negatives without requiring access to privileged label data. This observation is also consistent with recent work which has attempted to "debias" contrastive learning away from same-class negatives <ref type="bibr" target="#b12">(Chuang et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Understanding negatives by difficulty</head><p>Hard negatives are more semantically similar to the query. We have shown that easy negatives are unnecessary and insufficient, and that, inversely, hard negatives are necessary and sufficient. However, the properties that distinguish easy from hard negatives remain unclear. Intuitively, we might imagine that, to </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Easiest 95%</head><p>Hardest 5% 0 1 2 3 4 5 WordNet similarity (higher is more similar) Figure <ref type="figure">4</ref>: Semantic similarity is higher for the 5% of hard negatives than for the 95% of easy negatives Proportion of shared labels (higher is more similar) (a) and WordNet distance from root to least common ancestor (lower is more similar) (b) for the 5% of hard negatives and the 95% of easy negatives. Error bars are standard deviation on plot values across 3 seeds. learn a representation that is useful for a fine-grained classification task such as ImageNet, a network must learn to distinguish between categories that are similar but semantically distinct, e.g., different breeds of dogs. If this were the case, we would expect that the 5% hardest negatives, which were both necessary and sufficient for training, would also be more semantically similar to the query than the 95% easiest negatives.</p><p>To test this hypothesis, we first examined the fraction of the easy and hard negatives that had the same class as the query label.<ref type="foot" target="#foot_2">4</ref> Similar to our results above regarding the 0.1% very hardest negatives, we found that negatives of the same class were significantly overrepresented among the 5% hardest negatives relative to the easy negatives (p=5.1e-7, unpaired t-test; Figure <ref type="figure">4a</ref>). However, this experiment can only tell us whether the hard negatives contain more negatives that are semantically identical to the query (in that they have the same class); it cannot distinguish between negatives of different semantic similarity (which have classes that are related, but distinct from the query). To evaluate semantic similarity we used the ImageNet class hierarchy derived from WordNet <ref type="bibr" target="#b13">(Deng et al., 2009)</ref>. For each negative, we computed the tree depth of the least common ancestor between the negative and the query; higher WordNet similarity means that the least common ancestor is deeper in the tree and that the negative is therefore more similar to the query. As shown in Figure <ref type="figure">4b</ref>, we found that the hard negatives were significantly more semantically similar to the query than the easy negatives (p=4.8e-7, unpaired t-test). Together, these results demonstrate that semantic similarity is a property that distinguishes easy and hard negatives; however, evaluation of whether this relationship is causal is left for future work. Some of the easiest negatives are both anti-correlated and semantically similar to the query. Surprisingly, we also found that a small subset of the very easiest examples are anti-correlated with the query (i.e., the dot product between these negatives and the query is highly negative; Figure <ref type="figure">5c</ref>). While the presence of negatives orthogonal to the query might be expected (as the two might be unrelated to one another) the presence of a high magnitude negative dot product suggests that the network learned to anti-correlate these negatives with the query.</p><p>Moreover, these negatives are also substantially more semantically similar to the query than the majority of easy negatives (Figure <ref type="figure">5b</ref>); in fact, by the WordNet tree similarity, their semantic similarity nearly matches those of the hard negatives. In addition, qualitatively, the positive and negative classes with the highest mean pairwise negative dot product are consistently of closely related classes such as similar breeds of dog (see Table <ref type="table" target="#tab_9">A3</ref>). In contrast to the hard negatives, however, these easiest negatives do not contain many negatives of the same class as the query, although there is a slight increase for the very easiest negatives (see inset, Figure <ref type="figure">5a</ref>). Some negatives are consistently easy or hard across queries. The hard negatives drive the majority of learning in CID. However, the negatives are ranked independently for each query, so a hard negative for one query may be easy for another. Alternatively, are there negatives that are consistently hard or easy across queries? To test this, we started by measuring the percentage of queries for which each negative was hard, i.e. in the hardest 5%. In Figure <ref type="figure">6</ref>, we plot the pdf of the frequency with which each negative is hard; the median is 5% by definition. As a baseline for comparison, we randomized the negatives for each query to a) 0-10% 10-20% 20-30% 30-40% 40-50% 50-60% 60-70% 70-80% 80-90% 90-100%</p><p>Relative negative difficulty (larger is harder) 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 P(negative label = query label) (%) Figure <ref type="figure">5</ref>: Semantic similarity increases with easier negatives, for easy negatives, which have dot product less than zero with query Proportion of shared labels (higher is more similar) (a) and WordNet similarity from root to least common ancestor (lower is more similar) (b) decrease with easier negatives, for the easy half of negatives. Average negative distance is negative for the easy half of negatives (c). Error bars are standard deviation on plot values across 3 seeds (for b and c, error bars are so small they are not visible).</p><p>approximate the distribution we would expect by chance (orange in Figure <ref type="figure">6</ref>). The real data distribution (blue) is broader than that expected by chance, so that are indeed negatives that are more consistently hard and easy than we would expect by random chance. We hypothesize that maintaining consistently hard negatives in the queue and removing consistently easy ones could improve learning.</p><p>5 Related work Figure <ref type="figure">6</ref>: There exist negatives that are consistently harder or easier than expected by chance. Distribution of negatives based on the proportion of positives for which a negative is in the hardest 5% for the real data (blue) compared to the distribution obtained by shuffling the negatives for each query (orange).</p><p>Contrastive instance discrimination. Recently, CID has been utilized in a number of works including NPID <ref type="bibr" target="#b33">(Wu et al., 2018)</ref>, CMC <ref type="bibr">(Tian et al., 2019)</ref>, Moco <ref type="bibr" target="#b18">(He et al., 2019)</ref>, SimCLR <ref type="bibr" target="#b9">(Chen et al., 2020a)</ref>, MoCo v2 <ref type="bibr" target="#b11">(Chen et al., 2020c)</ref>, in chronological order. Inspired by its impressive performance, recent works have tried to understand CID from a variety of perspectives. In particular, <ref type="bibr" target="#b26">Tian et al. (2020)</ref> investigate the degree of shared information between two augmentations and how it connects to downstream performance, <ref type="bibr" target="#b30">Wang &amp; Isola (2020)</ref> suggest that contrastive objectives implicitly try to align similar instances while uniformly utilizing the embedding space, and <ref type="bibr" target="#b0">Arora et al. (2019)</ref> propose a theoretical framework for understanding contrastive learning. Recent work attempted to mitigate the effects of same-class negatives via a reweighting scheme <ref type="bibr" target="#b12">(Chuang et al., 2020)</ref>, but does not study negatives by difficulty, which is our focus here.</p><p>Non-instance-discrimination self-supervised learning methods. Beyond CID, a number of other approaches for self-supervised have been proposed that do not work within the CID paradigm, including RotNet <ref type="bibr" target="#b15">(Gidaris et al., 2018)</ref>, Jigsaw <ref type="bibr" target="#b22">(Noroozi &amp; Favaro, 2016)</ref>, DeepCluster <ref type="bibr" target="#b7">(Caron et al., 2018)</ref>, SwAV <ref type="bibr" target="#b8">(Caron et al., 2020)</ref>, SeLa <ref type="bibr" target="#b2">(Asano et al., 2020)</ref>, PCL <ref type="bibr" target="#b20">(Li et al., 2020)</ref>, and BYOL <ref type="bibr" target="#b16">(Grill et al., 2020)</ref>. Since these do not employ negatives in the same way as CID, our results do not directly relate to these methods.</p><p>Hard negative mining. It is a recurring theme in the machine learning literature to focus training on the most difficult examples. In active learning, for example, it is common to favor examples on which the model is most uncertain <ref type="bibr" target="#b14">(Fu et al., 2013)</ref>. Work in object detection has also benefited from efforts to find hard examples <ref type="bibr" target="#b25">(Sung, 1996;</ref><ref type="bibr">Canévet &amp; Fleuret, 2015;</ref><ref type="bibr" target="#b24">Shrivastava et al., 2016)</ref>. However, none of the aforementioned work explicitly involves negative examples as in CID.</p><p>Closest to CID is work on metric learning, where the goal is to learn a representation for each example that is conducive to clustering <ref type="bibr" target="#b19">(Kaya &amp; Bilge, 2019)</ref>. A standard approach is to use a triplet loss, where the loss encourages representing a query (often called an anchor) example in a fashion that is close to positive examples from the same class and far from negative examples from other classes <ref type="bibr" target="#b31">(Weinberger &amp; Saul, 2009)</ref>. In this paradigm, selecting the hardest <ref type="bibr" target="#b5">(Bucher et al., 2016)</ref> or harder <ref type="bibr" target="#b23">(Schroff et al., 2015)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>Contrastive instance discrimination relies critically on a pool of negatives to learn representations. We studied how effective various subsets of the negatives are in accomplishing this task. As illustrated in Figure <ref type="figure">1</ref>, we found that the utility of negatives varies dramatically by difficulty: the vast majority (easiest ∼ 95%) of negatives are insufficient without the remaining 5% and are unnecessary when those 5% are included (Section 3). Moreover, we found that the hardest negatives were actually harmful to performance and that this could be accounted for by an over-representation of same-class negatives. To understand why hard negatives are so helpful, we showed that the hard negatives are more semantically similar to the query than the easy negatives (Section 4). We also found that there exist easy negatives that are both anti-correlated and semantically similar to the query, and that some of the negatives are consistently easy or hard across queries. Many of these observations are in line with what has been found in other contexts on hard negative mining for metric learning, where accuracy and sample complexity have improved through judicious negative selection methods. We believe that the insights from our work may motivate approaches that yield similar benefit in CID.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Limitations and Future Work</head><p>While we focused our experiments on MoCo v2, we believe similar results may be observed for other CID frameworks. However, we leave this to future work along with a study of other downstream tasks. It is also possible that the lessons learned here may be useful for non-CID based approaches such as SwAV <ref type="bibr" target="#b8">(Caron et al., 2020)</ref> and PCL <ref type="bibr" target="#b20">(Li et al., 2020)</ref>.</p><p>One of our most surprising findings was that there exist negatives that are anti-correlated with the query and also more semantically similar to it than average. This seems undesirable from the perspective of a linear readout. Why would the network learn to anti-align two closely related concepts? Understanding the role of such negatives and discovering whether this behavior can be exploited or corrected is an important direction for future work.</p><p>Another avenue for future investigation is to explore the use of curricula for negative difficulty. For example, a larger quantity of easy negatives may be useful during the early stages of training while harder negatives are more useful later. While developing a negative curriculum is beyond the scope of this work, curricula have shown utility in many other contexts <ref type="bibr" target="#b3">(Bengio et al., 2009)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head><p>A </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Easy negatives are neither necessary nor sufficient, while hard negatives are both necessary and sufficient. a-b) Top-1 (a) and Top-5 (b) performance of networks trained on only segments of 5% of negatives ordered by difficulty. For example, 95-100% means that only the top 5% hard negatives were used for training. c-d) Top-1 (c) and Top-5 (d) performance of networks trained on increasingly larger fractions of the easiest negatives. Error bars are standard deviation across 3 seeds. a)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The hardest 0.1% of negatives hurt, especially at lower temperatures. Top-1 (a) and Top-5 (b) accuracy of networks trained on all but hard and hardest negatives, at different temperatures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>± 0.31 85.86 ± 0.12 67.48 ± 0.07 87.93 ± 0.05 Remove 0.1% hardest 66.25 ± 0.23 86.98 ± 0.09 67.64 ± 0.22 87.88 ± 0.07 Remove same class 66.61 ± 0.10 86.96 ± 0.07 68.07 ± 0.12 88.30 ± 0.15 Remove 0.1% hardest ∩ same class 66.43 ± 0.04 86.78 ± 0.06 67.67 ± 0.02 88.09 ± 0.18 Remove 0.1% hardest ∩ different class 63.69 ± 0.04 85.44 ± 0.00 67.38 ± 0.06 87.86 ± 0.08 Remove 99.9% easiest ∩ same class 65.06 ± 0.11 85.91 ± 0.01 67.79 ± 0.07 88.05 ± 0.05 The hardest 0.1% negatives hurt because of same-class negatives: Downstream accuracy when removing negatives of same/different class as the query and easier/hardest negatives at different temperatures. At temperature 0.07, accuracy improves when removing same-class negatives and/or hard negatives. At temperature 0.2 (default), there is a similar but smaller effect.</figDesc><table><row><cell></cell><cell cols="2">Temperature = 0.07</cell><cell cols="2">Temperature = 0.2</cell></row><row><cell></cell><cell>Top 1 Acc</cell><cell>Top 5 Acc</cell><cell>Top 1 Acc</cell><cell>Top 5 Acc</cell></row><row><cell>Baseline (remove none)</cell><cell>64.78</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>negatives has improved both the rate of learning and final performance. Similar to our findings about MoCo,<ref type="bibr" target="#b32">Wu et al. (2017)</ref> find that mining the very hardest negatives hurts performance (purportedly because it increases the variance of the gradients) and suggest mining harder (but not the hardest) negatives instead.Example importance in classification. In contrast to our work and the aforementioned work on hard negative mining in metric learning, nearly all examples are necessary in image classification. No paper that we are aware of could eliminate more than 20% of examples fromCIFAR-10 (Toneva et al., 2018)  or 10% from ImageNet<ref type="bibr" target="#b29">(Vodrahalli et al., 2018;</ref><ref type="bibr" target="#b4">Birodkar et al., 2019)</ref> without decreases in accuracy. However, not all examples are learned at the same time: the networks learn "easy" examples first<ref type="bibr" target="#b1">(Arpit et al., 2017;</ref><ref type="bibr" target="#b21">Mangalam &amp; Prabhu, 2019)</ref> and "hard" examples later in training. However, our notions of easy, hard, and necessary are different than this work: we determine these qualities on a per-query basis (meaning different examples can be easy or hard for different queries) while this work assigns these qualities to specific examples for all of training or across training runs.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table A1 :</head><label>A1</label><figDesc>.1 Additional necessity/sufficiency results (%) 19.47 ± 12.83 51.89 ± 1.00 66.69 ± 0.16 Top 5 accuracy (%) 36.78 ± 17.93 75.44 ± 0.74 87.35 ± 0.09 (%) 67.22 ± 0.21 67.15 ± 0.10 67.32 ± 0.88 Top 5 accuracy (%) 87.67 ± 0.09 87.60 ± 0.02 87.52 ± 0.63 Extended sufficiency results, 3 seeds each. (%) 67.56 ± 0.12 67.53 ± 0.20 62.1 ± 0.24 Top 5 accuracy (%) 87.98 ± 0.12 87.94 ± 0.12 84.0 ± 0.15 Top 1 accuracy (%) 47.91 ± 0.79 56.96 ± 0.36 61.95 ± 0.16 Top 5 accuracy (%) 72.13 ± 0.83 80.14 ± 0.20 83.87 ± 0.28</figDesc><table><row><cell>Train on only</cell><cell>85-90%</cell><cell>90-95%</cell><cell>95-100%</cell></row><row><cell>Top 1 accuracy Train on only</cell><cell>85-100%</cell><cell>90-100%</cell><cell>95-100%</cell></row><row><cell>Top 1 accuracy Train on all except</cell><cell>85-90%</cell><cell>90-95%</cell><cell>95-100%</cell></row><row><cell>Top 1 accuracy Train on all except</cell><cell>85-100%</cell><cell>90-100%</cell><cell>95-100 %</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table A2 :</head><label>A2</label><figDesc>Extended necessity results, 3 seeds each.A.2 Most correlated and most anti-correlated classes</figDesc><table><row><cell cols="2">Mean dot product Negative Class</cell><cell>Positive Class</cell></row><row><cell>-0.591357</cell><cell cols="2">Ibizan hound, Ibizan Podenco keeshond</cell></row><row><cell>-0.572822</cell><cell>Italian greyhound</cell><cell>Kerry blue terrier</cell></row><row><cell>-0.562565</cell><cell>macaw</cell><cell>ruddy turnstone</cell></row><row><cell>-0.494559</cell><cell>Staffordshire bullterrier</cell><cell>affenpinscher</cell></row><row><cell>-0.487417</cell><cell>box turtle, box tortoise</cell><cell>nematode</cell></row><row><cell>-0.476078</cell><cell>briard</cell><cell>refrigerator</cell></row><row><cell>-0.471706</cell><cell>Border collie</cell><cell>Mexican hairless</cell></row><row><cell>-0.467100</cell><cell>dalmatian</cell><cell>chow, chow chow</cell></row><row><cell>-0.460264</cell><cell>sports car</cell><cell>steam locomotive</cell></row><row><cell>-0.459015</cell><cell>Staffordshire bullterrier</cell><cell>Tibetan terrier</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table A3 :</head><label>A3</label><figDesc>Most anti-correlated classes. Mean dot product was computed pairwise across each pair of classes.</figDesc><table><row><cell cols="2">Mean dot product Negative Class</cell><cell>Positive Class</cell></row><row><cell>0.923779</cell><cell>monarch</cell><cell>daisy</cell></row><row><cell>0.901869</cell><cell>ground beetle</cell><cell>dung beetle</cell></row><row><cell>0.856066</cell><cell>rifle</cell><cell>rubber eraser</cell></row><row><cell>0.823796</cell><cell cols="2">entertainment center home theater</cell></row><row><cell>0.798866</cell><cell>minibus</cell><cell>police van</cell></row><row><cell>0.795254</cell><cell>bee</cell><cell>monarch,</cell></row><row><cell>0.794521</cell><cell>maillot</cell><cell>swimming trunks</cell></row><row><cell>0.789350</cell><cell>airliner</cell><cell>wing</cell></row><row><cell>0.789099</cell><cell>altar</cell><cell>organ, pipe organ</cell></row><row><cell>0.786902</cell><cell>dogsled</cell><cell>ski</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table A4 :</head><label>A4</label><figDesc>Most correlated classes. Mean dot product was computed pairwise across each pair of classes.</figDesc><table><row><cell cols="3">Mean dot product Negative Class Positive Class</cell></row><row><cell>-1.112930e-07</cell><cell>hog</cell><cell>totem pole</cell></row><row><cell>-2.239249e-07</cell><cell>canoe</cell><cell>tennis ball</cell></row><row><cell>6.617499e-07</cell><cell cols="2">Great Pyrenees knot</cell></row><row><cell>6.956980e-07</cell><cell>magpie</cell><cell>Cardigan</cell></row><row><cell>-7.122289e-07</cell><cell>china cabinet</cell><cell>running shoe</cell></row><row><cell>-7.863385e-07</cell><cell>spiny lobster</cell><cell>balance beam</cell></row><row><cell>8.588731e-07</cell><cell>screwdriver</cell><cell>sunglasses</cell></row><row><cell>-8.760835e-07</cell><cell>limpkin</cell><cell>packet</cell></row><row><cell>8.906354e-07</cell><cell>impala</cell><cell>coho</cell></row><row><cell>-9.792857e-07</cell><cell>boathouse</cell><cell>television</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table A5 :</head><label>A5</label><figDesc>Most orthogonal classes. Mean dot product was computed pairwise across each pair of classes.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0">We removed sets of negatives by treating them as through they were not present in the queue.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1">For this section, to remove a set of negatives, we replace them with slightly older negatives, so that the total number of negatives used does not change. To accommodate this change, the queue is made slightly larger, with the additional length remaining unused except to replace negatives we want to remove.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2">For this section, we randomly select 2000 images as queries and 2000 as negatives, and use the trained nonmomentum encoder at 200 epochs on both.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">A theoretical analysis of contrastive unsupervised representation learning</title>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hrishikesh</forename><surname>Khandeparkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Khodak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orestis</forename><surname>Plevrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikunj</forename><surname>Saunshi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A closer look at memorization in deep networks</title>
		<author>
			<persName><forename type="first">Devansh</forename><surname>Arpit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stanisław</forename><surname>Jastrzebski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emmanuel</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Maxinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tegan</forename><surname>Kanwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asja</forename><surname>Maharaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05394</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Self-labelling via simultaneous clustering and representation learning</title>
		<author>
			<persName><forename type="first">Yuki-Markus</forename><surname>Asano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Rupprecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=Hyx-jyBFPr" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Curriculum learning</title>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jérôme</forename><surname>Louradour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="DOI">10.1145/1553374.1553380</idno>
		<ptr target="https://doi.org/10.1145/1553374.1553380" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Conference on Machine Learning, ICML &apos;09</title>
				<meeting>the 26th Annual International Conference on Machine Learning, ICML &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Semantic redundancies in image-classification datasets: The 10% you don&apos;t need</title>
		<author>
			<persName><forename type="first">Vighnesh</forename><surname>Birodkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hossein</forename><surname>Mobahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.11409</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hard negative mining for metric learning based zeroshot classification</title>
		<author>
			<persName><forename type="first">Maxime</forename><surname>Bucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stéphane</forename><surname>Herbin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frédéric</forename><surname>Jurie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="524" to="531" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Efficient sample mining for object detection</title>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="48" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Unsupervised learning of visual features by contrasting cluster assignments</title>
		<author>
			<persName><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Big self-supervised models are strong semi-supervised learners</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<date type="published" when="2020">2020b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Improved baselines with momentum contrastive learning</title>
		<author>
			<persName><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020c</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Ching-Yao</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Yen-Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Debiased contrastive learning</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
				<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A survey on instance selection for active learning</title>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingquan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and information systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="249" to="283" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Praveer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=S1v4N2l0-" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Bootstrap your own latent: A new approach to selfsupervised learning</title>
		<author>
			<persName><forename type="first">Jean-Bastien</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florent</forename><surname>Altché</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Corentin</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><forename type="middle">H</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><surname>Avila Pires</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaohan</forename><surname>Daniel Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><forename type="middle">Gheshlaghi</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bilal</forename><surname>Piot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michal</forename><surname>Valko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Noise-contrastive estimation: A new estimation principle for unnormalized statistical models</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvärinen</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v9/gutmann10a.html" />
	</analytic>
	<monogr>
		<title level="m">JMLR Workshop and Conference Proceedings</title>
				<meeting><address><addrLine>Sardinia, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-05">May 2010</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="13" to="15" />
		</imprint>
	</monogr>
	<note>Chia Laguna Resort</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep metric learning: A survey</title>
		<author>
			<persName><forename type="first">Mahmut</forename><surname>Kaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hasan S ¸akir</forename><surname>Bilge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Symmetry</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">1066</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Prototypical contrastive learning of unsupervised representations</title>
		<author>
			<persName><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">Karttikeya</forename><surname>Mangalam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uday</forename><surname>Vinay</surname></persName>
		</author>
		<author>
			<persName><surname>Prabhu</surname></persName>
		</author>
		<title level="m">Do deep neural networks learn shallow learnable examples first? ICML Workshop on Deep Phenomena</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Favaro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
				<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Training region-based object detectors with online hard example mining</title>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
				<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="761" to="769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning and example selection for object and pattern detection</title>
		<author>
			<persName><forename type="first">Kah-Kay</forename><surname>Sung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Yonglong Tian, Dilip Krishnan, and Phillip Isola. Contrastive multiview coding</title>
				<imprint>
			<date type="published" when="1996">1996. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">What makes for good views for contrastive learning</title>
		<author>
			<persName><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Mariya</forename><surname>Toneva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Remi</forename><surname>Tachet Des Combes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">J</forename><surname>Gordon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.05159</idno>
		<title level="m">An empirical study of example forgetting during deep neural network learning</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Representation learning with contrastive predictive coding</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Are all training examples created equal? an empirical study</title>
		<author>
			<persName><forename type="first">Kailas</forename><surname>Vodrahalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.12569</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Understanding contrastive representation learning through alignment and uniformity on the hypersphere</title>
		<author>
			<persName><forename type="first">Tongzhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Distance metric learning for large margin nearest neighbor classification</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Kilian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><forename type="middle">K</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Sampling matters in deep embedding learning</title>
		<author>
			<persName><surname>Chao-Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><surname>Krahenbuhl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
				<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2840" to="2848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Unsupervised feature learning via non-parametric instance-level discrimination</title>
		<author>
			<persName><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
