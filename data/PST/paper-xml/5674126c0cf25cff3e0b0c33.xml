<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Student Member, IEEE</roleName><forename type="first">Yi</forename><surname>Chen</surname></persName>
							<email>ychen3@ntu.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Centre of Excellence in IC Design (VIRTUS)</orgName>
								<orgName type="department" key="dep2">School of Electrical and Electronic Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<postCode>639798</postCode>
									<settlement>Singapore</settlement>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Student Member, IEEE</roleName><forename type="first">Enyi</forename><surname>Yao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Centre of Excellence in IC Design (VIRTUS)</orgName>
								<orgName type="department" key="dep2">School of Electrical and Electronic Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<postCode>639798</postCode>
									<settlement>Singapore</settlement>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Arindam</forename><surname>Basu</surname></persName>
							<email>arindam.basu@ntu.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Centre of Excellence in IC Design (VIRTUS)</orgName>
								<orgName type="department" key="dep2">School of Electrical and Electronic Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<postCode>639798</postCode>
									<settlement>Singapore</settlement>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D26E9CDE5FAB48AD98708EE56384986F</idno>
					<idno type="DOI">10.1109/TBCAS.2015.2483618</idno>
					<note type="submission">received April 17, 2015; revised August 06, 2015; accepted September 18, 2015. This paper was recommended by Associate Editor J. Van der Spiegel.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Brain-machine interfaces</term>
					<term>extreme learning machine</term>
					<term>implant</term>
					<term>machine learning</term>
					<term>motor intention</term>
					<term>neural decoding</term>
					<term>neural network</term>
					<term>portable</term>
					<term>very large scale integration (VLSI)</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Currently, state-of-the-art motor intention decoding algorithms in brain-machine interfaces are mostly implemented on a PC and consume significant amount of power. A machine learning coprocessor in 0.35-m CMOS for the motor intention decoding in the brain-machine interfaces is presented in this paper. Using Extreme Learning Machine algorithm and low-power analog processing, it achieves an energy efficiency of 3.45 pJ/MAC at a classification rate of 50 Hz. The learning in second stage and corresponding digitally stored coefficients are used to increase robustness of the core analog processor. The chip is verified with neural data recorded in monkey finger movements experiment, achieving a decoding accuracy of 99.3% for movement type. The same coprocessor is also used to decode time of movement from asynchronous neural spikes. With time-delayed feature dimension enhancement, the classification accuracy can be increased by 5% with limited number of input channels. Further, a sparsity promoting training scheme enables reduction of number of programmable weights by .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>B RAIN-MACHINE INTERFACES (BMI) are becoming increasingly popular over the last decade and open up the possibility of neural prosthetic devices for patients with paralysis or in locked-in state. As depicted in Fig. <ref type="figure" target="#fig_0">1</ref>, a typical implanted BMI consists of a neural recording IC to amplify, digitize and transmit neural action potentials (AP) recorded by the micro-electrode array (MEA). Significant effort has been dedicated to develop energy efficient neural recording channel in recent years for long-term operation of the implanted devices <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b3">[4]</ref>. Some recent solutions have also integrated AP detection <ref type="bibr" target="#b4">[5]</ref>- <ref type="bibr" target="#b7">[8]</ref> and spike sorting features <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b10">[11]</ref>. However, in order to produce an actuation command (e.g., for a prosthetic arm), the subsequent step of motor intention decoding is required to map spike train patterns acquired in the neural recording to the motor intention of the subjects. Though various elaborate models and methods of motor intention decoding have been developed in past decades with the goal of achieving high decoding performance <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b13">[14]</ref>, the state-of-the art neural signal decoding are mainly conducted on PC consuming a considerable amount of power and making it impractical for the long-term use. With on-chip real-time motor intention decoding, the size and the power consumption of the computing device can be reduced effectively and the solution becomes truly portable. Furthermore, integrating the neural decoding algorithm with the neural recording device is also desired to reduce the wireless data transmission rate and make the implanted BMI solution scalable as required in the future <ref type="bibr" target="#b14">[15]</ref>. Until now, very few attempts have been made to give a solution for this problem. A low-power motor intention architecture using analog computing is proposed in <ref type="bibr" target="#b15">[16]</ref>, featuring an active filtering with massive parallel computing through low power analog filters and memories. However, no measurement results are published to support the silicon viability of the architecture. A more recent work proposes a universal computing architecture for the neural signal decoding <ref type="bibr" target="#b16">[17]</ref>. The architecture is implemented on a FPGA with a power consumption of 537 W.</p><p>In this paper, we present a machine learning coprocessor (MLCP) achieving low-power operation through massive parallelism, sub-threshold analog processing and careful choice of algorithm. Fig. <ref type="figure" target="#fig_0">1</ref> contrasts our approach with traditional approaches: our MLCP acts in conjunction with the digital signal processor (DSP) already present in implants (for spike sorting, detection and packetizing) to provide the decoded outputs. The bulk of processing is done on the MLCP while simple digital functions are performed on the DSP. Compared to traditional designs that perform the decoding outside the implant, our envisioned system that provides opportunity for huge data compression by integrating the decoder in the implant. The MLCP is characterized by measurement and the decoding performance of the proposed design is verified with data acquired in individuate finger movements experiment of monkeys. Some initial results of this work were presented in <ref type="bibr" target="#b17">[18]</ref>. Here, we present more detailed theory, experimental results including decoding time of movement, new sparsity promoting training and also discuss scalability of this architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PROPOSED DESIGN: ALGORITHM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Extreme Learning Machine</head><p>1) Network Architecture: The machine learning algorithm used in this design is Extreme Learning Machine (ELM) proposed in <ref type="bibr" target="#b18">[19]</ref>. As depicted in Fig. <ref type="figure" target="#fig_1">2</ref>(a), The ELM is essentially a single hidden-layer feed-forward network (SLFN). The k-th output of the network can be expressed as follows: <ref type="bibr" target="#b0">(1)</ref> where denotes the input feature vector, is the number of hidden neurons, is the output of the hidden layer, is the bias for each hidden layer node, and are input and output weights respectively. A non-linear activation function is needed for non-linear classification. A special case of the nonlinear function is the additive node defined by . The above equation can be compactly written for all classes as where denotes the matrix of output weights. While the output can be directly used in regression, for classification tasks the input is categorized as the k-th class if is the largest output. Formally, we can define the classification output as an integer class label given by . Intuitively, we can think of the first layer as creating a set of random basis functions while the second layer chooses how to combine these functions to match a desired target. Of course, if we could choose the basis functions through training as well, we would need less number of such functions. But the penalty to be paid is longer training times. More details about the algorithm can be found in <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>.</p><p>2) Training Methods: The special property of the ELM is that can be random numbers from any continuous probability distribution and remains unchanged after initiation <ref type="bibr" target="#b18">[19]</ref>, while only needs to be trained and stored with high resolution. Therefore the training of this SLFN reduces to finding a least-square solution of given the desired target values in a training set. We will next show two methods of training-the conventional one (T1) for improved generalization as well as a second method (T2) that promotes sparsity. For simplicity, we show the solution of weights for one output -the same method can be extended to other output weights as well and can be represented in a compact matrix equation <ref type="bibr" target="#b18">[19]</ref>.</p><p>Suppose there are training samples-then we can create a hidden layer output matrix where each row of has the hidden layer neuron output for each training sample. Let be the vector of target values for the samples. With these inputs, the two training methods are shown in Fig. <ref type="figure" target="#fig_2">3</ref>. The step for norm minimization can be solved directly with the solution given by where is the Moore-Penrose generalized inverse of the matrix . Hence, training can happen quickly in this case. The norm minimization step in T2 however has to be performed using standard optimization algorithms like LARS <ref type="bibr" target="#b20">[21]</ref>. Thus T2 provides reduced hardware complexity due to reduction in the number of hidden neurons at the cost of increased training time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Neural Decoding</head><p>The neural decoding algorithm we use is inspired by the method in <ref type="bibr" target="#b21">[22]</ref>. We replace the committee of ANN in their work with ELM in our case. Three specific advantages of the ELM for this application are 1) the fixed random input weights can be realized by a current mirror array exploiting fabrication mismatch of the CMOS process; 2) one-step training that is necessary for quick weight update to address change in input statistics, and 3) the hidden layer outputs can be reused for multiple operations on the same input data . In this case, we have reused to classify both the onset time and type of movement. One disadvantage of the ELM algorithm is the usage of hidden neurons compared to fully tuned architectures (e.g., SVM, AdaBoost) since the hidden nodes in ELM only create random projections that are not fine tuned <ref type="bibr" target="#b22">[23]</ref>. However, implementing random weights results in more than savings over fully tunable weights making this architecture more lucrative overall. Next, we give an overview of the decoding algorithm while the reader is pointed to <ref type="bibr" target="#b21">[22]</ref> for more details.</p><p>1) Movement Type and Onset Time Decoding: Fig. <ref type="figure" target="#fig_1">2</ref>(b) depicts how the ELM is used in neural decoding. Even though the input is an asynchronous spike train, the ELM produces classification outputs at a fixed rate of once every seconds. The input is created from the firing rate of spike trains of biological neurons by finding the moving average over a duration . Hence, we can define the firing rate of i-th neuron at time instant as where ms and ms following <ref type="bibr" target="#b21">[22]</ref>. Finally, where there are biological neurons in the recording . As shown in Fig. <ref type="figure" target="#fig_1">2</ref>(b), we have output neurons in this case where there are movement types to be decoded. The -th neuron is used to decode the onset time of movement. For decoding type of movement, we can directly use the method described in the earlier Section II.A for -class classifier to get the predicted output class at time as . For decoding movement onset time, we further create a binary classifier that reuses the same hidden layer but adds an extra output neuron. Similar to <ref type="bibr" target="#b21">[22]</ref>, this output is trained for regression-the target is a trapezoidal fuzzy membership function which gradually rises from 0 to 1 representing the gradual evolution of biological neural activity. This output is thresholded to produce the final output at time as</p><formula xml:id="formula_0">(2)</formula><p>where is a threshold optimized as a hyperparameter. Moreover, to reduce spurious classification and produce a continuous output, the primary output is processed to create that is high only if is high for at least times over the last time points. Further, to reduce false positives, another detection is prohibited for ms after a valid one. The final decoded output, is obtained by a simple combination of the two classifiers as .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Time Delay Based Dimension Increase (TDBDI):</head><p>A common problem in long-term neural recording is the loss of information from electrodes over time due to tissue reactions such as gliosis, meningitis or mechanical failures <ref type="bibr" target="#b23">[24]</ref>. Hence, initially functional electrodes may not provide information later on. To retain the quality of decoding, we propose a method commonly used in time series analysis-the use of information from earlier time points <ref type="bibr" target="#b24">[25]</ref>. In the context of neural decoding, it means that we use more information from the dynamics of neural activity in functional electrodes in place of lost information from the instantaneous values of activity in previously functional electrodes. So if we use previous values from the functional electrodes, the new feature vector is given by (3) IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS where the input dimension of the ELM is given by . This is a novel algorithmic feature in our work compared to <ref type="bibr" target="#b21">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED DESIGN: HARDWARE IMPLEMENTATION</head><p>Fig. <ref type="figure" target="#fig_0">1</ref> shows a typical usage scenario for our MLCP where it works in tandem with the DSP and performs the intention decoding. The DSP only needs to send very simple control signals to the MLCP and performs the calculation of the second stage of ELM (multiplication by learned weights ). The input to the MLCP comes from spike sorting that can be performed on the DSP <ref type="bibr" target="#b9">[10]</ref>. In some cases, spike sorting may not be needed and spike detection may be the only required pre-processing <ref type="bibr" target="#b23">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Architecture</head><p>Details and timing of the MLCP are shown in Fig. <ref type="figure" target="#fig_3">4</ref>. We map input and hidden layers of ELM into the MLCP fabricated in AMS 0.35m CMOS process, where high computation efficiency is achieved by exploiting fabrication mismatch abundantly found in analog devices, while the output layer that requires precision and tunability (tough to attain in analog de-signs) can be implemented on the DSP. Since the number of computations in first stage far outnumbers those in the second (as long as</p><p>), such a system partition still retains the power efficiency of the analog design. Up to 128 input channels and 128 hidden layer nodes are supported by the MLCP, with each input channel embedding an input processing circuit that extracts input feature from the incoming spike trains. As mentioned in the earlier section, we extract a moving average of the spike count as the input feature of interest.</p><p>On receiving a spike from the neural amplifier array (after spike detection and/or spike sorting), the DSP sends a pulse via and 7-bit channel address to the DEMUX in the MLCP for row-decoding. Each row of the MLCP has a 6-bit window counter to count the total number of input spikes in a moving window with length of and a moving step of . The length of , normally set to 20 ms, is determined by the period of . The counter value in j-th row is converted into input feature current for the ELM, corresponding to the input in Fig. <ref type="figure" target="#fig_1">2</ref>. Furthermore, a 1-bit control signal stored in each row determines whether the j-th row's input to the moving window circuit is an external spike count or a delayed spike count from the previous channel. The delay length can be selected from among 5 delay steps ranging from 20 ms to 100 ms, based on . This is how the TDBDI feature described earlier is implemented in the MLCP.</p><p>The input feature current from each row is further mirrored into all hidden-layer nodes by a current mirror array. Hence, ratios of the current mirrors are essentially the input weights, and are inherently random due to fabrication mismatch of the transistors even when identical value is used in the design. We use sub-threshold current mirror to achieve very low power consumption, resulting in with denoting thermal voltage and denoting the threshold voltage mismatch between input transistor on j-th row and mirror transistor on i-th column of that row. This is similar to the concepts described in <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>. The input weights are log-normal distributed since follows a normal distribution. We therefore realize random input weights in a very low 'cost' way that requires only one transistor per weight. It is the fixed random input weights of the ELM that makes this unique design possible. A capacitance fF on each row sets the SNR of the mirroring to 43 dB.</p><p>The hidden layer node is implemented by a current controlled oscillator (CCO) driving a 14-bit counter with a 3-bit programmable stop value to implement a saturating nonlinearity in the activation function . The advantage of choosing this nonlinearity is that it can be digitally set and also some neurons can be configured to be linear as well to achieve good performance in linearly separable problems <ref type="bibr" target="#b27">[28]</ref>. The computation of hidden layer nodes is activated by setting NEU high. The output of CCO is a pulse frequency modulated signal with the frequency proportional to total input current. The counter outputs are latched and serially read using the signal when NEU is low with CCO disabled to save power. The output weights, , are stored on the DSP where the final output is calculated. Thus the MLCP performs the bulk of MACs while the DSP only performs MACs of the output layer. It should be noted here, the output of hidden layer neurons changes with power supply voltage due to sensitivity of the CCO frequency to power supply variation, leading to degradation of the decoding accuracy. However, since power supply variation is a common-mode component to all CCOs, normalization methods can be applied in post-processing (see Section IV.E.4) to the hidden layer outputs to reduce the effect introduced by power supply variation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Sub-Circuit: Input Processing</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Sub-Circuit: Current Controlled Oscillator</head><p>The diagram of the current controlled oscillator (CCO) is depicted in Fig. <ref type="figure" target="#fig_4">5(c</ref>). The capacitance of fF sets oscillation frequency of this relaxation oscillator based on the summed input current while fF provides hysteresis through positive feedback. When NEU is pulled high, pFET is turned off. is used to set the leakage term in (1) and can be set to 0 for most cases.</p><p>from the current mirrors starts to discharge until it crosses the threshold voltage of the , leading to transition of all inverters. Then, is pulled down very quickly through a positive feedback loop formed by</p><p>. At the same time, turns on, charging towards until it crosses the threshold voltage of from low to high and the cycle repeats. Neglecting higher order effects, the time for each cycle of the CCO operation is determined by the sum of the charging and discharging time constant of , and can be expressed by <ref type="bibr" target="#b4">(5)</ref> where is the charging current when is on. Normally reducing (5) to (6)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. MEASUREMENT RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. MLCP Characterization</head><p>This section presents the measurement results from the MLCP fabricated in 0.35m CMOS process. To test the circuit, we have integrated it with a microcontroller unit or MCU (TI MSP430F5529) to act as the DSP. Though we have not integrated it with an implant yet, this setup does allow us to realistically assess performance of the MLCP with pre-recorded neural data as shown later. Moreover, the designed board is entirely portable with its own power supply and wireless TX-RX module (TI CC2500). Hence, it can be used as a portable external unit (PEU) for neural implant systems as well. As shown in Fig. <ref type="figure" target="#fig_6">6</ref>, the MLCP has a die area of 4.95 4.95 mm and the PEU measures 7.4 cm 5.1 cm.</p><p>For the characterization results shown next, we use V powering the reference circuits to generate bias currents and V for the rest.    experiment, shown in Fig. <ref type="figure">8</ref>, demonstrate percentage jitter less than 0.1% for the entire counting range. Next, we show characterization results for the input DAC channels. Since it is not possible to separately measure output current of the DAC, we measure the output of the CCO to infer the linearity of the DAC. This is reasonable since the linearity and the noise performance of the CCO is better than the 6 bit resolution of the DAC. Fig. <ref type="figure" target="#fig_8">9</ref> plots the measured differential non-linearity (DNL) of 64 randomly selected input DACs. The worst case DNL is approximately LSB. While this DNL can be part of the non-linearity in the general case, it makes the implementation of the additive node less accurate.</p><p>Variation in transfer curves of the CCO array is a result of random mismatch from various aspects of the circuits, mainly current mirror array, which is expected and desired in this design. By applying the same input spike frequency of 320 Hz to each row individually, a mismatch map of the CCO frequencies is generated nA, as presented in Fig. <ref type="figure" target="#fig_10">10</ref>   <ref type="table">I</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experiment</head><p>The neural data used to verify the decoding performance of the proposed design is acquired in a monkey finger movement experiment described in detail in <ref type="bibr" target="#b21">[22]</ref>. In the experiment, the IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Neural Decoding Performance</head><p>We have tested the MLCP based PEU using the data set mentioned above. A multiple-output ELM with number of classes is trained to identify the movement type of the trial.</p><p>An additional output is used to decode the onset time of movement. During training, the pre-recorded input spikes from biological neurons in M1 are sent to the MLCP the counter values of are wirelessly transmitted to a PC where and are calculated and communicated back. This process already includes non-idealities in the analog processor such as DNL of input DAC, non-linearity in CCO and early effect induced current addition errors-hence, the learning takes these effects into account and corrects for them appropriately. Then, the MLCP can run autonomously during testing phase.</p><p>We present decoding results in a format similar to <ref type="bibr" target="#b21">[22]</ref> for easy comparison wherever possible. For the first set of experiments, we use the normal training method T1 described in Section II-A.2. As shown in Fig. <ref type="figure" target="#fig_11">11(a) with</ref> , the decoding accuracy of the 12 types of movements (the flexion and extension of the fingers and wrist in one hand) increases as is increased, with a mean accuracy of 94.8% at . This trend is expected <ref type="bibr" target="#b18">[19]</ref> since more number of random projections should allow better separation of the classes till the point when the amount of extra information for a new projection is negligible. Based on this result, we fix for the rest of the experiments unless stated otherwise.</p><p>Next, we explore the variation in performance as number of available neural channels (or equivalently M1 neurons in this case) reduces while keeping fixed at 60. Fig. <ref type="figure" target="#fig_11">11(b)</ref> shows that an increase in accuracy from 85.4% to 91.7% can be obtained at</p><p>, by using delayed samples as added features (TDBDI). Here, we have used only one earlier sample-hence, and the effective input dimension of the ELM is . With and , a decoding accuracy of 99.3% can be achieved. Next, to check the robustness of the earlier result, the same experiment is performed using several different datasets, including individuated finger movement data from Monkey K, C and G and combined finger movement from Monkey K (12 individuate movements and 6 types of simultaneous movement of two fingers). The results of the MLCP with increasing M1 neurons, as shown in Fig. <ref type="figure" target="#fig_11">11(c</ref>), is consistent with software result in <ref type="bibr" target="#b21">[22]</ref>. The trend of increasing performance with more M1 neurons is expected since it provides more information. The performance of the proposed MLCP is also robust across eight sample chips, as presented in Fig. <ref type="figure" target="#fig_11">11(d)</ref> for the same experiment as in the last two cases.</p><p>The hidden layer output matrix is reused to decode the onset time of finger movement using the regression capacity of the ELM. As mentioned earlier, only one more output node is added to the ELM. The trapezoidal membership function described in Section II.B and shown in Fig. <ref type="figure" target="#fig_13">13(a</ref>) is set to 1 around the time of 1 s to indicate the onset and set to 0 where there is definitely no movement. Fig. <ref type="figure" target="#fig_12">12</ref> illustrates the finite state machine in the MCU to implement the post-processing described in Section II.B to obtain from the primary output . Optimal values of and ms can be found from the ROC curve shown in Fig. <ref type="figure" target="#fig_13">13(b</ref>). The nature of the ROC curves are again very similar to the ones in <ref type="bibr" target="#b21">[22]</ref>. With reused, we achieve real-time combined decoding by detecting when there is a movement in the trial and labeling the predicted movement type when a movement onset is detected. This is illustrated by a snapshot of the developed GUI in Fig. <ref type="figure" target="#fig_13">13(a)</ref>, where three 2-s trials are shown with 40-channel input spike trains recorded from M1 region printed at the bottom part of the figure. Primary, post-processed output and predicted movement type are also shown in the top half of the figure. Lastly we show the benefits of the sparsity promoting training method, T2 described in Section II-A.2. To show the benefit of this method, we compare with the first experiment shown earlier in Fig. <ref type="figure" target="#fig_11">11(a)</ref> where and the number of hidden layer neurons is varied to see its effect on performance. It can be seen that for the method T2, the decoding accuracy increases to approximately the maximum value of 94.8% attained by the method T1 for much fewer number of hidden layer neurons . This is possible because the sparsity promoting step of minimizing norm of output weights chooses the most relevant random projections in the hidden layer. Thus, the new method T2 can reduce power dissipation by approximately 50% due to reduction in number of hidden layer neurons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Power Dissipation</head><p>Finally, we report the power consumption of the proposed MLCP for the 40 input channels, 60 hidden layer nodes, 12-class classification problem. The current drawn from analog and digital power supply pins were measured using a Keithley picoammeter. The power breakup is shown in Fig. <ref type="figure" target="#fig_15">15</ref>. At the lowest value of V and V needed for robust operation, the total power dissipated is 414 nW with 54 nW from and 360 nW from . Performing  It is clear that the efficiency is limited by the fixed analog power that is amortized across the hidden layer neurons and current mirror multipliers. The fundamental limit of this architecture is the power dissipation of the CCO and current mirror array which is limited to 0.45 pJ/MAC.</p><p>In contrast, recently reported 16-bit digital multipliers consume 16-70 pJ/MAC <ref type="bibr" target="#b32">[33]</ref>- <ref type="bibr" target="#b35">[36]</ref> where we ignore the power consumed by the adder for simplicity. We have also implemented near threshold digital array multipliers in 65 nm CMOS operating at 0.65 V that resulted in energy efficiency of 11 pJ/MAC confirming the much lower energy attainable by analog solutions over digital ones. Moreover, implementing the MLCP computations in digital domain would incur further energy cost due to memory access (for getting the weight values) and clocking which are ignored here.</p><p>Since we implement the operation of second stage in digital domain, we need multiplications per classification. For the case of and described above and energy cost of 11 pJ/MAC for digital multiplies, the total energy cost of second stage operation is 7.92 nJ/classify. Hence, the total energy/classification becomes 16.22 nJ and the combined energy/operation increases to 5.2 pJ/MAC. For peak energy efficiency, we consider and resulting in a net energy/computation of 1.46 pJ/MAC including both stages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Discussion</head><p>1) Comparison: Our MLCP is compared with other recently reported machine learning systems in Table <ref type="table" target="#tab_0">II</ref>. Compared to the digital implementation of SVM in <ref type="bibr" target="#b28">[29]</ref>, our implementation achieves far less energy per MAC due to the analog implementation. Reference <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref> and <ref type="bibr" target="#b31">[32]</ref> achieve good energy efficiency similar to our method by using analog computing. Reference <ref type="bibr" target="#b30">[31]</ref> uses a multiplying DAC (MDAC) to perform the multiplication by weights-however, they have only 6 bit resolution in the multiply and also the MDAC occupies much larger area than the single transistor we use for multiplications. <ref type="bibr" target="#b29">[30]</ref> and <ref type="bibr" target="#b31">[32]</ref> use analog floating-gate transistors for the multiplication. Compared to these, our single transistor multiplier takes lesser area (no capacitors that are needed in floating-gates), does not require high voltages for programming charge and allows digital correction of errors because of the digital output.</p><p>2) Area Limits: Using a single transistor for multiplication in the first layer should provide area benefits over other schemes. The current layout (Fig. <ref type="figure" target="#fig_16">16</ref>) was done due to its simple connection patterns and is not optimized. It can be seen that the actual area of a unit transistor in the array (0.4 0.35 m ) is much less than the area of an unit cell in the layout which is limited by the pitch of the CCO and the window counter circuits. Moving to a highly scaled process or folding the placement of the output CCO layer to be parallel to the input window counter circuits would enable large reduction in the area of the current mirror array. The ultimate limit in terms of area for this architecture stems from the area of capacitors-for this 128 input, 128 output architecture, the total capacitor area is 0.132 mm .</p><p>3) Data Rate Requirements: When used in an implant with offline training, the MLCP can reduce transmission data rate drastically. Firstly, for direct transmission of 100 channel data sampled at 20 kHz with 10 bit resolution, required data rate is 20 Mbps. This massive data rate can be reduced partially by including spike sorting <ref type="bibr" target="#b10">[11]</ref>. In this case, assuming 8 bit address encoding a maximum of 256 biological neurons each firing at a rate , the data rate to be transmitted for a conventional implant without neural decoder is given by . As an example, with Hz, kbps. This can be reduced even further by integrating the decoder as proposed here. For the proposed case, the output of the decoder is obtained at a rate . During regular operation after training, the data rate for classes is given by . As an example, for the case described in Section IV.C with Hz and bps. This example, shows the potential for thousand fold data rate reductions over spike sorting by integrating the decoder in the implant.</p><p>From the viewpoint of power dissipation, the analog front end and spike detection can be accomplished within a power budget of 1 W per channel <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b4">[5]</ref>. Assuming a transmission energy of pJ/bit from recently reported wireless transmitters for implants <ref type="bibr" target="#b39">[39]</ref>- <ref type="bibr" target="#b41">[41]</ref>, the power dissipation for raw data rates of 200 kbps/channel and compressed data rates of 2 kbps/channel after spike sorting are 10 W and 0.1 W respectively. Hence, the power for wireless transmission is a bottleneck for systems transmitting raw data. For systems with spike sorting in the implant, this power dissipation is not a bottleneck. However, the power/channel needed for the spike sorter is about 5 W. In comparison, if our decoder operates directly on the spike detector output, it can provide compression at a power budget of W/channel. This would result in a total power dissipation/channel of W in our case compared to W in the case of spike sorting-a 6X reduction. There is a lot of evidence that the decoding algorithms can work on the spike detector output <ref type="bibr" target="#b23">[24]</ref>; in fact, it is believed that this will make the system more robust for long term use. This will be a subject of our future studies.</p><p>Even if the decoder is explanted, a MCU cannot provide sufficient throughput to support advanced decoding algorithms while FPGA based systems consume a large baseline power. A custom MLCP based solution provides an attractive combination of low-power and high throughput operation when paired with a flexible MCU for control flow.</p><p>4) Normalization for Increased Robustness: The variation of temperature is not a big concern in the case of implantable electronics since body temperature is well regulated. However, variation of power supply voltage can be a concern. A normalization method can be applied to the hidden layer output for reducing its variation due to power supply fluctuation, at the cost of additional computation. The normalization proposed here can be expressed by <ref type="bibr">(7)</ref> The rationale behind the proposed normalization is that the effect of power supply fluctuation on the hidden layer output can be modelled as multiplication factor in hidden layer output equation. As analyzed before, the output of the hidden layer node can be formulated as:</p><p>, where is the input current of the hidden layer node and is counting window length. Since is proportional to the strength of input vector , we can model the relation between the input vector and hidden layer output as:</p><p>, where the variation part is a multiplicative term , and lumps up the constant part of the path gain from input to th hidden layer output. It is reasonable to assume that is the same across different nodes, since fluctuation of power supply is a global effect on chip scale. Hence, it can be cancelled by the proposed normalization as <ref type="bibr" target="#b7">(8)</ref> Simulation results are presented here to verify the proposed method of normalization. The original hidden layer outputs are obtained by SPICE simulations where is swept from 0.6 V to 2.5 V and input changes from 8 to 10. Original and normalized values of one of the hidden layer outputs are compared in Fig. <ref type="figure" target="#fig_17">17</ref>. As can be observed here, the normalized output (in green dashed lines) varies significantly less due to variation of than the original output (in blue solid lines). The hardware cost for this normalization is additions and divisions. Assuming similar costs for division and multiplication, the normalization does not incur much overhead if since multiplications are required by the second stage anyway.</p><p>5) Considerations for Long Term Implants: When using this MLCP based decoder in long term implants, we have to consider issues of parameter drift over several time scales. Over long term of days, aging of the circuits in MLCP or probe impedance change due to gliosis and scarring may change performance. This is typically countered by retraining the decoder every day <ref type="bibr" target="#b23">[24]</ref>. Such retraining has allowed decoders to operate at similar level of performance over years. Over shorter time scales, any variation not sufficiently quenched by the normalization method described earlier can be explicitly calibrated by having digital multiplication of coefficients for every input and output channel. These can be determined periodically by injecting calibration inputs and observing the output of the CCO.</p><p>Another type of training-referred to as decoder retraining <ref type="bibr" target="#b42">[42]</ref>, <ref type="bibr" target="#b43">[43]</ref> are needed to take into account change in neural statistics during closed loop experiments. The training done here may be thought of as open loop training for initialization of coefficents of second stage of ELM. Next, the experiment has to be redone with closed loop feedback and new training data set has to be generated for retraining the second layer weights. After several such iterations, the final set of weights of second layer will be obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>We presented a MLCP in 0.35-m CMOS with a die area of 4.95 4.95 mm and a 7.4 cm cm PEU based on the proposed MLCP that achieves real-time motor intention decoding in an efficient way. Implementing the ELM algorithm, the MLCP utilizes massive parallel low power analog computing and hardware reuse, achieving a power consumption of 0.4 W at 50 Hz classification rate, resulting in an energy efficiency of 3.45 pJ/MAC. Learning in the second stage also compensates for non-idealities in the analog processor. Furthermore, It includes time-delayed sample based dimension increase feature for enhancing decoding performance when number of recorded neurons are limited. A sparsity promoting training method is shown to reduce the number of hidden layer neurons and output weights by %. We demonstrated the operation of the IC for decoding individuated finger movements using recordings of M1 neurons. However, the ELM algorithm used in the decoder is quite general and has been shown to be an universal approximator and equivalent to SVM or multi-layer perceptrons <ref type="bibr" target="#b19">[20]</ref>. Hence, our MLCP can also be used for other decoding applications requiring regression or classification computations. Higher dimensions of inputs and hidden layers can be handled by making a larger IC and also by reusing the same hidden layer several times. In either case, power dissipation increases but not energy/compute. Higher input dimensions can be accommodated at same power by reducing the bias current input of the splitter DACs in input channels <ref type="bibr" target="#b26">[27]</ref>. Increase of hidden layer neurons however do incur a proportional power increase. Given that the power requirement of the current decoder is lower than the AFE, we can easily extend it to handle many more input and output channels.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Comparison of envisioned and traditional implanted BMI. The envisioned system uses a machine learning coprocessor (MLCP) along with the DSP used in traditional neural implants to estimate motor intentions from neural recordings thus providing data compression. Traditional systems perform such decoding outside the implant and use bulky computers.</figDesc><graphic coords="1,307.88,166.64,81.19,99.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Algorithm. (a) The architecture of the Extreme Learning Machine (ELM) with one nonlinear hidden layer and linear output layer. (b) Use of ELM in neural decoding for classifying movement type and onset time of movement.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Training methods for ELM. T1 is the conventionally used training method to improve generalization by minimizing norm of weights as well as training error. T2 uses an additional step of sparsifying output weights to reduce the required hardware.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. (a) The diagram and (b) the timing of MLCP based neural decoder.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5</head><label>5</label><figDesc>Fig. 5 shows diagrams of the circuit blocks in the MLCP. Fig. 5(a) shows two adjacent input processing circuits with configured to receive an external spike train by setting and configured as time delay based channel by setting . The corresponding signal flows are also depicted in the figure by red dash lines. The moving window counter is realized by 1) counting spike in a sub-window in a length of ; 2) storing sub-window counter value in a delay chain made of shift registers; and 3) adding and subtracting previous 6-b output value with corresponding sub-window counter values in the delay chain to get new 6-b</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Fig. 7(a) verifies operation of the input processing by probing output of the window counter, with frequency of and input spike train being 20 Hz and 630 Hz respectively. The output, as labeled by , increases from 0 to 63 within 100 ms in the left half of Fig. 7(a). The TDBDI feature is shown in the right half of Fig. 7 based on setting of when . It adds a delay of 40 ms to the , comparing with waveforms in the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Die photo and test board. The die photo of MLCP fabricated in 0.35-m CMOS process and the portable external unit (PEU) integrating MLCP with MCU and battery.</figDesc><graphic coords="6,436.00,76.47,104.40,99.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .Fig. 8 .</head><label>78</label><figDesc>Fig. 7. Jitter performance. The variation in the counter output for a fixed value of input current is observed for 100 trials and plotted as a histogram for (a) low, (b) medium and (c) high input currents. The measured jitter is %.</figDesc><graphic coords="6,328.34,453.98,105.61,80.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. DNL performance. DNL of 64 randomly selected input DAC channels show LSB performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>(a), by reading out the quantized frequency values in the output counters. These frequencies are normalized to the median frequency and plotted in Fig. 10(b) and (c) to show conformance to the log-normal distribution as expected. The underlying random variable of has a normal distribution with mean and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. The random input weights. (a) Measured mismatch map of the CCO frequencies. (b) Distribution of input weights. (c). These values are measured by reading the output counter values when a fixed input value is given one row at a time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Measured movement types decoding performance. (a) Decoding accuracy versus number of hidden layer nodes. (b) Decoding accuracy versus number of M1 neurons (with/without TDBDI). (c) Decoding accuracy across monkeys. (d) Decoding accuracy across 8 dies;</figDesc><graphic coords="8,106.98,431.10,117.05,85.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Flow chart describing the finite state machine on DSP to calculate from .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Measured movement onset decoding results. (a) A segment of 40 channel input spike trains is shown with real-time decoding output deciding when a movement onset happens and which tpye is this onset. (b) ROC curves of onset decoding.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Advantage of Sparsity promoting training T2. The sparsity promoting method chooses best random projections and can reduce required number of hidden neurons by around 50%.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. Power breakup. Power dissipation in the MLCP is dominated by fixed analog power consumption of 360 nW compared to the power of 54 nW dissipated from in CCO and counter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Array Layout. The area of the current IC is limited by the pitch of the CCO and WINCNT circuits even though the actual area of the current mirrors (0.4 0.35 m ) are very small.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17. Normalization to reduce variation. Blue lines are original hidden layer output from SPICE simulation, while green dashed lines are normalized output in both (a) and (b). The input x in (a) and (b) are 8 and 10 respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="11,52.98,108.12,485.13,187.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE II COMPARISONTABLE</head><label>II</label><figDesc></figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank Dr. N. Thakor for providing neural recording data.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Enyi Yao (S'13) received the B.Eng. degree from the Harbin Institute of Technology, Harbin, China, in 2011.</p><p>Currently, he is working toward the Ph.D. degree in electrical and electronic engineering at Nanyang Technological University, Singapore. His research interest is mainly on low power analog, mixed-signal IC design, neuromorphic circuits design and low power smart sensor circuits design for biomedical applications. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Arindam</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A low-power integrated circuits for a wireless 100-electrode neural recording system</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Watkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Kier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">O</forename><surname>Lovejoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Greger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Solzbacher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Solid-State Circuits</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="123" to="133" />
			<date type="published" when="2007-01">Jan. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Low-power circuits for brain-machine interfaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sarpeshkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wattanapanitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Arfin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">I</forename><surname>Rapoport</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mandal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Fee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Musallam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Adersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Circuits Syst</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="173" to="183" />
			<date type="published" when="2008-09">Sep. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The 128-channel fully differnetial digital integrated neural recording and stimulation interface</title>
		<author>
			<persName><forename type="first">F</forename><surname>Shahrokhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Abdelhalim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Serletis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Carlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Genov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Circuits Syst</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="149" to="161" />
			<date type="published" when="2010-06">Jun. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A digitally assisted, signal folding neural recording amplifier</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rajkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dawe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Je</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Circuits Syst</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="528" to="542" />
			<date type="published" when="2014-08">Aug. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A 1 V, compact, current-mode neural spike detector with detection probability estimator in 65 nm CMOS</title>
		<author>
			<persName><forename type="first">E</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ISCAS</title>
		<meeting>IEEE ISCAS</meeting>
		<imprint>
			<date type="published" when="2015-05">May 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A micro-power neural spike detector and feature extractor in .13 um CMOS</title>
		<author>
			<persName><forename type="first">J</forename><surname>Holleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Diorio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Otis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Custom Integrated Circuits Conf</title>
		<meeting>IEEE Custom Integrated Circuits Conf</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">VLSI architecture of NEO spike detection with noise shaping filter and feature extraction using informative samples</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE EMBC Conf</title>
		<meeting>IEEE EMBC Conf</meeting>
		<imprint>
			<date type="published" when="2009-09">Sep. 2009</date>
			<biblScope unit="page" from="978" to="981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An ultra low-power CMOS automatic action potential detector</title>
		<author>
			<persName><forename type="first">B</forename><surname>Gosselin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sawan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Syst. Rehabil. Eng</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="346" to="353" />
			<date type="published" when="2009-08">Aug. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A biomedical multiprocessor SoC for closed-loop neuroprosthetic applications</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cockerham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Solid-State Circuits Conf., Dig, Tech, Papers</title>
		<meeting>IEEE Int. Solid-State Circuits Conf., Dig, Tech, Papers</meeting>
		<imprint>
			<date type="published" when="2009-02">Feb. 2009</date>
			<biblScope unit="volume">435</biblScope>
			<biblScope unit="page" from="434" to="435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A 130-uW, 64-channel neural spike-sorting DSP chip</title>
		<author>
			<persName><forename type="first">V</forename><surname>Karkare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Markovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Solid-State Circuits</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1214" to="1222" />
			<date type="published" when="2011-05">May 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A 75-uW, 16-channel neural spike-sorting processor with unsupervised clustering</title>
		<author>
			<persName><forename type="first">V</forename><surname>Karkare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Markovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Solid-State Circuits</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2230" to="2238" />
			<date type="published" when="2013-09">Sep. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Decoding individuated finger movements using volume-constrained neuronal ensembles in the M1 hand area</title>
		<author>
			<persName><forename type="first">S</forename><surname>Acharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tenore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Etienne-Cummings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schieber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Thakor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Syst. Rehabil. Eng</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="15" to="23" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A brain-machine interface enables bimanual arm movements in monkeys</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ifft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shokur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lebedev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nicolelis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science. Translat. Med</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Reach and grasp by people with tetraplegia using a neurally controlled robotic arm</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hochberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jarosiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Masse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Simeral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Haddain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Smagt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Donoghue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">485</biblScope>
			<biblScope unit="page" from="372" to="375" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">How advances in neural recording affect data analysis</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">H</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Kording</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neurosci</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="139" to="142" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A biomimetic adaptive algorithm and low-power architecture for implantable neural decoders</title>
		<author>
			<persName><forename type="first">B</forename><surname>Rapoport</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wattanapanitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Penagos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Musallam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sarpeshkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 31st Annu. Int. Conf. IEEE EMBS</title>
		<meeting>31st Annu. Int. Conf. IEEE EMBS</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient universal computing architectures for decoding neural activity</title>
		<author>
			<persName><forename type="first">B</forename><surname>Rapoport</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Turicchian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wattanapanitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sarpeshkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>p. e42492</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A 128 channel 290 GMACs/W machine learning based co-processor for intention decoding in brain machine interfaces</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Enyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ISCAS</title>
		<meeting>IEEE ISCAS</meeting>
		<imprint>
			<date type="published" when="2015-05">May 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Extreme learning machines: Theory and applications</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Siew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="489" to="501" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Extreme learning machine for regression and multiclass classification</title>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Systems</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="513" to="529" />
			<date type="published" when="2012-04">Apr. 2012</date>
			<pubPlace>Man, Cybern. B, Cybern</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Least angle regression</title>
		<author>
			<persName><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Johnstone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="407" to="499" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Asynchronous decoding of dexterous finger movements using M1 neurons</title>
		<author>
			<persName><forename type="first">V</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Acharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tenore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Etienne-Cummings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schieber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Thakor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Syst. Rehabil. Eng</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="3" to="14" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Weighted sums of random kitchen sinks: Replacing minimization with randomization in learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Neural Information Processing Systems</title>
		<meeting>Neural Information essing Systems</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Information systems opportunities in brain-machine interface decodersinformation systems opportunities in brain-machine interface decoders</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Stavisky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sussillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nuyujukian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Shenoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="2014-05">May 2014</date>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="666" to="682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Long-term time series pprediction using OP-ELM</title>
		<author>
			<persName><forename type="first">A</forename><surname>Grigorievskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Miche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ventela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Severin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lendasse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="50" to="56" />
			<date type="published" when="2014-03">Mar. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Silicon spiking neurons for hardware implementation of extreme learning machines</title>
		<author>
			<persName><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomput</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="125" to="134" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Computation using mismatch: Neuromorphic extreme learning machines</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Enyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Biomedical Circuits and Systems Conf</title>
		<meeting>IEEE Biomedical Circuits and Systems Conf<address><addrLine>Rotterdam, Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="294" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Op-elm: Optimally pruned extreme learning machine</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Miche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sorjamaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Simula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jutten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lendasse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="158" to="162" />
			<date type="published" when="2010-01">Jan. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A low-power processor with configurable embedded machine-learning accelerators for high-order and adaptive analysis of medical-sensor signals</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Solid-State Circuits</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1625" to="1637" />
			<date type="published" when="2013-07">Jul. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Sub-microwatt analog VLSI trainable pattern classifier</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chakrabartty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cauwenberghs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Solid-State Circuits</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1169" to="1179" />
			<date type="published" when="2007-05">May 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A 57 mw 12.5 uj/epoch embedded mixed-mode neuro-fuzzy processor for mobile real-time object recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-G</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Solid-State Circuits</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2894" to="2907" />
			<date type="published" when="2013-11">Nov. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">1 TOPS/W analog deep machine-learning engine with floating-gate storage in 0.13um CMOS</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Arel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Holleman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ISSCC Dig. Tech. Papers</title>
		<meeting>ISSCC Dig. Tech. Papers</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="504" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A new redundant binary booth encoding for fast 2n-Bit multiplier design</title>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. I, Reg. Papers</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1192" to="1201" />
			<date type="published" when="2009-06">Jun. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A micropower low-voltage multiplier with reduced spurious switching</title>
		<author>
			<persName><forename type="first">K.-S</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-H</forename><surname>Gwee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Very Large Scale Integr. (VLSI) Syst</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="255" to="265" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Razor based programmable truncated multiply and accumulate, energy-reduction for efficient digital signal processing</title>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
		<author>
			<persName><forename type="first">La</forename><surname>Guia De Solaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Conway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Very Large Scale Integr. (VLSI) Syst</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="189" to="193" />
			<date type="published" when="2015-01">Jan. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Truncated binary multipliers with variable correction and minimum mean square error</title>
		<author>
			<persName><forename type="first">N</forename><surname>Petra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">De</forename><surname>Caro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Garofalo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Napoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G M</forename><surname>Strollo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. I, Reg. Papers</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1312" to="1325" />
			<date type="published" when="2010-06">Jun. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A 0.45 V 100-channel neural-recording IC with sub-uW/channel consumption in 0.18 um CMOS</title>
		<author>
			<persName><forename type="first">D</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rajkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dawe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Je</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Solid-State Circuits Conf</title>
		<meeting>IEEE Int. Solid-State Circuits Conf</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="290" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Y</forename><surname>Enyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">40 nW compact, currentmode neural spike detector in 65 nm CMOS</title>
		<author>
			<persName><forename type="first">V</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Circuits Syst</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>IEEE Xplore</publisher>
			<pubPlace>Early Access</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A 2.4 GHz ULP reconfigurable asymmetric transceiver for single-chip wireless neural recording IC</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Circuits Syst</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="497" to="509" />
			<date type="published" when="2014-08">Aug. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A 50-Mb/s CMOS QPSK/O-QPSK transmitter employing injection locking for direct modulation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">X</forename><surname>Diao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">J</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Je</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Microw. Theory Tech</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="120" to="130" />
			<date type="published" when="2012-01">Jan. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A 128-channel 6 mW wireless neural recording IC with spike feature extraction and UWB transmitter</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yuce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Syst. Rehabil. Eng</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="312" to="321" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Intention estimation in brain machine interfaces</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neuroeng</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Closedloop decoder adaptation on intermediate time-scales facilitates rapid BMI performance improvements independent of decoder initialization conditions</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Orsborn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Moorman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Camena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Syst. Rehabil. Eng</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="468" to="477" />
			<date type="published" when="2012-07">Jul. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Currently, he is with the Virtus IC Design Centre of Excellence as a Research Fellow. His research interest is mainly on analog front-end circuits design for sensor interfaces as well as low power mixed signal machine learning IC design and system integration</title>
		<author>
			<persName><forename type="first">Yi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">respectively, and the Ph.D. degree in electrical and electronic engineering from Nanyang Technological University</title>
		<title level="s">S&apos;12) received the B.Sc. degree in micro</title>
		<meeting><address><addrLine>Beijing, China; Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007 and 2010. 2014</date>
		</imprint>
		<respStmt>
			<orgName>Xiamen University</orgName>
		</respStmt>
	</monogr>
	<note>Fugian, China, and the M.Sc. degree from the Chinese Academy of Science</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
