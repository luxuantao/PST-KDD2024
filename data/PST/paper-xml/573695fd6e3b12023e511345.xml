<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Estimation from Pairwise Comparisons: Sharp Minimax Bounds with Topology Dependence</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nihar</forename><forename type="middle">B</forename><surname>Shah</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering and Computer Sciences Department of Statistics</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>CA-94720</postCode>
									<settlement>Berkeley Berkeley</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sivaraman</forename><surname>Balakrishnan</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>PA-15213</postCode>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joseph</forename><surname>Bradley</surname></persName>
							<email>joseph.kurata.bradley@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering and Computer Sciences Department of Statistics</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>CA-94720</postCode>
									<settlement>Berkeley Berkeley</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Martin</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
							<email>wainwrig@berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering and Computer Sciences Department of Statistics</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>CA-94720</postCode>
									<settlement>Berkeley Berkeley</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Estimation from Pairwise Comparisons: Sharp Minimax Bounds with Topology Dependence</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="submission">Submitted 5/15; Revised 12/15;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Pairwise comparisons</term>
					<term>graph</term>
					<term>topology</term>
					<term>ranking</term>
					<term>crowdsourcing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Data in the form of pairwise comparisons arises in many domains, including preference elicitation, sporting competitions, and peer grading among others. We consider parametric ordinal models for such pairwise comparison data involving a latent vector w * ∈ R d that represents the "qualities" of the d items being compared; this class of models includes the two most widely used parametric models-the Bradley-Terry-Luce (BTL) and the Thurstone models. Working within a standard minimax framework, we provide tight upper and lower bounds on the optimal error in estimating the quality score vector w * under this class of models. The bounds depend on the topology of the comparison graph induced by the subset of pairs being compared, via the spectrum of the Laplacian of the comparison graph. Thus, in settings where the subset of pairs may be chosen, our results provide principled guidelines for making this choice. Finally, we compare these error rates to those under cardinal measurement models and show that the error rates in the ordinal and cardinal settings have identical scalings apart from constant pre-factors.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In an increasing range of applications, it is of interest to elicit judgments from non-expert humans. For instance, in marketing, elicitation of preferences of consumers about products, either directly or indirectly, is a common practice <ref type="bibr" target="#b14">(Green et al., 1981)</ref>. The gathering of this and related data types has been greatly facilitated by the emergence of "crowdsourcing"   platforms such as Amazon Mechanical Turk: they have become powerful, low-cost tools for collecting human judgments <ref type="bibr" target="#b23">(Khatib et al., 2011;</ref><ref type="bibr" target="#b27">Lang and Rio-Ross, 2011;</ref><ref type="bibr" target="#b52">von Ahn et al., 2008)</ref>. Crowdsourcing is employed not only for collection of consumer preferences, but also for other types of data, including counting the number of malaria parasites in an image of a blood smear <ref type="bibr">(Luengo-Oroz et al., 2012)</ref>; rating responses of an online search engine to search queries <ref type="bibr" target="#b21">(Kazai, 2011)</ref>; or for labeling data for training machine learning algorithms <ref type="bibr" target="#b18">(Hinton et al., 2012;</ref><ref type="bibr" target="#b40">Raykar et al., 2010;</ref><ref type="bibr" target="#b11">Deng et al., 2009)</ref>. In a different domain, competitive sports can be understood as a mechanism for sequentially performing comparisons between individuals or teams <ref type="bibr" target="#b41">(Ross, 2007;</ref><ref type="bibr" target="#b17">Herbrich et al., 2007)</ref>. Finally, peer-grading in massive open online courses (MOOCs) <ref type="bibr" target="#b38">(Piech et al., 2013)</ref> can be viewed as another form of elicitation.</p><p>A common method of elicitation is through pairwise comparisons. For instance, the decision of a consumer to choose one product over another constitutes a pairwise comparison between the two products. Workers in a crowdsourcing setup are often asked to compare pairs of items: for instance, they might be asked to identify the better of two possible results of a search engine, as shown in Figure <ref type="figure" target="#fig_1">1a</ref>. Competitive sports such as chess or basketball also involve sequences of pairwise comparisons. From a modeling point of view, we can think of pairwise comparisons as a means of estimating the underlying "qualities" or "weights" of the items being compared (e.g., skill levels of chess players, relevance of search engine results, etc.). Each pairwise comparison can be viewed as a noisy sample of some function of the underlying pair of (real-valued) weights. Noise can arise from a variety of sources. When objective questions are posed to human subjects, noise can arise from their differing levels of expertise. In a sports competition, many sources of randomness can influence the outcome of any particular match between a pair of competitors. Thus, one important goal is to estimate the latent qualities based on noisy data in the form of pairwise comparisons. A related problem is that of experimental design: assuming that we can choose the subset of pairs to be compared (e.g., in designing a chess tournament), what choice leads to the most accurate estimation? Characterizing the fundamental difficulty of estimating the weights allow us to make this choice judiciously. These tasks are the primary focus of this paper.</p><p>In more detail, the focus of this paper is the aggregation from pairwise comparisons in a fairly broad class of parametric models. This class includes as special cases the two most popular models for pairwise comparisons-namely, the Thurstone (Case V) <ref type="bibr" target="#b49">(Thurstone, 1927)</ref> and the Bradley-Terry-Luce (BTL) <ref type="bibr" target="#b4">(Bradley and Terry, 1952;</ref><ref type="bibr" target="#b32">Luce, 1959)</ref> models. The Thurstone (Case V) model has been used in a variety of both applied <ref type="bibr" target="#b48">(Swets, 1973;</ref><ref type="bibr" target="#b41">Ross, 2007;</ref><ref type="bibr" target="#b17">Herbrich et al., 2007)</ref> and theoretical papers <ref type="bibr" target="#b5">(Bramley, 2005;</ref><ref type="bibr" target="#b26">Krabbe, 2008;</ref><ref type="bibr" target="#b36">Nosofsky, 1985)</ref>. Similarly, the BTL model has been popular in both theory and practice <ref type="bibr" target="#b36">(Nosofsky, 1985;</ref><ref type="bibr" target="#b1">Atkinson et al., 1998;</ref><ref type="bibr" target="#b25">Koehler and Ridpath, 1982;</ref><ref type="bibr" target="#b16">Heldsinger and Humphry, 2010;</ref><ref type="bibr" target="#b31">Loewen et al., 2012;</ref><ref type="bibr" target="#b14">Green et al., 1981;</ref><ref type="bibr" target="#b22">Khairullah and Zionts, 1987)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related work</head><p>There is a vast literature on the Thurstone and BTL models, and we focus on those most closely related to our own work. <ref type="bibr" target="#b34">Negahban et al. (2012)</ref> provide minimax bounds for the BTL model in the special case where the comparisons are evenly distributed. They focus on this case in order to complement their analysis of an algorithm based on a random walk. In their analysis, there is a gap between the achievable rate of the MLE and the lower bound. In contrast, our analysis eliminates this discrepancy and shows that MLE is an optimal estimator (up to constant factors) and achieves the minimax rate. In a work concurrent with our initial submission to arXiv <ref type="bibr" target="#b45">(Shah et al., 2014)</ref>, <ref type="bibr">Hajek et al. (2014)</ref> consider the problem of estimation in the Plackett-Luce model, which extends the BTL model to comparisons of two or more items. They derive bounds on the minimax error rates under this model which, under certain conditions on the comparison graphs, are tight up to logarithmic factors. In general, their topology-dependent bounds rely on the degrees of the vertices in the comparison graph which makes the bounds quite loose. In contrast, our results are tight up to constants and, as we detail in the following sections, provide deeper insights into the role of the topology of the comparison graph. We elaborate on these differences in the appropriate sections in the sequel. We also note that the models studied in the present paper as well as in the aforementioned works fall under the broader paradigm of random utility models <ref type="bibr" target="#b49">(Thurstone, 1927;</ref><ref type="bibr" target="#b50">Train, 2009;</ref><ref type="bibr" target="#b2">Azari Soufiani et al., 2013)</ref>.</p><p>In other related works, <ref type="bibr" target="#b19">Jagabathula and Shah (2008)</ref> design an algorithm for aggregating ordinal data when the underlying distribution over the permutations is assumed to be sparse. <ref type="bibr" target="#b0">Ammar and Shah (2011)</ref> employ a different, maximum entropy approach towards parameterization and inference from partially ranked data. <ref type="bibr">Rajkumar and Agarwal (2014)</ref> study the statistical convergence properties of several rank aggregation algorithms.</p><p>Our work assumes a fixed design setup. In this setup, the choice of which pairs to compare and the number of times to compare them is chosen ahead of time in a nonadaptive fashion. There is a parallel line of literature on "sorting" or "active ranking" from pairwise comparisons. For instance, <ref type="bibr" target="#b6">Braverman and Mossel (2008)</ref> assume a noise model where the outcome of a pairwise comparison depends only on the relative ranks of the items being compared, and not on their actual ranks or values. On the other hand, <ref type="bibr" target="#b20">Jamieson and Nowak (2011)</ref> consider the problem of ranking a set of items assuming that items can be embedded into a smaller-dimensional Euclidean space, and that the outcomes of the pairwise comparisons are based on the relative distances of these items from a fixed reference point in the Euclidean space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shah et al.</head><p>A recent line of work considers a variant of the BTL and the Thurstone models where the comparisons may depend on some auxiliary unknown variable in addition to the items being compared; for instance, the accuracy of the individual making the comparison in an objective task. <ref type="bibr" target="#b9">Chen et al. (2013)</ref> consider a crowdsourcing setup where the outcome depends on the worker's expertise. They present algorithms for inference under such a model and present empirical evaluations. <ref type="bibr" target="#b54">Yi et al. (2013)</ref> consider a problem in the spirit of collaborative filtering where certain unknown preferences of a certain user must be predicted based on the preferences of other users as well as of that user over other items. <ref type="bibr" target="#b29">Lee et al. (2011)</ref> consider the inverse problem of measuring the expertise of individuals based on the rankings submitted by them, and the proposed algorithms assume an underlying Thurstone model. <ref type="bibr" target="#b44">Shah et al. (2013)</ref> make a case for ordinal evaluations in certain types of MOOC homeworks/exams and study a variant of the BTL model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Our contributions</head><p>Both the Thurstone (Case V) and BTL models involve an unknown vector w * ∈ R d corresponding to the underlying qualities of d items, and in a pairwise comparison between items j and k, the probability of j being ranked above k is some function F of the difference w * j − w * k . The Thurstone (Case V) and BTL are based on different choices of F , and both belong to the broader class of models analyzed in this paper, in which F is required only to be strongly log-concave.</p><p>With this context, the main contributions of this paper are to provide some answers to the following questions:</p><p>• How does the minimax error for estimating the weight vector w * in various norms scale with the problem dimension (the number of items) and the number of observations?</p><p>-We derive upper and lower bounds on the minimax estimation rates under the model described above. Our upper/lower bounds on the estimation error agree up to constant factors: to the best of our knowledge, despite the voluminous literature on these two models, this provides the first sharp characterization of the associated minimax rates. Moreover, our error guarantees provide guidance to the practitioner in assessing the number of pairwise comparisons to be made in order to guarantee a pre-specified accuracy.</p><p>• Given a budget of n comparisons, which pairs of items should be compared?</p><p>-The bounds that we derive depend on the comparison graph induced by the subset of pairs that are compared. Our theoretical analysis reveals that the spectral gap of a certain scaled version of the graph Laplacian plays a fundamental role, and provides guidelines for the practitioner on how to choose the subset of comparisons to be made.</p><p>• When is it better to elicit pairwise comparisons versus numeric scores?</p><p>-When eliciting data, one often has the liberty to ask for either cardinal values (Figure <ref type="figure" target="#fig_1">1b</ref>) or for pairwise comparisons (Figure <ref type="figure" target="#fig_1">1a</ref>) from the human subjects. One would like to adopt the approach that would lead to a better estimate. One may be tempted to think that cardinal elicitation methods are superior, since each cardinal measurement gives a real-valued number whereas an ordinal measurement provides at most one bit of information. Our bounds show, however, that the scaling of the error in the cardinal and ordinal settings is identical up to constant pre-factors. As we demonstrate, this result allows for a comparison of cardinal and ordinal data elicitation methods in terms of the per-measurement noise alone, independent of the number of measurements and the number of items. A priori, there is no obvious reason for the relative performance to be independent of the number of measurements and items.</p><p>Notation: For any symmetric matrix M of size (m × m), we let</p><formula xml:id="formula_0">λ 1 (M ) ≤ λ 2 (M ) ≤ • • • ≤ λ m (M )</formula><p>denote its ordered eigenvalues. We use the notation D KL (P 1 P 2 ) to denote the Kullback-Leibler divergence between the two distributions P 1 and P 2 . For any integer m, we let [m] denote the set {1, . . . , m}. For any pair of vectors u and v of the same length, we let u, v denote their inner product.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Problem formulation</head><p>We begin with some background followed by a precise formulation of the problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Generative models for ranking</head><p>Given a collection of d items to be evaluated, we suppose that each item has a certain numeric quality score, and a comparison of any pair of items is generated via a comparison of the two quality scores in the presence of noise. We represent the quality scores as a vector w * ∈ R d , so item j ∈ [d] has quality score w * j . Now suppose that we make n pairwise comparisons: if comparison i ∈ [n] pertains to comparing item a i with item b i , then it can be described by a differencing vector x i ∈ R d , with entry a i equal to one, entry b i equal to −1, and the remaining entries set to 0.</p><p>With this notation, we study the problem of estimating the weight vector w * based on observing a collection of n independent samples y i ∈ {−1, 1} drawn from the distribution</p><formula xml:id="formula_1">P y i = 1|x i , w * = F x i , w * σ for i ∈ [n],<label>(Ordinal)</label></formula><p>where F is a known function taking values in [0, 1]. Since the probability of item a i dominating b i should be independent of the order of the two items being compared, we require throughout that</p><formula xml:id="formula_2">F (x) = 1 − F (−x).</formula><p>In any model of the general form (Ordinal), the parameter σ &gt; 0, assumed to be known, plays the role of a noise parameter, with a higher value of σ leading to more uncertainty in the comparisons. Moreover, we assume that F is strongly log-concave in a neighborhood of the origin, meaning that there is some curvature parameter γ &gt; 0 such that</p><formula xml:id="formula_3">d 2 dt 2 (− log F (t)) ≥ γ for all t ∈ [−2B/σ, 2B/σ].</formula><p>(1)</p><p>Here the known parameter B denotes a bound on the ∞ -norm of the weight vector, namely</p><formula xml:id="formula_4">w * ∞ ≤ B.</formula><p>Shah et al.</p><p>As our analysis shows, a bound of this form is fundamental: the minimax error for estimating w * diverges to infinity if we are allowed to consider models in which B is arbitrarily large (see Proposition 17 in Appendix G). Informally, this behavior is related to the difficulty of estimating very small (or very large) probabilities that can arise in the two models for large w * ∞ . Note that any model of the form (Ordinal) is invariant to shifts in w * , that is, it does not differentiate between the vector w * and the shifted vector w * + 1, where 1 denotes the vector of all ones. Therefore, in order to ensure identifiability of w * , we assume throughout that 1, w * = 0. We use the notation W B to denote the set of permissible quality score vectors <ref type="table" target="#tab_4">and 1, w = 0 .</ref> (2)</p><formula xml:id="formula_5">W B : = w ∈ R d | w ∞ ≤ B,</formula><p>Both the Thurstone (Case V) model with Gaussian noise <ref type="bibr" target="#b49">(Thurstone, 1927)</ref> and Bradley-Terry-Luce (BTL) models <ref type="bibr" target="#b4">(Bradley and Terry, 1952;</ref><ref type="bibr" target="#b32">Luce, 1959)</ref> are special cases of this general set-up, as we now describe.</p><p>Thurstone (Case V): This model is is a special case of the family (Ordinal), obtained by setting</p><formula xml:id="formula_6">F (t) = t −∞ 1 √ 2π e −u 2 /2 du,<label>(3)</label></formula><p>corresponding to the CDF of the standard normal distribution. Consequently, the Thurstone model can alternatively be written as making n i.i.d. observations of the form</p><formula xml:id="formula_7">y i = sign x i , w * + i , for i ∈ [n],<label>(Thurstone)</label></formula><p>where i ∼ N (0, σ 2 ) is observation noise. It can be verified that the Thurstone model is strongly log-concave over the set W B (e.g., see Tsukida and Gupta ( <ref type="formula">2011</ref>)).</p><p>Bradley-Terry-Luce: The Bradley-Terry-Luce (BTL) model <ref type="bibr" target="#b4">(Bradley and Terry, 1952;</ref><ref type="bibr" target="#b32">Luce, 1959</ref>) is another special case in which</p><formula xml:id="formula_8">F (t) = 1 1 + e −t ,</formula><p>and hence</p><formula xml:id="formula_9">P y i = 1|x i , w * = 1 1 + exp − x i , w * σ for i ∈ [n]. (BTL)</formula><p>It can also be verified that the BTL model is strongly log-concave over the set W B .</p><p>Cardinal observation models: While our primary focus is on the pairwise-comparison setting, for comparison purposes we also analyze analogous cardinal settings where each observation is real valued. In particular, we consider the following two cardinal analogues of the Thurstone model. In the Cardinal model we consider, each observation i ∈ [n] consists of a numeric evaluation y i ∈ R of a single item,</p><formula xml:id="formula_10">y i = u i , w * + i for i ∈ [n],<label>(Cardinal)</label></formula><p>where u i in this case is a coordinate vector with one of its entries equal to 1 and remaining entries equal to 0, and i is independent Gaussian noise N (0, σ 2 ). One may alternatively elicit cardinal values of the differences between pairs of items</p><formula xml:id="formula_11">y i = x i , w * + i for i ∈ [n], (<label>Paired Cardinal)</label></formula><p>where i are i.i.d. N (0, σ 2 ). We term this model the Paired Cardinal model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Fixed design and the graph Laplacian</head><p>We analyze the estimation error when a fixed subset of pairs is chosen for comparison. Of interest to us is the comparison graph defined by these chosen pairs, with each pair inducing an edge in the graph. Edge weights are determined by the fraction of times a given pair is compared. The analysis in the sequel reveals the central role played by the Laplacian of this weighted graph. Note that we are operating in a fixed-design setup where the graph is constructed offline and does not depend on the observations. In the ordinal models, the i th measurement is related to the difference between the two items being compared, as defined by the measurement vector x i ∈ R d . We let X ∈ R n×d denote the measurement matrix with the vector x T i as its i th row. The Laplacian matrix L associated with this differencing matrix is given by</p><formula xml:id="formula_12">L : = 1 n X T X = 1 n n i=1 x i x T i .<label>(4)</label></formula><p>By construction, for any vector v ∈ R d , we have</p><formula xml:id="formula_13">v T Lv = j =k L jk (v j − v k ) 2</formula><p>, where L jk is the fraction of the measurement vectors {x i } n i=1 in which items (j, k) are compared. The Laplacian matrix is positive semidefinite, and has at least one zero-eigenvalue, corresponding to the all-ones eigenvector. The Laplacian matrix induces a graph on the vertex set {1, . . . , d}, in which a given pair (j, k) is included as an edge if and only if L jk = 0, and the weight on an edge (j, k) equals L jk . We emphasize that throughout our analysis, we assume that the comparison graph is connected, since otherwise, the quality score vector w * is not identifiable. Note that the Laplacian matrix L induces a semi-norm<ref type="foot" target="#foot_0">1</ref> on R d , given by</p><formula xml:id="formula_14">u − v L : = (u − v) T L(u − v).</formula><p>(5)</p><p>We study optimal rates of estimation in this semi-norm, as well as the usual 2 -norm. As will be clearer in the sequel the L semi-norm is a natural metric in our setup, and estimation in this induced metric can be done at a topology independent rate. The estimation error in the L semi-norm is closely related to the prediction risk in generalized linear models. In particular, for an estimate w of w * from n ij comparisons between each pair of items (i, j),</p><formula xml:id="formula_15">we have w − w * 2 L = i&lt;j n ij ( w i − w j ) − (w * i − w * j ) 2 .</formula><p>It arises naturally when one is interested in predicting the probability of a certain outcome for a new comparison.</p><p>Shah et al.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Bounds on the minimax risk</head><p>In this section, we state the main results of the paper, and discuss some of their consequences.</p><p>3.1 Minimax rates in the squared L semi-norm</p><p>Our first main result provides bounds on the minimax risk under the squared L seminorm (5) in the pairwise comparison models introduced earlier. In all of the statements, we use c 1 , c 2 , etc. to denote positive numerical constants, independent of the sample size n, number of items d and other problem-dependent parameters.</p><p>Apart from the curvature parameter γ defined earlier in (1), the bounds presented subsequently depend on F through a second parameter ζ, defined as</p><formula xml:id="formula_16">ζ : = max x∈[0,2B/σ] F (x) F (2B/σ)(1 − F (2B/σ)) .<label>(6)</label></formula><p>In the BTL and the Thurstone models, we have ζ : =</p><formula xml:id="formula_17">F (0) F (2B/σ)(1−F (2B/σ))</formula><p>. For instance, when B = σ = 1, then under the BTL model we have γ = 0.25 and ζ = 1.43. As observed in <ref type="bibr" target="#b35">Negahban et al. (2015)</ref>, the reader may consider the parameters B, σ, γ and ζ as having O(1) values: a fixed value of B is the hardest regime, and furthermore, in situations of practical interest, the problem dependent parameters σ, γ and ζ, are typically independent of d and n. Consequently, in the sequel, we treat these parameters as fixed.</p><p>Theorem 1 (Bounds on minimax rates in L semi-norm) (a) For a sample size n ≥ c 1 σ 2 tr(L † ) ζB 2</p><p>, any estimator w based on n samples from the Ordinal model has Laplacian squared error lower bounded as</p><formula xml:id="formula_18">sup w * ∈W B E w − w * 2 L ≥ c 1 ζ σ 2 d n .<label>(7a)</label></formula><p>(b) For any instance of the Ordinal model with γ-strong log-concavity and any w * ∈ W B , the maximum likelihood estimator satisfies the bound</p><formula xml:id="formula_19">P w ML − w * 2 L &gt; t cζ 2 σ 2 γ 2 d n ≤ e −t for all t ≥ 1,</formula><p>and consequently</p><formula xml:id="formula_20">sup w * ∈W B E w ML − w * 2 L ≤ c 1u ζ 2 γ 2 σ 2 d n . (<label>7b</label></formula><formula xml:id="formula_21">)</formula><p>The results of Theorem 1 characterize the minimax risk in the squared L semi-norm up to constant factors. The upper bounds follow from an analysis of the maximum likelihood estimator, which turns out to be a convex optimization problem. On the other hand, the lower bounds are based on a combination of information-theoretic techniques and carefully constructed packings of the parameter set W B . The main technical difficulty is in constructing a packing in the semi-norm induced by the Laplacian L. See Appendix A for the full proof.</p><p>Topology-dependent Estimation from Pairwise Comparisons</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Minimax rates in the squared 2 -norm</head><p>Let us now turn to optimizing the minimax risk under the squared Euclidean norm. Theorem 2 below presents upper and lower bounds on this quantity.</p><p>Theorem 2 (Bounds on minimax rates in 2 -norm) (a) For a sample size n ≥ c 2 σ 2 tr(L † ) ζB 2</p><p>, any estimator w based on n samples from the Ordinal model has squared Euclidean error lower bounded as</p><formula xml:id="formula_22">sup w * ∈W B E w − w * 2 2 ≥ c 2 σ 2 n max d 2 , max d ∈{2,...,d} d i= 0.99d 1 λ i (L) . (<label>8a</label></formula><formula xml:id="formula_23">)</formula><p>(b) For any instance of the Ordinal model with γ-strong log-concavity and any w * ∈ W B , the maximum likelihood estimator satisfies the bound</p><formula xml:id="formula_24">P w ML − w * 2 2 &gt; t cζ 2 σ 2 γ 2 d λ 2 (L)n ≤ e −t for all t ≥ 1, (<label>8b</label></formula><formula xml:id="formula_25">)</formula><p>and consequently</p><formula xml:id="formula_26">sup w * ∈W B E w ML − w * 2 2 ≤ c 2u ζ 2 γ 2 σ 2 d λ 2 (L)n .<label>(8c)</label></formula><p>See Appendix B for the proof of this theorem. As we describe in the next section, the upper and lower bounds on minimax risk from Theorem 2 to identify the comparison graph(s) that lead to the best possible minimax risk over all possible graph topologies.</p><p>Figure <ref type="figure" target="#fig_2">2</ref> depicts results from simulations under the Thurstone model, depicting the squared 2 error for the maximum likelihood estimator for various values of n and d. In the simulations, the true vector w * is generated by first drawing a d-length vector uniformly at random from [−1, 1] d , followed by a scale and shift to ensure w * ∈ W B . The n pairs are chosen uniformly (with replacement) at random from the set of d 2 possible pairs of items. The value of σ and B are both fixed to be 1. Given the n samples, inference is performed via the maximum likelihood estimator for the Thurstone model. Each point in the plots is an average of 20 such trials.</p><p>The error in Figure <ref type="figure" target="#fig_2">2</ref> reduces linearly with n, exactly as predicted by our Theorem 2. For the complete graph, 1 λ 2 (L) = d−1 2 . Theorem 2 thus predicts a quadratic increase in the error with d. As predicted, the error when normalized by 1 d 2 in Figure <ref type="figure" target="#fig_2">2</ref> converges to the same curve for all values of d.</p><p>Detailed comparison with other work: Having stated our main theoretical results we are now in a position to revisit the results of the earlier works of <ref type="bibr" target="#b34">Negahban et al. (2012</ref><ref type="bibr" target="#b35">Negahban et al. ( , 2015))</ref>; <ref type="bibr">Hajek et al. (2014)</ref>. The papers by <ref type="bibr" target="#b34">Negahban et al. (2012</ref><ref type="bibr" target="#b35">Negahban et al. ( , 2015) )</ref> consider the BTL model under a restricted sampling setting in which every pair considered is compared the same number of times. For the problem of recovering the vector w * (as considered in the present paper), they derive upper bounds when the pairs considered for comparisons arise  from an Erdős-Rényi comparison graph; setting t = log d in equation (8b) in Theorem 2 above recovers their results. The two papers also provide results pertaining to inference of a set of parameters that are an exponentiated form of w * . Their upper bounds for these parameters are derived in terms of the random-walk normalized Laplacian matrix of the comparison graph, while our bounds for w * are derived in terms of the (combinatorial) Laplacian matrix. Their associated information-theoretic lower bounds also assume an Erdős-Rényi comparison graph whereas our lower bounds apply to general comparison graphs.</p><p>A concurrent paper by <ref type="bibr">Hajek et al. (2014)</ref> also considers the specific BTL model, but a general comparison topology. Their high-probability upper bounds can be recovered by setting t = log d in equation (8b) of Theorem 2, while their upper bounds on the expected error are loose by a logarithmic factor. On the other hand, the lower bounds of <ref type="bibr">Hajek et al. (2014)</ref>, although dependent on topology, are quite loose due to their reliance on the degrees of the vertices in the comparison graph. On the other hand, our results are derived in terms of the graph Laplacian which better captures the critical aspects of the problem. For instance, considering a disconnected graph where every node has at least one neighbor as a sanity check, the degree-based lower bounds of <ref type="bibr">Hajek et al. (2014)</ref> do not reflect the non-identifiability of w * due to their reliance on only the degrees of the vertices, whereas the presence of the spectral gap in our bound (8a) indicates non-identifiability. As another example, the bounds of <ref type="bibr">Hajek et al. (2014)</ref> cannot distinguish between a star graph and a path graph, whereas our results establish the star graph as an optimal comparison graph and the path graph as strictly suboptimal. In Section 4 below, we further describe deeper insights on the graph topology derived from our analytical results.</p><p>The Paired Cardinal model: Before concluding this section, we also look at the Paired Cardinal model (Section 2.1), the cardinal analogue of the Thurstone model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Topology-dependent Estimation from Pairwise Comparisons</head><p>Theorem 3 (Bounds on minimax rates in 2 -norm) For the Paired Cardinal model, the minimax risk is sandwiched as</p><formula xml:id="formula_27">c 3 σ 2 tr(L † ) n ≤ inf w sup w * ∈W∞ E w − w * 2 2 ≤ c 3u σ 2 tr(L † ) n .<label>(9)</label></formula><p>The proof of Theorem 3 is available in Appendix C. We conjecture that the dependence of the squared 2 minimax risk under the Ordinal models on the problem parameters n, d and the graph topology is identical to that derived in Theorem 3 for the Paired Cardinal model, i.e., is proportional to tr(L † ) n . Note that the condition tr(L) = 2 implies that L) .</p><formula xml:id="formula_28">d 2 9 ≤ tr(L † ) ≤ d λ 2 (</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Extension to m-ary comparisons</head><p>Suppose instead of eliciting pairwise comparisons, one can instead ask the workers to make comparisons between more than two options. In particular, we assume that each sample is a selection of the item with the largest perceived quality among some m presented items. The setting of pairwise comparisons is a special case with m = 2. Recall from Theorem 2 that the minimum squared 2 minimax risk in the pairwise comparison setting is of the order d 2 n . Our goal in this section is to bring the concept of multiple-item comparison under the same framework as the pairwise case, and via a generalization of our earlier theoretical analysis, understand how the error exponent depends on m.</p><p>Consider d items, where every item j ∈ Let R 1 , . . . , R m be (m × m) permutation matrices representing m cyclic shifts in an arbitrary (but fixed) direction. Consider the observation model</p><formula xml:id="formula_29">P(y i = j|w * , E i ) = F ((w * ) T E i R j ) for all j ∈ [m], where F : [−B, B] m → [0, 1]</formula><p>represents the probability of choosing the first among the m items presented. We also assume that F does not depend on the order of the last (m − 1) coordinates in its input, meaning that the likelihood of choosing an item is independent of the ordering of the m items in the argument to F . For every x ∈ [−B, B] m , F (x) is assumed to satisfy:</p><p>• Shift-invariance: the probabilities depend only on the differences in the weights of the items presented, i.e, F (x) depends only on</p><formula xml:id="formula_30">{x i − x j } i,j∈[m] . • Strong log-concavity: ∇ 2 (− log F (x))</formula><p>H for some (m × m) symmetric matrix H with λ 2 (H) &gt; 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shah et al.</head><p>Note that the shift-invariance assumption implies 1 ∈ nullspace(∇ 2 (− log F (x))), thereby necessitating nullspace(H) = span(1) and λ 1 (H) = 0. One can also verify that the model proposed here reduces to the Ordinal model of Section 2.1 when m = 2.</p><p>For any hope of inferring the true weights w * , we must ensure that the comparison hyper-graph is "connected", i.e., for every pair of items i, j ∈ [d], there must exist a path connecting item i and item j in the comparison hyper-graph. We assume this condition is satisfied. We also continue to assume that w * ∈ W</p><formula xml:id="formula_31">B : = {w ∈ R d | w ∞ ≤ B, w, 1 = 0}.</formula><p>The popular Plackett-Luce model falls in this class, as illustrated below.</p><p>Example 1 (Plackett-Luce model <ref type="bibr" target="#b39">(Plackett, 1975;</ref><ref type="bibr" target="#b32">Luce, 1959</ref>)) The Plackett-Luce model concerns the process of choosing an item from a given set. Specifically, given m items with quality scores w * 1 , . . . , w * m respectively, the likelihood of choosing item ∈ [m] under this model is given by</p><formula xml:id="formula_32">e w * m j=1 e w * j =: F ([w * , w * 1 , . . . , w * −1 , w * +1 , . . . , w * m ]).</formula><p>Every choice is made independent of all other choices. It is easy to verify that the Plackett-Luce model satisfies shift invariance. Furthermore, the function F does not depend on the ordering of the last (m − 1) coordinates in its argument. We now show that it also satisfies strong log-concavity. A little algebra gives</p><formula xml:id="formula_33">∇ 2 (− log F (x)) = e x , 1 diag(e x ) − e x (e x ) T ( e x , 1 ) 2 ,</formula><p>where e x : = [e x 1 • • • e xm ] T . We now derive a lower bound for the expression above. An application of the Cauchy-Schwarz inequality yields that for any vector</p><formula xml:id="formula_34">v ∈ R m , v T (e x (e x ) T )v ≤ v T diag(e x ) e x , 1 v, with equality if and only if v ∈ span(1). It follows that λ 2 (∇ 2 (− log F (x))) &gt; 0 for all x ∈ [−B, B] m . Defining the scalar β : = min x∈[−B,B] m λ 2 ( e x , 1 diag(e x )−e x (e x ) T ( e x , 1 ) 2</formula><p>), one can see that setting H = β(I − 11 T ) satisfies the strong log-concavity conditions.</p><p>Our goal is to capture the scaling of the minimax error with respect to the number of observations n, the dimension d of the problem, and the choice of the subsets compared</p><formula xml:id="formula_35">{E i } i∈[n]</formula><p>. It is well understood <ref type="bibr" target="#b33">(Miller, 1956;</ref><ref type="bibr" target="#b24">Kiger, 1984;</ref><ref type="bibr" target="#b46">Shiffrin and Nosofsky, 1994;</ref><ref type="bibr" target="#b43">Saaty and Ozdemir, 2003)</ref> that humans have a limited information storage and processing capacity, which makes it difficult to compare more than a small number of items. For instance, <ref type="bibr" target="#b43">Saaty and Ozdemir (2003)</ref> recommend eliciting preferences over no more than seven options. Thus in this work we restrict our attention to m = O(1). Moreover, the amount of noise in the selection process also depends on the number of items m presented at a time: the higher the number, the greater the noise. We thus do not use a "noise parameter σ"in this setting, and assume the noise to be incorporated in the function F , which itself is a function of m.</p><p>Our results involve the Laplacian of the comparison graph, defined for the m-wise comparison setting as follows. Let L be an (d × d) matrix that depends on the choice of the comparison topology as</p><formula xml:id="formula_36">L : = 1 n n i=1 E i (mI − 11 T )E T i . (<label>10</label></formula><formula xml:id="formula_37">)</formula><p>We call L the Laplacian of the comparison hyper-graph. One can verify that when applied to the special case of m = 2, the matrix L defined in (10) reduces to the Laplacian of the pairwise-comparison graph defined earlier in (4).</p><p>The following theorem presents our main results for the m-wise comparison setting.</p><p>Theorem 4 For the m-wise model, the minimax risk is sandwiched as</p><formula xml:id="formula_38">c 3 inf z F (z) m 2 λ m (H) sup z ∇F (z) 2 H † d n ≤ inf w sup w * ∈W B E w − w * 2 L ≤ c 3u m 2 sup z ∇ log F (z) 2 2 λ 2 (H) 2 d n ,</formula><p>in the squared L semi-norm and as</p><formula xml:id="formula_39">c 4 inf z F (z) m 2 λ m (H) sup z ∇F (z) 2 H † d 2 n ≤ inf w sup w * ∈W B E w − w * 2 2 ≤ c 4u m 2 sup z ∇ log F (z) 2 2 λ 2 (H) 2 d λ 2 (L)n , in the squared 2 norm. Here we assume n ≥ c 5 tr(L † ) infz F (z) B 2 λm(H) sup z ∇F (z) 2 H †</formula><p>for both the lower bounds, and where the suprema and infima with respect to the parameter z are taken over the set [−B, B] m .</p><p>The proof of Theorem 4 is provided in Appendix D. Our results establish that the dependence of the squared L semi-norm and squared Euclidean minimax error on m occurs only as multiplicative pre-factors, and the error exponent is independent of m. Thus, if one follows the standard recommendation in the psychology literature <ref type="bibr" target="#b33">Miller (1956)</ref>; <ref type="bibr" target="#b24">Kiger (1984)</ref>; Shiffrin and Nosofsky (1994); Saaty and Ozdemir (2003)-namely to choose m = O(1)-then the best possible scaling of the squared L semi-norm minimax risk with respect to d and n is always d n , that of the squared Euclidean minimax risk is always</p><formula xml:id="formula_40">d 2</formula><p>n , and evenly spreading the samples across all possible choices of m items is optimal. Nevertheless, a more refined modeling and analysis is required to understand the precise tradeoffs governing the choice of the number m of items presented to the user. Finally, when specialized to the case of m = 2, the upper bounds of Theorem 4 are identical (up to constant factors) to those of Theorem 1 and Theorem 2. The lower bound for the L semi-norm is identical to that of Theorem 1. The additional generality results in a lower bound for the 2 norm that is weaker in general as compared to Theorem 2, but is tight when the underlying hypergraph forms a complete graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Role of graph topology</head><p>We now return to the setting of pairwise comparisons. In certain applications, one may have the liberty to decide which pairs are compared. The results of the previous section Shah et al.</p><p>demonstrated the role played by the Laplacian of the comparison graph in the estimation error. We now employ these results to derive guidelines towards designing the comparison graph. Let us focus on the estimation error in the squared 2 norm in the ordinal setting. As discussed earlier, we assume that the graph induced by the comparisons is connected. An application of Theorem 2 lets us identify good topologies for pairwise comparisons in the fixed-design setup.</p><p>A popular class of comparison topologies is that of evenly distributed samples on an unweighted graph (e.g., <ref type="bibr" target="#b34">Negahban et al. (2012)</ref>). Consider any fixed, unweighted graph G = (V, E). We assume that the samples are distributed evenly along the edges E of G, and that the sample size n is sufficiently large. Using standard matrix concentration inequalities, it is straightforward to extend our analysis to the setting of random chosen comparisons from a fixed graph (see, for instance, Oliveira ( <ref type="formula">2009</ref>)). Let L denote the Laplacian of G. We define the scaled Laplacian of G as</p><formula xml:id="formula_41">L : = 1 | E | L .</formula><p>One can verify that the matrix L defined here is identical to what was defined in (4) in a more general context. In order to differentiate from L, we refer to L as the regular Laplacian of the graph G. For a given budget n on the number of samples, we say that a comparison graph is optimal if the error under this graph is the smallest (up to constants) among all graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Analytical results</head><p>Consider the Ordinal model and the squared 2 -norm as the metric of interest. We claim that in order to determine whether a given comparison graph achieves minimax risk (up to a constant pre-factor), it suffices to examine the eigen-spectrum of the scaled Laplacian matrix. In particular, we claim that:</p><p>• If the scaled Laplacian has a second smallest eigenvalue that scales as 1 λ 2 (L) = Θ(d), then the comparison graph is optimal, and leads to the smallest possible minimax risk, in particular one that scales as d 2 n .</p><p>• Conversely, if the scaled Laplacian matrix has an eigen-spectrum satisfying</p><formula xml:id="formula_42">d 2 = o   max d ∈{2,...,d} d i= 0.99d 1 λ i (L)   ,<label>(11)</label></formula><p>then the associated estimation error is strictly larger than the minimax risk. In particular, this sub-optimality holds whenever</p><formula xml:id="formula_43">d 2 = o( 1 λ 2 (L) ).</formula><p>In order to verify these claims, we note that by definition (4) of the Laplacian matrix, we have</p><formula xml:id="formula_44">tr(L) = 1 n n i=1 tr(x i x T i ) = 2.</formula><p>It follows that λ 2 (L) ≤ 2 d−1 , i.e., that 1 λ 2 (L) = Ω(d). As we will see shortly, several classes of graphs satisfy 1 λ 2 (L) = Θ(d). Comparing the lower bound of Ω( d 2 n ) on the minimax risk (8a) with the upper bound (8c) gives the sufficient condition of 1 λ 2 (L) = Θ(d) for optimality, and the smallest minimax risk as Θ( d 2 n ). The lower bound (8a) now also gives the claimed condition for strict sub-optimality.</p><p>In order to illustrate these claims, let us consider a few canonical classes of graphs, and study how the estimation error under the squared Euclidean norm scales in the Ordinal model. The spectra of the regular Laplacian matrices of these graphs can be found in various standard texts on spectral graph theory (e.g., Brouwer and Haemers ( <ref type="formula">2011</ref>)).</p><p>• Complete graph. A complete graph has one edge between every pair of nodes. The spectrum of the regular Laplacian of the complete graph is 0, d, . . . , d, and hence the spectrum of the scaled Laplacian L is 0,</p><formula xml:id="formula_45">2 d−1 , . . . , 2 d−1 . Substituting λ 2 (L) = 2 d−1 in Theorem 2b gives an upper bound of Θ( d 2</formula><p>n ) on the minimax risk, and Theorem 2 gives a matching lower bound. The sufficiency condition discussed above proves optimality.</p><p>• Constant-degree expander. The spectrum of the regular Laplacian of a constantdegree expander graph is 0, Θ(d), Ω(d), . . . , Ω(d). Since the number of edges is Θ(d), the spectrum of the scaled Laplacian equals 0, Θ(</p><formula xml:id="formula_46">1 d ), Ω( 1 d ), . . . , Ω( 1 d ).</formula><p>The evaluation of this class of graphs with respect to the minimax risk is identical to that of complete graphs, giving a lower and upper bound of Θ( d 2 n ) on the minimax risk, and guaranteeing optimality.</p><p>• Complete bipartite. The d nodes are partitioned into two sets comprising, say, m 1 and m 2 nodes. There is an edge between every pair of nodes in different sets, and there are no edges between any two nodes in the same set. The eigenvalues of the regular Laplacian of this graph are 0, m 2 , . . . , m 2</p><formula xml:id="formula_47">m 1 −1 , m 1 , . . . , m 1 m 2 −1 , m 1 + m 2 . Since the total number of edges is m 1 m 2 , the scaled Laplacian L has a spectrum 0, 1 m 1 ,..., 1 m 1 m 1 −1 , 1 m 2 ,..., 1 m 2 m 2 −1 , 1 m 1 + 1 m 2 .</formula><p>Suppose without loss of generality that m 1 ≥ m 2 . Also suppose that m 2 &gt; 1 (the case of m 2 = 1 is the star graph discussed below). Then we have</p><formula xml:id="formula_48">1 m 1 ≤ 1 m 2 ≤ 1 m 1 + 1 m 2 and that d &gt; m 1 ≥ d 2 .</formula><p>Furthermore since m 2 &gt; 1, the multiplicity of 1 m 1 in the spectrum of the scaled Laplacian is at least 1. Thus we have λ 2 (L) = Θ( 1 d ). Theorem 2 then gives lower and upper bounds on the minimax risk as Θ( d 2 n ) and the sufficiency condition discussed above guarantees its optimality.</p><p>• Star. A star graph has one central node with edges to every other node. It is a special case of the complete bipartite graph with m 1 = d − 1 and m 2 = 1. The spectrum of the regular Laplacian is 0, 1, . . . , 1, d. Since there are (d − 1) edges, the spectrum of the scaled Laplacian is 0,</p><formula xml:id="formula_49">1 d−1 , . . . , 1 d−1 , d d−1 .</formula><p>Theorem 2 and the sufficiency condition discussed above imply that this class of graphs is optimal and is associated to a minimax risk of Θ( d 2 n ).</p><p>• Path. A path graph is associated to an arbitrary ordering of the d nodes with edges between pairs j and (j + 1) for every j ∈ {1, . . . , d − 1}. The spectrum of the regular ). This class of graphs is thus strictly suboptimal.</p><p>• Barbell. The nodes are partitioned into two sets of d 2 nodes each, and there is an edge between every pair of nodes within each set. In addition, there is exactly one edge across the sets. The spectrum of the regular Laplacian can be computed as 0, Θ( 1 d ), Θ(d), . . . , Θ(d). Since there are Θ(d<ref type="foot" target="#foot_1">2</ref> ) edges, the spectrum of the scaled Laplacian turns out to become 0, Θ(</p><formula xml:id="formula_50">1 d 3 ), Θ( 1 d ), . . . , Θ( 1 d ), Ω( 1 d ).</formula><p>Applying the results derived earlier in the paper, we get that a lower bound of Ω( d<ref type="foot" target="#foot_2">3</ref> n ) and an upper bound of O( d 4 n ) on the minimax risk, thereby also establishing the sub-optimality of this class of graphs.</p><formula xml:id="formula_51">• 2D Lattice. An (m 1 × m 2 ) lattice has d = m 1 m 2 vertices arranged as a (m 1 × m 2 ) grid. Assume m 1 = Θ(d) and m 2 = Θ(d)</formula><p>. This class of graphs can be written as a Cartesian product of a path graph of length m 1 and a second path graph of length m 2 . As a result, the spectrum of the scaled Laplacian is 2 d 2 − cos πi m 1 − cos πj m 2 , ... i∈{0,...,m 1 −1},j∈{0,...,m 2 −1}. Again, using the small angle approximation of the sinusoid, one can compute an upper bound on the minimax risk as O( d 3 n ) and a lower bound of Ω( d 2 n ). We do not know at this point whether the 2D lattice minimizes the minimax risk.</p><p>• Hypercube. Assume d = 2 m for some integer m. Representing each node as a distinct m-length binary vector, an edge exists between the nodes corresponding to any pair of vectors within a Hamming distance of one. The hypercube is an m-fold Cartesian product of a path with two nodes, and hence the regular Laplacian has an eigenvalue of 2i with multiplicity m i , for i ∈ {0, . . . , m}. The scaled Laplacian has an eigenvalue of 2i d log d with multiplicity m i , for i ∈ {0, . . . , m}. A lower bound on the minimax risk is Ω( d 2 n ) and an upper bound is O( d 2 log d n ). We do not know if the hypercube is optimal, our bounds do tell us that any sub-optimality is bounded by at most a logarithmic factor.</p><p>Observe that the degree-k expander requires n ≥ kd samples while the complete graph requires n ≥ d 2 samples, so in practical applications at least for small sample sizes we should prefer a low-degree expander.</p><p>Finally, if the conjecture discussed at the end of Section 3.2 were true, namely that the Topology-dependent Estimation from Pairwise Comparisons</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiments and simulations</head><p>This section evaluates the dependence of the squared 2 -error on the topology of the comparison graph. We consider the following five topologies: path, barbell, complete, expander and 2D-lattice. In order to form an expander graph, we used the construction due to <ref type="bibr" target="#b12">Gabber and Galil (1981)</ref>. For any chosen graph topology, the n difference vectors are selected as one edge each chosen uniformly at random (with replacement) from the comparison graph.</p><p>Recall that our theory predicts that the complete and expander graphs yield the best performance, and that the line and dumbbell graphs fare the worst. Also recall that our theory predicts the error scales as w * − w 2 2 scales with n as 1/n in the complete and expander topologies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Experiments on synthetic data</head><p>This section describes simulations using data generated synthetically from the Thurstone model. In the simulations, we first generate a quality score vector w * ∈ W B using one of the procedures described below. Once w * is chosen, the n pairwise comparisons for any given topology are generated as follows. An edge is selected uniformly (with replacement) at random from the underlying graph, and the chosen edge determines the pair of items compared. The outcome of the comparison is generated as per the Thurstone model with the chosen w * as the underlying quality score. Finally, the maximum likelihood estimator for the Thurstone model is employed to estimate w * . Every point in the plots is an average across 40 trials.</p><p>The following six procedures are employed to generated the true quality score vector w * in the six respective subfigures of Figure <ref type="figure" target="#fig_7">3</ref>. (e) Packing set for the complete graph: The procedure is identical to that in (c), except that the Laplacian matrix used is that of the complete graph.</p><p>(f) Packing set for the star graph: The procedure is identical to that in (c), except that the Laplacian matrix used is that of the star graph.</p><p>The vector w * generated in this procedure is then scaled and shifted to ensure</p><formula xml:id="formula_52">w * ∈ W B .</formula><p>The values of B and σ are set as 1.  Observe in the figure that the error is the lowest under the complete and the star graphs, and the highest under the barbell and the path graphs. In particular, the error consistently varies as Θ(d 2 /n) for the complete and star graphs -this phenomenon holds even in plots (e) and (f) where the procedure to choose w * forms the worst case for the complete and star graphs respectively according to the proof of Theorem 2. On the other hand, the minimax error varies as Ω(d 3 /n) in the worst case for the path and the barbell graphs. Finally, observe that in the simulations, the (constant) multiplicative factors to the term d 2 n in the error turn out to be rather small, in the range of 0 to 9.</p><p>Although not the primary focus of this paper, we note that our implementation for computing the maximum likelihood estimate under the Thurstone model requires several tens of minutes for modest problem dimensions. Computing the MLE is a convex optimization problem. Our implementation, which is not optimized for speed, employs the sequential least squares programming subroutine of the Scipy package in the Python programming language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Experiments on MTurk</head><p>In this section, we describe the results of experiments conducted on the popular Amazon Mechanical Turk (https://www.mturk.com/; henceforth referred to as "MTurk") commercial crowdsourcing platform, evaluating the effects of the choice of the topology. MTurk is an online platform where individuals or businesses can put up a task, and any individual can log in and complete the tasks in exchange for a payment that is specified along with the task. In our experiments, each worker was offered 20 cents per completed task. A worker was allowed to do no more than one task in an experiment. Workers were required to answer all the questions in a task. Only those workers who had 100 or more prior approved works and an approval rate of 95% or higher were allowed. Workers from any country were allowed to participate, except for the task of estimating distances between cities (for which only USA-based workers were permitted since all questions involved American cities).</p><p>We conducted three experiments that required the workers to make ordinal choices.</p><p>(a) Estimating areas of circles: In each question, the worker was shown a circle in a bounding box (Figure <ref type="figure" target="#fig_9">5a</ref>), and the worker was required to identify the fraction of the box's area that the circle occupied.</p><p>(b) Estimating age of people from photographs: The worker was shown photographs of people (Figure <ref type="figure" target="#fig_9">5b</ref>) and was asked to estimate their ages.</p><p>(c) Estimating distances between pairs of cities: Pairs of cities were listed (Figure <ref type="figure" target="#fig_9">5c</ref>) and for each pair, the worker had to estimate the distance between them.</p><p>For each experiment, we recruited 140 workers on MTurk, and assigned them to one of the five topologies uniformly at random. In this experiment and others involving aggregation of ordinal data from MTurk, the aggregation procedure follows maximum likelihood estimation under the Thurstone model, and the estimator is supplied the best-fitting value of σ obtained via 3-fold cross-validation. Each run of the estimation procedure employs the data provided by five randomly chosen workers from the pool of workers who performed that task. (The number five is inspired by practical systems as in <ref type="bibr" target="#b53">Wang et al. (2011)</ref>; <ref type="bibr" target="#b38">Piech et al. (2013)</ref>.) The complete dataset pertaining to these experiments is available on the first author's website. Figure <ref type="figure" target="#fig_8">4</ref> plots the squared 2 estimation error for the three experiments under the five topologies considered, and the associated standard deviation. We see that the relative errors are generally consistent with our theory, with the complete graph exhibiting the best performance and the path graph faring the worst. On real datasets, model misspecification can in some cases cause the outcomes to differ from our theoretical predictions. Understanding the effect of model misspecification, especially on topology considerations, is an important question we hope to address in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Cardinal versus ordinal measurements</head><p>In this section, we compare two approaches towards eliciting data: a score-based "cardinal" approach and a comparison-based "ordinal" approach. In a cardinal approach, evaluators directly enter numeric scores as their answers (Figure <ref type="figure" target="#fig_1">1b</ref>), while an ordinal approach involves comparing (pairs of) items (Figure <ref type="figure" target="#fig_1">1a</ref>).</p><p>There are obvious advantages and disadvantages associated with either approach. On one hand, the cardinal approach allows for very fine measurements. For instance, the cardinal measurements in Figure <ref type="figure" target="#fig_1">1</ref> can take any value between 0 and 100, whereas an ordinal measurement is binary. One might be tempted to go even further and argue that ordinal measurements necessarily give less information, for one can always convert a set of cardinal measurements into ordinal, simply by ordering the measurements by value. If this conversion were valid, the data processing inequality (Cover and Thomas, 2012), would then guarantee that estimators based on ordinal data can never outperform estimators based on cardinal data. However, this conversion assumes that cardinal and ordinal measurements suffer from the same type of statistical fluctuation. The following set of experiments show this assumption is false.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Raw data from MTurk</head><p>We conducted seven different experiments on MTurk to investigate the possibility of a "dataprocessing inequality" between the elicited cardinal and ordinal responses: Are responses elicited in ordinal form equivalent to data obtained by first eliciting cardinal responses and then subtracting pairs of items? Our experiments lead us to conclude that this is generally  not the case: converting cardinally collected data into ordinal (by subtracting pairs of responses) often leads to a higher amount of noise as compared to that in data that is elicited directly in ordinal form. The tasks were selected to have a broad coverage of several important subjective judgment paradigms such as preference elicitation, knowledge elicitation, audio and visual perception and skill utilization.</p><p>In addition to the three experiments described in Section 4.2.2, we conducted the following four experiments.</p><p>(d) Finding spelling mistakes in text: The worker had to identify the number of words that were misspelled in each paragraph shown (Figure <ref type="figure" target="#fig_9">5d</ref>).</p><p>(e) Identifying sounds: The worker was presented with audio clips, each of which was the sound of a single key on a piano (which corresponds to a single frequency). The worker had to estimate the frequency of the sound in each audio clip (Figure <ref type="figure" target="#fig_9">5e</ref>).</p><p>(f) Rating tag-lines for a product: A product was described and tag-lines for this product were shown (Figure <ref type="figure" target="#fig_9">5f</ref>). The worker had to rate each of these tag-lines in terms of its originality, clarity and relevance to this product.</p><p>(g) Rating relevance of the results of a search query: Results for the query 'Internet' for an image search were shown (Figure <ref type="figure" target="#fig_1">1</ref>) and the worker had to rate the relevance of these results with respect to the given query.</p><p>Note that the data collected for experiments (a)-(c) here was different and independent of the data collected for these tasks in Section 4.2.2.</p><p>The number of items d in the experiments ranged from 10 to 25. For each of the seven experiments, we recruited 100 workers, and assigned each worker to either the ordinal or the cardinal version of the task at random. Upon obtaining the data, we first reduced the cardinal data obtained from the experiments into ordinal form by comparing answers given by the subjects to consecutive questions. For five of the experiments ((a) through (e)), we had access to the "ground truth" solutions, using which we computed the fraction of answers that were incorrect in the ordinal and the cardinal-converted-to-ordinal data (any tie in the latter case was counted as half an error). For the two remaining experiments ((f) and (g)) for which there is no ground truth, we computed the 'error' as the fraction of (ordinal or cardinal-converted-to-ordinal) answers provided by the subjects that disagreed with each other. It is important to note that in the experiments in this section, we did not run any estimation procedure on the data: we only measured the noise in the raw responses.</p><p>The entire data pertaining to these experiments, including the interface seen by the workers and the data obtained from their work, is available on the first author's website.</p><p>The results are summarized in Table <ref type="table" target="#tab_4">1</ref>. If the cardinal measurements could always be converted to ordinal ones with the same noise level as directly eliciting ordinal responses, then it would be unlikely for the amount of error in the ordinal setting to be smaller than that in the cardinal setting. Table <ref type="table" target="#tab_4">1</ref> shows that converting cardinal data to an ordinal form very often results in a higher (and sometimes significantly higher) per-sample error in the (raw) responses than direct elicitation of ordinal evaluations. Such an outcome may be explained by the argument that the inherent evaluation process in humans is not the same in the cardinal and ordinal cases: humans do not perform an ordinal evaluation by first performing cardinal evaluations and then comparing them <ref type="bibr" target="#b3">(Barnett, 2003;</ref><ref type="bibr" target="#b47">Stewart et al., 2005)</ref>. One can also see from Table <ref type="table" target="#tab_4">1</ref> that the amount of time required for cardinal evaluations was typically (much) higher than for ordinal evaluations. One can thus assume that we typically have the per-observation error in the ordinal case lower than that in the cardinal case. In particular, considering the Thurstone and the Cardinal models (introduced in Section 2.1) with σ and σ c denoting the standard deviations of the noise in the Thurstone and the Cardinal models respectively, the above empirical results imply that σ &lt; √ 2σ c .</p><p>Topology-dependent Estimation from Pairwise Comparisons</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Analytical comparison of Cardinal versus Ordinal</head><p>As discussed earlier, while cardinal measurements allow more flexibility in the range of responses, ordinal measurements contain a lower per-sample error. Ordinal measurements have additional benefits in that they avoid calibration issues that are frequently encountered in cardinal measurements <ref type="bibr">(Tsukida and Gupta, 2011)</ref>, such as the evaluators' inherent (and possibly time-varying) biases, or tendencies to give inflated or conservative evaluations. Ordinal measurements are also recognized to be easier or faster for humans to make <ref type="bibr" target="#b3">(Barnett, 2003;</ref><ref type="bibr" target="#b47">Stewart et al., 2005)</ref>, allowing for more evaluations with the same amount of time, effort and cost.</p><p>The lack of clarity regarding when to use a cardinal versus an ordinal approach forms the motivation of this section. Can we make as reliable estimates from paired comparisons as from numeric scores? How much lower does the noise have to be for comparative measurements to be preferred over cardinal measurements? The answers to these questions help to determine how responses should be elicited.</p><p>In order to compare the cardinal and ordinal methods of data elicitation, we focus on a setting with evenly budgeted measurements. In accordance with the fixed-design setup assumed throughout the paper, we choose the vectors x i a priori. Suppose that n is large enough, and that in the ordinal case we compare each pair n/ d 2 times. In the cardinal case suppose that we evaluate the quality of each item n/d times. We consider the Gaussiannoise models Thurstone and Cardinal introduced earlier in Section 2.1. In order to capture the fact that the amount of noise is different in the cardinal and ordinal settings, we denote the standard deviation of the noise in the cardinal setting as σ c , and retain our notation of σ for the noise in the ordinal setting. In order to bring the two models on the same footing, we measure the error in terms of the squared 2 -norm.</p><p>Let With these preliminaries in place, we now compare the minimax error in the estimation under the cardinal and ordinal settings.</p><p>Proposition 5 Given a sample size n that is a multiple of d(d − 1)b(σ, B), suppose that we observe each coordinate n/d times under the Cardinal model. Then the minimax risk is given by</p><formula xml:id="formula_53">inf w sup w * ∈W B E w − w * 2 2 = σ 2 c d n . (<label>12a</label></formula><formula xml:id="formula_54">)</formula><p>Similarly, if we observe each pair n/ d 2 times in the Thurstone model, then the minimax risk is sandwiched as</p><formula xml:id="formula_55">σ 2 b (σ, B) d n ≤ inf w sup w * ∈W B E w − w * 2 2 ≤ σ 2 b u (σ, B) d n . (<label>12b</label></formula><formula xml:id="formula_56">)</formula><p>In the cardinal case, when each coordinate is measured the same number of times, the Cardinal model reduces to the well-studied normal location model, for which the MLE Shah et al.</p><p>is known to be the minimax estimator and its risk is straightforward to characterize (see <ref type="bibr" target="#b30">Lehmann and Casella (1998)</ref> for instance). In the ordinal case, the result follows from the general treatment in Section 3.</p><p>Let us now return to the question deciding between the cardinal and the ordinal methods of data elicitation. Suppose that we believe the Gaussian-noise models to be reasonably correct, and the per-observation errors σ and σ c under the two settings are known or can be separately measured. Proposition 5 shows that the scaling of the minimax error in the cardinal and ordinal settings is identical in terms of the problem parameters n and d. As an important consequence, our result thus allows for the choice to be made based only on the parameters (σ, σ c , B), and independent of n and d: the ordinal approach incurs a lower minimax error when b u (σ, B)σ<ref type="foot" target="#foot_3">2</ref> &lt; σ 2 c while the cardinal approach is better off in terms of minimax error whenever b (σ, B)σ 2 &gt; σ 2 c . Establishing the exact decision boundary would require tightening the constants in the bounds, a task we leave for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Aggregate estimation error in experiments on MTurk</head><p>For the sake of completeness, we also computed the estimation error in the cardinal and ordinal settings. We consider data from the three experiments (c), (d) and (e). 2 We normalize the true vector to have w * ∞ = 1 and set B = 1. For each of the three experiments, we execute 100 iterations of the following procedure. Select five workers from the cardinal and five from the ordinal pool of workers uniformly at random. (The number five is inspired by practical systems as in <ref type="bibr" target="#b53">Wang et al. (2011)</ref>; <ref type="bibr" target="#b38">Piech et al. (2013)</ref>.) We run the maximumlikelihood estimator of the Cardinal model on the data from the five workers selected from the cardinal pool, and the maximum-likelihood estimator of the Thurstone model on the data from the five workers of the ordinal pool. Note that unlike Section 5.1, the cardinal data here is not converted to ordinal. The results are tabulated in Table <ref type="table" target="#tab_5">2</ref>. To put the results in perspective of the rest of the paper, let us also recall the per-sample errors in these experiments from Table <ref type="table" target="#tab_4">1</ref>. Observe that among these three experiments, the per-sample noise in the cardinal data was closest to that in the ordinal data in the experiment on identifying the number of spelling mistakes. The gap was larger in the two remaining experiments. This fact is reflected in Topology-dependent Estimation from Pairwise Comparisons the results of Table <ref type="table" target="#tab_5">2</ref> where the estimator on the cardinal data incurs a lower 2 -error than the estimator on the ordinal data in the experiment on identifying the number of spelling mistakes, whereas the outcome goes the other way in the two remaining experiments. Our theory needs to tighten the constants in order to address this regime. With respect to the Kendall's tau correlation coefficient-a particular type of ordinal metric-the estimator on the ordinal data consistently gives a higher accuracy as compared to the cardinal case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>In this paper, we presented topology-aware minimax error bounds under a broad class of preference-elicitation models. We demonstrated the utility of these results in guiding the selection of comparisons and in guiding the choice of the elicitation paradigm (cardinal versus ordinal) when these options are available. A direction for future work would be to characterize the precise thresholds for making the choice between the cardinal and ordinal approaches. Secondly, the Thurstone and BTL models are parametric idealizations that have proved useful in a wide variety of applications. In future work we would like to investigate more flexible semi-parametric and non-parametric pairwise comparison models (see, for instance, Chatterjee (2014); <ref type="bibr" target="#b6">Braverman and Mossel (2008)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shah et al.</head><p>Lemma 6 (Pairwise Fano minimax lower bound) Suppose that we can construct a (δ, β)-packing with cardinality M . Then the minimax risk is lower bounded as</p><formula xml:id="formula_57">inf w sup w * ∈W E ρ( w, w * ) 2 ≥ δ 2 2 1 − β + log 2 log M .<label>(13)</label></formula><p>The main difficulty in deriving the lower bound is the construction of a suitable packing set for application in Lemma 6. To this end, given a scalar α ∈ (0, 1 4 ) whose value will be specified later, define the integer</p><formula xml:id="formula_58">M (α) : = exp d 2 log 2 + 2α log 2α + (1 − 2α) log(1 − 2α) .<label>(14)</label></formula><p>The following two lemmas aid in our construction of a packing set. The first lemma is a straightforward consequence of the Gilbert-Varshamov bound <ref type="bibr" target="#b13">(Gilbert, 1952;</ref><ref type="bibr">Varshamov, 1957)</ref>.</p><p>Lemma 7 For any α ∈ (0, 1 4 ), there exists a set of M (α) binary vectors {z 1 , . . . , z</p><formula xml:id="formula_59">M (α) } ⊂ {0, 1} d such that αd ≤ z j − z k 2 2 ≤ d for all j = k ∈ [M (α)], and<label>(15a)</label></formula><formula xml:id="formula_60">e 1 , z j = 0 for all j ∈ [M (α)],<label>(15b)</label></formula><p>where e 1 denotes the first canonical basis vector.</p><p>The next lemma derives an upper bound on the Kullback-Leibler divergence between the probability distributions induced by any pair of quality score vectors.</p><p>Lemma 8 For any pair of quality score vectors w j and w k , and for</p><formula xml:id="formula_61">ζ : = max x∈[0,2B/σ] F (x) F (2B/σ)(1 − F (2B/σ)) ,</formula><p>we have</p><formula xml:id="formula_62">D KL (P w j P w k ) ≤ nζ σ 2 (w j − w k ) T L(w j − w k ). (<label>16</label></formula><formula xml:id="formula_63">)</formula><p>We prove these two lemmas at the end of this section.</p><p>Taking these two lemmas as given for the moment, consider the set {z 1 , . . . , z M (α) } of d-dimensional binary vectors given by Lemma 7. The Laplacian L of the comparison graph is symmetric and positive-semidefinite, and so has a diagonalization of the form L = U T ΛU where U ∈ R d×d is an orthonormal matrix, and Λ is a diagonal matrix of nonnegative eigenvalues.</p><p>Letting matrix Λ † denote the Moore-Penrose pseudo-inverse of Λ, consider the collection {w 1 , . . . , w M (α) } of vectors given by w</p><formula xml:id="formula_64">j : = δ √ d U T √ Λ † z j for each j ∈ [M (α)]. Since 1 ∈ nullspace(L), we are guaranteed that 1, w j = δ √ d 1 T U T √ Λ † z j = 0. On the other hand, (w j − w k ) T L(w j − w k ) ≤ δ 2 d (z j − z k ) T √ Λ † U LU T √ Λ † (z j − z k ) = δ 2 d (z j − z k ) √ Λ † Λ √ Λ † (z j − z k ) = δ 2 d z j − z k 2 2 ,</formula><p>Here the last step makes use of the fact that the first coordinate of each vector z j and z k is zero. It follows that αδ 2 ≤ w j − w k 2 L ≤ δ 2 . Setting δ 2 : = 0.01 σ 2 d nζ , we find that</p><formula xml:id="formula_65">w j ∞ ≤ δ √ d √ Λ † z j 2 (i) ≤ δ √ d tr(Λ † ) (ii) = δ √ d tr(L † ) (iii) ≤ B,</formula><p>where inequality (i) follows from the fact that z j has entries in {0, 1}; equation (ii) follows since L † = U T Λ † U by definition; and inequality (iii) follows from our choice of δ and our assumption n ≥ cσ 2 tr(L † ) ζB 2</p><p>on the sample size with c = 0.01. We have thus verified that each vector w j also satisfies the boundedness constraint w j ∞ ≤ B required for membership in W B . Finally, observe that max j =k D KL (P w j P w k ) ≤ nζδ 2 σ 2 , and min</p><formula xml:id="formula_66">j =k w j − w k 2 L ≥ αδ 2 .</formula><p>We have thus constructed a suitable packing set for applying Lemma 6, which yields the lower bound</p><formula xml:id="formula_67">E[ w − w * 2 L ] ≥ α 2 δ 2 1 − δ 2 ζn σ 2 + log 2 log M (α) .</formula><p>Substituting our choice of δ and setting α = 0.01 proves the claim for d &gt; 9.</p><p>In order to handle the case d ≤ 9, we consider the set of the three d-length vectors given by z</p><formula xml:id="formula_68">1 = [0 • • • 0 − 1], z 2 = [0 • • • 0 1] and z 3 = [0 • • • 0 0].</formula><p>Construct the packing set {w 1 , w 2 , w 3 } from these three vectors {z 1 , z 2 , z 3 } as done above for the case of d &gt; 9. From the calculations made for the general case above, we have for all pairs min j =k w j − w k 2 L ≥ δ 2 9 and max j,k w j − w k 2 L ≤ 4δ 2 , and as a result max j,k D KL (P</p><formula xml:id="formula_69">w j P w k ) ≤ 4nζδ 2 σ 2 . Choosing δ 2 = σ 2 log 2 8nζ</formula><p>and applying Lemma 6 proves the theorem.</p><p>The only remaining detail is to prove and Lemma 7 and Lemma 8.</p><p>Proof of Lemma 7: The Gilbert-Varshamov bound <ref type="bibr" target="#b13">Gilbert (1952);</ref><ref type="bibr">Varshamov (1957)</ref> guarantees the existence of a binary code { z 1 , . . . , z N } in dimension (d − 1), minimum Hamming distance αd , and the number of code words N at least</p><formula xml:id="formula_70">N ≥ 2 d−1 αd −1 =0 d−1 . Shah et al.</formula><p>Since d ≥ 2 and α ∈ (0, 1 4 ), we have</p><formula xml:id="formula_71">αd − 1 d − 1 ≤ 2α ≤ 1 2 .</formula><p>Applying standard bounds on the tail of the binomial distribution gives</p><formula xml:id="formula_72">1 2 d−1 αd −1 =0 d − 1 ≤ exp − (d − 1)D KL ( αd − 1 d − 1 1 2 ) ≤ exp − (d − 1)D KL (2α 1 2 ) ,</formula><p>and hence N ≥ M (α). We now define the set of vectors {z 1 , . . . , z M (α) } as (z i ) T = [0 ( z i ) T ] for every i ∈ [M (α)]. Given this condition, it is easy to see that e 1 , z j = 0 for every vector z j in this set. Finally, the minimum distance condition gives the desired constraints on the difference between any pair of vectors in this set under the squared 2 metric.</p><p>Proof of Lemma 8: For any pair of quality score vectors w j and w k , the KL divergence between the distributions P w j and P w k is given by</p><formula xml:id="formula_73">D KL (P w j P w k ) = n i=1 F ( w j , x i /σ) log F ( w j , x i /σ) F ( w k , x i /σ) +(1−F ( w j , x i /σ)) log 1−F ( w j , x i /σ) 1−F ( w k , x i /σ) .</formula><p>For any a, b ∈ (0, 1), we have the elementary inequality a log a b ≤ (a − b) a b . Applying this inequality to our expression above gives</p><formula xml:id="formula_74">D KL (P w j P w k ) ≤ n i=1 (F ( w j , x i /σ) − F ( w k , x i /σ)) F ( w j , x i /σ) F ( w k , x i /σ) − F ( w j , x i /σ)) − F ( w k , x i /σ) 1 − F ( w j , x i /σ) 1 − F ( w k , x i /σ) ≤ n i=1 (F ( w j , x i /σ) − F ( w k , x i /σ)) 2 F ( w k , x i /σ)(1 − F ( w k , x i /σ)) .</formula><p>Since max{ w j ∞ , w k ∞ } ≤ B, and since F is a non-decreasing function, we have</p><formula xml:id="formula_75">D KL (P w j P w k ) ≤ n i=1 (F ( w j , x i /σ) − F ( w k , x i /σ)) 2 F (2B/σ)(1 − F (2B/σ)) .</formula><p>Finally, applying the mean value theorem and recalling the definition of ζ (from ( <ref type="formula" target="#formula_16">6</ref>)) yields</p><formula xml:id="formula_76">D KL (P w j P w k ) ≤ n i=1 ζ( w j , x i /σ − w k , x i /σ) 2 = nζ σ 2 (w j − w k ) T L(w j − w k ),</formula><p>as claimed.</p><p>Topology-dependent Estimation from Pairwise Comparisons</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Upper bound</head><p>For the Ordinal model, the MLE is given by ŵ ∈ arg min w∈W B (w), where</p><formula xml:id="formula_77">(w) = − 1 n n i=1 1[y i = 1] log F x i , w σ + 1[y i = −1] log 1 − F x i , w σ , and<label>(17a)</label></formula><formula xml:id="formula_78">W B : = w ∈ R d | 1, w = 0, and w ∞ ≤ B . (<label>17b</label></formula><formula xml:id="formula_79">)</formula><p>Our goal is to bound the estimation error of the MLE in the squared semi-norm</p><formula xml:id="formula_80">v 2 L = v T Lv.</formula><p>For the purposes of this proof (as well as subsequent ones), let us state and prove an auxiliary lemma that applies more generally to M -estimators that are based on minimizing an arbitrary convex and differentiable function over some subset W of the set W ∞ : = {w ∈ R d | 1, w = 0}. The MLE under consideration here is a special case. This lemma requires that is differentiable and strongly convex at w * with respect to the semi-norm</p><p>• L , meaning that there is some constant κ &gt; 0 such that</p><formula xml:id="formula_81">(w * + ∆) − (w * ) − ∇ (w * ), ∆ ≥ κ ∆ 2 L (<label>18</label></formula><formula xml:id="formula_82">)</formula><p>for all perturbations ∆ ∈ R d such that (w * + ∆) ∈ W. Finally, it is also convenient to introduce the semi-norm where W is any subset of W ∞ ,</p><formula xml:id="formula_83">u L † = √ u T L † u,</formula><p>and is a differentiable cost function satisfying the κ-strong convexity condition (18) at some w * ∈ W. Then</p><formula xml:id="formula_85">w − w * L ≤ 1 κ ∇ (w * ) L † .<label>(20)</label></formula><p>Proof Since w and w * are optimal and feasible, respectively, for the original optimization problem, we have ( w) ≤ (w * ). Defining the error vector ∆ = w − w * , adding and subtracting the quantity ∇ (w * ), ∆ yields the bound</p><formula xml:id="formula_86">(w * + ∆) − (w * ) − ∇ (w * ), ∆ ≤ − ∇ (w * ), ∆ .</formula><p>By the κ-convexity condition, the left-hand side is lower bounded by κ ∆ 2 L . As for the right-hand side, note that ∆ satisfies the constraint 1, ∆ = 0, and thus is orthogonal to the nullspace of the Laplacian matrix L. Therefore, by Lemma 16 (in Appendix F), we have | ∇ (w * ), ∆ | ≤ ∇ (w * ) L † ∆ L . Combining the pieces yields the claimed inequality (20).</p><p>In order to apply Lemma 9 to the MLE for the Ordinal model, we need to verify that the negative log likelihood (17a) satisfies the strong convexity condition, and we need to bound the random variable ∇ (w * ) L † defined in the dual norm • L † .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shah et al.</head><p>Verifying strong convexity: By chain rule, the Hessian of is given by</p><formula xml:id="formula_87">∇ 2 (w) = 1 nσ 2 n i=1 1[y i = 1]T i1 + 1[y i = −1]T i2 x i x T i ,</formula><p>where</p><formula xml:id="formula_88">T i1 : = F ( w, x i σ ) 2 − F ( w, x i σ )F ( w, x i σ ) F ( w, x i σ ) 2</formula><p>, and</p><formula xml:id="formula_89">T i2 : = F ( w, x i σ ) 2 + (1 − F ( w, x i σ ))F ( w, x i σ ) (1 − F ( w, x i σ )) 2</formula><p>.</p><p>Observe that the term T i1 is simply the second derivative of log F evaluated at w, x i σ , and hence the strong log-concavity of F implies T i1 ≥ γ. On the other hand, the term T i2 is the second derivative of log(1 − F ). Since F (−x) = 1 − F (x) for all x, it follows that the function x → 1 − F (x) is also strongly log-concave with parameter γ and hence T i2 ≥ γ. Putting together the pieces, we conclude that</p><formula xml:id="formula_90">v T ∇ 2 (w)v ≥ γ nσ 2 Xv 2 2 for all v, w ∈ W B ,</formula><p>where X ∈ R n×d has the differencing vector x i ∈ R d as its i th row. Thus, if we introduce the error vector ∆ : = w − w * , then we may conclude that</p><formula xml:id="formula_91">(w * + ∆) − (w * ) − ∇ (w * ), ∆ ≥ γ nσ 2 X∆ 2 2 = γ σ 2 ∆ 2 L ,</formula><p>showing that is strongly convex around w * with parameter κ = γ σ 2 . An application of Lemma 9 then gives ∆ 2 L ≤ σ 4 γ 2 ∇ (w * ) 2 L † . Bounding the dual norm: In order to obtain a concrete bound, it remains to control the quantity ∇ (w * ) T L † ∇ (w * ). Observe that the gradient takes the form</p><formula xml:id="formula_92">∇ (w * ) = −1 nσ n i=1 1[y i = 1] F ( w * , x i /σ) F ( w * , x i /σ) − 1[y i = −1] F ( w * , x i /σ) 1 − F ( w * , x i /σ) x i .</formula><p>Define a random vector V ∈ R n with independent components as</p><formula xml:id="formula_93">V i = F ( w * , x i /σ) F ( w * , x i /σ) w.p. F ( w * , x i /σ) −F ( w * , x i /σ) 1−F ( w * , x i /σ) w.p. 1 − F ( w * , x i /σ).</formula><p>With this notation, we have ∇ (w * ) = − 1 nσ X T V . One can verify that E[V ] = 0 and</p><formula xml:id="formula_94">|V i | ≤ sup z∈[−2B/σ,2B/σ] max F (z) F (z) , F (z) 1 − F (z) ≤ sup z∈[−2B/σ,2B/σ] F (z) F (z)(1 − F (z)) ≤ ζ, (<label>21</label></formula><formula xml:id="formula_95">)</formula><p>where ζ is as defined in (6). Defining the n-dimensional square matrix M : = σ 2 γ 2 n 2 XL † X T , our definitions and previous bounds imply that ∆ 2 L ≤ V T M V .</p><p>Topology-dependent Estimation from Pairwise Comparisons Consequently, our problem has been reduced to controlling the fluctuations of the quadratic form V T M V ; in order to do so, we apply the Hanson-Wright inequality (see Lemma 13 in Appendix E). A straightforward calculation yields</p><formula xml:id="formula_96">|||M ||| 2 fro = (d − 1) σ 4 γ 4 n 2 and |||M ||| op = σ 2 γ 2 n ,</formula><p>where we have used the fact that L = 1 n X T X. Moreover, since the components of V are independent and of zero mean, a straightforward calculation yields that </p><formula xml:id="formula_97">E[V T M V ] ≤ E[ V 2 ∞ tr(M )] ≤ ζ 2 σ 2 d γ 2 n . Since |V i | ≤ ζ,</formula><formula xml:id="formula_98">P V T M V − ζ 2 σ 2 d γ 2 n &gt; t ≤ 2exp − c min{ t 2 γ 4 n 2 ζ 4 (d − 1)σ 4 , tγ 2 n ζ 2 σ 2 } for all t &gt; 0.</formula><p>Consequently, after some simple algebra, we conclude that</p><formula xml:id="formula_99">P ∆ 2 L &gt; t cζ 2 σ 2 γ 2 d n ≤ e −t for all t ≥ 1,</formula><p>for some universal constant c. Integrating this tail bound yields the bound on the expectation.</p><p>Shah et al.</p><p>that it keeps the first coordinate constant. By construction, for each j = k, we have</p><formula xml:id="formula_100">w j − w k 2 2 = δ 2 d z j − z k 2 2 ≥ αδ 2</formula><p>, where the final inequality follows from the fact that the set {z 1 , . . . , z M (α) } comprises binary vectors with a minimum Hamming distance at least αd.</p><p>Consider any distinct j, k ∈ [M (α)]. Then, for some {i 1 , . . . , i r } ⊆ {2, . . . , d} with αd ≤ r ≤ d, it must be that</p><formula xml:id="formula_101">w j − w k 2 L = δ 2 d U T P z j − U T P z k 2 L = δ 2 d z j − z k 2 Λ = δ 2 d r m=1 λ im (L).</formula><p>It follows that for some non-negative numbers a 2 , . . . , a d such that αd</p><formula xml:id="formula_102">≤ d i=2 a i ≤ d, 1 M (α) 2 j =k w j − w k 2 L = δ 2 d d i=2 a i λ i (L).</formula><p>We choose the permutation matrix P such that the last (d − 1) coordinates are permuted to have a 2 ≥ • • • ≥ a d and the d th coordinate remains fixed. With this choice, we get 1</p><formula xml:id="formula_103">M (α) 2 j =k w j − w k 2 L ≤ δ 2 d d d − 1 tr(L) ≤ 2δ 2 d tr(L).</formula><p>Lemma ( <ref type="formula" target="#formula_58">14</ref>) (Appendix F) gives the trace constraint tr(L) = 2, which in turn guarantees that</p><formula xml:id="formula_104">1 ( M (α) 2 ) j =k w j − w k 2 L ≤ 4δ 2 d .</formula><p>For the choice of P specified above, we have for every</p><formula xml:id="formula_105">j ∈ [M (α)], 1, w j = δ √ d e T 1 P z j = e T 1 z j = 0,</formula><p>where the final equation employed the property (15b).</p><p>Setting δ 2 = 0.01 σ 2 d 2 4nζ , we have w</p><formula xml:id="formula_106">j ∞ ≤ δ √ d z j 2 (i) ≤ δ (ii)</formula><p>≤ B, where inequality (i)</p><p>follows from the fact that z j has entries in {0, 1}; inequality (ii) follows from our choice of δ and our assumption n ≥ cσ 2 tr(L † ) ζB 2</p><p>on the sample size with c = 0.002, where Lemma 14 guarantees n ≥ cσ 2 d 2 4ζB 2 . We have thus verified that each vector w j also satisfies the boundedness constraint w j ∞ ≤ B required for membership in W B . From the proof of Theorem 1, we have that for any distinct D KL (P w j P w k ) ≤ nζ σ 2 w j − w k 2 L , and hence 1</p><formula xml:id="formula_107">M (α) 2 j =k D KL (P w j P w k ) ≤ nζ σ 2 4δ 2 d = 0.01 d,</formula><p>where we have substituted our previous choice of δ.</p><p>Applying Lemma 6 with the packing set {w 1 , . . . , w M (α) } gives that any estimator w must incur an error lower bounded as sup</p><formula xml:id="formula_108">w * ∈W B E w − w * 2 2 ≥ αδ 2 2 1 − 0.01d + log 2 log M (α) .</formula><p>Topology-dependent Estimation from Pairwise Comparisons</p><p>Substituting our choice of δ and setting α = 0.01 proves the claim for d &gt; 9.</p><p>For the case of d ≤ 9, consider the set of the three d-length vectors z</p><formula xml:id="formula_109">1 = [0 • • • 0 − 1], z 2 = [0 • • • 0 1] and z 3 = [0 • • • 0 0].</formula><p>Construct the packing set {w 1 , w 2 , w 3 } from these three vectors {z 1 , z 2 , z 3 } as done above for the case of d &gt; 9. From the calculations made for the general case above, we have for all pairs min j =k w j −w k 2 2 ≥ δ 2 9 and max j,k w j −w k 2 L ≤ 4δ 2 , and as a result max j,k D KL (P w j P w k ) ≤ 4nζδ 2 σ 2 . Choosing δ 2 = σ 2 log 2 8nζ and applying Lemma 6 yields the claim.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Lower bound: Part II</head><p>Given an integer d ∈ {2, . . . , d}, and scalars α ∈ (0, 1 4 ) and δ &gt; 0, define the integer</p><formula xml:id="formula_110">M (α) : = exp d 2 log 2 + 2α log 2α + (1 − 2α) log(1 − 2α) . (<label>22</label></formula><formula xml:id="formula_111">)</formula><p>Applying Lemma 7 with d as the dimension yields a subset {z 1 , . . . , z M (α) } of the Boolean hypercube {0, 1} d with the stated properties. We then define a set of d-length vectors { w 1 , . . . , w M (α) } via</p><formula xml:id="formula_112">w j = [0 (z j ) T 0 • • • 0] T for each j ∈ [M (α)]. For each j ∈ [M (α)], let us define w j : = δ √ d U T √ Λ † w j . Now, letting e 1 ∈ R d denote the first standard basis vector, we have 1, w j = δ √ d 1 T U T √ Λ † w j = 0.</formula><p>where we have used the fact that 1 ∈ nullspace(L). Furthermore, for any j = k, we have</p><formula xml:id="formula_113">w j − w k 2 2 = δ 2 d ( w j − w k ) T Λ † ( w j − w k ) ≥ δ 2 d d i= (1−α)d 1 λ i .</formula><p>Thus, setting δ 2 = 0.01 σ 2 d nζ yields</p><formula xml:id="formula_114">w j ∞ ≤ δ √ d √ Λ † w j 2 (i) ≤ δ √ d tr(Λ † ) (ii) = δ √ d tr(L † ) (iii) ≤ B,</formula><p>where inequality (i) follows from the fact that z j has entries in {0, 1}; step (ii) follows because the matrices √ Λ † and √ L † have the same eigenvalues; and inequality (iii) follows from our choice of δ and our assumption n ≥ cσ 2 tr(L † ) ζB 2 on the sample size with c = 0.01. We have thus verified that each vector w j also satisfies the boundedness constraint w j ∞ ≤ B required for membership in W B . Furthermore, for any pair of distinct vectors in this set, we have</p><formula xml:id="formula_115">w j − w k 2 L = δ 2 d z j − z k 2 2 ≤ δ 2 .</formula><p>From the proof of Theorem 1, we D KL (P w j P w k ) ≤ nζ σ 2 w j − w k 2 L ≤ 0.01d . Applying Lemma 6 with the packing set {w 1 , . . . , w M (α) } gives that any estimator w must incur an error lower bounded as sup</p><formula xml:id="formula_116">w * ∈W B E w − w * 2 2 ≥ δ 2 d d i= (1−α)d 1 λ i 2 1 − 0.01d + log 2 log M (α) .</formula><p>Shah et al.</p><p>Substituting our choice of δ and setting α = 0.01 proves the claim for d &gt; 9.</p><p>For the case of d ≤ 9, we now prove a lower bound of cσ 2 n 9 λ 2 (L) for a universal constant c &gt; 0. This quantity is at least as large as the claimed lower bound. Consider the packing set of three d-length vectors w L) . Choosing δ 2 = σ 2 log 2 8nζ and applying Lemma 6 proves the claim for d ≤ 9. Finally, taking the maximum over all values of d ∈ {2, . . . , d} gives the claimed lower bound.</p><formula xml:id="formula_117">1 = δU √ Λ † [0 1 0 • • • 0] T , w 2 = −w 1 and w 3 = [0 • • • 0] T for some δ &gt; 0. Then for every j = k, one can verify that w j −w k 2 L ≤ 4δ 2 , w j −w k 2 2 ≥ δ 2 λ 2 (</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix C. Proof of Theorem 3</head><p>We now turn to the proof of Theorem 3 on the minimax rate for the Paired Cardinal model. Recall that this observation model takes the standard linear model, y = Xw * + , where y ∈ R n , w ∈ R d and ∼ N (0, σ 2 I).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Upper bound under the squared L semi-norm</head><p>The maximum likelihood estimate in the Paired Cardinal model is a special case of the general M -estimator ( <ref type="formula" target="#formula_84">19</ref>) with (w) : = 1 2n n i=1 y i − x i , w 2 . For this quadratic objective function, it is easy to verify that the γ-convexity condition holds with γ = 1. (In particular, note that the Hessian of is given by L = X T X/n.) Given the result of Lemma 9, it remains to upper bound</p><formula xml:id="formula_118">∇ (w * ) L † . A straightforward computation yields ∇ (w * ) 2 L † = ε σ T Q ε σ where Q : = σ 2 n 2 XL † X T . Consequently, the ran- dom variable ∇ (w * ) 2</formula><p>L † is quadratic form in the standard Gaussian random vector ε σ . An application of Lemma 15 (Appendix F) gives tr(Q) = σ 2 n d − 1 and |||Q||| op = σ 2 n , and then applying a known tail bound on Gaussian quadratic forms (see Lemma 12 in Appendix E) yields</p><formula xml:id="formula_119">P ∇ (w * ) 2 L † σ 2 ≥ d n + δ √ n 2 ≤ e − δ 2 2 for all δ ≥ 0. Since d ≥ 2, we have σ d n + σ √ n δ 2 ≤ 2σ 2 dδ 2 n</formula><p>for all δ ≥ 4, which yields</p><formula xml:id="formula_120">P ∇ (w * ) 2 L † ≥ t 4σ 2 d n ≤ e −t for all t ≥ 8.</formula><p>Integrating this tail bound yields that E ∇ (w * ) 2 L † ≤ cσ 2 d n , from which the claim follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Lower bound under the squared L semi-norm</head><p>Based on the pairwise Fano lower bound previously stated in Lemma 6, we need to construct a suitable (δ, β)-packing, where the semi-norm ρ(w j , w k ) = w j − w k L is defined by the Laplacian. Given the additive Gaussian noise observation model, we also have Verifying strong convexity: The gradient of the negative log likelihood is</p><formula xml:id="formula_121">D KL (P w j P w k ) = n 2σ 2 w j − w k 2 L ,<label>(23)</label></formula><formula xml:id="formula_122">∇ (w) = − 1 n n i=1 m j=1 1[y i = j]E i R j ∇ log F (v) v=w T E i R j .</formula><p>The Hessian of the negative log likelihood can be written as</p><formula xml:id="formula_123">∇ 2 (w) = 1 n n i=1 m j=1 1[y i = j]E i R j ∇ 2 log F (v) v=w T E i R j R T j E T i .</formula><p>Using our strongly log-concave assumption on F , we have that for any vector z ∈ R d ,</p><formula xml:id="formula_124">z T ∇ 2 (w)z = − 1 n n i=1 m j=1 1[y i = j]z T E i R j ∇ 2 log F (v) v=w T E i R j R T j E T i z ≥ 1 n n i=1 m j=1 1[y i = j]z T E i R j HR T j E T i z ≥ λ 2 (H) m 1 n n i=1 m j=1 1[y i = j]z T E i (mI − 11 T )E T i z,</formula><p>where the last step follows from Lemma 11. The definition (10) of L implies that</p><formula xml:id="formula_125">z T ∇ 2 (w)z ≥ λ 2 (H) m z T Lz = λ 2 (H) m z 2 L .</formula><p>Consequently, the κ-convexity condition holds around w * with κ = λ 2 (H) m . An application of Lemma 9 then yields</p><formula xml:id="formula_126">w ML − w * 2 L ≤ m 2 λ 2 (H) 2 ∇ (w * ) 2 L † = m 2 λ 2 (H) 2 ∇ (w * ) T L † ∇ (w * ). (<label>24</label></formula><formula xml:id="formula_127">)</formula><p>Controlling the dual norm: The gradient of the negative log likelihood can then be rewritten as</p><formula xml:id="formula_128">∇ (w * ) = − 1 n n i=1 E i V i , where each index i ∈ [n], the random vector vector V i ∈ R m is given by V i : = m j=1 1[y i = j] R j ∇ log F ( w * , E i R j )</formula><p>. Now observe that the matrix M : = I− 1 m 11 T is symmetric and positive semi-definite with rank (m−1), eigenvalues {1, . . . , 1, 0}, its nullspace equals the span of the all-ones vector, and that M † = M . Using this matrix, we define the transformed vector V i : = (M † ) 1 2 V i for each i ∈ [n]. Consider a vector x and its shifted version x+t1, where t ∈ R and 1 denotes the vector of all ones. By the shift invariance property, the function g(t) = F (x + t1) − F (x) is constant, and hence g (0) = ∇F (x), 1 = 0, and g (0) = 1, ∇ 2 F (x) 1 = 0, (25)</p><p>Shah et al.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1.1 Lower bound under the squared L semi-norm</head><p>For any pair of quality score vectors w j and w k , the KL divergence between the distributions P w j and P w k is given by</p><formula xml:id="formula_129">D KL (P w j P w k ) = n i=1 m l=1 F (w j T E i R l ) log F (w j T E i R l ) F (w k T E i R l )</formula><p>.</p><p>Applying the inequality log x ≤ x − 1, valid for x &gt; 0, we find that</p><formula xml:id="formula_130">D KL (P w j P w k ) ≤ n i=1 m l=1 F (w j T E i R l ) F (w j T E i R l ) F (w k T E i R l ) − 1 .</formula><p>Now employing the fact that m l=1 F (w j T E i R l ) = m l=1 F (w k T E i R l ) = 1 gives and applying Lemma 16 (noting that w j T E i R l , nullspace(H) = 0 for all i, j, l) gives</p><formula xml:id="formula_131">D KL (P w j P w k ) ≤ n i=1 m l=1 F (w j T E i R l ) 2 F (w k T E i R l ) − 2F (w j T E i R l ) + F (w k T E i R l ) . = n i=1 m l=1 (F (w j T E i R l ) − F (w k T E i R l )) 2 F (w k T E i R l ) ≤ 1 F (−B, B, . . . , B) n i=1 m l=1 (F (w j T E i R l ) − F (w k T E i R l )) 2</formula><formula xml:id="formula_132">D KL (P w j P w k ) ≤ n i=1 m l=1 ζ w j T E i R l − w k T E i R l 2 H ≤ ζ(w j − w k ) T n i=1 m l=1 E i R l HR T l E T i (w j − w k ) ≤ ζλ m (H)n w j − w k 2 L ,<label>(26)</label></formula><p>where the final step is a result of Lemma 11. Consider the pair of scalars α ∈ (0, 1 4 ) and δ &gt; 0 whose values will be specified later. Let M (α) be as defined in (14). Consider the packing set {w 1 , . . . , w M (α) } constructed in Appendix A.1. Each of these vectors is of length d, satisfies w j , 1 = 0, and furthermore, each pair from this set satisfies αδ 2 ≤ w j − w k 2 L ≤ δ 2 . Setting δ 2 = 0.01 d nζλm(H) yields D KL (P w j P w k ) ≤ 0.01d.</p><p>Every element from the packing set also satisfies w j ∞ ≤ B when n ≥ 0.01σ 2 tr(L † ) ζB 2 λm(H) , and thus belongs to the class W B . Consider the pair of scalars α ∈ (0, 1 4 ) and δ &gt; 0 whose values will be specified later. Let M (α) be as defined in <ref type="bibr">(14)</ref>. In Appendix B.2 we constructed a set {w 1 , . . . , w M (α) } of vectors of length d that satisfy w j , 1 = 0 for every j ∈ [M (α)], and for every pair of vectors in this set, w j − w k 2 2 ≥ αδ 2 and 1 ( M (α) 2 ) j =k w j − w k 2 L ≤ 2δ 2 d tr(L). Applying Lemma 10 gives 1</p><formula xml:id="formula_133">M (α) 2 j =k w j − w k 2 L ≤ 2δ 2 d m(m − 1).</formula><p>Setting δ 2 = 0.005</p><formula xml:id="formula_134">d 2</formula><p>nζλm(H)m(m−1) yields D KL (P w j P w k ) ≤ 0.01d.</p><p>In a manner similar to Lemma 14 in the pairwise comparison case, one can show that in the general setting of this section, tr(L † ) ≥ d 2 4m(m−1) . Then, every element from the packing set also satisfies w j ∞ ≤ B when δ ≤ B, which holds true under our assumption Setting α = 0.01 proves the claim for d &gt; 9.</p><p>For the case of d ≤ 9, consider the set of the three d-length vectors</p><formula xml:id="formula_135">z 1 = [0 • • • 0 − 1], z 2 = [0 • • • 0 1] and z 3 = [0 • • • 0 0].</formula><p>Construct the packing set {w 1 , w 2 , w 3 } from these three vectors {z 1 , z 2 , z 3 } as done above for the case of d &gt; 9. From the calculations made for the general case above, we have for all pairs min j =k w j −w k 2 2 ≥ δ 2 9 and max j,k w j −w k 2 L ≤ 4δ 2 , and as a result max j,k D KL (P w j P w k ) ≤ 4nζλ m (H)δ 2 . Choosing δ 2 = log 2 8nζλm(H) and applying Lemma 6 proves the claim.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Some implied properties of the model</head><p>In this section, we prove the two auxiliary lemmas stated at the start of this appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2.1 Proof of Lemma 10</head><p>From the definition (10) of L, have</p><formula xml:id="formula_136">L1 = 1 n n i=1 E i (mI − 11 T )E T i 1 = 1 n n i=1 E i (mI − 11 T )1 = 0,</formula><p>showing that 1 ∈ nullspace(L). Now consider any non-zero vector v : = [v 1 , . . . , v d ] T ∈ R d such that v / ∈ span(1). Then there must exist some i, j ∈ [d] such that v i = v j . We know that there exists some path from item i to j in the comparison hyper-graph. Thus there must exist some hyper-edge in this path with two items, say i , j , such that v i = v j . Suppose that hyper-edge corresponds to sample ∈ [n]. Let v : = E T v. Then v / ∈ span(1). The Cauchy-Schwarz inequality v , v 1, 1 &gt; ( v , 1 ) 2 thus implies v T E (mI − 11 T )E T v &gt; 0.</p><p>Furthermore, for any v ∈ R m , the Cauchy-Schwarz inequality v , v 1, 1 &gt; ( v , 1 ) 2 implies that for any i ∈ [n], we have v T E i (mI − 11 T )E T i v ≥ 0. Overall we conclude that have v T Lv &gt; 0 for every v / ∈ span(1), and hence, nullspace(L) = 1 and λ 2 (L) &gt; 0.  </p><formula xml:id="formula_137">λ i (H) v , h i 2 ≥ λ 2 (H) m i=2 v , h i 2 = λ 2 (H) m i=1 v , h i 2 − 1 m v , 1 2 = λ 2 (H)v T (I − 1 m 11 T )v ,</formula><p>where the final step employed the property m i=1 h i h T i = I of the eigenvectors h 1 , . . . , h m of H. A similar argument gives</p><formula xml:id="formula_138">v T Hv = m i=2 λ i (H) v , h i 2 ≤ λ max (H) m i=2 v , h i 2 = λ max (H) m i=1 v , h i 2 − 1 m v , 1 2 = λ max (H)v T (I − 1 m 11 T )v . Setting v = R T j v gives λ 2 (H)v T R j (I − 1 m 11 T )R T j v ≤ v T R j HR T j v ≤ λ max (H)v T R j (I − 1 m 11 T )R T j v.</formula><p>Observe that the matrix I − 1 m 11 T is invariant to permutation of the coordinates, and hence R j (I − 1 m 11 T )R T j = I − 1 m 11 T . This gives</p><formula xml:id="formula_139">λ 2 (H) m v T (mI − 11 T )v ≤ v T R j HR T j v ≤ λ max (H) m v T (mI − 11 T )v.</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>this image for the search query 'INTERNET'? (b) Asking for a numeric score.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of eliciting judgments from people: rating the relevance of the result of a search query.</figDesc><graphic url="image-4.png" coords="2,222.86,122.30,70.04,70.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Simulation results under the Thurstone model. The comparison topology chosen here is the complete graph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>[d] has a certain underlying quality score w * j ∈ [−B, B]. Suppose you have access to n samples, with each sample being a selection of the item with the largest perceived value among some m presented items. Consider (d × m) matrices E 1 , . . . , E n such that for each i ∈ [n], the m columns of E i are distinct unit vectors. The positions of the non-zero elements in the m columns of E i represent the identities of the m items compared in the i th sample. One can visualize the choices of the items compared as a hyper-graph, with d vertices representing the d items and hyper-edge i ∈ [n] containing the m items compared in observation i.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Shah et al. Laplacian is given by 2 1 − cos πi d , i ∈ {0, . . . , d − 1}, and that of the scaled Laplacian is thus 2 d−1 1 − cos πi d , i ∈ {0, . . . , d − 1}. The relation (1 − cos x) = sin 2 x 2 and the approximation sin x ≈ x for values of x close to zero gives λ 2 (L) = Θ( 1 d 3 ). The minimax risk is thus upper bounded as O( d 4 n ) and lower bounded as Ω( d 3 n ). This class of graphs is thus strictly suboptimal. • Cycle. A cycle is identical to a path except for an additional edge between node d and node 1. The spectrum of the regular Laplacian is given by 2 1 − cos 2πi d , i ∈ {0, . . . , d − 1}, and that of the scaled Laplacian is thus 2 d 1 − cos 2πi d , i ∈ {0, . . . , d − 1}. The relation (1 − cos x) = sin 2 x 2 and the approximation sin x ≈ x for values of x close to zero gives λ 2 (L) = Θ( 1 d 3 ). The minimax risk is thus upper bounded as O( d 4 n ) and lower bounded as Ω( d 3 n</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>(a) Gaussian: w * is drawn from the standard normal distribution N (0, I). (b) Uniform: w * is drawn uniformly at random from the set [−1, 1] d .(c) Packing set for the path graph: We first choose a vector z as by setting a value of 0 in the first coordinate, a value −1 in d 2 of the other coordinates chosen uniformly at random, and a value 1 in the remaining coordinates. Letting L = U T ΛU denote the eigen-decomposition of the Laplacian matrix of the path graph, w * is set as U T Λ † z, where Λ † is the Moore-Penrose pseudoinverse of Λ. This generation process mimics a construction used to prove the lower bound in Theorem 2, and tailors the construction for the path graph.(d) Packing set for the barbell graph: The procedure is identical to that in (c), except that the Laplacian matrix used is that of the barbell graph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Estimation error under different topologies for different generative processes in the synthetic simulations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Estimation error under different topologies in the experiments conducted on MTurk. Also shown is the standard deviation across the estimates (The error bars are smaller by a factor of √ number of samples).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Screenshots of the tasks presented to the subjects. For each task, only one version (cardinal or ordinal) is shown here.</figDesc><graphic url="image-59.png" coords="21,371.97,297.17,53.03,61.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>γ G and ζ G denote the parameters γ and ζ (defined in (1) and (6) respectively) specialized to the Gaussian distribution. Define b (σ, B) : = c 2 ζ G (B,σ) , b u (σ, B) : = c 2u ζ G (B,σ) γ G (B,σ) and b(σ, B) : = c 2 σ 2 ζ G B 2 . Observe that b , b u and b are independent of the parameters n and d.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>where L † is the Moore-Penrose pseudo-inverse of L. Lemma 9 (Upper bound for M -estimators) Consider the M -estimator w ∈ arg min w∈W (w),</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>the variables are ζ-sub-Gaussian, and hence the Hanson-Wright inequality implies that</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>Shah et al.and the MLE is obtained by constrained minimization over the set W B : = w ∈ R d | 1, w = 0, and w ∞ ≤ B . As in our proof of the upper bound in Theorem 1, we need to verify the κ-strong convexity condition, and to control the dual norm ∇ (w * ) L † .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>(</head><label></label><figDesc>∇F (z il ), w j T E i R l − w k T E i R l ) 2 , for some z il ∈ [−B, B] m . Letting ζ = sup z∈[−B,B] m ∇F (z) 2 H † F (−B,B,...,B)    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>Setting α = 0.01 proves the claim for d &gt; 9.For the case of d ≤ 9, consider the set of the three d-length vectorsz 1 = [0 • • • 0 − 1], z 2 = [0 • • • 0 1] and z 3 = [0 • • • 0 0].Construct the packing set {w 1 , w 2 , w 3 } from these three vectors {z 1 , z 2 , z 3 } as done above for the case of d &gt; 9. From the calculations made for the general case above, we have for all pairs min j =k w j − w k 2 L ≥ δ 2 9 and max j,k w j − w k 2 L ≤ 4δ 2 , and as a result max j,k D KL (Pw j P w k ) ≤ 4nζλ m (H)δ 2 . Choosing δ 2 = log 2 8nζλm(H)and applying Lemma 6 proves the claim.D.1.2 Upper bound under the squared Euclidean normThe upper bound under the squared 2 -norm follows directly from the upper bound under the squared L semi-norm in Theorem 4: noting that (w * − w) ⊥ nullspace(L), we get that(w * − w) T L(w * − w) ≥ λ 2 (L) w * − w 2 2 .Substituting this inequality in the upper bound on the minimax risk under the squared L semi-norm in Theorem 4 gives the desired result. D.1.3 Lower bound under the squared Euclidean norm Define ζ = sup z∈[−B,B] m ∇F (z) 2 H † F (−B,B,...,B) . Equation (26) in Appendix D.1.1 shows that for any vectors w j , w k ∈ W B , D KL (P w j P w k ) ≤ ζλ m (H)n w j − w k 2 L ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>Shah et al. of n ≥ cσ 2 tr(L † ) ζB 2 λm(H) ≥ cσ 2 d 2 4m(m−1)ζB 2 λm(H) with c = 0.01. Each element of our packing set thus belongs to the class W B . Applying Lemma 6 yields the lower bound w − w * 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Finally</head><label></label><figDesc>i E T i ) − tr(E i 11 T E T i ) . (27)By the definition of the matrices{E i } i∈[n] , tr(E i E T i ) = mand tr(E i 11 T E T i ) = m. Substituting these values in (27) gives the desired result tr(L) = m(m − 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>Topology-dependent Estimation from Pairwise Comparisons D.2.2 Proof of Lemma 11 Let h 1 , . . . , h m denote the m eigenvectors of H, with h 1 = 1 √ m 1. Then for any vector v ∈ R m , v T Hv = m i=2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Shah et al.</figDesc><table><row><cell cols="2">circle%is%BIGGER?%%</cell><cell></cell><cell>HIGHER%number%on%a%phone%keypad?%</cell></row><row><cell></cell><cell></cell><cell></cell><cell>!%</cell><cell>!%</cell></row><row><cell>%</cell><cell>!%</cell><cell></cell></row><row><cell cols="2">e%this%tagline%for%a%</cell><cell cols="2">%Which%image%is%more%relevant% for%the%search%query%'INTERNET'?%</cell><cell>How%relevant%is%this%image%for%% the%search%query%'INTERNET'?%</cell></row><row><cell cols="2">lthcare%plaMorm%</cell><cell></cell></row><row><cell cols="2">, fast but sure cure"</cell><cell></cell></row><row><cell></cell><cell>/%10%</cell><cell></cell></row><row><cell></cell><cell></cell><cell>!%</cell><cell>!%</cell><cell>/%100%</cell></row></table><note>(a) Asking for a pairwise comparison.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>But that is the beginning of a new story -the story of the gradual reneual of a man, the story of his gradual regeneration, of his pasing from one world into another, of his intiation into a new unknown life. That might be the subject of a new story, but our present story is ended.But that is the beginning of a new story -the story of the gradual reneual of a man, the story of his gradual regeneration, of his pasing from one world into another, of his intiation into a new unknown life. That might be the subject of a new story, but our present story is ended.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>healthcare%plaMorm% Rate%this%tagline%for%a%</cell><cell cols="2">%Which%circle%is%BIGGER?%% Who%do%you%think%is%OLDER?%</cell><cell>How%many%words%are%misspelled% between%these%ci.es?% in%this%paragraph?%% What%is%the%distance%%</cell></row><row><cell></cell><cell></cell><cell cols="4">Topology-dependent Estimation from Pairwise Comparisons !% !% /%10% !% !%</cell></row><row><cell>ine%for%a% laMorm% t sure cure" 0%</cell><cell cols="5">¢ Which circle is BIGGER? ¢ (a) How%many%words%are%misspelled% What%is%the%distance%between%% the%following%pairs%of%ci4es?% Which%pair%of%ci.es%is%farther% %Which%circle%is%BIGGER?%% in%this%paragraph?%% Who%do%you%think%is%OLDER?% !% !% away%from%each%other?% HIGHER%number%on%a%phone%keypad?% Which%tone%corresponds%to%a%% %Which%image%is%more%relevant !% (c) words%are%misspelled% (b) !% !% !% for%the%search%query%'INTERNET' Charlo2e$$ and$$ Boston$$ San$Francisco$$ and$$ Aus.n%%% !% !%</cell></row><row><cell>ink%is%OLDER?% !%</cell><cell cols="2">How many words are misspelled in this paragraph? What%is%the%distance%% (d) words are misspelled between%these%ci.es?% % San$Francisco$and$Aus.n%%% miles%</cell><cell>Which%sound%has%a%% HIGHER%frequency?% !% !% (e)</cell><cell cols="2">%Which%image%is%more%relevant% for%the%search%query%'INTERNET'?% !% !% Rate%this%tagline%for%a% healthcare%plaMorm% "Simple, fast but sure cure" /%10% (f)</cell><cell>!% %Which%circle%is%BIGGER !% How%relevant%is%this%image%for%% the%search%query%'INTERNET'?% /%100% !% !%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Who%do%you%think%is%OLDER?%</cell><cell>What%is%the%distance%betwe</cell></row><row><cell></cell><cell cols="2">%Which%image%is%more%relevant% for%the%search%query%'INTERNET'?%</cell><cell cols="2">the%search%query%'INTERNET'?% How%relevant%is%this%image%for%%</cell><cell>the%following%pairs%of%ci4e</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>!%</cell><cell>!%</cell></row><row><cell></cell><cell>!%</cell><cell>!%</cell><cell>/%100%</cell><cell></cell><cell>%Which%image%is%more%re for%the%search%query%'INT</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>!%</cell></row></table><note>%San$Francisco$and$Aus.n%%% miles% words%are%misspelled%But that is the beginning of a new story -the story of the gradual reneual of a man, the story of his gradual regeneration, of his pasing from one world into another, of his intiation into a new unknown life. That might be the subject of a new story, but our present story is ended."Simple, fast but sure cure" % San$Francisco$and$Aus.n%%% miles% % San$Francisco$and$Aus.n miles%</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Shah et al. Comparison of the average amount of error when ordinal data is collected directly versus when cardinal data is collected and converted to ordinal. Also tabulated is the median time (in seconds) taken to complete a task by a subject in either type of task.</figDesc><table><row><cell>Task</cell><cell>Circle</cell><cell>Age</cell><cell cols="5">Distance Spelling Audio Tagline Relevance</cell></row><row><cell>Error in Ordinal</cell><cell>6%</cell><cell>13%</cell><cell>17%</cell><cell>40%</cell><cell>20%</cell><cell>44%</cell><cell>31%</cell></row><row><cell>Std. dev.</cell><cell>.23</cell><cell>.33</cell><cell>.38</cell><cell>.49</cell><cell>.40</cell><cell>.47</cell><cell>.44</cell></row><row><cell cols="2">Error in Cardinal 17%</cell><cell>17%</cell><cell>20%</cell><cell>42%</cell><cell>29%</cell><cell>42%</cell><cell>35%</cell></row><row><cell>Std. dev.</cell><cell>.31</cell><cell>.38</cell><cell>.38</cell><cell>.46</cell><cell>.43</cell><cell>.46</cell><cell>.44</cell></row><row><cell>Time in Ordinal</cell><cell>98s</cell><cell>31s</cell><cell>84s</cell><cell>316s</cell><cell>66s</cell><cell>251s</cell><cell>105s</cell></row><row><cell>Std. dev.</cell><cell>21.1</cell><cell>14.3</cell><cell>62.1</cell><cell>33.2</cell><cell>11.1</cell><cell>28.1</cell><cell>13.1</cell></row><row><cell>Time in Cardinal</cell><cell>181s</cell><cell>70s</cell><cell>144s</cell><cell>525s</cell><cell>134s</cell><cell>342s</cell><cell>185s</cell></row><row><cell>Std. dev.</cell><cell>39.9</cell><cell>33.1</cell><cell>56.2</cell><cell>46.0</cell><cell>12.4</cell><cell>44.6</cell><cell>28.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Evaluation of the inferred solution from the data received from multiple workers (mean and standard deviation shown).</figDesc><table><row><cell>Task</cell><cell></cell><cell>Spelling</cell><cell>Distance</cell><cell>Audio</cell></row><row><cell>w  *  − w 2 2 d w  *  − w 2 2 d</cell><cell>in Ordinal in Cardinal</cell><cell>0.358 ± 0.035 0.350 ± 0.045</cell><cell cols="2">0.168 ± 0.026 0.444 ± 0.055 0.330 ± 0.028 0.508 ± 0.053</cell></row><row><cell cols="2">Kendall's tau coefficient in Ordinal</cell><cell cols="3">0.277 ± 0.049 0.547 ± 0.034 0.513 ± 0.047</cell></row><row><cell cols="2">Kendall's tau coefficient in Cardinal</cell><cell>0.129 ± 0.046</cell><cell>0.085 ± 0.038</cell><cell>0.304 ± 0.049</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">. A semi-norm differs from a norm in that the semi-norm of a non-zero element is allowed to be zero.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">minimax risk scales as σ 2 tr(L † )/n, then the condition tr(L † ) = Θ(d 2 ) would be necessary and sufficient for optimality of a comparison graph with the scaled Laplacian L. Observe that the graphs designated as 'optimal' in the discussion above indeed satisfy this condition. On the other hand, the graphs established as strictly suboptimal have tr(L † ) = Ω(d</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_3">. We restrict attention to these three experiments for the following reasons. There is no ground truth for experiments (f) and (g). In experiment (a), the size of each circle in each question is chosen independently from a continuous distribution, making all questions different and preventing aggregation. Experiment (b) employs a disconnected topology.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors are grateful to the Action Editor Moritz Hardt and anonymous referees for their suggestions that helped improve the manuscript. This work was partially supported by Office of Naval Research MURI grant N00014-11-1-0688, Air Force Office of Scientific Research Grant AFOSR-FA9550-14-1-0016, and National Science Foundation Grants CIF-31712-23800, DMS-1107000 and CIF-81652-23800. The work of NBS was also partially supported by a Microsoft Research PhD fellowship.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Proof of Theorem 1</head><p>The following two sections prove the lower and upper bounds (respectively) on the minimax risk of Ordinal model under the squared L semi-norm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Lower bound</head><p>Our lower bounds are based on the Fano argument, which is a standard method in minimax analysis (see for instance <ref type="bibr" target="#b51">Tsybakov (2008)</ref>). Suppose that our goal is to bound the minimax risk of estimating a parameter w over an indexed class of distributions P = {P w | w ∈ W} in the square of a pseudo-metric ρ. Consider a collection of vectors {w 1 , . . . , w M } contained within W such that min j,k∈ <ref type="bibr">[M ]</ref> j =k ρ w j , w k ≥ δ and 1 M 2 j,k∈[M ] j =k D KL (P w j P w k ) ≤ β.</p><p>We refer to any such subset as an (δ, β)-packing set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B. Proof of Theorem 2</head><p>The following two sections prove the upper and lower bounds (respectively) on the minimax risk in the squared Euclidean norm for Ordinal model. We prove the lower bound in two parts corresponding to the two components of the "max" in the statement of the theorem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Upper bound</head><p>The proof of the upper bound under the Euclidean norm follows directly from the upper bound under the L semi-norm proved in Theorem 1. From the setting described in Section 2, we have that the nullspace of the matrix L is given by the span of the all ones vector. Furthermore, we have w * − w, 1 = 0, and</p><p>Substituting this inequality into the upper bound (7b) gives the desired result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Lower bound: Part I</head><p>Since the Laplacian L of the comparison graph is symmetric and positive-semidefinite. By diagonalization, we can write L = U T ΛU where U ∈ R d×d is an orthonormal matrix, and Λ is a diagonal matrix of nonnegative eigenvalues with Λ jj = λ j (L).</p><p>We first use the Fano method (Lemma 6) to prove that the minimax risk is lower bounded as cσ 2 d 2 n . For scalars α ∈ (0, 1 4 ) and δ &gt; 0 whose values will be specified later, recall the set {z 1 , . . . , z M (α) } of vectors in the Boolean hypercube {0, 1} d given by Lemma 7. We then define a second set {w j , j ∈ [M (α)]} via w j : = δ √ d U T P z j , where P is a permutation matrix to be specified momentarily. At this point, the only constraint imposed on P is The construction of the packing and the remainder of the proof proceeds in a manner identical to the proof of the lower bound in Theorem 1, except for the absence of the requirement of w j ∞ ≤ B on the elements {w j } of the packing set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Upper bound under the squared Euclidean norm</head><p>The upper bound follows by direct analysis of the (unconstrained) least-squares estimate, which has the explicit form w = 1 n L † X T y, and thus</p><p>where we have used the fact that ∼ N (0,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 Lower bound under the squared Euclidean norm</head><p>We obtain the lower bound by computing the Bayes risk with respect to a suitably defined (proper) prior distribution over the weight vector w * . In particular, if we impose the prior w * ∼ N (0, σ 2 n L † ), Bayes' rule then leads to the posterior distribution</p><p>By applying iterated expectations, the Bayes risk is given by E w − 1 2 L † X T y 2 2 = σ 2 2 tr(L † ), which completes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix D. Proof of Theorem 4</head><p>This section presents the proof of Theorem 4 for the setting of m-wise comparisons. We first state some simple properties of the model introduced in Section 3.3, which we use subsequently in the proofs of the results.</p><p>Lemma 10 The Laplacian of the underlying pairwise-comparison graph satisfies the trace constraints nullspace(L) = 1, λ 2 (L) &gt; 0 and tr(L) = m(m − 1).</p><p>Lemma 11 For any j ∈ [m], i ∈ [n] and any vector v ∈ R m , we have</p><p>See Section D.2 for the proof of these auxiliary lemmas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Upper bound under the squared L semi-norm</head><p>We prove this upper bound by applying Lemma 9. In this case, the rescaled negative log likelihood takes the form</p><p>which implies that 1 ∈ nullspace(∇ 2 F (x)). Continuing on, we also have that</p><p>. This allows us to write</p><p>By definition, for every pair i</p><p>In order to further evaluate this expression, define a function g :</p><p>Then by definition we have g(z) = 1. Taking derivatives, we get 0 = ∇g(z) = m j=1 R j ∇F (z T R j ). It follows that E[ V i ] = 0, and hence that</p><p>Recalling the previously defined matrix M , observe that since R j is simply a permutation matrix, we have R T j M R j = M for every j ∈ [m]. By chain rule, we have ∇ log F (v), 1 = 1 F (v) ∇F (v), 1 = 0, where the last step follows from our previous calculation. It follows that</p><p>Substituting this bound into equation ( <ref type="formula">24</ref>) yields the claim.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix E. Some useful tail bounds</head><p>In this appendix, we collect a few useful tail bounds for quadratic forms in Gaussian and sub-Gaussian random variables.</p><p>Lemma 12 (Tail bound for Gaussian quadratic form) For any positive semidefinite matrix Q and standard Gaussian vector g ∼ N (0, I d ), we have</p><p>valid for all δ ≥ 0.</p><p>Proof Note that the function g → √ Qg 2 is Lipschitz with constant ||| √ Q||| op . Consequently, by concentration for Lipschitz functions of Gaussian vectors <ref type="bibr" target="#b28">(Ledoux, 2001)</ref>, the random variable Z = √ Qg 2 satisfies the upper bound</p><p>Shah et al.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>By Jensen's inequality, we have E</head><p>Lemma 13 <ref type="bibr" target="#b15">((Hanson and Wright, 1971;</ref><ref type="bibr" target="#b42">Rudelson and Vershynin, 2013)</ref>) Let V ∈ R d be a random vector with independent zero-mean components that are sub-Gaussian with parameter K, and let M ∈ R d×d be an arbitrary matrix. Then there is a universal constant c &gt; 0 such that</p><p>for all t &gt; 0.</p><p>(29)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix F. Properties of Laplacian matrices</head><p>By construction, the Laplacian L of the comparison graph is symmetric and positivesemidefinite. By the singular value decomposition, we can write L = U T ΛU where U ∈ R d×d is an orthonormal matrix, and Λ is a diagonal matrix of nonnegative eigenvalues with</p><p>In terms of the notation introduced, the Moore-Penrose pseudo-inverse is then given by L † = U T Λ † U , where Λ † is a diagonal matrix with entries</p><p>The following pair of lemmas establish some useful properties about L.</p><p>Lemma 14 The Laplacian matrix (4) satisfies the trace constraints tr(L) = 2, and tr(L † ) ≥ d 2 4 .</p><p>Proof From the definition (4) of the matrix L, we have tr(L) = 1 n n i=1 tr(x i x T i ) = 2. We also know that λ 1 (L) = 0, and hence d j=2 λ j (L) = 2. Given the latter constraint, the sum</p><p>. Some simple algebra now gives the claimed result.</p><p>Lemma 15 For the matrix L defined in (4), and for a (n × d) matrix X with x T i as its i th row,</p><p>Topology-dependent Estimation from Pairwise Comparisons</p><p>Proof Let Q = 1 n x T L † x. Since L = 1 n X T X = U T ΛU , the diagonal entries of Λ are the squared singular values of X/ √ n. Consequently, there must exist an orthonormal matrix V such that X/ √ n = V √ ΛU T , and thus we can write</p><p>By definition of the Moore-Penrose pseudo-inverse, the matrix √ Λ Λ † √ Λ is a diagonal matrix; since the Laplacian graph is connected, its diagonal contains (d − 1) ones and a single zero. Noting that V is an orthonormal matrix gives the claimed result.</p><p>For future reference, we state and prove a lemma showing that these two semi-norms satisfy a restricted form of the Cauchy-Schwarz inequality:</p><p>Lemma 16 For any two vectors u and v such that u ⊥ nullspace(L) or/and v ⊥ nullspace(L), we have</p><p>where we have defined v : = √ ΛU v and u : =</p><p>where we have used the fact that u or/and v are orthogonal to the null space of L. Since U is orthonormal, we conclude that v, u = v, u , which completes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix G. Minimax risk without assumptions on quality scores</head><p>The setting considered throughout the paper imposes two restrictions (2) on the quality score vector w * . The first condition is that of shift invariance, that is, w * , 1 = 0. The necessity of this condition for identifiability under the Ordinal model is easy to verify. The second condition is that the quality score vectors are B-bounded, that is, w * ∞ ≤ B for some finite B. In this section, for the sake of completeness, we show that the minimax risk is infinite in the absence of this condition. The remainder of this section is devoted to the formal proof of Proposition 17. Consider the event where for every comparison, the item with the higher quality score in w * wins. For any w * ∈ W ∞ \{0}, this event occurs with a probability at least 1 2 n . Under this event, the true w * is indistinguishable from the quality score vector cw * ∈ W ∞ for every c ≥ 0, and the error is also unbounded. Since the probability of this event is strictly bounded away from zero, the expected error is also unbounded. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Ranking: Compare, don&apos;t score</title>
		<author>
			<persName><forename type="first">Ammar</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devavrat</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Allerton Conference on Communication, Control, and Computing</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="776" to="783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Asian American preferences for counselor characteristics: Application of the Bradley-Terry-Luce model to paired comparison data</title>
		<author>
			<persName><forename type="first">Bruce</forename><forename type="middle">E</forename><surname>Donald R Atkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susana</forename><forename type="middle">M</forename><surname>Wampold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linda</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyun-Nie</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName><surname>Ahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Counseling Psychologist</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="101" to="123" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Preference elicitation for general random utility models</title>
		<author>
			<persName><forename type="first">Hossein</forename><surname>Azari Soufiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">C</forename><surname>Parkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lirong</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in Artificial Intelligence: Proceedings of the 29th Conference</title>
				<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The modern theory of consumer behavior: Ordinal or cardinal?</title>
		<author>
			<persName><forename type="first">William</forename><surname>Barnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Quarterly Journal of Austrian Economics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="65" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Rank analysis of incomplete block designs: I. the method of paired comparisons</title>
		<author>
			<persName><forename type="first">Ralph</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bradley</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Milton</forename><forename type="middle">E</forename><surname>Terry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="page" from="324" to="345" />
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A rank-ordering method for equating tests by expert judgment</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Bramley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Measurement</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="202" to="223" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Noisy sorting without resampling</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Braverman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elchanan</forename><surname>Mossel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Discrete Algorithms</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="268" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Andries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Willem</forename><forename type="middle">H</forename><surname>Brouwer</surname></persName>
		</author>
		<author>
			<persName><surname>Haemers</surname></persName>
		</author>
		<title level="m">Spectra of graphs</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Matrix estimation by universal singular value thresholding</title>
		<author>
			<persName><forename type="first">Sourav</forename><surname>Chatterjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="177" to="214" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Pairwise ranking aggregation in a crowdsourced setting</title>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevyn</forename><surname>Collins-Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Web Search and Data Mining</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="193" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Elements of information theory</title>
		<author>
			<persName><forename type="first">M</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joy</forename><forename type="middle">A</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Imagenet: A largescale hierarchical image database</title>
		<author>
			<persName><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
				<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Explicit constructions of linear-sized superconcentrators</title>
		<author>
			<persName><forename type="first">Ofer</forename><surname>Gabber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zvi</forename><surname>Galil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="407" to="420" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A comparison of signalling alphabets</title>
		<author>
			<persName><forename type="first">Gilbert</forename><surname>Edgar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell System Technical Journal</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="504" to="522" />
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Topology-dependent Estimation from Pairwise Comparisons Bruce Hajek, Sewoong Oh, and Jiaming Xu. Minimax-optimal inference from partial rankings</title>
		<author>
			<persName><forename type="first">Douglas</forename><surname>Paul E Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">S</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName><surname>Desarbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="1981">1981. 2014</date>
			<biblScope unit="page" from="1475" to="1483" />
		</imprint>
	</monogr>
	<note>Estimating choice probabilities in multiattribute decision making</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A bound on tail probabilities for quadratic forms in independent random variables</title>
		<author>
			<persName><forename type="first">David</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanson</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Farroll</forename><surname>Tim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wright</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Annals of Mathematical Statistics</title>
				<imprint>
			<date type="published" when="1971">1971</date>
			<biblScope unit="page" from="1079" to="1083" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Using the method of pairwise comparison to obtain reliable teacher assessments</title>
		<author>
			<persName><forename type="first">Sandra</forename><surname>Heldsinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Humphry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Australian Educational Researcher</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Trueskill: A Bayesian skill rating system</title>
		<author>
			<persName><forename type="first">Ralf</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Minka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thore</forename><surname>Graepel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">569</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups</title>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdel-Rahman</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tara</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="82" to="97" />
			<date type="published" when="2012">2012</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Inferring rankings under constrained sensing</title>
		<author>
			<persName><forename type="first">Srikanth</forename><surname>Jagabathula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devavrat</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="753" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Active ranking using pairwise comparisons</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kevin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Jamieson</surname></persName>
		</author>
		<author>
			<persName><surname>Nowak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2240" to="2248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">In search of quality in crowdsourcing for search engine evaluation</title>
		<author>
			<persName><forename type="first">Gabriella</forename><surname>Kazai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="165" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An approach for preference ranking of alternatives</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zahid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stanley</forename><surname>Khairullah</surname></persName>
		</author>
		<author>
			<persName><surname>Zionts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European journal of operational research</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="329" to="342" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Crystal structure of a monomeric retroviral protease solved by protein folding game players</title>
		<author>
			<persName><forename type="first">Firas</forename><surname>Khatib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Dimaio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maciej</forename><surname>Kazmierczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miroslaw</forename><surname>Gilski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Szymon</forename><surname>Krzywda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helena</forename><surname>Zabranska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iva</forename><surname>Pichova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zoran</forename><surname>Popović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariusz</forename><surname>Jaskolski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature structural &amp; molecular biology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1175" to="1177" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The depth/breadth trade-off in the design of menu-driven user interfaces</title>
		<author>
			<persName><forename type="first">John I</forename><surname>Kiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Man-Machine Studies</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="201" to="213" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">An application of a biased version of the Bradley-Terry-Luce model to professional basketball results</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kenneth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harold</forename><surname>Koehler</surname></persName>
		</author>
		<author>
			<persName><surname>Ridpath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Thurstone scaling as a measurement method to quantify subjective health outcomes</title>
		<author>
			<persName><surname>Paul Fm Krabbe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical care</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="357" to="365" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Using Amazon Mechanical Turk to transcribe historical handwritten documents</title>
		<author>
			<persName><forename type="first">Asid</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Rio-Ross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Code4Lib Journal</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">The Concentration of Measure Phenomenon. Mathematical Surveys and Monographs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ledoux</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>American Mathematical Society</publisher>
			<pubPlace>Providence, RI</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A model-based approach to measuring expertise in ranking tasks</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Michael D Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mindy</forename><forename type="middle">De</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brent</forename><forename type="middle">J</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd annual conference of the cognitive science society</title>
				<meeting>the 33rd annual conference of the cognitive science society</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Theory of Point Estimation</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Casella</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Springer Texts in Statistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Testing the power of arguments in referendums: A Bradley-Terry approach</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>John Loewen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Rubenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Spirling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electoral Studies</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="212" to="221" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Crowdsourcing malaria parasite quantification: an online game for analyzing images of infected thick blood smears</title>
		<author>
			<persName><forename type="first">Luce</forename><forename type="middle">;</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Frean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Miguel Angel Luengo-Oroz, Asier Arranz</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1959">1959. 2012</date>
			<biblScope unit="volume">14</biblScope>
		</imprint>
	</monogr>
	<note>Individual Choice Behavior: A Theoretical Analysis</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The magical number seven, plus or minus two: some limits on our capacity for processing information</title>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">81</biblScope>
			<date type="published" when="1956">1956</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Iterative ranking from pair-wise comparisons</title>
		<author>
			<persName><forename type="first">Sewoong</forename><surname>Sahand Negahban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devavrat</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2474" to="2482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Sewoong</forename><surname>Sahand Negahban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devavrat</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><surname>Shah</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1209.1688v4</idno>
		<title level="m">Rank centrality: Ranking from pairwise comparisons</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Luce&apos;s choice model and Thurstone&apos;s categorical judgment model compared: Kornbrot&apos;s data revisited</title>
		<author>
			<persName><surname>Robert M Nosofsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="89" to="91" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
	<note>Attention</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Imbuzeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oliveira</forename></persName>
		</author>
		<idno type="arXiv">arXiv:0911.0600</idno>
		<title level="m">Concentration of the adjacency matrix and of the laplacian in random graphs with independent edges</title>
				<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Tuned models of peer assessment in MOOCs</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Piech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenghao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuong</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Educational Data Mining</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Arun Rajkumar and Shivani Agarwal. A statistical convergence perspective of algorithms for rank aggregation from pairwise data</title>
		<author>
			<persName><forename type="first">Robin</forename><forename type="middle">L</forename><surname>Plackett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning</title>
				<meeting>the 31st International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="1975">1975. 2014</date>
			<biblScope unit="page" from="118" to="126" />
		</imprint>
	</monogr>
	<note>The analysis of permutations</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning from crowds</title>
		<author>
			<persName><forename type="first">Shipeng</forename><surname>Vikas C Raykar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linda</forename><forename type="middle">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerardo</forename><forename type="middle">Hermosillo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Valadez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Florin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linda</forename><surname>Bogoni</surname></persName>
		</author>
		<author>
			<persName><surname>Moy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="1297" to="1322" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Arpad Elo and the Elo rating system</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ross</surname></persName>
		</author>
		<ptr target="http://en.chessbase.com/post/arpad-elo-and-the-elo-rating-system" />
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Hanson-wright inequality and sub-gaussian concentration. Electronic Communications in Probability</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Rudelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Vershynin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Why the magic number seven plus or minus two</title>
		<author>
			<persName><forename type="first">L</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mujgan</forename><forename type="middle">S</forename><surname>Saaty</surname></persName>
		</author>
		<author>
			<persName><surname>Ozdemir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical and Computer Modelling</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="233" to="244" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A case for ordinal peer-evaluation in MOOCs</title>
		<author>
			<persName><forename type="first">B</forename><surname>Nihar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">K</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhay</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Parekh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kannan</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><surname>Ramchandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Data Driven Education</title>
				<imprint>
			<date type="published" when="2013-12">December 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Nihar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sivaraman</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhay</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kannan</forename><surname>Parekh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><forename type="middle">J</forename><surname>Ramchandran</surname></persName>
		</author>
		<author>
			<persName><surname>Wainwright</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.6618</idno>
		<title level="m">When is it better to compare than to score?</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Seven plus or minus two: a commentary on capacity limitations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">M</forename><surname>Shiffrin</surname></persName>
		</author>
		<author>
			<persName><surname>Nosofsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Absolute identification by relative judgment</title>
		<author>
			<persName><forename type="first">Neil</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gordon</forename><forename type="middle">Da</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Chater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">881</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The relative operating characteristic in psychology</title>
		<author>
			<persName><forename type="first">John</forename><surname>Swets</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">182</biblScope>
			<biblScope unit="issue">4116</biblScope>
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A law of comparative judgment</title>
		<author>
			<persName><surname>Louis L Thurstone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">273</biblScope>
			<date type="published" when="1927">1927</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Kristi Tsukida and Maya R Gupta. How to analyze paired comparison data</title>
		<author>
			<persName><surname>Kenneth E Train</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009. 2011</date>
			<publisher>DTIC Document</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>Discrete choice methods with simulation</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">RR Varshamov. Estimate of the number of signals in error correcting codes</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Tsybakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dokl. Akad. Nauk SSSR</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="739" to="741" />
			<date type="published" when="1957">2008. 1957</date>
			<publisher>Springer Series in Statistics</publisher>
		</imprint>
	</monogr>
	<note>Introduction to Nonparametric Estimation</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Recaptcha: Human-based character recognition via web security measures</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Luis Von Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Maurer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Mcmillen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName><surname>Blum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">321</biblScope>
			<biblScope unit="issue">5895</biblScope>
			<biblScope unit="page" from="1465" to="1468" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Managing crowdsourcing workers</title>
		<author>
			<persName><forename type="first">Jing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panagiotis</forename><forename type="middle">G</forename><surname>Ipeirotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Foster</forename><surname>Provost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Winter Conference on Business Intelligence</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="10" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Inferring users&apos; preferences from crowdsourced pairwise comparisons: A matrix completion approach</title>
		<author>
			<persName><forename type="first">Jinfeng</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaili</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anil</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Human Computation and Crowdsourcing</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
