<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Learning for IoT Big Data and Streaming Analytics: A Survey</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Western Michigan University</orgName>
								<address>
									<postCode>49008</postCode>
									<settlement>Kalamazoo</settlement>
									<region>MI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Idaho</orgName>
								<address>
									<postCode>83844</postCode>
									<settlement>Moscow</settlement>
									<region>ID</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Fast Data Analytics -Deep Learning Models for IoT Big Data Analytics IoT Devices Edge Devices/ Fog Computing IoT Cloud</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Learning for IoT Big Data and Streaming Analytics: A Survey</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/COMST.2018.2844341</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2018.2844341, IEEE Communications Surveys &amp; Tutorials received September 19, 2017; revised March 30, 2018; accepted May 23, 2018. This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2018.2844341, IEEE Communications Surveys &amp; Tutorials This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2018.2844341, IEEE Communications Surveys &amp; Tutorials</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Deep Learning</term>
					<term>Deep Neural Network</term>
					<term>Internet of Things</term>
					<term>On-device Intelligence</term>
					<term>IoT Big Data</term>
					<term>Fast data analytics</term>
					<term>Cloud-based analytics Model Category Learning model Typical input data Characteristics Sample IoT Applications AE Generative Unsupervised Various</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the era of the Internet of Things (IoT), an enormous amount of sensing devices collect and/or generate various sensory data over time for a wide range of fields and applications. Based on the nature of the application, these devices will result in big or fast/real-time data streams. Applying analytics over such data streams to discover new information, predict future insights, and make control decisions is a crucial process that makes IoT a worthy paradigm for businesses and a quality-of-life improving technology. In this paper, we provide a thorough overview on using a class of advanced machine learning techniques, namely Deep Learning (DL), to facilitate the analytics and learning in the IoT domain. We start by articulating IoT data characteristics and identifying two major treatments for IoT data from a machine learning perspective, namely IoT big data analytics and IoT streaming data analytics. We also discuss why DL is a promising approach to achieve the desired analytics in these types of data and applications. The potential of using emerging DL techniques for IoT data analytics are then discussed, and its promises and challenges are introduced. We present a comprehensive background on different DL architectures and algorithms. We also analyze and summarize major reported research attempts that leveraged DL in the IoT domain. The smart IoT devices that have incorporated DL in their intelligence background are also discussed. DL implementation approaches on the fog and cloud centers in support of IoT applications are also surveyed. Finally, we shed light on some challenges and potential directions for future research. At the end of each section, we highlight the lessons learned based on our experiments and review of the recent literature.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The vision of the Internet of Things (IoT) is to transform traditional objects to being smart by exploiting a wide range of advanced technologies, from embedded devices and communication technologies to Internet protocols, data analytics, and so forth <ref type="bibr" target="#b0">[1]</ref>. The potential economic impact of IoT is expected to bring many business opportunities and to accelerate the economic growth of IoT-based services. Based on McKinsey's report on the global economic impact of IoT <ref type="bibr" target="#b1">[2]</ref>, the annual economic impact of IoT in 2025 would be in the range of $2.7 to $6.2 trillion. Healthcare constitutes the major part, about 41% of this market, followed by industry and energy with 33% and 7% of the IoT market, respectively. Other domains such as transportation, agriculture, urban infrastructure, security, and retail have about 15% of the IoT market totally. These expectations imply the tremendous and steep growth of the IoT services, their generated data and consequently their related market in the years ahead.</p><p>Indeed, machine learning (ML) will have effects on jobs and the workforce, since parts of many jobs may be "suitable for ML applications" <ref type="bibr" target="#b2">[3]</ref>. This will lead to increase in demand for some ML products and the derived demand for the tasks, platforms, and experts needed to produce such products. The economic impact of machine learning in McKinsey's report <ref type="bibr" target="#b1">[2]</ref> is defined under knowledge work automation; "the use of computers to perform tasks that rely on complex analyses, subtle judgments, and creative problem solving". The report mentions that advances in ML techniques, such as deep learning and neural networks, are the main enablers of knowledge work automation. Natural user interfaces, such as speech and gesture recognition are other enablers that are highly benefiting from ML technologies. The estimated potential economic impact of knowledge work automation could reach $5.2 trillion to $6.7 trillion per year by 2025. Fig. <ref type="figure">2</ref>. The break down of estimated economic impact of $5.2 trillion to $6.7 trillion per year for machine learning in 2025.</p><p>their desired living standard.</p><p>In recent years, many IoT applications arose in different vertical domains, i.e., health, transportation, smart home, smart city, agriculture, education, etc. The main element of most of these applications is an intelligent learning mechanism for prediction (i.e., regression, classification, and clustering), data mining and pattern recognition or data analytics in general. Among the many machine learning approaches, Deep Learning (DL) has been actively utilized in many IoT applications in recent years. These two technologies (i.e., DL and IoT) are among the top three strategic technology trends for 2017 that were announced at Gartner Symposium/ITxpo 2016 <ref type="bibr" target="#b3">[4]</ref>. The cause of this intensive publicity for DL refers to the fact that traditional machine learning approaches do not address the emerging analytic needs of IoT systems. Instead, IoT systems need different modern data analytic approaches and artificial intelligence (AI) methods according to the hierarchy of IoT data generation and management as illustrated in Figure <ref type="figure" target="#fig_0">1</ref>.</p><p>The growing interest in the Internet of Things (IoT) and its derivative big data need stakeholders to clearly understand their definition, building blocks, potentials and challenges. IoT and big data have a two way relationship. On one hand, IoT is a main producer of big data, and on the other hand, it is an important target for big data analytics to improve the processes and services of IoT <ref type="bibr" target="#b4">[5]</ref>. Moreover, IoT big data analytics have proven to bring value to the society. For example, it is reported that, by detecting damaged pipes and fixing them, the Department of Park Management in Miami has saved about one million USD on their water bills <ref type="bibr" target="#b5">[6]</ref>.</p><p>IoT data are different than the general big data. To better understand the requirements for IoT data analytics, we need to explore the properties of IoT data and how they are different from those of general big data. IoT data exhibits the following characteristics <ref type="bibr" target="#b5">[6]</ref>:</p><p>? Large-Scale Streaming Data: A myriad of data capturing devices are distributed and deployed for IoT applications, and generate streams of data continuously. This leads to a huge volume of continuous data. ? Heterogeneity: Various IoT data acquisition devices gather different information resulting in data heterogeneity.</p><p>? Time and space correlation: In most of IoT applications, sensor devices are attached to a specific location, and thus have a location and time-stamp for each of the data items.</p><p>? High noise data: Due to tiny pieces of data in IoT applications, many of such data may be subject to errors and noise during acquisition and transmission.</p><p>Although obtaining hidden knowledge and information out of big data is promising to enhance the quality of our lives, it is not an easy and straightforward task. For such a complex and challenging task that goes beyond the capabilities of the traditional inference and learning approaches, new technologies, algorithms, and infrastructures are needed <ref type="bibr" target="#b6">[7]</ref>. Luckily, the recent progresses in both fast computing and advanced machine learning techniques are opening the doors for big data analytics and knowledge extraction that is suitable for IoT applications.</p><p>Beyond the big data analytics, IoT data calls for another new class of analytics, namely fast and streaming data analytics, to support applications with high-speed data streams and requiring time-sensitive (i.e., real-time or near real-time) actions. Indeed, applications such as autonomous driving, fire prediction, driver/elderly posture (and thus consciousness and/or health condition) recognition demands for fast processing of incoming data and quick actions to achieve their target. Several researchers have proposed approaches and frameworks for fast streaming data analytics that leverage the capabilities of cloud infrastructures and services <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>. However, for the aforementioned IoT applications among others, we need fast analytics in smaller scale platforms (i.e., at the system edge) or even on the IoT devices themselves. For example, autonomous cars need to make fast decisions on driving actions such as lane or speed change. Indeed, this kind of decisions should be supported by fast analytics of possibly multi-modal data streaming from several sources, including the multiple vehicle sensors (e.g., cameras, radars, LIDARs, speedometer, left/right signals, etc.), communications from other vehicles, and traffic entities (e.g., traffic light, traffic signs). In this case, transferring data to a cloud server for analysis and returning back the response is subject to latency that could cause traffic violations or accidents. A more critical scenario would be detecting pedestrians by such vehicles. Accurate recognition should be performed in strict real-time to prevent fatal accidents. These scenarios imply that fast data analytics for IoT have to be close to or at the source of data to remove unnecessary and prohibitive communication delays.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Survey Scope</head><p>DL models in general bring two important improvements over the traditional machine learning approaches in the two phases of training and prediction. First, they reduce the need for hand crafted and engineered feature sets to be used for the training <ref type="bibr" target="#b9">[10]</ref>. Consequently, some features that might not be apparent to a human view can be extracted easily by DL models. In addition, DL models improve the accuracy 1 .</p><p>In this paper, we review a wide range of deep neural network (DNN) architectures and explore the IoT applications that have benefited from DL algorithms. The paper identifies five main foundational IoT services that can be used in different vertical domains beyond the specific services in each domain. It will also discuss the characteristics of IoT applications and the guide to matching them with the most appropriate DL model. This survey focuses on the confluence of two emerging technologies, one in communication networks, i.e., IoT and the other in artificial intelligence, i.e., DL, detailing their potential applications and open issues. The survey does not cover traditional machine learning algorithms for IoT data analytics as there are some other attempts, mentioned in section I-B, that have covered such approaches. Moreover, this survey also does not go into the details of the IoT infrastructure from a communications and networking perspective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Related Work</head><p>To the best of our knowledge, there does not exist an article in the literature that is dedicated to surveying the specific relation between IoT data and DL as well as applications of DL methods in IoT. There are few works presenting common data mining and machine learning methods that have been used in IoT environments. The work presented in <ref type="bibr" target="#b10">[11]</ref> by Tsai et al. focused on data mining approaches in IoT. It addressed different classification, clustering, and frequent pattern mining algorithms for the IoT infrastructure and services. However, that work did not consider DL approaches, which is the focus of our survey. Moreover, their focus is mainly on offline data mining, while we also consider learning and mining for both real-time (i.e., fast) and big data analytics.</p><p>In <ref type="bibr" target="#b11">[12]</ref>, Perera et al. have reviewed different classes of machine learning approaches (supervised and unsupervised, rules, fuzzy logic, etc.) in the reasoning phase of a contextaware computing system, and have discussed the potentials of applying those methods in IoT systems. Nonetheless, they also did not study the role of DL on the context reasoning.</p><p>The work in <ref type="bibr" target="#b12">[13]</ref> by Alsheikh et al. provides a survey of machine learning methods for wireless sensor networks (WSNs). In that work, the authors studied machine learning methods in the functional aspects of WSNs, such as routing, localization, and clustering, as well as non-functional requirements, such as security and quality of service. They reviewed several algorithms in supervised, unsupervised, and reinforcement learning approaches. This work focuses on the infrastructure of WSN (which is one potential infrastructure for implementing 1 Accuracy in this work in general refers to the degree to which the result of the prediction conforms to the ground truth values. Readers may also face top-2 or top-3 accuracy in the text. In general, top-N accuracies refers to considering the N highest-probability answers of the prediction model and checking whether that set contains the expected value or not. Therefore, top-1 accuracy refers to the output with the highest probability. Likewise, top-3 accuracy refers to the three most probable predictions. For example, if we feed a picture of a tiger to a model that recognizes animal images, and it returns the list of possible outputs as dog:0.72, tiger:0.69, and cat:0.58, the top-1 accuracy will output the answer set containing only "dog", which is counted as wrong. On the other hand, the top-2 and top-3 accuracies will result in output sets containing "tiger" as an answer, and are thus counted as correct.</p><p>IoT applications), while our work is not dependent on the sources of data (i.e., IoT infrastructures) and covers a wide range of IoT applications and services. Moreover, the focus of <ref type="bibr" target="#b12">[13]</ref> was on traditional machine learning methods, whereas this article focuses on advanced and DL techniques.</p><p>Finally, Fadlullah et al. <ref type="bibr" target="#b13">[14]</ref> addressed DL approaches in network traffic control systems. While this work primarily focuses on the infrastructure of network, it differs from our work that focuses on the usage of DL in IoT applications.</p><p>Beyond the specific works on the IoT, Qiu et al.</p><p>[15] reviewed several traditional machine learning techniques along with several advanced techniques including DL for processing general big data. In specific, they highlighted the connection of different machine learning techniques with signal processing technologies to process and analyze timely big data applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Contributions</head><p>This paper is intended for IoT researchers and developers who want to build analytics, AI systems, and learning solutions on top of their IoT infrastructure, using the emerging DL machine learning approaches. The contributions of this paper can be summarized as follows:</p><p>? In order to adopt DL approaches in the IoT ecosystems, we identify the key characteristics and issues of IoT data. ? Compared to some related work in the literature that have addressed machine learning for IoT, we review the stateof-the-art DL methods and their applicability in the IoT domain both for big data and streaming data analytics. ? We review a wide range of IoT applications that have used DL in their context. We also provide a comparison and a guideline for using different types of DNN in the various IoT domains and applications. ? We review the recent approaches and technologies for deploying DL on all levels of IoT hierarchy from resource constrained devices to the fog and the cloud. ? We highlight the challenges and future research directions for the successful and fruitful merging of DL and IoT applications. The rest of this paper is organized as follows. In section II, we highlight the IoT data characteristics and describe what IoT big data as well as fast and streaming data are, and how they are different from the general big data. Section III presents several common and successful architectures of DNNs. It also includes a brief description of advancements toward real-time and fast DL architectures as well as state-ofthe-art algorithms that are joint with DL. A succinct review of several frameworks and tools with different capabilities and algorithms that support DNNs is also presented. IoT applications in different domains (e.g., healthcare, agriculture, ITS, etc.) that have used DL will be surveyed in section IV. Section V reviews the attempts to bring DNN to the resource constraint devices. Section VI explains the works that investigated bringing the DNN models to the scale of fog and cloud computing. Future research direction and open challenges are presented in section VII. The paper is concluded in Section VIII with a summary of its main take-away messages. Figure <ref type="figure" target="#fig_2">3</ref> depicts the structure of the paper. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. IOT DATA CHARACTERISTICS AND REQUIREMENTS FOR ANALYTICS</head><p>IoT data can be streamed continuously or accumulated as a source of big data. Streaming data refers to the data generated or captured within tiny intervals of time and need to be promptly analyzed to extract immediate insights and/or make fast decisions. Big data refers to huge datasets that the commonly used hardware and software platforms are not able to store, manage, process, and analyze. These two approaches should be treated differently since their requirements for analytic response are not the same. Insight from big data analytics can be delivered after several days of data generation, but insight from streaming data analytics should be ready in a range of few hundreds of milliseconds to few seconds.</p><p>Data fusion and sharing play a critical role in developing ubiquitous environments based on IoT data. This role is more critical for time-sensitive IoT applications where a timely fusion of data is needed to bring all pieces of data together for analysis and consequently providing reliable and accurate actionable insights. Alam et al. <ref type="bibr" target="#b15">[16]</ref> presented a survey paper in which data fusion techniques for IoT environments are reviewed followed by several opportunities and challenges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. IoT fast and streaming data</head><p>Many research attempts suggested streaming data analytics that can be mainly deployed on high-performance computing systems or cloud platforms. The streaming data analytics on such frameworks is based on data parallelism and incremental processing <ref type="bibr" target="#b16">[17]</ref>. By data parallelism, a large dataset is partitioned into several smaller datasets, on which parallel analytics are performed simultaneously. Incremental processing refers to fetching a small batch of data to be processed quickly in a pipeline of computation tasks. Although these techniques reduce time latency to return a response from the streaming data analytic framework, they are not the best possible solution for time-stringent IoT applications. By bringing streaming data analytics closer to the source of data (i.e., IoT devices or edge devices) the need for data parallelism and incremental processing is less sensible as the size of the data in the source allows it to be processed rapidly. However, bringing fast analytics on IoT devices introduces its own challenges such as limitation of computing, storage, and power resources at the source of data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. IoT Big data</head><p>IoT is well-known to be one of the major sources of big data, as it is based on connecting a huge number of smart devices to the Internet to report their frequently captured status of their environments. Recognizing and extracting meaningful patterns from enormous raw input data is the core utility of big data analytics as it results in higher levels of insights for decision-making and trend prediction. Therefore, extracting these insights and knowledge from the big data is of extreme importance to many businesses, since it enables them to gain competitive advantages. In social sciences, Hilbert <ref type="bibr" target="#b17">[18]</ref> compares the impact of big data analytics to that of the invention of the telescope and microscope for astronomy and biology, respectively.</p><p>Several works have described the general features of big data from different aspects <ref type="bibr" target="#b17">[18]</ref>- <ref type="bibr" target="#b20">[21]</ref> in terms of volume, velocity, and variety. However, we adopt the general definition of big data to characterize the IoT big data through the following "6V's" features:</p><p>? Volume: Data volume is a determining factor to consider a dataset as big data or traditional massive/ very large data. The quantity of generated data using IoT devices is much more than before and clearly fits this feature. ? Value: Value is the transformation of big data to useful information and insights that bring competitive advantage to organizations. A data value highly depends on both the underlying processes/services and the way that data is treated. For example, a certain application (e.g., medical vital sign monitoring) may need to capture all sensor data, while a weather forecast service may need just random samples of data from its sensors. As another example, a credit card provider may need to keep data for a specific period of time and discard them thereafter.</p><p>Beyond the aforementioned properties, researchers <ref type="bibr" target="#b17">[18]</ref> [20] have identified other characteristics such as:</p><p>? Big data can be a byproduct or footprint of a digital activity or IoT interplay. The use of Google's most common search terms to predict seasonal flu is a good example of such digital byproduct <ref type="bibr" target="#b21">[22]</ref>. ? Big data systems should be horizontally scalable, that is, big data sources should be able to be expanded to multiple datasets. This attribute also leads to the complexity attribute of big data, which in turn imposes other challenges like transferring and cleansing data.</p><p>Performing analytics over continuous data flows are typically referred to as stream processing or sometimes complex event processing (CEP) in the literature. Strohbach et al. <ref type="bibr" target="#b22">[23]</ref> proposed a big data analytics framework for IoT to support the volume and velocity attributes of IoT data analytics. The integration of IoT big data and streaming data analytics, an open issue that needs more investigation, has been also studied as part of that work. However, their proposed framework is designed to be deployed on cloud infrastructures. Moreover, their focus is on the data management aspect of the framework and did not use advanced machine learning models such as DL. Other off-the-shelf products such as Apache Storm are also available for real-time analytics on the cloud. A big gap in this area is the lack of frameworks and algorithms that can be deployed on the fog (i.e., system edge) or even on the IoT devices. When DL comes to play in such cases, a trade-off between the depth and performance of the DNN should be considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. DEEP LEARNING</head><p>DL consists of supervised or unsupervised learning techniques based on many layers of Artificial Neural Networks (ANNs) that are able to learn hierarchical representations in deep architectures. DL architectures consist of multiple processing layers. Each layer is able to produce non-linear responses based on the data from its input layer. The functionality of DL is imitated from the mechanisms of human brain and neurons for processing of signals.</p><p>DL architectures have gained more attention in recent years compared to the other traditional machine learning approaches. Such approaches are considered as being shallow-structured learning architectures versions (i.e., a limited subset) of DL. Figure <ref type="figure" target="#fig_3">4</ref> shows the searching trend of five popular machine learning algorithms in Google trends, in which DL is becoming more popular among the others. Although ANNs have been introduced in the past decades, the growing trend for DNNs started in 2006 when G. Hinton et al. presented the concept of deep belief networks <ref type="bibr" target="#b23">[24]</ref>. Thereafter, the stateof-the-art performance of this technology has been observed in different fields of AI including image recognition, image retrieval, search engines and information retrieval, and natural language processing. DL techniques have been developed on top of traditional ANNs. Feed-forward Neural Networks (FNNs) <ref type="bibr" target="#b24">[25]</ref> (a.k.a Multilayer Perceptrons -MLPs) have been used in the past decades to train systems, but when the number of layers is increased, they become difficult to train <ref type="bibr">[26]</ref>. The small size of training data was another factor that results in overfitted models. Moreover, the limitation in computational capabilities in those days prohibited the implementation of efficient deeper FNNs. These computational limitations have been resolved lately due to hardware advances in general and the development of Graphics Processing Units (GPUs) and hardware accelerators specifically. Beyond the structural aspects and significance of depth of DL architectures, as well as hardware advances, DL techniques have benefited from advancements in effective training algorithms of deep networks including:</p><p>? Using Rectified Linear Units (ReLUs) as activation function <ref type="bibr" target="#b25">[27]</ref>,</p><p>? Introducing dropout methods <ref type="bibr" target="#b26">[28]</ref>,</p><p>? Random initialization for the weights of the network <ref type="bibr" target="#b27">[29]</ref>,</p><p>? Addressing the degradation of training accuracy by residual learning networks <ref type="bibr" target="#b28">[30]</ref>,</p><p>? Solving vanishing gradient problem as well as exploding gradient problem by introducing and enhancing Long Short-Term Memory networks <ref type="bibr" target="#b29">[31]</ref>, <ref type="bibr" target="#b30">[32]</ref>. One advantage of DL architectures, compared to the traditional ANNs, is that DL techniques can learn hidden features from the raw data <ref type="bibr" target="#b9">[10]</ref>. Each layer trains on a set of features based on the previous layer's outputs. The inner-most layers can recognize more complex features, since they aggregate and recombine features from the previous layers. This is called the hierarchy of features. For example, in case of a face recognition model, raw image data of portraits as vector of pixels are fed to a model in its input layer. Each hidden layer can then learn more abstract features from the previous layer's outputs, e.g., the first hidden layer identifies the lines and edges, the second layer identifies face parts such as nose, eyes, etc., and the third layer combines all the previous features to generate a face.</p><p>However, the reported improvements of DL models are based on empirical evaluations, and there is still no concrete analytical foundation to answer why DL techniques outperform their shallow counterparts. Moreover, there is no clear boundary between deep and shallow networks based on the number of hidden layers. Generally, neural networks with two or more hidden layers that incorporate the recent advanced training algorithms are considered as deep models. Also, recurrent neural networks with one hidden layer are considered as deep since they have a cycle on the units of the hidden layer, which can be unrolled to an equivalent deep network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Architectures</head><p>In this section, we present a brief overview of several common DL models as well as the most cutting-edge architectures that have been introduced in recent years. Interested readers can refer to other literature that surveyed the models and architectures of DL in more details, such as <ref type="bibr" target="#b31">[33]</ref>. Table <ref type="table">I</ref> summarizes these models, their attributes, characteristics, and some sample applications.</p><p>A DNN consists of an input layer, several hidden layers, and an output layer. Each layer includes several units called neurons. A neuron receives several inputs, performs a weighted summation over its inputs, then the resulting sum goes through an activation function to produce an output. Each neuron has a vector of weights associated to its input size as well as a bias that should be optimized during the training process. Figure <ref type="figure" target="#fig_4">5</ref> depicts the structure of a neuron.</p><p>In the training process, the input layer assigns (usually randomly) weights to the input training data and passes it to the next layer. Each subsequent layer also assigns weights to their input and produces their output, which serves as the input for the following layer. At the last layer, the final output representing the model prediction is produced. A loss function determines the correctness of this prediction by computing the error rate between the predicted and true values. An optimization algorithm such as Stochastic Gradient Descent (SGD) <ref type="bibr" target="#b32">[34]</ref> is used to adjust the weight of neurons by calculating the gradient of the loss function. The error rate is propagated back across the network to the input layer (known as backpropagation algorithm <ref type="bibr" target="#b33">[35]</ref>, <ref type="bibr" target="#b34">[36]</ref>). The network then repeats this training cycle, after balancing the weights on each neuron in each cycle, until the error rate falls below a desired threshold. At this point, the DNN is trained and is ready for inference. In Figure <ref type="figure">6</ref>, the high level mechanism of training for DL models is illustrated.</p><p>In a broad categorization, DL models fall into three categories, namely generative, discriminative, and hybrid models. Though not being a firm boundary, discriminative models usually provide supervised learning approaches, while generative models are used for unsupervised learning. Hybrid models incorporate the benefits of both discriminative and generative models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Convolutional Neural Networks (CNNs):</head><p>For vision-based tasks, DNNs with a dense connection between layers are hard to train and do not scale well. One important reason is the translation-invariance property of such models. They thus do not learn the features that might transform in the image (e.g., rotation of hand in pose detection). CNNs have solved this problem by supporting translationequivariance computations. A CNN receives a 2-D input (e.g., an image or speech signal) and extracts high level features through a series of hidden layers. The hidden layers consist of convolution layers as well as fully connected layers at the end. The convolution layer is at the core of a CNN and consists of a set of learnable parameters, called filters, that have the same shape as the input's shape but with smaller dimensions. In the training process, the filter of each convolutional layer goes through the whole input volume (e.g., in case of an image, it goes across the width and length of the image) and calculates an inner product of the input and the filter. This computation over the whole input leads to a feature map of the filter.</p><p>Another building block of a CNN is the pooling layers, which operate on the feature maps. The objective of having pooling layers is to reduce the spatial size of the representation, in order to both cut down the number of parameters and computation times and to reduce the chance of overfitting. Max pooling is a common approach that partitions the input space into non-overlapping regions and picks the maximum value for each region.</p><p>The last important component in CNN is ReLU, which consist of neurons with activation function in the form of f (x) = max(0, x). The introduction of this activation function in CNN results in a faster training time without affecting the generalization of the network in a sensible negative way <ref type="bibr" target="#b35">[37]</ref>. Figure <ref type="figure">7</ref> depicts the structure of a CNN.</p><p>A main difference between CNNs and fully connected networks is that each neuron in CNNs is connected only to a small subset of the input. This decreases the total number of parameters in the network and enhances the time complexity of the training process. This property is called local connectivity.</p><p>Many IoT devices, such as drones, smart phones, and smart connected cars, are equipped with cameras. The CNN architecture and its variations have been investigated for a variety of application scenarios that involve these devices. Some typical applications include flood or landslide prediction through drone images, plant disease detection using plant pictures on smart phones, and traffic sign detection using vehicles' cameras.</p><p>2) Recurrent Neural Networks (RNNs): In many tasks, prediction is dependent on several previous samples such that, in addition to classifying individual samples, we also need to analyze the sequences of inputs. In such applications, a feed-forward neural network is not applicable since it assumes no dependency between input and output layers. RNNs have been developed to address this issue in sequential (e.g., speech or text) or time-series problems (sensor's data) with various length. Detecting drivers' behaviors in smart vehicles, identifying individual's movement patterns, and estimating energy consumption of a household are some examples where RNNs can be applied. The input to an RNN consists of both the current sample and the previous observed sample. In other words, the output of an RNN at time step t-1 affects the output at time step t. Each neuron is equipped with a feedback loop that returns the current output as an input for the next step. This structure can be expresses such that each neuron in an RNN has an internal memory that keeps the information of the computations from the previous input.</p><p>To train the network, an extension of the backpropagation algorithm, called Backpropagation Through Time (BPTT) <ref type="bibr" target="#b36">[38]</ref>, is used. Due to the existence of cycles on the neurons, we cannot use the original backpropagation here, since it works based on error derivation with respect to the weight in their upper layer, while we do not have a stacked layer model in RNNs. The core of BPTT algorithm is a technique called unrolling the RNN, such that we come up with a feed-forward network over time spans. Figure <ref type="figure" target="#fig_6">8</ref> depicts the structure of an RNN and unrolled concept.</p><p>Traditional RNNs can be considered as deep models since they can be seen as several non-linear layers of neurons between the input layer and the output layer when they are unfolded in time <ref type="bibr" target="#b37">[39]</ref>. However, considering the architecture and the functionality of RNNs, the hidden layers in RNNs are supposed to provide a memory instead of a hierarchical representation of features <ref type="bibr" target="#b38">[40]</ref>. There are several approaches to make RNNs deeper, including adding more layers between the input and hidden layers, stacking more hidden layers, and adding more layers between hidden layers and the output layer <ref type="bibr" target="#b37">[39]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Long Short Term Memory (LSTM):</head><p>LSTM is an extension of RNNs. Different variations of LSTM have been proposed, though most of them have followed the same design of the original network <ref type="bibr" target="#b29">[31]</ref>. LSTM uses the concept of gates for its units, each computing a value between 0 and 1 based on their input. In addition to a feedback loop to store the information, each neuron in LSTM (also called a memory cell) has a multiplicative forget gate, read gate, and write gate. These gates are introduced to control the access to memory cells and to prevent them from perturbation by irrelevant inputs. When the forget gate is active, the neuron writes its data into itself. When the forget gate is turned off by sending a 0, the neuron forgets its last content. When the write gate is set to 1, other connected neurons can write to that neuron. If the read gate is set to 1, the connected neurons can read the content of the neuron. Figure <ref type="figure" target="#fig_7">9</ref> depicts this structure.</p><p>An important difference of LSTMs compared to RNNs is that LSTM units utilize forget gates to actively control the cell states and ensure they do not degrade. The gates can use sigmoid or tanh as their activation function. In fact, these activation functions cause the problem of vanishing gradient during backpropagation in the training phase of other models using them. By learning what data to remember in LSTMs, stored computations in the memory cells are not distorted over time. BPTT is a common method for training the network to minimize the error. When data is characterized by a long dependency in time, LSTM models perform better than RNN models <ref type="bibr" target="#b39">[41]</ref>. This long lag of dependency can be observed in IoT applications such as human activity recognition, predicting educational performance in online programs, and disaster prediction based on environmental monitoring, to name a few.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Autoencoders (AEs):</head><p>AEs consist of an input layer and an output layer that are connected through one or more hidden layers. AEs have the same number of input and output units. This network aims to reconstruct the input by transforming inputs into outputs with the simplest possible way, such that it does not distort the input very much. This kind of neural networks has been used mainly for solving unsupervised learning problems as well as transfer learning <ref type="bibr" target="#b40">[42]</ref>. Due to their behavior of constructing the input at the output layer, AEs are mainly used for diagnosis and fault detection tasks. This is of great interest for industrial IoT to serve many applications such as fault diagnosis in hardware devices and machines, and anomaly detection in the performance of assembly lines.</p><p>AEs have two main components: An encoder and a decoder. The encoder receives the input and transforms it to a new representation, which is usually called a code or latent variable. The decoder receives the generated code at the encoder, and transforms it to a reconstruction of the original input. The training procedure in AEs involves minimizing reconstruction error, i.e., the output and input showing minimal difference. Figure <ref type="figure" target="#fig_0">10</ref> illustrates the structure of a typical AE. There are several variations and extensions of AEs like denoising AE, contractive AE, stacked AE, sparse AE, and variational AE. data is not strong, while having a fast training process through backpropagation <ref type="bibr" target="#b41">[43]</ref>. Moreover, this model has been used for semi-supervised learning <ref type="bibr" target="#b42">[44]</ref>. Therefore, it is a good fit for IoT solutions that deal with diverse data and the scarcity of labeled data. Such applications include failure detection in sensing or actuating levels and intrusion detection in security systems. For each data point x, there is a vector of corresponding latent variables denoted by z.</p><p>The training architecture of a VAE consists of an encoder and a decoder with parameters ? and ?, respectively. A fixed form distribution q ? (z|x) helps the encoder in estimating the posterior distribution p ? (z|x). The model consists of two networks: One generating samples and the other performing approximate inference. A schematic of the VAE is depicted in Figure <ref type="figure" target="#fig_0">11</ref>.</p><p>6) Generative Adversarial Networks (GANs): GANs, introduced by Goodfellow et al. <ref type="bibr" target="#b43">[45]</ref>, consist of two neural networks, namely the generative and discriminative networks, which work together to produce synthetic and highquality data. The former network (a.k.a. the generator) is in charge of generating new data after it learns the data distribution from a training dataset. The latter network (a.k.a. the discriminator) performs discrimination between real data (coming from training data) and fake input data (coming from the generator). The generative network is optimized to produce input data that is deceiving for the discriminator (i.e., data that the discriminator cannot easily distinguish whether it is fake or real). In other words, the generative network is competing with an adversary discriminative network. Figure <ref type="figure" target="#fig_9">12</ref> depicts the concept of GANs. The objective function in GANs is based on minimax games, such that one network tries to maximize the value function and the other network wants to minimize it. In each step of this imaginary game, the generator, willing to fool the discriminator, plays by producing a sample data from random noise. On the other hand, the discriminator receives several real data examples from the training set along with the samples from the generator. Its task is then to discriminate real and fake data. The discriminator is considered to perform satisfactorily if its classifications are correct. The generator also is performing well if its examples have fooled the discriminator. Both discriminator and generator parameters then are updated to be ready for the next round of the game. The discriminator's output helps the generator to optimize its generated data for the next round.</p><p>In IoT applications, GANs can be applied for scenarios that require the creation of something new out of the available data. This can include applications in localization and way-finding, where a generator network in GAN produces potential paths between two points, while the discriminator identifies which paths look viable. GANs are also very helpful for developing services for visually impaired people, such as images-to sound-converters using both GANs to generate descriptive texts from a given image <ref type="bibr" target="#b44">[46]</ref> and another DL model to perform text-to-speech conversion. In an image processing research using GANs, a large number of real celebrity snapshots have been analyzed to create new fake images such that a human cannot identify if they are real images or not <ref type="bibr" target="#b45">[47]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7) Restricted Boltzmann Machine (RBMs):</head><p>An RBM is a stochastic ANN that consists of two layers: A visible layer that contains the input that we know, and a hidden layer that contains the latent variables. The restriction in RBMs is applied to the connectivity of neurons compared to Boltzmann machine. RBMs should build a bipartite graph, such that each visible neuron should be connected to all hidden neurons and vice versa, but there is no connection between any two units in a same layer. Moreover, the bias unit is connected to all of the visible and hidden neurons. RBMs can be stacked to form DNNs. They are also the building block of deep belief networks.</p><p>The training data is assigned to visible units. The training procedure can use backpropagation and gradient descent algorithms to optimize the weights of the network. The objective of training RBM is to maximize the product of all probabilities of the visible units. The functionality of RBM is similar to the AEs as it uses forward feeding to compute the latent variables, which are in turn used to reconstruct the input using backward feeding. The structure of an RBM is shown in Figure <ref type="figure" target="#fig_10">13</ref>.</p><p>RBMs can perform feature extraction out of input data. This happens through modeling a probability distribution over a set of inputs that is represented in a set of hidden units. For example, having a set of favorite movies of individuals, an RBM model can have a visible layer consisting of as many neurons as the number of available movies, and a hidden layer consisting of three neurons to represent three different genres such as drama, action and comedy. So, based on the application, the hidden layer can be considered as the output layer. Or it can be complemented with an additional classifier layer to perform classification based on extracted features.</p><p>From the types of potential applications where RBMs can be used, we name indoor localization, energy consumption prediction, traffic congestion prediction, posture analysis, and generally any application that benefits from extracting the most important features out of the available ones. layers (corresponding to latent variables). They can extract hierarchical representation of the training data as well as reconstruct their input data. By adding a classifier layer like softmax, it can be used for prediction tasks.</p><p>The training of a DBN is performed layer by layer, such that each layer is treated as an RBM trained on top of the previous trained layer. This mechanism makes a DBN an efficient and fast algorithm in DL <ref type="bibr" target="#b46">[48]</ref>. For a given hidden layer in DBN, the hidden layer of previous RBM acts as the input layer. Figure <ref type="figure" target="#fig_3">14</ref> shows the structure of a typical DBN.</p><p>Several applications can benefit from the structure of DBNs, such as fault detection classification in industrial environments, threat identification in security alert systems, and emotional feature extraction out of images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9) Ladder Networks:</head><p>Ladder networks were proposed in 2015 by Valpola et al. <ref type="bibr" target="#b47">[49]</ref> to support unsupervised learning. Later, they were extended to work in semi-supervised settings <ref type="bibr" target="#b48">[50]</ref> and have shown stateof-the-art performance for several tasks, such as handwritten digits recognition and image classification. The architecture of a ladder network consists of two encoders and one decoder. The encoders act as the supervised part of the network and the decoder performs unsupervised learning. One of the encoders, called clean encoder, produces the normal computations while the other encoder, called corrupted encoder, adds Gaussian noise to all layers.</p><p>Using a denoising function, the decoder can reconstruct the representations at each layer given the corresponding corrupted data. The difference between the reconstructed and clean data at each layer is used for computing the denoising cost of that layer. In the encoder side, the cost function uses the difference between the corrupted output of encoder layers and the corresponding clean outputs. The training objective is to minimize the sum of cost in the supervised part and unsupervised network.</p><p>The initial experimental evaluations of ladder networks <ref type="bibr" target="#b47">[49]</ref> x are limited to some standard tasks, such as handwritten digits classification over the Modified National Institute of Standards and Technology (MNIST) datasets <ref type="bibr" target="#b49">[51]</ref> or image recognition tasks on the datasets of the Canadian Institute for Advanced Research (CIFAR)-10 <ref type="bibr" target="#b50">[52]</ref>. Though it has not been used widely in IoT scenarios, ladder networks have the potential to be used in many vision-based IoT analytics where semisupervision is a great bonus. Figure <ref type="figure" target="#fig_12">15</ref> shows the structure of a ladder network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Fast and Real-time DL Architectures</head><p>The research works for fast and real-time analytics using DL models over the stream of data are still in their infancy. An initial work in this area that utilizes ANNs is done by Liang et al. <ref type="bibr" target="#b51">[53]</ref>. It has extended the extreme learning machine (ELM) networks to apply an online sequential learning algorithm to single hidden layer feed-forward networks. Their framework, called OS-ELM, learns the training data one-byone as well as chunk-by-chunk, and only newly arrived data go through the training process. This architecture is the base for the real-time manufacturing execution system that is proposed in <ref type="bibr" target="#b52">[54]</ref>. In this work, OS-ELM has been used for shop floor object localization using RFID technology. Zou et al. <ref type="bibr" target="#b53">[55]</ref> have also reported using this architecture for an indoor localization algorithm based on WiFi fingerprinting, in which the OS-ELM model can bear well the dynamic environmental changes while still showing good accuracy.</p><p>For convolutional networks, the architecture proposed by Ren et al., called Faster R-CNN <ref type="bibr" target="#b54">[56]</ref> (based on Fast R-CNN <ref type="bibr" target="#b55">[57]</ref>), aims to detect objects in images in real-time. Object detection in images needs more computations and hence consumes more energy compared to the image classification tasks, since the system has a large number of potential object suggestions that need to be evaluated. The proposed architecture is based on applying region proposal algorithms in full CNNs that perform object bounds prediction and objectness score computation at each position at the same time. Their evaluation of the proposed object detection architecture indicates that the run time of the system is between 5-17 frames per second (fps) given that the original input frames are re-scaled such that the shortest side of the image would be 600 pixels. <ref type="bibr">Mao et al. [58]</ref> also used Fast R-CNN for embedded platforms reporting a run time of 1.85 fps with frames scaled to 600 pixels in the shortest side in embedded CPU+GPU platform, which have been shown to be energyefficient with a close-to-real-time performance. However, for image processing tasks, we can consider an approach to be truly real-time when it can process and analyze 30 fps or better. Redmon et al. <ref type="bibr" target="#b57">[59]</ref> developed You Only Look Once (YOLO) that has reached the performance of 45 fps for input images resized to 448 ? 448, and even a smaller version of it, Fast YOLO, achieving 155 fps, which are suitable for smart cameras.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Joint DL with Other Approaches</head><p>DL architectures also have been used jointly in other machine learning approaches to make them more efficient. The nonlinear function approximation of DL models that can support thousands or even billions of parameters is a strong motivation to use this method in other machine learning approaches in need of such functions. Moreover, the automatic feature extraction in deep models is another motivating reason to exploit these models jointly with other approaches. In the following subsections, a summary of such approaches that are suitable for IoT scenarios is provided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Deep Reinforcement Learning:</head><p>Deep Reinforcement Learning (DRL) <ref type="bibr" target="#b58">[60]</ref> is a combination of reinforcement learning (RL) with DNNs. It aims to create software agents that can learn by themselves to establish successful policies for gaining maximum long-term rewards. In this approach, RL finds the best policy of actions over the set of states in an environment from a DNN model. The need for a DNN in an RL model becomes evident when the underlying environment can be represented by a large number of states. In such situation, traditional RL is not efficient enough. Instead, a DL model can be used to approximate the action values in order to estimate the quality of an action in a given state. Systems that use DRL in their context are in their infancy, but already have showed very promising results. In the field of IoT, the work presented in <ref type="bibr" target="#b59">[61]</ref> uses DRL in a semi-supervised setting for localization in smart campus environments. The aim of this work is to localize the users based on received signals from multiple Bluetooth Low Energy (BLE) iBeacons. The learning agent uses DRL to find the best action to perform (i.e., moving in a direction like North, North-West, etc. from a starting point). The reward function is the reciprocal of the distance error to a predefined target, such that the learning agent receives more rewards when it gets closer to its intended target and vice versa. Figure <ref type="figure" target="#fig_13">16</ref> shows a sample result of such method when a DNN model helps for gaining more rewards in a semi-supervised setting (left sub-figure in Figure <ref type="figure" target="#fig_13">16</ref>) and its reward interpretation to the accuracy (right sub-figure).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Transfer Learning with Deep Models:</head><p>Transfer learning, which falls in the area of domain adaptation and multi-task learning, involves the adaptation and improvement of learning in a new domain by transferring the knowledge representation that has been learned from data of a related domain <ref type="bibr" target="#b60">[62]</ref>. Transfer learning is an interesting potential solution for many IoT applications where gathering training data is not an easy task. For example, considering the training of a localization system through BLE or WiFi fingerprinting using smart phones, the RSSI values at a same time and location for different platforms (e.g., iOS and Android) vary. If we have a trained model for one platform, the model can be transferred to the other platform without re-collecting another set of training data for the new platform.</p><p>DL models are well matched to transfer learning due to their ability to learn both low-level and abstract representations from input data. Specifically, Stacked denoising AEs <ref type="bibr" target="#b60">[62]</ref> and other variations of AEs <ref type="bibr" target="#b61">[63]</ref> have been shown to perform very well in this area. Transfer learning with DNNs is still an ongoing and active research area in AI community, and we have not seen reported real-world applications in IoT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Online Learning Algorithms joint with DL:</head><p>As the stream of data generated from IoT applications goes through the cloud platforms for analysis, the role of online machine learning algorithms becomes more highlighted, as the training model needs to be updated by the incremental volume of data. This is opposed to what the current technologies support, which is based on batch learning techniques, where the whole training data set should be available for training and, thereafter, the trained model cannot evolve by new data. Several research works report applying online learning techniques on various DL models, including stacked denoising AEs <ref type="bibr" target="#b62">[64]</ref>, sum-product networks <ref type="bibr" target="#b63">[65]</ref>, and RBMs <ref type="bibr" target="#b64">[66]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Frameworks</head><p>The rapid growth of interest to use DL architectures in different domains has been supported by introducing several DL frameworks in recent years. Each framework has its own strength based on its supported DL architectures, optimization algorithms, and ease of development and deployment <ref type="bibr" target="#b65">[67]</ref>. Several of these frameworks have been used widely in research for efficient training of DNNs. In this section, we review some of these frameworks.</p><p>H2O: H2O is a machine learning framework that provides interfaces for R, Python, Scala, Java, JSON, and Coffee-Script/JavaScript <ref type="bibr" target="#b66">[68]</ref>. H2O can be run in different modes including standalone mode, on Hadoop, or in a Spark Cluster. In addition to common machine learning algorithms, H2O includes an implementation of a DL algorithm, which is based on feed-forward neural networks that can be trained by SGD with backpropagation. H2O's DL AE is based on the standard deep (multi-layer) neural net architecture, where the entire network is learned together, instead of being stacked layerby-layer. Theano: Theano is an open source Python-based framework for efficient machine learning algorithms, which supports compiling for CPUs and GPUs <ref type="bibr" target="#b69">[71]</ref>. It uses the CUDA library in optimizing the complicated codes that need to be run on GPUs. It also allows parallelism on CPUs. Theano uses graph representations for symbolic mathematical expressions. Through this representation, symbolic differentiation of mathematical expressions is supported in Theano. Several wrappers including Pylearn2, Keras, and Lasagne provide easier programming experience on top of Theano <ref type="bibr" target="#b70">[72]</ref>.</p><p>Caffe: Caffe <ref type="bibr" target="#b71">[73]</ref> is an open source framework for DL algorithms and a collection of reference models. It is based on C++, supports CUDA for GPU computations, and provides interfaces for Python and Matlab. Caffe separates model representation from its implementation. This has been made possible by defining models by configurations without hardcoding them in the source code. Switching between platforms (e.g., CPU to GPU or mobile devices) is easy by only changing a flag. Its speed on GPU is reported to be 1 ms/image for prediction and 4 ms/image for training.</p><p>Neon: Neon<ref type="foot" target="#foot_2">3</ref> is another open source DL framework based on Python with high performance for modern DNNs, such as AlexNet <ref type="bibr" target="#b35">[37]</ref>, Visual Geometry Group (VGG) <ref type="bibr" target="#b72">[74]</ref>, and GoogleNet <ref type="bibr" target="#b73">[75]</ref>. It supports developing several commonly used models, such as CNNs, RNNs, LSTMs, and AEs, on both CPUs and GPUs. The list is being extended as they implemented GANs for semi-supervised learning using DL models. It also supports easy changing of the hardware platform backends.</p><p>Bahrampour et al. in <ref type="bibr" target="#b65">[67]</ref> have provided a comparative study for four of the aforementioned tools namely, Caffe, Neon, Theano and Torch. Although the performance of each tool varies in different scenarios, Torch and Theano showed the overall best performance in most of the scenarios. Another benchmarking is provided in <ref type="bibr" target="#b74">[76]</ref>, comparing the running performance of Caffe, TensorFlow, Torch, CNTK, and MXNet. Table <ref type="table" target="#tab_2">II</ref> summarizes and compares different DL frameworks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Lessons Learned</head><p>In this section, we reviewed several common DL architectures that can serve in the analytics component of various IoT applications. Most of these architectures work with various types of input data generated by IoT applications. However, to get better performance for serial or time-series data, RNNs and their variations are recommended. In particular, for long term dependencies among data points, LSTM is more favorable due to its concept of gates for memory cells. For cases where the input data is more than one-dimensional, variations of CNNs work better. RBM, DBN, and variations of AE perform well in handling high-dimensionality reduction, and hierarchical feature extraction. Combined with a classification layer, they can be used for a variety of detection and forecasting scenarios. More recent architectures including VAE, GAN, and Ladder Networks are expected to have a great impact on IoT applications since they cover semi-supervised learning. Those  <ref type="bibr" target="#b85">[87]</ref>, <ref type="bibr" target="#b86">[88]</ref> are more favorable for IoT applications where a huge amount of data is generated while a small fraction of that can be annotated for machine learning. The role of these architectures can be emphasized by knowing that only about 3% of all universe data by 2012 was annotated, and is hence useful for supervised machine learning <ref type="bibr" target="#b87">[89]</ref>. Table <ref type="table">I</ref> summarizes DL architectures.</p><p>A few attempts toward making DL architectures fast and real-time responsive were also discussed. This avenue needs more exploration and research to be applicable in many time-sensitive IoT applications. Emerging machine learning architectures and techniques that both benefit from DL and address the specific IoT application requirements were also highlighted. Indeed, DRL can support autonomousness of IoT applications, transfer learning can fill the gap of lack of training data sets, and online learning matches the need for stream analysis of IoT data.</p><p>We also reviewed several common and powerful frameworks for the development of DL models. For IoT applications, training times, run times, and dynamic update of the trained models are determining factors for a reliable and efficient analytic module. Most of the current frameworks follow the pattern of "define-and-run" instead of "defineby-run" <ref type="bibr" target="#b83">[85]</ref>. The former does not allow dynamic updates of the model while the latter supports such modifications. Chainer <ref type="bibr" target="#b83">[85]</ref> is a framework that follows the latter pattern and can handle dynamic changes of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. DL APPLICATIONS IN IOT</head><p>DL methods have been shown promising with state-of-theart results in several areas, such as signal processing, natural language processing, and image recognition. The trend is going up in IoT verticals. Some neural network models work better in special domains. For example, convolutional networks provide better performance in applications related to vision, while AEs perform very well with anomaly detection, data denoising, and dimensionality reduction for data visualization. It is important to make this link between the kind of neural network model that best fits each of the different application domains.</p><p>In this section, we review successful applications of DL in IoT domains. Based on our observation, many IoT related applications utilize vision and image classification (like traffic sign recognition, or plant disease detection that we will discuss in Section IV-B) as their base intelligent service. There are other services, such as human pose detection, which are utilized for smart home applications or intelligent car assistance. We identify several kinds of these services as foundational services on which other IoT applications can be built. The common property of these services is that they should be treated in a fast analytic mode instead of piling their data for later analytics. Indeed, each domain may have specific services beyond these foundational services. Figure <ref type="figure" target="#fig_15">17</ref> shows the foundational services and the IoT applications on top of them.</p><p>In the following subsections, we first review foundational services of IoT that use DL as their intelligence engine, then highlight the IoT applications and domains where a combination of foundational services as well as specific ones may be utilized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Foundational Services 1) Image Recognition:</head><p>A large portion of IoT applications address scenarios in which the input data for DL is in the form of videos or images. Ubiquitous mobile devices equipped with high resolution cameras facilitate generating images and videos by everyone, everywhere. Moreover, intelligent video cameras are used in many places like smart homes, campuses, and manufacturers for different applications. Image recognition/classification and object detection are among the fundamental usages of such devices.</p><p>One issue with the IoT-related systems that have addressed image recognition is the use of specific source datasets for evaluation of their performance. Most of these systems employ the available common image datasets such as the MNIST dataset of handwritten digits <ref type="bibr" target="#b49">[51]</ref>, VGG face dataset <ref type="bibr" target="#b72">[74]</ref>, CIFAR-10 and CIFAR-100 tiny images dataset, etc. Though being good for comparison with other approaches, those datasets do not show the specific characteristics of IoT systems. For example, the input for the task of vehicle detection in smart connected cars would not be always a clear image, and there are cases where the input image is at night, or in a rainy or foggy weather. These cases are not handled through the available datasets and hence the models trained based on these datasets are not comprehensive enough.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Speech/Voice Recognition:</head><p>With the massive proliferation of smart mobile devices and wearables, automatic speech recognition is becoming a more natural and convenient way for people to interact with their devices <ref type="bibr" target="#b88">[90]</ref>. Also, the small size of mobile devices and wearables nowadays lower the possibility of having touch screens and keyboards as a means of input and interaction with these devices. However, the main concern for providing speech/voice recognition functionality on resource-constrained devices is its energy-intensiveness, especially when the data is processed through neural networks. In a typical speech recognition neural network model, voice data is represented as the raw input to the network. The data is processed through the hidden layers, and the likelihood of the voice data to a particular speech sound is presented at the output layer.</p><p>Price et al. <ref type="bibr" target="#b89">[91]</ref> have reported that they have built a specialpurpose low-power DL chip for automatic speech recognition. The new specialized chip consumes a tiny amount of energy between 0.2 and 10 milliwatts, 100 times lesser than the energy consumption for running a speech recognition tool in current mobile phones. In the new chip, DNNs for speech recognition have been implemented. For the sake of energy saving, three levels of voice activity recognition are designed with three separate neural networks, each of which having a different level of complexity. A lowest complexity network, thus consuming the lowest amount of energy, detects voice activity by monitoring the noise in the environment. If this network identifies a voice, the chip runs the next complexity level recognition network whose task is acoustic modeling to identify if the voice looks like speech. If the output of this network is a high likelihood, then the third network, having the highest energy consumption, is triggered to run to identify individual words.</p><p>3) Indoor Localization: Providing location aware services, such as indoor navigation and location aware marketing in retailers, are becoming prevalent in indoor environments. Indoor localization may also have applications in other sectors of IoT, such as in smart homes, smart campuses, or hospitals. The input data generated from such applications usually comes from different technologies, such as vision, visible light communication (VLC), infrared, ultrasound, WiFi, RFID, ultrawide band, and Bluetooth. For the approaches based on WiFi or Bluetooth, most of the literature have used mobile phones for receiving signals from the fixed transmitters (i.e., access points or iBeacons), which are called fingerprints. Among these fingerprinting approaches, several attempts reported the use of DL models to predict the location <ref type="bibr" target="#b90">[92]</ref>- <ref type="bibr" target="#b92">[94]</ref>.</p><p>DL has been used successfully to locate indoor positions with high accuracy. In a system called DeepFi <ref type="bibr" target="#b90">[92]</ref>, a DL method over fingerprinting WiFi channel state information data has been utilized to identify user positions. This system consists of offline training and online localization phases. In the offline training phase, DL is exploited to train all the weights based on the previously stored channel state information fingerprints. Other works <ref type="bibr" target="#b91">[93]</ref>, <ref type="bibr" target="#b92">[94]</ref> report using variations of DL models in conjunction with other learning methods to extract features and estimate positions. These experiments assert that the number of hidden layers and units in DL models has a direct effect on the localization accuracy. In <ref type="bibr" target="#b93">[95]</ref>, a CNN is used for indoor localization by fusion of both magnetic and visual sensing data. Moreover, a CNN has been trained in <ref type="bibr" target="#b94">[96]</ref> to determine the indoor positions of users by analyzing an image from their surrounding scene.</p><p>Lu et al. have also used LSTM networks for localizing soccer robots <ref type="bibr" target="#b95">[97]</ref>. In this application, data collected from several sensors, namely Inertia Navigation System (INS) and vision perceptions, are analyzed to predict the position of the robot. The authors reported improved accuracy and efficiency compared to two baseline methods, namely standard Extended Kalman Filtering (EKF) and the static Particle Filtering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Physiological and Psychological State Detection:</head><p>IoT combined with DL techniques has been also employed to detect various physiological and psychological states of humans, such as pose, activity, and emotions. Many IoT applications incorporate a module for human pose estimation or activity recognition to deliver their services, e.g., smart homes, smart cars, entertainment (e.g., XBox), education, rehabilitation and health support, sports, and industrial manufacturing. For example, convenient applications in smart homes are built based on the analysis of occupant's poses. The  cameras transfer the video of the occupant to a DNN to find out the pose of the person and take the most appropriate action accordingly. Toshev et al. <ref type="bibr" target="#b96">[98]</ref> report a system employing a CNN model to achieve this goal. This sort of services can also be used in education to monitor the attention of students, and in retail stores to predict the shopping behavior of customers <ref type="bibr" target="#b97">[99]</ref>.</p><note type="other">Smart Home Smart City Smart Energy ITS Smart Healthcare Agriculture Education Industry Government Sport Retail</note><p>Ordonez et al. <ref type="bibr" target="#b98">[100]</ref> have proposed a DL framework that combines the strength of CNN and LSTM neural networks for human activity recognition from wearable sensor data (accelerometer, gyroscope, etc.). Their model consists of four convolutional layers with ReLUs followed by two LSTM layers and a softmax layer. They showed that this combination outperformed a baseline model that is just based on convolutional layers by 4% on average. The work of Tao et al. <ref type="bibr" target="#b99">[101]</ref> also used LSTM architecture for human activity recognition based on mobile phone sensor's data. Li et al.</p><p>[102] also report the usage of raw data from passive FRID tags for detecting medical activities in a trauma room (e.g., blood pressure measurement, mouth exam, cardiac lead placement, etc.) based on a deep CNN.</p><p>In <ref type="bibr" target="#b101">[103]</ref>, a combined model of CNN and RNN was proposed for gesture recognition in video frames. This model showed better results compared to the models without such combination, and asserted the importance of the recurrence component for such task. In Beyond the physical movements, emotion estimation of humans from video frames has been also investigated in <ref type="bibr" target="#b103">[105]</ref> using a model that consists of a CNN, DBN, and AE. Furthermore, the work in <ref type="bibr" target="#b104">[106]</ref> used mobile inertial sensor data for motion detection. It confirmed that human motion patterns can be used as a source of user identification and authentication. The employed model in this system is a combination of convolutional layers and clockwork RNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) Security and Privacy:</head><p>Security and privacy is a major concern in all IoT domains and applications. Smart homes, ITS, Industry, smart grid, and many other sectors consider security as a critical requirement. Indeed, the validity of the functionality of the systems depends on protecting their machine learning tools and processes from attackers.</p><p>False Data Injection (FDI) is a common type of attack on data-driven systems. In <ref type="bibr" target="#b105">[107]</ref>, He et al. proposed a Conditional DBN to extract FDI attack features from the historical data of smart grids, and use these features for attack detection in realtime. The work in <ref type="bibr" target="#b106">[108]</ref> is also related to anomaly detection that may occur in vehicle networks.</p><p>Smart phones as great contributers to IoT data and applications are also under serious threats of hacker attacks. Consequently, protecting these devices from a variety of security issues is necessary for IoT perspectives beyond the users' concerns. Yuan et al. <ref type="bibr" target="#b107">[109]</ref> proposed a DL framework to identify malwares in Android apps. Their architecture is based on a DBN by which they reported accuracy of 96.5% to detect malware apps.</p><p>The security and privacy preservation of deep machine learning approaches are the most important factors for the acceptance of using these methods in IoT sectors. Shokri et al. <ref type="bibr" target="#b108">[110]</ref> proposed a method to address the privacy preservation issues in DL models when they are subject to distributed learning. Their approach was able to preserve both the privacy of participants' training data and the accuracy of the models at the same time. The core of their approach is based on the fact that stochastic gradient descent optimization algorithms, used in many DL architectures, can be performed in a parallel and asynchronous way. Individual participants can thus independently train the model on their own data and share a portion of their model parameters with other participants. Abadi et al. <ref type="bibr" target="#b109">[111]</ref> also proposed a method for privacy guarantee in DL models using differentially private stochastic gradient descent algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Applications 1) Smart Homes:</head><p>The concept of smart homes involve a broad range of applications based on IoT, which can contribute to enhancing homes' energy usage and efficiency, as well as the convenience, productivity, and life-quality of their occupants. Nowadays, home appliances can connect to the Internet and provide intelligent services. For example, Microsoft and Liebherr in a collaborative project are applying Cortana DL to the information gathered from inside the refrigerator <ref type="bibr" target="#b110">[112]</ref>. These analytics and predictions can help the household to have a better control on their home supplies and expenses, and, in conjunction with other external data, can be used for monitoring and predicting health trends.</p><p>Over one third of the generated electricity in the U.S. is consumed by the residential sector <ref type="bibr" target="#b111">[113]</ref>, with HVAC and lighting devices consisting the largest source of such consumption in buildings. This demand is expected to grow in a slower pace by smart management of energy as well as the efficiency improvements in appliances. Hence, the ability to control and improve energy efficiency and predict the future need is a must for smart home systems. In the smart home applications, electricity load prediction are the most common applications that employ different DL networks to figure out the task. Manic et al. <ref type="bibr" target="#b111">[113]</ref> performed a comparison analysis of load forecasting for home energy consumption using three DL architectures, including LSTM, LSTM Sequence-to-Sequence (S2S) and CNN. Their results show that LSTM S2S predicts the future usage better than the other architectures, followed by CNN, and then LSTM. They also compared the same dataset over a conventional ANN, and all of the aforementioned models outperformed the ANN model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Smart City:</head><p>Smart city services span over several IoT domains, such as transportation, energy, agriculture <ref type="bibr" target="#b112">[114]</ref>, etc. However, this area is more interesting from a machine learning perspective as the heterogeneous data coming from different domains lead to big data, which can result in high-quality output when analyzed using DL models. Smart city benefits from advances in other domain to achieve efficient resource management for the whole city. For example, to improve public transportation infrastructure and offer new improved services, getting analytics and patterns out of public transportation behaviors is of interest for local authorities.</p><p>Toshiba has recently developed a DL testbed jointly with Dell Technologies, and used this testbed in a Smart Community Center in Kawasaki, Japan, to evaluate the data collected in the Center <ref type="bibr" target="#b113">[115]</ref>. The aim of running the testbed is to measure the effectiveness of using DL architectures in IoT ecosystems, and identify the best practices for service improvement including increasing machines' availability, optimizing monitoring sensors, and lowering maintenance expenses. The big data that feeds the testbed were gathered from building management, air conditioning and building security.</p><p>One important issue for smart city is predicting crowd movements patterns, and their use in public transportation. Song et al. <ref type="bibr" target="#b114">[116]</ref> developed a system based on DNN models to achieve this goal on a city level. Their system is built upon a four-layer LSTM neural network to learn from human mobility data (GPS data) joint with their transportation transition modes (e.g., stay, walk, bicycle, car, train). They treated the prediction of people's mobility and transportation mode as two separated tasks instead of joining all these features together. Consequently, their learning system is based on a multi-task deep LSTM architecture to jointly learn from the two sets of features. The choice of LSTM was driven by the spatiotemporal nature of human mobility patterns. The authors assert that their approach based on multi-task deep LSTM achieves better performance compared to both shallow LSTMs having only one single LSTM layer as well as deep LSTMs without multi-tasking.</p><p>Liang et al. <ref type="bibr" target="#b115">[117]</ref> presented a real-time crowd density prediction system in transportation stations that leverages the mobile phone users' telecommunication data known as caller detail record (CDR). CDR data are gathered when a user takes a telecommunication action (i.e., call, SMS, MMS, and Internet access) on the phone, which usually includes data about user ID, time, location, and the telecommunication action of the user. They built their system based on an RNN model for metro stations, and reported more accurate predictions compared to nonlinear autoregressive neural network models.</p><p>Waste management and garbage classification is another related task for smart cities. A straightforward method to perform this automation is through vision-based classifications using deep CNNs as it has been done in <ref type="bibr" target="#b79">[81]</ref>. Monitoring air quality and predicting the pollution is another direction for city management. Li et al. <ref type="bibr" target="#b116">[118]</ref> developed a DL-based air quality prediction model using a stacked AE for unsupervised feature extraction and a logistic regression model for regression of the final predictions.</p><p>Amato et al. in <ref type="bibr" target="#b117">[119]</ref> developed a decentralized system to identify the occupied and empty spots in parking lots using smart cameras and deep CNNs. The authors deployed a small architecture of a CNN on smart cameras, which are equipped with Raspberry Pi 2 model. These embedded devices in smart cameras can thus run the CNN on each device to classify images of individual parking spaces as occupied or empty. The cameras then send only the classification output to a central server. Valipour et al. <ref type="bibr" target="#b118">[120]</ref> also developed a system for detecting parking spots using CNN, which has shown improved results compared to SVM baselines. Table <ref type="table" target="#tab_3">III</ref> summarizes the aforementioned attempts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Energy:</head><p>The two way communication between energy consumers and the smart grid is a source of IoT big data. In this context, smart meters are in the role of data generation and acquisition for the fine grained level of energy consumption measurement. Energy providers are interested to learn the local energy consumption patterns, predict the needs, and make appropriate decisions based on real-time analytics. Mocanu et al. in <ref type="bibr" target="#b119">[121]</ref> have developed a kind of RBM to identify and predict the buildings' energy flexibility in real-time. Energy flexibility is about modifying a household's electricity consumption while minimizing the impact on the occupants and operations. In the mentioned work, time-of-use and consumption of individual appliances are predicted to achieve flexible energy control. The advantage of this model beyond showing good performance and accuracy is that flexibility identification can be performed with flexibility prediction concurrently. In <ref type="bibr" target="#b120">[122]</ref>, two variations of RBMs are used to forecast energy consumption for short term intervals in residential houses. The model includes a Conditional RBM (CRBM) and a Factored Conditional RBM (FCRBM). Their results indicate that FCRBM performs better that CRBM, RNN and ANN. Moreover, by extending the forecasting horizon, FCRBM and CRBM show more accurate predictions than the RBM and ANN.</p><p>On the smart grid side, forecasting the power from solar, wind, or other types of natural sustainable sources of energy is an active research field. DL is increasingly used in many applications in this domain. For example, in <ref type="bibr" target="#b121">[123]</ref>, Gensler et al. investigate the performance of several DL models, such as DBNs, AEs, and LSTMs, as well as MLP for predicting the solar power of 21 photovoltaic plants. For solar power prediction, a main element of the input is a numeric value for weather forecasting in a given time horizon. From their evaluation, the combination of AEs and LSTMs (Auto-LSTM) has been shown to produce the best results compared to other models, followed by DBN. The reason for obtaining a good prediction score by Auto-LSTM is that they are able to extract features from raw data, which is not the case for ANN and MLP. In <ref type="bibr" target="#b84">[86]</ref>, an online forecasting system based on LSTM is proposed to predict the solar flare power 24 hours ahead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Intelligent Transportation Systems:</head><p>Data from Intelligent Transportation Systems (ITS) is another source of big data that is becoming ubiquitous every day. Ma et al. <ref type="bibr" target="#b77">[79]</ref> presented a system of transportation network analysis based on DL. They have employed RBM and RNN architectures as their models in a parallel computing environment, and GPS data from participating taxies as the input of the models. The accuracy of their system to predict traffic congestion evolution over one hour of aggregated data is reported to be as high as 88% which was computed within less than 6 minutes. <ref type="bibr" target="#b122">[124]</ref> also reported the investigation on short-term traffic flow prediction. They used LSTM as their learning model and reported better accuracy for LSTM compared to other methods including SVM, simple feed forward neural networks, and stacked AEs. For different intervals (15, 30, 45, and 60 min) LSTM showed the lowest mean absolute percentage error (MAPE) rate. However, for short intervals of 15 minutes, the error rate of SVM is slightly higher than the LSTM model. This result can be interpreted by the fact that the small number of data points in short intervals does not make stronger discrimination boundaries for the classification task in the LSTM model compared to the SVM model. In another study <ref type="bibr" target="#b106">[108]</ref>, ITS data are exposed to an intrusion detection system based on DNN to improve the security of in-vehicular network communications.</p><p>ITS also motivate the development of methods for traffic sign detection and recognition. Applications such as autonomous driving, driver assistance systems, and mobile mapping need such sort of mechanisms to provide reliable services. Cires ?an et al. <ref type="bibr" target="#b123">[125]</ref> presented a traffic sign recognition system based on DNNs of convolutional and max-pooling layers. They introduced a multi-column DNN architecture that includes several columns of separate DNNs, and reported increased accuracy with this approach. The input is preprocessed by several different preprocessors, and a random number of columns receives the preprocessed input to proceed with training. The final prediction output is the average of all the DNNs' outputs. Their results show that this proposed method, achieving a recognition rate of 99.46%, has been able to recognize traffic signs better than the humans on the task with 0.62% more accuracy.</p><p>In order to be applicable in real scenarios, these analytics need to be performed in real-time. Lim et al. in <ref type="bibr" target="#b124">[126]</ref> proposed a real-time traffic sign detection based on CNN that has been integrated with a general purpose GPU. They reported F1 measure of at least 0.89 in their results with data having illumination changes. To have a faster inference engine, they used a CNN with two convolutional layers.</p><p>Furthermore, self-driving cars use DNNs in performing many tasks, such as detecting pedestrians, traffic signs, obstacles, etc. There are several startups that use DL in their self-driving cars to perform different tasks when driving in the streets <ref type="bibr" target="#b125">[127]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) Healthcare and Wellbeing:</head><p>IoT combined with DL has been also employed in providing healthcare and wellbeing solutions for individuals and communities. For instance, developing solutions based on mobile apps to accurately measure dietary intakes is a track of research that can help control the health and wellbeing of individuals. Liu et al. in <ref type="bibr" target="#b80">[82]</ref> and <ref type="bibr" target="#b126">[128]</ref> developed a system to recognize food images and their relevant information, such as types and portion sizes. Their image recognition algorithm is based on CNNs that achieved competitive results compared to the baseline systems.</p><p>DL for classification and analysis of medical images is a hot topic in the healthcare domain. For example, Pereira et al. <ref type="bibr" target="#b127">[129]</ref> used the idea of recognizing handwritten images by CNNs to help identifying Parkinson's disease in its early stages. Their model learns features from the signals of a smart pen that uses sensors to measure handwritten dynamics during the individual's exam. Muhammad et al. <ref type="bibr" target="#b128">[130]</ref> propose a voice pathology detection system using IoT and cloud frameworks, in which patients' voice signals are captured through sensor devices and are sent to a cloud server for analytics. They used an extreme learning machine trained by voice signals to diagnose the pathology. In <ref type="bibr" target="#b129">[131]</ref>, DL was employed for detection of cardiovascular diseases from mammograms. In their study, Wang et al. used breast arterial calcification (BAC) revealed in mammograms as a sign of coronary artery disease. They developed a CNN with twelve layers to identify the existence of BAC in a patient. Their results show that the accuracy of their DL model is as good as the human experts. Although this work has been done offline, it shows the potential of developing or extending mammogram devices in IoT contexts for online and early detection of such diseases.</p><p>Feng et al. <ref type="bibr" target="#b130">[132]</ref> report the use of RBMs and DBNs for fall detection in a home care environment. Normal postures in such environment are standing, sitting, bending, and lying. Lying on the floor longer than a threshold is considered as a fallen posture. Their evaluation shows that RBM outperforms DBN in terms of classification accuracy. The lack of large datasets and performing offline detection are the restrictions of their method.</p><p>Researchers also used time series medical data in conjunction with RNN based models for early diagnosis and prediction of diseases. Lipton et al. <ref type="bibr" target="#b131">[133]</ref> investigated the performance of LSTM networks to analyze and recognize patterns in multivariate time series of medical measurements in intensive care units (ICUs). The input data in their system consist of sensor data of vital signs as well as lab test results. Their performance results show that an LSTM model trained on raw time-series data outperforms a MLP network. A survey of DL in health informatics is provided in <ref type="bibr" target="#b132">[134]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6) Agriculture:</head><p>Producing healthy crops and developing efficient ways of growing plants is a requirement for a healthy society and sustainable environment. Disease recognition in plants using DNNs is a direction that has shown to be a viable solution. In a study that is reported by Sladojevic et al. <ref type="bibr" target="#b81">[83]</ref>, the authors developed a plant disease recognition system based on the classification of leave images. They have used a deep convolutional network model implemented using the Caffe framework. In this model, diseased leaves in 13 categories can be identified from the healthy ones with an accuracy of about 96%. Such recognition model can be exploited as a smart mobile applications for farmers to identify the fruit, vegetable, or plant disease based on their leaf images captured by their mobile devices. It can also allow them to select remedies or pesticides in conjunction with complementary data.</p><p>DL also has been used in remote sensing for land and crop detection and classification <ref type="bibr" target="#b133">[135]</ref> [136] <ref type="bibr" target="#b135">[137]</ref>. The direction established in these works enabled the automated monitoring and management of the agricultural lands in large scales. In most of such works, deep convolutional networks are used to learn from images of the land or crops. In <ref type="bibr" target="#b133">[135]</ref>, it is reported that using CNN has yielded an accuracy of 85% in detecting major crops, including wheat, sunflower, soybeans, and maize, while outperforming other approaches such as MLP and random forest (RF).</p><p>Furthermore, DL has been reported to be utilized for prediction and detection tasks for automatic farming. For example, <ref type="bibr" target="#b136">[138]</ref> has used a DL model based on deep CNNs for obstacle detection in agricultural fields, which enables autonomous machines to operate safely in them. The proposed system was able to detect a standardized object with an accuracy between 90.8% to 99.9%, based on the field (e.g., row crops or grass mowing).</p><p>Moreover, fruit detection and finding out the stage of fruit (raw or ripe) is critical for automated harvesting. In <ref type="bibr" target="#b137">[139]</ref>, Sa et al. used a variation of CNN, called Region-based CNN, for image analysis of fruits. The input image of the system comes in two modes: one containing RGB colors and the other is near-infrared. The information of these images are combined in the model and has achieved detection improvement compared to pixel-based training models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7) Education:</head><p>IoT and DL contribute to the efficiency of education systems, from kindergarten to higher education. Mobile devices can gather learners' data and deep analytical methods can be used for prediction and interpretation of learners progress and achievements. Augmented reality technology combined with wearables and mobile devices are also potential applications for DL methods in this area to make students motivated, lessons and studies to be interesting, and make educational learning methods to be efficient <ref type="bibr" target="#b138">[140]</ref>, <ref type="bibr" target="#b139">[141]</ref>. Moreover, DL can be used as a personalized recommendation module <ref type="bibr" target="#b140">[142]</ref> to recommend more relevant content to the educator. The applications of DL in other domains, such as natural language translation and text summarization, would be of help for smart education when it comes to online learning on mobile devices.</p><p>Furthermore, the advent of Massive Open Online Courses (MOOCs) and their popularity among the students has led to generating a huge amount of data from the learners' behavior in such courses. MOOCs analysis can help identify struggling students in early sessions of a course, and provide sufficient support and attention from instructors to those students to achieve a better performance. Yang et al. <ref type="bibr" target="#b141">[143]</ref> proposed a method for predicting student grades in MOOCs. They use clickstream data collected from lecture videos when students are watching the video and interacting with it. Clickstream data are fed to a time series RNN that learns from both prior performance and clickstream data. In addition, Piech et al. applied RNN and LSTM networks to model the prediction of educator answers to exercises and quizzes, based on their past activities and interactions in MOOCs <ref type="bibr" target="#b142">[144]</ref>. Results showed improvement over Bayesian Knowledge Tracing (BKT) methods, which employ a Hidden Markov Model (HMM) for updating probabilities of single concepts. Mehmood et al. <ref type="bibr" target="#b75">[77]</ref> also used DNNs for a personalized ubiquitous e-teaching and e-learning framework, based on IoT technologies, aiming for the development and delivery of educational content in smart cities. Their proposed framework is built on top of an IoT infrastructure (e.g., smart phone sensors, smart watch sensors, virtual reality technologies) connecting the users in order to optimize the teaching and learning processes. They used DNN for human activity recognition to deliver adaptive educational content to the students.</p><p>Classroom occupancy monitoring is another application that has been investigated by Conti et al. <ref type="bibr" target="#b143">[145]</ref>. In this work, the authors propose two methods for head detection and density estimation, both based on CNN architecture for counting students in a classroom. The algorithms have been deployed on off-the-shelf embedded mobile ARM platform. Their algorithm receives the images that are taken from the cameras in three classrooms with a rate of three pictures every 10 minutes. They report that the root-mean-square (RMS) error of their algorithms is at most 8.55.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8) Industry:</head><p>For the industry sector, IoT and cyber-physical systems (CPS) are the core elements to advance manufacturing technologies toward smart manufacturing (a.k.a Industry 4.0). Providing high-accuracy intelligent systems is critical in such applications, as it directly leads to increased efficiency and productivity in assembly/product lines, as well as decreased maintenance expenses and operation costs. Therefore, DL can play a key role in this field. Indeed, a wide range of applications in industry (such as visual inspection of product lines, object detection and tracking, controlling robots, fault diagnosis, etc.) can benefit from introduction of DL models.</p><p>In <ref type="bibr" target="#b76">[78]</ref>, visual inspection is investigated using CNN architectures including AlexNet and GoogLeNet over different platforms (Caffe, Tensorflow, and Torch). In this work, several images of produced vehicles in the assembly line along with their annotation are submitted to a DL system. It has been found that the best performance is achieved using Tensorflow with accuracy of 94%. Moreover, Tensorflow was the fastest framework in terms of training time, where the model reached its peak accuracy in a shorter time, followed by Torch and then Caffe.</p><p>Shao et al. <ref type="bibr" target="#b144">[146]</ref> used DNNs for feature extraction in a fault diagnosis (also referred as fault detection and classification (FDC)) system for rotating devices. Models using denoising auto-encoder (DAE) and contractive auto-encoder (CAE) were developed. The learned features from these models were both refined using a method called locality preserving projection (LPP), and fed to a softmax classifier for fault diagnosis. The input to the system is vibration data of a rotating device. In their system, seven operating conditions were considered, including normal operation, rubbing fault, four degrees of unbalance faults and compound faults (rub and unbalance). Given the vibration data, the diagnosis system identifies whether the device is in normal condition or in one of the fault conditions. Based on their experiments for fault diagnosis of rotor and locomotive bearing devices, the proposed approach is reported to outperform CNN and shallow learning methods.</p><p>In another study reported by Lee <ref type="bibr" target="#b145">[147]</ref>, a DBN model was proposed in conjunction with an IoT deployment and cloud platform to support fault detection of defect types in cars' headlight modules in a vehicle manufacturer setting. Their results confirmed the superior performance of the DBN model over two baseline methods, using SVM and radial basis function (RBF), in terms of error rate in test dataset. However, the reported error rate for their training dataset in the DBN model is comparable to that of the SVM model.</p><p>For the problem of fault detection and classification (FDC) in noisy settings, <ref type="bibr" target="#b146">[148]</ref> employed stacked denoising AEs (SdA) to both reduce the noise of sensory data caused by mechanical and electrical disturbances, and perform fault classification. Their system was applied for fault detection in wafer samples of a photolithography process. Results show that SdA leads to 14% more accuracy in noisy situations compared to several baseline methods including K-Nearest Neighbors and SVM. Yan et al. <ref type="bibr" target="#b147">[149]</ref> have also used SdA joint with extreme learning machines for anomaly detection in the behavior of gas turbine combustion system. Based on their results, the use of learned features by SdA leads to a better classification accuracy compared to the use of hand crafted features in their system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9) Government:</head><p>Governments can gain great potential advantages through enhanced and intelligent connectivity that comes from the convergence of IoT and DL. Indeed, a wide variety of tasks that pertains to the governments or city authorities require precise analysis and prediction. For instance, the recognition and prediction of natural disasters (landslide, hurricane, forest fires, etc.) and environmental monitoring is of high importance for governments to take appropriate actions. Optical remote sensing images that are fed to a deep AEs network and softmax classifiers were proposed by Liu et al. <ref type="bibr" target="#b148">[150]</ref> to predict geological landslides. An accuracy of 97.4% was reported for the proposed method, thus outperforming SVM and ANN models. In another study <ref type="bibr" target="#b149">[151]</ref>, an LSTM network is used for the prediction of earthquakes. They used the historical data from US Geological Survey website for training. Their system was shown to achieve an accuracy of 63% and 74% with 1-D and 2-D input data, respectively. In another study by Liu et al. <ref type="bibr" target="#b82">[84]</ref>, a CNN architecture is used for detection of extreme climate events, such as tropical cyclones, atmospheric rivers and weather fronts. Training data in their system included image patterns of climate events. The authors developed their system in Neon framework and achieved accuracy of 89%-99%.</p><p>In addition, damage detection in the infrastructures of the cities, such as roads, water pipelines, etc., is another area where IoT and DL can provide benefits to governments. In <ref type="bibr" target="#b150">[152]</ref>, the problem of road damage detection was addressed using DNNs that gets its data through crowd-sourcing, which can be enabled by IoT devices. Citizens can report the damage through a mobile app to a platform. However, these citizens have no expert knowledge to accurately assess the status of road damage, which may lead to uncertain and/or wrong assessments. To eliminate these instances, the app can determine the status of the road damage by analyzing the image of the scene. The analysis is performed by a deep CNN that is trained by citizen reports as well as road manager inspection results. Since the training phase is out of the capability of mobile phones, the DL model is created on a server and trained everyday. An Android application can then download the latest model from the server upon each launch, and identify the status of road damages reported by images. Evaluations showed a damage classification accuracy of 81.4% in 1 second of analysis on the mobile devices.</p><p>10) Sport and Entertainment: Sports analytics have been evolving rapidly during the recent years and plays an important role to bring a competitive advantage for a team or player. Professional sport teams nowadays have dedicated departments or employees for their analytics <ref type="bibr" target="#b151">[153]</ref>. Analytics and predictions in this field can be used to track the players' behavior, performance, score capturing, etc. DL is new to this area and only few works have used DNNs in different sports.</p><p>In <ref type="bibr" target="#b152">[154]</ref>, a DL method has been proposed for making an intelligent basketball arena. This system makes use of SVM to choose the best camera for real-time broadcasting from among the available cameras around the court. They also fed basketball energy images <ref type="foot" target="#foot_3">4</ref> to a CNN to capture the shoot and scoring clips from the non-scoring ones, hence providing accurate online score reporting and interesting highlight clips. This system was shown to achieve an accuracy of 94.59% in capturing score clips with 45 ms of processing time for each frame.</p><p>In another work by Wang et al. <ref type="bibr" target="#b153">[155]</ref>, an RNN has been used for classification of offensive basketball plays in NBA games. The authors used video clips of the games from SportVU<ref type="foot" target="#foot_4">5</ref> dataset. This dataset provides videos of the rate of 25 frames per second to detect players' unique ID, their location on the court, and the position of the ball. Their model is shown to achieve accuracy of 66% and 80% for top-1 and top-3 accuracies, respectively. Similarly, <ref type="bibr" target="#b154">[156]</ref> used an RNN with LSTM units over the same dataset to predict the success rates of three-point shots, and reported better classification accuracy compared to gradient boosted machine (GBM) and generalized linear model (GLM).</p><p>Kautz et al. <ref type="bibr" target="#b155">[157]</ref> investigated players' activity recognition in volleyball. Wearable sensor data and CNN were employed to achieve this task, and a classification accuracy of 83.2% to identify players activities was observed.</p><p>Group activity recognition is another interesting direction for sport teams. Ibrahim et al. <ref type="bibr" target="#b156">[158]</ref> investigated this option in a volleyball team using a hierarchical LSTM model. In this work, a single LSTM model was built to derive the activities of each player, and a top-level LSTM model was designed to aggregate the individual models to identify the overall behavior of the team. A CNN model was utilized to extract features from video frames, and feed them to the individual LSTM models. Compared to several baseline models, the proposed hierarchical model obtained better classification results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11) Retail:</head><p>Due to the proliferation of mobile devices, online shopping has increased greatly. A recent shift toward product image retrieval through visual search techniques was noticed <ref type="bibr" target="#b157">[159]</ref>. CNNs have been used for this visual search of clothes and fashion market, to find items in online shops that are identical or similar to what you have seen in a movie <ref type="bibr" target="#b158">[160]</ref> or in the street <ref type="bibr" target="#b159">[161]</ref>.</p><p>Moreover, shopping for visually impaired people needs to be made convenient. A combination of IoT technologies, including smart carts, integrated with DL methods can be a solution to this problem. In <ref type="bibr" target="#b160">[162]</ref>, a visual grocery assistance system that includes smart glasses, gloves, and shopping carts was designed to help visually impaired people in shopping. This system also used a CNN to detect items in the aisles.</p><p>Moreover, check-out counters in retail stores are usually the bottlenecks where people queue up to pay their shoppings. The development of smart carts can enable real-time self check-out and enhancing such system with prediction capabilities can offer an item that a customer may need based on his/her past shopping.</p><p>Furthermore, recommending items to shoppers is a popular application of IoT for retails that uses different technologies, like BLE signals or visual cameras. The latter approach can be done through identifying the shop items or shoppers actions (e.g., reach to a shelf, retract from a shelf, etc.) <ref type="bibr" target="#b161">[163]</ref> and providing a list of related items for the detected action.</p><p>To analyze the customer interest in merchandise, Liu et al. <ref type="bibr" target="#b97">[99]</ref> proposed a customer pose and orientation estimation system based on a DNN consisting of a CNN and RNN. The input data comes from surveillance cameras. The CNN network is used to extract image features. The image features and the last predicted orientation features are then fed to an RNN to get the output pose and orientation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>12) Smart IoT Infrastructure:</head><p>IoT environments consist of a large number of sensors, actuators, media and many other devices that generate big M2M and network traffic data. Therefore, the management, monitoring, and coordination of these devices are subject to processing such big data, with advanced machine learning techniques, to identify bottlenecks, improve the performance, and guarantee the quality of service.</p><p>One popular task for infrastructure management would be anomaly detection. For example, spectrum anomaly detection in wireless communications using AE was proposed by Feng et al. in <ref type="bibr" target="#b162">[164]</ref>. In this work, an AE model was developed to detect the anomaly that may happen due to sudden change in signalto-noise ratio of the communications channel. The model is trained on features based on the time-frequency diagram of input signals. Their result showed that a deeper AE performs better than the conventional shallow networks. Lopez-Martin et al. <ref type="bibr" target="#b163">[165]</ref> and Shone et al. <ref type="bibr" target="#b164">[166]</ref> have used conditional VAE and deep AEs, respectively, for network intrusion detection. In the conditional VAE, the labels of the samples are used in addition to the latent variables as extra inputs to the decoder network.</p><p>The tiny traces of IoT traffic may not lead to congestion at the backbone. However, the need to access the channel simultaneously by a large number of IoT devices can lead to contention during the channel access phase. The contention in channel access turns to a severe problem when the access delays are increased <ref type="bibr" target="#b165">[167]</ref>. Therefore, load balancing is a viable solution that can be performed by DL models to predict the traffic metrics and propose alternate routes. Kim et al. <ref type="bibr" target="#b166">[168]</ref> used DBNs to perform load balancing in IoT. Their DL model is trained on a large amount of user data and network loads. Interference identification can also be handled by DNNs as demonstrated by Schmidt et al. <ref type="bibr" target="#b167">[169]</ref>, where a wireless interference identification systems based on CNN was proposed. Ahad et al. <ref type="bibr" target="#b168">[170]</ref> provided a survey focused on the application of neural networks to wireless networks. They reviewed related literature on quality of service and quality of experience, load balancing, improved security, etc.</p><p>Since the emerging 5th Generation (5G) cellular networks constitute one of the main pillars of IoT infrastructure, it is necessary to utilize cutting-edge technologies to enhance the different aspects of cellular networks, including radio resource management, mobility management, service provisioning management, self-organization, and to find an efficient and accurate solution for complicated configuration problems <ref type="bibr" target="#b169">[171]</ref>. As part of these efforts, using crowd-sourced cellular networks data (e.g., signal strength) can help to come up with reliable solutions. For example, such big data can be used to create more precise coverage maps for cellular networks to improve the performance of the network <ref type="bibr" target="#b170">[172]</ref>, as was performed by the OpenSignal mobile application <ref type="bibr" target="#b171">[173]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Lessons Learned</head><p>In this section, we have identified five classes of IoT services as the foundational services that can be used in a wide range of IoT applications. We discussed how DL has been used to achieve these services. Moreover, we went through a wide range of IoT domains to find out how they exploit DL to deliver an intelligent service. Table <ref type="table" target="#tab_4">IV</ref> shows the works that utilized foundational services in IoT domains.</p><p>Many IoT domains and applications have greatly benefited from image recognition. The interest is expected to grow faster as the high-resolution cameras embedded in smart phones will result in easier generation of image and video data. The usage of other fundamental applications, especially physiological and psychological detections as well as localization, can be seen in different fields. However, the utilization of security and privacy services is shown to be limited. This is the gap in developing intelligent IoT applications, where the potential activities of hackers and attackers are ignored. Also, voice recognition with DL has not been used widely in IoT applications belonging to several domains, such as smart homes, education, ITS, and industry. There are works that use voice recognition with traditional machine learning approaches. Voice recognition has shown remarkable advancement with DL. One reason for the few appearance of this technique in IoT applications is the lack of comprehensive training datasets for each domain, as there is a need for large training datasets to train voice recognition DNNs.</p><p>Foundational services need fast data analytics to be efficient in their context. Despite several works in this direction, IoT fast data analytics based on DL has many spaces for development of algorithms and architectures.</p><p>Table <ref type="table" target="#tab_5">V</ref> summarizes the research in each domain, and their DL model. Figure <ref type="figure" target="#fig_17">18</ref> also depicts the frequency of different models that have been used in the different research works. About 43% of the papers have used CNN in building their proposed systems while DBN are less used compared to other models (about 7%). RNNs and LSTMs together, as time-series models, have been used in 30% of the works. The table also emphasizes the great impact of works related to image recognition on IoT applications. Moreover, one third of the IoT applications are related to time-series or serial data, in which employing RNNs is a helpful approach.</p><p>1) Complexity vs. Performance:</p><p>Canziani et al. <ref type="bibr" target="#b172">[174]</ref> analyzed several state-of-the-art DNN models to find out the relationship between their accuracy, memory usage, operations count, inference time, and power consumption. They found out that the accuracy and inference time show a hyperbolic relationship such that a minor increase in accuracy leads to a long computational time. They also illustrated that the number of operations in a network model have a linear relationship with the inference time. Their results also indicated that imposing an energy constraint would limit the maximum achievable accuracy. Regarding the memory footprint and batch size, the results showed that the maximum memory usage is constant during the initial memory allocation of the model and then linearly increases with the batch size. Given that the neurons are the main building blocks of a model that performs the operations, the number of operations is proportional to the number of neurons. So, the complexity can be expressed as the number of neurons in the network, such that increasing the number of neurons directly impacts the run-time.</p><p>However, there is not a clear relationship between the accuracy and number of layers (i.e., depth) or number of neurons. There are reports indicating degradation of accuracy after increasing the number of layers beyond some point. For example, Zhang et al. <ref type="bibr" target="#b92">[94]</ref> assert that the number of hidden layers and neurons have a direct effect on the accuracy of the localization system. Increasing the layers initially leads to better results, but at some point when the network is made deeper, the results start degrading. Their best result was obtained with a network of three hidden layers. On the other hand, the depth of representations has been shown to be most beneficial for many image recognition tasks <ref type="bibr" target="#b28">[30]</ref>. The high accuracy of vision-based tasks, in part, is due to introducing deeper networks with larger number of parameters (e.g., over 1000 layers as presented in <ref type="bibr" target="#b28">[30]</ref>, <ref type="bibr" target="#b173">[175]</ref>). There are many hyper-parameters to optimize (e.g., epoch count, loss function, activation function, optimization function, learning rate, etc.) that complicate the process of developing good and accurate DL models. Table <ref type="table" target="#tab_6">VI</ref> summarizes the characteristics of DNN models in several applications. In the table, the test time is for one sample unless specified otherwise.</p><p>2) Pitfalls and Criticisms: DL models were demonstrated to be as a great step toward creating powerful AI systems, but they are not a single solution for all problems. DL techniques are known as black boxes that show high predictability but low interpretability. While powerful prediction capability is most desired from the scientific perspective, the interpretability and explicability of the models are preferred from a business perspective <ref type="bibr" target="#b174">[176]</ref>. In [177], Chollet argued that problems requiring reasoning, longterm planning, and algorithmic-like data manipulation, cannot be solved by deep learning models. This is because of the nature of DL techniques that only transform one vector space into another, no matter how much data you feed them. there are criticisms on the performance of DNN models, suggesting that the traditional models may achieve comparable results or even outperform deep models <ref type="bibr" target="#b176">[178]</ref>. According to Chatfield et al. <ref type="bibr" target="#b177">[179]</ref>, the dimensionality of the convolutional layers in CNNs can be shrunk without adversely affecting the performance. They also discussed that the shallow techniques can reach a performance analogous to that of deep CNN models if the former models use the data augmentation techniques that are commonly applied to CNN-based methods. Ba et al. <ref type="bibr" target="#b178">[180]</ref> performed several empirical tests asserting that shallow FNNs can learn the complex functions and achieve accuracies that were previously possible only by deep models. In their work on optical communication systems, Eriksson et al. <ref type="bibr" target="#b179">[181]</ref> showed that using pseudo random bit sequences or short repeated sequences can lead to overestimating the signalto-noise ratio.</p><p>Generally, DL models are sensitive to the structure, and size of the data. Compared to shallow models, they work better when there is a large body of training data with a wide range of attributes. Otherwise, shallow models typically lead to better results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. DL ON IOT DEVICES</head><p>Prior to the era of IoT, most research on DL targeted the improvement of its models and algorithms to efficiently operate when the scale of the problem grows to the big data, by trying to deploy efficient models on cloud platforms. The emergence of IoT has then opened up a totally different direction when the scale of the problems shrank down to resource-constrained devices and to the need for real-time analytics.</p><p>Smart objects need to support some sort of light-weight intelligence. Due to DL's successful results in speech and video applications, which are among the fundamental services and common uses of IoT, adapting its models and approaches for deployment on resource-constrained devices became a very crucial point of study. So far, DL methods can hardly be used in IoT and resource-constrained devices for training purposes since DL models require a large portion of resources, such as the processors, battery energy, and memory. In some cases, the available resources are even not sufficient for running a pre-trained DL algorithm for inference tasks <ref type="bibr" target="#b78">[80]</ref>. Luckily, it has been recently shown that many parameters that are stored in DNNs may be redundant <ref type="bibr" target="#b180">[182]</ref>. It is also sometimes unnecessary to use a large number of hidden layers to get a high accuracy <ref type="bibr" target="#b178">[180]</ref>. Consequently, efficiently removing these parameters and/or layers will considerably reduce the complexity of these DNNs without significant degradation of the output <ref type="bibr" target="#b178">[180]</ref>, <ref type="bibr" target="#b180">[182]</ref> and make them IoT-friendly. In the remaining of this section, we will discuss methods and technologies to achieve this results, and illustrate their applications in different domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Methods and Technologies</head><p>DL models may consist of millions or even billions of parameters which need sophisticated computing and large storage resources. In this section, we discuss several state-ofthe-art approaches that bring DL models to IoT embedded Image Recognition <ref type="bibr" target="#b148">[150]</ref> and resource constrained devices.</p><p>1) Network Compression: One way of adopting DNNs to resource-constrained devices is through the use of network compression, in which a dense network is converted to a sparse network. This approach helps in reducing the storage and computational requirements of DNNs when they are used for classification or other sorts of inference on IoT devices. The main limitation of this approach is that they are not general enough to support all kinds of networks. It is only applicable to specific network models that can exhibit such sparsity.</p><p>Another interesting study to adopt compressed DL models on IoT devices is the one performed by Lane et al. <ref type="bibr" target="#b78">[80]</ref>. In this study, the authors measure different factors that embedded, mobile, and wearable devices can bear for running DL algorithms. These factors included measurements of the running time, energy consumption, and memory footprint. The study focused on investigating the behavior of CNNs and DNNs in three hardware platforms that are used in IoT, mobile, and wearable applications, namely Snapdragon 800 used in some models of smart phones and tablets, Intel Edison used in wearable and form-factor sensitive IoT, and Nvidia Tegra K1 employed in smart phones as well as IoT-enabled vehicles. Torch has been used for developing and training DNNs, and AlexNet <ref type="bibr" target="#b35">[37]</ref> was the dominant model used in these platforms. Their measurement of energy usage indicated that all the platforms, including Intel Edison (which is the weakest one), were able to run the compressed models. In terms of execution time for CNNs, it has been shown that the later convolutional layers tend to consume less time as their dimensions decrease.</p><p>Moreover, it is known that feed-forward layers are much faster than the convolutional layers in CNNs. Consequently, a good approach for improving CNN models on resourceconstrained devices is to replace convolutional layers with feed-forward layers whenever possible. In addition, choosing the employed activation function in DNNs can have a great effect on time efficiency. For instance, several tests have shown that ReLU functions are more time-efficient followed by Tanh, and then Sigmoid. However, the overall runtime reduction of such selection is not significant (less than 7%) compared to the execution time of layers (at least 25%). In terms of memory usage, CNNs use less storage than DNNs due to the fewer stored parameters in convolutional layers compared to their counterpart in DNNs.</p><p>As previously stated, reducing the number of employed parameters in DNNs, by pruning redundant and less-important ones, is another important approach to make DNNs implementable on resource-constrained devices. One of the first works on this approach is Optimal Brain Damage <ref type="bibr" target="#b181">[183]</ref> in At the core of this method, the second order derivative of the parameters are used to compute the importance of the parameters and prune unimportant parameters from the ? Train the network to find the connections with high weights.</p><p>? Prune the unimportant connections that have a weight less than a threshold. ? After pruning, there may remain some neurons with no input nor output connections. The pruning process identifies these neurons and removes them as well as all their remaining connections. ? Retrain the network to fine-tune the weight of the updated model. The weights should be transferred from the previous trained steps instead of initializing them, otherwise the performance will degrade to some extent.</p><p>The authors evaluated this approach on four models related to vision, namely AlexNet, VGG-16, LeNet-300-100, and LeNet-5. The models were compressed at least 9 times for AlexNet and 13 times at VGG-16, while the accuracy of the models were almost preserved. One limitation of this approach is that it cannot be used for other types of DNN models. Moreover, the resulting compressed networks are not efficient enough on all hardware platforms and CPU architectures, and thus need new kinds of accelerators that can handle dynamic activation sparsity and weight sharing. Figure <ref type="figure" target="#fig_18">19</ref> illustrates the concept of pruning a DNN. In <ref type="bibr" target="#b183">[185]</ref>, an inference engine, called EIE, was designed with a special hardware architecture and SRAMs instead of DRAMs, and was shown to work well with compressed network models. In this architecture, customized sparse matrix vector multiplication and weight sharing are handled without losing the efficiency of the network. The engine consists of a scalable array of processing elements (PEs), each of which keeping a part of the network in an SRAM and performing its corresponding computations. Since most of the energy that is used by neural networks is consumed for accessing the memory, the energy usage is reported to be 120 times fewer with this designed accelerator than the energy consumption of the corresponding original network.</p><p>In HashedNets <ref type="bibr" target="#b184">[186]</ref>, the neural network connection weights are randomly grouped into hash buckets using a hash function. All connections that fall into a same bucket are represented by a single parameter. Backpropagation is used to fine-tune the parameters during the training. Testing results show that the accuracy of this hash-based compressed model outperforms all other compression baseline methods.</p><p>The work in <ref type="bibr" target="#b185">[187]</ref> by Courbariaux et al. proposed to binarize network weights and neurons at both the inference phase and the entire training phase, in order to reduce the memory footprint and accesses. The network can also perform most of the arithmetic operations through bit-wise operations, leading to a decreased power consumption. MNIST, CIFAR-10 and Street View House Numbers (SVHN) <ref type="bibr" target="#b193">[195]</ref> datasets were tested over Torch7 and Theano frameworks using this approach, and results were found to be promising.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Approximate Computing:</head><p>Approximate computing is another approach to both implement machine learning tools on IoT devices and contribute to the energy saving of their hosting devices <ref type="bibr" target="#b186">[188]</ref>, <ref type="bibr" target="#b187">[189]</ref>. The validity of this approach arises from the fact that, in many IoT applications, machine learning outputs (e.g., predictions) need not to be exact, but rather to be in an acceptable range providing the desired quality. Indeed, these approaches need to define quality thresholds that the output must not pass. Integrating DL models with approximate computing can lead to more efficient DL models for resourceconstrained devices. Venkataramani et al. <ref type="bibr" target="#b186">[188]</ref> proposed the extension of approximate computing to neural networks, and converted a neural network to an approximate neural network. In their approach, the authors extend backpropagation to identify the neurons with the least effect on output accuracy. Then, the approximate NN is formed by substituting less important neurons in the original network with their approximate counterparts. Making approximate neurons is performed by an approximate design technique called precision scaling. Instead of using a typical fixed number of bits (16-bit or 32-bit format) to present computations, various number of bits (4 -10 bits) are used in this technique. After forming the approximate network, the precisions of the inputs and weights of neurons are adjusted to come up with an optimal trade-off between accuracy and energy. There are also other attempts that have reported applying approximate computing with precision scaling on CNNs <ref type="bibr" target="#b187">[189]</ref> and DBNs <ref type="bibr" target="#b194">[196]</ref>. However, the current practice requires that the process of training the model and converting it to approximate DL takes place on a resource rich platform and then the converted model is deployed on a resource-constrained device.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Accelerators:</head><p>Designing specific hardware and circuits is another active research direction aiming to optimize the energy efficiency <ref type="bibr" target="#b189">[191]</ref> and memory footprint <ref type="bibr" target="#b190">[192]</ref> of DL models in IoT devices. The focus of such research works is on the inference time of DL models, since the training procedure of complex models is time and and energy intensive. In <ref type="bibr" target="#b195">[197]</ref>, several approaches for improving the intelligence of IoT devices are identified including designing accelerators for DNNs, and using Post-CMOS technologies such as spintronics that employs electron spinning mechanism <ref type="bibr" target="#b196">[198]</ref>. This latter technology suggests a direction toward the development of hybrid devices that can store data, perform computations and communications within the same material technology.</p><p>The works in <ref type="bibr" target="#b188">[190]</ref> and <ref type="bibr" target="#b189">[191]</ref> have reported an investigation of developing accelerators for DNNs and CNNs, respectively. Beyond the hardware accelerators, the work in <ref type="bibr" target="#b191">[193]</ref> proposed the use of a software accelerator for the inference phase of DL models on mobile devices. It employs two resource control algorithms at run-time, one that compresses layers and the other that decomposes deep architecture models across available processors. This software accelerator can be a complementary solution for the hardware accelerator designs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Tinymotes:</head><p>In addition to all prior solutions, developing tiny size processors (micromotes) with strong DL capabilities is on the rise <ref type="bibr" target="#b192">[194]</ref>  <ref type="bibr" target="#b197">[199]</ref>. Designed within the range of one cubic millimeter, such processors can be operated by batteries, consuming only about 300 microwatts while performing onboard analysis and prediction using deep network accelerators. By this technology, many time-critical IoT applications can perform decision-making on the device instead of sending data to high performance computers and waiting for their response. For applications where data security and privacy are the main concerns, this integration of hardware and DL alleviates these concerns to some extent, as no or only limited data needs to be sent to the cloud for analysis. Moons et al. <ref type="bibr" target="#b198">[200]</ref> also developed a tiny processor for CNNs (total active area of 1.2 ? 2 mm 2 ) that is power efficient (power consumption is 25 to 288 mW).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Applications</head><p>There are existing mobile apps that employ pre-trained DNNs to perform their analytic and prediction tasks, such as using a CNN to identify garbage in images <ref type="bibr" target="#b79">[81]</ref>. However, resource consumption on these apps is still very high. Indeed, <ref type="bibr" target="#b79">[81]</ref> reports about 5.6 seconds for returning a prediction response, while consuming 83% of the CPU and 67 MB of memory. Howard et al. <ref type="bibr" target="#b199">[201]</ref> proposed MobileNets architecture for use in mobile and embedded vision applications. By restructuring a complex model through factorizing a standard convolution layer into a depthwise convolution and a 1 ? 1 convolution, they were able to reach a smaller and computationally efficient models for GoogleNet and VGG16. They also demonstrated several use cases of their model including object detection, image classification, and identifying face attributes.</p><p>Amato et al. <ref type="bibr" target="#b117">[119]</ref> run a CNN on Raspberry Pi boards that were incorporated in smart cameras to find out the empty parking slots. Ravi et al. in <ref type="bibr" target="#b200">[202]</ref> have reported the development of a fitness app for mobile devices that uses DL  ? Good for time-critical IoT apps ? Energy-efficient ? Provides more security and privacy for data</p><p>? Special-purpose networks for classifying human activities. The DL model is trained on a standard machine and then transferred to the mobile platform for activity recognition. However, the input of the DL model is mixed with several engineered features to improve the accuracy. As the authors describe, the small number of layers in the DNN models dedicated for a resource-constrained device is a potential reason for them achieving a poor performance.</p><p>In addition, the performance would not be satisfactorily if the training data is not well representing the entire ecosystem. Nguyen et al. <ref type="bibr" target="#b201">[203]</ref> proposed a conceptual softwarehardware framework to support IoT smart applications. Their framework consists of a cognitive engine and a smart connectivity component. The cognitive engine, which provides cognitive functionality to smart objects, utilizes both DL algorithms and game-theoretic decision analytics. To be suitable for IoT, these algorithms must be deployed on lowpower application-specific processors. The smart connectivity component integrates with cognitive radio transceivers and baseband processors to cater flexible and reliable connections to IoT smart objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Lessons Learned</head><p>In this section, the need to move toward supporting DL on IoT embedded and resource constrained devices were discussed. The adversary characteristics of IoT devices and DL techniques make this direction more challenging since IoT devices can rarely host DL models even to only perform predictions due to their resource constraints. To tackle these challenges, several methods were introduced in the recent literature including:</p><p>? DNN compression ? Approximate computing for DL ? Accelerators ? Tinymotes with DL. These approaches focus on the inference functionality of available or pre-trained DL models. So, training DL models on resource-constrained and embedded devices is still an open challenge. Shifting the training process to IoT devices is desired for scalable and distributed deployment of IoT devices. For example, having hundreds of smart security cameras deployed in a community for face-based authentication, the training process for each camera can be done on site. Network compression involves identifying unimportant connections and neurons in a DNN through several rounds of training. While this is a promising approach for getting close to real-time analytics on IoT devices, more investigations need to be performed to handle several challenges such as:</p><p>? It is not clear whether network compression approaches are suitable for data streaming, especially when the DL model is dynamic and may evolve over time. ? The compression methods for time-series architectures, such as RNN and LSTM, have not been well investigated, and there is a gap to see if the existing compression methods are applicable to these DL architectures. ? There is a need to specify the trade-off between the rate of compression and accuracy of a DNN, as more compression leads to degraded accuracy.</p><p>More recently, approximate computing approaches have also been utilized in making DL models simpler and more energy-efficient, in order to operate them on resource constrained devices. Similar to network compression techniques, these methods also take advantage of insignificant neurons. However, instead of manipulating the network structure, they preserve the structure but change the computation representations through bit-length reduction. For that reason, they seem applicable to a variety of DL architectures and can even cover the dynamic evolution of network models during run-time. Keeping a balance between accuracy and energy usage is their common goal. Nonetheless, more works are needed to find out the superiority of one of these approaches for embedding DL models in IoT devices.</p><p>Moreover, we discussed the emergence of special and small form-factor hardware that is designed to efficiently run DL models on embedded and resource constrained devices. These architectures can be utilized in wearable, mobile, and IoT devices, due to their reduced resource demands and their applicability to time-sensitive IoT applications. However, their generality to support any kind of DNN as well as their interoperability and compatibility with existing hardware platforms remain as clear challenges.</p><p>Table <ref type="table" target="#tab_8">VII</ref> summarizes the methods and technologies utilized in the recent literature to host DL analytics on IoT devices along with their pros and cons.</p><p>We also reviewed some applications that have implemented DL on resource constrained devices. Due to the aforementioned challenges, there are not many well developed applications in this category. However, by resolving these challenges and barriers, we will see the rise of many IoT applications where their core DL model is embedded into the sensors, actuators, and IoT smart objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. FOG AND CLOUD-CENTRIC DL FOR IOT</head><p>Cloud computing is considered a promising solution for IoT big data analytics. However, it may not be ideal for IoT data with security, legal/policy restrictions (e.g., data should not be transferred into cloud centers that are hosted outside of national territory), or time constraints. On the other hand, the high-level abstraction of data for some analytics purposes should be acquired by aggregating several sources of IoT data; hence, it is insufficient to deploy analytic solutions on individual IoT nodes in these cases.</p><p>Instead of being only on the cloud, the idea of bringing computing and analytics closer to the end-users/devices has been recently proposed under the name of fog computing. Relying on fog-based analytics, we can benefit from the advantages of cloud computing while reducing/avoiding its drawbacks, such as network latency and security risks. It has been shown that, by hosting data analytics on fog computing nodes, the overall performance can be improved due to the avoidance of transmitting large amounts of raw data to distant cloud nodes <ref type="bibr" target="#b202">[204]</ref>. It is also possible to perform real-time analytics to some extent since the fog is hosted locally close to the source of data. Smart application gateways are the core elements in this new fog technology, performing some of the tasks currently done by cloud computing such as data aggregation, classification, integration, and interpretation, thus facilitating the use of IoT local computing resources.</p><p>The work in <ref type="bibr" target="#b203">[205]</ref> proposed an intelligent IoT gateway that supports mechanisms by which the end users can control the application protocols in order to optimize the performance. The intelligent gateway primarily supports the inter-operation of different types of both IoT and resource-rich devices, causing them to be treated similarly. In the proposed intelligent gateway, a lightweight analytic tool is embedded to increase the performance at the application level. Equipping IoT gateways and edge nodes with efficient DL algorithms can localize many complex analytical tasks that are currently performed on the cloud. Table VIII summarizes several products that have incorporated DL in their intelligent core, and can serve IoT domains in the fog or cloud.</p><p>In the following subsection, we review several state-of-theart enabling technologies that facilitate deep learning on the fog and cloud platforms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Enabling Technologies and Platforms</head><p>Despite introducing DL analytics on fog infrastructure, cloud computing remains the only viable solution for analytics in many IoT applications that cannot be handled by fog computing. For example, complex tasks such as video analysis require large and complex models with a lot of computing resources. Thus, designing scalable and high performance cloud-centric DNN models and algorithms, which can perform analytics on massive IoT data, is still an important research area. Coates et al. <ref type="bibr" target="#b204">[206]</ref> proposed a large-scale system, based on a cluster of GPU servers, which can perform the training of neural networks with 1 billion parameters on 3 machines in few days. The system can be also scaled to train networks with 11 billion parameters on 16 machines.</p><p>Project Adam <ref type="bibr" target="#b205">[207]</ref> is another attempt to develop a scalable and efficient DL model. The system is based on distributed DL, where the computation and communication of the whole system are optimized for high scalability and efficiency. The evaluation of this system using a cluster of 120 machines shows that training a large DNN with 2 billion connection achieves two times higher accuracy compared to a baseline system, while using 30 times fewer machines.</p><p>Google's Tensor Processing Unit (TPU) <ref type="bibr" target="#b206">[208]</ref> is a specialized co-processor for DNNs in Google's data centers. It was designed in 2015 with the aim to accelerate the inference phase of DNNs that are written by TensorFlow framework. From 95% of DNN representatives in their data centers, CNNs only constitute about 5% of the workload, while MLPs and LSTMs cover the other 90%. Performance evaluation showed that TPU outperforms its contemporary GPUs or CPUs on average, by achieving 15 to 30 times faster operation execution, while consuming 30 to 80 times fewer energy per TeraOps/second.</p><p>Beyond the infrastructural advancements to host scalable DL models on cloud platforms, there is a need for mechanisms and approaches to make DL models accessible through APIs, in order to be easily integrated into IoT applications. This aspect has not been investigated much, and only a few products are available, such as Amazon's AWS DL AMIs<ref type="foot" target="#foot_5">6</ref> , Google cloud ML <ref type="foot" target="#foot_6">7</ref> , and IBM Watson<ref type="foot" target="#foot_7">8</ref> . This creates opportunities for cloud providers to offer "DL models as a service" as a new sub-category of Software as a Service (SaaS). However, this imposes several challenges for cloud providers, since DL tasks are computationally intensive and may starve other cloud services. Moreover, due to the data thirstiness of DL models, data transfers to the cloud may become a bottleneck. In order to deliver DL analytics on the cloud, Figure <ref type="figure">20</ref> presents a general stack for DL models as a service. Different providers may use their customized intelligence stack <ref type="bibr" target="#b207">[209]</ref>  <ref type="bibr" target="#b208">[210]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Challenges</head><p>When DL analytics come to fog nodes, several challenges need to be addressed, including:</p><p>? DL service discovery: Fog nodes are densely distributed in geographical regions, and each node may have specific analytics capabilities (e.g., one node runs CNN models for image detection, another node runs RNNs for timeseries data prediction, etc.). So, the devices need to identify the sources of appropriate analytic providers through some sort of extended service discovery protocols for DL analytics. ? DL model and task distribution: Partitioning the execution of DL models and tasks among the fog nodes, and optimally distributing of the data stream among the available nodes are critical for time-sensitive applications <ref type="bibr" target="#b209">[211]</ref>.</p><p>Aggregating the final results from the computing nodes and returning the action with the least latency are the other side of the coin.</p><p>? Design factors: Since fog computing environments are in their infancy and are expected to evolve, it is worthwhile to investigate how the design factors of the fog environment (e.g., architectures, resource management, etc.) and the deployment of DL models in this environment can impact the quality of analytic services. Alternatively, it would be also interesting to see how far these design factors can be tailored/extended to improve the operation and quality of DL analytics. ? Mobile edge: Through the ubiquity of mobile edge computing environments and their contribution to the IoT analytics, it is important to consider the dynamicity of such environments for designing edge-assisted DL analytics since mobile devices may join and leave the system. Also, the energy management of mobile edge devices should be accurate when analytic tasks are delegated to them. A few attempts reported the integration of DL on fog nodes in the IoT ecosystems. For example, a proof of concept for deploying CNN models on fog nodes for machine health prognosis was proposed by Qaisar et al. <ref type="bibr" target="#b210">[212]</ref>. In their work, a thorough search among fog nodes is done to find free nodes to delegate analytic tasks to. Also, Li et al. <ref type="bibr" target="#b211">[213]</ref> proposed a system that leverages the collaboration of mobile and edge devices running CNN models for object recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Lessons Learned</head><p>In this section, we highlighted the role of cloud and fog computing and their enabling technologies, platforms and challenges to deliver DL analytics to IoT applications. The great success of cloud computing in support of DL is backed by the advancement and employment of optimized processors for neural networks as well as scalable distributed DL algorithms. Deploying DL models on fog platforms for IoT applications, such as smart homes and smart grids, would draw the attention of the end users due to the ease of accessibility and fast response time. Nevertheless, cloud-based DL analytics would be of great importance for long-term and complex data analytics that exceed the capabilities of fog computing. Some smart city applications, government sector, and nation-wide IoT deployments need to utilize cloud-based DL infrastructures. Currently, the integration of DL analytics into IoT applications is limited to RESTful APIs, which are based on the HTTP protocol. While there exist several other application protocols that are extensively used in IoT applications, such as Message Queue Telemetry Transport (MQTT), Constrained Application Protocol (CoAP), Extensible Messaging and Presence Protocol (XMPP), and Advanced Message Queuing Protocol (AMQP), the integration of these protocols with the DL analytic interfaces calls for enhancing their compatibility with the aforementioned protocols to eliminate the need for message conversion proxies, which imposes extra overhead on the analytics response time.</p><p>We identified several challenges related to the deployment and usage of DL models in support of analytics on fog nodes. DL service discovery is a necessary requirement due to the dense deployment of fog nodes, which makes bruteforce search for available services an inefficient approach. Currently used service discovery protocols in IoT applications, such as multicast DNS (mDNS) or DNS Service Discovery (DNS-SD) <ref type="bibr" target="#b0">[1]</ref>, need to be extended to support DL service discovery (e.g., declare the type of analytics, DL model, input shape, etc.). Efficient distribution of DL models and tasks, and distribution of data streams on fog nodes and the aggregation of the results are other requirements that need to be addressed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. IOT CHALLENGES FOR DEEP LEARNING, AND FUTURE DIRECTIONS</head><p>In this section we first review several challenges that are important from the machine learning point of view to implement and develop IoT analytics. Then we point out research directions that can fill the existing gaps for IoT analytics based on DL approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Challenges 1) Lack of Large IoT Dataset:</head><p>The lack of availability of large real-world datasets for IoT applications is a main hurdle for incorporating DL models in IoT, as more data is needed for DL to achieve more accuracy. Moreover, more data prevents the overfitting of the models. This shortage is a barrier for deployment and acceptance of IoT analytics based on DL since the empirical validation and evaluation of the system should be shown promising in the natural world. Access to the copyrighted datasets or privacy considerations are another burdens that are more common in domains with human data such as healthcare and education. Also, a portfolio of appropriate datasets would be of a lot of help for developers and researchers. A general list of useful datasets has been compiled in Wikipedia <ref type="bibr" target="#b212">[214]</ref>. For the convenience of researchers in machine learning applications in IoT, table IX presents a collection of common datasets suitable to use for DL.</p><p>2) Preprocessing: Preparing raw data in an appropriate representation to be fed in DL models is another challenge for IoT applications. Most DL approaches need some sort of preprocessing to yield good results. For example, image processing techniques by CNNs work better when the input data at the pixel level are normalized, scaled into a specific range, or transformed into a standard representation <ref type="bibr" target="#b35">[37]</ref>  <ref type="bibr" target="#b58">[60]</ref>. For IoT applications, preprocessing is more complex since the system deals with data from different sources that may have various formats and distributions while showing missing data.</p><p>3) Secure and Privacy Preserving Deep Learning: Ensuring data security and privacy is a main concern in many IoT applications, since IoT big data will be transferred through the Internet for analytics, and can be thus observed around the world. While anonymization is used in many applications, these techniques can be hacked and re-identified as anonymized data. Moreover, DL training models are also subject to malicious attacks, such as False Data Injection or adversarial sample inputs, by which many functional or non-functional (e.g., availability, reliability, validity, trustworthiness, etc.) requirements of the IoT systems may be in jeopardy. Indeed, DL models learn the features from the raw data, and can therefore learn from any invalid data feed to it. In this case, DL models must be enhanced with some mechanism to discover abnormal or invalid data. A data monitoring DL model accompanying the main model should work in such scenarios. Papernot et al. <ref type="bibr" target="#b213">[215]</ref> have investigated the vulnerability of DNNs in adversarial settings where an adversary tries to provide some inputs that lead to an incorrect output classification and hence corrupting the integrity of the classification. Developing further techniques to defend and prevent the effect of this sort of attacks on DL models is necessary for reliable IoT applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Challenges of 6V's:</head><p>Despite the recent advancement in DL for big data, there are still significant challenges that need to be addressed to mature this technology. Each characteristic of IoT big data imposes a challenge for DL techniques. In the following we highlight these challenges.</p><p>The massive volume of data poses a great challenge for DL, especially for time and structure complexity. The voluminous number of input data, their broad number of attributes, and their high degree of classification result in a very complex DL model and affect running time performance. Running DL on distributed frameworks or clusters of CPUs with parallel processing is a viable solution that has been developed <ref type="bibr" target="#b6">[7]</ref>. The high volume of IoT big data also brings another challenge, namely the noisy and unlabeled data. Even though DL is very good at tolerating noisy data and learning from unlabeled data, it is not clear to what extent DL models can be accurate in the presence of such abnormal data.</p><p>The variety of IoT data formats that come from various sources pops up the challenge of managing conflicts between different data sources. In case of no conflict in data sources, DL has the ability to effectively work on heterogeneous data.</p><p>The high velocity of IoT big data, i.e., the high rate of data generation, also brings the challenge of high speed processing and analysis of data. Online learning is a solution for high velocity and has been proposed for DNNs. However, more research is needed to augment DL with online learning and sequential learning techniques.</p><p>The veracity of IoT big data also presents challenges for DL analytics. The IoT big data analytics will not be useful if the input data is not coming from a trustworthy source. Data validation and trustworthiness should be checked at each level of big data analytics, especially when we are dealing with online streams of input data to an analytic engine <ref type="bibr" target="#b214">[216]</ref>.</p><p>Moreover, the variability of IoT big data (variation in the data flow rates) rises challenges for online analytics. In case of immense streams of data, DL techniques, and in particular the online ones, handle them. Data sampling techniques would be beneficial in these scenarios.</p><p>Finally, a main challenge for business managers to adopt big data is that it is not clear for them how to use big data analytics to get value out of it and improve their business <ref type="bibr" target="#b215">[217]</ref>. Beyond that, the analytic engine may produce abstractions that are not important for the stakeholders, or are not clear enough for them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) Deep Learning for IoT Devices:</head><p>Developing DL on IoT devices poses a new challenge for IoT device designers, to consider the requirements of handling DNNs in resource-constrained devices. These requirements are expected to grow as the datasets sizes are growing every day, and new algorithms arise to be part of the solutions for DL in IoT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6) Deep Learning Limitations:</head><p>Despite showing impressive results in many applications, DL models still have several limitations. Nguyen et al. <ref type="bibr" target="#b216">[218]</ref> reported about the false confidence of DDN for predicting images that are unrecognizable by humans. By producing fooling examples that are totally unrecognizable by humans, the DNN classifies them as familiar objects.</p><p>The other limitation is the focus of DL models on classification, while many IoT applications (e.g., electricity load forecasting, temperature forecasting) need a kind of regression at their analytics core. Few works tried to enrich DNNs with regression capabilities, such as the work in <ref type="bibr" target="#b217">[219]</ref> proposing the ensemble of DBN and Support Vector Regression (SVR) for regression tasks. However, more investigation is required to clear many aspects of regression with DL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Future Directions 1) IoT Mobile Data:</head><p>One remarkable part of IoT data comes from mobile devices. Investigating efficient ways to utilize mobile big data in conjunction with DL approaches is a way to come up with better services for IoT domains, especially in smart city scenarios. In <ref type="bibr" target="#b218">[220]</ref>, the capabilities of DL models in mobile big data analytics were investigated using a distributed learning framework that executes an iterative MapReduce task on several parallel Spark workers.</p><p>2) Integrating Contextual Information: The environment's situation cannot be understood by the IoT sensor data alone. Therefore, IoT data needs to be fused with other sources of data, namely context information that complement the understanding of the environment <ref type="bibr" target="#b11">[12]</ref>. This integration can also help for fast data analytics and quick reasoning due to the bounded search space for the reasoning engine. For example, a smart camera with capability of face pose recognition can perform its job in various contexts such as security gates in smart homes or government buildings, or in smart cars for driving assistance. In all these situations, complementary contextual information (e.g., time within the day, daily habits, etc.) helps the system to reason about the best action that can be done based on the detected pose of the person.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Online Resource Provisioning for IoT Analytics:</head><p>The deployment of fast DL based data analytics on the fog and cloud would require online provisioning of fog or cloud resources to host the stream of data. Due to the streaming nature of IoT data, knowing the volume of data sequence in advance is not feasible. In this regard, we need a new class of algorithms that work based on the current stream of data and do not rely on the prior knowledge of the data stream. A DL mechanism and an online auctioning algorithm are proposed in <ref type="bibr" target="#b86">[88]</ref> and <ref type="bibr" target="#b219">[221]</ref>, respectively, to support online provisioning of fog and cloud resources for IoT applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Semi-supervised Analytic Frameworks:</head><p>Most of the analytic algorithms are supervised, thus needing a large amount of training labeled data that is either not available or comes at a great expense to prepare. Based on IDC's report <ref type="bibr" target="#b87">[89]</ref>, it is estimated that by 2012 only about 3% of all data in the digital universe has been annotated, which implies the poor source of training datasets for DL. A combination of advanced machine learning algorithms designed for semi-supervised settings fits well for smart cities systems, where a small training dataset can be used while the learning agent improves its accuracy using a large amount of unlabeled data <ref type="bibr" target="#b4">[5]</ref>. Figure <ref type="figure" target="#fig_20">21</ref> illustrates the role of semi-supervised learning in improving the output accuracy for deep reinforcement learning <ref type="bibr" target="#b59">[61]</ref> in indoor localization experiments. In their experiments, only 15% of data was labeled but the results were strengthened by utilizing unlabeled data in the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) Dependable and Reliable IoT Analytics:</head><p>As we rely more on CPS and IoT in large scales, the need for mechanisms to ensure the safety of the system against malicious attacks as well as failures become more crucial <ref type="bibr" target="#b220">[222]</ref>. DL approaches can be applied in these directions by analyzing the huge amount of log traces of CPS and IoT systems, in order to identify and predict weak points of the system where attacks may occur or functionality is defected. This will help the system to prevent or recover from faults and consequently increase the level of dependability of CPS and IoT systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6) Self-organizing Communication Networks:</head><p>With a huge number of IoT devices, the configuration and maintenance of their underlying physical M2M communications and networking become harder. Although the large body of network nodes and their relation is a challenge for traditional machine learning approaches, it opens the opportunity for DL architectures to prove their competency in this area by providing a range of self-services such as self-configuration, self-optimization, self-healing, and self-load balancing. Valente et al. <ref type="bibr" target="#b221">[223]</ref> have provided a survey of traditional machine learning approaches for self-organizing cellular networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7) Emerging IoT Applications:</head><p>Unmanned aerial vehicles: The usage of Unmanned aerial vehicles (UAVs) is a promising application that can improve service delivery in hard-reaching regions or in critical situations. UAVs have been also used for many image analysis in real-time such as surveillance tasks, searchand-rescue operations, and infrastructure inspection <ref type="bibr" target="#b222">[224]</ref>. These devices face several challenges for their adoption, including routing, energy saving, avoiding private regions, and obstacle avoidance <ref type="bibr" target="#b223">[225]</ref> etc. DL can be of great impact in this domain for the prediction and decision-making of tasks to get the best out of UAVs. Moreover, UAVs can be seen as on-the-fly analytics platforms that potentially can provide temporarily fog computing analytic services as well as distributed analytics.</p><p>Virtual/Augmented Reality: Virtual/augmented reality is another application area that can benefit from both IoT and DL. The latter can be used in this field to provide services such as object tracking <ref type="bibr" target="#b224">[226]</ref>, activity recognition, image classification, and object recognition <ref type="bibr" target="#b225">[227]</ref> to name a few. Augmented reality can greatly affect several domains such as education, museums, smart connected cars, etc.</p><p>Mobile Robotics: Mobile robots are being used in many commercial and industrial settings for moving materials or performing tasks in hazardous environments. There are many research efforts that have benefited from DL to develop an intelligent control software for mobile robots <ref type="bibr" target="#b226">[228]</ref>  <ref type="bibr" target="#b227">[229]</ref>. Being able to perceive the environment through different kinds of sensors, such as LIDARs and cameras, have made them a top topic to assess the performance of CNN techniques for a variety of vision-based tasks. A strict requirement for mobile robots is that DL models should be able to provide real-time responsiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSION</head><p>DL and IoT have drawn the attention of researchers and commercial verticals in recent years, as these two technology trends have proven to make a positive effect on our lives, cities, and world. IoT and DL constitute a chain of data producerconsumer, in which IoT generates raw data that is analyzed by DL models and DL models produce high-level abstraction and insight that is fed to the IoT systems for fine-tuning and improvement of services.</p><p>In this survey, we reviewed the characteristics of IoT data and its challenges for DL methods. In specific, we highlighted IoT fast and streaming data as well as IoT big data as the two main categories of IoT data generation and their requirements for analytics. We also presented several main architectures of DL that is used in the context of IoT applications followed by several open source frameworks for development of DL architectures. Reviewing different applications in various sectors of IoT that have utilized DL was another part of this survey in which we identified five foundational services along with eleven application domains. By distinguishing foundational services, as well as IoT vertical applications, and reviewing their DL approaches and use cases, the authors provided a basis for other researchers to understand the principle components of IoT smart services and apply the relevant techniques to their problems. The new paradigm of implementing DL on IoT devices was surveyed and several approaches to achieve it were introduced. DL based on fog and cloud infrastructures to support IoT applications was another part of this survey. We also identified the challenges and future research direction in the path of DL for IoT applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. IoT data generation at different levels and deep learning models to address their knowledge abstraction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure shows the break down of this estimate in different occupations. Compared to the economic impact of IoT, this estimation asserts the more attention toward the extraction of value out of data and the potential impacts of ML on the economic situation of individuals and societies. These economic impacts have serious consequences on individuals and countries, since people need to adapt to new means of earning income suitable for them to maintain</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Structure of the survey.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Google Trend showing more attention toward deep learning in recent years.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. A neuron is a unit of artificial neural networks, with several inputs and trainable weights and bias.</figDesc><graphic url="image-25.png" coords="6,354.66,64.86,150.84,102.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .Fig. 7 .</head><label>67</label><figDesc>Fig. 6. The overall mechanism of training of a DL model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Structure of a recurrent neural network.</figDesc><graphic url="image-45.png" coords="8,175.60,58.70,79.52,50.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Structure of a LSTM memory cell. Solid arrow lines show the flow of data and dashed arrow lines show the signals coming from gates.</figDesc><graphic url="image-115.png" coords="9,108.40,80.10,137.42,136.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>5 )Fig. 10 .Fig. 11 .</head><label>51011</label><figDesc>Fig. 10. Structure of an autoencoder network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Concept of a generative adversarial network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Structure of a restricted Boltzmann machine. The visible and hidden layers have separate bias.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>8 )Fig. 14 .</head><label>814</label><figDesc>Fig. 14. Structure of a deep belief network. The dash arrows show the feature extraction path and solid arrows show the generative path.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. Ladder network structure with two layers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Deep reinforcement learning (supervised and semi-supervised): Obtaining rewards (left) and their corresponding accuracy measurement (right) [61].</figDesc><graphic url="image-140.png" coords="13,305.77,53.14,231.86,173.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17. IoT applications and the foundational services.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>[104], Fragkiadaki et al. proposed a DNN model called Encoder-Recurrent-Decoder (ERD) for human body pose recognition and motion prediction in videos and motion capture data sets. The proposed model consisted of an RNN with an encoder before the recurrent layers and a decoder after them. This architecture was shown to outperform Conditional Restricted Boltzmann Machines (CRBMs) for this application.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 18 .</head><label>18</label><figDesc>Fig. 18. The percentage of surveyed papers that have used DL models</figDesc><graphic url="image-149.png" coords="23,349.13,284.77,203.71,103.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 19 .</head><label>19</label><figDesc>Fig. 19. The overall concept of pruning a DNN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head></head><label></label><figDesc>Fig. 20. A general stack of DL models as a service in the cloud platforms.</figDesc><graphic url="image-186.png" coords="29,83.15,51.76,182.70,206.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Fig. 21 .</head><label>21</label><figDesc>Fig. 21. Deep reinforcement learning with only labeled data (supervised) vs. with labeled and unlabeled data (semisupervised). At each epoch, semisupervised model outperforms the supervised model both in terms of total received rewards and closeness to the target.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>?</head><label></label><figDesc>Velocity: The rate of IoT big data production and processing is high enough to support the availability of big data in real-time. This justifies the needs for advanced tools and technologies for analytics to efficiently operate given this high rate of data production.? Variety: Generally, big data comes in different forms and types. It may consist of structured, semi-structured, and unstructured data. A wide variety of data types may be produced by IoT such as text, audio, video, sensory data and so on. ? Veracity: Veracity refers to the quality, consistency, and trustworthiness of the data, which in turn leads to accurate analytics. This property needs special attention to hold for IoT applications, especially those with crowd-sensing data.</figDesc><table /><note><p>? Variability: This property refers to the different rates of data flow. Depending on the nature of IoT applications, different data generating components may have inconsistent data flows. Moreover, it is possible for a data source to have different rates of data load based on specific times. For example, a parking service application that utilizes IoT sensors may have a peak data load in rush hours.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II PROPERTIES</head><label>II</label><figDesc>OF FRAMEWORKS FOR DEVELOPING DEEP LEARNING (AS OF SEPTEMBER 2017).</figDesc><table><row><cell>Frameworks</cell><cell>Core Language</cell><cell>Interface</cell><cell>Pros</cell><cell>Cons</cell><cell>Used in IoT Application</cell></row><row><cell>H2O</cell><cell>Java</cell><cell>R, Python, Scala, REST API</cell><cell>? Wide range of interfaces</cell><cell>? Limited number of ? Is not flexible models are supported</cell><cell>[77]</cell></row><row><cell>Tensorflow</cell><cell>C++</cell><cell>Python, Java, C, C++, Go</cell><cell>? Fast on LSTM training networks ? Support to visualize</cell><cell>? Slower training Python-based frameworks compared to other</cell><cell>[78]</cell></row><row><cell></cell><cell></cell><cell></cell><cell>? Supports various models</cell><cell></cell><cell></cell></row><row><cell>Theano</cell><cell>Python</cell><cell>Python</cell><cell>? Fast on LSTM training</cell><cell>? Many low level APIs</cell><cell>[79]</cell></row><row><cell></cell><cell></cell><cell></cell><cell>on GPU</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>? Supports various models</cell><cell></cell><cell></cell></row><row><cell>Torch</cell><cell>Lua</cell><cell>C, C++</cell><cell>? Good documentation ? Helpful error debugging</cell><cell>? Learning a new language</cell><cell>[78] [80]</cell></row><row><cell></cell><cell></cell><cell></cell><cell>messages</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>? Provides a collection of</cell><cell></cell><cell></cell></row><row><cell>Caffe</cell><cell>C++</cell><cell>Python, Matlab</cell><cell>reference models ? Easy platform switching ? Very good at convolutional</cell><cell>? Not very good for recurrent networks</cell><cell>[81]-[83]</cell></row><row><cell></cell><cell></cell><cell></cell><cell>networks</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>? Fast training time</cell><cell></cell><cell></cell></row><row><cell>Neon</cell><cell>Python</cell><cell>Python</cell><cell>? Easy platform switching ? Supports modern</cell><cell>? Not supporting CPU multi-threading</cell><cell>[84]</cell></row><row><cell></cell><cell></cell><cell></cell><cell>architectures like GAN</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>? Supports modern</cell><cell></cell><cell></cell></row><row><cell>Chainer [85]</cell><cell>Python</cell><cell>Python</cell><cell>architectures ? Easier to implement complex architectures</cell><cell>? Slower forward computation in some scenarios</cell><cell>[86]</cell></row><row><cell></cell><cell></cell><cell></cell><cell>? Dynamic change of model</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>? Distributed training</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>? Imports models from</cell><cell></cell><cell></cell></row><row><cell cols="2">Deeplearning4j Java</cell><cell>Python, Scala, Clojure</cell><cell>major frameworks (e.g., TensorFlow, Caffe,</cell><cell>? Longer training time compared to other tools</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Torch and Theano)</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>? Visualization tools</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III TYPICAL</head><label>III</label><figDesc>IOT-BASED SERVICES IN SMART CITY</figDesc><table><row><cell>Service</cell><cell>Reference</cell><cell>Input data</cell><cell>DL model</cell></row><row><cell>Crowd density/</cell><cell>[116]</cell><cell>GPS/ transition mode</cell><cell>LSTM</cell></row><row><cell>transportation prediction</cell><cell>[117]</cell><cell>Telecommunication data/CDR</cell><cell>RNN</cell></row><row><cell>Waste management</cell><cell>[81]</cell><cell>Garbage images</cell><cell>CNN</cell></row><row><cell>Parking lot management</cell><cell>[119], [120]</cell><cell>Images of parking spaces</cell><cell>CNN</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE IV USAGE</head><label>IV</label><figDesc>OF FOUNDATIONAL SERVICES IN IOT DOMAINS.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">IoT Foundational Services</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Image Recognition</cell><cell>Voice Recognition</cell><cell>Physiological &amp; Psychological Detection</cell><cell>Localization</cell><cell>Security &amp; Privacy</cell></row><row><cell></cell><cell>Smart Home</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Smart City</cell><cell>[81], [119], [120]</cell><cell></cell><cell></cell><cell>[116], [117]</cell></row><row><cell></cell><cell>Energy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>[107]</cell></row><row><cell>Domains</cell><cell>ITS Healthcare Agriculture</cell><cell>[125], [126] [82], [128], [129], [131] [83], [135]-[139]</cell><cell>[130]</cell><cell>[132]</cell><cell></cell><cell>[108]</cell></row><row><cell>IoT</cell><cell>Education Industry</cell><cell>[145] [78], [147]</cell><cell></cell><cell>[77]</cell><cell>[54]</cell></row><row><cell></cell><cell>Government</cell><cell>[84], [150], [152]</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Sport</cell><cell>[154]-[156]</cell><cell></cell><cell>[157], [158]</cell><cell>[97]</cell></row><row><cell></cell><cell>Retail</cell><cell>[159]-[162]</cell><cell></cell><cell>[99]</cell><cell>[163]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE V THE</head><label>V</label><figDesc>COMMON USE OF DIFFERENT DNN MODELS IN IOT DOMAINS.</figDesc><table><row><cell>Domain</cell><cell>AE</cell><cell>CNN</cell><cell>Usage of DNNs DBN</cell><cell>LSTM</cell><cell>RBM</cell><cell>RNN</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VI DNN</head><label>VI</label><figDesc>SIZES AND COMPLEXITIES IN DIFFERENT APPLICATIONS. (NA: NOT AVAILABLE, C: CONVOLUTIONAL LAYER, F: FULLY CONNECTED LAYER, FF: FEEDFORWARD LAYER, SG: SUMMATION (COLLAPSE) LAYER, P: POOLING LAYER, LRN: LOCAL RESPONSE NORMALIZATION LAYER, SM: SOFTMAX LAYER, L: LSTM LAYER, R: RNN LAYER, RBM: RBM HIDDEN LAYER) with an n bit index from a shared table that has 2 n possible values. The steps to prune the network as describe by Han et al. in [184] consist of:</figDesc><table><row><cell cols="2">Work Application</cell><cell>Type of DNN</cell><cell>Depth</cell><cell>Layers Sizes</cell><cell>Training Time</cell><cell>Test Time</cell></row><row><cell>[79]</cell><cell>Transportation analysis</cell><cell>RNN+RBM</cell><cell>2</cell><cell>R(100)-RBM(150)</cell><cell>NA</cell><cell>354 (s), whole test set</cell></row><row><cell>[92]</cell><cell>Localization</cell><cell>RBM DBN</cell><cell>4 4</cell><cell>500-300-150-50 300-150-100-50</cell><cell>NA</cell><cell>NA</cell></row><row><cell></cell><cell></cell><cell>SdA</cell><cell>4</cell><cell>26-200-200-71</cell><cell>451 (s)</cell><cell></cell></row><row><cell>[93]</cell><cell>Localization</cell><cell>DBN ML-ELM</cell><cell>3 5</cell><cell>26-300-71 26-300-300-1500-71</cell><cell>110 (s) 14 (s)</cell><cell>NA</cell></row><row><cell></cell><cell></cell><cell>SDELM</cell><cell>5</cell><cell>26-300-300-1500-71</cell><cell>24 (s)</cell><cell></cell></row><row><cell>[94]</cell><cell>Localization</cell><cell>SdA</cell><cell>5</cell><cell>163-200-200-200-91</cell><cell>NA</cell><cell>0.25 (s)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>C(55?55?96)-LRN-P-</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>C(27?27?256)-LRN-P-</cell><cell></cell><cell></cell></row><row><cell>[98]</cell><cell>Pose detection</cell><cell>CNN</cell><cell>12</cell><cell>C(13?13?384)-C(13?13?384)-</cell><cell>NA</cell><cell>0.1 (s)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>C(13?13?256)-P-</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>F(4096)-F(4096)-SM</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>C(384)-C(20544)-C(20544)-</cell><cell></cell><cell></cell></row><row><cell>[100]</cell><cell>Human activity detection</cell><cell>CNN+LSTM</cell><cell>7</cell><cell>C(20544)-L(942592)-</cell><cell>340 (min)</cell><cell>7 (s), whole test set</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>L(33280)-SM</cell><cell></cell><cell></cell></row><row><cell>[101]</cell><cell>Human activity detection</cell><cell>LSTM</cell><cell>5</cell><cell>L(4)-FF(6)-L(10)-SG-SM</cell><cell>NA</cell><cell>2.7 (ms)</cell></row><row><cell>[107]</cell><cell>FDI detection</cell><cell>DBN</cell><cell>4</cell><cell>50-50-50-50</cell><cell>NA</cell><cell>1.01 (ms)</cell></row><row><cell>[109]</cell><cell>Malware detection</cell><cell>DBN</cell><cell>3</cell><cell>150-150-150</cell><cell>NA</cell><cell>NA</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>C(64?11?11)-C(256?5?5)-</cell><cell></cell><cell></cell></row><row><cell>[120]</cell><cell>Parking space</cell><cell>CNN</cell><cell>8</cell><cell>C(256?3?3)-C(256?3?3)-</cell><cell>NA</cell><cell>0.22 (s)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>C(256?3?3)-F(4096)-F(2)-SM</cell><cell></cell><cell></cell></row><row><cell>[126]</cell><cell>Traffic sign detection</cell><cell>CNN</cell><cell>6</cell><cell>C(36?36?20)-P-C(14?14?50)-P-FC(250)-SM</cell><cell>NA</cell><cell>29.6 (ms) on GPU 4264 (ms) on CPU</cell></row><row><cell>[128]</cell><cell>food recognition</cell><cell>CNN</cell><cell>22</cell><cell>Used GoogLeNet [75]</cell><cell>NA</cell><cell>50 (s)</cell></row><row><cell>[135]</cell><cell>Crop recognition</cell><cell>CNN</cell><cell>6</cell><cell>C(96?7?7)-P-C(96?4?4)-P-F(96)-F(96)</cell><cell>12 (h)</cell><cell>NA</cell></row><row><cell>[145]</cell><cell>Classroom Occupancy</cell><cell>CNN</cell><cell>5</cell><cell>C(6?28?28)-P-C(16?10?10)-P-F(120)</cell><cell>2.5 (h)</cell><cell>2 (s) (4 thread)</cell></row><row><cell>[146]</cell><cell>Fault diagnosis</cell><cell>AE</cell><cell>4</cell><cell>300-300-300-300</cell><cell>NA</cell><cell>91 (s)</cell></row><row><cell>[152]</cell><cell>Road damage detection</cell><cell>CNN</cell><cell>8</cell><cell>Used AlexNet [37]</cell><cell>NA</cell><cell>1.08 (s)</cell></row><row><cell>[155]</cell><cell>Classifying offensive plays</cell><cell>RNN</cell><cell>3</cell><cell>10-10-11</cell><cell>NA</cell><cell>10 (ms)</cell></row><row><cell cols="5">network. The method presented in [184] also works based on</cell><cell></cell><cell></cell></row><row><cell cols="5">pruning redundant and unnecessary connections and neurons</cell><cell></cell><cell></cell></row><row><cell cols="5">as well as using weight sharing mechanisms. Weight sharing</cell><cell></cell><cell></cell></row><row><cell cols="2">replaces each weight</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>1553-877X (c) 2018 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2018.2844341, IEEE Communications Surveys &amp; Tutorials IEEE COMMUNICATIONS SURVEYS &amp; TUTORIALS , VOL. X, NO. X, XXXXX 201X 27</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE VII METHODS</head><label>VII</label><figDesc>AND TECHNOLOGIES TO BRING DL ON IOT DEVICES</figDesc><table><row><cell>Method / Technology</cell><cell>Reference</cell><cell>Pros</cell><cell></cell><cell>Cons</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">? Not general for all DL models</cell></row><row><cell>Network Compression</cell><cell>[184] [186] [187]</cell><cell>? Reduce storage and computation</cell><cell cols="2">? Need specific hardware ? The pruning process bring</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">overload to training</cell></row><row><cell cols="2">Approximate Computing [188], [189]</cell><cell>? Makes fast DL models ? Save energy</cell><cell cols="2">? Not suitable for precise systems</cell></row><row><cell>Accelerators</cell><cell>[91] [185] [190] [191] [192] [193]</cell><cell>? Integrates DL model with the hardware ? Efficient computations</cell><cell>?</cell><cell>Does not work with the traditional hardware platforms</cell></row><row><cell>Tinymote with DL</cell><cell>[194]</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE VIII SOME</head><label>VIII</label><figDesc>PRODUCTS THAT USED DEEP LEARNING AND SERVING IOT DOMAINS ON THE FOG OR CLOUD.</figDesc><table><row><cell>Product</cell><cell>Description</cell><cell>Application</cell><cell>Platform</cell></row><row><cell></cell><cell>Intelligent</cell><cell></cell><cell></cell></row><row><cell>Amazon Alexa</cell><cell>personal</cell><cell>Smart home</cell><cell>Fog</cell></row><row><cell></cell><cell>assistant (IPA)</cell><cell></cell><cell></cell></row><row><cell>Microsoft Cortana</cell><cell>IPA</cell><cell>Smart Car, XBox</cell><cell>Fog</cell></row><row><cell>Google Assistant</cell><cell>IPA</cell><cell>Smart Car, Smart home</cell><cell>Fog</cell></row><row><cell>IBM Watson</cell><cell>Cognitive framework</cell><cell>IoT domains</cell><cell>Cloud</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE IX -</head><label>IX</label><figDesc>Continued from previous page.</figDesc><table><row><cell>Dataset Name</cell><cell>Domain</cell><cell>Provider</cell><cell>Notes</cell><cell>Address/Link</cell></row><row><cell>Taxi Service Trajectory</cell><cell>Transportation</cell><cell>Prediction Challenge, ECML PKDD 2015</cell><cell>Trajectories performed by all the 442 taxis running in the city of Porto, in Portugal.</cell><cell>http://www.geolink.pt/ ecmlpkdd2015-challenge/ dataset.html</cell></row><row><cell>GeoLife GPS Trajectories</cell><cell>Transportation</cell><cell>Microsoft</cell><cell>A GPS trajectory by a sequence of time-stamped points</cell><cell>https://www.microsoft.com /en-us/download/details.aspx? id=52367</cell></row><row><cell>T-Drive trajectory data</cell><cell>Transportation</cell><cell>Microsoft</cell><cell>Contains a one-week trajectories of 10,357 taxis</cell><cell>https://www.microsoft.com/ en-us/research/publication/ t-drive-trajectory-data-sample/</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Bus traces from the</cell><cell></cell></row><row><cell>Chicago Bus Traces data</cell><cell>Transportation</cell><cell>M. Doering</cell><cell>Chicago Transport Authority for 18 days with a rate</cell><cell>http://www.ibr.cs.tu-bs.de/ users/mdoering/bustraces/</cell></row><row><cell></cell><cell></cell><cell></cell><cell>between 20 and 40 seconds.</cell><cell></cell></row><row><cell>Uber trip data</cell><cell>Transportation</cell><cell>FiveThirty-Eight</cell><cell>About 20 million Uber pickups in New York City during 12 months.</cell><cell>https://github.com/fivethirtyeight/ uber-tlc-foil-response</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Three datasets: Korean</cell><cell></cell></row><row><cell>Traffic Sign Recognition</cell><cell>Transportation</cell><cell>K. Lim</cell><cell>daytime, Korean nighttime, and German daytime traffic signs based on</cell><cell>https://figshare.com/articles /Traffic Sign Recognition Testsets/4597795</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Vienna traffic rules.</cell><cell></cell></row><row><cell>DDD17</cell><cell>Transportation</cell><cell>J. Binas</cell><cell>End-To-End DAVIS Driving Dataset.</cell><cell>http://sensors.ini.uzh.ch/ databases.html</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>IEEE COMMUNICATIONS SURVEYS &amp; TUTORIALS , VOL. X, NO. X, XXXXX 201X</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://keras.io/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>http://neon.nervanasys.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>Basketball energy image is the spatial-temporal tracks of basketballs in the hotspot area. Hotspot area includes basketball backboard, hoop, and basket.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>http://go.stats.com/sportvu</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>https://aws.amazon.com/amazon-ai/amis/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6"><p>https://cloud.google.com/products/machine-learning/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7"><p>https://www.ibm.com/watson/</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Internet of Things: A survey on enabling technologies, protocols, and applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Al-Fuqaha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guizani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mohammadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aledhari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ayyash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2347" to="2376" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Disruptive technologies: Advances that will transform life, business, and the global economy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Manyika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bughin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dobbs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bisson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marrs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>McKinsey Global Institute</publisher>
			<biblScope unit="volume">180</biblScope>
			<pubPlace>San Francisco, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">What can machine learning do? workforce implications</title>
		<author>
			<persName><forename type="first">E</forename><surname>Brynjolfsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">358</biblScope>
			<biblScope unit="issue">6370</biblScope>
			<biblScope unit="page" from="1530" to="1534" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Gartner&apos;s top 10 strategic technology trends for 2017</title>
		<author>
			<persName><forename type="first">K</forename><surname>Panetta</surname></persName>
		</author>
		<ptr target="http://www.gartner.com/smarterwithgartner/gartners-top-10-technology-trends-2017/" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Enabling Cognitive Smart Cities Using Big Data and Machine Learning: Approaches and Challenges</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mohammadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Al-Fuqaha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Magazine</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="94" to="101" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">C</forename><surname>Leung</surname></persName>
		</author>
		<title level="m">Big data: related technologies, challenges and future prospects</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Big data deep learning: challenges and perspectives</title>
		<author>
			<persName><forename type="first">X.-W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="514" to="525" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fast and interactive analytics over hadoop data with spark</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mccauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">USENIX Login</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="45" to="51" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Shark: fast data analysis using coarse-grained distributed memory</title>
		<author>
			<persName><forename type="first">C</forename><surname>Engle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lupher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2012 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="689" to="692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page">436</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Data mining for internet of things: A survey</title>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-F</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-C</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys and Tutorials</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="97" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Context aware computing for the internet of things: A survey</title>
		<author>
			<persName><forename type="first">C</forename><surname>Perera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zaslavsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Christen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Georgakopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="414" to="454" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Machine learning in wireless sensor networks: Algorithms, strategies, and applications</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Alsheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Niyato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1996" to="2018" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">State-of-the-art deep learning: Evolving machine intelligence toward tomorrow&apos;s intelligent network traffic control systems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Fadlullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Akashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mizutani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys Tutorials</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A survey of machine learning for big data processing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP Journal on Advances in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">2016</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">67</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Data fusion and iot for smart ubiquitous environments: A survey</title>
		<author>
			<persName><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mehmood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Katib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Albogami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Albeshri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="9533" to="9554" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Supporting scalable analytics with latency constraints</title>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Diao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shenoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1166" to="1177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Big data for development: a review of promises and challenges</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Development Policy Review</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="135" to="174" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Mining big data: current status, and forecast to the future</title>
		<author>
			<persName><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bifet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM sIGKDD Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Toward scalable systems for big data analytics: A technology tutorial</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="652" to="687" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Addressing big data issues in scientific data infrastructure</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Demchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Grosso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Laat</surname></persName>
		</author>
		<author>
			<persName><surname>Membrey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Collaboration Technologies and Systems (CTS), 2013 International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="48" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Detecting influenza epidemics using search engine query data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ginsberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Mohebbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Brammer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Smolinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Brilliant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">457</biblScope>
			<biblScope unit="issue">7232</biblScope>
			<biblScope unit="page">1012</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Towards a big data analytics framework for iot and smart city applications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Strohbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ziekow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gazis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Akiva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Modeling and processing for next-generation big-data technologies</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="257" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="issue">5786</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Introduction to multilayer feed-forward neural networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Svozil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kvasnicka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pospichal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Chemometrics and intelligent laboratory systems</title>
		<imprint>
			<date type="published" when="1997">1997. 2015</date>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="85" to="117" />
		</imprint>
	</monogr>
	<note>Deep learning in neural networks: An overview</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep sparse rectifier neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the Fourteenth International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="315" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Improving neural networks by preventing coadaptation of feature detectors</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1207.0580</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On the importance of initialization and momentum in deep learning</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1139" to="1147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Learning longer memory in recurrent neural networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.7753v2[cs.NE</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A tutorial of architectures, algorithms, and applications for deep learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">APSIPA Transactions on Signal and Information Processing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Large-scale machine learning with stochastic gradient descent</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COMPSTAT&apos;2010</title>
		<meeting>COMPSTAT&apos;2010</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="177" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning representations by back-propagating errors</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="issue">6088</biblScope>
			<biblScope unit="page">533</biblScope>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Chauvin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<title level="m">Backpropagation: theory, architectures, and applications</title>
		<imprint>
			<publisher>Psychology Press</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Backpropagation through time: what it does and how to do it</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1550" to="1560" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">How to construct deep recurrent neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6026v5[cs.NE]</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Training and analysing deep recurrent neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schrauwen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="190" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Empirical evaluation of gated recurrent neural networks on sequence modeling</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.3555v1[cs.NE</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Autoencoders, unsupervised learning, and deep architectures</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML unsupervised and transfer learning</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Tutorial on variational autoencoders</title>
		<author>
			<persName><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.05908v2</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>stat.ML</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Semisupervised learning with deep generative models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3581" to="3589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Towards Diverse and Natural Image Descriptions via a Conditional GAN</title>
		<author>
			<persName><forename type="first">B</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2970" to="2979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">How an A.I. &apos;Cat-and-Mouse Game&apos; Generates Believable Fake Photos</title>
		<author>
			<persName><forename type="first">C</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Collins</surname></persName>
		</author>
		<ptr target="https://www.nytimes.com/interactive/2018/01/02/technology/ai-generated-photos.html" />
		<imprint>
			<date type="published" when="2018-02-09">2018-02-09</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning deep architectures for AI</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations and trends R in Machine Learning</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">From neural pca to deep unsupervised learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Independent Component Analysis and Learning Machines</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="143" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Semi-supervised learning with ladder networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rasmus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Berglund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Honkala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3546" to="3554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">The MNIST Database of handwritten digits</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist/" />
		<imprint>
			<date type="published" when="2018-02-01">2018-02-01</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Learning Multiple Layers of Features from Tiny Images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A fast and accurate online sequential learning algorithm for feedforward networks</title>
		<author>
			<persName><forename type="first">N.-Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Saratchandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sundararajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on neural networks</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1411" to="1423" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">RFID-enabled indoor positioning method for a real-time manufacturing execution system using OS-ELM</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">174</biblScope>
			<biblScope unit="page" from="121" to="133" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">An online sequential extreme learning machine approach to wifi based indoor positioning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Internet of Things (WF-IoT)</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="111" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Faster R-CNN: Towards realtime object detection with region proposal networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1137" to="1149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Fast R-CNN</title>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Towards realtime object detection on embedded systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Emerging Topics in Computing</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">You only look once: Unified, real-time object detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="779" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Playing atari with deep reinforcement learning</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.5602v1[cs.LG]</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Semisupervised deep reinforcement learning in support of IoT and smart city services</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mohammadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Al-Fuqaha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guizani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-S</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Deep learning of representations for unsupervised and transfer learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Unsupervised and Transfer Learning</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="17" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Introducing sharedhidden-layer autoencoders for transfer learning and their application in acoustic emotion recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schuller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="4818" to="4822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Online multimodal deep similarity learning with application to image retrieval</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Miao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st ACM international conference on Multimedia</title>
		<meeting>the 21st ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="153" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Online algorithms for sum-product networks with continuous variables</title>
		<author>
			<persName><forename type="first">P</forename><surname>Jaini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rashwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Banijamali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Poupart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Conference on Probabilistic Graphical Models</title>
		<meeting>the Eighth International Conference on Probabilistic Graphical Models</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="228" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Sequential labeling with online deep learning: Exploring model initialization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Srihari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint European Conference on Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="772" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Comparative study of deep learning software frameworks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bahrampour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06435v3[cs.LG</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Deep learning with h2o</title>
		<author>
			<persName><forename type="first">A</forename><surname>Candel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ledell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Arora</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Tensorflow: Large-scale machine learning on heterogeneous distributed systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04467v2[cs.DC</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Torch7: A matlab-like environment for machine learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Farabet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BigLearn, NIPS Workshop, no. EPFL-CONF-192376</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Bastien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bergeron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bouchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1211.5590v1[cs.SC</idno>
		<title level="m">Theano: new features and speed improvements</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Raschka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mirjalili</surname></persName>
		</author>
		<title level="m">Python Machine Learning</title>
		<meeting><address><addrLine>Birmingham, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Packt Publishing</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM international conference on Multimedia</title>
		<meeting>the 22nd ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="675" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Deep Face Recognition</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">M</forename><surname>Parkhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Going Deeper With Convolutions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-H. Rick</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Benchmarking state-of-theart deep learning software tools</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.07249v7</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>cs.DC</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Utilearn: A personalised ubiquitous teaching and learning system for smart societies</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mehmood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Albogami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Katib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Albeshri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Altowaijri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="2615" to="2635" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Deep learning in the automotive industry: Applications and tools</title>
		<author>
			<persName><forename type="first">A</forename><surname>Luckow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ashcraft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Weill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Djerekarov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vorster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Big Data (Big Data)</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="3759" to="3768" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Large-scale transportation network congestion evolution prediction using deep learning theory</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2015">0119044. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">An early resource characterization of deep learning on wearables, smartphones and internet-of-things devices</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Georgiev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Forlivesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Kawsar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 International Workshop on Internet of Things towards Applications</title>
		<meeting>the 2015 International Workshop on Internet of Things towards Applications</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="7" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Spotgarbage: smartphone app to detect garbage using deep learning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Yagnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing</title>
		<meeting>the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="940" to="945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">A new deep learning-based food recognition system for dietary assessment on an edge computing service infrastructure</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vokkarane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Services Computing</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Deep neural networks based recognition of plant diseases by leaf image classification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sladojevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Arsenovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anderla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Culibrk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stefanovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">2016</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Application of deep convolutional neural networks for detecting extreme weather in climate datasets</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Racah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Correa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khosrowshahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lavers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kunkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wehner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int&apos;l Conf. on Advances in Big Data Analytics</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Chainer: a next-generation open source framework for deep learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tokui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Oono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clayton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of workshop on machine learning systems (LearningSys) in the twenty-ninth annual conference on neural information processing systems (NIPS)</title>
		<meeting>workshop on machine learning systems (LearningSys) in the twenty-ninth annual conference on neural information processing systems (NIPS)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">A deep-learning approach for operation of an automated realtime flare forecast</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hada-Muranushi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Muranushi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Asai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Okanohara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nemoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shibata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SPACE WEATHER</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Ceml: Mixing and moving complex event processing and machine learning to the edge of the network for iot applications</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A C</forename><surname>Soto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jentsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Preuveneers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ilie-Zudor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on the Internet of Things</title>
		<meeting>the 6th International Conference on the Internet of Things</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="103" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Predicting cloud resource utilization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Borkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schulte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hochreiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference on Utility and Cloud Computing</title>
		<meeting>the 9th International Conference on Utility and Cloud Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="37" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">The digital universe in 2020: Big data, bigger digital shadows, and biggest growth in the far east</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gantz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Reinsel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IDC iView: IDC Analyze the future</title>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="volume">2007</biblScope>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">Voice control everywhere: Low-power specialpurpose chip could make speech recognition ubiquitous in electronics</title>
		<author>
			<persName><forename type="first">H</forename><surname>Larry</surname></persName>
		</author>
		<ptr target="http://news.mit.edu/2017/low-power-chip-speech-recognition-electronics-0213" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">A scalable speech recognizer with deep-neural-network acoustic models and voice-activated power gating</title>
		<author>
			<persName><forename type="first">M</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chandrakasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE ISSCC</title>
		<meeting>the IEEE ISSCC</meeting>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Deepfi: Deep learning for indoor fingerprinting using channel state information</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pandey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Wireless Communications and Networking Conference (WCNC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1666" to="1671" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Semi-supervised deep extreme learning machine for wi-fi based localization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">166</biblScope>
			<biblScope unit="page" from="282" to="293" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Deep neural networks for wireless localization in indoor and outdoor environments</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">194</biblScope>
			<biblScope unit="page" from="279" to="287" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Fusion of magnetic and visual sensors for indoor localization: Infrastructure-free and more effective</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zimmermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="874" to="888" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Indoor positioning solely based on user&apos;s sight</title>
		<author>
			<persName><forename type="first">M</forename><surname>Becker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Information Science and Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="76" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Multimodal sensory fusion for soccer robot self-localization based on long short-term memory recurrent neural network</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Ambient Intelligence and Humanized Computing</title>
		<imprint>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Deeppose: Human pose estimation via deep neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1653" to="1660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Joint customer pose and orientation estimation using deep neural network from surveillance camera</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kamijo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multimedia (ISM), 2016 IEEE International Symposium</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="216" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Deep convolutional and lstm recurrent neural networks for multimodal wearable activity recognition</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Ord??ez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Roggen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">115</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Multi-column bi-directional long shortterm memory for mobile devices-based human activity recognition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Deep learning for rfid-based activity recognition</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Marsic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sarcevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Burd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM Conference on Embedded Network Sensor Systems</title>
		<meeting>the 14th ACM Conference on Embedded Network Sensor Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="164" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Beyond temporal pooling: Recurrence and temporal convolutions for gesture recognition in video</title>
		<author>
			<persName><forename type="first">L</forename><surname>Pigou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Herreweghe</surname></persName>
		</author>
		<author>
			<persName><surname>Dambre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Recurrent network models for human dynamics</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fragkiadaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Felsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="4346" to="4354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Emonets: Multimodal deep learning approaches for emotion recognition in video</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Kahou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bouthillier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michalski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Konda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Froumenty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Boulanger-Lewandowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal on Multimodal User Interfaces</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="111" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Learning human identity from motion patterns</title>
		<author>
			<persName><forename type="first">N</forename><surname>Neverova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lacey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fridman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Barbello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1810" to="1820" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Real-time detection of false data injection attacks in smart grid: A deep learning-based intelligent mechanism</title>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Mendis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Smart Grid</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Intrusion detection system using deep neural network for in-vehicle network security</title>
		<author>
			<persName><forename type="first">M.-J</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-W</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">e0155781</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Droid-sec: deep learning in android malware detection</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="371" to="372" />
			<date type="published" when="2014">2014</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Privacy-preserving deep learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shmatikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGSAC conference on computer and communications security</title>
		<meeting>the 22nd ACM SIGSAC conference on computer and communications security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1310" to="1321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Deep learning with differential privacy</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security</title>
		<meeting>the 2016 ACM SIGSAC Conference on Computer and Communications Security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="308" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<monogr>
		<title level="m" type="main">Microsoft and liebherr collaborating on new generation of smart refrigerators</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Hazen</surname></persName>
		</author>
		<ptr target="http://blogs.technet.microsoft.com/machinelearning/2016/09/02/" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Intelligent buildings of the future: Cyberaware, deep learning powered, and human interacting</title>
		<author>
			<persName><forename type="first">M</forename><surname>Manic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Amarasinghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Rodriguez-Andina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rieger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Industrial Electronics Magazine</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="32" to="49" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
		<title level="m" type="main">The internet of things that matter: Integrating smart cities with smart agriculture</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yoshida</surname></persName>
		</author>
		<ptr target="http://www.digitalistmag.com/iot/2016/05/19/internet-of-things-that-matter-integrating-smart-cities-with-smart-agriculture-04221203" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Digitalist Magazine. [Online]. Available</note>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<title level="m" type="main">Toshiba and dell technologies&apos; deep learning testbed for iot is first approved by industrial internet consortium</title>
		<ptr target="https://www.toshiba.co.jp/about/press/201610/pr1702.htm" />
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Toshiba:Press-Release</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Deeptransport: Prediction and simulation of human mobility and transportation mode at a citywide level</title>
		<author>
			<persName><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kanasugi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shibasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Mercury: Metro density prediction with recurrent neural network on streaming cdr data</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">C</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Winslett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Engineering (ICDE)</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="1374" to="1377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Deep learning architecture for air quality predictions</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Environmental Science and Pollution Research</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="22" to="408" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Deep learning for decentralized parking lot occupancy detection</title>
		<author>
			<persName><forename type="first">G</forename><surname>Amato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Carrara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Falchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gennaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Meghini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vairo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Parking-stall vacancy indicator system, based on deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Valipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Siam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Stroulia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jagersand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE 3rd World Forum on Internet of Things</title>
		<imprint>
			<publisher>WF-IoT</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="655" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Big iot data mining for real-time energy disaggregation in buildings</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Mocanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mocanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gibescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liotta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Systems, Man, and Cybernetics</title>
		<meeting>the IEEE International Conference on Systems, Man, and Cybernetics</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="9" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Deep learning for estimating building energy consumption</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mocanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gibescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Kling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sustainable Energy, Grids and Networks</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="91" to="99" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Deep learning for solar power forecasting-an approach using autoencoder and lstm neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gensler</surname></persName>
			<affiliation>
				<orgName type="collaboration">SMC</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Henze</surname></persName>
			<affiliation>
				<orgName type="collaboration">SMC</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sick</surname></persName>
			<affiliation>
				<orgName type="collaboration">SMC</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Raabe</surname></persName>
			<affiliation>
				<orgName type="collaboration">SMC</orgName>
			</affiliation>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2858" to="2865" />
		</imprint>
	</monogr>
	<note>Systems, Man, and Cybernetics</note>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Predicting short-term traffic flow by long short-term memory recurrent neural network</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Smart City/SocialCom/SustainCom (SmartCity), 2015 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="153" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Multi-column deep neural network for traffic sign classification</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cires ?an</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="333" to="338" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Real-time traffic sign recognition based on a general purpose gpu and deep-learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Byun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS one</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2017">0173317. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Deep-learning first: Drive.ai&apos;s path to autonomous driving</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ackerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pagano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Spectrum</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Deepfood: Deep learning-based food image recognition for computer-aided dietary assessment</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vokkarane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Smart Homes and Health Telematics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="37" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Convolutional neural networks applied for parkinson&apos;s disease identification</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Papa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Rosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning for Health Informatics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="377" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Smart health solution integrating IoT and cloud: A case study of voice pathology monitoring</title>
		<author>
			<persName><forename type="first">G</forename><surname>Muhammad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M M</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alelaiwi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alamri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Magazine</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="69" to="73" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Detecting cardiovascular disease from mammograms with deep learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Azamian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Iribarren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Molloi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Deep learning for posture analysis in fall detection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Naqvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Chambers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014 19. 2014</date>
			<biblScope unit="page" from="12" to="17" />
		</imprint>
	</monogr>
	<note>Digital Signal Processing</note>
</biblStruct>

<biblStruct xml:id="b131">
	<monogr>
		<title level="m" type="main">Learning to diagnose with lstm recurrent neural networks</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Elkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wetzell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Deep learning for health informatics</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rav?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Deligianni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Andreu-Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-Z</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE journal of biomedical and health informatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="21" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Deep learning classification of land cover and crop types using remote sensing data</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kussul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lavreniuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Skakun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shelestov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Estimating crop yields with deep learning and remotely sensed data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kuwata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shibasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Geoscience and Remote Sensing Symposium (IGARSS)</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="858" to="861" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">Training deep convolutional neural networks for landcover classification of high-resolution imagery</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>England</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Starms</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Marcum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="549" to="553" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Using deep learning to challenge safety standard for highly autonomous machines in agriculture</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Steen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Karstoft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>J?rgensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Imaging</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">Deepfruits: A fruit detection system using deep neural networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dayoub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Upcroft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mccool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">1222</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Experimenting with electromagnetism using augmented reality: Impact on flow student experience and educational effectiveness</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Ib??ez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?</forename><surname>Di Serio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Villar?n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Kloos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Education</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">A vision for the development of i-campus</title>
		<author>
			<persName><forename type="first">L.-F</forename><surname>Kwok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Smart Learning Environments</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Collaborative deep learning for recommender systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-Y</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1235" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Behaviorbased grade prediction for moocs via time series neural networks</title>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Brinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Joe-Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Signal Processing</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Deep knowledge tracing</title>
		<author>
			<persName><forename type="first">C</forename><surname>Piech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sahami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="505" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Brain-inspired classroom occupancy monitoring on a low-power mobile platform</title>
		<author>
			<persName><forename type="first">F</forename><surname>Conti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pullini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Benini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="610" to="615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">An enhancement deep feature fusion method for rotating machinery fault diagnosis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="200" to="220" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Framework and development of fault detection classification using iot device and cloud environment</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Manufacturing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">A deep learning model for robust wafer fault monitoring with sensor measurement noise</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">O</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Semiconductor Manufacturing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="31" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">On accurate and reliable anomaly detection for gas turbine combustors: A deep learning approach</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Conference of the</title>
		<meeting>the Annual Conference of the</meeting>
		<imprint>
			<publisher>Prognostics and Health Management Society</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Geological disaster recognition on optical remote sensing images using deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Computer Science</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="566" to="575" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Earthquake prediction based on spatio-temporal data mining: An lstm network approach</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Emerging Topics in Computing</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">Lightweight road manager: smartphone-based automatic determination of road damage status by deep neural network</title>
		<author>
			<persName><forename type="first">H</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sekimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Seto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th ACM SIGSPATIAL International Workshop on Mobile Geographic Information Systems</title>
		<meeting>the 5th ACM SIGSPATIAL International Workshop on Mobile Geographic Information Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="37" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<monogr>
		<title level="m" type="main">Forbes -Changing the game: The rise of sports analytics</title>
		<author>
			<persName><forename type="first">L</forename><surname>Steinberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main">Deep learning based intelligent basketball arena with energy image</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Multimedia Modeling</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="601" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Classifying NBA offensive plays using neural networks</title>
		<author>
			<persName><forename type="first">K.-C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MIT SLOAN Sports Analytics Conf</title>
		<meeting>MIT SLOAN Sports Analytics Conf</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">Applying deep learning to basketball trajectories</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Romijnders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM KDD&apos;16</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Activity recognition in beach volleyball using a deep convolutional neural network</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Groh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hannink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Strubberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Eskofier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">A hierarchical deep temporal model for group activity recognition</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Ibrahim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Muralidharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1971" to="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">Learning visual similarity for product design with convolutional neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">98</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main">Exact clothing retrieval approach based on deep neural network</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yichao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Technology, Networking, Electronic and Automation Control Conference</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="396" to="400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">Where to buy it: Matching street clothing photos in online shops</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hadi Kiapour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3343" to="3351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">A multitask grocery assist system for the visually impaired: Smart glasses, gloves, and shopping carts provide auditory and tactile feedback</title>
		<author>
			<persName><forename type="first">S</forename><surname>Advani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zientara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shukla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Okafor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Irick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Consumer Electronics Magazine</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="73" to="81" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">A multistream bi-directional recurrent neural network for fine-grained action detection</title>
		<author>
			<persName><forename type="first">B</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Marks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1961" to="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">Anomaly detection of spectrum in wireless communication via deep auto-encoders</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Supercomputing</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3161" to="3178" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">Conditional variational autoencoder for prediction and feature recovery applied to intrusion detection in iot</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lopez-Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Carro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sanchez-Esguevillas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lloret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">1967</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">A deep learning approach to network intrusion detection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Shone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Ngoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">D</forename><surname>Phai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Forest (RF)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">Random access for machineto-machine communication in lte-advanced networks: issues and approaches</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Niyato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE communications Magazine</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="86" to="93" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main">A load balancing scheme based on deeplearning in iot</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cluster Computing</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="873" to="878" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<monogr>
		<title level="m" type="main">Wireless interference identification with convolutional neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Block</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.00737v1[cs.LG</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b168">
	<analytic>
		<title level="a" type="main">Neural networks in wireless networks: Techniques, applications and guidelines</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ahad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qadir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ahsan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Network and Computer Applications</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main">Intelligent 5g: When cellular networks meet artificial intelligence</title>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Wireless Communications</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="175" to="183" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<analytic>
		<title level="a" type="main">Zipweave: Towards efficient and reliable measurement based mobile coverage maps</title>
		<author>
			<persName><forename type="first">M.-R</forename><surname>Fida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lutu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Marina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?</forename><surname>Alay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INFOCOM 2017-IEEE Conference on Computer Communications</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b171">
	<monogr>
		<title level="m" type="main">Global Cell Coverage Maps</title>
		<author>
			<persName><surname>Opensignal</surname></persName>
		</author>
		<ptr target="http://opensignal.com/networks" />
		<imprint>
			<date type="published" when="2018-02-06">2018-02-06</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b172">
	<monogr>
		<title level="m" type="main">An analysis of deep neural network models for practical applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Canziani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Culurciello</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07678v4[cs.CV</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2016</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Leibe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Matas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Sebe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="630" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<monogr>
		<title level="m" type="main">Interpretable vs Powerful Predictive Models: Why We Need Them Both</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bourguignat</surname></persName>
		</author>
		<ptr target="https://medium.com/@chrisbour/interpretable-vs-powerful-predictive-models-why-we-need-them-both-990340074979" />
		<imprint>
			<date type="published" when="2014">2014. 2018-02-15</date>
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b175">
	<monogr>
		<title level="m" type="main">Deep learning with Python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Chollet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Manning Publications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main">Are deep neural networks the best choice for modeling source code</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Hellendoorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Devanbu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering</title>
		<meeting>the 2017 11th Joint Meeting on Foundations of Software Engineering</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="763" to="773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b177">
	<monogr>
		<title level="m" type="main">Return of the devil in the details: Delving deep into convolutional nets</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chatfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1405.3531v4[cs.CV</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b178">
	<analytic>
		<title level="a" type="main">Do deep nets really need to be deep?</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2654" to="2662" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b179">
	<analytic>
		<title level="a" type="main">Applying neural networks in optical communication systems: Possible pitfalls</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Eriksson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>B?low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Leven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Photonics Technology Letters</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="2091" to="2094" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b180">
	<analytic>
		<title level="a" type="main">Predicting parameters in deep learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shakibi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2148" to="2156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b181">
	<analytic>
		<title level="a" type="main">Optimal Brain Damage</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Solla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Jackel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPs</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="598" to="605" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b182">
	<analytic>
		<title level="a" type="main">Learning both weights and connections for efficient neural network</title>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1135" to="1143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b183">
	<monogr>
		<title level="m" type="main">Eie: efficient inference engine on compressed deep neural network</title>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pedram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.01528v2[cs.CV</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b184">
	<analytic>
		<title level="a" type="main">Compressing neural networks with the hashing trick</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tyree</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>W&amp;CP</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">37</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b185">
	<monogr>
		<title level="m" type="main">Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1</title>
		<author>
			<persName><forename type="first">M</forename><surname>Courbariaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.02830v3[cs.LG</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b186">
	<analytic>
		<title level="a" type="main">AxNN: energy-efficient neuromorphic systems using approximate computing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Venkataramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raghunathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 international symposium on Low power electronics and design</title>
		<meeting>the 2014 international symposium on Low power electronics and design</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="27" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b187">
	<analytic>
		<title level="a" type="main">Energyefficient convnets through approximate computing</title>
		<author>
			<persName><forename type="first">B</forename><surname>Moons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>De Brabandere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Verhelst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Applications of Computer Vision (WACV)</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b188">
	<analytic>
		<title level="a" type="main">Spindle: Spintronic deep learning engine for largescale neuromorphic computing</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Ramasubramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Venkatesan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sharad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raghunathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 international symposium on Low power electronics and design</title>
		<meeting>the 2014 international symposium on Low power electronics and design</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="15" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b189">
	<analytic>
		<title level="a" type="main">Eyeriss: An energyefficient reconfigurable accelerator for deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">Y.-H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Emer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Solid-State Circuits</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="127" to="138" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b190">
	<analytic>
		<title level="a" type="main">Diannao: A small-footprint high-throughput accelerator for ubiquitous machine-learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Temam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Sigplan Notices</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="269" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b191">
	<analytic>
		<title level="a" type="main">Deepx: A software accelerator for lowpower deep learning inference on mobile devices</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Georgiev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Forlivesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qendro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Kawsar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Processing in Sensor Networks (IPSN), 2016 15th ACM/IEEE International Conference</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b192">
	<analytic>
		<title level="a" type="main">14.7 a 288?w programmable deep-learning processor with 270kb on-chip weight storage using nonuniform memory hierarchy for mobile intelligence</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dreslinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Solid-State Circuits Conference (ISSCC)</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="250" to="251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b193">
	<monogr>
		<title level="m" type="main">The Street View House Numbers (SVHN) Dataset</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<ptr target="http://ufldl.stanford.edu/housenumbers/" />
		<imprint>
			<date type="published" when="2018-02-09">2018-02-09</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b194">
	<monogr>
		<title level="m" type="main">ApproxDBN: Approximate Computing for Discriminative Deep Belief Networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kreutz-Delgado</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.03993v3[cs.NE</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b195">
	<analytic>
		<title level="a" type="main">Efficient embedded learning for iot devices</title>
		<author>
			<persName><forename type="first">S</forename><surname>Venkataramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raghunathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 21st Asia and South Pacific Design Automation Conference (ASP-DAC</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="308" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b196">
	<analytic>
		<title level="a" type="main">Challenges for semiconductor spintronics</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Awschalom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Flatt?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Physics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="153" to="159" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b197">
	<analytic>
		<title level="a" type="main">Speck-size computers: Now with deep learning [news]</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bourzac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Spectrum</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="13" to="15" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b198">
	<analytic>
		<title level="a" type="main">A 0.3-2.6 tops/w precision-scalable processor for real-time large-scale convnets</title>
		<author>
			<persName><forename type="first">B</forename><surname>Moons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Verhelst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLSI Circuits (VLSI-Circuits), 2016 IEEE Symposium</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="2" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b199">
	<monogr>
		<title level="m" type="main">Mobilenets: Efficient convolutional neural networks for mobile vision applications</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Andreetto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04861v1[cs.CV</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b200">
	<analytic>
		<title level="a" type="main">A deep learning approach to on-node sensor data analytics for mobile or wearable devices</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-Z</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Biomedical and Health Informatics</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b201">
	<analytic>
		<title level="a" type="main">Cognitive computation and communication: A complement solution to cloud for iot</title>
		<author>
			<persName><forename type="first">N</forename><surname>Nguyen-Thanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jabbour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Murmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Technologies for Communications (ATC), 2016 International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="222" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b202">
	<analytic>
		<title level="a" type="main">Incorporating intelligence in fog computing for big data analysis in smart cities</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hefferman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b203">
	<analytic>
		<title level="a" type="main">Toward better horizontal integration among iot services</title>
		<author>
			<persName><forename type="first">A</forename><surname>Al-Fuqaha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khreishah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guizani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rayes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mohammadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Magazine</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="72" to="79" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b204">
	<analytic>
		<title level="a" type="main">Deep learning with cots hpc systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Huval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Catanzaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Machine Learning</title>
		<meeting>the 30th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>JMLR: W &amp; CP</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b205">
	<analytic>
		<title level="a" type="main">Project adam: Building an efficient and scalable deep learning training system</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Chilimbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Suzue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Apacible</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kalyanaraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th USENIX Symposium on Operating Systems Design and Implementation</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="571" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b206">
	<analytic>
		<title level="a" type="main">In-datacenter performance analysis of a tensor processing unit</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bajwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Boden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Borchers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">44th International Symposium on Computer Architecture (ISCA)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b207">
	<monogr>
		<title level="m" type="main">Lessons learned from deploying deep learning at scale,&quot; O&apos;Reilly Artificial Intelligence conference</title>
		<author>
			<persName><forename type="first">K</forename><surname>Daniel</surname></persName>
		</author>
		<ptr target="http://conferences.oreilly.com/artificial-intelligence/ai-ny-2016/public/schedule/detail/54098" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b208">
	<monogr>
		<title level="m" type="main">GPU Platforms Set to Lengthen Deep Learning Reach</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hemsoth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>The Next Platform</note>
</biblStruct>

<biblStruct xml:id="b209">
	<analytic>
		<title level="a" type="main">Big data analytics platforms for real-time applications in iot</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Simmhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Perera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Big Data Analytics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="115" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b210">
	<analytic>
		<title level="a" type="main">Fog networking for machine health prognosis: A deep learning perspective</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Qaisar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Usman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computational Science and Its Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="212" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b211">
	<analytic>
		<title level="a" type="main">Deepcham: Collaborative edge-mediated adaptive deep learning for mobile object recognition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salonidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Chuah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM Symposium</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="64" to="76" />
		</imprint>
	</monogr>
	<note>in Edge Computing (SEC</note>
</biblStruct>

<biblStruct xml:id="b212">
	<analytic>
		<title level="a" type="main">List of datasets for machine learning research</title>
		<author>
			<persName><surname>Wikipedia</surname></persName>
		</author>
		<ptr target="https://en.wikipedia.org/wiki/" />
	</analytic>
	<monogr>
		<title level="m">List of datasets for machine learning research</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b213">
	<analytic>
		<title level="a" type="main">The limitations of deep learning in adversarial settings</title>
		<author>
			<persName><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fredrikson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">B</forename><surname>Celik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Security and Privacy (EuroS&amp;P), 2016 IEEE European Symposium</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="372" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b214">
	<analytic>
		<title level="a" type="main">Deep learning applications and challenges in big data analytics</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Najafabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Villanustre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Khoshgoftaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Seliya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Muharemagic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Big Data</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b215">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Lavalle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lesser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shockley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kruschwitz</surname></persName>
		</author>
		<title level="m">Big data, analytics and the path from insights to MIT sloan management review</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b216">
	<analytic>
		<title level="a" type="main">Deep neural networks are easily fooled: High confidence predictions for unrecognizable images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="427" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b217">
	<analytic>
		<title level="a" type="main">Ensemble deep learning for regression and time series forecasting</title>
		<author>
			<persName><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Amaratunga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Intelligence in Ensemble Learning (CIEL), 2014 IEEE Symposium</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b218">
	<analytic>
		<title level="a" type="main">Mobile big data analytics using deep learning and apache spark</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Alsheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Niyato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="22" to="29" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b219">
	<analytic>
		<title level="a" type="main">Online auction of cloud resources in support of the internet of things</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gharaibeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khreishah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mohammadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Al-Fuqaha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Khalil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b220">
	<monogr>
		<title level="m" type="main">Cyber-Physical Systems (CPS) -Program Solicitation (NSF 17-529)</title>
		<ptr target="https://www.nsf.gov/pubs/2017/nsf17529/nsf17529.pdf" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
		<respStmt>
			<orgName>National Science Foundation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b221">
	<analytic>
		<title level="a" type="main">A survey of machine learning techniques applied to self organizing cellular networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Valente Klaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Imran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Onireti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Souza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys and Tutorials</title>
		<imprint>
			<biblScope unit="page">2017</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b222">
	<analytic>
		<title level="a" type="main">Real-time, cloud-based object detection for unmanned aerial vehicles</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>?abanovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotic Computing (IRC), IEEE International Conference</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="36" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b223">
	<analytic>
		<title level="a" type="main">A deep-network solution towards model-less obstacle avoidance</title>
		<author>
			<persName><forename type="first">L</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b224">
	<analytic>
		<title level="a" type="main">Applying deep learning in augmented reality tracking</title>
		<author>
			<persName><forename type="first">O</forename><surname>Akgul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">I</forename><surname>Penekli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Genc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Signal-Image Technology &amp; Internet-Based Systems (SITIS), 2016 12th International Conference</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="47" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b225">
	<analytic>
		<title level="a" type="main">3d integral imaging based augmented reality with deep learning implemented by faster r-cnn</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Sutanto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pribadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Mobile and Wireless Technology</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="241" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b226">
	<monogr>
		<title level="m" type="main">Deep-learning in mobile robotics-from perception to control systems: A survey on why and why not</title>
		<author>
			<persName><forename type="first">L</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.07139v3[cs.RO</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b227">
	<analytic>
		<title level="a" type="main">Learning semantic place labels from occupancy grids using CNNs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Goeddel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Olson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="3999" to="4004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b228">
	<analytic>
		<title level="a" type="main">His research interests include the use of machine learning in general and deep learning in particular in support of the datadriven and self-driven management of large-scale deployments of IoT and smart city infrastructure and services, Wireless Vehicular Networks (VANETs), cooperation and spectrum access etiquettes in cognitive radio networks, and management and planning of software defined networks (SDN)</title>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Mohammadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">(</forename><surname>S'14</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">His research interests include Internet of Things, IoT data analytics</title>
		<meeting><address><addrLine>Isfahan, Iran; Kalamazoo, MI, USA; Egypt</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2010. 2002 and 2006. 2016</date>
		</imprint>
		<respStmt>
			<orgName>Computer Engineering from Kharazmi University, Tehran, Iran in 2003 and his M.S. degree in Computer Engineering (Software) from Sheikhbahaee University ; Computer Science from Western Michigan University (WMU) ; University of Missouri-Columbia and Ph.D. from the University of Missouri-Kansas City. Currently ; NEST Research Lab at the Computer Science Department of Western Michigan University ; Electrical and Computer Engineering from University of Toronto, Canada. After two postdoctoral fellowships at University of Toronto and King Abduallah University of Science and Technology (KAUST), he joined King Fahd University of Petroleum and Minerals</orgName>
		</respStmt>
	</monogr>
	<note>His research interests lie in the broad area of advanced communications/networking/computing/learning technologies for smart cities applications, including cyber physical systems. internet of things (IoT) and IoT-enabled systems, cloud and fog networking, network coding, device-todevice networking, autonomous driving and autonomous systems. intelligent transportation systems, and mathematical modelling and optimization for smart systems</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
