<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DVFaaS: Leveraging DVFS for FaaS Workflows</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Achilleas</forename><surname>Tzenetopoulos</surname></persName>
							<idno type="ORCID">0000-0001-6084-4297</idno>
						</author>
						<author>
							<persName><forename type="first">Dimosthenis</forename><surname>Masouros</surname></persName>
							<idno type="ORCID">0000-0001-6147-6908</idno>
						</author>
						<author>
							<persName><forename type="first">Dimitrios</forename><surname>Soudris</surname></persName>
							<idno type="ORCID">0000-0002-6930-6847</idno>
						</author>
						<author>
							<persName><forename type="first">Sotirios</forename><surname>Xydis</surname></persName>
						</author>
						<title level="a" type="main">DVFaaS: Leveraging DVFS for FaaS Workflows</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/LCA.2023.3288089</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Quality of Services</term>
					<term>power management</term>
					<term>distributed systems</term>
					<term>emerging technologies</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this letter, we propose DVFaaS, a per-core DVFS framework that utilizes control systems theory to assign justenough frequency for the purpose of addressing the QoS requirements on serverless workflows comprising unseen functions. DVFaaS exploits the intermittent nature of serverless workflows, which enables staged control on distinguishable functions, which jointly contribute to the end-to-end latency. Our results show that DVFaaS considerably outperforms related work, reducing power consumption by up to 22%, with 2x fewer QoS violations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The advent of serverless computing has brought forth opportunities for automation of resource provisioning, cost optimization, and improvement of code producibility and maintenance. By delegating the management of infrastructure operations to Cloud Service Providers (CSPs), developers can concentrate solely on developing distinct functionalities of their code. In turn, CSPs gain increased control over workload management and have the opportunity to implement sophisticated resource management strategies to maximize hardware utilization and minimize costs.</p><p>Function-as-a-Service (FaaS) is a subset of serverless computing offerings, according to which applications are decomposed into short-lived, stateless functions that exhibit diverse characteristics, with regard to resource usage and execution time. Functions are orchestrated by back-end services (Backend-as-a-Service) <ref type="bibr" target="#b0">[1]</ref>, and collectively form graphs, referred to hereafter as workflows or chains. Serverless environments feature system noise <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, which amplifies uncertainty in performance, and resource utilization. In response to the challenges posed by the FaaS model, recent research projects have started focusing on developing QoS-aware serverless engines. In <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref> authors utilize CPU quotas to regulate the end-to-end serverless chain execution time.</p><p>Meanwhile, there is a significant opportunity for managing intermittent function chains. Unlike previous approaches <ref type="bibr" target="#b6">[7]</ref>, which employ, rather implicitly, fine-grained monitoring to arbitrarily map time-to-application phases, serverless chains provide the possibility of determining them explicitly. The authors are with the School of Electrical and Computer Engineering (ECE), National Technical University of Athens, 15780 Athens, Greece (e-mail: atzenetopoulos@microlab.ntua.gr; demo.masouros@microlab.ntua.gr; dsoudris@microlab.ntua.gr; sxydis@microlab.ntua.gr).</p><p>Digital Object Identifier 10.1109/LCA.2023.3288089 decomposition supported in the FaaS paradigm is a key enabler for finer timing control since its multi-staged nature permits transparent and per-stage monitoring of the overall timing. This unambiguous phase definition allows for staged resource efficiency optimization, by adjusting computing power, e.g., CPU limits enforcement <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, or core-frequency scaling, even if it results in slightly longer processing times or latencies that are still within acceptable limits, i.e., QoS constraints. While power consumption becomes more and more critical, various works have opted for adopting system-level techniques such as Dynamic Voltage and Frequency Scaling (DVFS) <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, or sleep state management (C-states) <ref type="bibr" target="#b13">[14]</ref> to control QoS with just-enough-power. However, those approaches treat applications as traditional monolithic deployments, without readjusting mechanisms to regulate errors in function latency estimation caused by performance variability. This variability is provoked by the stochastic nature of FaaS, i.e., complex software stack, coldstarts, stronger presence of network communication, and resource interference due to application co-location <ref type="bibr" target="#b2">[3]</ref>. Therefore, existing DVFS solutions are inadequate by design for addressing the needs of this updated cloud computing architecture model. This can lead to QoS violations or resource waste. In the motivational example in Fig. <ref type="figure" target="#fig_1">1</ref>, a QoS-unaware deployment (yellow bar) over power-conservative policies would most probably violate the QoS requirements, especially if the requirements are not relaxed. On the contrary, a power-unaware FaaS controller (blue bar), i.e., the OS-level mechanisms used by the existing FaaS frameworks by default, while addressing the latency requirements, neglects the opportunities for reduced power consumption offered by the unexploited latency capacity, i.e., timing slack. However, as shown, an Oracle controller (green bar) following a monitor-and-act policy, would be both QoS precise and power efficient, by eliminating the distance from the accumulated QoS requirement (denoted by the red lines).</p><p>In this paper, we introduce DVFaaS, a QoS-aware and function-agnostic serverless framework extension, implemented on a physical setup, which distinguishes it from prior works <ref type="bibr" target="#b10">[11]</ref>. DVFaaS is the first solution, to the best our our knowledge, that applies intermittent, closed-loop control of serverless function chains, employing Dynamic Voltage and Frequency Scaling to regulate the end-to-end execution latency. It achieves that by applying just-enough frequency, exploiting the aforementioned Fig. <ref type="figure">2</ref>. A staged approach, it determines and applies the required frequency for each function.</p><p>timing slack, to minimize power consumption. The main contributions of this work are: i) We highlight the apparent insufficiency of the Linux frequency governors when they have to regulate frequency for satisfying QoS requirements, thus, suggesting the need for further investigation into alternative approaches. ii) We design and implement a real-system runtime mechanism that utilizes a PID controller to regulate the end-to-end execution time of serverless chains across nodes, considering the propagated latency (slack) in each step. iii) By evaluating on commodity hardware/software setup, we demonstrate the QoS-precision of our proposed solution, which remains within the desired limits at the millisecond level. DVFaaS outperforms SeqClock <ref type="bibr" target="#b4">[5]</ref>, a CPU-quota scaling controller, and presents a 20% power improvement (P90) over Gemini <ref type="bibr" target="#b8">[9]</ref>, a state-of-the-art DVFS governor, narrowing the optimality distance w.r.t. the Oracle (1.7% more power consumed on average) while addressing the end-to-end QoS latency requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. DVFAAS: FUNCTION-GRANULAR DYNAMIC FREQUENCY SCALING</head><p>DVFaaS leverages the intermittent invocations on serverless chains to regulate the end-to-end execution time, addressing the QoS requirement, while keeping the power consumption as low as possible. As shown in Fig. <ref type="figure">2</ref>, we use Proportional-Derivative-Integral (PID) control to apply the required core frequency to regulate the cumulative execution time at every stage of the workflow, with a focus on avoiding violations in the end-to-end execution latency. More specifically, at any stage k, i) the Workflow manager, acting as a wrapper for the chain, monitors the execution latency (m k ) of the latest invoked function (f ) that is f k . ii) The PID controller after calculating the propagated latency (V k ), generates the output u(k), which is propagated to the iii) Frequency Scaling component that determines the core frequency F to be applied in the next function in the chain f k+1 . Finally, the Workflow manager invokes the function f k+1 and sets the frequency F to the specified cores.</p><p>Workflow Manager (WM): DVFaaS targets serverless chains, which are composed of multiple functions. The Workflow Manager is responsible for synthesizing those serverless chains, by invoking the required functions. Due to the inherent function-level granularity of FaaS deployments, we can avoid function-specific source code customization for checkpointing and application-level metrics advertisement <ref type="bibr" target="#b6">[7]</ref>. Thus, we use the function serving time as the reporting interval. WM assumes a per-function QoS constraint, derived either through time budgeting at the function level or directly provided by the user. After the function f k concludes its operation, WM calculates its latency m k and forwards it to the PID controller. After the frequency F is determined from the Frequency Scaling component, WM communicates via a message broker with the respective node to apply it.</p><p>PID Controller: Our closed-loop, PID controller is activated between function invocations. At each stage k, it constructs the process variable M from the previous functions' measured accumulated latency and calculates the output to be applied before the invocation of the next function. Let t k be the QoS-target latency and m k be the actual measured latency, for the function in stage k. In (1) we define the cumulative (up to stage k) target T k , measured M k latency as well as the violation time or slack V k .</p><formula xml:id="formula_0">T k = k i=1 t i , M k = k i=1 m i , V k = T k -M k . (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>Considering the target control loop, M forms the process variable, T is the setpoint, and V forms the error e. To rectify the error, we define the following proportional, integral, and derivative terms. The proportional term P is equal to the slack V (k). The integral and derivative terms are calculated using the following equations:</p><formula xml:id="formula_2">I = k 0 V (k) dk = k i=1 V (i), D = dV (k) dM k = V (k-1)-V (k) m k</formula><p>. Finally, the controller produces the output signal u, using the sum of the previously defined terms:</p><formula xml:id="formula_3">u = K p P + K i I + K d D.</formula><p>The PID gains K p , K i , K d were extracted through a typical grid search approach.</p><p>Frequency Scaling: At stage k, the output u(k) of the PID controller is forwarded to the frequency scaling component which determines the core frequency to be applied (Fig. <ref type="figure">2</ref>). We employ a function-agnostic, dynamically re-configurable selector to determine the desired frequency. This selector calculates the core frequency as a function of the PID controller's output (u(k)), by using a parameterized linear function. More precisely, we use the function F = a ? u(k) + b, where F denotes the core frequency. We construct a, b as follows:</p><formula xml:id="formula_4">a= F max -F min thr max (p)-thr min (p) , b=F max -a ? thr max (p)<label>(2)</label></formula><p>where F max and F min are the max. and min. core frequencies supported by the system. We also set the initial latency thresholds as thr init min = -1 s (negative slack) and thr init max = 0.8 s, to determine the sensitivity of our actuator to the latency variation, i.e., the min./max. tolerable slack before applying the min./max. core frequency. Finally, in order to preserve the end-to-end latency requirement, we introduce the parameter p, which represents the percentage of the functions that have completed execution out of the total number of functions in the serverless chain. Therefore, in stage k, if n is the total number of functions, p = k n . This parameter is leveraged to adjust the max. and min. latency thresholds in a time-conservative fashion. Specifically, as the workflow progresses closer to completion, thr min and thr max are proportionally reconfigured with stricter slack limits being set. Hence, the linear function that maps the PID controller's output (u(k)) to frequency (F ) is altered (blue line in Fig. <ref type="figure">2</ref>). We define these thresholds as follows: thr max (p) = thr init max ? (1p) and thr min (p) = thr init min ? (1 + p). For example, in the first stages of the chain, max. frequency (turbo) will be applied for values greater or equal to 0.8 seconds. Conversely, in the last stages of the chain, the turbo frequency is applied for values close to zero. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EVALUATION</head><p>Experimental Setup: We deployed an 8-core Virtual Machine (VM), on top of an Intel Xeon E5-2658A CPU with 24 cores and 132 GB of DRAM. The virtual cores were one-to-one mapped to cores belonging to the same socket of the physical machine. We utilized the RAPL-based <ref type="bibr" target="#b14">[15]</ref> Intel Performance Counter Monitor to measure the power consumption with a sampling period of 20 ms. The frequency range available for adjustment is between 1.2 GHz and 2.2 GHz (2.5 GHz turbo). Notably, core frequency increments can be performed in steps of 100 MHz. On top of this, we installed Kubernetes for container orchestration and Apache Openwhisk for function lifecycle management. The management components of those frameworks were deployed on a VM provisioned on a separate physical node. Last, we also enabled the pre-warming mechanism provided by Openwhisk.</p><p>In order to determine the impact of frequency scaling on the domain of serverless computing, we utilize the Serverless-Benchmark-Suite <ref type="bibr" target="#b15">[16]</ref>. We compose chains consisting of functions from various domains such as multimedia (e.g., video-processing, thumbnailer), scientific (e.g., graphbfs, graph-mst, graph-pagerank), utilities (e.g., compression, dna-visualization), and web applications (e.g., dynamic-html, uploader). While in this paper only static function workflows are examined, DVFaaS can be also extended for dynamic workflow scenarios. Inter-function communication occurs over the network and is facilitated by the MinIO remote storage solution hosted on a separate physical node. The functions were chosen based on their ability to represent typical workloads and their consistency with the latency findings described in <ref type="bibr" target="#b1">[2]</ref>.</p><p>In the rest of this section, we aim to provide motivation for the utilization of DVFS as a means of regulating latency in FaaS deployments. This approach has been previously employed for single-service latency regulation <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>. We demonstrate the impact of DVFS on function performance in comparison to CPU-quota enforcement, which has been utilized for serverless chain latency regulation in recent studies <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>. Our findings emphasize the potential of DVFS as an alternative or complementary solution for latency regulation in serverless functions. Additionally, to evaluate the effectiveness in terms of violation rate and power consumption, of DVFaaS, we conducted experiments comparing it against i) the Linux frequency scaling governors, ii) Gemini <ref type="bibr" target="#b8">[9]</ref>, a state-of-the-art DVFS solution that estimates single-service end-to-end latency, and accommodates any prediction errors by turbo-boosting, iii) SeqClock <ref type="bibr" target="#b4">[5]</ref>, which employs CPU-quota scaling to control the latency, and iv) an Oracle controller with zero slack at every stage of the workflow. To determine the per-stage power consumption, we divide the energy consumed during the execution of a stage (function) by its corresponding execution time.</p><p>Exploring DVFS Impact on Function Performance: In Fig. <ref type="figure" target="#fig_2">3</ref>, we illustrate the kernel density estimation plots for the latency distributions of three serverless functions when CPU quota (left), and core frequency scaling (right) are employed. Regarding the CPU-quota scaling experiment, we use dynamic frequency scaling (odemand Linux governor) and measure the average latency of 100 invocations for CPU quota in the range of 0.55 to 8 times the CPU period. Conversely, for the core frequency scaling, we set the number of cores to a fixed value (2) and measure the average latency of 100 invocations on varying frequency levels (1.2-2.5 GHz). We normalize the measured tail latency (P90) using the min. and the max. values per function, regardless of the scenario in which they occur. As demonstrated, the varying CPU-usage characteristics of different functions, result in unpredictable performance variability (thumbnailer, graph-pagerank). On the contrary, frequency scaling presents a more regular scaling behaviour and proves to be a good configuration knob for function-agnostic latency regulation.</p><p>Regular Function Chain Length Scenarios: In order to evaluate the efficacy and compare the efficiency of DVFaaS against other solutions, we use 20 unique function chains. These chains were randomly sampled from the Serverless-Benchmark-Suite <ref type="bibr" target="#b15">[16]</ref>, in order to resemble typical workflows <ref type="bibr" target="#b16">[17]</ref>. We established multiple levels of QoS stringency to investigate the response of the frameworks to alterations in the desired throughput. Each function is mapped to 2 vCPUs based on the configurations commonly used by CSPs <ref type="bibr" target="#b2">[3]</ref>. We consider the QoS requirement violated if the end-to-end latency exceeds the desired value. We measured the accumulated slack and the average power consumed per stage for i) ondemand and conservative Linux governors, ii) Gemini <ref type="bibr" target="#b8">[9]</ref>, iii) SeqClock <ref type="bibr" target="#b4">[5]</ref>, and iv) DVFaaS. The QoS requirements were classified into low, mid, and high categories based on the corresponding execution latency of Oracle at 1.4, 1.7, and 2 GHz frequencies, respectively. Fig. <ref type="figure" target="#fig_3">4</ref> (left) shows the per-stage accumulated slack distribution of the evaluated governors. The red points depict the stages that were part of the function chain executions that violated the QoS, while the boxplots correspond to the non-violated ones. The results indicate that Gemini and SeqClock fail to maintain QoS in many cases due to static estimation and unpredictable scaling impact, respectively. In addition, Linux governors exhibit QoS violations (10%, 20%) only in the most stringent scenarios. DVFaaS achieves a 95% preservation rate at the most QoS stringent scenario (100% for the rest), while closely adhering to the target. The right subplot of Fig. <ref type="figure" target="#fig_3">4</ref> demonstrates the per-stage power consumption distribution of the non-violated chains. While the lower QoS levels offer a greater opportunity for improvement in terms of power efficiency, DVFaaS outperforms the other governors, with a median power consumption that is on average only 1.7% higher than that of Oracle. The deviations in power distribution stem from the frequency fluctuations and function behavior across the distinct stages of the chain.</p><p>Large-Scale Deployments: In an effort to provide more insight and to further analyze the behavior of the more closely related frequency governors, we evaluate them on a large-scale deployment scenario. More specifically, we composed a 100function chain through random sampling and assigning functions from the SeBS <ref type="bibr" target="#b15">[16]</ref>. As shown in <ref type="bibr" target="#b1">[2]</ref>, FaaS deployments with more than 100 functions, form a rather rare (occurrence probability &lt; 1%) but realistic use case in large-scale production workloads.</p><p>Fig. <ref type="figure" target="#fig_4">5</ref>(a) depicts the slack of various Linux frequency scaling governors during the workflow execution. The red line indicates the required QoS for each stage. The powersave and performance governors, which prioritize power efficiency and latency reduction, respectively, exhibit greater deviation from the desired value. Similarly, while the CPU-utilization-driven ondemand and more power-efficient conservative governors are closer to the desired QoS values, they fail to capitalize on negative slack to conserve power due to the absence of this information at the OS level.</p><p>Likewise, we evaluate DVFaaS and Gemini <ref type="bibr" target="#b8">[9]</ref>, which are designed to address the issues caused by Linux governors. The results, presented in Fig. <ref type="figure" target="#fig_4">5(b)</ref>, were obtained by deploying the serverless chain multiple times to account for stochasticity. The lower part of Fig. <ref type="figure" target="#fig_4">5</ref>(b) illustrates the distribution of the slack (symmetrical log-scale) per stage, using the min. and max. values observed to depict the error (gray and cyan areas). The average values are represented by the points, while the red line indicates the QoS target. Gemini, which estimates the required frequency, introduces an increased variability (gray area) in the slack distribution, with ? = 10.93(s). This variability is either violating the QoS requirement or squandering resources. DVFaaS, taking into consideration the accumulated latency, fine-tunes the per-core frequency, to eliminate the slack. We demonstrate the fine-grained frequency selection in the upper part of Fig. <ref type="figure" target="#fig_4">5(b)</ref>. While it may surpass the zero-slack (red) line during the chain execution, it successfully addresses the end-to-end QoS requirement due to the dynamically reconfigurable controller (2), presenting a resilient trace distribution (cyan area), with ? equal to 0.45(s). DVFaaS achieves QoS precision with a granularity of milliseconds, meeting the latency requirement with a mean slack of -320 ms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONCLUSION</head><p>In this letter, we presented DVFaaS, a power-efficient scheme for regulating the end-to-end latency of serverless workflows, leveraging DVFS. The proposed framework exploits the intermittent nature of serverless chains to apply effective closed-loop control of core frequency. We evaluated DVFaaS on realistic serverless workloads, showing its advanced capabilities in meeting the QoS requirements, while considerably reducing the 90 th percentile of power consumption up to 22% compared to a state-of-the-art DVFS framework.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Function-level Manuscript received 15 May 2023; accepted 4 June 2023. Date of publication 20 June 2023; date of current version 14 August 2023. This work was supported by the Hellenic Foundation for Research and Innovation (HFRI) under the 3rd Call for HFRI PhD Fellowships (Fellowship Number: 5349) and it was partially funded by the EU Horizon 2020 research and innovation programme, under project AIatEDGE, grant agreement No 101015922. (Corresponding author: Achilleas Tzenetopoulos.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Inadequacy of static policies w.r.t. QoS and/or power efficiency.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Impact of CPU-quota and frequency scaling on latency.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Accumulated slack (V ) and Power distribution per function invocation (20 chains ? 10 functions ? 6 governors ? 3 QoS levels).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Slack trace of a large-scale serverless chain deployment using Linux governors (a) and custom governors (b).</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Authorized licensed use limited to: Tsinghua University. Downloaded on January 01,2024 at 08:21:23 UTC from IEEE Xplore. Restrictions apply.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Aws step functions</title>
		<ptr target="https://aws.amazon.com/step-functions" />
		<imprint>
			<date type="published" when="2023-03">Mar. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Serverless in the wild: Characterizing and optimizing the serverless workload at a large cloud provider</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shahrad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. USENIX Annu. Tech. Conf</title>
		<meeting>USENIX Annu. Tech. Conf</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="205" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Peeking behind the curtains of serverless platforms</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ristenpart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Swift</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. USENIX Annu. Tech. Conf</title>
		<meeting>USENIX Annu. Tech. Conf</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="133" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Characterizing serverless platforms with serverlessbench</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th ACM Symp. Cloud Comput</title>
		<meeting>11th ACM Symp. Cloud Comput</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="30" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Sequence clock: A dynamic resource orchestrator for serverless architectures</title>
		<author>
			<persName><forename type="first">I</forename><surname>Fakinos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tzenetopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Masouros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xydis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Soudris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 15th Int. Conf. Cloud Comput</title>
		<meeting>IEEE 15th Int. Conf. Cloud Comput</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="81" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">AQUATOPE: QoS-anduncertainty-aware resource management for multi-stage serverless workflows</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Delimitrou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 28th ACM Int. Conf. Architectural Support Program</title>
		<meeting>28th ACM Int. Conf. Architectural Support Program</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Heracles: Improving resource efficiency at scale</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Govindaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ranganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kozyrakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 42nd Annu. Int. Symp. Comput. Archit</title>
		<meeting>42nd Annu. Int. Symp. Comput. Archit</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="450" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">ReTail: Opting for learning simplicity to enable QoS-aware power management in the cloud</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Delimitrou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Mart?nez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. High-Perform</title>
		<meeting>IEEE Int. Symp. High-Perform</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="155" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Gemini: Learning to manage cpu power for latency-critical search engines</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">N</forename><surname>Bhuyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Ramakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 53rd Annu</title>
		<meeting>53rd Annu</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="637" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Rubik: Fast analytical power management for latency-critical systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kasture</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Bartolini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/ACM 48th Annu. Int. Symp. Microarchitecture</title>
		<meeting>IEEE/ACM 48th Annu. Int. Symp. Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="598" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Tackling performance variability due to RAS mechanisms with PID-controlled DVFS</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rodopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Catthoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Soudris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Archit. Lett</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="156" to="159" />
			<date type="published" when="2015-12">Jul.-Dec. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dark silicon aware power management for manycore systems under dynamic workloads</title>
		<author>
			<persName><forename type="first">M.-H</forename><surname>Haghbayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 32nd Int. Conf. Comput. Des</title>
		<meeting>IEEE 32nd Int. Conf. Comput. Des</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="509" to="512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Coordinated, distributed, formal energy management of chip multiprocessors</title>
		<author>
			<persName><forename type="first">P</forename><surname>Juang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-S</forename><surname>Peh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Symp. Low Power Electron. Des</title>
		<meeting>Int. Symp. Low Power Electron. Des</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="127" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">DPM: Dynamic power management for the microsecond era</title>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">N</forename><surname>Bhuyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. High Perform</title>
		<meeting>IEEE Int. Symp. High Perform</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="120" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">RAPL: Memory power estimation and capping</title>
		<author>
			<persName><forename type="first">H</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gorbatov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">R</forename><surname>Hanebutte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Khanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/ACM 16th Int. Symp. Low Power Electron. Des</title>
		<meeting>IEEE/ACM 16th Int. Symp. Low Power Electron. Des</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="189" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">SeBS: A serverless benchmark suite for function-as-a-service computing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Copik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kwasniewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Besta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Podstawski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hoefler</surname></persName>
		</author>
		<idno type="DOI">10.1145/3464298.3476133</idno>
		<ptr target="https://doi.org/10.1145/3464298.3476133" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">WISEFUSE: Workload characterization and DAG transformation for serverless workflows</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mahgoub</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Meas</title>
		<meeting>ACM Meas</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="28" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
