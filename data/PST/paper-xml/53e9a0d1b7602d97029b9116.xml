<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Pierpaolo</forename><surname>Battigalli</surname></persName>
							<email>pierpaolo.battigalli@uni-bocconi.it</email>
						</author>
						<author>
							<persName><forename type="first">Marciano</forename><surname>Siniscalchi</surname></persName>
							<email>marciano@princeton.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Harvard</orgName>
								<address>
									<settlement>Caltech, Northestern, Princeton</settlement>
									<region>Michigan, MIT, Stanford</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Tel Aviv</orgName>
								<address>
									<settlement>Tilburg, Toulouse, Torino</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Euro-pean</orgName>
								<orgName type="institution" key="instit1">University Institute and Bocconi University (Battigalli)</orgName>
								<orgName type="institution" key="instit2">IGIER-Bocconi University</orgName>
								<address>
									<settlement>Kellogg</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Istituto di Economia Politica</orgName>
								<orgName type="institution">Università Bocconi</orgName>
								<address>
									<postCode>20136</postCode>
									<settlement>Milano</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Department of Economics</orgName>
								<orgName type="institution">Princeton University</orgName>
								<address>
									<postCode>08544-1021</postCode>
									<settlement>Princeton</settlement>
									<region>New Jersey</region>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6C1183421A60A190AC674101E010560B</idno>
					<idno type="DOI">10.1006/jeth.2001.2942</idno>
					<note type="submission">Received January 22, 2000; final version received September 26, 2001</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T04:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>conditional belief</term>
					<term>strong belief</term>
					<term>forward induction</term>
					<term>rationalizability</term>
					<term>intuitive criterion</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Strong Belief and Forward Induction Reasoning 1</head><p>1 This is a significantly expanded and revised version of Battigalli and Siniscalchi <ref type="bibr" target="#b5">[6]</ref>. We thank Drew Fudenberg for helpful comments. We also benefited from conversations with Adam Brandenburger, Eddie Dekel, Faruk Gul, and seminar participants at Barcelona,</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Forward-induction reasoning 2 is motivated by the assumption that unan- 2 To the best of our knowledge the earliest example of forward-induction reasoning is due to Elon Kohlberg. See Van Damme <ref type="bibr" target="#b32">[33]</ref> and Kohlberg <ref type="bibr" target="#b20">[21]</ref> for excellent surveys and references on forward-induction equilibria. Non-equilibrium solution concepts featuring forward induction are put forward and/or analyzed by Asheim and Dufwenberg <ref type="bibr" target="#b0">[1]</ref>, Battigalli <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>, Pearce <ref type="bibr" target="#b24">[25]</ref>, and Reny <ref type="bibr" target="#b26">[27]</ref>. ticipated strategic events, including deviations from a putative equilibrium path, result from purposeful choices. Thus, if a player observes an unexpected move, she should revise her beliefs so as to reflect its likely purpose.</p><p>However, in order to divine the purpose of unexpected moves, a player must formulate assumptions about her opponents' rationality and strategic reasoning. This paper focuses on these assumptions and emphasizes their rôle in guiding the players' belief revision process, and hence their behavior (cf. Stalnaker <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32]</ref>). In particular, we adopt a model of interactive conditional beliefs based on Battigalli and Siniscalchi <ref type="bibr" target="#b6">[7]</ref> and propose a formal analysis of forward-induction reasoning whose centerpiece is the notion of ''strong belief. <ref type="bibr">''</ref> We say that a player strongly believes event E if she believes that E is true at the beginning of the game, and continues to do so as long as E is not falsified by the evidence. <ref type="foot" target="#foot_0">3</ref> In other words, E serves as a ''working hypothesis.''</p><p>The notion of strong belief allows us to provide a unified epistemic analysis of different versions of forward induction, listed below in an order that, loosely speaking, reflects the complexity of the corresponding assumptions about beliefs:</p><p>• In its simplest form, forward-induction reasoning involves the assumption that, upon observing an unexpected (but undominated) move of her opponent, a player maintains the ''working hypothesis'' that the latter is rational (for example, see <ref type="bibr" target="#b23">[24]</ref>, pp. 110-111). Strong belief in the rationality of opponents captures precisely this type of argument.</p><p>• In the context of signalling games, we show that strong belief in rationality and in a candidate equilibrium path justifies the deletion of equilibrium-dominated messages for each sender type. This leads to an epistemic characterization of the intuitive criterion of Cho and Kreps <ref type="bibr" target="#b14">[15]</ref>.</p><p>• Extensive-form rationalizability (Battigalli <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>, Pearce <ref type="bibr" target="#b24">[25]</ref>) is based on the informal assumption that a player interprets unexpected moves of her opponents in a manner consistent with the highest possible ''degree of strategic sophistication.'' Using the notion of strong belief, we formalize this assumption in the context of our epistemic model, and obtain an epistemic characterization of extensive-form rationalizability.</p><p>Since extensive-form rationalizability induces the backward-induction outcome in generic perfect-information games (cf. <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b26">[27]</ref>), our analysis additionally provides sufficient epistemic conditions for backward induction.</p><p>The above results are meant to illustrate ''typical'' applications of strong belief to the analysis of forward-induction reasoning. Thus, we have restricted our attention to (relatively) well-known solution concepts and examples. However, as we suggest in Section 6, different assumptions involving rationality and strong belief may be used to obtain characterizations of other known extensive-form solution concepts that embody notions of forward induction-as well as to derive new solution concepts which may be more germane to specific applications.</p><p>On a similar note, we do not wish to suggest that any of the solution concepts analyzed in this paper should be regarded as embodying the ''right'' notion of forward induction. Rather, we suggest that the notion of strong belief allows to uncover and make explicit certain assumptions about the belief revision processes associated with different versions of forward-induction reasoning.</p><p>Finally, normal-form solution concepts such as strategic stability (cf. Kohlberg and Mertens <ref type="bibr" target="#b21">[22]</ref>) and iterated weak dominance also typically select outcomes consistent with versions of forward-induction reasoning. When this is the case, normal-form analysis may be viewed as providing an alternative rationale for ''forward induction outcomes.'' However, normal-form analysis is unlikely to shed light on the aspect of forward induction reasoning we emphasize, namely the players' belief revision process.</p><p>Following Battigalli and Siniscalchi <ref type="bibr" target="#b6">[7]</ref>, in the model of interactive beliefs adopted here, a state comprises a specification of the strategy and epistemic type of each player. Every epistemic type corresponds to a conditional probability system over opponents' strategies and types-hence, implicitly, to an infinite hierarchy of conditional beliefs on opponents' actions and conditional beliefs.</p><p>As we argue in Section 3, the analysis of the behavioral implications of forward induction is considerably simplified by focusing on belief-complete models. Loosely speaking, in such models, every conceivable hierarchy of conditional beliefs a player may hold about her opponents is represented by an epistemic type.</p><p>We have already mentioned some of the key references on forward induction. Further comments on the related literature are deferred to the discussion section.</p><p>The remainder of the paper is organized as follows. The framework is introduced in Section 2. Section 3 provides the formal definition of strong belief and illustrates its features by means of an example. Section 4 provides a characterization of extensive-form rationalizability. Section 5 contains our characterization of the intuitive criterion. Section 6 discusses some modelling choices and possible extensions of the analysis, and comments on the related literature. All proofs are contained in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">THE FRAMEWORK</head><p>This section introduces most of the required game-theoretic notation, and summarizes the features of type spaces that will be relevant to our analysis. Further details may be found in Battigalli and Siniscalchi <ref type="bibr" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Multistage Games</head><p>We focus on dynamic, finite games, and allow for the possibility that payoff functions may not be commonly known. This may reflect imperfect knowledge of the opponents' preferences, or of the link between actions and payoff-relevant consequences. Therefore, in general we allow for incomplete information.</p><p>In order to keep notation at a minimum, our analysis shall deal with multistage games with observable actions, <ref type="foot" target="#foot_1">4</ref> although our framework and techniques can be adapted to deal with general extensive-form games (see Section 6 for further details).</p><p>We shall be interested in the following primitive objects: a set I= {1, ..., |I|} of players, a finite collection H of (non-terminal) histories, 5   5 Histories are sequences of consecutive action profiles.</p><p>including the empty history f, a finite collection of terminal histories Z, and, for each player i ¥ I, a finite collection G i of payoff types and a payoff function</p><formula xml:id="formula_0">u i : Z × G Q R, where G=G 1 × • • • × G I . Each element h i ¥ G i</formula><p>represents Player i's private information about the unknown payoff-relevant aspects of the game. If the set G contains only one element, we say that the game has complete information.</p><p>As the game progresses, each player is informed of the history that has just occurred. However, a player is never informed of her opponents' payoff types. The set of feasible actions for Player i may depend on previous history, but not on his private information h i , and it is denoted A i (h).</p><p>Player i is active at h ¥ H if A i (h) contains more than one element. There are simultaneous moves at h if at least two players are active at h. If there is only one active player at each h ¥ H, we say that the game has perfect information.</p><p>Moreover, we shall make use of certain derived objects. First, for every i ¥ I, we shall denote by S i the set of strategies available to Player i (where a strategy is defined as a function 6 In keeping with standard game-theoretic notation, 6 A strategy of player i at an hypothetical stage of the game where she does not yet know her payoff type would be a map with domain G i × H. Here, however, we are not assuming that such an ''ex ante stage'' exists. Therefore, we take the point of view of a player who knows her payoff type. This simplifies the analysis and emphasizes the incomplete-information interpretation of our framework.</p><formula xml:id="formula_1">s i : H Q 1 h ¥ H A i (h) such that s i (h) ¥ A i (h) for all h).</formula><p>we let S=&lt; i ¥ I S i and S -i =&lt; j ] i S j .</p><p>For any h ¥ H 2 Z, S(h) denotes the set of strategy profiles which induce history h; its projections on S i and S -i are denoted by S i (h) and S -i (h), respectively. The correspondence S( • ) provides a convenient strategic-form representation of the information structure.</p><p>We denote by S i =S i × G i the set of strategy-payoff type pairs for Player i and let S=&lt; i ¥ I S i and S -i =&lt; j ] i S i .</p><p>Using this notation, we can define a strategic-form payoff function</p><formula xml:id="formula_2">U i : S i × S -i Q R in the usual way: for all z ¥ Z, (s i , h i ) ¥ S i and (s -i , h -i ) ¥ S -i , if (s i , s -i ) ¥ S(z), then U i (s i , h i , s -i , h -i )=u i (z, (h j ) j ¥ I ).</formula><p>Finally, for every strategy s i , we let H(s i )={h ¥ H : s i ¥ S i (h)} denote the collection of histories consistent with s i .</p><p>Note that the structure (H, Z, I, (G i , u i ) i ¥ I ) is not a game with incomplete information in the sense of Harsanyi <ref type="bibr" target="#b19">[20]</ref>, because it contains no description of the possible interactive beliefs about payoff types. Such description will be provided in the following subsections within a richer framework encompassing interactive beliefs conditional on (non-terminal) histories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Conditional Beliefs and Type Spaces</head><p>As the game progresses, players update and/or revise their conjectures in light of newly acquired information. In order to account for this process, we represent beliefs by means of conditional probability systems (see Rênyi <ref type="bibr" target="#b27">[28]</ref>).</p><p>Fix a player i ¥ I. For a given measure space (X i , X i ), consider a nonempty collection B i ı X i of events such that " ¨Bi . The interpretation is that Player i is uncertain about the ''true'' element x ¥ X i , and B i is a collection of observable events-or ''relevant hypotheses''-concerning x.</p><formula xml:id="formula_3">Definition 1. A conditional probability system (or CPS) on (X i , X i , B i ) is a mapping m( • | • ): X i × B i Q [0, 1] such that, for all B, C ¥ B i and A ¥ X i , (1) m(B | B)=1, (2) m( • | B) is a probability measure on (X i , X i ), and (3) A ı B ı C implies m(A | B) m(B | C)=m(A | C).</formula><p>We assume that X i is a topological space, and it is understood that X i is the Borel sigma-algebra on X i . Therefore we often omit to mention X i explicitly and we refer only to X i and B i . The set of probability measures on X i is denoted by D(X i ). The set of conditional probability systems on (X i , B i ) can be regarded as a subset of [D(X i )] B i and is denoted by</p><formula xml:id="formula_4">D B i (X i ). D(X i</formula><p>) is endowed with the topology of weak convergence of measures and [D(X i )] B i is endowed with the product topology.</p><p>Throughout this paper, we shall be interested solely in ''relevant hypotheses'' corresponding to the event that a certain partial history has occurred. Thus, Player i's first-order (conditional) beliefs about her opponents' behavior and payoff types may be represented by taking X i =S -i and B i ={B ı S -i : B=S -i (h) × G -i for some h ¥ H}. We denote the collection of CPSs on (S -i , B i ) thus defined by D H (S -i ). Since S -i and H are finite, D H (S -i ) is easily seen to be a closed subset of Euclidean</p><formula xml:id="formula_5">|H| • |S -i |-dimensional space.</formula><p>To represent Player i's higher-order beliefs, we introduce the notion of an extensive-form type space. The conditional beliefs of each player j are parametrized by her epistemic type t j ¥ T j , where T j is a compact topological space. A state of the world is an array w=(w j ) j ¥ I =(s j , h j , t j ) j ¥ I of strategies, payoff types and epistemic types. We consider a set of ''possible worlds'' W=&lt; j ¥ I W j ı &lt; j ¥ I (S j × T j ), where every combination (s j , h j ) j ¥ I ¥ S occurs at some state. Player i has conditional beliefs about the strategies, payoff types and epistemic types of her opponents. Therefore the structure (X i , B i ) is specified as follows:</p><formula xml:id="formula_6">X i =&lt; j ] i W j =W -i and B i ={B ¥ X i : B={(s -i , h -i , t -i ) ¥ W -i : s -i ¥ S -i (h)} for some h ¥ H}.</formula><p>The set of CPSs on (W -i , B i ) will be denoted by D H (W -i ).</p><p>Definition 2 (cf. Ben Porath <ref type="bibr" target="#b8">[9]</ref>). A type space on (H, S( • ), G, I) is a tuple T=(H, S( • ), G, I, (W i , T i , g i ) i ¥ I ) such that, for every i ¥ I, T i is a compact topological space and</p><formula xml:id="formula_7">1. W i is a closed subset of S i × T i such that proj S i W i =S i ; 2. g i =(g i, h ) h ¥ H : T i Q D H (W -i ) is a continuous mapping. 7</formula><p>For any i ¥ I, g i, h (t i ) denotes the beliefs of epistemic type t i conditional on h. 8   8 Once we have specified a type space T, we may derive a Bayesian game à la Harsanyi by taking, for each epistemic type t i , the the initial marginal beliefs over G -i × T -i . Of course, Harsanyi-consistency (i.e., the possibility to derive beliefs at each state from a common prior) is satisfied only in special cases. Thus, at any ''possible world'' w=(s i , h i , t i ) i ¥ I ¥ W, we specify each player i's dispositions to act (her strategy s i ) and dispositions to believe (her system of conditional probabilities g i (t i )=(g i, h (t i )) h ¥ H ), together with her payoff type. These dispositions also include what a player would do and think at histories that are inconsistent with w (history h is inconsistent with, or counterfactual at, w=(s, h, t) if s ¨S(h)). <ref type="foot" target="#foot_3">9</ref> We call ''event'' any Borel subset of W.</p><p>Notably absent in our definition of a type space is the description of the beliefs of a player about herself. We omit such beliefs because the epistemic assumptions appearing in our results only involve beliefs about the opponents. Thus, beliefs about oneself do not play an explicit role. But our analysis is consistent with the standard assumption that a player knows her beliefs and assigns probability one to the strategy she intends to carry out.</p><p>Type spaces encode a collection of infinite hierarchies of CPSs for each player. It is natural to ask whether there exists a type space which encodes all ''conceivable'' hierarchical beliefs. Mertens and Zamir <ref type="bibr" target="#b22">[23]</ref> and Brandenburger and Dekel <ref type="bibr" target="#b11">[12]</ref> answered this question in the affirmative when beliefs are represented by probability measures on a compact or Polish space; Battigalli and Siniscalchi <ref type="bibr" target="#b6">[7]</ref> provide a counterpart of these results in the present ''dynamic'' setting where beliefs are represented by CPSs.</p><p>Consider the following definition.</p><p>Definition 3. A belief-complete type space on (H, S( • ), G, I) is a type space T=(H, S( • ), G, I, (W i , T i , g i ) i ¥ I ) such that, for every i ¥ I, W i =S i × T i and the function g i maps T i onto D H (&lt; j ] i S j × T j ). <ref type="foot" target="#foot_4">10</ref>It is shown in <ref type="bibr" target="#b6">[7]</ref> that a belief-complete type space may always be constructed (for finite games and also for ''well-behaved'' infinite games) by taking the sets of epistemic types to be the collection of all possible hierarchies of conditional probability systems that satisfy certain intuitive coherency conditions. Also, every type space may be viewed as a belief-closed subspace of the space of infinite hierarchies of conditional beliefs. 11 11 <ref type="bibr" target="#b6">[7]</ref> uses a slightly different definition of type space. But all the arguments in <ref type="bibr" target="#b6">[7]</ref> can be easily adapted to the present framework.</p><p>Finally, since we assume that the set of external states S is finite and hence compact, the sets T i (i ¥ I) of epistemic types in the belief-complete type space thus constructed are compact topological spaces, as assumed in our definition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Sequential Rationality</head><p>Our basic behavioral assumption is that each Player i chooses and carries out a strategy s i ¥ S i that is optimal, given her payoff type h i and her beliefs, conditional upon any history consistent with s i . This does not impose restrictions on the actions specified at histories that cannot obtain if Player i follows the strategy s i . Thus, we use a sequential best response property which applies to plans of action 12 as well as strategies (see, for 12 Intuitively, a plan of action for player i is silent about which actions would be taken by i if i did not follow that plan. Formally, a plan of action is a class of realization-equivalent strategies. In generic extensive games, a plan of action is a strategy of the reduced normal form.</p><p>example, <ref type="bibr" target="#b28">[29]</ref> and <ref type="bibr" target="#b26">[27]</ref>). 13   13 Hence, our analysis could be carried out in a more parsimonious (but less conventional) formal setup, wherein each player's behavior at a state is described by a plan of action. </p><formula xml:id="formula_8">- i ¥ S i (h), C (s -i , h -i ) ¥ S -i [U i (s i , h i , s -i , h -i ) -U i (s - i , h i , s -i , h -i )] × m i ({(s -i , h -i )} | S -i (h) × G -i ) \ 0 For any CPS m i ¥ D H (S -i ), let r i (m i ) denote the set of pairs (s i , h i ) ¥ S i such that s i is a sequential best reply to m i for h i .</formula><p>It can be shown by standard arguments that (a) for all (h i , m i ) the set of sequential best replies to m i for h i is nonempty (i.e., proj G i r i (m i )=G i for all m i ) and (b) r i is an upper-hemicontinuous correspondence.</p><p>It is convenient to introduce the following additional notation. Fix a type space T. For every player i ¥ I, let</p><formula xml:id="formula_9">f i =(f i, h ) h ¥ H : T i Q [D(S -i )] H denote her first-order belief mapping; that is, for all t i ¥ T i and h ¥ H, f i, h (t i )=marg S -i g i, h (t i ). It is easy to see that f i (t i ) ¥ D H (S -i ) for every t i ¥ T i ; also, f i is continuous.</formula><p>We say that Player i is rational at a state w in T if and only if</p><formula xml:id="formula_10">w ¥ R i ={(s, h, t) ¥ W : (s i , h i ) ¥ r i (f i (t i ))} (Note that R i is closed because the correspondence r i p f i is upper hemi- continuous.</formula><p>Hence R i is an event.) We shall also refer to the events R=4 i ¥ I R i (''every player is rational'') and R -i =4 j ] i R j (''every opponent of Player i is rational'').</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Conditional Belief Operators</head><p>The next building block is the epistemic notion of (conditional) probability-one belief, or (conditional) certainty. Recall that an epistemic type encodes the beliefs a player would hold, should any one of the possible histories occur. This allows us to formalize statements such as, ''Player i would be certain that Player j is rational, were she to observe history h.''</p><formula xml:id="formula_11">Let A i denote the sigma-algebra of events E ı W such that E= W -i × proj W i E.</formula><p>A i is the collection of events concerning Player i. The collection of events concerning the opponents of Player i, A -i , is similarly defined.</p><p>The conditional (probability-one) belief operator for player i ¥ I given history h ¥ H is a map B i, h : A -i Q A i defined by 14 14 For any E ¥ A -i , B i, h (E) is closed, hence measurable; this follows from the continuity of g i, h , via an application of the portmanteau theorem. Clearly, B i, h (E)</p><formula xml:id="formula_12">¥ A i . -E ¥ A -i , B i, h (E)={(s, h, t) ¥ W : g i, h (t i )(proj W -i E)=1}.</formula><p>For any E ¥ A -i , B i, h (E) corresponds to the statement ''Player i would be certain that her opponents' strategies, payoff and epistemic types are consistent with E, were she to observe history h.''</p><p>For each player i and history h ¥ H, the operator B i, h : A -i Q A i satisfies the standard properties <ref type="foot" target="#foot_5">15</ref> of falsifiable beliefs (see, for example, Chapter 3 of Fagin et al. <ref type="bibr" target="#b15">[16]</ref>); in particular, it satisfies</p><formula xml:id="formula_13">• Conjunction: For all events E, F ¥ A -i , B i, h (E 5 F)=B i, h (E) 5 B i, h (F); • Monotonicity: For all events E, F ¥ A -i : E ı F implies B i, h (E) ı B i, h (F).</formula><p>Finally, we shall often be interested in formalizing assumptions such as ''Every player believes that her opponents are rational.'' In order to simplify notation, we introduce an auxiliary ''mutual belief'' operator. For any Borel subset E ı W such that E=&lt; i ¥ I proj W i E, and for any history</p><formula xml:id="formula_14">h ¥ H, let B h (E)=3 i ¥ I B i, h (W i × proj W -i E).</formula><p>For instance, if I={1, 2} and E=R, then</p><formula xml:id="formula_15">R=R 1 5 R 2 and R i = W -i × proj W i R for i ¥ I; thus, B h (R)=B 1, h (R 2 ) 5 B 2, h (R 1 ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">STRONG BELIEF</head><p>With the basic framework and notation in place, we now turn to the main focus of this paper, the notion of strong belief. This section provides the basic definition, and illustrates the key features of strong beliefs by means of a simple example. Finally, it draws a first connection with forward-induction reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Definition</head><p>We say that Player i strongly believes that an event E ] " is true (i.e., adopts E as a ''working hypothesis'') if and only if she is certain of E at all histories consistent with E. 16 Formally, for any type space T, define the 16 An analogous notion (called ''absolutely robust belief'') was independently put forth by Stalnaker <ref type="bibr" target="#b31">[32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>operator SB</head><formula xml:id="formula_16">i : A -i Q A i by SB i (")=" and SB i (E)= 3 h ¥ H : E 5 [h] ] " B i, h (E)</formula><p>for all events E ¥ A -i 0 {"}, where [h] :=&lt; j ¥ I S j (h) × G j × T j is the event ''history h occurs.'' 17 17 For any partial description p of the world, such as a history, a strategy, a player's beliefs, we let [p] denote the set of states of the world satisfying p.</p><p>As in Section 2.4, it is convenient to define an auxiliary ''mutual strong belief'' operator. For any Borel subset E ı W such that E=&lt; i ¥ I proj W i E, and for any history h ¥ H, let</p><formula xml:id="formula_17">SB(E)=3 i ¥ I SB i (W i × proj W -i E).</formula><p>As in the case of conditional belief, if I={1, 2} and E=R, then </p><formula xml:id="formula_18">SB(R)=SB 1 (R 2 ) 5 SB 2 (R 1 ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Belief and Strong Belief</head><p>The features of strong beliefs are best illustrated by means of a comparison with conditional beliefs. Note first that SB</p><formula xml:id="formula_19">i (E) ı B i, f (E) for all E ¥ A -i ; that is, strong belief implies initial certainty. More generally, SB i (E) ı B i, h (E) for all E ¥ A -i and h ¥ H such that [h] 5 E ] ".</formula><p>Unlike conditional belief, strong belief does not satisfy conjunction and monotonicity. To illustrate this point (as well as others later on), we refer to a well-known game-theoretic example: the Battle of the Sexes with an outside option. The game is depicted in Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>Table <ref type="table" target="#tab_1">1</ref> describes a type space for the game under consideration; we shall denote it by T. Since there is complete information (each set G i is a singleton), we simply omit payoff types.</p><p>The table specifies the sets T 1 ={t 1 1 , t 2 1 } and T 2 ={t 1 2 , t 2 2 , t 3 2 } of epistemic types, the sets W 1 , W 2 and W=W 1 × W 2 , and the maps g i : T i Q D H (W -i ), as required by our definitions. Note that proj S W=S. It will be notationally convenient to denote pairs w i =(s i , t i ) by w n i i , where n i is the corresponding line number in the relevant table; thus, w 5  1 =(In T, t 2 1 ). The Type Space T</p><formula xml:id="formula_20">n 1 w 1 g 1, f (t 1 ) g 1, (In) (t 1 ) n 2 w 2 g 2, f (t 2 ) g 2, (In) (t 2 ) 1 (In B, t 1 1 ) 0,1,0 0,1,0 1 (L, t 1 2 ) 0,1,0,0,0 0,1,0,0,0 2 (In T, t 1 1 ) 0,1,0 0,1,0 2 (R, t 2 2 ) 0,0,1,0,0 1,0,0,0,0 3 (Out B, t 1 1 ) 0,1,0 0,1,0 3 (L, t<label>3</label></formula><p>2 ) 0,0,0,0,1 0,0,0,0,1 4 (Out T, t 1 1 ) 0,1,0 0,1,0 5 (In T, t 2 1 ) 0,0,1 0,0,1</p><p>We keep using square brackets to denote events corresponding to histories or strategies. For example, in type space T, the event ''Player 1 chooses Out at f'' is [Out]={w 3  1 , w 4 1 } × W 2 . Also, the notation [s i =s i ] corresponds to the event that Player i adopts strategy s i ; for instance, the event ''Player 2 would choose R if the subgame were reached'' is 2  2 }. Player 2 might entertain one or both of the following initial hypotheses, corresponding to events in T:</p><formula xml:id="formula_21">[s 2 =R]=W 1 × {w</formula><formula xml:id="formula_22">• ''Player 1 is rational'': R 1 ={w 3 1 , w 4 1 , w 5 1 } × W 2 . • ''Player 1 initially believes that Player 2 would play R after observ- ing In'': B 1, f ([s 2 =R])=(W 1 0 {w 5 1 }) × W 2 .</formula><p>The two hypotheses jointly imply that Player 1 chooses Out:</p><formula xml:id="formula_23">R 1 5 B 1, f ([s 2 =R])={w 3 1 , w 4 1 } × W 2 =[Out]=W 0 [In]. However, R 1 and B 1, f ([s 2 =R]) are individually consistent with Player 1 choosing In: R 1 5 [In]={w 5 1 } × W 2 ] " and B 1, f ([s 2 =R]) 5 [In]= {w 1 1 , w 2 1 } × W 2 ] ". Therefore SB 2 (R 1 ) ı B 2, (In) (R 1 ) and SB 2 (B 1, f ([s 2 =R])) ı B 2, (In) (B 1, f ([s 2 =R])).</formula><p>It follows that Player 2 cannot strongly believe R 1 and strongly believe B 1, f ([s 2 =R]) in the same state, or else she would hold contradictory beliefs after In:</p><formula xml:id="formula_24">SB 2 (R 1 ) 5 SB 2 (B 1, f ([s 2 =R])) ı B 2, (In) ([Out])=".</formula><p>On the other hand, Player 2 can strongly believe the joint hypothesis</p><formula xml:id="formula_25">R 1 5 B 1, f ([s 2 =R]). In particular, at w 2 2 Player 2 initially believes R 1 5 B 1, f ([s 2 =R]</formula><p>) and would give up his belief in Player 1's rationality after In:</p><formula xml:id="formula_26">SB 2 (R 1 5 B 1, f ([s 2 =R]))=W 1 × {w 2 2 } ] ".</formula><p>This shows that SB 2 does not satisfy conjuction. A similar argument shows that strong belief does not satisfy monotonicity: for instance,</p><formula xml:id="formula_27">R 1 5 B 1, f ([s 2 =R]) ı R 1 , but SB 2 (R 1 5 B 1, f ([s 2 =R])) ¼ SB 2 (R 1 )=W 1 × {w 3 2 }.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Strong Belief and Forward Induction</head><p>Affinities between intuitions about forward induction and the notion of strong belief emerge clearly in the analysis of the Battle of the Sexes with an outside option.</p><p>The usual ''forward-induction analysis'' of this game runs as follows. Observe first that the strategy profile (Out B, R) is a subgame-perfect equilibrium. It is sustained by Player 2's implicit threat to play R in the simultaneous-moves subgame, were Player 1 to deviate and choose In at the initial history.</p><p>According to forward-induction reasoning, this threat is not credible: InB is strictly dominated for Player 1, so if in the subgame Player 2 believes that Player 1 is rational, he should not expect her to follow In with R. On the other hand, the subgame-perfect equilibrium (In T, L) passes the forward-induction test.</p><p>The key step in this argument is the italicized statement about Player 2's beliefs. First note that at state (w 3  1 , w 2 2 ), which corresponds to the subgameperfect equilibrium (Out B, R), the players are rational and there is initial common certainty of the opponent's rationality, that is,</p><formula xml:id="formula_28">(w 3 1 , w 2 2 ) ¥ R i 5 B i, f (R -i ) 5 B i, f (B -i, f (R i )) 5 B i, f (B -i, f (B i, f (R -i ))) 5 • • • for i=1, 2.</formula><p>But, as noted above, (w 3  1 , w 2 2 ) ¨B2, (In) (R 1 ). On the other hand, forward-induction reasoning suggests that Player 2's conditional beliefs following the unexpected move In should still be consistent with Player 1's rationality. To capture this intuition, assume that Player 2 strongly believes in Player 1's rationality; this leads to an epistemic characterization of the forward-induction solution. Note that SB 2 (R 1 )= W 1 × {w 3  2 } and R 2 =W; thus,</p><formula xml:id="formula_29">R 1 5 R 2 5 SB 2 (R 1 )={(w n 1 1 , w 3 2 ) : n 1 =3, 4, 5}</formula><p>If we now add the further assumption that Player 1 is initially certain that Player 2 is rational and strongly believes that Player 1 is rational, we obtain</p><formula xml:id="formula_30">R 1 5 R 2 5 SB 2 (R 1 ) 5 B 1, f (R 2 5 SB 2 (R 1 ))={(w 5 1 , w 3 2 )};</formula><p>i.e., we identify the strategy profile (In T, L).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">The Pitfalls of Incomplete Type Spaces</head><p>We wish to point out an important consequence of the fact that strong belief fails monotonicity and conjunction: analyzing an extensive-form game in the framework of an incomplete type space introduces implicit and potentially undesirable restrictions on forward-induction reasoning.</p><p>Consider for instance the game in Fig. <ref type="figure" target="#fig_0">1</ref>, together with the type space T - described in Table <ref type="table" target="#tab_2">II</ref>. </p><formula xml:id="formula_31">n 1 w 1 g 1, f (t 1 ) g 1, (In) (t 1 ) n 2 w 2 g 2, f (t 2 ) g 2, (In) (t 2 ) 1 (In B, t 1 1 ) 0,1 0,1 1 (L, t 1 2 ) 0,1,0,0 0,1,0,0 2 (In T, t 1 1 ) 0,1 0,1 2 (R, t 2 2 ) 0,0,1,0 1,0,0,0 3 (Out B, t 1 1 ) 0,1 0,1 4 (Out T, t 1 1 ) 0,1 0,1</formula><p>T -is a belief-closed subspace of T. Indeed W -… W and every state w ¥ W -corresponds to the same profile of strategies and hierarchies of CPSs in T and T -. To emphasize that events and belief operators are defined within the latter type space, we write R - i , SB - i ( • ) and so forth. The type space T -incorporates the assumption that Player 1, if rational, never chooses In, and that Player 2 strongly believes this. W -incorporates other restrictions as well: for instance, at any state w -¥ W -there is common certainty conditional on both f and (In) that either Player 1 is rational or she chooses In.</p><p>Intuitively, these assumptions break the forward-induction argument: if Player 2 observes that the simultaneous-moves game is reached, he must conclude that Player 1 is irrational, and hence may be planning to choose B. But then Player 2 may rationally respond with R.</p><p>Formally, observe first that R -</p><formula xml:id="formula_32">1 ={w 3 1 , w 4 1 } × W - 2 . Next, note that SB - 2 (R - 1 )=W - 1 × {w 2 2 }:</formula><p>since there is no state in the type space T -consistent both with Player 1's rationality and with the event that the subgame is reached, the assumption that Player 2 strongly believes that Player 1 is rational puts no constraint on Player 2's beliefs after (In). On the other hand, Player 2 must initially believe that Player 1 is rational, which singles out type t 2 2 . It is then easy to see that</p><formula xml:id="formula_33">R - 1 5 R - 2 5 SB - 2 (R - 1 ) 5 B - 1, f (R - 2 5 SB - 2 (R - 1 ))={(w 3 1 , w 2 2 ), (w 4 1 , w 2 2 )},</formula><p>where both (w 3 1 , w 2 2 ) and (w 4 1 , w 2 2 ) yield outcome Out: by restricting the type space, we make Out consistent with forward induction! To relate this to the properties of strong belief, note that R -</p><formula xml:id="formula_34">1 =R 1 5 W -; therefore SB - 2 (R - 1 )=SB 2 (R 1 5 W -)=W 1 × {w 2 2 } ] SB 2 (R 1 ) 5 SB 2 (W -)="</formula><p>(a failure of conjunction) and</p><formula xml:id="formula_35">R - 1 5 SB - 2 (R - 1 )=(R 1 5 W -) 5 SB 2 (R 1 5 W -) ł R 1 5 SB 2 (R 1 )</formula><p>(a failure of monotonicity).</p><p>In general, our epistemic assumptions reflecting forward-induction reasoning interact with the restrictions on beliefs implicit in the belief-incomplete type space T -. The violations of conjunction and monotonicity exhibited here mirror this interaction.</p><p>The type space T -is not ''rich enough'' to capture the intuitive forward-induction argument in this example. In general, we need to ensure that our epistemic analysis of forward induction is not biased by extraneous (and perhaps non-transparent) restrictions on the players' hierarchical beliefs. Since any belief-incomplete type space incorporates such restrictions, adopting a belief-complete type space is the simplest way to avoid potential biases. 18   18 For more on this see Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">ITERATED STRONG BELIEFS AND RATIONALIZABILITY</head><p>We now turn to the implications of iterated strong beliefs about the players' rationality. The main result of this section is an epistemic characterization of extensive-form rationalizability. We also present related results on backward induction and the relationship between extensive-form rationalizability and common certainty of rationality at a given history.</p><p>Throughout this section, we adopt a standard notation for the n-fold composition of operators. Fix a map O: A Q A; then, for any event</p><formula xml:id="formula_36">E ¥ A, let O 0 (E)=E and, for n \ 1, let O n (E)=O(O n -1 (E)).</formula><p>We begin with a caveat on the subtle issues one has to deal with when defining iterations involving the strong belief operator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">A Caveat on Iterated Strong Beliefs</head><p>The epistemic analysis of static games with complete information shows that a strategy profile s survives n+1 steps of iterated (maximal) deletion of dominated strategies if and only if it is consistent with mutual certainty of rationality of order n, i.e., if and only if there exists a profile of epistemic types t (in some type space) such that (s, t) ¥ 4 n m=0 B m (R), where B is the mutual certainty operator. Similar results involving mutual belief in rationality at a specific history can be proved for dynamic games with complete or incomplete information (see <ref type="bibr" target="#b8">[9]</ref> and <ref type="bibr" target="#b6">[7]</ref>).</p><p>A formal analogy with such results might suggest considering assumptions of the form 4 n m=0 SB m (R). However, consider the event</p><formula xml:id="formula_37">3 2 m=0 SB m (R)=3 i ¥ I 1 R i 5 SB i (R -i ) 5 SB i 1 3 j ] i SB j (R -j ) 22 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FIG. 2.</head><p>A perfect-information game (Reny <ref type="bibr" target="#b26">[27]</ref>).</p><p>The key observation is that, although the events SB(R), SB(SB(R)) and SB(R 5 SB(R)) are nonempty in any belief-complete model, it may still be the case that SB(R) 5 SB(SB(R))=". Thus, one may have 4 2 m=0 SB m (R)=". This is an instance of the general observation that the strong belief operator need not satisfy the conjunction property (see Section 3).</p><p>The game in Fig. <ref type="figure">2</ref> offers an example. It can be checked that (in a beliefcomplete model) proj 19 Although history (A 1 ) is consistent with R 1 19 Formally, both equalities follow from Proposition 6. The intuition is that A 1 D 2 is strictly dominated for Player 1, and a 1 a 2 is not sequentially rational; the further assumption that players strongly believe that these strategies will not be chosen eliminates</p><formula xml:id="formula_38">S R=(S 1 0{A 1 D 2 }) × (S 2 0{a 1 a 2 }) and proj S R 5 SB(R) ={D 1 D 2 , D 1 A 2 } × {a 1 d 2 }.</formula><formula xml:id="formula_39">A 1 A 2 , d 1 d 2 and d 1 a 2 .</formula><p>and with the assumption SB 1 (R 2 ) (which, by itself, has no behavioral implications), it is clearly inconsistent with R 1 5 SB 1 (R 2 ); thus, Player 2 cannot assign probability one to both R 1 and SB 1 (R 2 ) conditional upon observing A 1 , which implies that SB(R) 5 SB(SB(R))=".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Strong Belief and the Best-Rationalization Principle</head><p>The best-rationalization principle <ref type="bibr">(Battigalli [4]</ref>) requires that players' beliefs conditional upon observing a history h ¥ H be consistent with the highest degree of ''strategic sophistication'' of their opponents.</p><p>Our analysis clarifies what is meant by ''strategic sophistication'' in terms of interactive beliefs. Moreover, it illustrates how iterated strong beliefs may be employed to formulate assumptions about the players' belief revision policy-in this case, to ensure that they attribute the highest degree of strategic sophistication to their opponents at each history.</p><p>We introduce an auxiliary operator that allows us to express complex events concerning interactive strong beliefs in a compact way. Define</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CSB(E)=E 5 SB(E)</head><p>for any event E ı W such that E=&lt; i ¥ I proj W i E. Thus, CSB(E) is the set of states where each player i strongly believes E -i , and such beliefs happen to be correct. Hence the notation CSB. Also let CSB . (E)=4 n \ 0 CSB n (E).</p><p>Note that operator CSB inherits the non-monotonicity of the strong belief operator. However, since CSB satisfies the Truth axiom (CSB(E) ı E), the iterations of CSB give rise to a weakly decreasing sequence of events. Therefore 4 n m=0 CSB m (E) ] " whenever CSB m (E) ] " for each m=0, ..., n, and the difficulties described in Section 4.1 do not arise.</p><p>For every n \ 0, we associate the event CSB n (R) with n-th order strategic sophistication:</p><p>A minimally sophisticated player is simply rational: CSB 0 (R)=R.</p><p>A first-order strategically sophisticated player is rational, and also maintains whenever possible the hypothesis that her opponents are rational:</p><formula xml:id="formula_40">CSB 1 (R)=R 5 SB(R).</formula><p>More interestingly, a second-order strategically sophisticated player is rational, and maintains the hypothesis that her opponents are first-order strategically sophisticated until the latter is contradicted by the evidence. However, when this happens, she switches to the assumption that her opponents are simply rational, and maintains this hypothesis until it, too, is contradicted. Formally, this corresponds to the event</p><formula xml:id="formula_41">CSB 2 (R)=R 5 SB(R) 5 SB(CSB 1 (R)) =3 i ¥ I R i 5 SB i (R -i ) 5 SB i 1 R -i 5 3 j ] i SB j (R -j ) 2 .</formula><p>In the game of Fig. <ref type="figure">2</ref>, at any state w ¥ CSB 2 (R) Player 2 believes at the initial node that Player 1 is rational and that Player 1 strongly believes that her opponent is rational. However, as soon as Player 2 observes A 1 , he abandons the assumption SB 1 (R 2 ) but retains the assumption R 1 .</p><p>More generally, for every n \ 0,</p><formula xml:id="formula_42">CSB n (R)=R 5 3 n -1 m=0 SB(CSB m (R)); also, CSB . (R)=R 5 3 n \ 0 SB(CSB n (R))</formula><p>which may now be seen to capture the intuition behind the best-rationalization principle.</p><p>The main result of this section states that rationality and the best-rationalization principle completely characterize extensive-form rationalizability (Pearce <ref type="bibr" target="#b24">[25]</ref> and Battigalli <ref type="bibr" target="#b4">[5]</ref>). The following is an extension of this solution procedure to the present incomplete-information framework.</p><p>Definition 5. Consider the following procedure.</p><p>(Step 0) For every i ¥ I, let S 0 i =S i . Also, let S 0 -i =&lt; j ] i S 0 i and S 0 =&lt; i ¥ I S 0 i . (Step n &gt; 0) For every i ¥ I, and for every s i ¥ S i and</p><formula xml:id="formula_43">h i ¥ G i , let (s i , h i ) ¥ S n i if and only if (s i , h i ) ¥ S n -1 i and there exists a CPS m ¥ D H (S -i ) such that 1. (s i , h i ) ¥ r i (m); 2. -h ¥ H, if S n -1 -i 5 [S -i (h) × G -i ] ] ", then m(S n -1 -i | S -i (h) × G -i ) =1. Also let S n -i =&lt; j ] i S n i and S n =&lt; i ¥ I S n i . Finally, let S . =4 k \ 0 S n .</formula><p>The profiles of strategies and payoff types in S . are said to be extensive-form rationalizable.</p><p>In the Battle of the Sexes with an outside option S . =S 3 ={(InT, L)}, while in the game of Fig. <ref type="figure">2,</ref><ref type="figure">S</ref> </p><formula xml:id="formula_44">. =S 2 ={D 1 D 2 , D 1 A 2 } × {a 1 d 2 }.</formula><p>Proposition 6. For any belief-complete type space, (i) S n+1 = proj S CSB n (R) for all n \ 0, and (ii) S . =proj S CSB . (R).</p><p>We emphasize that Proposition 6 should not be viewed as providing unqualified support to extensive-form rationalizability. Rather, it is intended to clarify the epistemic assumptions underlying this solution concept, and hence enable potential users to judge whether or not these assumptions are appropriate, or plausible, in a specific situation.</p><p>To illustrate this point, consider the game form in Fig. <ref type="figure">2</ref>, and replace the payoff vectors (3, 0), (1, 2), (2, 1), (0, 3), and (4, 0) with (1, 0), (0, 2), <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b0">1)</ref>, <ref type="bibr" target="#b1">(2,</ref><ref type="bibr" target="#b3">4)</ref>, and (5, 3) respectively; the resulting game is a four-legged Centipede (cf. <ref type="bibr" target="#b23">[24]</ref>, pp. 106-7). The extensive-form rationalizability solution</p><formula xml:id="formula_45">S 4 ={D 1 D 2 , D 1 A 2 } × {d 1 d 2 , d 1 a 2 }</formula><p>is obtained in four steps, and corresponds to the backward-induction solution in terms of outcome and conditional first-order beliefs. Proposition 6 implies that (s 1 , s 2 ) ¥ S 4 if and only if there are epistemic types t 1 and t 2 such that, for i=1, 2</p><formula xml:id="formula_46">(s i , t i ) ¥ proj W i CSB 3 (R) =R i 5 SB i (R -i ) 5 SB i (R -i 5 SB -i (R i )) 5 SB i (R -i 5 SB -i (R i ) 5 SB -i (R i 5 SB -i (R i ))). The events R 1 , R 1 5 SB 1 (R 2 ) and R 1 5 SB 1 (R 2 ) 5 SB 1 (R 2 5 SB 2 (R 1</formula><p>)) correspond to increasing degrees of strategic sophistication of Player 1. The first entails no restrictions on the latter's behavior; the second rules out the strategy A 1 A 2 , because R 2 rules out a 1 a 2 ; finally, the third forces the choice of D 1 at the initial node, because R 2 5 SB 2 (R 1 ) rules out a 1 d 2 .</p><p>Now take the point of view of Player 2. At the initial node, he attributes the highest degree of strategic sophistication to Player 1, and expects her to choose D 1 . If, however, Player 1 were to choose A 1 at the initial node, Player 2 would attribute her the second-highest degree of strategic sophistication, in accordance with the best-rationalization principle. This implies that Player 2 would expect Player 1 to choose D 2 at the third node; hence, Player 2 would best-respond by choosing d 1 . Anticipating this, Player 1 will choose D 1 at the initial node.</p><p>The example illustrates how iterations of the CSB operator formalize the best-rationalization principle. However, it also illustrates that the latter embodies rather strong assumptions about the players' belief-revision policies.</p><p>We can also clarify the connection between extensive-form rationalizability and common certainty of rationality at a given history h: if a history h is consistent with extensive-form rationalizability, then it is also consistent with rationality and common certainty of rationality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 7. For all histories h ¥ H, in any belief-complete type space, S . 5 [S(h) ×</head><formula xml:id="formula_47">G] ] " implies [h] 5 4 n \ 0 B n h (R) ] ".</formula><p>Note that Proposition 7 only provides a sufficient condition. Reny <ref type="bibr" target="#b25">[26]</ref> provides an example where a non-extensive-form-rationalizable history is consistent with common certainty of rationality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.2.1.</head><p>Strong Belief and Backward Induction. Battigalli <ref type="bibr" target="#b4">[5]</ref> shows that, in generic games with perfect and complete information, extensive-form rationalizability is outcome-equivalent to backward induction (for a related result, see Reny <ref type="bibr" target="#b26">[27]</ref>). Note that, since S is finite and S n+1 ı S n , there is some N \ 0 such that S . =S N . Hence, Proposition 6 also provides a set of sufficient epistemic conditions for the backward-induction outcome: Proposition 8. Suppose the game under consideration has complete and perfect information and no player is indifferent among payoffs at different terminal nodes. Then there exists an integer N \ 0 such that for any beliefcomplete type space, any strategy profile s ¥ proj S CSB N (R) induces the unique backward-induction outcome.</p><p>Our results provide an explicit set of assumptions about the players' beliefs revision processes leading to backward-induction play. But it should </p><formula xml:id="formula_48">m ¥ M=A 1 , p 1 ( • ) ¥ [D(M)] G a ¥ A=A 2 , p 2 ( • | • ) ¥ [D(A)] M S 1 =M, S 1 =M × G S 2 =S 2 =A M Histories H={f} 2 M Player 2's prior about h p 0 ¥ D 0 (G) p 0 (h) &gt; 0 for all h ¥ G. Player 2's belief system n( • | • ) ¥ [D(G)] M Outcome or outcome distribution z ¥ D(G × M × A)</formula><p>be noted that these assumptions do not imply that a player at a non-rationalizable history/node would play and/or expect the backward-induction continuation. Indeed, in certain games this is actually inconsistent with the forward-induction logic of the best-rationalization principle (cf. Reny <ref type="bibr" target="#b26">[27]</ref>). For example, in the game of Fig. <ref type="figure">2</ref>, backward-induction reasoning implies that Player 2, upon being reached, should expect Player 1 to choose D 2 at her next node; as we noted above, our assumptions instead imply that Player 2 rules out D 2 , because A 1 D 2 is strictly dominated by D 1 D 2 for Player 1, whereas A 1 A 2 may at least be justified by the ''unsophisticated'' belief that Player 2 will irrationally play a 1 a 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">STRONG BELIEF AND THE INTUITIVE CRITERION</head><p>The strong belief operator may also be used to analyze equilibrium refinements motivated by forward-induction considerations. As an example, in this section we provide an epistemic characterization of the Intuitive Criterion (Cho and Kreps <ref type="bibr" target="#b14">[15]</ref>).</p><p>Consider a (finite) signaling game: Player 1 (the Sender) is active at the first stage and Player 2 (the Receiver) is active at the second stage; the payoff type of Player 1 is unknown, while the payoff type of Player 2 is known, thus, we may write G 1 =G. For the sake of simplicity, we assume that the set of feasible actions of the Sender does not depend on her payofftype and that the set of feasible actions for the Receiver does not depend on the Sender's action. <ref type="foot" target="#foot_6">20</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table III summarizes our notation for signaling</head><p>The actions of the Sender will be referred to as messages or signals; those of the Receiver will also be called responses.</p><p>In this framework, an external state is given by a tuple s=(m, h, </p><formula xml:id="formula_49">s 2 ) ¥ M × G × A M and</formula><formula xml:id="formula_50">p h 2 ¥ [D(A)] M ) such that, for all h ¥ G, m ¥ M, a ¥ A, (1) if z(m|h) &gt; 0, then m ¥ arg max m -; a -p h 2 (a -| m -) u 1 (h, m -, a -), (2) if z(m, a) &gt; 0, then a ¥ arg max a -; h -z(h -| m) u 2 (h -, m, a -), (3) if z(m) &gt; 0, then p h 2 (a | m)=z(a | m).</formula><p>Our definition of self-confirming-equilibrium outcome agrees with the definition of self-confirming equilibrium with unitary beliefs put forward by Fudenberg and Levine <ref type="bibr" target="#b16">[17]</ref>, if each incarnation h of the Sender is regarded as an individual player selected by chance with probability p 0 (h).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The behavioral strategy p h</head><p>2 is to be interpreted as a conjecture of incarnation h of the Sender about the Receiver. Clearly, every sequential-equilibrium outcome is also a self-confirming-equilibrium outcome. But the converse does not hold, because in a self-confirming-equilibrium outcome the (randomized) choices of different types may be justified by different conjectures about Player 2, and actions following off-equilibrium messages need not be optimal. Cho and Kreps <ref type="bibr" target="#b14">[15]</ref> put forward the Intuitive Criterion as a test for sequential-equilibrium outcomes, but clearly the same criterion can be naturally be applied to self-confirming-equilibrium outcomes (cf. Kohlberg <ref type="bibr" target="#b20">[21]</ref>, p. 23, Footnote 17).</p><p>For any p 0 -feasible outcome z, we let u z 1 (h)=; m, a z(m, a | h) u 1 (h, m, a) denote the expected payoff for type h. For any subset of types " ] G -ı G and message m, BR 2 (G -, m) is the set of best responses to beliefs concentrated on G -given message m. Consider the following procedure.</p><formula xml:id="formula_51">Definition 10 [Intuitive Criterion]. Fix a self-confirming-equilibrium outcome z and a message m ¥ M such that z(m)=0. Let G ¯(m; z)={h ¥ G : u z 1 (h) &gt; max a ¥ BR 2 (G, m) u 1 (h, m, a)} A(m; z)= ˛BR 2 (G 0 G ¯(m; z), m) G ¯(m; z) ] " BR 2 (G, m) G ¯(m; z)="</formula><p>Outcome z satisfies the Intuitive Criterion (IC) if and only if, for every message m ¥ M with z(m)=0 and every payoff-type h ¥ G, there exists an action a ¥ A(m; z) such that</p><formula xml:id="formula_52">u 1 (h, m, a) [ u z 1 (h).</formula><p>Informally, a candidate outcome fails the Intuitive Criterion if a Sender's type may deviate to an off-equilibrium message and expect to obtain a higher payoff than she receives according to z, provided that the Receiver applies forward induction whenever he observes an unexpected message (cf. <ref type="bibr" target="#b14">[15]</ref>).</p><p>Our objective is to clarify the epistemic assumptions leading to this criterion. Cho and Kreps <ref type="bibr" target="#b14">[15]</ref> argue that ''the Intuitive Criterion relies heavily on the common knowledge of the fixed candidate equilibrium outcome and, in particular, attaches a very specific meaning (a conscious attempt to break that equilibrium) to defections from the supposed equilibrium.'' Thus, the equilibrium path plays a different role than the specification of off-equilibrium-path behavior and beliefs. To anticipate, our characterization states that outcome z satisfies the Intuitive Criterion if and only if the assumption that the Receiver's beliefs ''agree'' with z is consistent with certain assumptions involving initial belief and strong belief.</p><p>Say that Player i's beliefs agree with outcome z at state (s i , t i , w -i ) if f i, f (t i ) (the initial first-order beliefs of t i ) yields the same (conditional) probabilities as z. In particular, the event ''the Sender's beliefs agree with z'' is</p><formula xml:id="formula_53">[z] 1 ={(s 1 , t 1 , w 2 ) ¥ W : -m ¥ M, -a ¥ A, z(m) &gt; 0 S f 1, f (t 1 )({s 2 : s 2 (m)=a})=z(a | m)}.</formula><p>Similarly, the event ''the Receiver's beliefs agree with z'' is</p><formula xml:id="formula_54">[z] 2 ={(w 1 , s 2 , t 2 ) ¥ W : -(h, m) ¥ S 1 , f 2, f (t 2 )({(h, m)})=z(h, m)}.</formula><p>Part (1) of the following proposition is a preliminary step of some independent interest, similar in spirit to Theorem A in Aumann and Brandenburger <ref type="bibr" target="#b2">[3]</ref>.</p><p>Part (2) provides two alternative (but closely related) characterizations of the Intuitive Criterion.</p><p>Define the following events:</p><formula xml:id="formula_55">IC z 1 -R 1 5 [z] 1 5 B 1, f (R 2 ) IC z 2 -R 2 5 [z] 2 5 SB 2 (IC z 1 ) IC z -R 1 5 [z] 1 5 B 1, f (IC z 2 )</formula><p>Proposition 11. Fix a p 0 -feasible outcome z.</p><p>(</p><formula xml:id="formula_56">) If 4 i=1, 2 [z] i 5 B i, f (R -i 5 [z] -i ) ]<label>1</label></formula><p>" in some type space, then z is a self-confirming-equilibrium outcome.</p><p>(</p><formula xml:id="formula_57">)<label>2</label></formula><p>The following statements about outcome z are equivalent:</p><p>(a) For any belief-complete type space, {(h, m):</p><formula xml:id="formula_58">z(h, m) &gt; 0} ı proj h × M IC z ; (b) For any belief-complete type space, [z] 2 5 B 2, f (IC z ) ] "; (c) z is a self-confirming-equilibrium outcome satisfying the Intuitive Criterion.</formula><p>We provide some intuition for the characterization of the Intuitive Criterion via the event IC z . First, strong belief in the event</p><formula xml:id="formula_59">IC z 1 =R 1 5 [z] 1 5 B 1, f (R 2 )</formula><p>captures the forward-induction assumption that, upon observing an off-equilibrium message m ¥ M, the Receiver's beliefs are concentrated on types for which m is not equilibrium-dominated, given that the Sender does not expect the Receiver to choose conditionally dominated actions. Second, at each state w ¥ IC z , the Sender is rational, and her initial beliefs agree with z; moreover, she expects the Receiver to play a best response to a belief consistent with equilibrium domination if she chooses to ''deviate'' from z. Then characterization (2.a) follows: z passes the Intuitive Criterion if and only if, for every (h, m) with z(h, m) &gt; 0, there exists a state w ¥ IC z in which the Sender's type is h and she sends message m. (2.b) is essentially a restatement of (2.a) in terms of the initial beliefs of the Receiver.</p><p>6. DISCUSSION 6.1. Extensions</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1.">More General Information Structures and Characterizations</head><p>In order to focus on the properties and applications of strong belief, we have confined our analysis of extensive-form rationalizability to the simplified setting of games with observable actions. However, Proposition 6 immediately extends to general extensive games. Moreover, the result can be generalized in order to incorporate ''exogenous restrictions'' on players' first-order beliefs in the sense that, for any event F about the players' first-order beliefs, one can obtain the behavioral implications of the epistemic assumptions CSB n (R 5 F) (n=1, 2, ...) with a modification of the extensive-form rationalizability procedure. We refer the interested reader to the working-paper version of this article <ref type="bibr" target="#b5">[6]</ref> and to <ref type="bibr" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2.">Other Results on Refinements</head><p>Similarly, the techniques employed in our analysis of the Intuitive Criterion may be adapted to study other refinements for signalling games. For example, equilibrium dominance is characterized as follows.</p><formula xml:id="formula_60">Let ED z 2 - R 2 5 [z] 2 5 SB 2 (R 1 5 [z] 1 ) and ED z =R 1 5 [z] 1 5 B 1, f (ED z 2 ).</formula><p>Then z is a self-confirming equilibrium outcome satisfying the test of equilibrium dominance if and only if {(h, m): z(h, m) &gt; 0} ı proj h × M ED z , and the latter holds if and only if</p><formula xml:id="formula_61">[z] 2 5 B 2, f (ED z ) ] ".</formula><p>In <ref type="bibr" target="#b7">[8]</ref>, we build on a generalization of our Proposition 6 to provide an epistemic characterization of the Iterated Intuitive Criterion. We conjecture that other forward-induction refinements for signalling games and more general incomplete incomplete information games may also be analyzed using a combination of the techniques presented in Sections 4 and 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.3.">Beliefs about Oneself</head><p>In the analysis of static games, it is standard to assume that a player knows her epistemic type and strategy (of course, in an incomplete information setting she also knows her payoff type). We could adapt this assumption to our analysis of dynamic games in several ways. In <ref type="bibr" target="#b5">[6]</ref> and <ref type="bibr" target="#b6">[7]</ref> we assume that players know their epistemic types and, if rational, they assign probability one to their plan of action at each history consistent with it. Versions of our results can be proved for these extended epistemic models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Related Literature</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1.">Extensive-Form Type Spaces</head><p>Finite (hence incomplete) extensive-form type spaces are introduced in Ben Porath <ref type="bibr" target="#b8">[9]</ref> to characterize common certainty of rationality at the beginning of a perfect-information game. Battigalli and Siniscalchi <ref type="bibr" target="#b6">[7]</ref> provide a general analysis of (finite and infinite) type spaces for extensiveform games and show the existence of a belief-complete type space, a building block of our analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2.">Belief Revision</head><p>Belief revision (mostly in a single-person setting) has been studied extensively in the philosophy literature. See, e.g., Gärdenfors <ref type="bibr" target="#b18">[19]</ref> and references therein.</p><p>In that literature, the following alternative framework for belief revision is often employed. First, one fixes a logically closed set of propositions, called a belief set, that an individual accepts as true. Then, for each proposition that the individual may subsequently learn to be true, one considers a corresponding logically closed belief set, representing the individual's new epistemic state. Belief revision is defined via axioms relating prior and posterior belief sets.</p><p>A similar construction and a characterization of strong belief in terms of belief sets can be carried out in the present setting, with the proviso that each player can only learn about the occurrence of a history h ¥ H.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3.">Belief Revision in Games and Forward Induction</head><p>Our paper is related to work by Stalnaker and Board. Stalnaker <ref type="bibr" target="#b30">[31]</ref> puts forward a normal-form, finite epistemic model, which can also be used to analyze extensive-form reasoning. This model is used by Stalnaker <ref type="bibr" target="#b31">[32]</ref> to provide a brief discussion of forward induction and by Board <ref type="bibr" target="#b9">[10]</ref> to characterize some extensive-form solution concepts, including extensiveform rationalizability. Some comments on the relationship between our work and Stalnaker's are warranted.</p><p>From a substantive viewpoint, Stalnaker <ref type="bibr" target="#b31">[32]</ref> independently proposes a notion of ''absolutely robust belief'' that is analogous to our strong belief. He employs this notion to sketch a characterization of the following procedure: perform two rounds of elimination of weakly dominated strategies, followed by iterated strict dominance. In some simple games (such as the one we analyze in Section 3), this procedure singles out the forward-induction outcome.</p><p>Our analysis employs the notion of strong belief to analyze different solution concepts, i.e., extensive-form rationalizability and the Intuitive Criterion. 21 In this respect, Stalnaker's <ref type="bibr" target="#b31">[32]</ref> result complements ours. 21 Stalnaker's iterative procedure is clearly unrelated to the Intuitive Criterion. It also differs from extensive-form rationalizability: for instance, the latter selects the forward-induction outcome in the game Burning Money, whereas Stalnaker's procedure does not. Also observe that, in a large class of games, extensive-form rationalizability is equivalent to iterated weak dominance <ref type="bibr">(Battigalli [5]</ref>).</p><p>As our analysis indicates, extensive-form rationalizability is based on the assumption that, at any history, a player's beliefs about her opponents are consistent with the highest degree of strategic sophistication compatible with observed game play. Stalnaker's procedure is based on the simpler assumption that players believe that their opponents are rational, whenever this is compatible with observed game play.</p><p>The notion of ''degrees of strategic sophistication'' does not play any rôle in Stalnaker's analysis. On the other hand, it is central to our characterization of extensive-form rationalizability. Section 4.1 indicates that formalizing this notion requires some care.</p><p>From a technical standpoint, the main difference between our type spaces and Stalnaker's epistemic model is that, for each state, our model specifies beliefs conditional on observable events only, while Stalnaker's model specifies beliefs conditional on every event, including unobservable events concerning the beliefs of the players. This prevents the construction of belief-complete models by standard methods. 22 Stalnaker and Board are 22 We are not aware of any proof of existence of belief-complete models à la <ref type="bibr">Stalnaker.</ref> thus forced to qualify their characterization results with the proviso that the incomplete model at hand is ''sufficiently rich'' to allow for forwardinduction reasoning in the game under consideration (see the discussion in Section 3.4). This is made precise by Board <ref type="bibr" target="#b9">[10]</ref>. However, this notion of ''richness'' depends crucially on the payoffs of the game, as well as on the specific solution concept one wishes to characterize. Finally, characterizing the notion of richness in any given context is somewhat cumbersome. Adopting belief-complete type spaces makes it possible to avoid these complications altogether.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.4.">Normal-Form Solution Concepts and Forward-Induction Outcomes</head><p>The present paper focuses on explicit forward-induction reasoning in extensive games. However, forward-induction strategies are also selected by appropriate normal-form solution concepts. Epistemic characterizations of two such solution concepts are discussed below.</p><p>It is well-known that iterated weak dominance supports forward-induction outcomes in several games (see, e.g., <ref type="bibr" target="#b23">[24]</ref>, Section 6.6). Brandenburger and Keisler <ref type="bibr" target="#b13">[14]</ref> provide an epistemic characterization of this solution concept. In their model, players' types correspond to lexicographic sequences (a generalization of lexicographic probability systems that allows for an uncountable state space) over the set of opponents' strategies and types. We note that, as in our paper, a crucial ingredient in the analysis is the existence of belief-complete type spaces of this nature, which Brandenburger and Keisler also establish.</p><p>In the context of a finite, normal-form epistemic model, Asheim and Dufwenberg <ref type="bibr" target="#b0">[1]</ref> propose a notion of ''full admissible consistency'' of a player's preferences with the game being played and with the preferences of his opponent. Correspondingly, they define a solution concept, ''full permissibility,'' which selects the forward-induction outcome in games such as the Battle of the Sexes with an outside option. Their main result shows that common ''certain belief'' of full admissible consistency characterizes fully permissible sets of strategies. The authors provide a thorough discussion of the differences and similarities between standard forward-induction arguments and full permissibility, as well as between the latter and iterated weak dominance: see <ref type="bibr" target="#b0">[1]</ref>, Section 5.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.5.">Backward Induction</head><p>Aumann <ref type="bibr" target="#b1">[2]</ref> originated a literature where partitional epistemic models are used to provide sufficient conditions for the backward-induction strategies, or path, in generic perfect-information games (see Section 6 in <ref type="bibr" target="#b6">[7]</ref> for a discussion of this literature). We emphasize that, as was noted in Section 4, Proposition 8 only provides sufficient conditions for the backwardinduction path.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.6.">(Iterated) Intuitive Criteron</head><p>Sobel et al. <ref type="bibr">([30]</ref>, Proposition 2) relate the iterated intuitive criterion (IIC) to extensive-form rationalizability in a modified signalling game. Thus, their result concerns the equivalence of certain iterative deletion procedures. The epistemic characterization of the IIC we provide in <ref type="bibr" target="#b7">[8]</ref> partially builds on their work. Christian Ewerhart (private communication) also provides a non-epistemic analysis of the Intuitive Criterion, whereby players' ''assumptions'' about each other are represented by sets of strategy profiles. The suggested interpretation of these ''assumptions'' is reminiscent of the events appearing in Proposition 11.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX: PROOFS</head><p>Lemma 12. Fix a map y -i : S -i Q T -i . Also, fix a first-order CPS d ¥ D H (S -i ). Then there exists an epistemic type t i ¥ T i such that, for each h ¥ H, g i, h (t i ) has finite support and</p><formula xml:id="formula_62">g i, h (t i )((s -i , y -i (s -i )))=d(s -i | S -i (h)) for all s -i ¥ S -i . Proof. Define a candidate CPS m on S -i × T -i by setting m({(s -i , y -i (s -i ))} | S -i (h) × T -i )=d(s -i | S -i (h))</formula><p>for every h ¥ H, and extending the assignments by additivity. Properties (1) and (2) in Definition 1 follow immediately from the observation that the map s </p><formula xml:id="formula_63">-i W (s -i , y -i (s -i )) yields an embedding of 1 h ¥ H supp[d( • | S -i (h))] ı S -i (a finite set) in S -i × T -i , so that, for every h ¥ H, m( • | S -i (h) × T -i ) is indeed a probability measure on S -i × T -i .</formula><formula xml:id="formula_64">(S -i ) such that s i ¥ r i (d) and -m=0, ..., n -1, -h ¥ H : S m+1 -i 5 S -i (h) ] " S d(S m+1 -i | S -i (h))=1 (1)</formula><p>Proof. Omitted (for a similar result see <ref type="bibr" target="#b4">[5]</ref>, Theorem 1 and Corollary 1).</p><p>Proof of Proposition 6. (i) We proceed by induction. Part of the argument consists in showing that, for every n \ 0 and i ¥ I, we can associate to each s i an epistemic type t i =y n+1 i (s i ) in such a way that (s i , y n+1 i</p><formula xml:id="formula_65">(s i )) i ¥ I ¥ CSB n (R) whenever (s i ) i ¥ I ¥ S n+1 . (Step 0.) Fix (s, t) ¥ CSB 0 (R)=R. Then by definition s i ¥ r i (f i (t i )) for every i ¥ I, which implies that s ¥ S 1 .</formula><p>Conversely, for each i ¥ I and s i ¥ S i , pick y 0 i (s i ) ¥ T i arbitrarily. Now fix s ¥ S 1 , and for each player i ¥ I, let d ¥ D H (S -i ) be such that s i ¥ r i (d). Now Lemma 12 yields a type</p><formula xml:id="formula_66">y 1 i (s i ) ¥ T i such that g i, h (y 1 i (s i ))({(s - j , y 0 j (s j )) j ] i }) =d(s - -i | S -i (h)) for every s - -i ¥ S -i , and hence f i (y 1 i (s i ))=d. Thus, (s i , y 1 i (s i )) i ¥ I ¥ R. Finally, for each i ¥ I, we complete the definition of the function y 1 i ( • ) by letting y 1 i (s i )=y 0 i (s i ) for s i ¥ S i 0 S 1 i . (</formula><p>Step n &gt; 0.) Now assume that Part (i) has been shown to hold for m=0, ..., n -1, and that, for each such m, we have defined functions</p><formula xml:id="formula_67">y m+1 i : S i Q T i such that (s i , y m+1 i (s i )) i ¥ I ¥ CSB m (R) whenever s ¥ S m+1 .</formula><p>Finally, let the functions y 0 i ( • ) be defined as above. We will prove that (a) (s, t) ¥ CSB n (R) implies s ¥ S n+1 and (b) we can construct functions y n+1 i : S i Q T i such that (s i , y n+1 i (s i )) i ¥ I ¥ CSB n (R) whenever s ¥ S n+1 . Note that, for every n \ 1,</p><formula xml:id="formula_68">CSB n (R)=R 5 3 i ¥ I 3 3 n -1 m=0 SB i (W i × [proj W -i CSB m (R)]) 4 . (2)</formula><p>Also note that, for any i ¥ I, h ¥ H and event E such that</p><formula xml:id="formula_69">E=W i × proj W -i E (that is, E ¥ A -i ), E 5 (S(h) × T) ] " Z [proj S -i E] 5 S -i (h) ] ".<label>(3)</label></formula><p>(a) Now consider (s, t) ¥ CSB n (R) and fix i ¥ I. Let d= f i (t i ) be the first-order belief of type t i . Equation (2) yields s i ¥ r i (d). By the induction hypothesis, proj S -i CSB m (R)=S m+1 -i for every m=0, ..., n -1. Thus, (3) implies that, for every m=0, ..., n -1 and h ¥ H, S m+1 for every i ¥ I and s - -i ¥ S -i (recall that S 0 -i =S -i , so m -i ( • ) is welldefined). Now consider s ¥ S n+1 and fix a player i ¥ I. By Lemma 13, we can find a CPS d ¥ D H (S -i ) satisfying <ref type="bibr" target="#b0">(1)</ref>. By <ref type="bibr" target="#b2">(3)</ref>  </p><formula xml:id="formula_70">(s i ))({(s - j , y m -i (s - -i ) j (s - j )) j ] i })=d(s - -i | S -i (h))</formula><p>for all h ¥ H and s - -i ¥ S -i . Now note that, for m=0, ..., n -1, . This conludes the proof of part (i).</p><formula xml:id="formula_71">s - -i ¥ S m+1 -i S (s - j , y m -i (s - -i ) j (s - j )) j ] i ¥ proj W -i CSB m (R)</formula><p>(ii) By Lemma 13, S n ] " for every n \ 0. Thus, Part (i) implies that CSB n (R) ] " for every n \ 0. Then CSB . (R) is nonempty, because T is compact by assumption and the nested, nonempty closed sets {CSB n (R)} n \ 0 form a family with the finite intersection property. Now suppose (s, t) ¥ CSB . (R). Since, by Part (i), S n+1 =proj S CSB n (R) for any n \ 0, we conclude that s ¥ S n for every n \ 1; so s ¥ 4 n \ 1 S n =S . . Hence proj S CSB . (R) ı S . . Next, let N be the smallest integer such that S N =S . (which must exist because S is finite). Pick any s ¥ S N =S . and consider the sequence of sets M(m, s)=CSB (N -1)+m (R) 5 ({s} × T), m \ 0 (let M(0, s)={s} × T if N=0). Each set M(m, s) is nonempty and closed; also, the sequence of sets M(m, s) is decreasing, and hence has the finite intersection property. Then there is some profile of epistemic types t such that (s, t) ¥ 4 m \ 0 M(m, s) ı CSB . (R). It follows that S . ı proj S CSB . (R). L Proof of Proposition 7. We claim that, for all n \ 0 and h ¥ H, S . 5 S(h) ] " implies CSB n (R) ı B n h (R); the assertion of the Proposition then follows immediately.</p><p>By definition, CSB 0 (R)=B 0 h (R)=R, so the claim is true for n=0. Assume it is true for some n \ 0. Recall that CSB n+1 (R)=CSB n (R) 5 SB(CSB n (R)). Suppose that S . 5 S(h) ] ". By Proposition 6, this implies CSB n (R) 5 We often need to associate an epistemic type to every payoff typemessage pair or, respectively, strategy. When this is the case, we denote the epistemic type by y 1 (h, m) and y 2 (s 2 ) (cf. <ref type="bibr">Lemma 12)</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIG. 1 .</head><label>1</label><figDesc>FIG. 1.The battle of the sexes with an outside option.</figDesc><graphic coords="11,94.83,31.09,151.20,110.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>-i 5 S</head><label>5</label><figDesc>-i (h)= [proj S -i CSB m (R)] 5 S -i (h) ] " if and only if [W i × proj W -i CSB m (R)] 5 (S(h) × T) ] ".The definition of strong belief and (2) imply that, whenever the latter condition is satisfied,g i, h (t i )(proj W -i CSB m (R))= d(S m+1 -i | S -i (h))=1. Therefore d satisfies<ref type="bibr" target="#b0">(1)</ref>, and Lemma 13 implies thats i ¥ S n+1 i . (b) Define m -i (s - -i )=max{m=0, ..., n : s - -i ¥ S m -i }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>[h]  ] ". Then, by definition of strong belief, SB(CSB n (R)) ı B h (CSB n (R)). By the induction hypothesis, CSBn (R) ı B n h (R). By monotonicity of B h , B h (CSB n (R)) ı B h (B n h (R))=B n+1 h (R). Therefore, we conclude that S . 5 S(h) ] " implies CSB n+1 (R) ı SB(CSB n (R)) ı B h (CSB n (R)) ı B n+1 h (R). L Proof of Proposition 11. Preliminaries. Note first that we can identify D(S 2 ) with D H (S 2 ), because S 2 (m)=S 2 (f)=S 2 for all m. To simplify the notation, for any CPS n ¥ D H (S 1 ), we write n(h, m)=n((h, m) | S 1 ) and n(h | m)=n((h, m) | G × {m}). Let m ¥ D(S 2 ), n ¥ D H (S 1 ), p 2 ¥ [D(A)] M , z ¥ D(G × M × A).We say that:(i) m agrees with z if -m, -a, z(m) &gt; 0 implies z(a | m)=m({s 2 : s 2 (m)=a}); (ii) n agrees with z if -h, -m, n(h, m)= z(h, m); (iii) p 2 agrees with z if -m, -a, z(m) &gt; 0 implies p(a | m)=z(a | m); (iv) m is the mixed representation of p 2 , and p 2 is the behavioral representation of m, if -s 2 , m(s 2 )=&lt; m ¥ M p 2 (s 2 (m) | m); (v)m is a best reply for h to p 2 , written (h, m) ¥ r 1 (p 2 ), if (h, m) ¥ r 1 (m) and m is the mixed representation of p 2 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Definition 4. Fix a CPS m i ¥ D H (S -i ). A strategy s i ¥ S i is a sequential best reply to m i for payoff type h i ¥ G i if and only if, for every h ¥ H(s i ) and every s</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 1</head><label>1</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II The</head><label>II</label><figDesc>Type Space T -</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>a state of the world is a tuple (s, t 1 , t 2 ) where t 1 and t 2 are-respectively-the epistemic types of the Sender and Receiver in a (belief-complete) type space based on S=S 1 × S 2 and H. We say that outcome z is p 0 -feasible if there is a behavioral profile (p 1 , p 2 ) such that (p 0 , p 1 , p 2 ) generates z. With a slight abuse of notation we denote the marginal and conditional probabilities derived from z as follows: Definition 9. A p 0 -feasible outcome z is a self-confirming-equilibrium outcome if there is a |G|-tuple of behavioral strategies (p h2 ) h ¥ G (where</figDesc><table><row><cell>z(h),</cell></row><row><cell>z(m), z(m, a), z(m | h), z(m, a | h), z(h | m), z(a | m). Note that if z is</cell></row><row><cell>p 0 -feasible z(m | h) and z(m, a | h) are always well defined, because</cell></row><row><cell>z(h)=p 0 (h) &gt; 0 for all h; moreover, z(a | m, h)=z(a | m).</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>By the same argument, m must also satisfy Property (3), i.e., it must be a CPS; of course, each m( • | S -i (h) × T -i ) has finite support by construction. Since g i is onto, there exists a type t i ¥ T i such that g i (t i )=m. By construction, t i satisfies the property stated in the Lemma. L Lemma 13. For every i ¥ I and n \ 0, S n+1 i ] "; furthermore s i ¥ S n+1 i if and only if there exists a CPS d ¥ D H</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>and the induction hypothesis, for h ¥ H and m=0, ..., n -1,[W i × proj W -i CSB m (R)] 5 (S(h) × T) ] " if and only if S m+1 -i 5 S -i (h) ] ". Moreover, by (1), if the latter inequality holds, then d(S m+1 -i | S -i (h))=1. Define y -i : S -i Q T -i by letting y -i (s - -i )=(y m -i (s -</figDesc><table><row><cell>j</cell><cell>-i )</cell><cell>(s -</cell></row></table><note><p>j )) j ] i -s - -i ¥ S -i ; Lemma 12 now yields a type y n+1 i (s i ) ¥ T i such that g i, h (y n+1 i</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>))(proj W -i CSB m (R))=1 for any m=0...n -1 and h ¥ H such that [W i × proj W -i CSB m (R)] 5 (S(h) × T) ] ", because, by the preceding argument, supp d( • | S -i (h)) ı S m+1 )) i ¥ I which, by (2), satisfies (s i , y n+1 i (s i )) i ¥ I ¥ CSB n (R). This shows how to define the functions y n+1</figDesc><table><row><cell></cell><cell>(s -j , y m -i (s -j ) j</cell><cell>(s -</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>-i</cell><cell>at any</cell></row><row><cell cols="2">such history.</cell><cell></cell><cell></cell></row><row><cell cols="4">Moreover, by construction f i (y n+1 i</cell><cell>(s i ))=d, so s i ¥ r i (f i (y n+1 i</cell><cell>(s i ))).</cell></row><row><cell cols="5">Repeating the argument for every i ¥ I yields a profile of types</cell></row><row><cell>(y n+1 i</cell><cell cols="2">(s i i</cell><cell cols="2">on S n+1 i</cell><cell>. To complete the induction step,</cell></row><row><cell cols="5">for each i ¥ I we now extend y n+1 i y n+1 i (s -i )=y n i (s -</cell><cell>to the whole S i by letting</cell></row></table><note><p><p><p><p>because,</p><ref type="bibr" target="#b0">(1)</ref> </p>m -i (s - -i ) \ m+1 if s - -i ¥ S m+1 -i ; (2) if m -i (s - -i ) \ 1 then, by the induction hypothesis, j )) j ] i ¥ proj W -i CSB m -i (s --i ) -1 (R);</p>and finally (3) the sets {CSB m (R)} m \ 0 are monotonically decreasing. But then g i, h (y n+1 i (s i i ) for every s - i ¥ S i 0 S n+1 i</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>In a different formal setting, Stalnaker<ref type="bibr" target="#b31">[32]</ref> independently introduced the notion of ''robust belief,'' which captures a similar intuition.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>For a complete definition see Fudenberg and Tirole<ref type="bibr" target="#b17">[18]</ref>, §3.3, §8.2.3 or Osborne and Rubinstein<ref type="bibr" target="#b23">[24]</ref>, §6.3.2, §12.3 (note that<ref type="bibr" target="#b23">[24]</ref> uses ''perfect information'' to refer to all games with observable actions, including those featuring simultaneous moves).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_2"><p>It would make sense to assume that g i is injective, but this is immaterial for our arguments. Continuity of the mapping g i means that the index set T i inherits the topological structure of the beliefs set D H (W -i ). For more on this see<ref type="bibr" target="#b22">[23]</ref> and<ref type="bibr" target="#b6">[7]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_3"><p>We comment on the role of actions at certain counterfactual histories before Definition 4.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_4"><p>We use ''complete'' in the same sense as Brandenburger<ref type="bibr" target="#b10">[11]</ref>, who shows (in a different framework) that a (belief-) complete, filter-theoretic type space does not exists (see also<ref type="bibr" target="#b12">[13]</ref>). Of course, this notion of completeness is not to be confused with the topological one.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_5"><p>It is easy to extend the definition of B i, h to all Borel subsets of W in a manner consistent with all properties of falsifiable beliefs: see, e.g.,<ref type="bibr" target="#b6">[7]</ref>. However, this extension requires additional notation, and is irrelevant for our analysis.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="20" xml:id="foot_6"><p>The first assumption is already part of the (relatively) general framework adopted here. Removing these assumptions is straightforward but requires a more complex notation. games.STRONG BELIEF AND FORWARD INDUCTION</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We prove <ref type="bibr" target="#b1">(2)</ref> first. The argument involves six claims. For some of them we only sketch the proof. </p><p>Proof. Fix (h, m) ¥ S 1 and suppose there exists t 1 as above. Let p h, m 2 be the behavioral representation of f 1, f (t 1 ). Then (h, m) ¥ r 1 (p h, m 2 ) and p h, m 2 agrees with z. To see that Eq. ( <ref type="formula">4</ref>) is also satisfied, observe first that</p><p>Conversely, suppose that (h, m) ¥ r 1 (p h, m 2 ), p h, m 2 agrees with z and (4) holds. Let m ¥ D(S 2 ) be the mixed representation of p h, m 2 . Then (h, m) ¥ r 1 (m) and m agrees with z. Moreover, for every s 2 ¥ S 2 such that m(s 2 ) &gt; 0, and for every m -¥ M, s 2 (m -) ¥ BR 2 (G, m -); thus, by Claim 1, there exists an epistemic type y 2 (s 2 ) such that (s 2 , y 2 (s 2 )) ¥ proj W 2 R 2 . By Lemma 12, there exists an epistemic type</p><p>-m, -a, z(m, a) &gt; 0 2 a ¥ BR 2 (G, m) (8) 1 (h), as claimed in <ref type="bibr" target="#b5">(6)</ref>.</p><p>To see that (8) holds, note that the assumption implies  <ref type="formula">6</ref>), <ref type="bibr" target="#b6">(7)</ref>, and (8) hold and, moreover, there exists n ¥ D H (S 1 ) such that s 2 ¥ r 2 (n), n agrees with z and</p><p>Proof. (Only if). Fix s 2 ¥ S 2 . If t 2 ¥ T 2 as above can be found, then in particular</p><p>] ", so Claim 3a implies that ( <ref type="formula">5</ref>), ( <ref type="formula">6</ref>), <ref type="bibr" target="#b6">(7)</ref>, and (8) hold. Let n=f 2 (t 2 ). Then s 2 ¥ r 2 (n) and n agrees with z. To show that (9) also holds, consider</p><p>, where a(h g , m -) is as in Eq. ( <ref type="formula">7</ref>); and finally let p</p><p>) and p h g , m 2 satisfies (4). Thus, by Claim 2, there exists</p><p>2 ), (4) holds (see Claim 2) and <ref type="formula">5</ref>)). Thus, h ¨G ¯(m; z) and Eq. ( <ref type="formula">9</ref>) must hold. (If). Suppose that n ¥ D H (S 1 ) agrees with z, s 2 ¥ r 2 (n) and Eq. ( <ref type="formula">5</ref>), ( <ref type="formula">6</ref>), ( <ref type="formula">7</ref>), <ref type="bibr" target="#b7">(8)</ref>, and (9) are satisfied. For all (h, m) such that z(h, m) &gt; 0, let p h, m 2 the behavioral strategy that agrees with z and satisfies p h, m 2 (a(h, m -) | m -) =1 for all m -with z(m -)=0, where the action a(h, m -) is as in Eq. <ref type="bibr" target="#b6">(7)</ref>.</p><p>Equations ( <ref type="formula">5</ref>), <ref type="bibr" target="#b5">(6)</ref>, and <ref type="bibr" target="#b6">(7)</ref> ensure that (h, m) ¥ r 1 (p h, m 2 ). Moreover, p h, m 2 satisfies Eq. ( <ref type="formula">4</ref>), so by Claim 2 we can find an epistemic type</p><p>Thus, any pair in the support of n( • | S 1 ) can be matched with a suitable epistemic type. Hence, by Bayes' Rule, the same is true of points (h, m) in the support of n( • | m) for all messages m with z(m) &gt; 0.</p><p>Next, we consider pairs (h, m) such that n(h | m) &gt; 0 and z(m)=0. If G ¯(m; z)=G, choose an epistemic type y 1 (h, m) arbitrarily. Otherwise, by Eq. 9 and the definition of G ¯(m; z), there exists</p><p>be the behavioral strategy that agrees with z and satisfies</p><p>2 ) and Eq. ( <ref type="formula">4</ref>) holds, so Claim 2 yields an epistemic type y 1 (h, m) such that (h, m, y 1 (h, m)) ¥ proj W 1 IC z 1 . By Lemma 12, there exists t 2 ¥ T 2 such that, for all (h, m) ¥ S 1 and h ¥ H={"} 2 M,</p><p>z] 2 ; the above construction also ensures that g 2, f (t 2 )(proj W 1 IC z 1 )=1, and similarly g 2, m (t 2 )(proj</p><p>agrees with z and (4) holds. Therefore, since z(m)=0, there must exist</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>and only if z is a selfconfirming equilibrium that satisfies the Intuitive Criterion. (Only if).</head><p>The assumption implies that IC z ] "; hence, IC z 2 ] " and [z] 2 5 B 2, f (IC z 1 ) ] ". Claim 3a then implies that Eqs. ( <ref type="formula">5</ref>) and ( <ref type="formula">6</ref>) hold.</p><p>Moreover, for every (h, m) with z(h, m) &gt; 0, there exists an epistemic type</p><p>. For any such pair (h, m), let p h, m 2 be the behavioral representation of f 1, f (y 1 (h, m)); then p h, m 2 agrees with z, and m is a best reply for h to p h, m 2 . In particular, for all mOE with z(mOE)=0, there exists an action a(mOE, h) such that p h, m 2 (a(mOE, h) | mOE) &gt; 0 and u z 1 (h) \ u 1 (h, mOE, a(mOE, h)). Furthermore, we claim that (a) for all mOE ¥ M such that z(mOE)=0, a(mOE, h) ¥ A(z; mOE); and (b) for all (mOE, a) ¥ M × A such that z(mOE, aOE) &gt; 0, a ¥ arg max aOE ; hOE z(hOE | mOE) u 2 (hOE, mOE, a).</p><p>To see this, note first that, for all (mOE, a)</p><p>Claim 3b then implies that, for some CPS n ¥ D H (S 1 ) that agrees with z, s 2 ¥ r 2 (n) and Eq. ( <ref type="formula">9</ref>) holds. Thus, in particular, s 2 (mOE) ¥ arg max a ; hOE n(hOE | mOE) u 2 (hOE, mOE, a). If z(mOE)=0, Eq. ( <ref type="formula">9</ref>) implies that n(G ¯(mOE; z) | mOE)=0 whenever G ¯(mOE; z) ] G, so (a) holds. If z(mOE, a) &gt; 0, then (b) follows because n agrees with z.</p><p>To see that z is a self-confirming equilibrium, for every h ¥ G, let p h 2 be a behavioral strategy that agrees with z and such that p h 2 (a(m, h) | m)=1 for all m ¥ M with z(m)=0. By the preceding observations, the profile {p h 2 } h ¥ G satisfies Conditions (1) and (3) in Definition 9. Moreover, (b) above shows that Condition (2) is also satisfied.</p><p>Finally, for all m, h with z(h, m)=0, (a) above shows that the actions a(m, h) satisfy Definition 10, so z passes the Intuitive Criterion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(If)</head><p>. Suppose now z is a self-confirming equilibrium that passes the Intuitive Criterion. By Definition 10, for every h ¥ G and m ¥ M with z(m)=0, there exists a(h, m) ¥ A(m; z) such that u z 1 (h) \ u 1 (h, m, a(h, m)), and a belief</p><p>Fix h ¥ G and define a behavioral strategy p h 2 as follows: p h 2 agrees with z, and p h 2 (a(h, m) | m)=1 for all m ¥ M with z(m)=0. Observe that, by the choice of actions a(h, • ) and Conditions (1) and (3) in Definition 9, z(h, m) &gt; 0 implies (h, m) ¥ r 1 (p h 2 ). Correspondingly, define a belief system n h as follows: n h agrees with z, and n</p><p>By construction, n h satisfies Eq. ( <ref type="formula">9</ref>). Moreover, let m h be the mixed representation of p h 2 ; for every strategy s 2 ¥ supp m h , Condition (2) in Definition 9 and the choice of n h, m for z(m)=0 ensure that s 2 ¥ r 2 (n h ). Finally, Condition (2) also implies that z satisfies Eq. ( <ref type="formula">8</ref>), and Conditions (1) and (3) imply that it satisfies Eqs. ( <ref type="formula">5</ref>), <ref type="bibr" target="#b5">(6)</ref>, and (7) as well. Therefore, by Claim 3b, for every s 2 ¥ supp m h there exists y</p><p>By Lemma 12, there exists t 1 such that</p><p>The proof is straightforward, and is therefore omitted. To prove Part (1), note first that, if [z] 2 5 B 2, f (R 1 5 [z] 1 ) ] ", the proof of Claim 3a shows that Eqs. ( <ref type="formula">5</ref>) and ( <ref type="formula">6</ref>) hold, whereas Eq. ( <ref type="formula">7</ref>) is replaced by the weaker condition z(m)=0 S -h, ,a(m, h) ¥ A : u 1 (h, m, a) [ u z 1 (h). This implies that it is possible to define a tuple of behavioral strategies {p h 2 } as in the ''only if'' part of the proof of Claim 4, so that Conditions (1) and (3) of Definition 9 hold. Also, the proof of Claim 3b shows that, if (s 2 , t 2 ) ¥ proj W 2 R 2 5 [z] 2 , then there exists a CPS n that agrees with z and such that s 2 ¥ r 2 (n). Then, as in the proof of the ''only if'' part of Claim 4,</p><p>implies that, whenever z(m, a) &gt; 0, there exists s 2 ¥ supp f 1, f (t 1 ) such that s 2 (m)=a ¥ arg max aOE ; h z(h | m) u 2 (h, m, aOE). Hence, Condition (2) also holds, and the proof of Proposition 11 is complete. L</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Admissibility and common belief, Memorandum 07/2000</title>
		<author>
			<persName><forename type="first">G</forename><surname>Asheim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dufwenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
		<respStmt>
			<orgName>Department of Economics, University of Oslo</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Backward induction and common knowledge of rationality</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Aumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Games Econ. Behav</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="6" to="19" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Epistemic conditions for Nash equilibrium</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Aumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Brandenburger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="1161" to="1180" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<author>
			<persName><forename type="first">P</forename><surname>Battigalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Strategic rationality orderings and the best rationalization principle</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="178" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On rationalizability in extensive games</title>
		<author>
			<persName><forename type="first">P</forename><surname>Battigalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Theory</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="40" to="61" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">An epistemic characterization of extensive-form rationalizability, Social Science Working Paper 1009</title>
		<author>
			<persName><forename type="first">P</forename><surname>Battigalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Siniscalchi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Hierarchies of conditional beliefs and interactive epistemology in dynamic games</title>
		<author>
			<persName><forename type="first">P</forename><surname>Battigalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Siniscalchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Theory</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="188" to="230" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Rationalization and Incomplete Information</title>
		<author>
			<persName><forename type="first">P</forename><surname>Battigalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Siniscalchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">mimeo</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rationality, Nash equilibrium and backwards induction in perfect information games</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ben-Porath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rev. Econ. Stud</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="23" to="46" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Algorithmic characterization of rationalizability in extensive-form games, mimeo, Brasenose College</title>
		<author>
			<persName><forename type="first">O</forename><surname>Board</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>Oxford University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">On the existence of a &apos;complete&apos; belief model</title>
		<author>
			<persName><forename type="first">A</forename><surname>Brandenburger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<pubPlace>Harvard Business School</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Working Paper 99-056</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Hierarchies of beliefs and common knowledge</title>
		<author>
			<persName><forename type="first">A</forename><surname>Brandenburger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dekel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Theory</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="189" to="198" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">An impossibility theorem on beliefs in games</title>
		<author>
			<persName><forename type="first">A</forename><surname>Brandenburger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Keisler</surname></persName>
		</author>
		<idno>00-10</idno>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Harvard Business School</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Working Paper</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Epistemic conditions for iterated admissibility, mimeo</title>
		<author>
			<persName><forename type="first">A</forename><surname>Brandenburger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Keisler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<pubPlace>Harvard Business School</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Signalling Games and Stable Equilibria</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kreps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quart. J. Econ</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="179" to="221" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">R</forename><surname>Fagin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Moses</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reasoning About Knowledge</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Self-confirming equilibrium</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fudenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="523" to="545" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">D</forename><surname>Fudenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tirole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Game Theory</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">P</forename><surname>Gärdenfors</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge in Flux</title>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Games of incomplete information played by Bayesian players. Parts I, II, III</title>
		<author>
			<persName><forename type="first">J</forename><surname>Harsanyi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Manage. Sci</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="486" to="502" />
			<date type="published" when="1967">1967-68</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Refinement of Nash Equilibrium: The Main Ideas, in &apos;&apos;Game Theory and Applications</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kohlberg</surname></persName>
		</author>
		<editor>T. Ichiishi, A. Neyman, and Y. Tauman</editor>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Academic Press</publisher>
			<pubPlace>San Diego</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On the strategic stability of equilibria</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kohlberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Mertens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="1003" to="1037" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Formulation of Bayesian analysis for games with incomplete information</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Mertens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Game Theory</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">A Course in Game Theory</title>
		<author>
			<persName><forename type="first">M</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rubinstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Rationalizable strategic behavior and the problem of perfection</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pearce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="1029" to="1050" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Rationality, common knowledge and the theory of games, mimeo</title>
		<author>
			<persName><forename type="first">P</forename><surname>Reny</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
		</imprint>
		<respStmt>
			<orgName>Department of Economics, Princeton University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Backward induction, normal-form perfection and explicable equilibria</title>
		<author>
			<persName><forename type="first">P</forename><surname>Reny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="626" to="649" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On a new axiomatic theory of probability</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rênyi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Math. Acad. Sci. Hungar</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="285" to="335" />
			<date type="published" when="1955">1955</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Comments on the interpretation of game theory</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rubinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="909" to="904" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Fixed-equilibrium rationalizability in signaling games</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sobel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Stole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Zapater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Theory</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="304" to="331" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Knowledge, belief, and counterfactual reasoning in games</title>
		<author>
			<persName><forename type="first">R</forename><surname>Stalnaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econ. Philos</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="133" to="163" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Belief revision in games: forward and backward induction</title>
		<author>
			<persName><forename type="first">R</forename><surname>Stalnaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Soc. Sci</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="31" to="56" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Stability and Perfection of Nash Equilibria</title>
		<author>
			<persName><forename type="first">E</forename><surname>Van Damme</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
	<note>nd ed.</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
