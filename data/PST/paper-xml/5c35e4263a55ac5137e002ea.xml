<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adaptive Generation of Structured Medical Report using NER regarding Deep Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Cheng-Tse</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hsiao-Ko</forename><surname>Chang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ji-Han</forename><surname>Liu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Graduate Institute of Networking and Multimedia</orgName>
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Jyh-Shing</forename><forename type="middle">Roger</forename><surname>Jang</surname></persName>
							<email>jang@csie.ntu.edu.tw</email>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<settlement>Taipei</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Adaptive Generation of Structured Medical Report using NER regarding Deep Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TAAI.2018.00012</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>chest x-ray medical reports</term>
					<term>deep learning</term>
					<term>NER model training</term>
					<term>dependency parsing</term>
					<term>relation extracting</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The structured electronic medical record is the basis for computers to process and achieve the target of precise diagnosis and treatment automatically using the knowledge and features of the techniques such as machine learning and artificial intelligence (AI). Because of the increasing demands on improving the efficiency and the flexibility during the step or phase of classification and extraction, providing the expansion mechanism for the automatic adaption of new NER (Named Entity Recognition, NER) model training during the NER model training stage anytime when the new entities/tags shall be learned and classified and hence the related knowledge database (DB) shall be expanded automatically. The proposed method includes a training stage involving the step of adaptiveimproved NER model training for the chest x-ray medical reports/files and a test stage involving the step of the dependency parsing and the relation extracting to be perform sequentially, and thus the goals of automatic information extraction and structured medical report generation using the machine learning technique, and the optimization and accuracy improvement of the doctor's work and performance through referring to the structured medical report for diagnosis and treatment can be achieved.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>The structured electronic medical record is the basis for computers to understand, automatically generate or learn by implementing the methods such as the deep recursive neural network (deep RNN) constructed by stacking multiple recursive layers <ref type="bibr" target="#b0">[1]</ref> from the unstructured medical records, and apply for obtaining or embedding the specific codes by matching the structured output generated consisting of findings and modifiers automatically <ref type="bibr" target="#b1">[2]</ref>  <ref type="bibr" target="#b2">[3]</ref>. In particularly, based on the structured electronic medical records, the relationship between some medical subjects such as the symptoms, diseases, drugs and inspection and their probabilities can be inferenced and calculated more easier, and further the knowledge map of the medical field and the well-organized medical record data can be constructed to optimize the doctor's work and reduce the cost in the diagnosis and treatment. Hence, the structured electronic medical records also play a major role in clinical medical research, and it is believed that the auto-analysis or statistical analysis for judging the medicine prescribed by the doctor and the prediction the probability of misdiagnosis according to the symptoms and previous medical records is helpful for the doctors to search the relevant medical records and discover potential knowledge connections more intelligently. However, it seems that the doctors usually make the medical records manually and unstructured, and thus it raises the issues in lacking the well-structured medical records data and the inefficiency.</p><p>There are various aspects and researchs <ref type="bibr" target="#b3">[4]</ref> trying to solve the problem mentioned by deploying the skills of computer science. For instance, Anna K. et al. <ref type="bibr" target="#b4">[5]</ref> implement an environment/information extraction (IE) platform for extracting the mammogram reports collected from various Polish health care provider and transforming them into the attribute-value structures by the simplified mammographic ontology preset or selected, Taira et al. <ref type="bibr" target="#b5">[6]</ref> develop a natural language processor and a graphical user interface (GUI) within a system that the radiologist requires no reporting style changes in creating their input radiology free-text document, Hassanpour et al. <ref type="bibr" target="#b6">[7]</ref> describe a machine learning system to annotate radiology reports, extract report contents according to an information model, and use the discriminative sequence classifiers for named-entity recognition to extract and organize clinically significant terms and phrases consistent with the information model, and Gupta et al. <ref type="bibr" target="#b7">[8]</ref> proposed a hybrid approach for information extraction that combines dependency-based parse tree with distributed semantics for generating structured information frames about findings/abnormalities from the free-text mammography reports. In addition, Gupta's method or algorithm implemented is associated with Stanford Dependency Parser and BIRSDS-Ontology recited from the prior research proposed by Liberman et al. <ref type="bibr" target="#b8">[9]</ref>.</p><p>Actually, Gupta's research is not suitable for realistic situation because it is too complicated in the algorithm and lacking flexibility due to it provides the fixed and predefined categories for the classification of the identified entity so that it may not suitable for the simple and literal medical report such as chest x-ray report, and further it may runs in the opposite direction to the goal of information extraction automatically for deploying fixed and pre-defined categories for the entities extracted by the ordinary NER (Named Entity Recognition, NER) tools, such as Stanford NER [10] or NLTK NER <ref type="bibr">[11]</ref>, and thus the new tags may not be classified successfully using the current model and then the model shall be adjusted or adapted automatically to a new one for fulfilling the new demands by taking advantage of the technique such as machine learning can't be achieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. THE PROPOSED METHOD</head><p>In this paper, our method of deploying a modeling mechanism for the new model creation or adaption from the current model, and a different and novel relation extraction method/ algorithm. The proposed method shown in Figure <ref type="figure" target="#fig_0">1</ref> includes two stages. In the training stage, the doctors of the chest department provide the unstructured electronic medical record texts (socall free text") as the chest report file. After preprocessing the file for generating the content of chest database shown in Figure <ref type="figure" target="#fig_0">1</ref>, we store them for the chest database creation or expansion, performing NER training and modeling using NeuroNER <ref type="bibr" target="#b9">[12]</ref> and then generating the current or the new model, and hence determining whether the new chest x_ray tags exist or not that confirmed by an expert. If there exist the new tags can't be classified based on the current model, performing the previous step for chest database (DB) expansion and repeat the step of NER training and modeling and generating the new model, and the training stage is complete while no new tags shall be classified. Our method classifies those entities such as "calcified mas", "upper abdomen", "PTCD", etc., into one of three categories/classes such as "Finding, Location, Implant" and store them with some contents written in the medical records as the annotated tags into a chest x_ray data file of knowledge database such as that shown in Table <ref type="table" target="#tab_0">I</ref> below.</p><p>Consequently, in the testing stage as shown in Figure <ref type="figure" target="#fig_0">1</ref>, we deploy the new model for the new chest report file to extract the entities, perform the step of dependency parsing to the new chest report file as well, and then perform the step of relation extraction for generating the structured electronic medical record.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. The structured chest x_ray report generated in the test stage</head><p>In our experiments, the amount of the new unstructured chest x-ray report files is 3,312, and the text of each new unstructured report file is segmented to 3 or more sentences during the step of dependency parsing, i.e., the amount of sentence "n" listed in the Table III is 9,942.</p><p>After deploying the new NER model to one or more new unstructured chest x-ray report files differing from those unstructured chest x-ray report files provided by the doctor for training in the training stage, we obtain the structure reports for a normal case and several abnormal ones can be illustrated and explained briefly below in the test stage.</p><p>The structure report for a normal case shown in Figure <ref type="figure" target="#fig_1">2</ref> reveals that the keywords in accordance with a healthy or normal status of a potential patient or an individual taking physical examination are "Normal" and "No definite". Accordingly, it is believed that the readability of the wellorganized and structured report may optimize the doctor's work and reduce the cost in the diagnosis and treatment. In addition, some structure reports for the abnormal cases are shown in Figure <ref type="figure" target="#fig_3">3 and 4</ref> respectively. The structure reports reveal that the keywords in accordance with the abnormal status of potential patients are "opacity" and "haziness", and the general format of the structured record applied to the case shown in Figure <ref type="figure">3</ref> is "finding opacity at location left apical lung". Therefore, it is believed that the precision and efficiency can be improved for the doctor's diagnosis and treatment.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Test result, discussion and future works</head><p>Based on the proposed method, the entities are classified into one of three categories/classes, Finding, Location, Implant, and the structured record generated and outputted with the format such as "finding [W] at location [X]" or "implant [Y] at location [Z]", wherein the contents of W, X, Y and Z are the data of/with annotated tags provided by the experts, i.e., the doctors of the hospital mentioned, and then collected into the chest DB.</p><p>In general, the evaluation factors or metrics for classification or identification are "Precision", "Recall" and "F1-Score" listed below. Particularly, the definition of them can be described below. Precision = TP/(TP+FP), wherein TP (True Positive) is the amount of the keyword in the unstructured report file that represents the abnormal status, and FP (False Positive) is the opposite meaning of keyword to compare in the unstructured report file, e.g. negative sentences. Recall = TP/ (TP+FN), wherein FN (False Negative) is the amount of the keyword in the unstructured report file but not be found. Actually, the evaluation factor F1-Score is the weighted average of the Precision and the Recall, and it takes both false positives and false negatives into account.</p><p>Accordingly, Table <ref type="table" target="#tab_2">III</ref> shows one embodiment of the test result of our proposed method, and wherein TN (True Negative) represents the normal or no lesion status. As shown in TABLE III, the value of Precision is 98.80%, the value of Recall is 80.65%, and the value of F1-Score is 88.80%. We noticed that the recall value is smaller than precision value from proposed method. In order to improve the value of recall, we check and analyze all structured output reports classified into FN, and the problem probably comes from three types of errors described as below.</p><p>Type 1 error: Keywords not existing in the database Example: The Ill-defined calcification near left glenohumeral joint.</p><p>We noticed that the keyword "glenohumeral" can't be found in the chest DB, and thus we shall collect more training files to train our model for solving this issue in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Type 2 error: Typo error</head><p>Example: The air space nodu le at right medial basal lung.</p><p>We noticed that the keyword "nodu le" is typed incorrectly by the doctor, whereas it should be type in "nodule" as a correct data. Accordingly, we shall practice some pre-processing or examining steps in deploying the unstructured chest x-ray report files before the test stage for solving this issue in the future. Type 3 error: Lower-case acronym or abbreviation Example: The postsurgical changes in rul. We noticed that the keyword "rul" is the acronym typed in lower case or abbreviation of "Right Upper Lobe" in the sentence of the test data, and thus we shall ask the doctor to provide more information about this kind of domain knowledge as a lookup table or a dictionary for mapping and interpreting to the original and exact meanings in the future.</p><p>In hence, we further propose an improved method for the data or the works with the similar or same features and errors here based in our error analysis above. Accordingly, we add a pre-processing step before that of "NER Model Deploying" shown in Figure <ref type="figure" target="#fig_5">5</ref>. The preliminary result shows that the performance of the improved method is improved, and the works still in progress and undergoing. In this paper, our proposed methods have at least two novel features and the contributions accordingly. First, we deploy the modeling and knowledge database expansion mechanism for the new model creation or adaption from the current model during a NER model training stage anytime when the new tags with/ without the pre-processing shall be learned and classified automatically and hence the related knowledge database can be auto-expanded once the training is completed. The approval, confirmation or verification will be made by the experts. Therefore, the goal of automatic information extraction, structured medical report generation and related applications using the machine learning technique can be achieved.</p><p>Second, we deploy a different and novel relation extraction method/algorithm for tracing the dependency parsing tree of the unstructured medical report data to extract the relationships between the entities and categories/classes, finding, location and implant we concerned, so that we can obtain the structured medical report and collect them into the chest knowledge database for creation or expansion. Therefore, the optimization and accuracy improvement of the doctor's work and performance through referring to the structured medical report for diagnosis and treatment can be achieved as well.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Flowchart of our method</figDesc><graphic url="image-2.png" coords="2,61.67,251.84,227.59,133.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. The illustrated structured report for normal case</figDesc><graphic url="image-3.png" coords="3,53.99,316.40,243.07,53.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure</head><label></label><figDesc>Figure The illustrated structured report for one abnormal case</figDesc><graphic url="image-4.png" coords="3,53.99,503.72,242.77,54.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. The illustrated structured report for another abnormal case</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>F1-Score = (2*Precision*Recall)/ (Precision+Recall).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. The new Flowchart of our method</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I .</head><label>I</label><figDesc>The illustrated chest x_ray data file of knowledge DB created For this task, the doctors of the chest department of National Taiwan University Hospital (NTUH) provides at least 30 thousand of the unstructured chest x-ray report files for training the NER model. After performing all the steps of the training stage, we obtain the created and the expanded knowledge DB shown in Table I listed above and II sequentially, and a NER model (not shown in this paragraph) for deploying in the test stage later. By contrast, more new entities or annotated tags can be classified into these three categories/classes using a new NER model trained automatically.</figDesc><table><row><cell>Finding</cell><cell>Location</cell><cell>Implant</cell></row><row><cell>calcified mass</cell><cell>upper abdomen</cell><cell>PTCD</cell></row><row><cell>calcified nodule</cell><cell>right abdomen</cell><cell>PTCD tube</cell></row><row><cell>calcified plaque</cell><cell>right chest</cell><cell>Port-A catheter</cell></row><row><cell>nodule</cell><cell>right mediastinum</cell><cell>metallic coil</cell></row><row><cell>opacity</cell><cell>left middle lung</cell><cell>metallic band</cell></row><row><cell cols="3">III. EXPERIMENTAL RESULT AND DISCUSSION</cell></row><row><cell cols="3">A. The expanded chest x_ray data file of knowledge</cell></row><row><cell cols="3">DB generated in the training stage</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II .</head><label>II</label><figDesc>The illustrated chest x_ray data file of knowledge DB expanded</figDesc><table><row><cell>Finding</cell><cell>Location</cell><cell>Implant</cell></row><row><cell>calcified mass</cell><cell>upper abdomen</cell><cell>PTCD</cell></row><row><cell>calcified nodule</cell><cell>right abdomen</cell><cell>PTCD tube</cell></row><row><cell>calcified plaque</cell><cell>right chest</cell><cell>Port-A catheter</cell></row><row><cell>calcified spot</cell><cell>left chest</cell><cell>Swan-Ganz catheter</cell></row><row><cell>cavitary lesion</cell><cell>left lung</cell><cell>VP shunt</cell></row><row><cell>air-fluid layering</cell><cell>right lung</cell><cell>central venous line</cell></row><row><cell>cystic lesion</cell><cell>left mediastinum</cell><cell>central line</cell></row><row><cell>nodule</cell><cell>right mediastinum</cell><cell>metallic coil</cell></row><row><cell>opacity</cell><cell>left middle lung</cell><cell>metallic band</cell></row><row><cell>mass</cell><cell>left upper lung</cell><cell>metallic object</cell></row><row><cell>pleural effusion</cell><cell>left lower lung</cell><cell>metallic pin</cell></row><row><cell>pneumonia</cell><cell>right upper lung</cell><cell>metallic wire</cell></row><row><cell>cardiomegaly</cell><cell>right middle lung</cell><cell>stent</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III .</head><label>III</label><figDesc>The test result of our method</figDesc><table><row><cell></cell><cell>Our Method</cell><cell></cell></row><row><cell>n=9,933</cell><cell>predicted</cell><cell>Precision Recall F1-Score</cell></row><row><cell></cell><cell>TP=5,507 TN=67</cell><cell></cell></row><row><cell>observed</cell><cell></cell><cell>98.80% 80.65% 88.80%</cell></row><row><cell></cell><cell>FN=1,321 FP=3,038</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">Authorized licensed use limited to: Tsinghua University. Downloaded on December 30,2022 at 13:18:14 UTC from IEEE Xplore. Restrictions apply.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors would like to express their sincere gratitude to the anonymous reviewers for their constructive comments on the manuscript of this paper. The work presented in this paper was supported in part by the Ministry of Science and Technology, R.O.C., under grant number MOST 107-2634-F-002-015. The authors acknowledge the support.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep recursive neural networks for compositionality in language</title>
		<author>
			<persName><forename type="first">Irsoy</forename><surname>Ozan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2096" to="2104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Automated Encoding of Clinical Documents Based on Natural Language Processing</title>
		<author>
			<persName><forename type="first">Carol</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lyudmila</forename><surname>Shagina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yves</forename><surname>Lussier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Hripcsak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association (JAMIA)</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="392" to="402" />
			<date type="published" when="2004-09">September 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Automatically Correlating Clinical Findings and Body Locations in Radiology Reports Using MedLEE</title>
		<author>
			<persName><forename type="first">Merlijn</forename><surname>Sevenster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Van Ommering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuechen</forename><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Digit Imaging</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="240" to="249" />
			<date type="published" when="2012-07">July 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Natural Language Processing Systems for Capturing and Standardizing Unstructured Clinical Information: a systematic review</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kreimeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Arya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Halford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Forshee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Walderhaug</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Botsis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<date type="published" when="2017-07">July 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Information Extraction from Mammogram Reports</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kupść</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marciniak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mykowiecka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Piskorski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Podsiadly-Marczy-Kowska</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
			<publisher>KONVENS</publisher>
			<biblScope unit="page" from="113" to="116" />
			<pubPlace>Vienna, Austria</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automatic Structuring of Radiology Free-Text Reports</title>
		<author>
			<persName><forename type="first">Ricky</forename><forename type="middle">K</forename><surname>Taira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">G</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rex</forename><forename type="middle">M</forename><surname>Jakobovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiographics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="237" to="245" />
			<date type="published" when="2001-01">January 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Information extraction from multi-institutional radiology reports</title>
		<author>
			<persName><forename type="first">Saeed</forename><surname>Hassanpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Curtis</forename><forename type="middle">P</forename><surname>Langlotz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell. Med</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="29" to="39" />
			<date type="published" when="2016-01">January 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automatic Information Extraction from Unstructured Mammography Reports Using Distributed Semantics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="78" to="86" />
			<date type="published" when="2017-01">January 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Breast Imaging Reporting and Data System (BI-RADS)</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liberman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Menell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Radiologic Clinics, North Am</title>
				<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="409" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">NeuroNER: an easy-to-use program for named-entity recognition based on neural networks</title>
		<author>
			<persName><forename type="first">Franck</forename><surname>Dernoncourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><forename type="middle">Young</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Szolovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Empirical Methods on Natural Language (EMNLP) System Demonstrations</title>
				<meeting>the 2017 Empirical Methods on Natural Language (EMNLP) System Demonstrations<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09">September 2017</date>
			<biblScope unit="page" from="97" to="102" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
