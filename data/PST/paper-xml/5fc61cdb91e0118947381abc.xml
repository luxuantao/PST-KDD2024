<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On Disambiguating Authors: Collaboration Network Reconstruction in a Bottom-up Manner</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-11-29">29 Nov 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Na</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Data Science and Engineering</orgName>
								<orgName type="institution">East China Normal University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Renyu</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Data Science and Engineering</orgName>
								<orgName type="institution">East China Normal University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaoxu</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Data Science and Engineering</orgName>
								<orgName type="institution">East China Normal University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
							<email>xiangnanhe@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="department">School of Information Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wenyuan</forename><surname>Cai</surname></persName>
							<email>wenyuan.cai@hypers.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Shanghai Hypers Data Technology Inc</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ming</forename><surname>Gao</surname></persName>
							<email>mgao@dase.ecnu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Data Science and Engineering</orgName>
								<orgName type="institution">East China Normal University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">School of Statistics</orgName>
								<orgName type="institution" key="instit1">KLATASDS-MOE</orgName>
								<orgName type="institution" key="instit2">East China Normal University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aoying</forename><surname>Zhou</surname></persName>
							<email>ayzhou@dase.ecnu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Data Science and Engineering</orgName>
								<orgName type="institution">East China Normal University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yurong</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dong</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Fuad</forename><forename type="middle">E</forename><surname>Alsaadi</surname></persName>
						</author>
						<author>
							<affiliation key="aff4">
								<address>
									<addrLine>1 1 1 1 1</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">DUT)</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<address>
									<addrLine>PKU) Lei Zou 51 5</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">On Disambiguating Authors: Collaboration Network Reconstruction in a Bottom-up Manner</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-11-29">29 Nov 2020</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2011.14333v1[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Collaboration Network</term>
					<term>Author Disambiguation</term>
					<term>Probabilistic Generative Model</term>
					<term>Exponential Family</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Author disambiguation arises when different authors share the same name, which is a critical task in digital libraries, such as DBLP, CiteULike, CiteSeerX, etc. While the state-of-the-art methods have developed various paper embedding-based methods performing in a top-down manner, they primarily focus on the ego-network of a target name and overlook the low-quality collaborative relations existed in the ego-network. Thus, these methods can be suboptimal for disambiguating authors.</p><p>In this paper, we model the author disambiguation as a collaboration network reconstruction problem, and propose an incremental and unsupervised author disambiguation method, namely IUAD, which performs in a bottom-up manner. Initially, we build a stable collaboration network based on stable collaborative relations. To further improve the recall, we build a probabilistic generative model to reconstruct the complete collaboration network. In addition, for newly published papers, we can incrementally judge who publish them via only computing the posterior probabilities. We have conducted extensive experiments on a large-scale DBLP dataset to evaluate IUAD. The experimental results demonstrate that IUAD not only achieves the promising performance, but also outperforms comparable baselines significantly. Codes are available at https://github.com/papergitgit/IUAD.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Author disambiguation, which aims at identifying the distinct authors shared with the same name from the paper database, is an important yet challenging task in many applications, especially in the online bibliography systems, such as DBLP, CiteULike, CiteSeerX, and so on. For example, searching for "Wei Wang" in DBLP returns 224 entries. Not only they have the same name, but also many of them work in similar research fields. Although different authors have different emails and affiliations, these information is difficult to obtain if you do not read the papers. It is thus a natural question that how to accurately disambiguate such authors. For convenience, the word "author" represents a unique individual in this paper, while a name may be shared by multiple authors.</p><p>Author disambiguation is related to several similar tasks like record linkage <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>, entity resolution <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b6">[7]</ref>, object identification <ref type="bibr" target="#b7">[8]</ref>, duplicate detection <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b10">[11]</ref> and entity Fig. <ref type="figure">1:</ref> A running example of the collaboration network, where edges in dashed lines do not belong to the ego-network of "Wei Wang (DUT)". matching <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b14">[15]</ref>, etc., being helpful to many applications in database, information retrieval, and data mining. To date, existing solutions can be roughly classified into two categories: supervised methods <ref type="bibr" target="#b15">[16]</ref>- <ref type="bibr" target="#b19">[20]</ref> and unsupervised methods <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b20">[21]</ref>- <ref type="bibr" target="#b29">[30]</ref>. Since supervised learning methods require manual efforts to do data annotation and feature engineering, they are less transferable to new domains and are not suitable for largescale applications.</p><p>As such, recent advances in author disambiguation primarily focus on unsupervised methods <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b30">[31]</ref>. Among them, embedding-based approaches achieve state-of-the-art performance <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>. Based on the ego-network of a target name, they embed all papers into low-dimensional vectors and then cluster them into clusters. All papers of a cluster are considered as published by an identical author. Despite effectiveness, we argue that such methods suffer from three limitations:</p><p>? They largely focus on clustering vertices in the ego-network, and perform in a top-down manner, i.e., all authors with the same name are represented by a vertex in the egonetwork. As such, the ego-network may not fully preserve the collaborative relations. As demonstrated in Figure <ref type="figure">1</ref>, "Dong Wang", "Yurong Liu" and "Wei Wang" are likely to belong to the same community. However, the community structure is ignored by the ego-network of the target name</p><p>? To address the limitations of existing unsupervised approaches, we propose an incremental and unsupervised author disambiguation method, namely IUAD, which consists of two stages. To the best of our knowledge, IUAD is the first work for addressing author disambiguation in a bottomup manner. ? In the first stage, we find the stable collaborative relations, which are defined by the frequent co-author relationships, from the co-author lists. Based on them, we build a stable collaboration network (SCN) to guarantee high precision of IUAD. ? In the second stage, to further improve the recall, we adopt a general probabilistic generative model, which utilizes the exponential family to integrate diversified information, such as network structures, research interests, and research communities, to recover the global collaboration network (GCN) via merging vertices in the SCN. ? For newly published papers, we can incrementally and efficiently judge who publish these papers in the global collaboration network. ? We conduct extensive experiments on the DBLP dataset to fully evaluate the performance and efficiency of IUAD. The experimental results demonstrate that IUAD outperforms the state-of-the-art methods significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Our work is related to record linkage <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>, entity resolution <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b6">[7]</ref>, object identification <ref type="bibr" target="#b7">[8]</ref>, duplicate detection <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b10">[11]</ref> and entity matching <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b14">[15]</ref>, etc., which are applied in many scenes widely, such as social network linkage, data integration, database de-duplication, and so on. Existing approaches can be classified into two categories: supervised and unsupervised methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Supervised Methods</head><p>Some existing works train classifiers to address the author disambiguation problem <ref type="bibr" target="#b15">[16]</ref>- <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b31">[32]</ref>. Han et al. adopt coauthor names, paper titles, and journal titles, etc., to train classifiers to disambiguate authors <ref type="bibr" target="#b15">[16]</ref>. Treeratpituk et al. extract a set of features, including similarities of authors, affiliations, coauthors, concepts, journals and titles, etc., to address the author disambiguation problem in scientific databases <ref type="bibr" target="#b16">[17]</ref>.</p><p>For supervised approaches, they need a lot of labeled data to train models, which require labor overhead for data annotation. We, therefore, propose an unsupervised approach to address the author disambiguation problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Unsupervised Methods</head><p>Since unsupervised methods do not need to collect the labeled data, they are suitable to apply for addressing large-scale author disambiguation problems. As such, recent advances in author disambiguation have primarily focused on unsupervised methods <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b27">[28]</ref>- <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b32">[33]</ref>.</p><p>However, most of them are top-down approaches. When these top-down approaches construct the ego-networks, they treat all authors shared the same name as an identical author <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b27">[28]</ref>- <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref>. Zhang et al. model the author disambiguation as a clustering problem after embedding each paper into a low-dimensional space <ref type="bibr" target="#b21">[22]</ref>. Similarly, Xu et al. employ five types of networks to embed papers into a low-dimensional space, and further cluster papers into groups <ref type="bibr" target="#b22">[23]</ref>. <ref type="bibr">Peng et al. adopt</ref> Generative Adversarial Networks to learn the paper representation of the heterogeneous network, then, HDBScan and AP are used to cluster papers <ref type="bibr" target="#b29">[30]</ref>. <ref type="bibr">Shin et al. tackle</ref> this problem by splitting vertices in the graph of co-authorships <ref type="bibr" target="#b27">[28]</ref>. Liu et al. introduce a coarse-to-fine multiple clustering framework <ref type="bibr" target="#b33">[34]</ref>. Despite effectiveness, we argue that such methods suffer from the following limitations: (1) the top-down approaches tend to initially mine the low-quality collaborative relations since they do not distinguish authors in the ego-networks; (2) they are designed for dealing with the static data, cannot handle the newly published papers incrementally.</p><p>Fan et al. are conscious of the limitations of existing unsupervised methods <ref type="bibr" target="#b26">[27]</ref>. For multiple papers published by a target name, they do not merge the authors with the target name into a single vertex in the ego-network. However, they do not distinguish the names of their co-authors, i.e., two different co-authors sharing the same name are treated as a unique coauthor. In addition, they only utilize the network structure to disambiguate authors. Actually, the other information, such as paper titles, published venues, and research communities, is helpful to disambiguate authors.</p><p>To the best of our knowledge, our proposed IUAD approach is the first work to perform author disambiguation in a bottomup manner. In the beginning, instead of mining the low-quality collaborative relations, we extract the stable collaborative relations from the co-author lists. To further improve the performance of recall, we build a probabilistic generative model to further disambiguate authors via integrating diversified information, such as paper titles, published venues, and research communities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROBLEM FORMULATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Problem Definition</head><p>In this paper, we disambiguate authors via reconstructing the collaboration network. Our input is a paper database D, where each paper has four attributes: co-author list, title, published venue, and published year. Our goal is to reconstruct the collaboration network, which is defined as follows: Definition 1. Collaboration Network Given a paper database D associated with author set V, a collaboration network is a graph G = (V, E, P ), where V is a vertex set, such that E ? V ? V , and edge (u, v) ? E associates with a set of papers, denoted as P uv , and all papers in P uv are published by coauthors u and v.</p><p>Based on the above definition, the author disambiguation task can be treated as a collaboration network reconstruction problem. We propose a two-stage, incremental, and unsupervised author disambiguation algorithm, namely IUAD, and reconstruct the collaboration network in a bottom-up manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. General Framework</head><p>In our solution, we propose a two-stage author disambiguation algorithm IUAD. In the first stage, we build a stable collaboration network (SCN) to capture accurate and higher-order collaborative relations. In the second stage, we construct a global collaboration network (GCN) via applying a probabilistic generative model to judge whether two vertices in the stable collaboration network belong to a unique author or not. The framework of IUAD is illustrated in Figure <ref type="figure" target="#fig_0">2</ref>.</p><p>As demonstrated in Figure <ref type="figure" target="#fig_0">2</ref> and Algorithm 1, IUAD consists of two sub-tasks: stable collaboration network (SCN) construction and global collaboration network (GCN) construction. In the first stage (Lines 2-5), IUAD forms the stable collaboration network via mining all ?-stable collaborative relations and their formed triangles (Line 5). In the second stage (Lines 7-15), IUAD further merges vertices of SCN via adopting a probabilistic generative model (Line 9), where a vertex in SCN can be modeled as a subset of papers published by author a. IUAD employs the EM algorithm to solve the model at Line 10. For each name a ? A, IUAD computes a score for every vertex pair (v a i , v a j ) to judge whether two vertices v a i and v a j belong to an identical author or not at Lines 13-15. Finally, IUAD recovers the collaborative relations existing in the paper co-author lists (Line 16).</p><p>IUAD performs a good trade-off between precision and recall. In the first stage, SCN mines stable collaborative relations to capture the higher-order and higher-quality collaborative information, which ensures the high precision of IUAD. In the second stage, GCN captures the identical authors in the SCN as many as possible, which is responsible for improving the recall of IUAD. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. STABLE COLLABORATION NETWORK CONSTRUCTION</head><p>Instead of mining the low-quality collaborative relations in the existing methods, we design a bottom-up method, which aims at finding the stable collaborative relations from the co-author lists, and further construct the stable collaboration network. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Key Observation</head><p>In a collaboration network, a name exists in the co-author list can be considered as a random event. Let n a and n b be the numbers of papers published by names a and b, respectively, and N be the total number of papers in paper database D. Assume that a and b independently appears in the co-author list of paper p ? D, we have P r(a ? p, b ? p) = na N ? n b N (we will infer that the independent assumption is incorrect). Let X i be a Bernoulli r.v., such that,</p><formula xml:id="formula_0">X i =</formula><p>1, names a and b exist in the co-author list of p i ; 0, otherwise.</p><p>Thus, P r(X i = 1) = nan b N 2 , and X = N i=1 X i is the number of papers co-authored by a and b. We know that X ? Binom(N, nan b N 2 ). Under the independent assumption, we approximate the probability of names a and b co-exist in papers at least x times, i.e., P r(X ? x). According to the weakly Central Limit Theorem, we can approximate the probability by using the standard normal distribution. The probability can be computed as:</p><formula xml:id="formula_1">P r(X ? x) = 1 -P r(X &lt; x -0.5) ? 1 -?( (x -0.5) -E(X) var(X) ),<label>(1)</label></formula><p>where "-0.5" is to convert discrete case to continuous case, the standardized r.v. X-E(X) ? var(X) can be approximated as N (0, 1),</p><formula xml:id="formula_2">and ?(?) is a CDF of N (0, 1).</formula><p>As illustrated in Figure <ref type="figure" target="#fig_1">3</ref>(a), we can observe that the average number of papers, which are published by the same name, is less than 500. Suppose</p><formula xml:id="formula_3">n a = 5 ? 10 2 , n b = 5 ? 10 2 , N = 5 ? 10 5 , then E(X) = N ? nan b N 2 = 0.5, V ar(X) = N ? nan b N 2 ? (1 -nan b N 2 ) ? 0.5. Let x = 3, the probability of P (X ? x) is: P r(X ? 3) = 1 -?( 2.5 -E(X) var(X) ) = 2.3389 ? 10 -3 .</formula><p>(2) From this case, the tail probability P r(X ? 3) is very small, i.e., the probability of names a and b co-exist in papers at least 3 times is very small, and the tail probability will become smaller if the values of n a and n b decrease.</p><p>Surprisingly, we can observe that the frequencies of name pairs follow the power-law distribution in co-author lists as illustrated in Figure <ref type="figure" target="#fig_1">3(b)</ref>. This indicates that an author tends to collaborate with others who collaborate with him/her frequently. This phenomenon proves that the independence assumption for name co-occurrence is incorrect. That is, two authors a 1 and a 2 share name a, and the other two authors b 1 and b 2 also share name b, then it is almost an impossible event that both author pairs (a 1 , b 1 ) and (a 2 , b 2 ) have the high frequencies in the co-author lists.</p><p>Thus, we have strong evidence to conclude that all papers co-authored by a and b are published by a unique author a or a unique author b if name pair (a, b) frequently appears in the co-author lists. This is due to the fact that a collaborative relationship, which is formed in a scale-free network, is not a random event <ref type="bibr" target="#b34">[35]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Stable Collaborative Relation</head><p>Based on the above observations, we define the following stable collaborative relation as follows:</p><p>Definition 2. ?-Stable Collaborative Relation Given a paper database D associated with name set A, name pair (a, b) forms an ?-stable collaborative relation (short in SCR) if co-occurrence frequency of names a and b is no less than ? in all co-author lists for a, b ? A.</p><p>Note that the ?-SCR is a symmetric relation. According to the definition, we can find all ?-SCRs via mining all frequent itemsets with support threshold ? from the co-author lists of papers.</p><p>Once we find all ?-SCRs, we will accurately recover a large number of collaborative relations in the collaboration network. Furthermore, a triangle, which is formed in a scalefree network, is also not a random event. This is because that the number of triangles, which a vertex participates in, also follows the power-law pattern in a scale-free network <ref type="bibr" target="#b35">[36]</ref>. Thus, if (a, b), (a, c) and (b, c) are ?-SCRs, then (a, b, c) also forms a stable collaborative triangle. Thus, we construct a stable collaboration network, short in SCN, which preserves all ?-SCRs or their formed triangles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Stable Collaboration Network</head><p>Next, we will address how to construct the stable collaboration network from the input paper database. The construction consists of two steps:</p><p>? Step I: Generating ?-Stable Collaborative Relations. We employ the FP-growth algorithm <ref type="bibr" target="#b36">[37]</ref> with support threshold ? to mine all ?-SCRs, denoted as F, from the co-author lists. If name pair (a, b) ? F, a and b will be two vertices in the SCN, and an edge will be formed between them. In the SCN, a vertex is treated as a unique author, i.e., all papers co-authored by a and b are published by a unique author a or unique author b if (a, b) forms a ?-SCR. Thus, edge (a, b) in the SCN associates with a set of papers, denoted as P ab , which are co-authored by authors a and b.  is not a 2-SCR between names e and existing neighbor vertices of b. Therefore, vertices b and e will be inserted into the network as new vertices, and edge (b, e) is also formed. (v) Insert remaining names: The authors, who do not exist in any 2-SCRs, will be inserted into the network as isolated vertices. In this stage, we construct the SCN which captures the stable and higher-order collaborative relations from the paper database. As we analyzed, all edges of a SCN are stable collaborative relations. Thus, the constructed SCN ensures the high precision of IUAD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. GLOBAL COLLABORATION NETWORK CONSTRUCTION</head><p>In the SCN construction stage, we ensure the high precision of IUAD by mining ?-SCRs. However, due to the changes in research interests, the collaboration network may change over time. Therefore, two vertices with the same name in SCN may be the identical author, i.e., multiple vertices of SCN may belong to an identical author. To improve the recall, IUAD further judges whether two vertices with the same name are a unique author or not. Finally, we reconstruct a global collaboration network, short in GCN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Problem Formulation</head><formula xml:id="formula_4">Let V a = {v a 1 , v a 2 , ? ? ? , v a n } be the set of vertices with name a in SCN, R a ? V a ? V a = {(v a i , v a j )|v a i ? V a , v a j ?</formula><p>V a , i = j} be the set of candidate pairs, and R = a?A R a . For r j ? R, ? j represents the similarity vector between two vertices in pair r j . The task of constructing GCN aims at determining whether two vertices are a unique author or not, i.e., R = M ? U , where M is the set of vertex pairs whose two vertices belong to a unique author (called the set of matched pairs), otherwise U (called the set of unmatched pairs).</p><p>To solve the problem, we propose a generative probabilistic model to calculate the probabilities P r(r j ? M |? j , ?) and P r(r j ? U |? j , ?) to make the decision <ref type="bibr" target="#b37">[38]</ref>, where ? denotes the parameters of the generative model. To calculate the probability, we need to compute the similarity vectors of candidate vertex pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Similarity Computation</head><p>As we know, the topological structures of the collaboration network, research interests, and research communities are helpful to identify authors from the SCN. We propose six similarity functions for vertex pair r j , denoted as ? j = (?</p><formula xml:id="formula_5">(1) j , ? (2) j , ? ? ? , ?<label>(6)</label></formula><p>j ), to capture how similar between two vertices in SCN.</p><p>1) Similarities in Network Structures: The network structures reflect the collaborative relations of authors, which are important to identify whether two vertices are a unique author or not. Two similarity functions are defined in this part to measure similarities in topological structures of the collaboration network.</p><p>Normalized Weisfeiler-Lehman Sub-graph Kernel. The topological structures of the collaboration network can well reflect the similarity between vertices. Usually, paths, cycles, or kernels <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref> are used to measure the similarity of vertices. Due to the inefficiency of computing paths and cycles with larger networks, IUAD adopts Weisfeiler-Lehman sub-graph kernel <ref type="bibr" target="#b38">[39]</ref> to evaluate the similarity between two vertices. WL-kernel captures topological information to quantify the similarity of vertices in SCN, which can judge how similar two vertices are. The WL sub-graph kernel of two vertices v a i and v a j is defined as:</p><formula xml:id="formula_6">K h (v a i , v a j ) = ? h (v a i ), ? h (v a j ) ,<label>(3)</label></formula><p>where K h (v a i , v a j ) measures the similarity between vertices v a i and v a j based on the number of occurrences of co-authors in h-th iteration, which is denoted as ? h (?). To avoid the negative effect of different sub-graph sizes, the normalized WL sub-graph kernel is adopted:</p><formula xml:id="formula_7">? (1) j = K h (v a i , v a j ) K h (v a i , v a i ) ? K h (v a j , v a j ) .<label>(4)</label></formula><p>Due to page limitation, more details please refer to <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>.</p><p>For the WL sub-graph kernel, the more similar in topological structures of v a i and v a j are, the larger value of the WL subgraph kernel is, and the more likely that two vertices are a unique author.</p><p>Co-author Clique Coincidence Ratio. As analyzed before, triangles describe one kind of stable collaborative relations. In general, a clique will form more stable collaborative relations. In SCN, two vertices are more likely to be a unique author if they have many common cliques. Co-author clique coincidence ratio measures how many co-author common cliques they have. Let L(v a i ) and L(v a j ) are the sets of co-author cliques of vertices v a i and v a j , respectively. The co-author clique coincidence ratio is defined as:</p><formula xml:id="formula_8">? (2) j = 1 ? |L(v a i ) ? L(v a j )|,<label>(5)</label></formula><p>where ? , which balances the productivity of authors, is the smaller number of papers published by v a i and v a j . To speed up the clique computation, we only list the triangles in L(?). For this similarity, the higher the coincident degree of coauthor clique is, the higher probability to be a unique author is, which is consistent with our intuition.</p><p>2) Similarity in Research Interests: Different authors may have different interests, and the same author may have coherent interests over time. Since paper titles reflect author interests, we define two similarity functions to measure similarities of author interests based on paper titles.</p><p>Similarity of Research Interests. The keywords in paper titles reflect author interests. Since the distributed representations of words preserve the semantic information of text, we adopt word vectors learned by language models, such as Word2Vec, GloVe and BERT, etc., to capture the semantic of keywords. The similarity of research interests can be measured by cosine similarity of word vectors, which is defined as follows:</p><formula xml:id="formula_9">? (3) j = W (v a i ) ? W (v a j ) ||W (v a i )|| 2 ? ||W (v a j )|| 2 ,<label>(6)</label></formula><p>where W (v a i ) and W (v a j ) are the centers of all keyword vectors of vertices v a i and v a j . To extract the keywords, the stop words or the frequent words in paper titles are excluded. Thus, the cosine similarity is larger, i.e., v a i and v a j are more similar in the research interests, the more probability that two vertices belong to a unique author.</p><p>Time Consistency in Research Interests. For an author, although the research field may not change, the research problems vary over time. Thus, we define a similarity to capture the time consistency in research interests. Let multisets B(v a i ) and B(v a j ) are keywords that exist in paper titles of vertices v a i and v a j , respectively. The similarity of time consistency in research interests is defined as:</p><formula xml:id="formula_10">? (4) j = 1 ? b?B(v a i )?B(v a j ) e ? * min (b) * 1 log(F B(b)) ,<label>(7)</label></formula><p>where ? is a decay factor introduced in <ref type="bibr" target="#b40">[41]</ref> (set to 0.62 in our experiment), min (b) is the minimum year difference of word b, F B(b) is occurrence frequency of word b in all titles of the whole dataset, and ? is the same to the definition in ?</p><p>(2) j . From this definition, if more unfrequent words are used by authors v a i and v a j , they have higher time consistency in research interests.</p><p>3) Similarity of Research Communities: Due to the cognitive limitations of the human <ref type="bibr" target="#b41">[42]</ref>, authors may have stable research communities. In this paper, we employ the venues of published papers to capture the similarity of the research communities.</p><p>Similarity of Representative Community. An author has a stable research field, which forms a research community, he/she may publish papers in the same venue frequently. Let multiset H(v) be the set of venues, in which papers published by vertex v, and h a i and h a j be the most frequent venues in H(v a i ) and H(v a j ), respectively. Note that h a i and h a j are considered as the representative communities of vertices v a i and v a j , respectively. The following similarity function is defined to measure the similarity of representative community:</p><formula xml:id="formula_11">? (5) j = 1 ? (cnt(H(v a j ), h a i ) + cnt(H(v a i ), h a j )),<label>(8)</label></formula><p>where cnt(H, h) denotes the frequency of venue h existed in multiset H, and ? is the same as the definition in ?</p><p>(2) j . If vertices v a i and v a j frequently publish papers in the same venue, they have high representative community similarity.</p><p>Similarity of Research Communities. Apart from the representative community, all venues are helpful to disambiguate authors. Especially, some authors may have special research communities, which can be represented as small minority venues. Referring to the Adamic/Adar metric, we define the following similarity function to measure the similarity of the research communities:</p><formula xml:id="formula_12">? (6) j = 1 ? h?H(v a i )?H(v a j ) 1 log(F H(h)) ,<label>(9)</label></formula><p>where F H(h) is the number of papers published in venue h among the entire dataset, and ? is the same to ?</p><p>(2) j . In this similarity function, it emphasizes the small minority venues to disambiguate authors. If two vertices v a i and v a j frequently publish papers in small minority venues, they are more likely to be a unique author.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Likelihood and Parameter Learning</head><p>For a candidate vertex pair r j , P (r j ? M |?) and P (r j ? U |?) represent the matched and unmatched probabilities, respectively. If we suppose that P (r j ? M |?) = p, then P (r j ? U |?) = 1-p. Let l j = 1 if r j ? M , otherwise l j = 0, and binary vector l j = (l j , 1 -l j ). We define x j = (l j , ? j ) as the "complete data" for r j . The log-likelihood is:</p><formula xml:id="formula_13">L(?|X) = N j=1 l j log P (? j |r j ? M, ?), log P (? j |r j ? U, ?) T + N j=1 l j log p, log (1 -p) T .</formula><p>(10) Under the independent assumption, probabilities P (? j |r j ? M, ?) and P (? j |r j ? U, ?) can be computed as</p><formula xml:id="formula_14">m i=1 P (? (i) j |r j ? M, ?) and m i=1 P (? (i) j |r j ? U, ?)</formula><p>, where m is the number of similarity functions. However, for different similarity functions, the distributions of ? (i) j are different from each other. To simplify the log-likelihood, we employ the exponential family to model the distribution of similarity ? (i) j .</p><p>In the above probabilistic generative model, l j is a random vector. Thus, the parameter vector ? cannot be directly learned by their MLEs. IUAD adopts the EM algorithm to learn the MLEs of parameters <ref type="bibr" target="#b37">[38]</ref>. The MLEs of parameters for distributions are summarized in Table <ref type="table" target="#tab_2">I</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Decision Making</head><p>Once we learn the parameters of the model, the computed probabilities P (r j ? M |? j , ?) and P (r j ? U |? j , ?) can be used to judge whether two vertices in SCN are a unique author or not. To simplify the judgment process, IUAD defines the following matching score for vertex pair r j :</p><formula xml:id="formula_15">sc j = log P (r j ? M |? j , ?) P (r j ? U |? j , ?) . (<label>11</label></formula><formula xml:id="formula_16">)</formula><p>When sc j is much larger than 0, two vertices in r j are more likely to be merged as a single vertex. As shown in Algorithm 1, given decision threshold ?, if sc j ? ?, two vertices in r j are merged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Incremental Manner</head><p>For a newly published paper p a , which is published by author a, then we need to judge whether author a is identical to an existing vertex in GCN. The problem is called the single paper disambiguation problem. Since all vertices named a are different authors after constructing GCN, our proposed IUAD method can easily extend to incrementally solve the single paper disambiguation problem.</p><p>For new paper p a , a is viewed as an isolated vertex, denoted as v a , in the GCN. Let V a = {v a 1 , v a 2 , ? ? ? , v a n } be the set of vertices named a in GCN. The single paper disambiguation problem aims at judging whether v a is identical to</p><formula xml:id="formula_17">v a k ? V a for a fixed k (1 ? k ? n).</formula><p>To make the decision, we first calculate similarity vector ? a i for vertex pair r a i = (v a , v a i ). Based on learned parameter vector ?, we can compute probabilities P (r a i ? M |? a i , ?) and P (r a i ? U |? a i , ?). We then compute matching score sc a i for vertex pair r a i by using Equation <ref type="bibr" target="#b10">(11)</ref>. Since v a is identical at most one vertex v a k in V a , we make the decision that v a is identical to v a k if the following two conditions satisfy: (1) for</p><formula xml:id="formula_18">i = k and v a i ? V a , sc a k ? sc a i ; (2) sc a k ? ?. That is, v a is identical to v a</formula><p>k if the largest matching score sc a k is larger than our pre-defined threshold ?. If the conditions do not satisfy, v a will be an isolated vertex in the constructed GCN. For newly published papers, in contrast to the existing embeddingbased approaches that need to re-train the whole model, our proposed IUAD method can incrementally address the single paper disambiguation problem one by one efficiently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Discussion</head><p>1) Efficiency of IUAD: IUAD is an efficient algorithm mainly due to the following facts:</p><p>? In SCN construction stage, it only mines the frequent 2itemsets which can be efficiently found, instead of using high complexity operations such as extracting paths or cycles from the network. Furthermore, IUAD captures the higher-order collaborative relations via inferring the stable triangles from the found ?-SCRs. In this stage, IUAD therefore performs efficiently. ? In GCN construction stage, we only merge the vertices in the SCN, which share the same name. Note that a small number of names are shared by many vertices in SCN. To further reduce the complexity of GCN construction, we randomly sample a small number of vertex pairs (i.e., 10%), which share the same name, to train the generative probabilistic model. The sampling strategy speeds up the computation significantly. In existing top-down approaches, they involve many repeated calculations. For example, given a paper of five authors, it will be considered five times to generate different ego-networks to disambiguate each author. However, our proposed IUAD method aims at recovering the global collaborative network in the bottom-up manner, and avoids the repeated calculations. Comparing to the existing top-down approaches, our IUAD is therefore more efficient than them.</p><p>2) Sampling Strategy: When we learn parameter vector ? of the generative probabilistic model, we encounter the imbalance problem, i.e., there are only a small number of matched vertex pairs comparing with the unmatched vertex pairs. To reduce the negative impact of imbalance problem, we partition a vertex in SCN, which has many published papers, into two vertices at random. As such, the matched and unmatched vertex pairs are more balanced for training when the number of matched vertex pairs increases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EXPERIMENTS</head><p>We conduct comprehensive experiments to evaluate the performance and efficiency of IUAD via comparing it with 8 competitors on the real DBLP data. Through empirical study, we aim at addressing the following research questions:</p><p>? RQ1 How does IUAD perform comparing with baselines?</p><p>? RQ2 What is the contribution of each stage of IUAD? ? RQ3 Does IUAD perform well on the large-scale dataset? ? RQ4 Whether is the incremental manner practicable in performance and efficiency? </p><formula xml:id="formula_19">= N j=1 l k j I ? (i) j =h N j=1 l k j p h, k 2,i = N j=1 (1-l k j )I ? (i) j =h N -N j=1 l k j Gaussian ? k 1,i = N j=1 l k j ? (i) j N j=N l k j ? k 2,i = N j=1 (1-l k j )? (i) j N -N j=1 l k j (? k 1,i ) 2 = N j=1 l k j (? (i) j -? k 1,i ) 2 N j=1 l k j (? k 2,i ) 2 = N j=1 (1-l k j )(? (i) j -? k 2,i ) 2 N -N j=1 l k j Exponential ? k 1,i = N j=1 l k j N j=1 l k j ? (i) j ? k 2,i = N -N j=1 l k j N j=N (1-l k j )? (i) j</formula><p>? RQ5 Whether are similarity functions reasonable?</p><p>A. Experimental Settings 1) Dataset: We use a large-scale DBLP dataset 1 to conduct our experiments. In this dataset, there are 72,522 different author names, 641,377 published papers associated with coauthor lists, paper titles, venues, and published years. Totally, there are 2,393,969 author-paper pairs.</p><p>To evaluate the performance of IUAD and competitors, we build a testing dataset via intersecting two datasets DBLP and DAminer <ref type="bibr" target="#b32">[33]</ref> 2 . We do not evaluate the performance of IUAD and competitors on dataset DAminer since it only contains papers published by randomly selecting 600 author names, which only support to partially preserve the collaborative relations for the selected author names. Furthermore, IUAD method cannot fully capture the collaborative relations between authors on dataset DAminer. As a result, we obtain a testing dataset, which contains 336 real authors and 50 different author names who co-exist in both datasets DBLP and DAminer. Table II lists the descriptive statistics of 50 different author names in our testing dataset, where #Authors TD and #Papers TD are the number of authors and the number of papers in the testing dataset, respectively, and #Papers DBLP denotes the number of papers in the whole DBLP dataset.</p><p>2) Evaluation Metrics.: To avoid the disturbance of different numbers of papers published by different authors, microaccuracy (MicroA), micro-precision (MicroP), micro-recall (MicroR), and micro-F1 (MicroF) are utilized to evaluate the performance of IUAD and its competitors. These measurements can be computed as followings:</p><formula xml:id="formula_20">M icroA = T P + T N T P + F P + F N + T N , M icroP = T P T P + F P , M icroR = T P T P + F N , M icroF = 2 * M icroP * M icroR M icroP + M icroR ,</formula><p>1 https://dblp.uni-trier.de/xml/ 2 https://github.com/neozhangthe1/disambiguation/ where TP and FP are the numbers of paper pairs that they are correctly and incorrectly predicted to be from the same author, respectively; FN and TN are the number of paper pairs that the they are incorrectly and correctly predicted to be from different authors, respectively. To reduce the impact of the imbalance in published papers for different names, all the values of TP, FP, FN, and TN count the total number of corresponding paper pairs of all names.</p><p>For evaluating the efficiency of methods, the average time cost per name is also computed.</p><p>3) Baselines: We compare IUAD with unsupervised and supervised baselines. For comparing baselines, their experimental settings are consistent with their original papers. For our IUAD, we only sample 10% vertex pairs to training the generative probabilistic model in the stage of GCN construction.</p><p>(i) Unsupervised Baselines Similar to IUAD, there is a set of unsupervised methods <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b32">[33]</ref> to disambiguate authors, where NetE achieves the state-ofthe-art performance <ref type="bibr" target="#b22">[23]</ref>.</p><p>? ANON <ref type="bibr" target="#b21">[22]</ref>: ANON employs the Hierarchical Agglomerative Clustering (HAC) to cluster papers after embedding papers into a low-dimensional space, where all papers in a cluster are published by a unique author.</p><p>? NetE <ref type="bibr" target="#b22">[23]</ref>: NetE embeds papers into a low-dimensional space via mining multiple relationships. Furthermore, NetE employs HDBSCAN and AP (i.e., Affinity Propagation) methods to cluster papers.</p><p>? Aminer <ref type="bibr" target="#b32">[33]</ref>: Aminer leverages both global and local information to embed papers into a low-dimensional space. To improve disambiguation accuracy, Aminer also leverages human annotations to learn paper embeddings. Furthermore, Aminer disambiguates authors via employing the HAC algorithm to group papers.</p><p>? GHOST <ref type="bibr" target="#b26">[27]</ref>: GHOST is a graph-based method, which devises a path-based similarity metric to evaluate the similarity between papers, and further groups papers into clusters with the AP algorithm. (ii) Supervised Baselines To verify the effectiveness of our method, we compare IUAD with the supervised methods. We employ AdaBoost, GBDT, RF, and XGBoost to learn  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Performance Comparison (RQ1)</head><p>To demonstrate the performance of our proposed IUAD method, we compare IUAD with four unsupervised methods and four supervised methods with four evaluating metrics. The experimental results are illustrated in Table <ref type="table" target="#tab_4">III</ref>, where we have the following key observations:</p><p>? Comparing to supervised methods, IUAD has achieved better performance. This is due to the fact that supervised approaches do not consider co-author relationships. This points to the positive effect of capturing the collaborative relations during SCN and GCN construction stages.  ego-network, which captures the low-quality collaborative relations. This sheds light on the benefit of our bottom-up author disambiguation method, which preserves the highquality collaborative relations in the beginning. ? IUAD outperforms both Aminer and GHOST significantly.</p><p>Although both Aminer and GHOST preserve higher-order collaborative relationships, their mined higher-order collaborative relationships will also introduce new uncertainty into the task when author disambiguation has not done yet. This also points to the positive effect of finding stable collaborative relations from the co-author lists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Effect Analysis of Different Stages (RQ2)</head><p>IUAD is a two-stage author disambiguation method. To demonstrate the rationality of our two-stage method, we evaluate the performance after SCN and GCN construction stages of IUAD as illustrated in Table <ref type="table" target="#tab_6">IV</ref>, where we have the following key observations: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Scalability Analysis (RQ3)</head><p>We report the average time cost per name disambiguation of our IUAD and four unsupervised baselines in Table <ref type="table" target="#tab_7">V</ref>. We can observe that IUAD is the most efficient method comparing to all unsupervised baselines. This is due to the facts that: (1) SCN construction is very efficient since mining all ?-SCRs is very efficient; (2) GCN construction is also efficient since only the vertices with the same name need to judge whether they are a unique author or not; (3) existing top-down approaches will consider a paper multiple times when it has multiple coauthors.</p><p>To further evaluate the scalability of IUAD, we use only 20%, 40%, 60%, 80% and full data to run IUAD. The performance is illustrated in Figure <ref type="figure" target="#fig_3">5</ref>, where we have the following key observations: (1) IUAD achieves high precision in the SCN construction stage even in a smaller dataset; (2) recall is continually improved from almost 50% to more than 81% as data scale increasing. The observations reveal that:</p><p>(1) the effect of mining stable collaboration relations during SCN construction is positive; (2) a large-scale dataset is more helpful to construct the GCN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Incremental Manner Analysis (RQ4)</head><p>We also study the performance and efficiency of the incremental author disambiguation task. In this task, we separate the testing data into two parts. The first part is utilized to construct the GCN, and then adopt the second part to study the performance of incremental author disambiguation. To evaluate the incremental author disambiguation task, the second part of the testing data consists of 100, 200 and 300 papers, which are treated as the recently published ones. As illustrated in Table <ref type="table" target="#tab_8">VI</ref>, we report the performance and improvement after addressing the incremental author disambiguation problem. In Table VI, "MicroA" and "MicroA+" are the micro-accuracy on the first part of testing data and the entire testing data after incrementally identifying authors, respectively; "Improv." is the improvement after the incremental author disambiguation comparing to the first stage, other effective metrics are similar, and "Avg. time" is the average elapsed time per paper in the incremental author disambiguation. We have the following key observations:</p><p>? We almost observe a performance reduction for incremental author disambiguation. This is due to the facts that: <ref type="bibr" target="#b0">(1)</ref> single paper only provides limited information to identify the authors;</p><p>(2) the stable collaboration relations in newly published papers are not utilized to disambiguate authors. However, incremental author disambiguation does not greatly reduce the performance of our IUAD. It indicates that our proposed similarity functions are rational and effective to disambiguate authors. ? To address the incremental author disambiguation problem, IUAD is very efficient since the average time cost per paper is less than 50 milliseconds. This result thanks to: (1) IUAD incrementally judges who publish a newly published paper via only computing the posterior probability, rather than re-training the entire model; (2) once we compute the six similarity functions, we can efficiently calculate the posterior probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Rationality of Similarity Functions (RQ5)</head><p>There are six similarity functions designed for recovering GCN in subsection V-B. To demonstrate the rationality of our proposed six similarity functions, we only employ a single similarity to construct GCN, and illustrate the performance in Figure <ref type="figure" target="#fig_4">6</ref>, where we have the following key observations:</p><p>? We observe that all similarity functions have influences on the performance of IUAD positively. The observation indicates that all similarity functions are reasonable to identify authors. ? Note that a similarity function is more influential for recovering GCN if its threshold has larger degree of dispersion. Thus, the similarities of representative community (in Figure <ref type="figure" target="#fig_4">6</ref>(a)) and research community (in Figure <ref type="figure" target="#fig_4">6</ref>(b)) are the two most important similarity functions for constructing GCN. This is due to the fact that the stable collaboration relationships have been explored in the SCN construction stage, then the similarities of topological structures (in Figure <ref type="figure" target="#fig_4">6(d-e</ref>)) only capture few helpful information. The time consistency in research interests (in Figure <ref type="figure" target="#fig_4">6</ref>(c)) is more influential than research interests (in Figure <ref type="figure" target="#fig_4">6</ref>(f)), which are only represented by the paper titles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION AND FUTURE WORK</head><p>In this paper, we address the author disambiguation problem in a bottom-up manner. We design an incremental and unsupervised algorithm that consists of two stages: stable collaboration network construction and global collaboration network construction. We first construct the stable collaboration network of authors by mining frequent collaborative relations, ensuring the high precision of our proposed IUAD method. We then build a probabilistic generative model by employing the exponential family to incorporate six reasonable similarity functions. Lastly, we develop the EM algorithm to infer the parameters and judge whether two vertices belong to a unique author or not. For newly published papers, IUAD can incrementally and efficiently judge who publish these papers in the global collaboration network. Empirical results demonstrate the effectiveness and efficiency of IUAD and its superiority over the state-of-the-art methods.</p><p>In this work, we have addressed the author disambiguation problem in an unsupervised manner, while ignoring the possible labeled data. To this end, we plan to extend our method to build a semi-supervised approach to further improve the performance. In addition, we are interested in generalizing IUAD to disambiguate entities in the other domains, such as record linkage in the database, entity resolution in knowledge engineering, and de-duplication in data cleaning, etc. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: The framework of IUAD.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Descriptive analysis of DBLP dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: A running example of SCN construction (frequent 2-itemsets construction part.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: Data scale analysis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 :</head><label>6</label><figDesc>Fig. 6: Rationality of similarity functions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I :</head><label>I</label><figDesc>MLEs of parameters for matched and unmatched groups, where N is the number of samples, k represents the k-th iteration, and ? 1,i , ? 2,i denote the MLEs of matched and unmatched groups for the i-th similarity function, respectively.</figDesc><table><row><cell>Distribution</cell><cell cols="2">MLEs for matched group</cell><cell>MLEs for unmatched group</cell></row><row><cell>Multinomial</cell><cell>p</cell><cell>h, k 1,i</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II :</head><label>II</label><figDesc>The descriptive statistics for our testing dataset.</figDesc><table><row><cell>Name</cell><cell cols="3">#Authors TD #Papers TD #Papers DBLP</cell><cell>Name</cell><cell cols="3">#Authors TD #Papers TD #Papers DBLP</cell></row><row><cell>Jia Xu</cell><cell>12</cell><cell>79</cell><cell>223</cell><cell>Song Chen</cell><cell>5</cell><cell>49</cell><cell>121</cell></row><row><cell>Lixin Tang</cell><cell>4</cell><cell>79</cell><cell>112</cell><cell>Bo Ai</cell><cell>4</cell><cell>98</cell><cell>179</cell></row><row><cell>Ping Fu</cell><cell>5</cell><cell>16</cell><cell>32</cell><cell>Wensheng Yang</cell><cell>4</cell><cell>14</cell><cell>14</cell></row><row><cell>Qi Hu</cell><cell>5</cell><cell>9</cell><cell>33</cell><cell>Hongbin Liang</cell><cell>3</cell><cell>5</cell><cell>19</cell></row><row><cell>Geng Yang</cell><cell>4</cell><cell>55</cell><cell>92</cell><cell>Yang Shen</cell><cell>14</cell><cell>30</cell><cell>65</cell></row><row><cell>Xu Xu</cell><cell>12</cell><cell>60</cell><cell>110</cell><cell>Jing Luo</cell><cell>8</cell><cell>35</cell><cell>61</cell></row><row><cell>Jianhua Lu</cell><cell>7</cell><cell>138</cell><cell>222</cell><cell>Jian Du</cell><cell>5</cell><cell>15</cell><cell>41</cell></row><row><cell>Lin Huang</cell><cell>12</cell><cell>75</cell><cell>105</cell><cell>Lu Han</cell><cell>11</cell><cell>29</cell><cell>57</cell></row><row><cell>Yong Tian</cell><cell>10</cell><cell>13</cell><cell>25</cell><cell>Rong Yu</cell><cell>4</cell><cell>53</cell><cell>101</cell></row><row><cell>Jian Feng</cell><cell>9</cell><cell>33</cell><cell>85</cell><cell>Bo Hong</cell><cell>5</cell><cell>18</cell><cell>78</cell></row><row><cell>Wei Quan</cell><cell>4</cell><cell>32</cell><cell>87</cell><cell>Tao Deng</cell><cell>7</cell><cell>10</cell><cell>33</cell></row><row><cell>Hongbin Li</cell><cell>8</cell><cell>65</cell><cell>258</cell><cell>Yun Zhou</cell><cell>16</cell><cell>41</cell><cell>137</cell></row><row><cell>Hua Bai</cell><cell>4</cell><cell>9</cell><cell>16</cell><cell>Yanqing Wang</cell><cell>6</cell><cell>17</cell><cell>47</cell></row><row><cell>Ping Sun</cell><cell>9</cell><cell>14</cell><cell>37</cell><cell>Jianqiang Yi</cell><cell>3</cell><cell>84</cell><cell>124</cell></row><row><cell>Dandan Zhang</cell><cell>8</cell><cell>26</cell><cell>39</cell><cell>Weiwei Li</cell><cell>10</cell><cell>22</cell><cell>66</cell></row><row><cell>Xi Huang</cell><cell>7</cell><cell>17</cell><cell>26</cell><cell>Xue Qin</cell><cell>3</cell><cell>4</cell><cell>6</cell></row><row><cell>Jie Jiang</cell><cell>8</cell><cell>39</cell><cell>109</cell><cell>Fei Sun</cell><cell>8</cell><cell>17</cell><cell>58</cell></row><row><cell>Lei Song</cell><cell>17</cell><cell>44</cell><cell>118</cell><cell>Junling Wang</cell><cell>2</cell><cell>5</cell><cell>15</cell></row><row><cell>Shuai Yuan</cell><cell>8</cell><cell>18</cell><cell>96</cell><cell>Tian Chen</cell><cell>6</cell><cell>10</cell><cell>20</cell></row><row><cell>Min Zheng</cell><cell>6</cell><cell>15</cell><cell>42</cell><cell>Chuanyan Liu</cell><cell>6</cell><cell>9</cell><cell>18</cell></row><row><cell>Minghui Li</cell><cell>6</cell><cell>14</cell><cell>32</cell><cell>Yin Shi</cell><cell>2</cell><cell>11</cell><cell>17</cell></row><row><cell>Zhifeng Liu</cell><cell>5</cell><cell>12</cell><cell>20</cell><cell>Rong Lu</cell><cell>3</cell><cell>4</cell><cell>11</cell></row><row><cell>Hongtao Liu</cell><cell>5</cell><cell>13</cell><cell>21</cell><cell>Hong Fan</cell><cell>6</cell><cell>25</cell><cell>50</cell></row><row><cell>Yin Wu</cell><cell>9</cell><cell>15</cell><cell>38</cell><cell>Shuang Song</cell><cell>3</cell><cell>9</cell><cell>52</cell></row><row><cell>Dan Sun</cell><cell>4</cell><cell>9</cell><cell>18</cell><cell>Lili Ma</cell><cell>4</cell><cell>16</cell><cell>40</cell></row><row><cell>Total</cell><cell>336</cell><cell>1529</cell><cell>3426</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE III :</head><label>III</label><figDesc>Performance compared with baselines.</figDesc><table><row><cell cols="2">Algorithm</cell><cell>MicroA</cell><cell>MicroP</cell><cell>MicroR</cell><cell>MicroF</cell></row><row><cell></cell><cell>AdaBoost</cell><cell>0.6812</cell><cell>0.6891</cell><cell>0.8046</cell><cell>0.7424</cell></row><row><cell>Supervised</cell><cell>GBDT RF</cell><cell>0.6914 0.7118</cell><cell>0.7422 0.7215</cell><cell>0.7041 0.8066</cell><cell>0.7226 0.7617</cell></row><row><cell></cell><cell>XGBoost</cell><cell>0.6935</cell><cell>0.7467</cell><cell>0.7009</cell><cell>0.7231</cell></row><row><cell></cell><cell>ANON</cell><cell>0.6697</cell><cell>0.8164</cell><cell>0.5438</cell><cell>0.6528</cell></row><row><cell>Un-Supervised</cell><cell>NetE Aminer GHOST</cell><cell>0.7318 0.6182 0.4800</cell><cell>0.8273 0.8235 0.6814</cell><cell>0.6702 0.4217 0.1675</cell><cell>0.7405 0.5578 0.2690</cell></row><row><cell>Our</cell><cell>IUAD</cell><cell>0.8174</cell><cell>0.8608</cell><cell>0.8113</cell><cell>0.8353</cell></row><row><cell cols="6">classifiers, which are to determine whether two papers</cell></row><row><cell cols="6">are published by a unique author or not. For extracting</cell></row><row><cell cols="6">features, we follow the work of Treeratpituk et al. [17].</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>? IUAD outperforms ANON and NetE significantly. The suboptimal performance of them is due to the fact that ANON and NetE model the co-author relationships as an</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE IV :</head><label>IV</label><figDesc>Effect of two stages.</figDesc><table><row><cell></cell><cell>SCN</cell><cell>GCN</cell><cell>Improv.</cell></row><row><cell>MicroA</cell><cell>0.6402</cell><cell>0.8174</cell><cell>+0.1772</cell></row><row><cell>MicroP</cell><cell>0.8662</cell><cell>0.8608</cell><cell>-0.0054</cell></row><row><cell>MicroR</cell><cell>0.4374</cell><cell>0.8113</cell><cell>+0.3739</cell></row><row><cell>MicroF</cell><cell>0.5813</cell><cell>0.8353</cell><cell>+0.2540</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE V :</head><label>V</label><figDesc>Average time cost per name disambiguation (seconds).</figDesc><table><row><cell>Algorithm</cell><cell>20%</cell><cell>40%</cell><cell>60%</cell><cell>80%</cell><cell>100%</cell></row><row><cell>ANON</cell><cell>4.221</cell><cell>9.214</cell><cell>17.955</cell><cell>35.833</cell><cell>58.489</cell></row><row><cell>NetE</cell><cell>16.113</cell><cell>21.597</cell><cell>24.396</cell><cell>28.798</cell><cell>33.093</cell></row><row><cell>Aminer</cell><cell>2.901</cell><cell>3.564</cell><cell>4.420</cell><cell>5.258</cell><cell>6.078</cell></row><row><cell>GHOST</cell><cell>8.500</cell><cell>21.575</cell><cell>44.195</cell><cell>92.165</cell><cell>183.480</cell></row><row><cell>IUAD</cell><cell>0.092</cell><cell>0.420</cell><cell>1.132</cell><cell>2.044</cell><cell>2.599</cell></row><row><cell cols="6">? After the stage of GCN construction, the improvements</cell></row><row><cell cols="6">compared to the first stage are 17.7%, -0.5%, 37.4%, and</cell></row><row><cell cols="6">25.4% on four evaluating metrics. There are two paramount</cell></row><row><cell cols="6">findings that: (1) the biggest improvement appears on micro-</cell></row><row><cell cols="6">recall, where the improvement is up to 37.4%; (2) although</cell></row><row><cell cols="6">we identify more authors in this stage, the precision of IUAD</cell></row><row><cell cols="6">only decreases 0.5%. The experimental result reveals that:</cell></row><row><cell cols="6">(1) our proposed way of constructing the global collabora-</cell></row><row><cell cols="6">tion network is also effective to disambiguate authors; (2)</cell></row><row><cell cols="6">our proposed two-stage collaboration network reconstruction</cell></row><row><cell cols="6">makes a very good balance in micro-precision and micro-</cell></row><row><cell>recall.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE VI :</head><label>VI</label><figDesc>Performance and efficiency of incremental author disambiguation.</figDesc><table><row><cell cols="2">Metric</cell><cell>100</cell><cell>200</cell><cell>300</cell></row><row><cell></cell><cell>MicroA</cell><cell>0.8154</cell><cell>0.8104</cell><cell>0.8166</cell></row><row><cell>MicroA</cell><cell>MicroA+</cell><cell>0.8062</cell><cell>0.8079</cell><cell>0.8085</cell></row><row><cell></cell><cell>Improv.</cell><cell>-0.0092</cell><cell>-0.0025</cell><cell>-0.0081</cell></row><row><cell></cell><cell>MicroP</cell><cell>0.8685</cell><cell>0.8546</cell><cell>0.8544</cell></row><row><cell>MicroP</cell><cell>MicroP+</cell><cell>0.8649</cell><cell>0.8588</cell><cell>0.8606</cell></row><row><cell></cell><cell>Improv.</cell><cell>-0.0036</cell><cell>+0.0042</cell><cell>+0.0062</cell></row><row><cell></cell><cell>MicroR</cell><cell>0.7974</cell><cell>0.8008</cell><cell>0.8160</cell></row><row><cell>MicroR</cell><cell>MicroR+</cell><cell>0.7829</cell><cell>0.7941</cell><cell>0.7931</cell></row><row><cell></cell><cell>Improv.</cell><cell>-0.0145</cell><cell>-0.0067</cell><cell>-0.0229</cell></row><row><cell></cell><cell>MicroF</cell><cell>0.8315</cell><cell>0.8268</cell><cell>0.8348</cell></row><row><cell>MicroF</cell><cell>MicroF+</cell><cell>0.8218</cell><cell>0.8252</cell><cell>0.8255</cell></row><row><cell></cell><cell>Improv.</cell><cell>-0.0097</cell><cell>-0.0016</cell><cell>-0.0093</cell></row><row><cell cols="2">Avg. time (ms)</cell><cell>47.76</cell><cell>45.22</cell><cell>45.40</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>? IUAD achieves a high precision after the stage of SCN construction. It indicates that our proposed way of capturing stable collaborative relations is rather effective to identify authors, and ensures the high-precision of IUAD.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The state of record linkage and current research problems</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Winkler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Statistical Research Division</title>
		<imprint>
			<publisher>US Census Bureau. Citeseer</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Overview of record linkage and current research directions</title>
	</analytic>
	<monogr>
		<title level="m">Bureau of the Census</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A theory for record linkage</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">P</forename><surname>Fellegi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Sunter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">328</biblScope>
			<biblScope unit="page" from="1183" to="1210" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A latent dirichlet model for unsupervised entity resolution</title>
		<author>
			<persName><forename type="first">I</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 SIAM International Conference on Data Mining</title>
		<meeting>the 2006 SIAM International Conference on Data Mining</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="47" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Dianed: time-aware named entity disambiguation for diachronic corpora</title>
		<author>
			<persName><forename type="first">P</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Str?tgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Del Corro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="686" to="693" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multimodal named entity disambiguation for noisy social media posts</title>
		<author>
			<persName><forename type="first">S</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Carvalho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2000" to="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Mention and entity description co-attention for entity disambiguation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning object identification rules for information integration</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tejada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Knoblock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Minton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Systems</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="607" to="633" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Adaptive duplicate detection using learnable string similarity measures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bilenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the ninth ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Online deduplication for databases</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pavlo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Ganger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM International Conference on Management of Data</title>
		<meeting>the 2017 ACM International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1355" to="1368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A data driven approach for person name disambiguation in web search results</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Delgado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mart?nez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Fresno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Montalvo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="301" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Constraint-based entity matching</title>
		<author>
			<persName><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="862" to="867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Adversarial learning for weakly-supervised social network alignment</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="996" to="1003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Pct: partial co-alignment of social networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on World Wide Web</title>
		<meeting>the 25th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="749" to="759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Aligning users across social networks using network embedding</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ijcai</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1774" to="1780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Two supervised learning approaches for name disambiguation in author citations</title>
		<author>
			<persName><forename type="first">H</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tsioutsiouliklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Joint ACM/IEEE Conference on Digital Libraries</title>
		<meeting>the 2004 Joint ACM/IEEE Conference on Digital Libraries</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="page" from="296" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Disambiguating authors in academic publications using random forests</title>
		<author>
			<persName><forename type="first">P</forename><surname>Treeratpituk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th ACM/IEEE-CS joint conference on Digital libraries</title>
		<meeting>the 9th ACM/IEEE-CS joint conference on Digital libraries</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Entity disambiguation in anonymized graphs using graph kernels</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hermansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kerola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Jethava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dubhashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM international conference on Information &amp; Knowledge Management</title>
		<meeting>the 22nd ACM international conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1037" to="1046" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hybrid deep pairwise classification for author name disambiguation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rohatgi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2369" to="2372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A deep neural network for pairwise classification: Enabling feature conjunctions and ensuring symmetry</title>
		<author>
			<persName><forename type="first">K</forename><surname>Atarashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kurihara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Furudo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific-Asia Conference on Knowledge Discovery and Data Mining</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="83" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Name disambiguation using atomic clusters</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2008 The Ninth International Conference on Web-Age Information Management</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="357" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Name disambiguation in anonymized graphs using network embedding</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Al</forename><surname>Hasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM on Conference on Information and Knowledge Management</title>
		<meeting>the 2017 ACM on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1239" to="1248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A network-embedding based method for author disambiguation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 27th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1735" to="1738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A unified probabilistic framework for name disambiguation in digital library</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="975" to="987" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Efficient topic-based unsupervised name disambiguation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">G</forename><surname>Councill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM/IEEE-CS joint conference on Digital libraries</title>
		<meeting>the 7th ACM/IEEE-CS joint conference on Digital libraries</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="342" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Exploiting citation networks for large-scale author name disambiguation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mazloumian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Penner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Helbing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EPJ Data Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On graph-based name disambiguation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Data and Information Quality (JDIQ)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Author name disambiguation using a graph model with node splitting and merging based on bibliographic information</title>
		<author>
			<persName><forename type="first">D</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientometrics</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="50" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Author name disambiguation using graph node embedding method</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE 23rd International Conference on Computer Supported Cooperative Work in Design (CSCWD)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="410" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Author disambiguation through adversarial network representation learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A graph combination with edge pruningbased approach for author name disambiguation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mondal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chandra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Topologicalcollaborative approach for disambiguating authors&apos; names in collaborative networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Amancio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">N</forename><surname>Oliveira</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D F</forename><surname>Costa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientometrics</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="465" to="485" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Name disambiguation in aminer: Clustering, maintenance, and human in the loop</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1002" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A fast method based on multiple clustering for name disambiguation in bibliographic citations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="634" to="644" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">On random graphs, i</title>
		<author>
			<persName><forename type="first">P</forename><surname>Erd?s</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>R?nyi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Publicationes Mathematicae (Debrecen)</title>
		<imprint>
			<date type="published" when="1959">1959</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="290" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Fast counting of triangles in large real networks without counting: Algorithms and laws</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Tsourakakis</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDM.2008.72</idno>
		<ptr target="https://doi.org/10.1109/ICDM.2008.72" />
	</analytic>
	<monogr>
		<title level="m">ICDM 2008</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="608" to="617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Mining frequent patterns without candidate generation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM sigmod record</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Cnl: collective network linkage across heterogeneous social platforms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E.-P</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Prasetyo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Data Mining</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="757" to="762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Weisfeiler-lehman graph kernels</title>
		<author>
			<persName><forename type="first">N</forename><surname>Shervashidze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schweitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J V</forename><surname>Leeuwen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mehlhorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2539" to="2561" />
			<date type="published" when="2011-09">Sep. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Normalized kernels as similarity indices</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ah-Pine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific-Asia Conference on Knowledge Discovery and Data Mining</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="362" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Futurerank: Ranking scientific articles by predicting their future pagerank</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sayyadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 SIAM International Conference on Data Mining</title>
		<meeting>the 2009 SIAM International Conference on Data Mining</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="533" to="544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Neocortex size as a constraint on group size in primates</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">I M</forename><surname>Dunbar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Human Evolution</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="469" to="493" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
