<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Evidence of Meaning in Language Models Trained on Programs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-05-18">18 May 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Charles</forename><surname>Jin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">CSAIL MIT Cambridge</orgName>
								<address>
									<postCode>02139</postCode>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Martin</forename><surname>Rinard</surname></persName>
							<email>rinard@csail.mit.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">CSAIL MIT Cambridge</orgName>
								<address>
									<postCode>02139</postCode>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Evidence of Meaning in Language Models Trained on Programs</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-05-18">18 May 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2305.11169v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present evidence that language models can learn meaning despite being trained only to perform next token prediction on text, specifically a corpus of programs. Each program is preceded by a specification in the form of (textual) input-output examples. Working with programs enables us to precisely define concepts relevant to meaning in language (e.g., correctness and semantics), making program synthesis well-suited as an intermediate testbed for characterizing the presence (or absence) of meaning in language models. We first train a Transformer model on the corpus of programs, then probe the trained model's hidden states as it completes a program given a specification. Despite providing no inductive bias toward learning the semantics of the language, we find that a linear probe is able to extract abstractions of both current and future program states from the model states. Moreover, there is a strong, statistically significant correlation between the accuracy of the probe and the model's ability to generate a program that implements the specification. To evaluate whether the semantics are represented in the model states rather than learned by the probe, we design a novel experimental procedure that intervenes on the semantics of the language while preserving the lexicon and syntax. We also demonstrate that the model learns to generate correct programs that are, on average, shorter than those in the training set, which is evidence that language model outputs may differ from the training distribution in semantically meaningful ways. In summary, this paper does not propose any new techniques for training language models, but develops an experimental framework for and provides insights into the acquisition and representation of (formal) meaning in language models.</p><p>Preprint. Under review.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Despite the rapidly improving performance of large, pretrained language models (LMs) in a range of downstream tasks, a major open question is whether such LMs capture any semantically meaningful information about the text that they consume and generate <ref type="bibr" target="#b33">[Mitchell and Krakauer, 2023]</ref>. One possibility is that LMs trained purely on form-such as the conditional distribution of tokens in the training corpus-do not acquire meaning. Instead, they produce text only according to surface statistical correlations gleaned from the training data <ref type="bibr" target="#b4">[Bender and Koller, 2020]</ref>, with any apparently sophisticated behavior attributable to the scale of the model and training data. Indeed, a recent meta-survey reveals a sharp divide within the NLP community, with 51% of respondents agreeing to the statement, "Some generative model trained only on text, given enough data and computational resources, could understand natural language in some non-trivial sense" <ref type="bibr" target="#b31">[Michael et al., 2022]</ref>.</p><p>This work studies the extent to which meaning can emerge in LMs trained solely to perform next token prediction on text. We empirically evaluate the following two hypotheses: Main Hypotheses. LMs trained only to perform next token prediction on text are (H1) fundamentally limited to repeating the surface-level statistical correlations in their training corpora; and (H2) unable to assign meaning to the text that they consume and generate.</p><p>To investigate H1 and H2, we apply language modeling to the task of program synthesis, or synthesizing a program given a specification in the form of input-output examples. Our primary motivation in adopting this approach is that the meaning (and correctness) of a program is given exactly by the semantics of the programming language. Specifically, we train an LM on a corpus of programs and their specifications, then probe the LM's hidden states for a representation of the program semantics using a linear classifier. We find the probe's ability to extract semantics is random at initialization, then undergoes a phase transition during training, with the phase transition strongly correlated with the LM's ability to generate a correct program in response to previously unseen specifications. We also present results from a novel interventional experiment, which indicate that the semantics are represented in the model states (rather than learned by the probe).</p><p>Our contributions are as follows:</p><p>1. We present experimental results that support the emergence of meaningful representations in LMs trained to perform next token prediction (Section 3). In particular, we use the trained LM to generate programs given several input-output examples, then train a linear probe to extract information about the program state from the model state. We find that the internal representations contain linear encodings of (1) an abstract semantics-specifically, an abstract interpretation-that track the specified inputs through the execution of the program, and (2) predictions of future program states corresponding to program tokens that have yet to be generated. During training, these linear representations of semantics develop in lockstep with the LM's ability to generate correct programs across training steps. 2. We design and evaluate a novel interventional technique that enables us to disentangle the contributions of the LM and probe when extracting meaning from representations (Section 4). Specifically, we seek to distinguish whether (1) the LM representations contain purely (syntactic) transcripts while the probe learns to interpret the transcript to infer meaning, or (2) the LM representations contain semantic state, and the probe just extracts the meaning from the semantic state. Our results indicate that the LM representations are, in fact, aligned with the original semantics (rather than just encoding some lexical and syntactic content), which-together with the results in Section 3-rejects H2. 3. We present evidence that the outputs of the LM can differ from the training distribution in semantically meaningful ways (Section 5): namely, the LM tends to generate programs that are shorter than those in the training set (while still being correct), and the perplexity of the LM remains consistently high on the programs in the training set even as its ability to synthesize correct programs improves, rejecting H1.</p><p>More broadly, this work presents a framework for conducting empirical research on LMs based on the semantics of programming languages (Section 2). Working with programs allows us to define, measure, and experiment with concepts from the precise formal semantics of the underlying programming language, yielding novel insights that contribute toward a principled understanding of the capabilities of current LMs. Going forward, we believe methods similar to those developed in the present work can offer a complementary formal perspective on how key concepts related to language and cognition can be mapped to the setting of LMs and, more generally, machine intelligence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>This section provides a short overview of the trace semantics as our chosen model of meaning in programs, and introduces our experimental setting and procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Program tracing as meaning</head><p>A foundational topic in the theory of programming languages, formal semantics <ref type="bibr" target="#b43">[Winskel, 1993]</ref> is the study of how to formally assign meaning to strings in the language. In this work, our model of semantics consists of tracing a program's execution <ref type="bibr" target="#b10">[Cousot, 2002]</ref>: given a set of inputs (i.e, assignments to variables), the meaning of a (syntactic) program is identified with the (semantic) value computed from the expression, and the trace is the sequence of intermediate values generated as the program executes on the inputs.</p><p>Beyond its amenability to formal analysis, tracing is attractive as a model of program meaning for several reasons. In novice programmers, the ability to accurate trace a piece a code has been directly linked to the ability to explain the code <ref type="bibr" target="#b28">[Lopez et al., 2008</ref><ref type="bibr" target="#b26">, Lister et al., 2009]</ref>, and computer science education has emphasized tracing as a method of developing program understanding <ref type="bibr" target="#b16">[Hertz and Jump, 2013]</ref> and localizing reasoning errors <ref type="bibr" target="#b39">[Sorva, 2013]</ref>. Expert programmers also rely on tracing, both as a mental process <ref type="bibr" target="#b19">[Letovsky, 1987]</ref> and as implemented in the vast array of trace-based debuggers.</p><p>Abstract interpretation Given a program semantics, abstract interpretation <ref type="bibr" target="#b11">[Cousot and Cousot, 1977]</ref> is one way to coarsen the semantics while preserving its compositional structure. For instance, given the multiplication operator ? over the integers Z, we could define an abstract interpretation ? by mapping each integer to its sign ? : Z ? {-, 0, +}, with the corresponding abstract operator ? ? defined in the natural way. This abstraction is precise because, for any two integers x, y ? Z, we have that ?(x ? y) = ?(x) ? ? ?(y) (i.e., ? is a homomorphism). We leverage abstract interpretation to precisely isolate a subset of the trace semantics. As compositionality is often described as a key tenet of human-like intelligence and language <ref type="bibr" target="#b13">[Fodor and Lepore, 2002</ref><ref type="bibr" target="#b9">, Chomsky, 2002</ref><ref type="bibr" target="#b32">, Mikolov et al., 2018]</ref>, we believe our techniques can be applied as a formal framework to test claims of intelligence in LMs beyond the present work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Methods</head><p>Karel Karel is an educational programming language <ref type="bibr" target="#b36">[Pattis, 1994]</ref>  Karel has been adopted by the program synthesis community as a standard benchmark <ref type="bibr" target="#b5">[Bunel et al., 2018</ref><ref type="bibr" target="#b38">, Shin et al., 2018</ref><ref type="bibr" target="#b40">, Sun et al., 2018</ref><ref type="bibr" target="#b7">, Chen et al., 2019</ref><ref type="bibr">, 2021b]</ref>, in which input-output examples are provided, and the task is to produce a program which maps the inputs to the outputs.</p><p>Figure <ref type="figure" target="#fig_0">1</ref> gives an overview of our domain. Each 8x8 grid world contains 4 types of tokens: the robot controlled by the program, which is represented by an arrow indicating the direction the robot currently faces (?, &lt;, ?, &gt;); markers (a space can accumulate up to 10 markers); obstacles (#); or an empty space. We focus on the subset of the language consisting of straight line programs composed from the following 5 operations: MOVE advances the robot by one space in the facing direction if there is not an obstacle ahead (otherwise, the robot does not move); TURNRIGHT and TURNLEFT turn the robot right and left, respectively; PUTMARKER and PICKMARKER increment and decrement the number of markers on the space occupied by the robot (with no effect if there are 10 and 0 markers), respectively. Note that the robot obscures the number of markers on the space it currently occupies, and the obscured markers have no effect on the correctness of a program.</p><p>Karel synthetic dataset construction Our training set consists of one million randomly sampled Karel programs. <ref type="foot" target="#foot_0">1</ref> For each program, we randomly sample 5 grid worlds to serve as input, then evaluate the output of the program on each input. We create textual representations for Karel grid worlds by scanning the grid in row order, with one token per grid space. Each training sample consists of the concatenation of the input-output examples (the specification), followed by the reference program. Note that the training set consists only of programs which are correct with respect to their specification, and furthermore the correctness of a program can be evaluated solely on the basis of the textual representations of the input-output examples (i.e., the synthesis task is well-defined). We also generate a test set of 5000 specifications in the same manner. At test time, we consider any program that satisfies the input-output examples to be correct (not just the reference program).</p><p>Training an LM to synthesize programs We train an off-the-shelf 2 Transformer <ref type="bibr" target="#b42">[Vaswani et al., 2017]</ref> to perform next token prediction on our dataset. To measure synthesis accuracy, we use the LM to generate text starting from a specification using greedy decoding. The completion is correct if it is a well-formed program that maps each input in the specification to its corresponding output. We refer to this as the generative accuracy of the LM. After 64000 training steps (roughly 1.5 epochs), the final trained LM achieves a generative accuracy of 96.4% on the test set.</p><p>Trace dataset construction Every 2000 training steps, we also capture a trace dataset. Namely, we use the LM to complete a specification using greedy decoding, and for each generated token, we take a snapshot of (1) the hidden states of the LM and (2) the corresponding program states after evaluating the partially generated program on each of the 5 specified inputs. We average the hidden state over the layer dimension, so that the snapshot is a 1-dimensional tensor of size 1024 (= number of attention heads * dimension per head), and call this the model state. Syntactically malformed text (i.e., programs that do not parse) is excluded, but we do include traces of programs that do not implement their specifications. We repeat this process for each of the training and test sets, producing two trace datasets consisting of pairs of model and program states.</p><p>Probing experiments Finally, for each training trace dataset, we train a linear probe to predict the facing direction in all 5 program states given the model state. As the facing direction yields a precise abstraction of the full trace semantics, we say the probe predicts a semantic state of the partial program. We then evaluate the accuracy of the probe on the test trace dataset from the same step, and refer to this as the semantic content of the LM. The semantic content captures, in a precise sense, the extent to which model state is aligned with semantic state, i.e., a subset of the semantics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Emergence of meaning</head><p>We investigate the hypothesis that representations of the semantic state emerge in the model state as a byproduct of training the LM to perform next token prediction. Given that the final trained LM achieves generative accuracy of 96.4%, rejecting this hypothesis would be consistent with H2, namely, that the LM has learned to "only" leverage surface statistics to consistently generate correct programs.</p><p>To test this hypothesis, we train a linear probe to extract the semantic state from the model state as 5 separate 4-way classification tasks (one facing direction for each input), as described in Section 2.2. Figure <ref type="figure">3</ref>: Plotting generative accuracy and semantic content with respect to the next two ("Semantic (+1)" and "Semantic (+2)") semantic states over time.</p><p>Representations are predictive of future program semantics The previous section asks whether LMs can represent the meaning of the text that they have generated. Our results suggest a positive resolution to this question, in that the LM is able to (abstractly) interpret the program as it is generated. However, interpreters are not synthesizers, and understanding alone is insufficient for generation. In the case of human speech production, the broad consensus is that speech begins in the mind as a preverbal message, before being translated into an utterance that reflects the initial conception <ref type="bibr" target="#b20">[Levelt, 1993]</ref>.</p><p>We hypothesize that the generative process of the trained LM follows an analogous mechanism, whereby the LM representations encode the semantics of text that has yet to be generated.</p><p>To test this hypothesis, we train a linear probe to predict future semantic states from model states following the same method as described above.</p><p>Note that because we use a greedy decoding strategy, future semantic states are also deterministic, and hence the task is well-defined.</p><p>Figure <ref type="figure">3</ref> displays how well a linear probe is able to predict semantic states 1 and 2 steps into the future (dashed green line labeled "Semantic (+1)" and dotted green line labeled "Semantic (+2)", respectively). As with the previous results, the probe's performance starts at the baseline of random guessing then increases significantly with training, and we also find a strong correlation between the semantic content of future states and the generative accuracy ("Generative", blue line) across training steps. Regressing the semantic content against the generative accuracy yields an R 2 of 0.919 and 0.900 for 1 and 2 semantic states into the future, respectively, with p &lt; .001 in both cases.</p><p>We also consider the hypothesis that the model representations only encode the current semantic state, and the probe is simply predicting the future semantic state from the current semantic state. We test this hypothesis by computing the optimal classifier mapping the ground truth facing direction in the current program to one of the 4 facing directions in the future program. Note that 3 of the 5 operations Figure <ref type="figure">4</ref>: The proposed interventional experiment. We use green for the original semantics, red for the alternative semantics, and gray for non-semantic components (such as syntax). Solid arrows indicate a (supervised) training signal. We aim to distinguish between two hypotheses: (1) the LM only records a syntactic transcript, while the probe learns to infer semantics from the transcript (left), and (2) the LM learns to represent the semantic state, and the probe just extracts the latent meaning (right). We mark the emergent connection between the original semantics and the LM representations in the latter case by a dashed green line. The top row depicts how, pre-intervention, both cases can lead to the high semantic content measured in Section 3. The bottom row displays how intervening on the semantics while preserving the form of programs distinguishes the two hypotheses: if the LM representations are not meaningful (bottom left), then the probe's job is the same as before, i.e., it simply learns to interpret the transcript according to the alternative semantics (and achieves high alternative semantic content); however, if the LM representations encode the original semantic state (bottom right), then the probe needs to extract the alternative meaning from the original semantic state, leading to a low alternative semantic content.</p><p>preserve the facing direction, and the next token is sampled uniformly, so we expect the optimal classifier for 1 state into the future to achieve 60% accuracy by predicting that the facing direction stays the same. Indeed, we found that, by fitting directly to the test set, the upper bound on predicting future semantic state from the current semantic state is 62.2% and 40.7% for 1 and 2 states into the future, respectively. In contrast, a probe's accuracy in predicting future states, when conditioned on a probe correctly predicting the current state, is 68.4% and 61.0% for 1 and 2 states into the future, respectively. This suggests that the probe's ability to extract future semantic states from the model states cannot be explained by simply extrapolating from a representation of the current semantic state.</p><p>Our results thus indicate that the LM learns to represent the meaning of tokens that have yet to be generated, which refutes that LMs cannot learn meaning (H2) and also indicates that the generative process is not just based purely on surface statistics (H1).</p><p>4 Semantic content is attributable to model states (not the probe)</p><p>We next evaluate the possibility that semantics are learned by the probe instead of latent in the model state. Because the probe is explicitly supervised on semantic state, one explanation for the semantic content is that (1) the LM encodes only lexical and syntactic structure, while (2) the probe learns to infer the semantics. For instance, the model states may simply encode the inputs and a list of tokens in the program generated thus far, while the probe reads off then interprets the tokens one-by-one. We refer to this hypothesis as the LM learning a syntactic transcript (as opposed to semantic state).</p><p>To test this hypothesis, we design a novel interventional experiment that preserves the lexical and syntactic structure of the language, and intervenes only on the semantics. In particular, we define an alternative semantics by exchanging the meaning of individual operations in the language. Then, we retrace the program according to the alternative semantics and train a new probe to decode the original model states to the alternative semantic states. This experimental design allows us to distinguish between the two cases where either (1) the model states directly encode a representation of the semantic state, and so the probe needs to learn to map from the original semantic state directly to the alternative semantic state; or (2) the model states merely encode a (syntactic) transcript of the partial program, and the probe just needs to learn to interpret the transcript according to the alternative semantics. In this case, because we limit the alternative semantics to exchanging the meaning of  individual operations in the language<ref type="foot" target="#foot_4">4</ref> (as opposed to inventing completely new operations, e.g., move two spaces in one step), the probe should be able to interpret the transcript equally well, resulting in comparable measurements of the alternative semantic content. Figure <ref type="figure">4</ref> illustrates our setup.</p><p>Note that exhibiting any alternative semantics (within the limitations described above) which degrades the alternative semantic content is sufficient to reject the syntactic transcript hypothesis. As such, the experiment relies crucially on the difficulty of (1), i.e., the harder the task of mapping from the original to alternative semantic state, the easier it will be to distinguish (1) and (2) based on the outcome of the experiment. Hence, we design the alternative semantics to be as distinct as possible from the original semantics with respect to the semantic state of interest, while still using the same set of base operations. Concretely, we define an alternative semantics as follows:</p><formula xml:id="formula_0">original PICKMARKER PUTMARKER TURNRIGHT TURNLEFT MOVE alternative TURNRIGHT TURNLEFT MOVE TURNRIGHT TURNLEFT</formula><p>For instance, the TURNRIGHT operation in the original semantics would have the robot turn 90 degrees clockwise, but in the alternative semantics the robot instead advances by a step (i.e., according to the original definition of the MOVE operation).</p><p>Figure <ref type="figure" target="#fig_3">5</ref> displays the results of this experiment, where we trained a linear classifier to probe up to two states into the past and future using the original and alternative semantics. In all 5 cases, the semantic content for the alternative semantics is significantly degraded when compared to the original semantics, which supports rejecting the hypothesis that the model states only encode a syntactic transcript (i.e., lexical and syntactic information only) while the probe learns to interpret the transcript (i.e., semantics). We note also that the alternative semantic content barely exceeds the baseline of random guessing when probing into the past, which is consistent with the hypothesis that model states directly represent the original semantic states. We thus conclude that the probing results of Section 3 can be attributed to meaning being represented in the model states.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Generated outputs differ from the training distribution</head><p>We next present evidence against H1 by comparing the distribution of programs generated by the trained LM with the distribution of programs in the training set. If H1 holds, one would expect the two distributions to be roughly equivalent, since the LM would just be repeating the statistical correlations of text in the training set.</p><p>Figure <ref type="figure" target="#fig_5">6a</ref> plots how the average length of programs generated by the LM changes over time (solid blue line) against the average length of reference programs in the training set (dashed red line). We find a statistically significant difference,<ref type="foot" target="#foot_5">5</ref> which indicates that the output distribution of the LM is indeed distinct from the distribution of programs in its training set. <ref type="foot" target="#foot_6">6</ref> This contradicts the view put forth in H1 that LMs can only repeat the statistical correlations in their training data.</p><p>Furthermore, the LM output length is, on average, shorter than the reference program length. Indeed, though there are trivial ways to make programs longer (for instance, by inserting no-ops like a TURNRIGHT followed by a TURNLEFT), being able to reliably generate programs that are shorter would intuitively require some level of semantic knowledge. For instance, Figure <ref type="figure" target="#fig_0">1</ref> depicts an actual completion generated by the LM, which is equivalent to the original reference program that is 2 operations longer. This equivalence requires 3 steps to prove: starting from the reference program, (1) PUTMARKER commutes with TURNLEFT, (2) TURNLEFT, TURNRIGHT is a no-op that can be removed, and (3) TURNRIGHT, MOVE, TURNLEFT, MOVE is equivalent to MOVE, TURNRIGHT, MOVE, TURNLEFT (assuming no obstacles, as is the case in the full specification). Though each step might seem clear from a human perspective, we emphasize that the training procedure provides no inductive bias toward discovering equivalent expressions of the same program.</p><p>Finally, we also measure the perplexity of the LM on programs in the training set across time. Figure <ref type="figure" target="#fig_5">6b</ref> displays our results. We see that the LM never learns to fit the distribution of programs in the training set very well, which further supports rejecting H1. This can be attributed to the fact that the randomly sampled programs in the training set contain many no-ops, while the LM prefers to generate more concise programs. Interestingly, the sharp increase in perplexity-when the LM moves beyond imitation-appears to lead the improvements in generative accuracy (and semantic content). As the problem of program equivalence is closely related to the program semantics, the ability to produce short, correct programs suggests the LM has indeed learned an aspect of semantics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Meaningful representations in LMs <ref type="bibr" target="#b22">Li et al. [2023]</ref> train a Transformer on transcripts of Othello, then probe the model activations (not the hidden states) to extract the board state. <ref type="bibr" target="#b21">Li et al. [2021]</ref> fine-tune several pretrained LMs on text that describes evolving situations, then probe the model states to test propositions about entities in the situation. <ref type="bibr" target="#b0">Abdou et al. [2021]</ref> find that pretrained LMs' representations of color terms are geometrically aligned with CIELAB space.</p><p>This work makes several novel contributions within this body of literature. We are the first to explore how meaning in LMs emerges over time (instead of a single snapshot at the end of training), and find a strong, linear relationship between the emergence of meaning and correctness. We are also the first to probe for representations of program semantics in LMs, including future semantics, which corresponds to a notion of intention during generation. In addition, while prior work has studied the differences between an LM's output and its training corpus based on surface statistics <ref type="bibr" target="#b29">[Meister and</ref><ref type="bibr">Cotterell, 2021, LeBrun et al., 2022]</ref>, we are, to the best of our knowledge, the first to identify a semantically meaningful difference between an LM's outputs and its training corpus. We leave an exploration of this phenomenon and its implications, particularly for generalization, to future work.</p><p>Analyzing the behavior of LMs Researchers have investigated the ability of LMs to successfully complete a range of semantically meaningful tasks <ref type="bibr" target="#b1">[Austin et al., 2021</ref><ref type="bibr" target="#b41">, Toshniwal et al., 2022</ref><ref type="bibr" target="#b35">, Patel and Pavlick, 2022</ref><ref type="bibr" target="#b27">, Liu et al., 2023]</ref>. Unlike our research, which probes the internal state of the LM to determine the presence or absence of semantically meaningful state, this line of research works only with the externally observable behavior of the LM.</p><p>Probing Probing <ref type="bibr">[Shi et al., 2016, Belinkov and</ref><ref type="bibr" target="#b3">Glass, 2019]</ref> is widely used as a technique to investigate the inner workings of LMs. A key challenge is controlling for what is learned by the probe rather than latent in the LM <ref type="bibr" target="#b2">[Belinkov, 2022]</ref>. A standard method is to establish a baseline measurement on a task for which the model states are assumed to be meaningless. <ref type="bibr" target="#b17">Hewitt and Liang [2019]</ref> develop control tasks for word-level properties in the context of probing for parts of speech in LM representations. They compare against the performance of a probe that maps from the model states to a dataset with a random part of speech assigned to each word. In our case, the control task approach would assign a random label to each program state; however, this would destroy the compositional structure of the program. Instead, we establish a baseline by intervening on the semantics of program constructs, and generate a new label for each program state by evaluating the program according to the alternative semantics. Preserving the syntax of the language enables us to reject the hypothesis that the model states encode syntax while the probe learns semantics, making our technique better suited than control tasks when probing for compositional semantics. To the best of our knowledge, we are also the first to apply probing to future semantic states.</p><p>Program synthesis with LMs There is a growing body of work on training large-scale, Transformer-based LMs for program synthesis <ref type="bibr">[Chen et al., 2021a</ref><ref type="bibr" target="#b24">, Li et al., 2022</ref><ref type="bibr" target="#b34">, Nijkamp et al., 2023</ref><ref type="bibr" target="#b14">, Fried et al., 2023</ref><ref type="bibr" target="#b1">, Austin et al., 2021]</ref>, as well as program synthesis as a benchmark for LMs <ref type="bibr" target="#b15">[Hendrycks et al., 2021</ref><ref type="bibr" target="#b25">, Liang et al., 2022]</ref>, but none of this previous research investigates the internal representations of LMs for evidence of semantic state. We note that these papers have also observed that the BLEU score with respect to a reference solution is not a good predictor of the LM's competency, which complements our results regarding the LM's perplexity on the training corpus.</p><p>Grounding programs from text Prior work has argued specifically that LMs cannot ground programs given only textual hints of semantics <ref type="bibr" target="#b30">[Merrill et al., 2021]</ref>. <ref type="bibr" target="#b4">Bender and Koller [2020]</ref> concede that meaning could be learned from programs paired with unit tests, but assert this requires a "learner which has been equipped by its human developer with the ability to identify and interpret unit tests," implying that an LM would require an additional supervised signal to associate unit tests with the meaning of programs. In contrast, our results indicate that an LM learns the meaning of programs from textual instances of input-output behavior using only next token prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>The question of whether semantics can be learned from text has garnered considerable interest in recent years. This paper presents empirical support for the position that meaning is learnable from form. More broadly, the formal approach to meaning presented here offers a principled foundation for studying meaning in models of language-a question of both practical and philosophical importance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An overview of the Karel domain. We construct training examples by sampling a random reference program, then sampling 5 random inputs and executing the program to obtain the corresponding 5 outputs. The LM is trained to perform next token prediction on a corpus of examples. At test time, we provide only the input-output prefix to the LM, and use greedy decoding to complete the program. The figure depicts an actual reference program and completion from the final trained LM.</figDesc><graphic url="image-1.png" coords="3,108.00,72.00,396.02,218.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Plotting generative accuracy (blue line) and semantic content (green line) over time. The dotted line at 25% plots the baseline semantic content for random guessing.Emergence of meaning is correlated with generative accuracy Figure2plots our main results. Our first observation is that the semantic content starts at the baseline performance of random guessing (25%), and increases significantly over the course of training. This result indicates that the hidden states of the LM do in fact contain (linear) encodings of the semantic state, and crucially this meaning emerges within an LM trained purely to perform next token prediction on text. Linearly regressing generative accuracy against semantic content yields a surprisingly strong, statistically significant linear correlation across training steps (R 2 = 0.968, p &lt; 0.001), i.e., the variability in the LM's ability to synthesize correct programs is almost completely explained by the semantic content of the LM's hidden layers. This suggests that, within the scope of our experimental setup, learning to model the distribution of correct programs is directly related to learning the meaning of programs, 3 which refutes that LMs are unable to acquire meaning (H2).</figDesc><graphic url="image-2.png" coords="5,309.96,80.67,190.07,130.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(a) Probing 2 states into the past. (b) Probing 1 state into the past. (c) Probing the current state. (d) Probing 1 state into the future. (e) Probing 2 states into the future.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Comparing the semantic content of the alternative (red) and original (green) semantics, with the generative accuracy (blue) plotted for context.</figDesc><graphic url="image-8.png" coords="7,178.03,180.18,135.12,91.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>(a) The length of reference programs in the training set (dashed red line, ? 1 standard deviation within dotted red lines) vs. LM outputs (solid blue line, ? 1 standard deviation within blue region) over time. (b) Perplexity of LM on the reference program tokens in the training set over time (green line, plotted on a log scale), with the generative accuracy as a comparison (blue line, plotted on a linear scale).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Evidence that the LM does not generate programs according to the training distribution. The LM tends to output shorter programs (left) and perplexity on the reference programs in the training set does not converge (right).</figDesc><graphic url="image-10.png" coords="8,108.00,72.00,186.12,146.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>developed at Stanford in the 1970s, which is still in use in their introductory programming course today [Piech and Roberts,</figDesc><table /><note><p><p><p><p><ref type="bibr" target="#b36">January 2019</ref>, CS106A, 2023]</p>. The domain features a robot (named Karel) navigating a grid world with obstacles while leaving and picking up markers. Since being introduced by</p><ref type="bibr" target="#b12">Devlin et al. [2017]</ref></p>,</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We use the official implementation from the Karel benchmark[Devlin et al.,  </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>2017]. The sampled programs range in length from 1 to 8 operations, with an average length of 2.5.2 Specifically, we train a 350M parameter variant of the CodeGen architecture<ref type="bibr" target="#b34">[Nijkamp et al., 2023]</ref> in the HuggingFace Transformers library<ref type="bibr" target="#b44">[Wolf et al., 2020]</ref> from initialization.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Or more precisely, the ability of a linear probe to extract meaning; Section</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>strengthens this claim by attributing the semantic content directly to the model states, rather than what is learned by the probe.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4"><p>Specifically, given a formal grammar and semantics, the intervention should only exchange the meaning of terminals that are on the right hand side of the same production.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5"><p>95% confidence intervals for the mean lengths of the reference programs and LM outputs at the end of training are (2.417, 2.521) and (1.565, 1.629), respectively, measured using the BCa bootstrap with 9999 samples.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_6"><p>Strictly speaking, this result is specific to the output distribution induced by greedy decoding, but our conclusion still holds for the LM as an end-to-end system.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Can language models encode perceptual structure without grounding? a case study in color</title>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Abdou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artur</forename><surname>Kulmizev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Hershcovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anders</forename><surname>S?gaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Conference on Computational Natural Language Learning</title>
		<meeting>the 25th Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="109" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Program synthesis with large language models</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henryk</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carrie</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Terry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07732</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Probing classifiers: Promises, shortcomings, and advances</title>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
		</author>
		<idno type="DOI">10.1162/coli_a_00422</idno>
		<ptr target="https://aclanthology.org/2022.cl-1.7" />
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="207" to="219" />
			<date type="published" when="2022-03">March 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Analysis methods in neural language processing: A survey</title>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Glass</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00254</idno>
		<ptr target="https://aclanthology.org/Q19-1004" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="49" to="72" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Climbing towards nlu: On meaning, form, and understanding in the age of data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Emily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th annual meeting of the association for computational linguistics</title>
		<meeting>the 58th annual meeting of the association for computational linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5185" to="5198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Leveraging grammar and reinforcement learning for neural program synthesis</title>
		<author>
			<persName><forename type="first">Rudy</forename><surname>Bunel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Hausknecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishabh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=H1Xw62kRZ" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiming</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henrique</forename><surname>Ponde De Oliveira Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harri</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Brockman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.03374</idno>
		<title level="m">Evaluating large language models trained on code</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Execution-guided neural program synthesis</title>
		<author>
			<persName><forename type="first">Xinyun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Latent execution for neural program synthesis beyond domainspecific languages</title>
		<author>
			<persName><forename type="first">Xinyun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuandong</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="22196" to="22208" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Syntactic structures</title>
		<author>
			<persName><forename type="first">Noam</forename><surname>Chomsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Mouton de Gruyter</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Constructive design of a hierarchy of semantics of a transition system by abstract interpretation</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Cousot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">277</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="47" to="103" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Cousot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radhia</forename><surname>Cousot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th ACM SIGACT-SIGPLAN symposium on Principles of programming languages</title>
		<meeting>the 4th ACM SIGACT-SIGPLAN symposium on Principles of programming languages</meeting>
		<imprint>
			<date type="published" when="1977">1977</date>
			<biblScope unit="page" from="238" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural program meta-induction</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rudy</forename><forename type="middle">R</forename><surname>Bunel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishabh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Hausknecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">The compositionality papers</title>
		<author>
			<persName><forename type="first">Jerry</forename><forename type="middle">A</forename><surname>Fodor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ernest</forename><surname>Lepore</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Incoder: A generative model for code infilling and synthesis</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armen</forename><surname>Aghajanyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sida</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Freda</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiqi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=hQwb-lbM6EL" />
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Measuring coding challenge competence with apps</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurav</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mantas</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akul</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Collin</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samir</forename><surname>Puranik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Horace</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.09938</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Trace-based teaching in early programming courses</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Hertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Jump</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 44th ACM technical symposium on Computer science education</title>
		<meeting>eeding of the 44th ACM technical symposium on Computer science education</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="561" to="566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Designing and interpreting probes with control tasks</title>
		<author>
			<persName><forename type="first">John</forename><surname>Hewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1275</idno>
		<ptr target="https://aclanthology.org/D19-1275" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11">November 2019</date>
			<biblScope unit="page" from="2733" to="2743" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Evaluating distributional distortion in neural language modeling</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Lebrun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">J</forename><surname>O'donnell</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=bTteFbU99ye" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Cognitive processes in program comprehension</title>
		<author>
			<persName><forename type="first">Stanley</forename><surname>Letovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Systems and software</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="325" to="339" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Speaking: From intention to articulation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Willem</surname></persName>
		</author>
		<author>
			<persName><surname>Levelt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Implicit representations of meaning in neural language models</title>
		<author>
			<persName><forename type="first">Belinda Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1813" to="1827" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Emergent world representations: Exploring a sequence model trained on a synthetic task</title>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Aspen</surname></persName>
		</author>
		<author>
			<persName><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernanda</forename><surname>Bau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanspeter</forename><surname>Vi?gas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><surname>Wattenberg</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=DeG07" />
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName><surname>Tczvt</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Competition-level code generation with alphacode</title>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R?mi</forename><surname>Leblond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Eccles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Keeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Gimeno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Agustin</forename><surname>Dal Lago</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">378</biblScope>
			<biblScope unit="issue">6624</biblScope>
			<biblScope unit="page" from="1092" to="1097" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Holistic evaluation of language models</title>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tony</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dilara</forename><surname>Soylu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deepak</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananya</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.09110</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Further evidence of a relationship between explaining, tracing and writing skills in introductory programming</title>
		<author>
			<persName><forename type="first">Raymond</forename><surname>Lister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Fidge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donna</forename><surname>Teague</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acm sigcse bulletin</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="161" to="165" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Mind&apos;s eye: Grounded language model reasoning through simulation</title>
		<author>
			<persName><forename type="first">Ruibo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shixiang</forename><surname>Shane Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Te-Yen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soroush</forename><surname>Vosoughi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=4rXMRuoJlai" />
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Relationships between reading, tracing and writing skills in introductory programming</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacqueline</forename><surname>Whalley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Robbins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raymond</forename><surname>Lister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourth international workshop on computing education research</title>
		<meeting>the fourth international workshop on computing education research</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="101" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Language model evaluation beyond perplexity</title>
		<author>
			<persName><forename type="first">Clara</forename><surname>Meister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5328" to="5339" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Provable limitations of acquiring meaning from ungrounded form: What will future language models understand?</title>
		<author>
			<persName><forename type="first">William</forename><surname>Merrill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1047" to="1060" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alicia</forename><surname>Parrish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angelica</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Divyam</forename><surname>Madaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">Yuanzhe</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Phang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.12852</idno>
		<title level="m">What do nlp researchers believe? results of the nlp community metasurvey</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A roadmap towards machine intelligence</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics and Intelligent Text Processing: 17th International Conference</title>
		<meeting><address><addrLine>Konya, Turkey</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016-04-03">2016. April 3-9, 2016. 2018</date>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="29" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The debate over understanding in AI&apos;s large language models</title>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">C</forename><surname>Krakauer</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2215907120</idno>
		<ptr target="https://doi.org/10.1073%2Fpnas.2215907120" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">13</biblScope>
			<date type="published" when="2023-03">mar 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Codegen: An open large language model for code with multi-turn program synthesis</title>
		<author>
			<persName><forename type="first">Erik</forename><surname>Nijkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroaki</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lifu</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingbo</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=iaYcJKpY2B_" />
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Mapping language models to grounded conceptual spaces</title>
		<author>
			<persName><forename type="first">Roma</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=gJcEM8sxHK" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Karel the robot: a gentle introduction to the art of programming</title>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Pattis</surname></persName>
		</author>
		<ptr target="https://compedu.stanford.edu/karel-reader/docs/python/en/intro.html" />
	</analytic>
	<monogr>
		<title level="m">Chris Piech and Eric Roberts. Karel Reader: Python version</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1994-01">1994. January 2019. May 8, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Does string-based neural MT learn source syntax?</title>
		<author>
			<persName><forename type="first">Xing</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inkit</forename><surname>Padhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1159</idno>
		<ptr target="https://aclanthology.org/D16-1159" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-11">November 2016</date>
			<biblScope unit="page" from="1526" to="1534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Improving neural program synthesis with inferred execution traces</title>
		<author>
			<persName><forename type="first">Chul</forename><surname>Eui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Notional machines and introductory programming education</title>
		<author>
			<persName><forename type="first">Juha</forename><surname>Sorva</surname></persName>
		</author>
		<idno type="DOI">10.1145/2483710.2483713</idno>
		<ptr target="https://doi.org/10.1145/2483710.2483713" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Comput. Educ</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2013-07">jul 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Neural program synthesis from diverse demonstration videos</title>
		<author>
			<persName><forename type="first">Shao-Hua</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyeonwoo</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sriram</forename><surname>Somasundaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Lim</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4790" to="4799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Chess as a testbed for language model state tracking</title>
		<author>
			<persName><forename type="first">Shubham</forename><surname>Toshniwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="11385" to="11393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">The formal semantics of programming languages: an introduction</title>
		<author>
			<persName><forename type="first">Glynn</forename><surname>Winskel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Remi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-demos.6</idno>
		<ptr target="https://aclanthology.org/2020.emnlp-demos.6" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-10">October 2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
