<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Limitations of Concurrency in Transaction Processing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Peter</forename><surname>Franaszek</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM Thomas J. Watson Research Center</orgName>
								<address>
									<postBox>P.O. Box 218</postBox>
									<postCode>10598</postCode>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">John</forename><forename type="middle">T</forename><surname>Robinson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM Thomas J. Watson Research Center</orgName>
								<address>
									<postBox>P.O. Box 218</postBox>
									<postCode>10598</postCode>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ibm</forename><surname>Thomas</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM Thomas J. Watson Research Center</orgName>
								<address>
									<postBox>P.O. Box 218</postBox>
									<postCode>10598</postCode>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">J</forename><surname>Watson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM Thomas J. Watson Research Center</orgName>
								<address>
									<postBox>P.O. Box 218</postBox>
									<postCode>10598</postCode>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Research</forename><surname>Center</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM Thomas J. Watson Research Center</orgName>
								<address>
									<postBox>P.O. Box 218</postBox>
									<postCode>10598</postCode>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Limitations of Concurrency in Transaction Processing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">86BD7CF7D57EB3BE3556E0D8693CD336</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T10:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>F.2.2 [Analysis of Algorithms and Problem Complexity]: Nonnumerical Algorithms and Problems; H.2.4 [Database Management]: Systems Algorithms</term>
					<term>Theory Concurrency control</term>
					<term>multiprocessors</term>
					<term>parallel processing</term>
					<term>transaction processing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Given the pairwise probability of conflict p among transactions in a transaction processing system, together with the total number of concurrent transactions n, the effective level of concurrency E(n,p) is defined as the expected number of the n transactions that can run concurrently and actually do useful work. Using a random graph model of concurrency, we show for three general classes of concurrency control methods, examples of which are (1) standard locking, (2) strict priority scheduling, and (3) optimistic methods, that (1) E(n, p) 5 n(1 -p/2)"-',</p><p>(2) E(n, p) 5 (1 -(1 -p)")/p, and (3) 1 + ((1 -p)/p)ln(p(n -1) + 1) 5 E(n, p) 5 1 + (l/p)ln(p(n -1) + 1). Thus, for fixed p, as n + Q), (1) E + 0 for standard locking methods, (2) E 5 l/p for strict priority scheduling methods, and (3) E + co for optimistic methods. Also found are bounds on E in the case where conflicts are analyzed so as to maximize E.</p><p>The predictions of the random graph model are confirmed by simulations of an abstract transaction processing system. In practice, though, there is a price to pay for the increased effective level of concurrency of methods ( <ref type="formula">2</ref>) and (3): using these methods there is more wasted work (i.e., more steps executed by transactions that are later aborted). In response to this problem, three new concurrency control methods suggested by the random graph model analysis are developed. Two of these, called (a) running priority and (b) older or running priority, are shown by the simulation results to perform better than the previously known methods (l)-( <ref type="formula">3</ref>) for relatively large n or large p, in terms of achieving a high effective level of concurrency at a comparatively small cost in wasted work.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>As is well known, the problem of supporting increased transaction rates against a common shared database can be approached by developing systems with increased numbers of processors. The details of such systems are not of direct concern here, except we assume that in order to utilize effectively a system consisting of many processors it will be necessary to run many transactions concurrently, with more concurrent transactions required as the number of processors inceases.</p><p>However, two or more transactions can conflict in a variety of ways: they can require common resources l;hat must be allocated exclusively, or they can access common data items in incompatible modes. In such a case it will generally be necessary to have some transactions wait, or backup, or restart certain transactions, until the transactions they conflict with have run to completion. Intuittively, if the probability of 'conflict is high, then only a few transactions can run concurrently so that all run to completion. In such a case a limit to increased transaction rates will soon be encountered, and this limit is determined by the nature of the transactions.</p><p>Our primary goal here is to analyze this fundamental limitation of concurrency for various general classes of scheduling policies independently of any given transaction processing system. In contrast, previous work has concentrated mainly on analysis and simulation of relatively detailed models of particular kinds of systems, and on experiments with actual systems (e.g., <ref type="bibr">[l-4, 8, 9, 11, 121)</ref>. In such cases it is difficult to separate the effect of probability of conflict from other system characteristics, particularly in the case in which concurrency is increased to an arbitrari1.y high degree.</p><p>A conflict between two transactions is defined as a condition existing between them that results in the restriction that both cannot concurrently do useful work (i.e., work leading to their completion). The work done by a transaction that is currently executing but later aborted is not considered useful since in general it will be necessary to repeat this work in order that the transaction run to completion (in some systems this is only approximately true, since it may be possible to backup a transaction to a previously established checkpoint). We call the steps executed by a transaction that is later aborted wasted work. A transaction may also not be doing useful work because it is waiting. If the total number of concurrent transactions is n, and any pair of transactions conflict with probability p, we define the effective level of concurrency E(n, p) as the expected number of the n transactions that will be doing useful work. The expected remaining n -E(n, p) transactions will either be doing wasted work or else be waiting.</p><p>In Section 2, using a random graph model of transaction processing systems, we bound the effective level of concurrency for three general classes of concurrency control policies, examples of which are (1) the usual locking method, which we call standard locking; (2) strict priority scheduling, with priorities assigned independently of conflicts; and (3) optimistic methods. These classes are shown to be fundamentally different. For example, as p is held fixed and n + m, (1) E + 0 for the first class, (2) E 5 l/p for the second class, and (3) E +-m for the third class. Also found are bounds on E in the case where priorities are assigned based on an analysis of the conflicts so as to maximize E.</p><p>The results of the random graph model analysis are confirmed by simulations of an abstract transaction processing system, as described in Section 3, using the three aforementioned concurrency control policies. Although the latter two policies do indeed increase the effective level of concurrency, they do so only with large costs in increased wasted work. However, the random graph model analysis suggests that policies that take into account the waiting or executing state of conflicting transactions could be useful for increasing the effective level of concurrency. Using this information only, or combining it with the priorities used in the strict priority scheduler, leads to three new concurrency control policies. Two of these methods are shown to offer substantial performance improvements for relatively large n or large p, in terms of achieving a high effective level of concurrency at a comparatively small cost in wasted work.</p><p>Section 4 contains a summary of the main results, their implications, and a discussion of further research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">ANALYSIS OF A RANDOM GRAPH MODEL OF CONCURRENCY</head><p>In this section we consider the effective level of concurrency that can be achieved under various basic types of scheduling policies, using a simple random graph model of a concurrent transaction processing system. Let S = (sl, s2, s3, . . .) be the sequence of transactions to be processed by the system, and let T = (Z'i, T2, T3, . . . T,,) be the concurrent set, consisting of those transactions that have entered the system but whose processing has not yet completed. Each Y'i should be thought of as a variable that can assume the values Sl, s2, s3, * -*. The cardinality of the concurrent set, n, is called the total level of concurrency. It is assumed that the concurrent set is ordered by a priority relation that is a total ordering of the transactions in S. In an actual system transaction priority could be determined by the time of entry, for example, possibly combined with transaction class (such as interactive or batch).</p><p>Given T, we define a conflict graph C as a graph whose nodes are members of T and whose edges, Cij, i &lt; j, represent conflicts between transaction pairs Ti and Tj. We also define a scheduling function as a function V: T + (0, l), where V(Ti) = 1 represents the case in which the transaction Ti is doing useful work (as discussed in the Introduction), and V(Ti) = 0 otherwise. If V(Ti) = 1 we say Ti is active, otherwise Ti is said to be inactive.</p><p>We investigate the expected number of active transactions (i.e., the effective level of concurrency as defined in the Introduction) as a function of the total level of concurrency and the probability of conflict, using the following model of a transaction processing system.</p><p>(1) Initially, the concurrent set consists of the first n transactions from the transaction sequence S, and each conflict Cij occurs with probability p, independently of any other conflicts.</p><p>(2) At the end of each unit of time, all active transactions complete and are removed from the concurrent set. Each such transaction is replaced with a new transaction taken from the transaction sequence S in sequence order, so that the concurrent set always contains n transactions.</p><p>(3) After all active transactions have been removed and replaced, a new cycle begins. Given a pair of transactions in the concurrent set of the new cycle, Ti and Tj, i &lt;j, if both transactions were in the concurrent set of the previous cycle, the conflict Cij occurs in the new cycle if and only if a conflict occurred between these two transactions in the previous cycle. Otherwise, one or both of Ti and Tj are new transactions, and Cij occurs with probability p, independently of any other conficts.</p><p>Note that it is assumed that sufficient processing power is available to handle any effective level of concurrency up to n, the total level of concurrency. What is being studied is the effective level of concurrency permitted by the probability of conflict among transactions and the scheduling function.</p><p>The above is a highly simplified picture of transaction processing, and questions arise concerning whether results obtained using this model are applicable to real systems.What concerns us here, though, is not so much the problem of detailed performance prediction as that of achieving a fundamental understanding of what is to be expected for differing policies as the total level of concurrency is increased. For example, the amount of useful work may, for increasing n, go to zero, be bounded by a constant, or increase indefinitely. Furthermore, the outcome of the analysis of the above model has been confirmed by simulations, as described in Section 3. The simulation results indicate that some of the analytic expressions derived in this section can be surprisingly accurate.</p><p>Four scheduling functions will be studied here. In defining these scheduling functions, we are motivated by a consideration of basic types of policies that can be used in actual systems. If some transaction l'i cannot do useful work because of a conflict with some transaction Tj, we say that Ti is blocked (from doing useful work) by Tj. The first two scheduling functions we study correspond to policies in which a transaction Ti can block other transactions even though Ti is itself blocked by another transaction. In contrast, the latter two scheduling functions correspond to policies in which a transaction can block other transactions only if it is doing useful work. We call this property essential blocking. In general, the essential blocking property cannot be obtained using incremental locking techniques, in which transactions acquire locks on required resources and data items as they run, since it may be impossible to determine whether a transaction is actually doing useful work: a currently running transaction may later be aborted due to deadlock, or in some locking policies it may later be aborted due to a conflict with a higher priority transaction. However, essential blocking can be realized by locking in the case where each transaction requests all required locks at initiation time (see below). Essential blocking is also a property of optimistic methods <ref type="bibr" target="#b5">[6]</ref>, since in these methods access requests are always granted, and transactions are aborted only when they conflict with transactions that are guaranteed to run to completion (i.e., guaranteed to be doing useful work).</p><p>The four types of policies that are the motivation for the scheduling functions we define differ according to whether blocking is nonessential or essential, whether priorities are used, and whether the conflicts that occur are analyzed globally. These four basic types are as follows:</p><p>(1) Priority-less. In this type of policy, no priorities are used in determining which transaction blocks another; instead, any transaction Ti may be blocked by any other conflicting transaction Tja Examples of this type of policy are those we call standard locking policies, in which locks are requested incrementally, a lock is always granted to the first transaction that requests it, and subsequent transactions that request the lock in a conflicting mode are made to wait until the earlier transaction completes or is aborted. Variants result from the lock modes that are available, the way deadlock is detected and resolved, and so on.</p><p>A more detailed description of the use of this type of method in actual systems can be found in <ref type="bibr" target="#b4">[5]</ref>. Most of today's transaction processing systems use a concurrency control method of this type.</p><p>(2) Strict priority. In a strict priority type of policy, given a conflict between two transactions, the higher priority transaction always blocks the other. It is assumed that priorities are assigned independently of the conflicts that occur, as is typically the case in actual systems. Note that this means that blocking is nonessential, since the decision to block is made only on the basis of priorities, and not on any available information on which transactions are doing useful work. An example of this type of policy is the wound-wait method of <ref type="bibr" target="#b12">[13]</ref> in which, given a conflict between two transactions, the transaction with a larger transaction number (i.e., lower priority) is made to wait if possible, and is otherwise aborted.</p><p>(3) Essential blocking with priority. Under this type of policy, a transaction is blocked if and only if it conflicts with some higher priority transaction that is doing useful work. Again, it is assumed that priorities are assigned independently of conflicts. In the case that transactions request all required locks at initiation time, an example of this type of policy is the method in which transactions wait until all of their requested locks can be granted, with either all or none of the locks being granted atomically. If the concurrency control examines the waiting transactions in FIFO order, then priorities are determined by starting times. As discussed above, other examples of this type of policy are optimistic methods, in which access requests are always granted. Under optimistic methods, priorities are determined by read-phase completion times, where the read-phase completion of a transaction is defined as that point at which the transaction is known to require no further reads to the database.</p><p>(4) Conflict dependent. Here it is assumed that the system is capable of examining all conflicts, either in advance, or (in systems using an optimistic method) before completion time. This information is then used to select active transactions with the objective of maximizing throughput. We are not aware of any current system that uses a concurrency control method of this type. Our purpose in considering this type of policy is to investigate the improvement that could be achieved by a concurrency control method that makes use of such an approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Priority-Less</head><p>Since under standard locking policies a conflict is handled (in the absence of deadlock) without the use of priorities, and without regard to any other conflicts, we assume that given a conflict between two transactions, either transaction is determined as inactive as a result of the conflict with probability l/2. We therefore define VPL, the priority-less scheduling function, algorithmically as follows: (1) let I be a set of transactions, initially empty (I will become the set of inactive transactions); (2) for each transaction Ti in the concurrent set, for each j such that the conflict Cij or Cji occurs, add Ti to I with probability l/2; (3) VpL(Ti) = 0 if Ti E 1, otherwise VpL(Ti) = 1.</p><p>This scheduling function is reasonable only in a probabilistic sense, since given two conflicting transactions, outcomes are permitted in which neither or both are active. A possibly more! serious problem is that in an actual system, if two transactions conflict, it is in general more likely that the transaction that began most recently will be waiting on the other "older" transaction, since the latter transaction will have had more time to acquire locks on needed resources and data items. Nevertheless, this simple model appears to yield accurate predictions on the overall behavior of t:he effective level of concurrency for standard locking policies, as will be seen in Election 3. For this scheduling function, the computation of the expected number of active transactions for the first cycle is straightforward: each transaction !Z'i is active if and only if for each transaction Tj, j # i, it is not the case that (1) Ti conflicts with Tj and (2) Ti is added to I as a result of the conflict. Since there are n -1 transactions Tj with j # i, Ti is active with probability (1 -~/2)(~-l). The expected number of active transactions for the first cycle, A&amp;(n, p), is thus n(1 -p/2)'"-". Note that A&amp;(n, p) + 0 for fixed p as n + 00.</p><p>The concurrent set during the rth cycle, r &gt; 1, may contain transactions for which this is the 9th cycle, q = 1, 2, 3, . . . , r (i.e., transactions that have been inactive for q -1 cycles). For a transaction with q = 1, the probability of being active is (1 -~/2)(~-l), as in the analysis of the first cycle. Next consider a transaction Ti with q = 2'. Let Xi be the subset of the concurrent set of the (r -1)st cycle consisting of those transactions that conflicted with Tie Note that the conditional probability of a transaction Tj completing at the end of the (r -1)st cycle, given that 7) E Xi, is less than the unconditional probability of Tj completing, since, if Tj E .Xi, it is known that Tj has at least one conflict. Thus the expected number of conflicts for Ti during its second cycle is greater than during its first, and, similarly, greater during its qth cycle than during its (q -1)st. We have the following result. AbL(n, p) is shown for various values of n and p in Figure <ref type="figure" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Strict Priority</head><p>We assume that the concurrent set is ordered by the priority relation on the transactions in S, with Ti having higher priority than Tj if i &lt; j. With this definition of priority, the scheduling function corresponding to the class of strict priority policies, Vsp, is as follows: for each transaction Tip if for some j &lt; i there exists a conflict Cji, then Vsp(Ti) = 0, otherwise Vsp(Ti) = 1.</p><p>Consider the operation of the system during the first cycle. Each transaction Ti has i -1 higher priority transactions, and since for this class of policies we assume that the priority relation is independent of conflicts, Ti is active with probability (1p)'-l. Therefore, the expected number of active transactions during the first cycle, A&amp;(n, p), is</p><formula xml:id="formula_0">A,&amp;(n, p) = i (1 -p)i-l = '11 yl I"d; = 1 -(i-P)". i=l</formula><p>Note that A&amp;(n, p) is bounded above by l/p. Next we examine the probability of Ti completing in the rth cycle, r &gt; 1. If Ti is a new transaction in the concurrent set for this cycle, then its probability of completion is again (1 -P)~-'. Otherwise it was present and inactive in the previous cycle as, say, Tip. Note that the conditional probability of Ti not conflicting with a higher priority transaction, given that there was at least one such conflict in the previous cycle, is no greater than (1 -P)~-', since transactions in the (r -1)st cycle with higher priority than Ti* completed independently of conflicts with Tie. This yields the following result. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Essential Blocking with Priority</head><p>As in the case of strict priority policies, we order the concurrent set using the priority relation. The class of essential blocking with priority policies is represented in the random graph model by defining a scheduling function VEB that satisfies the property that Ti can block Tj only if i &lt; j and VEB(Ti) = 1. Such a scheduling function can be defined recursively as follows: (1) V,,( Tl) = 1, and</p><p>(2) for each Tiy if for some j &lt; i with VE,(Tj) = 1 there exists a conflict Cji, then VEB (Ti) = 0, otherwise VEB (Ti) = 1.</p><p>Consider the operation of the system under V Es during the first cycle. Let ei be the probability that Ti is active. Since we are assuming that the priority a.</p><p>P. Franaszek and J. T. Robinson Next consider the opera.tion of the system during the rth cycle, r &gt; 1. If a transaction Ti in the concurrent set of the rth cycle was in the concurrent set of the (r -l)st cycle, then it is known that Ti conflicted with one or more higher priority active transactions. However, all such transactions completed and were removed from the concurrent set at the end of that cycle. Note that under essential blocking the conflicts that occur between inactive transactions in a given cycle are independent of the set of transactions to complete in that cycle, since an inactive transaction does not block any other transaction. Furthermore, conflicts between transactions in S occur independently, and thus Ti is equivalent to a new transaction in terms of its probability of conflict with other transactions in the rth cycle. It follows that oi is the steady state probability that Ti completes in a given cycle.</p><p>LEMMA. ai satisfies and the fact that 0 -E pai 5 1. For the lower bound, let</p><formula xml:id="formula_1">L1 = 1, Li+l = Li 1 - i ' p(i -1) + 1 ) -</formula><p>The solution to this is Li = 1-P p(i -2) + 1' and it is easy to prove by induction that Li 5 ai, using (from the upper bound) l-P p(i -1) + 1 Consider a scheduler that has complete knowledge of all conflicts that will occur between transaction pairs, and uses this information so as to maximize the expected steady state effective level of concurrency. The selection of active transactions in a given cycle has two goals: (a) to maximize the number of active transactions in the current cycle, and (b) to minimize the conflicts in subsequent cycles. Figure <ref type="figure" target="#fig_7">4</ref> shows all conflict graphs for n = 4. A brute force analysis of these graphs (omitted here) leads to the observation that the above goals are on the average contradictory: removing a maximal set of nonconflicting transactions leads to a greater expected number of conflicts for the next cycle. Although this may be true in general, our purpose in considering conflict-dependent policies is only to estimate the improvement that could be achieved by such an approach. In the following we ignore goal (b), and consider only conflict-dependent scheduling that meets goal (a). Also, it is assumed that conflicts occur independently with probability p, as is the case in the first cycle of operation.</p><p>Let VcD be a scheduling function that selects a set of active transactions Y of maximal size, subject to the constraint that for all i, j, i &lt; i, if Ti E Y and Tj E Y, then Cij does not occur. Note that VcD is not determined uniquely, since there may be more than one subset Y of maximal size satisfying the above constraint; however, the following applies to any such scheduling function.</p><p>Let F(k) be the probability that k or less transactions are active and that nk or more transactions are inactive under V cn. Note that F(k) is the discrete c.d.f. of the random variable that is the number of active transactions, and that F(0) = 0 and F(n) = 1.  The lower bound AEB (computed exactly, using the recurrence of Section 2.3) and the upper bound given above are shown in Figure <ref type="figure">5</ref> for various values of n andp. Examining this figure, we conclude that although some performance gains may be possible using conflict-dependent scheduling, it appears that no dramatic improvements such as an order of magnitude increase in the effective level of concurrency can be expected. Fig. <ref type="figure">5</ref>. Bounds on expected active transactions for conflict-dependent policies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">NEW POLICIES, SIMULATIONS, AND COMPARISONS</head><p>The simplifying assumption of the random graph model that conflicts occur independently between pairs of transactions uniformly with probability p makes it seem difficult to apply the analytic results directly to actual transaction processing systems. First, in an actual system, transactions do varying amounts of work: a transaction that accesses many data objects and/or takes a long time to execute will clearly have a higher probability of conflict than a "small quick" transaction. In other words, the pairwise probability of conflict is not uniformly p. Second, scheduling policies in which transactions are made to wait affect the set of concurrently executing transactions, so that if we were to examine successive states of an actual system, conflicts would not be seen to occur independently. For example, imagine that a "snapshot" was taken in an actual system using a locking-based scheduling policy by saving the current wait-graph at the completion of each transaction. Then, if by chance it happened at some point that m transactions T,, T2, . . . , T,,, were waiting each for the next in a chain, with T2 waiting on T1, T3 waiting on T2, and so on, then T,,, would be waiting on T,,-, for at least m -1 successive snapshots, assuming no transaction in the chain was aborted. That is, conflicts are not regenerated pairwise independently in successive system states in locking-based policies, since some transactions that conflict are "held back" by the scheduler. This is essentially the effect that led to the analytic expressions of Propositions 1 and 2 in the previous section being upper bounds rather than exact results. Third, regarding the limiting values of the analytic expressions of Section 2, in any real system the database will consist of some maximum number of indivisible granules, and clearly there can never be more concurrent transactions doing useful work than this number. There are many similar considerations, such as the effect of deadlock resolution, the effect l P. Franaszek and J. T. Robinson of data structures used by the transaction processing system, the effect of interleaving of transactions, and so on, that are not addressed in the random graph model.</p><p>However, as explained earlier, our goal is not to analyze in detail the performance of actual systems, but to investigate system-independent limitations on the effective levels of concurrency that result from various basic types of scheduling policies. One can hypothesize that the random graph model captures enough of the behavior of dynamic transaction processing systems to give valid predictions on the nature of the performance limits of these systems as the total level of concurrency is increased. Another consideration is the followfng: the "real-life" scheduling policies that were the motivation for the three scheduling functions of Section 2 can achieve an increase in the effective level of concurrency only by aborting more transactions, but the distinction between a transaction that is waiting and a transaction that will later be aborted is not made in the random graph model. For optimistic methods this distinction is not needed: since no transactions wait, all inactive transactions are doing wasted work. For the "wound-wait" method, though, the cost in wasted work of achieving an increase in the effective level of concurrency is of interest. Finally, the definition of essential blocking suggests new locking-based scheduling policies, described below in Section 3.2.</p><p>For these reasons-to try to validate the random graph model, to determine the costs of achieving increases in the effective level of concurrency in wasted work, and to investigate new scheduling policies suggested by the concept of essential blocking-simulations were done of an abstract transaction processing system. Before discussing the scheduling policies that were used, and the validation procedure, it is necessary to discuss in more detail the simulation model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Simulation Model</head><p>In the simulation model there are d distinct objects, where d is called the database size, n processors, and initially n concurrent transactions. A transaction exists through one or more incarnations, where each incarnation consists of a number of steps, each of which is processed in one unit of time: an initialization step, followed by one or more access steps, and, finally, if the transaction is not aborted, a completion step. If a transaction is aborted, a new incarnation begins, as described below. Otherwise the transaction completes, and a new transaction enters the system on the next step. That is, there are always exactly n concurrent transactions in the system.</p><p>When a transaction enters the system, and its first incarnation begins, the number of access steps it executes, along with the object accessed in each step, is randomly generated, and the starting "time" of the transaction (generated by incrementing a counter) is recorded. At each access step, the transaction requests access from a scheduler. Each access request is interpreted as a request for exclusive access to the object from the beginning of the step when the access request is issued until the end of the step when the transaction is aborted or completed. Based on the decision of the scheduler, the transaction either begins waiting, is aborted, or executes its access step. In the case where the transaction begins waiting, it continues to wait either until all the transactions it conflicts with are aborted or completed, or until it is aborted due to some other conflict that occurs after it begins waiting. The scheduling policies that were used are described in the following section.</p><p>All transactions that are not waiting due to an access request execute in parallel, so that in one unit of time up to n steps can be executed concurrently. Note that a transaction can be delayed only due to conflicts with other transactions. Our motivation in using an infinite server model is similar to our choice of the random graph model in the previous section: although a model with CPU and I/O queueing delays would be more immediately applicable to certain types of actual systems, it would offer less insight concerning inherent limitations of concurrency due to conflict among transactions.</p><p>At the beginning of each unit of time the access requests of all transactions beginning an access step are processed in random order, any order equally likely. In the case in which a transaction is aborted, a new incarnation is begun on the next step, with the same number of accesses and the same object accesses in each step as in the previous incarnation.</p><p>All the steps of a transaction were classified as one of three types: (1) a waiting step is a step in which an incarnation of the transaction is waiting; (2) a wasted step is an initialization or access step executed by an incarnation that was later aborted; and (3) a useful step is an initialization, access, or completion step of an incarnation that completed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Scheduling Policies</head><p>Six scheduling policies were simulated, three of which were the motivation for the definition of the three scheduling functions of Section 2. These three were as follows, where in each case the actions taken in response to a request that causes a conflict are described (any access request that did not cause a conflict was of course granted).</p><p>(1) Standard locking. The requesting transaction is made to wait on all transactions whose current incarnation has previously requested access to the object causing the conflict (henceforth we call this set of transactions the conflicting transactions). If this results in a deadlock, the transaction participating in the deadlock with the greatest starting time (the most "recent" transaction) is aborted.</p><p>(2) Older priority. First, define the priority of a transaction as the starting time of the transaction, with lesser starting times giving higher priority (that is, "older" transactions are given higher priority). The requesting transaction is made to wait on all conflicting transactions with higher priority, and all conflicting transactions with lesser priority are aborted. Note that this is the "woundwait" method of [ 131, with starting times used for transaction numbering.</p><p>(3) Optimistic. Access requests of transactions are always granted. Whenever a transaction reaches the completion step, all transactions whose current incarnation has previously been granted access to any object accessed by the completing transaction are aborted. In this policy, conflicting transactions are aborted at the time of validation of the completing transaction (as in <ref type="bibr" target="#b11">[12]</ref>), which results in less wasted work than optimistic methods in which conflicting transactions are aborted when they request validation. The older priority policy is a strict priority policy, while the optimistic policy is an example of a policy that satisfies the essential blocking property. The results of Section 2 suggest that essential blocking should yield substantially greater effective levels of concurrency for large n. However, as explained earlier, essential blocking has the disadvantage that, if it is obtained using an optimistic policy, no transactions wait: all transactions not doing useful work are doing wasted work. Since the number of transactions doing wasted work is expected to be n -O(log(n)), this is a potentially serious problem.</p><p>The amount of wasted work under an optimistic policy might be reduced by determining at some point that a given transaction Tl is unlikely to "win" the race to the completion step with a conflicting transaction T2. In such a case, Tl could be made to wait on Tz if the conflict resulted from its current request, otherwise Tl could be aborted immediately. Alternatively, essential blocking might be approximated using incremental locking techniques by not permitting a transaction to wait on other transactions that are known not to be doing useful work. The simplest such criterion when incremental locking techniques are used is that a waiting transaction is not doing useful work. Expressing this as a form of priority leads to the following policy:</p><p>(4) Running priority (RP). Define the priority of a transaction as 1 if the transaction is not waiting, otherwise its priority is 3, with 1 as highest priority. Process an access request that causes a conflict by first evaluating the priority of all conflicting transactions, with the requesting transaction being given priority 2, and then follow the older priority method above, using this new definition of priority. This results in the requesting transaction waiting on all conflicting transactions that are running, and all conflicting transactions that were waiting at the time of the request being aborted.</p><p>There are two ways in which waiting/running priorities can be combined with starting time priorities: we can either take the disjunction or the conjunction of the two priority relations. This results in the following two scheduling policies:</p><p>(5) Older or running priority (OOR). Combine the older priority and running priority policies by having the requesting transaction wait on all conflicting transactions that are older or are running, and by aborting all conflicting transactions that are not older and are waiting. <ref type="bibr" target="#b5">(6)</ref> Older and runningpriority (OAR). Combine the older priority and running priority policies by having t.he requesting transaction wait on all conflicting transactions that are older and are running, and by aborting all conflicting transactions that are not older or are waiting.</p><p>In addition to standard locking, deadlock can occur under the older or running priority (OOR) policy. For this policy, deadlock was also resolved by aborting the most recent transaction participating in the deadlock, as in standard locking. It is easy to show that deadlock cannot occur in any of the remaining four policies.</p><p>The simulation results presented below indicate that the running/waiting status of a transaction is indeed useful: ranges of n and p exist for which of the two new policies yield better t.rade-offs between useful and wasted work than the earlier policies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MJWER OF CUdCURRENT TrUNW3IM</head><p>Fig. <ref type="figure">6</ref>. Useful steps for d = 1000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Simulation Results</head><p>Two sets of simulations were done, one set with a database size d = 1000 and another set with d = 2000, for n = 10, 20, 30,. . . , 100, 120, 140,. . . , 200, 250, and 300, and for each of the six scheduling policies. In all runs the number of access steps of a new transaction was generated by selecting one of 8, 9, 10, 11, or 12 access steps, any equally likely, and the object accessed in each access step was generated by randomly selecting one of the d objects, any equally likely. Note that it was possible that more than one access step of a transaction could be for the same object. If a transaction requested access from the scheduler for an object to which it had previously been granted access, it was simply granted access again.</p><p>In each run the model was simulated for 3000 steps. Statistics on the total number of waiting, wasted, and useful steps were saved and reset at the end of each 1000 steps. Thus, statistics for the first lOOO-step segment could have included some start-up transient, but it will be seen that the statistics for a given d, IL, and scheduling policy were close for the three segments in all cases.</p><p>All statistics were normalized by dividing by 1000, resulting in the average number of transactions waiting, executing a wasted step, or executing a useful step, at each step of the segment. The results are shown in Figures <ref type="figure" target="#fig_12">6 through 11</ref>. Note that there are three curves for each policy: one for each lOOO-step segment.</p><p>Several results are of interest. First, note that the curves representing useful steps for the standard locking, older priority, and optimistic methods generally correspond to the predictions of the random graph model: under the standard locking method, the number of useful steps reaches a maximum and then is monotonically decreasing; under the older priority method, the number of useful steps is monotonically increasing but seems to be approaching a constant; and under the optimistic method, the number of useful steps is monotonically increasing but does not seem to be approaching any limiting value. This correspondence is analyzed more exactly in the following section. The difference between the older priority and OAR policies is that, in the latter policy, there is an additional condition in which a conflicting transaction is aborted: a conflicting transaction is aborted if it is currently waiting, even if it is older than the requesting transaction.</p><p>The simulation results show that, although this leads to significantly more wasted work, it does not affect the effective level of concurrency, since the useful steps for these two policies are uniformly close. Thus, using OAR does not offer any advantages over older priority.</p><p>The peak in useful steps under standard locking occurs at about n = 20 for d = 1000 and at about n = 40 for d = 2000. "Blow-ups" of Figures <ref type="figure">6</ref> and<ref type="figure" target="#fig_4">9</ref>, showing this peak more clearly, are shown in Figures <ref type="figure" target="#fig_13">12</ref> and<ref type="figure" target="#fig_14">13</ref>. Up to this peak, all policies yield roughly similar performance in terms of useful steps; however, standard locking has the advantage of having the lowest level of wasted work. We believe that most current systems either have a small enough degree of concurrency or sufficiently low probability of conflict that they operate in the region well to the left of this peak.</p><p>To the right of the standard-locking peak, the number of useful steps under standard locking falls sharply, eventually reaching levels that could have been achieved with very small n. Higher throughput requires other forms of concurrency control, independently of the particular system. Although the optimistic method gives the most useful steps, it does so only at a very high cost in wasted work. For example, for d = 1000 and n = 300, there are 6.1 wasted steps for every useful step under the optimistic method, and for d = 2000, n = 300, there are 3.4 wasted steps per useful step. The next two best methods in this region, in terms of useful steps, are the RP and OOR policies. These methods also result in a peak and subsequent drop in the effective level of concurrency, but these peaks occur well to the right of that for standard locking. Prior to this second set of peaks, since these two methods are also best in terms of doing the least wasted work (with the exception of standard locking), these are probably the best choices for a system operating in this region. Subsequent to these peaks, increasing the  PRICRITY effective level of concurrency appears to require a closer approach to essential blocking.</p><p>There is a range of total levels of concurrency lying between the peaks for standard locking and those for the RP and OOR policies where the latter policies yield improved trade-offs between the effective level of concurrency and the amount of wasted work. For example, consider the simulation data for d = 1000 shown in Figures <ref type="figure">6</ref> and<ref type="figure">7</ref>. The peak for standard locking occurs at about n = 20 (as noted above), but the peak for the RP policy is at approximately n = 80. At n = 80, the optimistic policy yields an average of 27.6 percent more useful work than the RP policy, but at a penalty of 2.7 times as much wasted work. For n = 40, the useful steps for the optimistic and RP policies are essentially the same, about 50 percent more than the maximum for standard locking. Here the ratio of useful to wasted work produced by the RP policy is approximately a factor of three better than that resulting from the optimistic policy. This is a significant improvement, since the optimistic policy is at this total level of concurrency yielding less than one useful step for every two steps executed.</p><p>The exact point at which the OOR or RP policies would perform better than standard locking in a real system is highly system-dependent. First of all, we expect that these policies will be useful primarily in systems that are "contention bound" under standing locking, that is, systems in which increased throughput is limited by conflicts among transactions and not by CPU, I/O, or communication bottlenecks. Given a contention-bound system, the cost of wasted work could depend on several factors. For example, in a multiprocessor system in which data objects are cached in memories local to processors executing transactions, a transaction that is later restarted, and thus doing wasted work, can actually be doing some useful work in caching copies of data objects [ 121. A more detailed model of a system of interest would be required to determine whether the OOR or RP policies would provide more throughput than standard locking at a given level of concurrency in that particular system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Comparisons to Random Graph Model Analysis</head><p>In order to compare the analysis of Section 2 with the simulation results in more detail, we first need a value for p. As explained earlier, there are various complex effects that can influence the probability of conflict between transactions, but, as a first approximation, we simply assume that two concurrent transactions conflict if they access any common object. In the simulations, each transaction accessed 8, 9, 10, 11, or 12 objects, any number equally likely, and each object access was to one of d objects, any equally likely, independently of all other accesses. Given two random selections of d objects, with any object selected equally likely in each selection, the probability that the selections are to different objects is 1 -l/d. Next, by our assumption, two transactions accessing i and i objects respectively do not conflict only if all IJ pairs of selections are to different objects. In the case where i andj are small compared to d, the probability that two transactions conflict can be closely approximated by assuming that i distinct objects and j distinct objects are selected (for an exact analysis see <ref type="bibr" target="#b6">[7]</ref>), and is given by 1 -(1 -l/d)'j. Finally, there are 25 possible pairs (i, j). Therefore, under these assumptions,  The simulation results are compared to the analytic expressions derived in Section 2 by inverting these expressions to findp, as follows: for each lOOO-step segment of each simulation run, given the n used in that run, a value of p is found for each of the three expressions (1) n(1p/2)"-l, (2) (1 -(1p)")/p, and (3) 1 + (l/p)ln(p(n -1) + l), so that the resulting value is the average number of transactions executing useful steps per simulation step for that run. The resulting values are shown in Figures <ref type="figure" target="#fig_5">14</ref><ref type="figure" target="#fig_1">15</ref><ref type="figure" target="#fig_1">16</ref><ref type="figure" target="#fig_1">17</ref><ref type="figure" target="#fig_1">18</ref><ref type="figure" target="#fig_4">19</ref>for the standard locking, older priority, and optimistic methods, and for d = 1000, 2000. Note that there are three curves for each of the expressions (l)-(3): one for each lOOO-step simulation segment. The interpretation of these figures is that a constant value of p over n for one of the expressions (l)-(3) for a particular method indicates a fit of the analytic expression to the results of the simulations of that method.</p><p>The older priority and optimistic methods do indeed appear to have an associated constant value of p, and, in fact, plots of the expressions (2) (for the older priority method) and (3) (for the optimistic method), using values of p estimated from the data of Figures <ref type="figure" target="#fig_1">15,</ref><ref type="figure" target="#fig_1">16</ref>, 18, and 19, fit the useful step results of the simulations quite closely, lying uniformly within the "noise" of the statistics for each of the three segments of each run. However, the values of p estimated from this data (0.079 for Figure <ref type="figure" target="#fig_1">15</ref>, 0.076 for Figure <ref type="figure" target="#fig_1">16</ref>, 0.041 for Figure <ref type="figure" target="#fig_1">18</ref>, and 0.036 for Figure <ref type="figure" target="#fig_4">19</ref>) fall below ~(1000) and ~(2000) computed above. Although the expressions above were derived in Section 2 only as upper bounds on the effective level of concurrency, some of the additional factors that could result in this discrepancy are: (1) two concurrent transactions that access a common object will not conflict in the simulations if they overlap so that one completes before the second requests access to the common object, in contrast to the assumption made in derivingp(d) above; (2) for the older priority method, in the case where Returning to the standard locking method, although the values of p derived from expression (1) are not constant, they are "relatively" constant, lying within the range 0.04 5 p 5 0.09 for Figure <ref type="figure" target="#fig_5">14</ref>  back" effect of locking described earlier, and that the decrease in p starting at n = 50 in Figure <ref type="figure" target="#fig_5">14</ref> and n = 90 in Figure <ref type="figure" target="#fig_1">17</ref> is partly due to the deadlock resolution procedure: since, given a deadlock, the most recent transaction participating in the deadlock is aborted, as the number of deadlocks increases one would expect more of an older priority kind of behavior, leading to a higher effective level of concurrency. Another effect is the following: in the case where many transactions are currently waiting, each waiting transaction will have requested access to some number of objects less than all of its accesses, so that a new transaction entering the system will have a probability of conflict lower than that computed above. In summary, although the analytic expression for standard locking does not fit the simulation results exactly, it is possible to vary p over a small range so that the expression does coincide with the simulation results. This expression does capture the essential behavior of this method, consisting of a peak and subsequent fall-off of the effective level of concurrency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">SUMMARY AND CONCLUSIONS</head><p>We have shown that three basic classes of concurrency control methods have fundamentally different limiting properties, independent of any particular system: as the total level of concurrency n is increased and the pairwise probability of conflict p remains fixed, the effective level of concurrency (1) reaches a maximum and then goes to zero under priority-less policies such as standard locking methods, (2) increases but is bounded by l/p for strict priority policies such as the older priority method, and (3) increases indefinitely under policies satisfying the essential blocking property such as optimistic methods, but only at a rate of O(log (n)). Although an increase in the effective level of concurrency may be possible using conflict-dependent scheduling, it appears that no dramatic increase can be expected in the case where conflicts occur independently.</p><p>In terms of current systems, these results are of practical importance only for fairly large n or p. However, recent work on parallel program structuring, and on operating system design for distributed systems consisting of large numbers of processors, has focused on the use of the database transaction concept as a fundamental construct for system development (e.g., see <ref type="bibr">[lo, 141)</ref>. In systems in which a transaction mechanism is used at the lowest level, one might expect greater numbers of concurrent transactions than in today's transaction processing systems. Even in the case of traditional transaction processing systems, throughput requirements are in many cases growing rapidly, while response times are limited by such factors as disk accesses. This suggests that substantial increases can be expected in multiprogramming levels.</p><p>As explained earlier, essential blocking has the disadvantage that it results in very high costs in wasted work if it is obtained using optimistic methods. However, it has been shown that essential blocking can be approximated by using information on the running/waiting states of conflicting transactions in the scheduler. Two such methods, the RP and OOR policies, offer significant performance advantages over standard locking for relatively large n or p, in terms of yielding high effective levels of concurrency at comparatively small costs in wasted work. Although the effective level of concurrency also peaks and then drops under these policies, the peaks occur for much larger values of n than with standard locking. Thus, these techniques have the potential to significantly extend the usefulness of incremental locking in contention-bound systems.</p><p>The essential blocking property can also be obtained when transactions request all required locks at initiation time. This could be the case, for example, in the proposed distributed operating systems mentioned above that use transactions as a fundamental construct, since one might expect typical operating system primitives to be "simpler" than the application programs of current transaction processing systems. This would avoid the wasted work problem of optimistic methods, but the problem that the effective level of concurrency increases at a rate of only O(log (n)) still remains. If we assume that the utilization of every processor is held fixed, the conclusion is that a linear increase in the number of processors requires an exponential increase in the total number of concurrent transactions in the case where conflicts occur independently with fixed probability. The implication is that distributed systems consisting of extremely large numbers of processors can be effectively utilized only if they can be designed so that conflicts do not occur independently (and this is used to advantage), or else designed so that the probability of conflict decreases with increasing system size. A more precise analysis requires more detailed system assumptions, and is a subject for future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Upper bounds on expected active transactions for priority-less policies,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>PROPOSITION 1 .</head><label>1</label><figDesc>The steady state expected number of active transactions under the priority-less scheduling function, ApL(n, p), satisfies &amp;A P) &lt; &amp;L(n, P) = n 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>PROPOSITION 2 .</head><label>2</label><figDesc>The steady state expected number of active transactions under the strict priority scheduling function, AsP(n, p), satisfies &amp;dn, , p) is shown for various values of n and p in Figure2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Upper bounds on expected active transactions for strict priority policies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>9 The</head><label>9</label><figDesc>---= p(i -1) + 1. PROOF. For the upper bound, let u; = 1, ui Ui+l = ~ 1 + PUi' ACM Transactions on Database Systems, Vol. 10, No. 1, March 1985. Limitations of Concurrency in Transaction Processing l 1) + 1' and it is easy to prove by induction that ai 5 Ui, using Ui+l = *i (1 -(Pai)2)9</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>5 1 -Fig. 4 .</head><label>14</label><figDesc>Fig. 4. All conflict graphs for n = 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>lP.</head><label></label><figDesc>Franaszek and J. T. Robinson LEMMA. Let G(k) = (1 -(1 -p) W+W) (k:l).Then F(k) 2 G(k), 0 5 k &lt; n.PROOF. F(k) (k &lt; n) is the probability that all subsets of transactions of size k + 1 contain at least one conflict. Given a subset of transactions 2, let c(Z) be the event in which there exists at least one conflict between transactions in 2. Given two subsets, Z1 and ZZ, probM&amp;) n c&amp;J) = probM&amp;) I cG)hobM.&amp;)). If Z1 and Z2 do not have two or more transactions in common, ~(2,) and ~(2,) are independent, and so prob(c(Z1) 1 ~(2,)) = prob(c(&amp;)). Otherwise, ranging over the probability space restricted to c(Z,), a conflict appearing in 22 may also appear in &amp;, in which case c(Z,), and so prob(c(ZJ lc(&amp;)) &gt; prob(c(2,)). Repeating, it can be shown that given subsets &amp;, 22, 23, . . . , prob(c(&amp;) n ~(2,) n c(&amp;) . . .) L prob(c(Zi))prob(c(Z2))prob(c(Z3)) . . . . Next, given a subset of size k + 1, there are k(k + 1)/2 transaction pairs in the subset, and so there is at least one conflict with probability 1 -(1 -P)~(~+')". The lemma follows from the fact that there are (kr'+l) subsets of size k + 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>PROPOSITION 4 .</head><label>4</label><figDesc>If all conflicts occur independently, each with probability p, the expected number of active transactions under the conflict-dependent scheduling function Vco, Aco(n, p), satisfies n-1 AEB(n, p) 5 AcD(~, P) 5 n -c (1 -(1 -P) k(k+lW)(k:l)~ k=l PROOF. The lower bound follows from the fact that we can define VcD as the essential blocking scheduling function with priorities assigned based on an analysis of C so as to maximize the number of active transactions: we simply assign every Ti in Y (where Y is as in the definition of Vco) a higher priority than all Tj not in Y. Therefore, under Vco we must have an equal number or more active transactions than under VEB with priorities assigned independently of conflicts. For the upper bound, evaluating Ace using F(k): AcD(n, p) = (F(1) -F(0)) + 2(F(2) -F(1)) + 3(F(3) -F(2)) + . . . + n(F(n) -F(n -1)) = n -F(1) -F(2) -. . . -F(n -1) 5 n -G(1) -G(2) -. . . -G(n -1). 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>lP.</head><label></label><figDesc>Franaszek and J. T.Robinson    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 7 .Fig. 8 .</head><label>78</label><figDesc>Fig. 7. Wasted steps for d = 1000.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 9 .Fig. 10 .</head><label>910</label><figDesc>Fig. 9. Useful steps for d = 2000.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Waiting steps for d = 2000.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Useful steps for d = 1000, n 5 40.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Useful steps for d = 2000, n I 80.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>p as a function of d is Evaluating this for d = 1000 and d = 2000 gives ~(1000) = 0.095 and ~(2000) = 0.049.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. p computed for standard-locking simulations, d = 1000.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>Fig. 15. p computed for older priority simulations, d = 1000.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>Fig. 19. p computed for optimistic method simulations, d = 2000.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>ACM Transactions on Database Systems, Vol. 10, No. 1, March 1985, Pages 1-28.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>ACM Transactions on Database Systems, Vol. 10, No. 1, March 1985.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>P. Franaszek and J. T.Robinson   </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>P. Franaszek and J. 7'.Robinson   </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p>ACM Transactions on Database Systems, Vol. 10, No. 1, March 1985.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_5"><p>ACM Transactions on Database Systems, Vol. 10, NO. 1, March 1985.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_6"><p>ACM Transactions on Database Systems, Vol. 10, No. 1. March 1985.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_7"><p>l P. Franaszek and J. T. Robinson</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Integrated concurrency control and recovery mechanism: Design and performance evaluation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Dewitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rep</title>
		<imprint>
			<biblScope unit="volume">497</biblScope>
			<date type="published" when="1983-02">Feb. 1983</date>
		</imprint>
		<respStmt>
			<orgName>Computer Sciences Dept., Univ. of Wisconsin-Madison</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Modelling and evaluation of database concurrency control algorithms</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Carey</surname></persName>
		</author>
		<ptr target="UCB/ERL83/56" />
		<editor>Ph.D. P. Franaszek and J. T. Robinson dissertation</editor>
		<imprint>
			<date type="published" when="1983-09">Sept. 1983</date>
		</imprint>
		<respStmt>
			<orgName>Electronics Research Lab., Univ. of California, Berkeley</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Concurrency control performance issues</title>
		<author>
			<persName><forename type="middle">B I</forename><surname>Galler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982-09">Sept. 1982</date>
		</imprint>
		<respStmt>
			<orgName>Dept. of Computer Science, Univ. of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Performance of update algorithms for replicated data in a distributed database</title>
		<author>
			<persName><forename type="first">Garcia-M</forename><surname>Lina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1979-06">June 1979</date>
		</imprint>
		<respStmt>
			<orgName>Dept. of Computer Science, Stanford Univ.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation (STAN-CS-79-744</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Notes on database operating systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Operating</forename><surname>Systems</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Bayer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Graham</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Seegmuller</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1978">1978</date>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="393" to="481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On optimistic methods for concurrency control</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Kung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Database Syst</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="213" to="226" />
			<date type="published" when="1981-06">June 1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The distribution of granule accesses made by database transactions</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Langer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="831" to="832" />
			<date type="published" when="1982-11">Nov. 1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Queueing analysis of global locking synchronization schemes for multicopy databases</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput. C</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="371" to="384" />
			<date type="published" when="1980-05">May 1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Performance evaluation of two concurrency control mechanisms in a distributed database system</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM-SIGMOD 1981 International Conference on Management of Data</title>
		<meeting>ACM-SIGMOD 1981 International Conference on Management of Data<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="84" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Process structuring, synchronization, and recovery using atomic actions</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Lomet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGPLAN Not</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<date type="published" when="1977-03">Mar. 1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Analysis of locking policies in database management systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Potier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Leblanc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="584" to="593" />
			<date type="published" when="1980-10">Oct. 1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Experiments with transaction processing on a multimicroprocessor. Rep. RC 9725, IBM</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Robinson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982-12">Dec. 1982</date>
			<publisher>Watson Research Center</publisher>
			<pubPlace>Yorktown Heights, N.Y.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">System level concurrency control for distributed database systems</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rosenkrantz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Stearns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><surname>Ii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Database Syst</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="178" to="198" />
			<date>June 19781</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Transactions: A construct for reliable, distributed computing</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Z</forename><surname>Spector</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Syst. Reu</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="18" to="35" />
			<date type="published" when="1983-04">Apr. 1983</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
