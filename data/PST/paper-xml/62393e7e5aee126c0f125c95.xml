<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Clickbait Spoiling via Question Answering and Passage Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-03-19">19 Mar 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Matthias</forename><surname>Hagen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Martin-Luther-Universität Halle-Wittenberg</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Maik</forename><surname>Fröbe</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Martin-Luther-Universität Halle-Wittenberg</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Artur</forename><surname>Jurk</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Martin-Luther-Universität Halle-Wittenberg</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Leipzig University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Clickbait Spoiling via Question Answering and Passage Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-03-19">19 Mar 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2203.10282v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce and study the task of clickbait spoiling: generating a short text that satisfies the curiosity induced by a clickbait post. Clickbait links to a web page and advertises its contents by arousing curiosity instead of providing an informative summary. Our contributions are approaches to classify the type of spoiler needed (i.e., a phrase or a passage), and to generate appropriate spoilers. A large-scale evaluation and error analysis on a new corpus of 5,000 manually spoiled clickbait poststhe Webis Clickbait Spoiling Corpus 2022shows that our spoiler type classifier achieves an accuracy of 80%, while the question answering model DeBERTa-large outperforms all others in generating spoilers for both types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>New York Post</head><p>@nypost Just how safe are NYC's water fountains? nyp.st/2yHSGnr</p><p>"The Post independently tested eight water fountains in New York City's most frequented parks, and found that all met or exceeded the state's guidelines for water quality."</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Clickbait is the term used to describe posts in social media that are intended to inappropriately entice their readers to visit a web page. This is achieved through formulations such as sensationalism or cataphors that are believed to create a so-called curiosity gap: "a form of cognitively induced deprivation that arises from the perception of a gap in knowledge or understanding" <ref type="bibr" target="#b23">(Loewenstein, 1994)</ref>. Clickbait is perceived as inappropriate since its resolution is usually ordinary or trivial, comprising little more than a phrase, short passage, or a list of things that could just as easily have been included in the post. This observation motivates us to introduce the task of clickbait spoiling: identifying or generating a spoiler for a clickbait post.</p><p>Figure <ref type="figure" target="#fig_1">1</ref> shows four examples of clickbait on Twitter, along with spoilers. The first two tweets explicitly or implicitly promise a surprising resolution to spark curiosity, but their spoilers are brief and trivial. The linked page of the first tweet adds almost nothing, and the spoiler of the second is common sense. The third spoiler is a passage from the linked page, and the fourth is a list of things.  Even though there are length limits to the informativeness of tweets, the spoilers in all examples could easily have been part of the original tweets.</p><p>This paper reports about our investigation into clickbait spoiling and the following contributions:</p><p>(1) The Webis Clickbait Spoiling Corpus 2022 (Webis-Clickbait-22), consisting of 5,000 clickbait posts, their linked pages and a spoiling piece of text therein. <ref type="foot" target="#foot_0">1</ref> (2) A two-step approach to clickbait spoiling that first classifies a clickbait post according to its spoiler type (phrase or passage), and then treats spoiling either as a question answering or as a passage retrieval task. (3) A systematic evaluation of state-of-the-art methods for spoiler type classification, question answering, and passage retrieval. <ref type="foot" target="#foot_1">2</ref>Although the first step of spoiler type classification is not necessary, our results suggest that it can be helpful. Even more so, as we have not yet tackled multipart spoilers (bottom example in Figure <ref type="figure" target="#fig_1">1</ref>; 876 cases also part of our corpus) that probably require a different spoiling approach.</p><p>Following an overview of research on clickbait and its operationalization so far, models of question answering and passage retrieval are examined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Clickbait and its Operationalization</head><p>The underlying assumption of most research on clickbait is that it is a form of data-driven optimization of social media posts to exploit the curiosity gap described by <ref type="bibr" target="#b23">Loewenstein (1994)</ref>. At least that's what Peter <ref type="bibr" target="#b18">Koechley (2012)</ref>, the CEO of Upworthy, claimed. Upworthy became one of the first major spreaders of clickbait on Facebook, and their success has prompted Facebook to change its news recommendation algorithms to curb the amount of clickbait, twice <ref type="bibr" target="#b11">(El-Arini and Tang, 2014;</ref><ref type="bibr" target="#b31">Peysakhovich and Hendrix, 2016)</ref>.</p><p>Exploratory and theoretical studies of clickbait and its impact on journalism analyzed its prevalence for more than 150 publishers <ref type="bibr" target="#b38">(Rony et al., 2017)</ref>; its economics for the news market <ref type="bibr" target="#b25">(Munger, 2020)</ref>; its impact on perceptions of credibility and quality (overall negative) <ref type="bibr" target="#b24">(Molyneux and Coddington, 2020)</ref>; and noted a slow decline over the past decade <ref type="bibr" target="#b21">(Lischka and Garz, 2021)</ref>.</p><p>Journalistic studies of this kind rely on clickbait detection technologies. Originally proposed by <ref type="bibr" target="#b39">Rubin et al. (2015)</ref> but not followed up, <ref type="bibr" target="#b34">Potthast et al. (2016)</ref> and <ref type="bibr" target="#b1">Chakraborty et al. (2016)</ref> independently developed the first detectors. Starting from a shared task organized by <ref type="bibr" target="#b33">Potthast et al. (2018)</ref> shortly after, more than 50 approaches have been contributed to date. An overview is beyond the scope of our work, but transformer models dominate this task as well. For the clickbait generation task, preceded by a rule-based generator <ref type="bibr" target="#b10">(Eidnes, 2015)</ref>, only <ref type="bibr" target="#b40">Shu et al. (2018)</ref> and <ref type="bibr" target="#b42">Xu et al. (2019)</ref> have presented more advanced models, while <ref type="bibr" target="#b17">Karn et al. (2019)</ref> generate teaser headlines that are explicitly not meant to be clickbait. So far, no attempt has been made to generate spoilers for clickbait.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Question Answering</head><p>If one considers clickbait spoiling as a question answering problem, there are numerous possible solutions. Among the available question-answering benchmarks <ref type="bibr" target="#b9">(Dzendzik et al., 2021)</ref>, we select two to choose appropriate state-of-the-art models for our evaluation: (1) SQuAD <ref type="bibr" target="#b36">(Rajpurkar et al., 2016)</ref> compiles 107,785 questions and answers based on 536 Wikipedia articles. Although a wide range of questions and answers are included, the vast majority of 93.6% are factual (32% names, 31.8% noun phrases, 19.8% numbers, 5.5% verb phrases, and 3.9% adjective phrases), while the remainder are descriptive (3.7% clauses and 2.7% other). We use SQuAD v1.1, not the v2.0 superset <ref type="bibr" target="#b35">(Rajpurkar et al., 2018)</ref>, which contains unanswerable questions, since we do not expect clickbait to be "unspoilable". (2) TriviaQA <ref type="bibr" target="#b16">(Joshi et al., 2017)</ref> contains 95,000 question-answer pairs, mostly dealing with trivia questions that are supposed to be particularly difficult to answer. These are comparable to clickbait in that many of them address rather trivial things (see Figure <ref type="figure" target="#fig_1">1</ref>).</p><p>The question answering models used in our experiments are ALBERT <ref type="bibr" target="#b19">(Lan et al., 2020)</ref>, AllenAI-Document-QA <ref type="bibr" target="#b2">(Clark and Gardner, 2018)</ref>, BERT (cased/uncased) <ref type="bibr" target="#b8">(Devlin et al., 2019</ref><ref type="bibr">), Big Bird (Zaheer et al., 2020)</ref>, DeBERTa (large) <ref type="bibr" target="#b15">(He et al., 2021)</ref>, ELECTRA <ref type="bibr" target="#b3">(Clark et al., 2020)</ref>, Funnel-Transformer <ref type="bibr" target="#b6">(Dai et al., 2020)</ref>, MPNet <ref type="bibr" target="#b41">(Song et al., 2020)</ref>, and RoBERTa (base/large) <ref type="bibr" target="#b22">(Liu et al., 2019)</ref>. Many of them are or were state of the art on the above benchmarks and implement various different architectural paradigms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Passage Retrieval</head><p>Passage retrieval relaxes the question answering task a bit in the sense of allowing longer passages of text as answers (e.g., one or more sentences), rather than exact phrases or statements. Neural retrieval models, as surveyed by <ref type="bibr" target="#b13">Guo et al. (2020)</ref> and <ref type="bibr" target="#b20">Lin et al. (2021)</ref>, have been successfully applied to passage retrieval. One of the most important passage retrieval benchmarks is part of MS MARCO, a series of challenges whose first edition was a large question answering task <ref type="bibr" target="#b26">(Nguyen et al., 2016)</ref>. A passage retrieval dataset of 8.8 million passages was derived for the underlying set of 100,000 questions originally submitted to Bing. This dataset formed the basis for two consecutive shared tasks at the TREC 2019 and 2020 Deep Learning tracks <ref type="bibr" target="#b5">(Craswell et al., 2019</ref><ref type="bibr" target="#b4">(Craswell et al., , 2020))</ref>.</p><p>The passage retrieval models used in our experiments are MonoBERT <ref type="bibr">(Nogueira and Cho, 2019;</ref><ref type="bibr">Nogueira et al., 2019)</ref> and MonoT5 <ref type="bibr" target="#b28">(Nogueira et al., 2020)</ref> (both topped the MS MARCO passage retrieval leaderboard once), and the classic baseline models BM25 <ref type="bibr" target="#b37">(Robertson and Zaragoza, 2009)</ref> and Query Likelihood <ref type="bibr" target="#b32">(Ponte and Croft, 1998)</ref>, implemented in Anserini <ref type="bibr" target="#b43">(Yang et al., 2017)</ref>.</p><p>To tackle clickbait spoiling for the first time, we created the Webis Clickbait Spoiling Corpus 2022 (Webis-Clickbait-22), a collection of 5,000 clickbait posts and their associated spoilers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Corpus Construction</head><p>Our corpus is primarily based on five social media accounts on Twitter, Reddit, and Facebook that manually spoil clickbait: r/savedyouaclick, @HuffPoSpoilers, @SavedYouAClick, @Upwor-thySpoiler, and @StopClickBaitOfficial. With the goal of collecting 5,000 "spoilable" clickbait posts at an expected rejection rate of around 10% of unusable posts, 5,555 were initially collected from the accounts. Each of them was manually reviewed, and those that turned out not to be spoiled clickbait were removed (e.g., funny posts not intended to be spoilers, or posts with unavailable linked documents). The rejection rate was higher than expected, and only 4,204 posts remained.</p><p>To reach our goal of 5,000 posts, we then sampled from the Webis-Clickbait-17 corpus used in the Clickbait Challenge 2017 <ref type="bibr" target="#b33">(Potthast et al., 2018)</ref>. The corpus contains 38,517 tweets, each of which was rated by 5 annotators on a 4-point Likert scale for clickbaitiness: "no clickbait," "slight clickbait," "considerable clickbait," and "heavy clickbait." Of the tweets, 1,845 scored an average of 0.8 or higher and can safely be considered clickbait. We selected tweets from this subset and manually spoiled them based on the linked document until our target size of 5,000 posts was reached.</p><p>Thus, our final corpus consists of 4,204 posts from Twitter, Reddit, and Facebook that were spoiled by a third party specializing in this task, and 796 tweets from the Webis-Clickbait-17 corpus with an average clickbaitiness of at least 0.8 that we spoiled ourselves. For each of the 5,000 clickbait posts, we also reviewed and corrected erroneous spoilers and labeled their exact positions in the linked documents. Our internal guidelines dictated that a spoiler should be as short as possible (i.e., if one word is enough, not a whole sentence should be chosen). Since the underlying annotation task is simple, one main annotator was sufficient. Nevertheless, randomly selected as well as ambiguous cases were discussed with two additional experts among the co-authors. No systematic errors or unforeseen difficulties in solving the annotation task were identified during these discussions.</p><p>During our annotation, we found that none of the common approaches to main content extraction worked reliably for all the documents linked in the clickbait posts. Yet, clean content is a prerequisite for research on clickbait spoiling to eliminate as many confounding variables as possible. To ensure a clean corpus, one annotator manually extracted the main content of the linked documents, removing (inline) advertisements, links to related articles (e.g., "READ ALSO: [. . . ]" or "Also from CNBC [. . . ]"), credits (e.g., "Image credit: [. . . ]" or "Photo by [. . . ]"), and social media links (e.g., "Subscribe to [. . . ]" or "Follow us on [. . . ]"). A random selection was reviewed to ensure high quality.</p><p>Moreover, during spoiler annotation, it turned out that there are basically three types of spoilers:</p><p>(1) phrase spoilers consisting of a single word or phrase from the linked document (e.g., the first two spoilers in Figure <ref type="figure" target="#fig_1">1</ref>, but often named entity spoilers as well), (2) passage spoilers consisting of one or a few sentences of the linked document (e.g., the third spoiler in Figure <ref type="figure" target="#fig_1">1</ref>), and (3) multipart spoilers consisting of more than one non-consecutive phrases or passages of the linked document (e.g., the fourth spoiler in Figure <ref type="figure" target="#fig_1">1</ref>). Spoiler types were also annotated by the main annotator, and randomly checked by the other two.</p><p>In sum, each of the 5,000 posts in our corpus consists of a unique ID, the platform from which it was taken, the respective platform's post ID, the post's text (i.e., the "clickbait"), the URL to the linked document, the manually extracted title and paragraph-divided main content of the linked document, the manually optimized spoiler, the spoiler's character position in the main content, and the type of spoiler (phrase, passage, or multipart). In total, the annotation took about 560 hours, which marked the limit of our budget dedicated for this step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Corpus Statistics</head><p>Table <ref type="table" target="#tab_0">1</ref> summarizes the main statistics of our corpus. Most spoiled clickbait posts come from Twitter (47.5%) and Reddit (36%), whereas the Facebook account contributes less (16.5%). Most spoilers are phrases (42.5%) and passages (40%). That there are fewer multi-part spoilers could be due to the fact that spoiler account operators prefer to spoil "simpler" clickbait posts. For the corpus, we also provide a fixed random 80/20/20 train/validation/test split to ensure future reproducibility and comparability with our results. 4 Type-dependent Clickbait Spoiling</p><p>Our approach to clickbait spoiling is based on the observation that there are three types of spoilers: (1) phrase spoilers, (2) passage spoilers, and</p><p>(3) multipart spoilers. We assume that different tailored approaches will work best for each spoiler type. However, an important prerequisite for this is the corresponding classification of clickbait. Therefore, we first investigate how well the spoiler type of a clickbait post can be predicted (Section 4.1). The generation of phrase and passage spoilers for a given clickbait post is similar in that the solution to the problem in both cases amounts to extracting a coherent piece of text from the linked document. To this end, there are a variety of existing approaches in related disciplines whose output is either a phrase or a passage, and which may be adapted to clickbait spoiling. We therefore investigate whether phrase spoilers can be identified by conventional question answering methods (i.e., we treat a clickbait post as a "question" to which a phrase of the linked document should be returned as the "answer"; Section 4.2), and whether passage spoilers can be identified by conventional passage retrieval methods (i.e., we treat a clickbait post as a "query" and the paragraphs of the linked document as the collection from which to retrieve the best "passage"; Section 4.3). In our evaluation, we focus on phrase and passage spoilers and also examine the abilities of the above question answering and passage retrieval methods to serve as one-size-fitsall solutions for phrases and passages. For multipart spoilers, a novel approach will be needed, which is beyond the scope of our current work but an interesting direction for the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Spoiler Type Classification</head><p>For the spoiler classification subtask, we experimented with classic feature-based models (Naïve Bayes, Logistic Regression, SVM) and the neural models BERT-, DeBERTa-, and RoBERTa.</p><p>As feature types for the classic models, we use tf -and tf • idf -weighted word and POS tag uniand bigrams from the clickbait post and tf • idfweighted word and POS tag uni-and bigrams from the linked document. We include features from the linked document, since it has to be analyzed for the spoiler generation anyway. The idf values are calculated on the OpenWebText corpus <ref type="bibr" target="#b12">(Gokaslan and Cohen, 2019)</ref> to prevent any bias from the comparatively small size of our corpus.</p><p>The input for the neural models is a post concatenated with the main content of the linked document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Phrase Spoiler Generation</head><p>Viewing a clickbait post for which a phrase spoiler should be derived as a "question" and the linked document as potentially containing an "answer", phrase spoiler generation can be tackled by question answering methods. We therefore employ ten state-of-the-art question answering methods trained on the SQuAD data and fine-tune them on our new clickbait spoiling training set: AL-BERT, BERT (cased/uncased), BigBird, DeBERTa (large), ELECTRA, FunnelTransformer, MPNet, and RoBERTa (base/large).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Passage Spoiler Generation</head><p>Treating the clickbait post whose spoiler type is a passage as a "query" for which the "most relevant" passage from the linked document is to be retrieved, passage spoiler generation can be tackled by passage retrieval methods. We therefore use ten state-of-the-art passage retrieval approaches trained on the MS MARCO data: BM25 and QLD in four variants each (alone or with RM3/Ax/PRF query expansion), MonoBERT, and MonoT5. In addition, we also adapt all of the above question answering models to retrieve passages by simply considering the passage as the returned result from which the question answering model extracts its answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation of Spoiler Type Classification</head><p>In our evaluation, we assume a setup in which a previous clickbait detection would have (perfectly) identified posts as clickbait. To then evaluate the effectiveness of spoiler type classification on such detected clickbait posts, we conduct three experiments: (1) multi-class, (2) one-vs-rest, and (3) onevs-one for the types of phrase and passage spoilers. In all cases, the hyperparameters of the six studied classifiers were optimized based on the validation set of our corpus. For the three featurebased approaches, a chi-square feature selection step selected all post-based features and 70% of the document-based features. The post-based features are weighted 4-times higher than the documentbased features. Most hyperparameters of the transformer models were left at their default values, but a grid search was used to find the most effective combination of learning rate (1e-5, 4e-5, 1e-4), warm-up ratio (0.02, 0.06, and 0.1), stack size (8, 16, and 32), number of epochs (1 to 10), and maximum sequence length <ref type="bibr">(256,</ref><ref type="bibr">384,</ref><ref type="bibr">512)</ref>.</p><p>Table <ref type="table" target="#tab_1">2</ref> shows the balanced accuracy of the six classifiers. All are less effective in the multi-class setting than in the one-vs-rest settings and the transformer-based classifiers are clearly more effec- tive than the feature-based ones; DeBERTa is best in the multi-class setting (accuracy of 73.63) and RoBERTa in the one-vs-rest ones (79.12 to 80.39).</p><p>Table <ref type="table" target="#tab_2">3</ref> shows the accuracy of the six classifiers on the 826 test posts with phrase and passage spoilers (almost balanced setup, since there is hardly any class imbalance). Again, the transformerbased classifiers clearly are more effective than the feature-based ones; with RoBERTa achieving the best accuracy of 80.39.</p><p>The substantial improvements of DeBERTa and RoBERTa over the feature-based classifiers in all settings (about 9-10 accuracy points) indicates that classifying the clickbait spoiler type requires more advanced language "understanding" than what is encoded in the basic features that the Naïve Bayes, SVM, or logistic regression classifiers used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation of Spoiler Generation</head><p>To assess the effectiveness of the question answering and passage retrieval methods for clickbait spoiling, we evaluate both for their respective intended spoiler types, but each also for the respective other spoiler type. Multipart spoilers are deferred to future work. We continue to assume that prior clickbait detection (perfectly) identifies clickbait posts as such. Our evaluation of the generated spoilers includes quantitative and qualitative assessments (Section 6.1). In a pilot study with ten question answering and ten passage retrieval models at their default settings, two models in each category dominate the respective others (Section 6.2). The computationally expensive step of hyperparameter optimization is restricted to these four models plus two baselines (Section 6.3). Then, the effectiveness of spoiling clickbait posts dependent on spoiler type is evaluated (Sections 6.4 and 6.5), and compared to an end-to-end clickbait spoiling setup independent of spoiler type (section 6.6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Quantitative and Qualitative Assessment</head><p>We introduce the measures used to evaluate generated spoilers and how we manually determined thresholds for them above which a generated spoiler is considered as "correct".</p><p>Evaluation measures. To assess the quantitative correspondence between a derived spoiler and the ground truth, we use three question answeringoriented and one passage retrieval-oriented measure: BLEU-4 <ref type="bibr" target="#b30">(Papineni et al., 2002)</ref>, METEOR <ref type="bibr" target="#b0">(Banerjee and Lavie, 2005)</ref> in its extended version of Denkowski and Lavie (2014), BERTScore <ref type="bibr" target="#b45">(Zhang et al., 2020)</ref>, and Precision@1.</p><p>The three question answering-oriented measures each calculate a (penalized) harmonic mean of measure-specific definitions of precision and recall when comparing a generated spoiler to the ground truth. In case of BLEU-4, the overlap of word 1-to 4-grams is determined (if the length n of a generated spoiler is less than 4 words, we compute BLEU-n), in case of METEOR the overlap of word 1-grams, and in case of BERTScore the best matching embeddings of word pairs. Note that in their original formulation, BLEU-4 and METEOR penalize the score, the more the n-gram order differs. To arrange the measures on a spectrum from calculating predominantly syntactic (BLEU-4) to predominantly semantic similarity (BERTScore), we omit METEOR's penalization term.</p><p>The question answering-oriented measures are not really suited to assess the effectiveness of passage retrieval models since a retrieved passage is often longer than the ground truth spoiler. Therefore, we also use Precision@1 to measure whether the top-ranked passage contains the ground truth spoiler (all phrase spoilers and 98% of the passage spoilers come from a single passage; for the other passage spoilers, we consider all containing passages as relevant). To calculate the Precision@1 of question answering models, we use the first passage that contains the returned spoiler.</p><p>High-confidence thresholds. Candidates with higher scores on the question answering-oriented measures BLEU-4, METEOR, and BERTScore are closer to the ground truth. However, it is unclear what score threshold a particular spoiler candidate has to exceed so that it would be considered a true positive in a manual analysis. Determining such thresholds enables "high confidence" estimations of how many correct spoilers an approach gener-  ates without having to manually check its outputs each time with each new variant.</p><p>In a pilot study, we thus determined such thresholds by running all question answering models (cf. Section 4.2 and 4.3) on a random sample of 500 clickbait posts with phrase spoilers and 500 with passage spoilers. For each post, a random spoiler generated by a question answering model and a random spoiler generated by a passage retrieval model were manually checked for whether they could be viewed as correct. Table <ref type="table" target="#tab_3">4</ref> shows the number of manually determined false positives and false negatives for different thresholds of BLEU-4, METEOR, and BERTScore. The manually selected subjective thresholds (FP/FN in bold) for each combination of measure, spoiler type, and model type (question answering or passage retrieval) minimize the false positives at a rate where being more strict would incur too many false negatives. For instance, for phrase spoilers and BLEU-4, we set the question answering model threshold at 50% since a more strict threshold of 60% does not reduce the false positives but increases the false negatives.</p><p>In addition to reporting quantitative mean effectiveness scores, applying the determined thresholds helps to estimate how many of the spoilers of a Table <ref type="table">5</ref>: Pilot study spoiling effectiveness of question answering and passage retrieval models on 200 validation posts (models ordered lexicographically). The bracketed numbers indicate the expected number of true positives as per our pre-determined high-confidence score thresholds; P@1 is the Precision@1. The models DeBERTa-large and RoBERTa-large, as well as MonoBERT and MonoT5 are the most effective in their groups. model would be perceived as "good" by human readers. This corresponds to a conservative assessment, since we believe that a model should only be deployed to production if it has been tuned to not return a spoiler if in doubt about its correctness; also probably somewhat minimizing the otherwise possible spread of auto-generated misinformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Pilot Study for Model Selection</head><p>In a pilot study on 1,000 clickbait posts (800 training, 200 validation), we compare ten question answering and ten passage retrieval models (cf. Table <ref type="table">5</ref>) at their default settings to select models for subsequent experiments with more extensive (and expensive) hyperparameter tuning. The question answering models were or are among the most effective in the SQuAD and TriviaQA question answering benchmarks. In our setup, they return a piece of text from the linked document as an "answer" to the clickbait post as the "query". As passage retrieval models, we empoly MonoBERT and MonoT5 using their PyGaggle 3 implementations, and eight variants of the popular baseline retrieval models BM25 and QLD using their Anserini implementations <ref type="bibr" target="#b43">(Yang et al., 2017)</ref>. These models return the most "relevant" paragraph from the linked document for the clickbait post as the "query".</p><p>3 https://github.com/castorini/pygaggle Using Nvidia A100 GPUs, the question answering models were first fine-tuned on SQuAD v1.1 and then on the pilot training data. This was the most effective setup from an ablation study with other fine-tuning regimes (e.g., the phrase spoiler BERTScore for RoBERTa-large dropped from 84.04 to 69.91 when only fine-tuned on our pilot study data, to 64.61 when only fine-tuned on SQuAD, and to 46.60 without fine-tuning). Interestingly, the models' SQuAD effectiveness does not predict their spoiling effectiveness (e.g., RoBERTabase and FunnelTransformer were tied on SQuAD, but RoBERTa-base is more effective at spoiling). This indicates the importance of the pilot study.</p><p>Table <ref type="table">5</ref> shows the pilot study effectiveness of all models on the 200 validation posts. RoBERTalarge (for phrasal spoilers) and DeBERTa-large (for passage spoilers) are the most effective. Among the passage retrieval models, MonoBERT and MonoT5 achieve the best scores. Contrary to our original assumption that passage retrieval models might be particularly well-suited to identify passage spoilers, MonoBERT and MonoT5 have similar Precision@1 scores on both phrase and passage spoilers and are substantially less effective than the best question answering models (e.g., DeBERTa-large has a Precision@1 of 48.39 for passage spoilers compared to 31.18 for MonoBERT).</p><p>Table <ref type="table">6</ref>: Effectiveness on the 826 test clickbait posts with phrase and passage spoilers. The bracketed numbers indicate the expected number of true positives as per our pre-determined high-confidence score thresholds; P@1 is the Precision@1. Overall, DeBERTa-large and RoBERTa-large are the most effective models. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Tuning the Selected Models</head><p>Given the pilot study results, six models are selected for a more extensive hyperparameter tuning: the best two question answering models (DeBERTalarge was best for phrase spoilers, RoBERTa-large for passage spoilers) plus BERT as baseline, as well as the best two passage retrieval models (MonoBERT and MonoT5) plus BM25 as baseline.</p><p>As the ablation study in our pilot study showed that fine-tuning the question answering models on SQuAD first and then on our corpus works best, we apply this fine-tuning regime to DeBERTalarge, RoBERTa-large, and BERT using the clickbait spoiling training data (depending on the experiment, either only the phrase spoilers, only the passage spoilers, or both combined). Most hyperparameters of DeBERTa-large, RoBERTa-large, BERT, MonoBERT, and MonoT5 are left at their defaults, but a grid search is run to find the most effective combination of learning rate (1e-5, 4e-5, 1e-4), warmup ratio (0.02, 0.06, 0.1), batch size <ref type="bibr">(8,</ref><ref type="bibr">16,</ref><ref type="bibr">32)</ref>, number of epochs (1 to 10), and maximum sequence length <ref type="bibr">(256,</ref><ref type="bibr">384,</ref><ref type="bibr">512)</ref>. For BM25, we try combinations of k 1 from 0.1 to 0.4 and b from 0.1 to 1.0 with a step size of 0.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Effectiveness on Phrase Spoilers</head><p>The 'Phrase Spoilers' column group in Table <ref type="table">6</ref> shows the effectiveness of the selected question answering and passage retrieval models on the 423 test clickbait posts with phrase spoilers. Given the ground-truth spoiler, we report the predicted spoilers' average BLEU-4, METEOR, BERTScore, and Precision@1 (using 1,367 posts with phrase spoilers for training and 335 posts for validation to tune the hyperparameters; cf. Table <ref type="table" target="#tab_0">1</ref>).</p><p>Overall, DeBERTa-large is the most effective model for phrase spoilers. Based on our highconfidence score thresholds, it generates the cor-rect spoiler for 250-300 of the 423 test posts (i.e., for about 60-70% of the cases) according to a BERTScore or BLEU-4 evaluation. Similar to our pilot study, the passage retrieval models are comparably ineffective in identifying phrase spoilers. Among them, MonoT5 achieves the highest scores but is even substantially less effective than the question answering baseline BERT. For instance, with a BLEU-4 of 58.89 and probably 257 correct spoilers (61% of the 423 test posts), BERT is way ahead of MonoT5 with a BLEU-4 of 4.95 and only 82 probably correct spoilers (19% of the 423 posts).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Effectiveness on Passage Spoilers</head><p>The 'Passage Spoilers' column group in Table <ref type="table">6</ref> shows the effectiveness of the selected passage retrieval models on the 403 test clickbait posts with passage spoilers (using 1,274 and 322 posts for training and validation). The numbers of probably correct spoilers are lower for all models compared to the phrase spoilers (even the higher amount of probably correct passage spoilers of the passage retrieval models according to their BERTScore threshold are still worse than the estimated probably correct phrase spoilers according to BLEU-4 or METEOR). Similar to the pilot study, all question answering models are also substantially more effective on passage spoilers than the passage retrieval models. Overall, DeBERTalarge and RoBERTa-large achieve the highest Precision@1 scores and the highest amount of probably correct passage spoilers (about 35-41% of the passage spoilers are correctly identified according to our high-confidence thresholds).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Effectiveness of the End-to-End System</head><p>We evaluate the entire spoiling pipeline using all 826 phrase and passage test posts by comparing two-step pipelines that first classify the spoiler type to then select an appropriately trained spoiler model (trained on the respective type) and single-step approaches that skip the spoiler type classification and simply run the same spoiler model on all posts (trained on the complete training data). For the two-step pipelines, we experiment with two variants: (1) using an artificial classifier that returns perfect oracle-style answers about a post's type, and (2) using the best RoBERTa-based phrase-vspassage classifier from Section 5.</p><p>Since the passage retrieval models were less effective in our spoiler experiments (cf. Table <ref type="table">6</ref>), we report results only for pipelines with question answering models. In the two-step pipelines the respective question answering models are fine-tuned on the respective spoiler types, in the single-step approach on the combined training data.</p><p>Table <ref type="table" target="#tab_6">7</ref> shows the achieved end-to-end effectiveness values. The individual two-step pipelines with oracle type classification (row group 'Oracle') are substantially more effective than their single-step counterparts without type classification (row group 'None') that again are more effective than the respective two-step pipelines with "real" RoBERTabased type classification (row group 'Classif.'). Overall, the DeBERTa pipeline with oracle classifier achieves an estimated amount of about 50-55% correctly spoiled posts (i.e., 411 to 457 of 826). This result confirms that classifying the required spoiler type can be beneficial for clickbait spoiling. Still, among the currently realistically applicable end-to-end spoiling approaches (with RoBERTa type classification or without spoiler type classi-fication), the one-step DeBERTa approach without spoiler type classification is the most effective according to the number of probably correctly spoiled posts (382 to 409 of the 826 posts, i.e., 46-50%). This indicates that the currently best RoBERTa-based spoiler type classifier with its accuracy of 80.39% is still not good enough to result in an end-to-end system that actually benefits from spoiler type classification.</p><p>Our results show that effectively spoiling clickbait with question answering models is possible in practice but also that there is still room for improvements (e.g., improved spoiler type classification, improved spoiler generation for the individual types, and taking multipart spoilers into account).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>Clickbait spoiling is a new task to help social media users who do not want to be manipulated into falling for clickbait links. Unlike clickbait detection, which often involves filtering out clickbait posts from users' timelines, clickbait spoiling subverts the curiosity triggered by clickbait, presenting users with the withheld "punchline" in advance.</p><p>We compile the first large resource for clickbait with associated spoilers. By interpreting clickbait spoiling as either a question answering task or a passage retrieval task, many possible approaches are available to extract from the linked document of a clickbait post the phrase or passage that spoils it. We have explored the effectiveness of a number of state-of-the-art solutions for both tasks in a largescale experiment, including fine-tuning the respective models on our resource to determine their effectiveness for type-specific clickbait spoiling. Our experimental setup considers type-specific spoiling on the one hand, but on the other hand it also includes an end-to-end configuration for comparison. Overall, our results show that type-agnostic question answering-based spoiling is the most effective yet, but also that spoiler type-specific solutions have the potential to outperform them.</p><p>In addition to the possibilities explored, there might also be other approaches to clickbait spoiling: for example, paraphrasing technology could be used to directly transform a clickbait post into a version that contains its own spoiler. With respect to multipart spoilers, the use of summarization models could be an interesting direction to select the different parts of the linked document of a clickbait post that make up its multipart spoiler.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>and brain expert says she avoids these 5 foods that "weaken memory and focus." (via @CNBCMakeIt) cnb.cx/2TG6zeX "1. Added sugar" [...] "2. Fried foods" [...] "3. High-glycemic-load carbohydrates" [...] "4. Alcohol" [...] "5. Nitrates"[...]    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Examples of clickbait tweets and spoilers for them extracted from the respective linked web page.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Key statistics of the Webis Clickbait Spoiling Corpus 2022 (Webis-Clickbait-22).</figDesc><table><row><cell>Source</cell><cell>Spoiler</cell><cell>Entries</cell><cell cols="3">Average text length ± Std.Dev.</cell><cell cols="3">Corpus splits</cell><cell>Top source</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Post</cell><cell>Document</cell><cell>Spoiler</cell><cell cols="3">Train Val. Test Name</cell><cell>Count</cell></row><row><cell></cell><cell>Phrase</cell><cell>342</cell><cell cols="2">13.4 ±3.6 433.7 ±347.9</cell><cell>3.0 ±1.6</cell><cell>221</cell><cell>45</cell><cell>76 Stop Clickbait</cell><cell>342</cell></row><row><cell cols="2">Facebook Passage</cell><cell>388</cell><cell cols="2">13.4 ±4.0 490.9 ±351.5</cell><cell>24.9 ±20.0</cell><cell>231</cell><cell>73</cell><cell>84 Stop Clickbait</cell><cell>388</cell></row><row><cell></cell><cell>Multipart</cell><cell>94</cell><cell cols="2">14.2 ±4.1 651.8 ±545.2</cell><cell>28.5 ±33.0</cell><cell>68</cell><cell>12</cell><cell>14 Stop Clickbait</cell><cell>94</cell></row><row><cell></cell><cell>Phrase</cell><cell>688</cell><cell cols="2">13.2 ±4.0 584.6 ±798.6</cell><cell>2.8 ±1.6</cell><cell cols="2">455 109</cell><cell>124 savedyouaclick</cell><cell>688</cell></row><row><cell>Reddit</cell><cell>Passage</cell><cell>859</cell><cell cols="3">13.1 ±4.0 657.2 ±1004.7 25.4 ±20.3</cell><cell cols="2">533 148</cell><cell>178 savedyouaclick</cell><cell>859</cell></row><row><cell></cell><cell>Multipart</cell><cell>250</cell><cell cols="2">12.8 ±4.4 991.7 ±899.5</cell><cell>32.7 ±36.2</cell><cell>162</cell><cell>46</cell><cell>42 savedyouaclick</cell><cell>250</cell></row><row><cell></cell><cell>Phrase</cell><cell>1,095</cell><cell cols="2">11.0 ±3.4 479.1 ±502.9</cell><cell>2.7 ±1.7</cell><cell cols="2">691 181</cell><cell>223 HuffPoSpoilers</cell><cell>794</cell></row><row><cell>Twitter</cell><cell>Passage</cell><cell>752</cell><cell cols="2">10.3 ±4.2 597.4 ±605.8</cell><cell>22.3 ± 13.5</cell><cell cols="2">510 101</cell><cell>141 HuffPoSpoilers</cell><cell>328</cell></row><row><cell></cell><cell>Multipart</cell><cell>532</cell><cell cols="2">11.5 ±3.8 884.0 ±930.3</cell><cell>35.4 ±34.4</cell><cell>329</cell><cell>85</cell><cell>118 HuffPoSpoilers</cell><cell>148</cell></row><row><cell></cell><cell>Phrase</cell><cell>2,125</cell><cell>12.1 ±3.8</cell><cell>505.9 ±599.4</cell><cell cols="3">2.8 ±1.6 1,367 335</cell><cell>423 HuffPoSpoilers</cell><cell>794</cell></row><row><cell></cell><cell>Passage</cell><cell>1,999</cell><cell>12.1 ±4.3</cell><cell>602.4 ±774.0</cell><cell cols="3">24.1 ±18.1 1,274 322</cell><cell>403 savedyouaclick</cell><cell>859</cell></row><row><cell></cell><cell>Multipart</cell><cell>876</cell><cell>12.2 ±4.1</cell><cell>889.8 ±892.2</cell><cell>33.9 ±34.8</cell><cell cols="2">559 143</cell><cell>174 savedyouaclick</cell><cell>250</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Effectiveness of spoiler type classification in the multi-class (first column) and one-vs-rest settings on 1000 test posts (training: 3200; validation: 800).</figDesc><table><row><cell cols="5">Model Balanced accuracy (0, 1, 2 indicate class labels)</cell></row><row><cell>Phrase</cell><cell>0</cell><cell>1</cell><cell>0</cell><cell>0</cell></row><row><cell>Passage</cell><cell>1</cell><cell>0</cell><cell>1</cell><cell>0</cell></row><row><cell>Multipart</cell><cell>2</cell><cell>0</cell><cell>0</cell><cell>1</cell></row><row><cell>Naïve Bayes</cell><cell>56.15</cell><cell>65.03</cell><cell>62.50</cell><cell>64.82</cell></row><row><cell>SVM</cell><cell>59.62</cell><cell>68.03</cell><cell>68.70</cell><cell>70.28</cell></row><row><cell>Log. Regression</cell><cell>60.04</cell><cell>68.04</cell><cell>69.33</cell><cell>71.26</cell></row><row><cell>BERT</cell><cell>67.84</cell><cell>74.06</cell><cell>75.70</cell><cell>75.56</cell></row><row><cell>DeBERTa</cell><cell>73.63</cell><cell>78.39</cell><cell>78.65</cell><cell>77.93</cell></row><row><cell>RoBERTa</cell><cell>71.57</cell><cell>80.39</cell><cell>79.30</cell><cell>79.12</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Effectiveness of spoiler type classification in the one-vs-one (phrase-vs-passage) setting on 826 test posts (training: 2,641; validation: 657).</figDesc><table><row><cell>Model</cell><cell></cell><cell></cell><cell cols="2">Effectiveness</cell><cell></cell></row><row><cell></cell><cell>TP</cell><cell>TN</cell><cell>FP</cell><cell>FN</cell><cell>Acc.</cell></row><row><cell>Naïve Bayes</cell><cell>298</cell><cell>256</cell><cell>147</cell><cell>125</cell><cell>67.07</cell></row><row><cell>SVM</cell><cell>311</cell><cell>264</cell><cell>139</cell><cell>112</cell><cell>69.61</cell></row><row><cell>Log. Regression</cell><cell>306</cell><cell>273</cell><cell>130</cell><cell>117</cell><cell>70.10</cell></row><row><cell>BERT</cell><cell>315</cell><cell>315</cell><cell>88</cell><cell>108</cell><cell>76.27</cell></row><row><cell>DeBERTa</cell><cell>318</cell><cell>335</cell><cell>68</cell><cell>105</cell><cell>79.06</cell></row><row><cell>RoBERTa</cell><cell>332</cell><cell>332</cell><cell>71</cell><cell>91</cell><cell>80.39</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Manually determined numbers of false positives/negatives (FP/FN) on 500 sampled clickbait posts with phrase spoilers and 500 with passage spoilers for question answering (top row group) and passage retrieval models (bottom row group), dependent on score threshold (Thresh.), spoiler type, and effectiveness measure (BL4 = BLEU-4, MET = METEOR, BSc. = BERTScore). The thresholds selected for subsequent assessment are indicated by bold FP/FN numbers.</figDesc><table><row><cell cols="2">Thresh. Phrase Spoilers</cell><cell cols="3">Passage Spoilers</cell></row><row><cell>BL4 MET</cell><cell>BSc.</cell><cell>BL4</cell><cell>MET</cell><cell>BSc.</cell></row><row><cell cols="5">FP FN FP FN FP FN FP FN FP FN FP FN</cell></row><row><cell cols="2">10% 11 11 18 7 238 0</cell><cell cols="3">5 44 168 15 399 0</cell></row><row><cell cols="2">20% 7 14 16 7 234 0</cell><cell cols="3">3 48 67 27 325 3</cell></row><row><cell cols="2">30% 7 14 14 9 165 1</cell><cell cols="3">1 51 31 35 134 21</cell></row><row><cell cols="2">40% 2 27 8 13 59 6</cell><cell cols="3">0 55 15 39 18 38</cell></row><row><cell cols="2">50% 2 27 2 28 24 14</cell><cell cols="3">0 60 9 42 5 51</cell></row><row><cell cols="2">60% 2 30 3 31 11 25</cell><cell cols="3">0 64 4 57 1 59</cell></row><row><cell cols="2">70% 1 33 2 31 6 36</cell><cell cols="3">0 66 1 54 0 66</cell></row><row><cell cols="2">80% 1 34 0 37 1 40</cell><cell cols="3">0 66 0 61 0 73</cell></row><row><cell cols="2">5% 8 40 28 64 208 0</cell><cell cols="3">0 95 225 10 355 0</cell></row><row><cell cols="2">10% 4 104 8 108 180 60</cell><cell cols="3">0 95 140 30 355 0</cell></row><row><cell cols="2">20% 0 184 0 164 44 144</cell><cell cols="3">0 95 35 65 305 15</cell></row><row><cell cols="2">30% 0 188 0 184 0 176</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>End-to-end effectiveness on the 826 phrase and passage test posts. Spoiling models that classify the spoiler type to then select an appropriately trained spoiler model ('Classif.', using the most effective spoiler type classifier), models without spoiler type classification ('None'), and unrealistic models with perfect-accuracy type classification ('Oracle').</figDesc><table><row><cell></cell><cell>Model</cell><cell>End-to-End Effectiveness</cell></row><row><cell></cell><cell></cell><cell>BLEU-4</cell><cell>METEOR BERTScore P@1</cell></row><row><cell>Classif.</cell><cell cols="2">BERT DeBERTa 44.98 (392) 44.32 (377) 59.18 (378) 63.44 35.95 (311) 34.25 (303) 53.86 (294) 52.66 RoBERTa 42.70 (374) 43.23 (356) 58.01 (361) 61.86</cell></row><row><cell>None</cell><cell cols="2">BERT DeBERTa 46.16 (409) 47.01 (407) 60.43 (382) 64.16 38.85 (346) 37.80 (330) 54.60 (314) 55.33 RoBERTa 44.69 (400) 44.72 (395) 59.51 (375) 65.13</cell></row><row><cell>Oracle</cell><cell cols="2">BERT DeBERTa 50.58 (457) 49.40 (440) 64.36 (411) 65.50 40.69 (367) 39.02 (366) 58.05 (324) 54.84 RoBERTa 48.10 (438) 48.57 (438) 62.71 (400) 63.44</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">Data: https://webis.de/data.html?q=clickbait</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">Code: https://github.com/webis-de/ACL-22</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We thank Tim Gollub, and our students Jana Puschmann and Bagrat Ter-Akopyan, who helped to create earlier versions of the dataset.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics Statement</head><p>The spread of clickbait on social media by news publishers to promote click-through to their websites has been empirically found to decrease their perceived credibility in readers <ref type="bibr" target="#b24">(Molyneux and Coddington, 2020)</ref>. There is, of course, nothing wrong with monitoring and optimizing the effectiveness of marketing a newly published news article, especially in cases where the editors make an honest effort to reach and inform their target audience. But the clickbait in our corpus mostly spreads trivial facts that could have been easily fitted into the length limits of a social media post, which is why we consider these posts to fall short of the journalistic ideal. However, it is as of yet unclear, in terms of journalism ethics, whether clickbait is an acceptable means to an end for publishers (i.e., whether it is "necessary in driving audiences to the journalism they need by giving them the journalism they seem to want."), or whether it serves to "crowding out «real» journalism by reducing quality in favor of the need for a click-through at whatever cost" <ref type="bibr" target="#b14">(Harte, 2021)</ref>.</p><p>Facebook intervened twice with algorithmic filters to reduce the amount of clickbait that people are exposed to in their timelines-even though this probably also lowered Facebook's user engagement metrics. Our technology demonstrates another, complementary way of relatively simply circumventing the purported exploitation of the curiosity gap by giving the audience a choice on whether or not they wish their cognitive "loopholes" to be exploited. If a sufficiently large portion of people decide to adopt spoiling tools, that would send a clear message to publishers and social media platforms alike. Spoiling clickbait, as opposed to removing it, however, still gives publishers the benefit of the doubt, since, as the publishers claim, there are people who enjoy these kinds of trivia.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments</title>
		<author>
			<persName><forename type="first">Satanjeev</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization@ACL 2005</title>
				<meeting>the Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization@ACL 2005<address><addrLine>Ann Arbor, Michigan, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005-06-29">2005. June 29, 2005</date>
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Stop Clickbait: Detecting and Preventing Clickbaits in Online News Media</title>
		<author>
			<persName><forename type="first">Abhijnan</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhargavi</forename><surname>Paranjape</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sourya</forename><surname>Kakarla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niloy</forename><surname>Ganguly</surname></persName>
		</author>
		<idno type="DOI">10.1109/ASONAM.2016.7752207</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining</title>
		<imprint>
			<biblScope unit="page" from="9" to="16" />
			<date type="published" when="2016-08-18">2016. 2016. 2016. August 18-21, 2016</date>
		</imprint>
	</monogr>
	<note>ASONAM</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Simple and Effective Multi-Paragraph Reading Comprehension</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1078</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018</title>
				<meeting>the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-07-15">2018. July 15-20. 2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="845" to="855" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">ELECTRA: pretraining text encoders as discriminators rather than generators</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
				<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-26">2020. April 26-30, 2020</date>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Overview of the TREC 2020 Deep Learning Track</title>
		<author>
			<persName><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emine</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Campos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth Text REtrieval Conference, TREC 2020, Virtual Event</title>
				<meeting>the Twenty-Ninth Text REtrieval Conference, TREC 2020, Virtual Event<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-11-16">2020. November 16-20, 2020</date>
			<biblScope unit="volume">1266</biblScope>
		</imprint>
		<respStmt>
			<orgName>NIST Special Publication. National Institute of Standards and Technology (NIST)</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Overview of the TREC 2019 Deep Learning Track</title>
		<author>
			<persName><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emine</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth Text REtrieval Conference, TREC 2019</title>
				<meeting>the Twenty-Eighth Text REtrieval Conference, TREC 2019<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-11-13">2019. November 13-15, 2019</date>
			<biblScope unit="volume">1250</biblScope>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST)</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing</title>
		<author>
			<persName><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guokun</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems</title>
				<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-12-06">2020. 2020. 2020. December 6-12, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Meteor Universal: Language Specific Translation Evaluation for Any Target Language</title>
		<author>
			<persName><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alon</forename><surname>Denkowski</surname></persName>
		</author>
		<author>
			<persName><surname>Lavie</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/w14-3348</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Workshop on Statistical Machine Translation, WMT@ACL</title>
				<meeting>the Ninth Workshop on Statistical Machine Translation, WMT@ACL<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<publisher>The Association for Computer Linguistics</publisher>
			<date type="published" when="2014-06-26">2014. 2014. June 26-27, 2014</date>
			<biblScope unit="page" from="376" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06-02">2019. June 2-7, 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">English Machine Reading Comprehension Datasets: A Survey</title>
		<author>
			<persName><forename type="first">Daria</forename><surname>Dzendzik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><surname>Vogel</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.693</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana</title>
				<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-07-11">2021. 7-11 November, 2021</date>
			<biblScope unit="page" from="8784" to="8804" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Lars</forename><surname>Eidnes</surname></persName>
		</author>
		<ptr target="https://web.archive.org/web/20220223161935/http://larseidnes.com/2015/10/13/auto-generating-clickbait-with-recurrent-neural-networks/" />
		<title level="m">Auto-Generating Clickbait With Recurrent Neural Networks</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Khalid</forename><surname>El</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-Arini</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Joyce</forename><surname>Tang</surname></persName>
		</author>
		<ptr target="http://web.archive.org/web/20150529104738/http://newsroom.fb.com/news/2014/08/news-feed-fyi-click-baiting/" />
		<title level="m">News Feed FYI: Click-baiting</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Gokaslan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vanya</forename><surname>Cohen</surname></persName>
		</author>
		<ptr target="http://Skylion007.github.io/OpenWebTextCorpus" />
		<title level="m">OpenWeb-Text Corpus</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Deep Look Into Neural Ranking Models for Information Retrieval</title>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamed</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ipm.2019.102067</idno>
	</analytic>
	<monogr>
		<title level="j">Inf. Process. Manag</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">102067</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Clickbait and Banal News</title>
		<author>
			<persName><forename type="first">David</forename><surname>Harte</surname></persName>
		</author>
		<idno type="DOI">10.4324/9780429262708-45/clickbait-banal-news-david-harte</idno>
	</analytic>
	<monogr>
		<title level="m">The Routledge Companion to Journalism Ethics</title>
				<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="346" to="353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">DeBERTa: Decoding-Enhanced BERT with Disentangled Attention</title>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations, ICLR 2021, Virtual Event</title>
				<meeting><address><addrLine>Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-05-03">2021. May 3-7, 2021</date>
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension</title>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1147</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017</title>
		<title level="s">Long Papers</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-07-30">2017. July 30 -August 4</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1601" to="1611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">News Article Teaser Tweets and How to Generate Them</title>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Kumar Karn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulli</forename><surname>Waltinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-1398</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06-02">2019. June 2-7, 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3967" to="3977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Why The Title Matters More Than The Talk</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Koechley</surname></persName>
		</author>
		<ptr target="http://web.archive.org/web/20150611110506/http://blog.upworthy.com/post/26345634089/why-the-title-matters-more-than-the-talk" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</title>
		<author>
			<persName><forename type="first">Zhenzhong</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingda</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piyush</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
				<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-26">2020. April 26-30, 2020</date>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Pretrained Transformers for Text Ranking: BERT and Beyond. Synthesis Lectures on Human Language Technologies</title>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<idno type="DOI">10.2200/S01123ED1V01Y202108HLT053</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Clickbait News and Algorithmic Curation: A Game Theory Framework of the Relation between Journalism, Users, and Platforms</title>
		<author>
			<persName><forename type="first">Juliane</forename><forename type="middle">A</forename><surname>Lischka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcel</forename><surname>Garz</surname></persName>
		</author>
		<idno type="DOI">10.1177/14614448211027174</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>New Media &amp; Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno>CoRR, abs/1907.11692</idno>
		<title level="m">RoBERTa: A Robustly Optimized BERT Pretraining Approach</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The Psychology of Curiosity: A Review and Reinterpretation</title>
		<author>
			<persName><forename type="first">George</forename><surname>Loewenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="75" to="98" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Aggregation, Clickbait and Their Effect on Perceptions of Journalistic Credibility and Quality</title>
		<author>
			<persName><forename type="first">Logan</forename><surname>Molyneux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Coddington</surname></persName>
		</author>
		<idno type="DOI">10.1080/17512786.2019.1628658</idno>
	</analytic>
	<monogr>
		<title level="j">Journalism Practice</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="429" to="446" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">All the News That&apos;s Fit to Click: The Economics of Clickbait Media</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Munger</surname></persName>
		</author>
		<idno type="DOI">10.1080/10584609.2019.1687626</idno>
	</analytic>
	<monogr>
		<title level="j">Political Communication</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="376" to="397" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">MS MARCO: A Human Generated MAchine Reading COmprehension Dataset</title>
		<author>
			<persName><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Cognitive Computation: Integrating neural and symbolic approaches 2016 colocated with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016)</title>
		<title level="s">CEUR Workshop Proceedings. CEUR-WS.org</title>
		<meeting>the Workshop on Cognitive Computation: Integrating neural and symbolic approaches 2016 colocated with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016)<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-12-09">2016. December 9, 2016</date>
			<biblScope unit="volume">1773</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Passage Re-ranking with BERT</title>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno>CoRR, abs/1901.04085</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Document Ranking with a Pretrained Sequence-to-Sequence Model</title>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiying</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronak</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.63</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
				<imprint>
			<date type="published" when="2020-11-20">2020. 16-20 November 2020</date>
			<biblScope unit="page" from="708" to="718" />
		</imprint>
	</monogr>
	<note>EMNLP 2020 of Findings of ACL. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno>CoRR, abs/1910.14424</idno>
		<title level="m">Multi-Stage Document Ranking with BERT</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">BLEU: A Method for Automatic Evaluation of Machine Translation</title>
		<author>
			<persName><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.3115/1073083.1073135</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2002-07-06">2002. July 6-12, 2002</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">Alex</forename><surname>Peysakhovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristin</forename><surname>Hendrix</surname></persName>
		</author>
		<ptr target="https://web.archive.org/web/20210207042429/https://about.fb.com/news/2016/08/news-feed-fyi-further-reducing-clickbait-in-feed/" />
		<title level="m">Further Reducing Clickbait in Feed</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A Language Modeling Approach to Information Retrieval</title>
		<author>
			<persName><forename type="first">Jay</forename><forename type="middle">M</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<idno type="DOI">10.1145/290941.291008</idno>
	</analytic>
	<monogr>
		<title level="m">SI-GIR &apos;98: Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
				<meeting><address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998-08-24">1998. August 24-28 1998</date>
			<biblScope unit="page" from="275" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">The Clickbait Challenge 2017: Towards a Regression Model for Clickbait Strength</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<idno>CoRR, abs/1812.10847</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Clickbait Detection</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Köpsel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hagen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-30671-1_72</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval. 38th European Conference on IR Research</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="volume">9626</biblScope>
			<biblScope unit="page" from="810" to="817" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Know What You Don&apos;t Know: Unanswerable Questions for SQuAD</title>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-2124</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018</title>
				<meeting>the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="784" to="789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ Questions for Machine Comprehension of Text</title>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d16-1264</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-01">2016. 2016. November 1-4, 2016</date>
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
	<note>The Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The Probabilistic Relevance Framework: BM25 and Beyond</title>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
		<idno type="DOI">10.1561/1500000019</idno>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="333" to="389" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Diving Deep into Clickbaits: Who Use Them to What Extents in Which Topics with What Effects?</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">U</forename><surname>Md</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naeemul</forename><surname>Rony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><surname>Yousuf</surname></persName>
		</author>
		<idno type="DOI">10.1145/3110025.3110054</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining</title>
				<meeting>the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017-07-31">2017. 2017. July 31 -August 03, 2017</date>
			<biblScope unit="page" from="232" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Towards News Verification: Deception Detection Methods for News Discourse</title>
		<author>
			<persName><forename type="first">Victoria</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niall</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yimin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Hawaii International Conference on System Sciences (HICSS48) Symposium on Rapid Screening Technologies, Deception Detection and Credibility Assessment Symposium</title>
				<meeting>the Hawaii International Conference on System Sciences (HICSS48) Symposium on Rapid Screening Technologies, Deception Detection and Credibility Assessment Symposium<address><addrLine>Kauai, Hawaii, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Deep Headline Generation for Clickbait Detection</title>
		<author>
			<persName><forename type="first">Kai</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thai</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDM.2018.00062</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Data Mining, ICDM 2018</title>
				<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2018-11-17">2018. November 17-20. 2018</date>
			<biblScope unit="page" from="467" to="476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">MPNet: Masked and Permuted Pretraining for Language Understanding</title>
		<author>
			<persName><forename type="first">Kaitao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems</title>
				<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-12-06">2020. 2020. 2020. December 6-12, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Clickbait? Sensational Headline Generation with Auto-tuned Reinforcement Learning</title>
		<author>
			<persName><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chien-Sheng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1303</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-11-03">2019. November 3-7, 2019</date>
			<biblScope unit="page" from="3063" to="3073" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Anserini: Enabling the Use of Lucene for Information Retrieval Research</title>
		<author>
			<persName><forename type="first">Peilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1145/3077136.3080721</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
				<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Shinjuku, Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017-08-07">2017. August 7-11, 2017</date>
			<biblScope unit="page" from="1253" to="1256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Big Bird: Transformers for Longer Sequences</title>
		<author>
			<persName><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guru</forename><surname>Guruganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avinava</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Ainslie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Santiago</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Ontañón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anirudh</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qifan</forename><surname>Ravula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amr</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><surname>Ahmed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems</title>
				<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-12-06">2020. 2020. 2020. December 6-12, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">BERTScore: Evaluating Text Generation with BERT</title>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varsha</forename><surname>Kishore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
				<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-26">2020. April 26-30, 2020</date>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
