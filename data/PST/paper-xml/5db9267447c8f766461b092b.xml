<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Lower complexity bounds of first-order methods for convex-concave bilinear saddle-point problems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yuyuan</forename><surname>Ouyang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yangyang</forename><surname>Xu</surname></persName>
							<idno type="ORCID">0000-0002-4163-3723</idno>
						</author>
						<title level="a" type="main">Lower complexity bounds of first-order methods for convex-concave bilinear saddle-point problems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0A8E2A3B8BD87F205107A838A970DFCB</idno>
					<idno type="DOI">10.1007/s10107-019-01420-0</idno>
					<note type="submission">Received: 6 August 2018 / Accepted: 2 August 2019</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Convex optimization</term>
					<term>Saddle point problems</term>
					<term>First-order methods</term>
					<term>Information-based complexity</term>
					<term>Lower complexity bound Mathematics Subject Classification 90C25</term>
					<term>90C06</term>
					<term>90C60</term>
					<term>49M37</term>
					<term>68Q25</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>On solving a convex-concave bilinear saddle-point problem (SPP), there have been many works studying the complexity results of first-order methods. These results are all about upper complexity bounds, which can determine at most how many iterations would guarantee a solution of desired accuracy. In this paper, we pursue the opposite direction by deriving lower complexity bounds of first-order methods on large-scale SPPs. Our results apply to the methods whose iterates are in the linear span of past first-order information, as well as more general methods that produce their iterates in an arbitrary manner based on first-order information. We first work on the affinely constrained smooth convex optimization that is a special case of SPP. Different from gradient method on unconstrained problems, we show that first-order methods on affinely constrained problems generally cannot be accelerated from the known convergence rate O(1/t) to O(1/t 2 ), and in addition, O(1/t) is optimal for convex problems. Moreover, we prove that for strongly convex problems, O(1/t 2 ) is the best possible convergence rate, while it is known that gradient methods can have linear convergence on unconstrained problems. Then we extend these results to general SPPs. It turns out that our lower complexity bounds match with several established upper complexity bounds in the literature, and thus they are tight and indicate the optimality of several existing first-order methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years, first-order methods have been particularly popular partly due to the huge scale of many modern applications. These methods only access the function value and gradient information of the underlying problems, and possibly also other "simple" operations. For example, on solving the constrained optimization problem f * := min x∈X f (x), the projected gradient (PG) method x (t+1) ← Proj X x (t) -α∇ f (x (t) ) is a first-order method if the projection operator Proj X is easy to evaluate such as projection onto a box constraint set. For convex problems, if ∇ f is Lipschitz continuous and α is appropriately chosen, the PG method can have convergence rate in the order of 1  t , namely, f (x (t) )f * = O( 1 t ), where t is the number of gradient evaluations. Through smart extrapolation, the rate can be improved to O( 1 t 2 ); see <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b36">36]</ref>. In addition, there exists an instance showing that the order 1 t 2 cannot be further improved (see <ref type="bibr" target="#b31">[31]</ref><ref type="bibr" target="#b32">[32]</ref><ref type="bibr" target="#b33">[33]</ref><ref type="bibr" target="#b34">[34]</ref>) and thus is optimal.</p><p>In this paper, we consider the bilinear saddle-point problem (SPP): (</p><p>Here, X ⊆ R n and Y ⊆ R m are closed convex sets, f : R n → R and g : R m → R are closed convex functions, A ∈ R m×n , and b ∈ R m . We assume that the function f is L f -smooth, namely, f is differentiable, and ∇ f is L f -Lipschitz continuous:</p><formula xml:id="formula_1">∇ f (x 1 ) -∇ f (x 2 ) ≤ L f x 1 -x 2 , ∀ x 1 , x 2 ∈ X . (1.2)</formula><p>In addition, we assume that g is simple such that its proximal mapping can be easily computed. The scale of the problem is large, so it is expensive to form the Hessian of f and also, it is expensive to solve or project onto a linear system of size m × n. Two optimization problems are associated with (1.1). One is called the primal problem (1.4)</p><p>The weak duality always holds, i.e., ψ * ≤ φ * . Under certain mild assumptions (e.g., X and Y are compact <ref type="bibr" target="#b38">[38]</ref>), the strong duality holds, i.e., ψ * = φ * , and in this case, (1.6)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Main goal</head><p>We aim at answering the following question:</p><p>For any deterministic first-order method, what is the best possible performance on solving a general large scale saddle-point problem (1.1)?</p><p>More precisely, our goal is to study the lower information-based complexity bound of first-order methods on solving the class of problems that can be formulated into (1.1). In the literature, all existing works about first-order methods on solving saddlepoint problems only provide upper complexity bounds. Establishing lower complexity bounds is important because they can tell us whether the existing methods are improvable and also because they can guide us to design "optimal" algorithms that have the best performance. To achieve this goal, we will construct worst-case SPP instances such that the complexity result of a first-order method to reach a desired accuracy is lower bounded by a problem-dependent quantity.</p><p>In the above question, we say an iterative algorithm for solving (1.1) is a first-order method if it accesses the information of the function f and the matrix A through a first-order oracle, denoted by O : R n × R m → R n × R m × R n . For an inquiry on any point (x, y) ∈ R n × R m , the oracle returns O(x, y) := ∇ f (x), Ax, A y .</p><p>(1.7)</p><p>Given an initial point (x (0) , y (0) ), a first-order method M for solving SPPs, at the t-th iteration, calls the oracle on (x (t) , y (t) ) to collect the oracle information O(x (t) , y (t) ) and then obtains a new point (x (t+1) , y (t+1) ) by a rule I t . The complete method M can be described by the initial point (x (0) , y (0) ) ∈ X × Y and a sequence of rules {I t } ∞ t=0 such that</p><p>x (t+1) , y (t+1) , x(t+1) , ȳ(t+1) = I t ϑ; O(x (0) , y (0) ), . . . , O(x (t) , y (t) ) , ∀ t ≥ 0, <ref type="bibr">(1.8)</ref> where (x (t) , y (t) ) ∈ X × Y denotes the inquiry point, and (x (t) , ȳ(t) ) ∈ X × Y is the approximate solution by the method. We are interested at the performance of M for solving very large scale instances of (1.1), namely, m and n are so large that we can only afford t m oracle calls. In <ref type="bibr">(1.8)</ref>, ϑ contains all rest information in an SPP, including the sets X and Y , the function g, the vector b, and the Lipschitz constant L f and its associated norm. Given a maximum number T of iterations, we assume without loss of generality that the output by M coincides with the last inquiry point, namely, x(T +1) = x (T +1) and ȳ(T +1) = y (T +1) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Literature review</head><p>Among existing works on complexity analysis of numerical methods, many more are about showing upper complexity bounds instead of lower bounds. Usually, the upper complexity bounds are established on solving problems with specific structures. They are important because they can tell the users at most how many iterations would guarantee a desired solution. On the contrary, lower complexity bounds, which were first studied in the seminal work <ref type="bibr" target="#b31">[31]</ref>, are usually information-based and shown on solving a general class of problems. Their importance lies in telling if a certain numerical method can still be improved for a general purpose and also in guiding the algorithm designers to make "optimal" methods. Although there are not many works along this line, each of them sets a base for designing numerical approaches. Below we review these lower complexity bound results on different classes of problems.</p><p>Proximal gradient methods On solving convex problems in the form of F * := min x {F(x) := f (x) + g(x)}, the proximal gradient method (PGM) iteratively updates the estimated solution by acquiring information of ∇ f and prox ηg at certain points, where η &gt; 0 is the stepsize, and the proximal mapping of ηg is defined as</p><formula xml:id="formula_2">prox ηg (z) = arg min x g(x) + 1 2η x -z 2 .</formula><p>For the problem class that has L f -smooth f , the lower bound has been established in <ref type="bibr" target="#b15">[15,</ref><ref type="bibr" target="#b31">31,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b34">34]</ref>. For example, <ref type="bibr" target="#b34">[34,</ref><ref type="bibr">Theorem 2.1.7</ref>] establishes a lower convergence rate bound:</p><formula xml:id="formula_3">F(x (t) ) -F * ≥ 3L f x (0) -x * 2 32(t+1) 2</formula><p>, where x(t) is the approximate solution output by PGM after t iterations, and x * is one optimal solution. In addition, setting η =<ref type="foot" target="#foot_0">1</ref> L f , <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b36">36]</ref> show that the PGM can achieve O(L f /t 2 ) convergence rate, and more precisely,</p><formula xml:id="formula_4">F(x (t) ) -F * ≤ 2L f x (0) -x * 2 (t+1) 2</formula><p>. Comparing the lower and upper bounds, one can easily see that they differ only by a constant multiple. Hence, the lower bound is tight in terms of the dependence on t, L f , and x (0)x * , and also the method given in <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b36">36]</ref> is optimal 1 among all methods that only access the information of ∇ f and prox ηg .</p><p>For the class of problems where f is L f -smooth and also μ-strongly convex (μ-SC), namely,</p><formula xml:id="formula_5">∇ f (x 1 ) -∇ f (x 2 ), x 1 -x 2 ≥ μ x 1 -x 2 2 , ∀ x 1 , x 2 ,</formula><p>the lower bound has been established in <ref type="bibr" target="#b31">[31]</ref><ref type="bibr" target="#b32">[32]</ref><ref type="bibr" target="#b33">[33]</ref><ref type="bibr" target="#b34">[34]</ref>. For example, <ref type="bibr" target="#b34">[34,</ref><ref type="bibr">Theorem 2.1.13]</ref> establishes a lower convergence rate bound:</p><formula xml:id="formula_6">F(x (t) ) -F * ≥ μ x (0) -x * 2 2 √ κ-1 √ κ+1 2t ,</formula><p>where κ = L f μ denotes the condition number. In addition, assuming the knowledge of μ and L f , <ref type="bibr" target="#b36">[36,</ref><ref type="bibr">Theorem 6]</ref> shows the convergence rate: -2t . Note that both lower and upper bounds of convergence rate are linear, and they have the same dependence on x (0)x * and κ. In this sense, the lower bound is tight, and the method is optimal.</p><formula xml:id="formula_7">F(x (t) )-F * ≤ L f x (0) -x * 2 4 1+ 1 √<label>2κ</label></formula><p>Inexact gradient methods On the convex problem f * := min x f (x) for which only approximation of ∇ f is available, there have been several studies on the corresponding lower complexity bound. For example, on solving the convex stochastic program</p><formula xml:id="formula_8">f * := min x { f (x) := E ξ f ξ (x)</formula><p>}, the stochastic gradient method (SGM) performs iterative update to the solution by accessing the stochastic approximation of subgradient ∇ f at a certain point. For the class of problems whose f is Lipschitz continuous<ref type="foot" target="#foot_1">2</ref> , <ref type="bibr" target="#b31">[31]</ref> shows that to find a stochastic ε-optimal solution x, i.e., E f (x)f * ≤ ε, the algorithm needs to run O(1/ε 2 ) iterations. On the other hand, as shown in <ref type="bibr" target="#b30">[30]</ref>, the order 1/ε 2 is achievable with appropriate setting of algorithm parameters. Hence, the lower complexity bound O(1/ε 2 ) is tight, and the stochastic gradient method is optimal on finding an approximate solution to the convex stochastic program. Further study of lower complexity bound of inexact gradient methods is also performed in <ref type="bibr" target="#b9">[10]</ref>. When f (x) has a special finite-sum structure, the lower complexity bound of randomized gradient method is studied in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b40">40]</ref>.</p><p>Primal-dual first-order methods On an affinely constrained problem <ref type="bibr">(1.6)</ref> or the more general saddle-point problem (1.1), many works have studied primal-dual first-order methods, e.g., <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b16">16,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b37">37,</ref><ref type="bibr" target="#b42">42,</ref><ref type="bibr" target="#b44">44]</ref>. To obtain an ε-optimal solution in a certain measure, an O(1/ε) complexity result is established by many of them for convex problems. In addition, for strongly convex cases, an improved result of O(1/ √ ε) has been shown in a few works such as <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b16">16,</ref><ref type="bibr" target="#b42">42,</ref><ref type="bibr" target="#b43">43]</ref>. All these results are about upper complexity bounds and none about lower bounds. Hence, it is unclear if these methods achieve the optimal order of convergence rate. Our results fill the missing part and can be used to determine the optimality of these existing algorithms.</p><p>Others In adddition to the above list of lower complexity bounds, there are also a few results on special types of problems. For convex quadratic minimization, <ref type="bibr" target="#b39">[39]</ref> gives a high-probability lower complexity bound of randomized first-order method. The lower complexity bound of subgradient methods for uniformly convex optimization has been studied in <ref type="bibr" target="#b20">[20]</ref>. Under the assumption that an algorithm has access to gradient information and is only allowed to perform linear optimization (instead of computing a projection), the lower complexity bounds have been studied in <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b21">21]</ref>. The lower complexity bounds of oblivious algorithms are studied in <ref type="bibr" target="#b1">[2]</ref>, where the way to generate new iterates by the algorithms is restricted. To find stationary points of smooth convex or nonconvex problems <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>, study the lower complexity bounds of first-order and also higher-order methods.</p><p>We list in Table <ref type="table" target="#tab_0">1</ref> several results that are reviewed above and also the results we establish in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Research tools, main results, and contributions</head><p>In this subsection, without specifying many technical details, we state the main results obtained in this paper, and the research tools that lead to such results. We start with a brief review of the seminal research tools developed in <ref type="bibr" target="#b31">[31]</ref><ref type="bibr" target="#b32">[32]</ref><ref type="bibr" target="#b33">[33]</ref><ref type="bibr" target="#b34">[34]</ref> that lead to the classical lower complexity bound result of first-order methods for unconstrained smooth convex optimization min x∈R n f (x). Then, we describe our efforts adapting their research tools to derive lower complexity bounds of first-order methods for SPPs, and state our main results.</p><p>The work in <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b33">33]</ref> constructs a worst-case instance of unconstrained smooth convex optimization in the form of a quadratic problem:</p><formula xml:id="formula_9">f * := min x∈R n f (x) := 1 2 x Qx -q x , (1.9)</formula><p>which is also equivalent to solving the linear system Qx = q. Briefly speaking, the main research tool in <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b33">33]</ref> is rotating into a certain linear subspace the iterates given by a deterministic first-order method for solving (1.9). Ignoring most of the technical details, given (Q, q) and a deterministic first-order method M, the tool allows us to analyze the performance of M by simply assuming that the output x(t) lies in K 2t+1 := span{q, Qq, . . . , Q 2t q}, the Krylov subspace generated by Q and q.</p><p>To construct a worst-case instance of (1.9), it then suffices to maximize the objective value difference min x∈K 2t+1 f (x)f * with respect to (Q, q). In <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b33">33]</ref>, it is proved that the worst-case Q can be any matrix (e.g., diagonal matrix) that has certain specified eigenvalues, which are computed through Chebyshev Equioscillation theorem. In <ref type="bibr" target="#b34">[34]</ref>, a tri-diagonal worst-case matrix Q is constructed along with a worst-case vector q.</p><p>The tri-diagonal Q has eigenvalues specified in <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b33">33]</ref>. Also, with the (Q, q), K 2t+1 is spanned by standard basis vectors. This makes it easier to prove that the constructed Q and q yield worst-case performance of first-order methods. The analysis in <ref type="bibr" target="#b34">[34]</ref> focuses only on first-order methods whose iterates lie in the Krylov subspace. However, combining with the aforementioned research tool in <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b33">33]</ref>, the result can be extended to an arbitrary deterministic first-order method.</p><p>Our main contribution is to establish lower complexity bounds of deterministic first-order methods on solving bilinear saddle-point problem (1.1), through adapting the techniques in <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b33">33]</ref> and <ref type="bibr" target="#b34">[34]</ref>. First, we design a worst-case instance of the convex constrained problem <ref type="bibr">(1.6)</ref>. It is an affinely constrained convex quadratic program:</p><formula xml:id="formula_10">f * := min x∈R n f (x) := 1 2 x Hx -h x, s.t. Ax = b .</formula><p>Our design of (H, h, A, b) is inspired by the setting in <ref type="bibr" target="#b34">[34]</ref> of (Q, q) in a worstcase instance of (1.9). Also, we follow the constructive proof in <ref type="bibr" target="#b34">[34]</ref> and focus on </p><formula xml:id="formula_11">f (x) + g(x) f is L f -smooth (∇ f , prox ηg ) O( L f ε ) [34] O( L f ε ) [3,36]</formula><p>Where g is closed convex</p><formula xml:id="formula_12">f is L f -smooth and μ-SC (∇ f , prox ηg ) O( L f μ log 1 ε ) [34] O( L f μ log 1 ε ) [36] min x f (x) := E f ξ (x) f is Lipschitz continuous ∇ f ξ O 1 ε 2 [31,34] O 1 ε 2 [30] min x∈X f (x), s.t. Ax = b f is L f -smooth (∇ f , Ax, A y) O L f ε + A ε [this paper] O L f ε + A ε [37] SPP (1.1) f is L f -smooth (∇ f , Ax, A y) O L f ε + A ε [this paper] O L f ε + A ε [35]</formula><p>All problems are convex. First through third rows:</p><formula xml:id="formula_13">ε-solution x if obj(x) -obj * ≤ ε; fourth row: ε-solution x ∈ X if f (x) -f * ≤ ε and Ax -b ≤ ε; fifth row: ε-solution (x, ȳ) ∈ X × Y if primal dual gap φ(x) -ψ(ȳ) ≤ ε. Here, f is L f -smooth if (1.</formula><p>2) holds, and SC stands for strongly convex first-order methods whose iterates lie in a certain linearly spanned subspace. This way, we establish the lower complexity bound of deterministic first-order methods on solving <ref type="bibr">(1.6)</ref>. Secondly, we adapt the rotation technique in <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b33">33]</ref> to relax the linear span restriction and show lower complexity of any deterministic first-order method on solving <ref type="bibr">(1.6)</ref>. Due to the additional linear constraint, the analysis in <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b33">33]</ref> cannot be directly applied. It may not be true that for any (H, h, A, b), the iterates by a given firstorder method M can be rotated into a Krylov subspace. However, with our specific designed (H, h, A, b), we are able to do so. Finally, we use as a bridge the designed worse-case instance of (1.6) to design a worst-case instance of (1.1) and thus address our main question posed in Sect. 1.1.</p><p>The main results we obtain in this paper are summarized in the following two theorems. Throughout this paper, by a t = Ω(b t ), we mean that there is a positive constant C independent of t such that a t ≥ C • b t .</p><p>Theorem 1.1 (Lower complexity bounds for affinely constrained problems) Let t be a positive integer, L f &gt; 0, and L A &gt; 0. For any first-order method M that is described in (1.8), there exists a problem instance of (1.6) such that f is L f -smooth, A = L A , the instance has a primal-dual solution (x * , y * ), and</p><formula xml:id="formula_14">f (x (t) ) -f (x * ) = Ω L f x * 2 t 2 + L A x * • y * t , Ax (t) -b = Ω L A x * t ,</formula><p>where x(t) is the approximate solution output by M. In addition, given μ &gt; 0, there exists an instance of (1.6) with μ-strongly convex function f , and it has a primal-dual solution (x * , y * ) satisfying</p><formula xml:id="formula_15">x(t) -x * 2 = Ω L 2 A y * 2 μ 2 t 2 .</formula><p>Theorem 1.2 (Lower complexity bounds for bilinear saddle-point problems) Let t be a positive integer, L f &gt; 0, and L A &gt; 0. For any first-order method M that is described in (1.8), there exists a problem instance of (1.1) such that f is L f -smooth, A = L A , X and Y are Euclidean balls with radii R X and R Y respectively, and</p><formula xml:id="formula_16">φ(x (t) ) -ψ(ȳ (t) ) = Ω L f R 2 X t 2 + L A R X R Y t ,</formula><p>where φ and ψ are the associated primal and dual objective functions in (1.3) and (1.4), and (x (t) , ȳ(t) ) is the approximate solution output by M. In addition, given μ &gt; 0, there exists an instance of (1.1) such that f is μ-strongly convex, X and Y are Euclidean balls with radii R X and R Y respectively, and</p><formula xml:id="formula_17">φ(x (t) ) -ψ(ȳ (t) ) = Ω L 2 A R 2 Y μt 2 .</formula><p>Comparing to upper complexity bounds of several existing first-order methods, we find that our lower complexity bounds are tight, up to the difference of constant multiples and/or logarithmic terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Notation and outline</head><p>We use bold lower-case letters x, y, c, . . . for vectors and bold upper-case letters A, Q, . . . for matrices. For any vector x ∈ R n , we use x i to denote its i-th component. When describing an algorithm, we use x (k) for the k-th iterate. A denotes the transpose of a matrix A. We use 0 for all-zero vector and 1 for all-one vector, and we use O for a zero matrix and I for the identity matrix. Their sizes will be specified by a subscript, if necessary, and otherwise are clear from the context. We adopt MATLAB's operations to concatenate matrices and vectors. For example, e j, p = [0 j-1 ; 1; 0 p-j ] ∈ R p denotes the j-th standard basis vector in R p . We use Z ++ for the set of positive integers and S n + for the set of all n × n symmetric positive semidefinite matrices. Without further specification, • is used for the Euclidean norm of a vector and the spectral norm of a matrix.</p><p>The rest of the paper is organized as follows. In Sect. 2, for affinely constrained problems, we present lower complexity bounds of first-order methods that satisfy a linear span requirement. We drop the linear span assumption in Sect. 3 and show lower complexity bounds of first-order methods that are described in <ref type="bibr">(1.8)</ref>. Section 4 is about the bilinear saddle-point problems. Lower complexity bounds are established there for first-order methods described in (1.8). In Sect. 5, we show the tightness of the established lower complexity bounds by comparing them with existing upper complexity bounds. Finally, Sect. 6 proposes a few interesting topics for future work and concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Lower complexity bounds under linear span assumption for affinely constrained problems</head><p>In this and the next sections, we study lower complexity bounds of first-order methods on solving the affinely constrained problem (1.6). Our approach is to design a "hard" problem instance such that the convergence rate of any first-order method is lower bounded. The designed instances are convex quadratic programs in the form of</p><formula xml:id="formula_18">f * := min x∈R n f (x) := 1 2 x Hx -h x, s.t. Ax = b , (<label>2.1)</label></formula><p>where A ∈ R m×n , and H ∈ S n + . Note that the above problem is a special case of (1.6). Throughout this section, we assume that -the dimensions m, n ∈ Z ++ are given and satisfy m ≤ n, and -a fixed positive integer number k &lt; m 2 is specified. Our lower complexity analysis will be based on the performance of the k-th iterate of a first-order method on solving the designed instance. It should be noted that the assumption k &lt; m 2 is valid if the problem dimensions m and n are very big and we do not run too many iterations of the algorithm.</p><p>To have a relatively simple start, we focus on a special class of first-order methods in this section. More precisely, we make the following assumption. Assumption 2.1 (Linear span) The iterate sequence {x (t) } ∞ t=0 satisfies x (0) = 0 and (1) ), A r (1) , . . . , ∇ f (x (t-1) ), A r (t-1) , t ≥ 1,</p><formula xml:id="formula_19">x (t) ∈ span ∇ f (x (0) ), A r (0) , ∇ f (x</formula><p>where r = Axb denotes the residual.</p><p>In the context, we refer to the above assumption as the linear span assumption. It is not difficult to find rules {I t } ∞ t=0 such that the iterate sequence {x (t) } in Assumption 2.1 can be obtained by <ref type="bibr">(1.8)</ref>. Note that we do not lose generality by assuming x (0) = 0, because otherwise we can consider a shifted problem</p><formula xml:id="formula_20">min x f (x -x (0) ), s.t. A(x -x (0) ) = b.</formula><p>It should be noted that Assumption 2.1 may not always hold for a first-order method, e.g., when there is projection involved in the algorithm. The lower complexity bound analysis can be performed without the linear span assumption, thanks to a technique introduced in <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b33">33]</ref> that utilizes a certain rotational invariance of quadratic functions over a Euclidean ball. To facilitate reading, we defer the incorporation of such a technique to Sect. 3, where we will elaborate on the technical details and perform the lower complexity bound analysis without Assumption 2.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Special linear constraints</head><p>In this subsection, we describe a set of special linear constraints, which will be used to study the lower complexity bound of first-order methods satisfying Assumption 2.1.</p><p>We let the matrix Λ and vector c be</p><formula xml:id="formula_21">Λ = B O O G ∈ R m×n and c = 1 2k 0 ∈ R m , (<label>2.2)</label></formula><p>where G ∈ R (m-2k)×(n-2k) is any matrix of full row rank such that G = 2, and</p><formula xml:id="formula_22">B := ⎡ ⎢ ⎢ ⎢ ⎢ ⎣ -1 1 . . . . . . -1 1 -1 1 1 ⎤ ⎥ ⎥ ⎥ ⎥ ⎦ ∈ R 2k×2k . (2.3)</formula><p>All the designed "hard" instances in this paper are built upon Λ and c given in (2.2). Two immediate observations regarding (2.2) and (2.3) are as follows. First, for any</p><formula xml:id="formula_23">u = (u 1 ; • • • ; u 2k ) ∈ R 2k , we have Bu 2 = (u 2k -u 2k-1 ) 2 + • • • + (u 2 -u 1 ) 2 + u 2 1 ≤ 2(u 2 2k + u 2 2k-1 ) + • • • + 2(u 2 2 + u 2 1 ) + u 2 1 ≤ 4 u 2 , so B ≤ 2. (2.4)</formula><p>Consequently, noting G = 2 and the block diagonal structure of Λ, we have</p><formula xml:id="formula_24">Λ = max{ B , G } = 2. (2.5)</formula><p>Second, it is straightforward to verify that</p><formula xml:id="formula_25">B -1 = ⎡ ⎢ ⎢ ⎣ 1 1 1 . . . . . . . . . 1 • • • 1 1 ⎤ ⎥ ⎥ ⎦ . (2.6)</formula><p>Krylov subspaces We study two Krylov subspaces that are associated with the matrix Λ and vector c described in (2.2). In particular, we consider the Krylov subspaces</p><formula xml:id="formula_26">J i := span c, (ΛΛ )c, (ΛΛ ) 2 c, . . . , (ΛΛ ) i c ⊆ R m and K i := Λ J i ⊆ R n , for i ≥ 0. (2.7)</formula><p>As shown below in (2.17), restricting on the first 2k entries, the above two Krylov subspaces reduce to</p><formula xml:id="formula_27">F i := span 1 2k , B 2 1 2k , . . . , B 2i 1 2k and R i := span B1 2k , . . . , B 2i+1 1 2k . (2.8)</formula><p>We first establish some important properties of F i and R i as follows.</p><p>Lemma 2.1 Let F i and R i be defined in (2.8). For any 0 ≤ i ≤ 2k -1, we have </p><formula xml:id="formula_28">F i = span{1 2k , e 1,</formula><formula xml:id="formula_29">F 0 = span{1 2k }, R 0 = span{B1 2k } = span{e 2k,2k }, BR 0 = span{Be 2k,2k } = span{e 1,2k }, F 1 = span{1 2k , B 2 1 2k } = span{1 2k , e 1,2k }, R 1 = span{B1 2k , B 3 1 2k } = span{e 2k,2k , Be 1,2k } = span{e 2k-1,2k , e 2k,2k }, BR 1 = span{B 2 1 2k , B 4 1 2k } = span{e 1,2k , B 2 e 1,2k } = span{e 1,2k , e 2,2k }.</formula><p>Therefore, the results in (2.9) and (2.10) hold for i = 0 and i = 1.</p><p>Below we prove the results by induction. Assume that there is a positive integer s &lt; 2k and (2.9) holds for i = s -1, namely, </p><formula xml:id="formula_30">F s-1 = span{1 2k , e 1,2k , e 2,2k , . . . , e s-1,2k }, R s-1 = span{e 2k-s+1,2k , . . . ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof</head><p>Observe that for any i = 0, . . . , 2k -1 we have</p><formula xml:id="formula_31">(ΛΛ ) i c = B 2i 1 2k 0 m-2k and Λ (ΛΛ ) i c = B 2i+1 1 2k 0 n-2k .</formula><p>(2.17)</p><p>Consequently, the definitions in (2.7) becomes</p><formula xml:id="formula_32">J i = F i × {0 m-2k } and K i = R i × {0 n-2k }.</formula><p>Therefore, the results in (2.15) and (2.16) immediately follow from Lemma 2.1.</p><p>Two remarks are in place for the Krylov subspaces K i and J i . First, by the definitions of K i and J i in (2.7) and the relation (2.16), we have</p><formula xml:id="formula_33">ΛK i ⊆ J i+1 and Λ J i = K i , ∀i = 1, . . . , 2k -1.</formula><p>(</p><p>Second, by (2.15) we have</p><formula xml:id="formula_35">K i-1 K i and J i-1 J i , ∀i = 1, . . . , 2k -1. (2.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>19)</head><p>An important lemma We conclude this subsection by showing a lemma that will be used a few times in our analysis. It specifies the conditions on (2.1) to guarantee that any iterate sequence {x (t) } k t=1 satisfying Assumption 2.1 is in the subspace K k-1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 2.3 Let Λ and c be given in (2.2). Given any L</head><formula xml:id="formula_36">A ∈ R, let A = L A 2 Λ and b = L A 2 c. (2.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>20)</head><p>Consider (2.1) with A and b defined as above, h ∈ K 0 and H satisfying HK t-1 ⊆ K t for any 1 ≤ t ≤ k, where K i is defined in (2.7). Then under Assumption 2.1, we have</p><formula xml:id="formula_37">x (t) ∈ K t-1 for any 1 ≤ t ≤ k.</formula><p>Proof It suffices to prove that for any t = 1, . . . , k, span ∇ f (x (0) ), A r (0) , ∇ f (x (1) ), A r (1) , . . . , ∇ f (x (t-1) ), A r (t-1) ⊆ K t-1 .</p><p>(2.21)</p><p>We prove the result by induction. First, since x (0) = 0, from (2.2) and (2.20) we have A r (0) = -A b ∈ span{e 2k,n } = K 0 . In addition, from the condition h ∈ K 0 , it follows that ∇ f (x (0) ) = -h ∈ K 0 . Therefore, (2.21) holds when t = 1. Assume that for a certain 1 ≤ s &lt; k, (2.21) holds for t = s, and consequently</p><formula xml:id="formula_38">x (s) ∈ K s-1 . (2.22)</formula><p>We go to prove the result in (2.21) for t = s+1, or equivalently ∇ f (x (s) ), A r (s) ∈ K s , and finish the induction. From (2.19) we have K 0 ⊆ K s . By this observation, noting x (s) ∈ K s-1 , and using the conditions h ∈ K 0 and HK s-</p><formula xml:id="formula_39">1 ⊆ K s , we have ∇ f (x (s) ) = Hx (s) -h ∈ K s .</formula><p>In addition, from (2.18) and (2.22), we have (s) ) and A r (s) are both in K s , and by induction (2.21) holds for any 1 ≤ t ≤ k. This completes the proof.</p><formula xml:id="formula_40">A Ax (s) ∈ K s . Since A b ∈ K 0 ⊆ K s , then A r (s) = A Ax (s) -A b ∈ K s . Therefore, ∇ f (x</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">A lower complexity bound for convex case</head><p>In this subsection, we establish a lower complexity bound of any first-order method that satisfies the linear span assumption (Assumption 2.1) on solving (2.1). Our approach is to build an instance such that the iterate (2.23)</p><formula xml:id="formula_41">x (t) ∈ K k-1 ,</formula><p>In the above equation, the former value is used to measure the performance of an algorithm by the objective value difference and the latter by the feasibility error. The instance we construct is in the form of (2.1) with</p><formula xml:id="formula_42">H = L f 4 B B I n-2k ∈ R n×n , h = L f 2 e 2k,n , A = L A 2 Λ, b = L A 2 c,<label>(2.24)</label></formula><p>where L f and L A are given nonnegative numbers, B, Λ and c are those given in (2.2) and (2.3). From (2.4), (2.5), and the block diagonal structure of H above, we have</p><formula xml:id="formula_43">H = (L f /4) B 2 ≤ L f and A = L A .</formula><p>Therefore, (2.1) with data specified in (2.24) provides an instance of (1.6) whose objective function f is L f -smooth.</p><p>To establish the lower complexity bound, we first present three technical lemmas. We show in Lemma 2.4 below that under Assumption 2.1, the iterates generated by a first-order method on solving the designed instance would satisfy x (t) ∈ K t-1 for any 1 ≤ t ≤ k. In Lemma 2.5, we give a pair of optimal primal-dual solution and also the optimal objective value of the instance. Then, in Lemma 2.6, we provide lower bounds of the values in (2.23).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 2.4</head><p>Consider the instance of (2.1) with data described in <ref type="bibr">(2.24)</ref>. Under Assumption 2.1, we have</p><formula xml:id="formula_44">x (t) ∈ K t-1 for any 1 ≤ t ≤ k, where K t-1 is defined in (2.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7).</head><p>Proof To prove the lemma, it suffices to verify that h ∈ K 0 and HK t-1 ⊆ K t for any 1 ≤ t ≤ k and then apply Lemma 2.3. Since h is a multiple of e 2k,n , from (2.15) we immediately have h ∈ K 0 . Using the definition of H and the second line of equation in <ref type="bibr">(2.11)</ref>, one can easily verify that H span{e 2k-t+1,n , . . . , e 2k,n } = span{e 2k-t,n , e 2k-t+1,n , . . . , e 2k,n } for any 1 ≤ t ≤ k. Hence we have all the conditions required by Lemma 2.3, and thus x (t) ∈ K t-1 , which completes the proof.</p><p>The next lemma gives the primal-dual solution and optimal objective value of the considered instance. Lemma 2.5 Let L f &gt; 0 and L A &gt; 0 be given. The instance of (2.1) with data given in (2.24) has a unique optimal solution x * with a unique associated Lagrange multiplier y * given by</p><formula xml:id="formula_45">x * = (1; 2; • • • ; 2k; 0 n-2k ), y * = - L f 2L A (1 2k ; 0 m-2k ) .</formula><p>(2.25)</p><p>In addition, the optimal objective value is</p><formula xml:id="formula_46">f * = - 3k L f 4 , (<label>2.26)</label></formula><p>and the norm of the dual solution is</p><formula xml:id="formula_47">y * = L f 2L A √ 2k.</formula><p>(2.27)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof</head><p>We split x into two parts as x = (u; v) with u ∈ R 2k and v ∈ R n-2k . Then from the block structure of H and A in (2.24), we obtain the following two optimization problems with respect to u and v:</p><formula xml:id="formula_48">min u 1 2 u Su -s u, s.t. L A 2 Bu = L A 2 1 2k , (2.28) min v L f 8 v 2 , s.t. L A 2 Gv = 0,<label>(2.29)</label></formula><p>where</p><formula xml:id="formula_49">S = L f 4 B B and s = L f 2 e 2k,2k<label>.</label></formula><p>Since L A &gt; 0 and B is nonsingular, we have that u * = (1; 2; • • • ; 2k) is the unique feasible and thus optimal solution of (2.28). In addition, since L f &gt; 0, (2.29) clearly has a unique solution v * = 0. Hence, x * is unique and given in <ref type="bibr">(2.25)</ref>. Consequently,</p><formula xml:id="formula_50">f * = 1 2 (u * ) Su * -s u * = L f 8 Bu * 2 -s u * = - 3k L f 4 .</formula><p>To derive the corresponding dual variable, we split y = (λ; π ) with λ ∈ R 2k and π ∈ R m-2k . It follows from the KKT conditions of (2.28) that</p><formula xml:id="formula_51">L A 2 B λ * = Su * -s, L A 2 G π * = L f 4 v * = 0.</formula><p>Since G has full row rank, we have π * = 0. In addition, noting the description of B -1 in (2.6), we have</p><formula xml:id="formula_52">λ * = 2 L A B -1 (Su * -s) = - L f 2L A 1 2k .</formula><p>Therefore, (2.25) follows immediately, and it is straightforward to have (2.27).</p><p>Using Lemma 2.5, we have the following estimate.</p><p>Lemma 2.6 Let L f &gt; 0 and L A &gt; 0 be given. Then for the instance of (2.1) with data given in (2.24), we have</p><formula xml:id="formula_53">min x∈K k-1 f (x) -f * = k L f 4 ,<label>(2.30a)</label></formula><formula xml:id="formula_54">min x∈K k-1 Ax -b ≥ √ 3L A x * 4 √ 2(k + 1) , (<label>2.30b)</label></formula><p>where x * is given in (2.25), and K k-1 is defined in (2.7).</p><p>Proof Using the formula</p><formula xml:id="formula_55">p i=1 i 2 = p( p + 1)(2 p + 1) 6 , ∀ p ∈ Z ++ , (<label>2.31)</label></formula><p>and the description of x * in (2.25), we have </p><formula xml:id="formula_56">x * 2 = 2k i=1 i 2 = k(2k + 1)(4k + 1) 3 . (<label>2</label></formula><formula xml:id="formula_57">Ax -b 2 ≥ L 2 A 4 k (2.32) = 3L 2 A x * 2 4(2k + 1)(4k + 1) ≥ 3L 2 A x * 2 32(k + 1) 2 , (<label>2.33)</label></formula><p>and hence (2.30b) holds.</p><p>To prove (2.30a), we need to compute the minimal objective value of f (x) over K k-1 . By (2.15) we have K k-1 = span{e k+1,n , . . . , e 2k,n }. Hence, for any x ∈ K k-1 , we can write it as x = (0 ; z; 0 n-2k ) where z ∈ R k . Recalling (2.24), we have</p><formula xml:id="formula_58">h x = L f 2 e 2k,n x = L f 2 z k , x Hx = L f 4 B(0 k ; z) 2 = L f 4 Bz 2 ,</formula><p>where</p><formula xml:id="formula_59">B := ⎡ ⎢ ⎢ ⎢ ⎢ ⎣ -1 1 . . . . . . -1 1 -1 1 1 ⎤ ⎥ ⎥ ⎥ ⎥ ⎦ ∈ R k×k is a k × k submatrix of B. Therefore, min x∈K k-1 f (x) = min z∈R k L f 8 Bz 2 - L f 2 z k . (2.34)</formula><p>Let z * be the optimal solution to the right hand side minimization problem in (2.34).</p><p>Then it must satisfy the optimality condition:</p><formula xml:id="formula_60">L f 4 B2 z * = L f 2 e k,k , which has the unique solution z * = 2(1; • • • ; k). Plugging z = z * into the right hand side of (2.34) yields min x∈K k-1 f (x) = - k L f 2 . (<label>2.35)</label></formula><p>From the above result and (2.26), we have (2.30a) and complete the proof.</p><p>Using Lemmas 2.4 through 2.6, we are ready to establish the following lower complexity bound results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 2.1 (Lower complexity bound for convex case under linear span assumption)</head><p>Let m ≤ n be positive integers, L f &gt; 0, and L A &gt; 0. For any positive integer t &lt; m 2 , there exists an instance of (1.6) such that f is L f -smooth, A = L A , and it has a unique primal-dual solution (x * , y * ). In addition, on solving (1.6), if the algorithm satisfies Assumption 2.1, then</p><formula xml:id="formula_61">f (x (t) ) -f (x * ) ≥ 3L f x * 2 64(t + 1) 2 + √ 3L A x * • y * 16(t + 1) , (<label>2.36a</label></formula><p>)</p><formula xml:id="formula_62">Ax (t) -b ≥ √ 3L A x * 4 √ 2(t + 1) . (<label>2</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.36b)</head><p>Proof Set k = t &lt; m 2 and consider the instance (2.1) with data given in (2.24). Clearly, this instance is in the form of (1.6), f is L f -smooth, and A = L A .</p><p>Lemma 2.5 indicates that the considered instance has a unique primal-dual solution (x * , y * ) given in <ref type="bibr">(2.25)</ref>. By Lemma 2.4 and noting t = k, we have</p><formula xml:id="formula_63">x (t) ∈ K k-1 . Consequently, f (x (t) ) -f (x * ) ≥ min x∈K k-1 f (x) f * , and Ax (t) -b ≥ min x∈K k-1 Ax -b .</formula><p>From (2.30a), (2.32) and (2.27), it follows that min </p><formula xml:id="formula_64">x∈K k-1 f (x) -f * = k L f 8 + k L f 8 = 3L f x * 2 8(2k + 1)(4k + 1) + √ 3L A x * • y * 4 √ 2 √ (2k + 1)(4k + 1) . Since k = t,</formula><formula xml:id="formula_65">x∈K k-1 f (x) -f * = L f 16 k + √ 2L A 8 k + L 2 f -L 2 A 16L f k.</formula><p>Hence, assuming L f ≥ L A and taking k = t we have</p><formula xml:id="formula_66">f (x (t) ) -f (x * ) ≥ min x∈K t-1 f (x) -f * ≥ L f 16 t + √ 2L A 8 t = 3L f x * 2 16(2t + 1)(4t + 1) + √ 6L A x * • y * 4 √ (2t + 1)(4t + 1</formula><p>) .</p><p>The proof of the above claim follows the same lines of arguments throughout this subsection. We do not repeat it here but leave the details to interested readers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">A lower complexity bound for strongly convex case</head><p>In this subsection, we develop a lower complexity bound for solving (1.6) when f is μ-strongly convex. The measure we use is different from those in (2.36). Instead of bounding the objective and feasibility error, we directly bound the distance of generated iterate to the unique optimal solution. Similar to the previous subsection, the "hard" instance we design is also a quadratic program in the form of (2.1). The following theorem summarizes our result.</p><p>Theorem 2.2 (Lower complexity bound for strongly convex case under linear span assumption) Let m ≤ n be positive integers, μ &gt; 0, and L A &gt; 0. For any positive integer t &lt; m 2 , there exists an instance of (1.6) such that f is differentiable and μstrongly convex, A = L A , and it has a unique primal-dual solution pair (x * , y * ). In addition, for any algorithm on solving (1.6), if it satisfies Assumption 2.1, then</p><formula xml:id="formula_67">x (t) -x * 2 ≥ 5L 2 A y * 2 256μ 2 (t + 1) 2</formula><p>Proof Set k = t and consider an instance of (2.1) with H = μI, h = 0, and A and b given in <ref type="bibr">(2.20)</ref>. Clearly, f is differentiable and μ-strongly convex, and A = L A . It is easy to verify that Lemma 2.3 applies to this instance, and thus x (t) ∈ K t-1 . Also, by the KKT condition μx * = A y * , we can easily verify that the system has a unique primal-dual solution (x * , y * ) x * given in (2.25) and y * given by</p><formula xml:id="formula_68">y * i = μ L A i(4k -i + 1), if 1 ≤ i ≤ 2k, 0, if i ≥ 2k + 1.</formula><p>(2.37)</p><p>From the formula of K i in (2.15), it follows that for any</p><formula xml:id="formula_69">x ∈ K k-1 , x -x * 2 ≥ k i=1 i 2 (2.31) = k(k + 1)(2k + 1) 6 . (<label>2.38)</label></formula><p>Moreover, by (2.31) and also the formulas</p><formula xml:id="formula_70">p i=1 i 3 = p 2 ( p + 1) 2 4 , p i=1 i 4 = p( p + 1)(2 p + 1)(3 p 2 + 3 p -1) 30 ,</formula><p>we have from (2.37) that</p><formula xml:id="formula_71">y * 2 = μ 2 L 2 A 2k i=1 i 2 (4k -i + 1) 2 = μ 2 L 2 A (4k + 1) 2 2k i=1 i 2 -2(4k + 1) 2k i=1 i 3 + 2k i=1 i 4 = 2k(2k + 1)(4k + 1)μ 2 L 2 A (4k + 1) 2 6 -k(2k + 1) + 12k 2 + 6k -1 30 = 2k(2k + 1)(4k + 1)μ 2 15L 2 A (16k 2 + 8k + 2).</formula><p>Since t = k and x (t) ∈ K t-1 , it is not difficult to verify the desired result from (2.38) and the above equation, and thus we complete the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Lower complexity bounds of general deterministic first-order methods for affinely constrained problems</head><p>In this section, we drop the linear span assumption (see Assumption 2.1) and establish lower complexity bounds of general first-order methods described in (1.8) on solving <ref type="bibr">(1.6)</ref>. The key idea is to utilize certain rotational invariance of quadratic functions and linear systems, a technique that was introduced in <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b33">33]</ref>. Specifically, we first establish a key proposition (i.e., Proposition 3.1 below) as our main tool and then derive the lower complexity bounds by the results obtained in the previous section.</p><p>For ease of notation, we define a specific class of SPPs as follows. <ref type="figure">P(θ ;</ref><ref type="figure">H,</ref><ref type="figure">A</ref>) is defined as one instance of (1.3) with</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 3.1 (A special class of SPPs)</head><formula xml:id="formula_72">Given H ∈ S n + , A ∈ R m×n , and θ = (h, b, R X , R Y , λ) where R X , R Y ∈ [0, +∞] and λ ≥ 0,</formula><formula xml:id="formula_73">f (x) = 1 2 x Hx -h x, g(y) = λ y , X = {x ∈ R n : x ≤ R X },</formula><p>and</p><formula xml:id="formula_74">Y = {y ∈ R m : y ≤ R Y }. (3.1)</formula><p>Hence, by P(θ ; H, A) or more specifically P (h, b, R X , R Y , λ); H, A , we mean the instance</p><formula xml:id="formula_75">φ * := min x ≤R X φ(x) := 1 2 x Hx -h x + max y ≤R Y Ax -b, y -λ y . (3.2)</formula><p>Remark 3.1 We will call (θ; H, A) as the data in the instance P(θ ; H, A). Given H ∈ S n + , A ∈ R m×n , h ∈ R n and b ∈ R m , then an instance of (2.1) can be denoted as P(θ ; H, A) with θ = (h, b, +∞, +∞, 0).</p><formula xml:id="formula_76">Proposition 3.1 Let m ≤ n, k &lt; m</formula><p>2 , and t ≤ k 2 -1 be positive integers, and let L f and L A be nonnegative numbers. Suppose that we have an instance P(θ ; H, A), called original instance, where H ≤ L f , and A and b are those given in <ref type="bibr">(2.20)</ref>. Moreover, assume that H ∈ S n + and satisfies HK 2s-1 ⊆ K 2s for any s ≤ k 2 and h ∈ K 0 , where K i is defined in (2.7). Then for any deterministic first-order method M that is described in (1.8), there exists another instance P(θ ; H, Ã), called rotated instance, where H = U HU, Ã = V AV, U and V are certain orthogonal matrices dependent on t such that Uh = h and Vb = b, and 1. In addition, (x * , y * ) is a saddle point that satisfies <ref type="bibr">(1.5)</ref> to the original instance if and only if (x, ŷ) := (U x * , V y * ) is a saddle point to the rotated instance. 2. Furthermore, when M is applied to solve P(θ ; H, Ã), its t-th computed approximate solution x(t) satisfies</p><formula xml:id="formula_77">φ(x (t) ) -φ * ≥ min x∈K k-1 φ(x) -φ * , (3.3) f (x (t) ) -f (x) ≥ min x∈K k-1 f (x) -f (x * ), (<label>3.4)</label></formula><p>Lower complexity bounds of first-order methods…</p><formula xml:id="formula_78">Ãx (t) -b ≥ min x∈K k-1</formula><p>Axb , (3.5)</p><formula xml:id="formula_79">x(t) -x 2 ≥ min x∈K k-1 x -x * 2 , (3.6)</formula><p>where φ and f are the functions in the original instance (see the definitions in (3.1) and (3.2)), and φ and f are those in the rotated instance.</p><p>The proof of Proposition 3.1 is rather technical and deferred after we present the lower complexity bound results. Here we give a few remarks on this proposition. First, in Proposition 3.1 there are two problem instances, which have been distinguished as original and rotated instances, respectively. Second, the results in (3.3) through <ref type="bibr">(3.6)</ref> establish an important relation between the original and rotated instances. Specifically, by this relation, we are able to study the best possible performance of general first-order methods through the linear subspace K k-1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Lower complexity bounds</head><p>In this subsection, we apply Proposition 3.1 together with Theorems 2.1 and 2.2 to establish the lower complexity bounds of general first-order methods on solving <ref type="bibr">(1.6)</ref>. The theorem below extends the results in Theorem 2.1. Theorem 3.1 (Lower complexity bound of general first-order methods) Let 8 &lt; m ≤ n be positive integers, L f &gt; 0, and L A &gt; 0. For any positive integer t &lt; m 4 -1 and any deterministic first-order method M that is described in (1.8), there exists an instance of (1.6) such that f is L f -smooth and A = L A . In addition, the instance has a unique primal-dual solution (x * , y * ), and</p><formula xml:id="formula_80">f (x (t) ) -f * ≥ 3L f x * 2 64(2t + 5) 2 + √ 3L A x * • y * 16(2t + 5) , (<label>3.7a</label></formula><p>)</p><formula xml:id="formula_81">Ax (t) -b ≥ √ 3L A x * 4 √ 2(2t + 5) , (<label>3.7b)</label></formula><p>where x(t) is the output by M.</p><formula xml:id="formula_82">Proof Set k = 2t + 2 &lt; m</formula><p>2 in the definition of Λ and c given in (2.2). Consider (2.1) with data given in <ref type="bibr">(2.24)</ref>. By Remark 3.1, this problem instance is P(θ ; H, A) with θ = (h, b, +∞, +∞, 0). It is easy to check that the data satisfy the conditions required in Proposition 3.1. Hence, there exists a rotated instance P(θ ; H, Ã), i.e.,</p><formula xml:id="formula_83">f * := min x∈R n f (x) := 1 2 x Hx -h x, s.t. Ãx = b , (<label>3.8)</label></formula><p>where H = U HU and Ã = V AV with orthogonal matrices U and V dependent on t, and in addition (3.4) and (3.5) hold. From the proof of Theorem 2.1 together with these two inequalities, we have</p><formula xml:id="formula_84">f (x (t) ) -f * ≥ min x∈K k-1 f (x) -f * ≥ 3L f x * 2 64(k + 1) 2 + √ 3L A x * • y * 16(k + 1)<label>,</label></formula><formula xml:id="formula_85">Ãx (t) -b ≥ min x∈K k-1 Ax -b ≥ √ 3L A x * 4 √ 2(k + 1) , (3.9)</formula><p>where (x * , y * ) is the unique primal-dual solution to the original instance. By item 1 of Proposition 3.1, the rotated instance (3.8) also has a unique primal-dual solution (x, ŷ) given by x = U x * and ŷ = V y * . Since U and V are orthogonal, it holds that x * = x and y * = ŷ . Therefore, noting that k = 2t + 2 and (3.8) is an instance of (1.6), we obtain the desired results from the two inequalities in (3.9) and abusing the notation ( f , A, x * , y * ) for ( f , Ã, x, ŷ).</p><p>For strongly convex case, we below generalize Theorem 2.2 to any first-order method given in (1.8). Theorem 3.2 (Lower complexity bound of general first-order methods for strongly convex case) Let 8 &lt; m ≤ n be positive integers, and μ and L A be positive numbers. For any positive integer t &lt; m 4 -1 and any deterministic first-order method M that is described in (1.8), there exists an instance of (1.6) such that f is μ-strongly convex, and A = L A . In addition, the instance has a unique primal-dual solution (x * , y * ), and</p><formula xml:id="formula_86">x(t) -x * 2 ≥ 5L 2 A y * 2 256μ 2 (2t + 5) 2 , (<label>3.10)</label></formula><p>where x(t) is the output by M.</p><p>The proof of Theorem 3.2 is similar to that of Theorem 3.1: one can use (3.6) together with Theorem 2.2. We omit the details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Proof of Proposition 3.1</head><p>This subsection is dedicated to the technical details on the proof of Proposition 3.1. On an instance P(θ ; H, A) defined in Definition 3.1, the first-order method M described in (1.8) can be written as Therefore, we conclude that for any x ∈ U K 2s-1 and y ∈ V J 2s-1 ,</p><formula xml:id="formula_87">Ũ H Ũx (3.15) = Φ U HUx (3.14) = U HUx, Ṽ Λ Ũx (3.15) = Ψ V ΛUx (3.14) = V ΛUx, Ũ Λ Ṽy = Φ U Λ Vy<label>(3.14)</label></formula><p>= U Λ Vy.</p><p>Hence, we complete the proof.</p><p>Proposition 3.2 Given m ≤ n and k &lt; m 2 , let Λ and c be the matrix and vector in (2.2), and let h ∈ K 0 , R X , R Y ∈ [0, +∞], and λ ≥ 0. Suppose that A and b are respectively a multiple of Λ and c and H ∈ S n + satisfying HK 2s-1 ⊆ K 2s for all s ≤ k 2 . Then for any 0 ≤ t ≤ k 2 -1 and any deterministic first-order method M described in (1.8), there exist orthogonal matrices U t ∈ R n×n and V t ∈ R m×m and a problem instance P(θ ; U t HU t , V t AU t ) with θ = (h, b, R X , R Y , λ) such that U t h = h, V t c = c, and in addition, when M is applied to solve the instance, the iterates {(x (i) , y (i) )} t i=0 satisfy</p><formula xml:id="formula_88">x (i) ∈ U t K 2t+1 , y (i) ∈ V t J 2t+1 , ∀ i = 0, . . . , t,</formula><p>where K 2t+1 and J 2t+1 are the Krylov subspaces defined in (2.7). Moreover, the output</p><formula xml:id="formula_89">x(t) ∈ U t K 2t+1 . Proof Note K 0 K 1 and J 0 J 1 from Lemma 2.2.</formula><p>Hence, by Lemma 3.1 there exist orthogonal matrices U 0 and V 0 such that U 0 x = x, ∀x ∈ K 0 , and U 0 x (0) ∈ K 1 V 0 y = y, ∀y ∈ J 0 , and V 0 y (0) ∈ J 1 .</p><p>Therefore, from the condition h ∈ K 0 and c ∈ J 0 by Lemma 2.2, we have U 0 h = h and V 0 c = c. Consequently, the results in the lemma hold for t = 0. Below we prove the results for any t &lt; k 2 -1 by induction. Assume that for some 1 ≤ s &lt; k 2 -1, the results hold for t = s -1, namely, there exist orthogonal matrices U s-1 ∈ R n×n and V s-1 ∈ R m×m such that U s-1 h = h, V c = c, and when M is applied to the instance P(θ ; U s-1 HU s-1 , V s-1 AU s-1 ), the iterates {(x (i) , y (i) )} s-1 i=0 satisfy</p><formula xml:id="formula_90">x (i) ∈ U s-1 K 2s-1 , and y (i) ∈ V s-1 J 2s-1 , ∀i = 0, . . . , s -1. (3.16)</formula><p>Suppose the next inquiry point generated by M is (x (s) , y (s) ). Since s &lt; k 2 -1, it holds that 2s &lt; k, and from (2.19) we have</p><formula xml:id="formula_91">U s-1 K 2s-1 U s-1 K 2s U s-1 K 2s+1 and V s-1 J 2s-1 V s-1 J 2s V s-1 J 2s+1 . By Lemma 3.1, there exist orthogonal matrices Φ ∈ R n×n and Ψ ∈ R m×m such that Φx = x, ∀x ∈ U s-1 K 2s , and Φx (s) ∈ U s-1 K 2s+1 , Ψ y = y, ∀y ∈ V s-1 J 2s , and Ψ y (s) ∈ V s-1 J 2s+1 .</formula><p>(3.17)</p><p>Since c ∈ J 2s and V s-1 c = c, we have c ∈ V s-1 J 2s , and thus it follows from (3.17</p><formula xml:id="formula_92">) that Ψ c = c. Let U s = U s-1 Φ and V s = V s-1 Ψ .</formula><p>Clearly, both U s and V s are orthogonal matrices, and because V s-1 c = c and Ψ c = c, we have V s c = c. By a similar argument we also have U s h = h. In addition, from (3.17), Lemma 3.2, and the assumptions on H and A, it follows that for any</p><formula xml:id="formula_93">x ∈ U s-1 K 2s-1 and y ∈ V s-1 J 2s-1 , U s HU s x = U s-1 HU s-1 x, V s AU s x = V s-1 AU s-1 x, and U s A V s y = U s-1 A V s-1 y.<label>(3.18)</label></formula><p>Therefore, from the induction hypothesis (3.16) and the equations in (3.18), we conclude that the first s + 1 iterates obtained from M applied to P(θ ; U s HU s , V s AU s ) are exactly the same as the first s + 1 iterates obtained from M applied to P(θ ; U s-1 HU s-1 , V s-1 AU s-1 ), because exactly the same information is used to generate those iterates (cf. <ref type="bibr">(3.11)</ref>). Consequently, when M is applied to P(θ ; U s HU s , V s AU s ), the first s + 1 iterates are (x (i) , y (i) ), i = 0, 1, . . . , s. Hence, from (2.19), <ref type="bibr">(3.16</ref>) and (3.17), and also the facts U s = U s-1 Φ and V s = V s-1 Ψ , we have</p><formula xml:id="formula_94">x (i) ∈ U s K 2s+1 , y (i) ∈ V s J 2s+1 , ∀i = 0, . . . , s.</formula><p>This finishes the induction. Recalling that in the discussion below (1.8) we have assumed that the output by M coincides with the last inquiry point, we have x(t) = x (t) ∈ U t K 2t+1 , and hence complete the proof. Using Proposition 3.2, we are now ready to prove Proposition 3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof (of Proposition 3.1)</head><p>Note that for the original instance P(θ ; H, A) in Proposition 3.1, its data H, A, b and h satisfy the conditions in Proposition 3.2. Hence, we apply Proposition 3.2 to obtain a rotated instance P(θ ; U HU, V AU), where U and V are orthogonal matrices such that Uh = h and Vb = b, and we have used the fact that b is a multiple of c.</p><p>Let Ã = AU, φ and f denote the functions in the original instance P(θ ; H, A), and φ and f denote those in the rotated instance P(θ ; U HU, V AU). Then it is straightforward to observe the relations f (x) = f (Ux), and φ(x) = φ(Ux).</p><p>(</p><p>By the optimality conditions (e.g., <ref type="bibr" target="#b29">[29]</ref>) of the original instance and the rotated instance, it is also easy to show that the pair (x * , y * ) is a saddle point to the original instance if and only if (x, ŷ) = (U x * , V y * ) is a saddle point to the rotated instance, and that φ * = φ * . It remains to prove the inequalities from (3.3) through <ref type="bibr">(3.6)</ref>. By Proposition 3.2, when M is applied to the rotated instance, the approximate solution x(t) ∈ U K 2t+1 , which indicates Ux (t) ∈ K 2t+1 by the orthogonality of U. Since t ≤ k 2 -1, we have 2t + 1 ≤ k -1, and thus from <ref type="bibr">(2.19)</ref>, it follows that Ux (t) </p><formula xml:id="formula_96">∈ K 2t+1 ⊆ K k-1 .</formula><p>Therefore, from the facts Ã = V AU, Uh = h and Vb = b, and the relations in <ref type="bibr">(3.19)</ref>, we have</p><formula xml:id="formula_97">φ(x (t) ) -φ * = φ(Ux (t) ) -φ * ≥ min x∈K k-1 φ(x) -φ * , f (x (t) ) -f (x) = f (Ux (t) ) -f (Ux) ≥ min x∈K k-1 f (x) -f (x * ), Ãx (t) -b = A(Ux (t) ) -b ≥ min x∈K k-1 Ax -b , x(t) -x 2 = Ux (t) -x * 2 ≥ min x∈K k-1 x -x * 2 ,</formula><p>which complete the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Lower complexity bounds on bilinear saddle-point problems</head><p>In this section, we derive lower complexity bounds of first-order methods on solving the bilinear saddle-point problem (1.1) through considering its associated primal problem <ref type="bibr">(1.3</ref>). As we mentioned in the beginning, the affinely constrained problem (1.6) is a special case of (1.3) if Y = R m and g = 0. Hence, the results obtained in previous sections also apply to (1.3), namely, our designed instances of (1.6) are also "hard" instances of (1.3). However, they will not be the instance of (1.3) if we require Y to be a compact set. On solving (1.1) with both X and Y being compact, <ref type="bibr" target="#b35">[35]</ref> gives a first-order method that can be described as <ref type="bibr">(1.8)</ref>, and it proves</p><formula xml:id="formula_98">0 ≤ φ(x (t) ) -ψ(ȳ (t) ) ≤ 4L f D 2 X (t + 1) 2 + 4D X D Y A t + 1 , (<label>4.1)</label></formula><p>where D X and D Y are the diameters <ref type="foot" target="#foot_2">3</ref> of X and Y respectively. It is an open question if the convergence rate in (4.1) can still be improved. Under the Euclidean setting, a lower bound for the special case f = 0 has been shown in <ref type="bibr" target="#b29">[29]</ref>. We give instances below to show a lower complexity bound under the Euclidean setting but with L f &gt; 0. The bound is in the same form as that in (4.1) and differs only at the constants, and thus the convergence rate result in <ref type="bibr" target="#b35">[35]</ref> is optimal under the Euclidean setting. The ingredients in the designed "hard" SPP instances are the same as those used in Sect. 2. Let m ≤ n and k &lt; m 2 be positive integers, and let L f &gt; 0 and L A &gt; 0. We consider the instance P (h, b, R X , R Y , λ); H, A with (H, h, A, b) given in <ref type="bibr">(2.24)</ref>, and</p><formula xml:id="formula_99">R X = (2k + 1) √ k, R Y = L f 2L A √ 2k, λ = L A √ k 4 . (4.2)</formula><p>Clearly the above problem is a special instance of (1.3). In the following lemma, we give a lower bound of its optimal objective value. 4 k. By the optimality condition (e.g., <ref type="bibr" target="#b29">[29]</ref>), x * ∈ R n is an optimal solution to (4.4) if x * ∈ X , and there exists y * ∈ Y such that</p><formula xml:id="formula_100">∇ f (x * ) + A y * , x * -x ≤ 0, b -Ax * , y * -y ≤ 0, ∀ x ∈ X , y ∈ Y . (4.5)</formula><p>Let x * and y * be the vectors given in <ref type="bibr">(2.25)</ref>. Note from the proof of Lemma 2.5, it holds that ∇ f (x * ) = Hx *h = A y * and Ax *b = 0. Hence, (x * , -y * ) satisfies the optimality condition in (4.5). In addition, from (2.32) and (2.27), it follows that x * ≤ R X and y * ≤ R Y . Therefore, x * is an optimal solution, and it is straightforward to compute l * = f (x * ) = -3L f 4 k. This completes the proof. In the following lemma, we compute the minimum value of φ(x) over K k-1 . Then </p><formula xml:id="formula_101">min x∈K k-1 -φ * ≥ L R 2 X 4(2k + 1) 2 + L A R X R Y 4(2k + 1) . (<label>4</label></formula><formula xml:id="formula_102">0 i f Ax -b ≤ λ, R Y ( Ax -b -λ) if Ax -b &gt; λ.</formula><p>For any x ∈ K k-1 , we have from (2.33) and ( <ref type="formula" target="#formula_98">4</ref></p><formula xml:id="formula_103">.2) that Ax -b -λ ≥ L A √ k 4</formula><p>&gt; 0, and thus</p><formula xml:id="formula_104">φ(x) = f (x) + R Y ( Ax -b -λ) ≥ f (x) + L A R Y √ k 4 (4.2) = f (x) + L A R X R Y 4(2k + 1) . (4.7)</formula><p>In addition, note that f (x) here is exactly the same as that discussed in Lemma 2.6. Thus by <ref type="bibr">(2.35)</ref>, we have that for any</p><formula xml:id="formula_105">x ∈ K k-1 , f (x) ≥ - L f 2 k. (<label>4.8)</label></formula><p>Applying (4.8) to (4.7), and noting the bound of φ * in Lemma 4.1, we have for any</p><formula xml:id="formula_106">x ∈ K k-1 that φ(x) -φ * ≥ L f 4 k + L A R X R Y 4(2k + 1) (4.2) = L f R 2 X 4(2k + 1) 2 + L A R X R Y 4(2k + 1) ,</formula><p>which implies the desired result in (4.6).</p><p>Using Proposition 3.1 and Lemma 4.2, we are able to show a lower complexity bound of deterministic first-order methods on (1.1) as summarized in the following theorem.</p><p>Theorem 4.1 (Lower complexity bound for SPPs) Let 8 &lt; m ≤ n and t &lt; m 4 -1 be positive integers, L f &gt; 0, and L A &gt; 0. Then for any deterministic first-order method M described in (1.8) on solving (1.1), there exists a problem instance of (1.1) such that f is L f -smooth, A = L A , and X and Y are Euclidean balls with radii R X and R Y respectively. In addition,</p><formula xml:id="formula_107">φ(x (t) ) -ψ(ȳ (t) ) ≥ L f R 2 X 4(4t + 5) 2 + L A R X R Y 4(4t + 5) , (<label>4.9)</label></formula><p>where φ and ψ are the associated primal and dual objective functions, and (x (t) , ȳ(t) ) is the approximate solution output by M.</p><p>Proof Set k = 2t + &lt; m 2 and consider the problem instance P(θ H, A) described in Lemma 4.2. Note that the data (H, h, A, b, R X , R Y , λ) satisfies the conditions required by Proposition 3.1. Hence, there is a rotated instance P(θ ; H, Ã), and from (3.3) and Lemma 4.2, it follows that We finish this section by showing a lower complexity bound for SPPs when the function f (x) in (1.1) is strongly convex. Theorem 4.2 (Lower complexity bound for SPPs with strong convexity) Let 8 &lt; m ≤ n and t &lt; m 4 -1 be positive integers, and μ and L A be positive numbers. Then for any deterministic first-order method M described in (1.8), there exists a problem instance of (1.1) such that f is μ-strongly convex, A = L A , X and Y are Euclidean balls with radii R X and R Y respectively, and the associated primal problem (1.3) has a unique optimal solution x * ∈ X . In addition,</p><formula xml:id="formula_108">φ(x (t) ) -φ * ≥ min x∈K k-1 φ(x) -φ * ≥ L f R 2 X 4(4t + 5) 2 + L A R X R Y 4(4t + 5) , (<label>4</label></formula><formula xml:id="formula_109">x(t) -x * 2 ≥ 5L 2 A R 2 Y 256μ 2 (4t + 5) 2 (4.11) and φ(x (t) ) -ψ(ȳ (t) ) ≥ 5L 2 A R 2 Y 512μ(4t + 5) 2 , (<label>4.12)</label></formula><p>where φ and ψ are the associated primal and dual objective functions, and (x (t) , ȳ(t) ) is the output by M.</p><p>Proof Set k = 2t + 2 &lt; m 2 and consider the problem instance of (1.1), where f (x) = μ 2 x 2 , A and b are those in (2.20), g ≡ 0, and</p><formula xml:id="formula_110">X = x ∈ R n | x 2 ≤ R 2 X := k(2k + 1) 2 , Y = y ∈ R m | y 2 ≤ R 2 Y := 128μ 2 15L 2 A k(k + 1) 3 (2k + 1) . (4.13)</formula><p>From the proof of Theorem 2.2, it is easy to verify x * in (2.25) and y * in (2.37) satisfy x * ∈ , y * ∈ Y , and the optimality condition in (4.5) holds for (x * , -y * ).</p><p>Since f is strongly convex, x * must be the unique optimal solution to the instance. From (2.38) and also the definitions of X and Y in (4.13), it follows that min Let φ and ψ be the primal and dual objective functions of the rotated instance. By the strong convexity and the optimality of x, we have</p><formula xml:id="formula_111">x∈K k-1 x -x * 2 ≥ 5L 2 A R 2 Y 256μ 2 (2k + 1) 2 . (<label>4</label></formula><formula xml:id="formula_112">φ(x (t) ) -φ * ≥ μ 2 x(t) -x 2 .</formula><p>Together with (4.11) and the fact ψ(ȳ (t) ) ≤ ψ * ≤ φ * , the above inequality gives (4.12) by abusing the notation (φ, ψ, x * ) for ( φ, ψ, x). Therefore, we complete the proof.</p><p>Remark 4.2 In the proof of Theorem 4.2, we have g = 0 in the obtained rotated instance. Similar to Theorem 4.1, we can have an instance with a nonzero g and have a result similar to that in (4.12). Specifically, we consider P (0, b, R X , R Y , λ); μI, A , where λ = L A 6 √ k, and the tuple (A, b, R X , R Y ) is the same as that in the above proof. Let φ be the primal objective of the new instance. Then by the same arguments as those in the proof of Lemma 4.1, we can show φ * ≤ μ 2 x * 2 , where x * is given in (2.25). Furthermore, similar to (4.7), we can show that for any</p><formula xml:id="formula_113">x ∈ K k-1 , it holds φ(x) ≥ μ 2 x 2 + L A R Y √ k 3 ≥ L A R Y √ k 3 . Therefore, min x∈K k-1 φ(x) -φ * ≥ L A R Y √ k 3 -μ 2 x * 2</formula><p>. Now applying Proposition 3.1, we obtain a rotated instance P (0, b, R X , R Y , λ); μI, Ã with primal objective φ, and by (3.3), we have</p><formula xml:id="formula_114">φ(x (t) ) -φ * ≥ L A R Y √ k 3 - μ 2 x * 2 ≥ 4 √ 2 3 2 √ 15 - 1 2 μk (k + 1) 3 (2k + 1) = Ω L 2 A R 2 Y μk 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">On the tightness of the established lower complexity bounds</head><p>In this section, compare the established lower complexity bounds to the best known upper complexity bounds. It turns out that lower complexity bounds developed in this paper are tight in terms of the order, and thus they can be used to justify the optimality of first-order methods in the literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Upper complexity bounds of first-order methods on affinely constrained problems</head><p>The work <ref type="bibr" target="#b37">[37]</ref> proposes an accelerated linearized alternating direction method of multipliers (AL-ADMM). Applying to (1.6), i.e., setting one block to zero, we have from one convergence rate result in <ref type="bibr">[37, eqn. (2.34)</ref>] that</p><formula xml:id="formula_115">f (x (t) ) -f * ≤ 2L f D 2 X t(t + 1) + 2 A D X D Y t + 1 ,</formula><p>where D X and D Y are the diameters of the primal and dual feasible sets. If the size of the optimal primal and dual solutions is assumed, then the above result coincides with that in (3.7a) up to the difference of a constant multiple.</p><p>For the strongly convex case, the result in (3.10) indicates that given any ε &gt; 0, to have an iterate within √ ε-neighborhood of x * , the iterate number is at least</p><formula xml:id="formula_116">t = √ 5L A y * 32μ √ ε - 5 2 , (<label>5.1)</label></formula><p>where a denotes the smallest integer no less than a ∈ R. In [42, proof of Thm.4], it is shown that f (x (t) )f (x * ) + y * , Ax (t)b ≤ y * 2 2ρ 0 + ε 0 , (</p><p>where (x * , y * ) is a pair of primal-dual solution, and x (t) is the output of Nesterov's optimal first-order method applied to a penalized problem after t iterations. In addition, with ρ 0 = 2 y * 2 με and ε 0 = με 4 in (5.2), <ref type="bibr">[42, eqn.(49)</ref>] shows that the iteration number t satisfies:</p><formula xml:id="formula_118">t ≤ 2 L f μ + 2L A y * μ √ ε O(1) + log 1 ε . (5.3)</formula><p>From the strong convexity of f , it follows that f (x (t) )f (x * ) + y * , Ax (t)b ≥ μ 2 x (t)x * 2 , which together with (5.2) gives x (t)x * 2 ≤ ε. Hence, the dominant term in the upper bound <ref type="bibr">(5.3)</ref> is the same as that in (5.1) except for a logarithmic term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Upper complexity of first-order methods on saddle-point problems</head><p>For optimization in the form of (1.3), a smoothing technique is proposed in <ref type="bibr" target="#b35">[35]</ref>. It first approximates the nonsmooth objective function by a smooth one and then minimizes the smooth approximation function by an accelerated gradient method. In <ref type="bibr" target="#b35">[35]</ref>, it is shown that, if X and Y are compact with diameter D X and D Y respectively, and the total number of iterations is pre-specified to t, then the convergence rate of this smoothing scheme applied to (1.3) is given in (4.1). Comparing the upper bound in (4.1) and the lower bound in (4.9), we conclude that our lower complexity bound in Theorem 4.1 is tight in terms of the order, and that Nesterov's smooth scheme is an optimal method for computing approximate solutions to bilinear SPPs in the form of (1.1). Note that Theorem 4.1 also confirms the optimality of several follow-up works of <ref type="bibr" target="#b35">[35]</ref>. For example, when the algorithms in <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref> are applied to solve (1.3), their convergence rates all coincide with the lower bound in (4.9) up to a constant multiple, and hence these methods are all optimal first-order methods for solving problems in the form of (1.3).</p><p>In the literature, there have also been several results on either the saddle point or the variational inequality formulation of (1.3) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b27">[27]</ref><ref type="bibr" target="#b28">[28]</ref><ref type="bibr" target="#b29">[29]</ref>. When applied to solve (1.3) with f ≡ 0 (and hence L f ≤ L A ), those results all imply φ(x (t) </p><formula xml:id="formula_119">) -φ * = O L A D X D Y t ,</formula><p>where D X and D Y are the diameters of X and Y . The above result indicates the tightness of the lower bound in (4.9).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Concluding remarks</head><p>On finding solutions to bilinear saddle-point problems, we have established lower complexity bounds of first-order methods that acquire problem information through a first-order oracle and are described by a sequence of updating rules. Through designing "hard" instances of convex quadratic programming, we first show the lower complexity bound results under a linear span assumption on solving affinely constrained problems.</p><p>Then by a rotation invariance technique, we extend the results to general first-order methods that are still applied to affinely constrained problems. Finally, we establish the results for general first-order methods on solving bilinear saddle-point problems with compact primal and dual feasible regions. The established lower complexity bounds have been compared to several existing upper bound results. The comparison implies the tightness of our bounds and optimality of a few first-order methods in the literature.</p><p>We conclude the paper with a few more remarks. First, note that for affinely constrained problems, the feasibility residual in none of our results depends on the objective; see (2.36b) and (3.7b) for example. This is reasonable because we can choose not to use the objective gradient though the oracle (1.7) provides such infor-mation. However, towards finding an optimal solution, the information must be used. All existing works <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b41">41]</ref>) on primal-dual first-order methods have objective-dependent quantity in their upper bounds on the feasibility error. One interesting question is how to derive a lower complexity bound of the feasibility residual that depends on the constraint itself and also the objective. To achieve that, we would need to enforce a minimum portion of objective information to be used in the solution update. Second, a few existing works <ref type="bibr" target="#b22">[22,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b25">25]</ref> have shown that if ∇ f is much more expensive than matrix-vector multiplication Ax and A y, it could be beneficial to skip computing ∇ f at the cost of more Ax and/or A y. This setting is different from what we have made. In (1.7), we assume that one inquiry of the first-order oracle will obtain gradient and matrix-vector multiplications simultaneously. In the future work, we will allow multiple oracles that can return separate pieces of information, and we will pursue the lower bound of each oracle inquiry to reach a solution with desired accuracy and also design optimal oracle-based algorithms. Thirdly, in all our established results, we do not pre-specify the size of X and Y but allow them to be determined in the designed instances. That is the key reason why we obtain a lower complexity bound that looks greater than existing upper bound, e.g., by comparing (4.1) and (4.9). It is interesting to design "hard" instances to establish similar lower complexity bound results, provided that L f , L A and the diameters of X , Y are all given. We leave this to the future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>, y) := f (x) + Axb, yg(y).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>φ</head><label></label><figDesc>* := min x∈X φ(x) := f (x) + max y∈Y Axb, yg(y) , (1.3) and the other is the dual problem ψ * := max y∈Y ψ(y) := -g(y) + min x∈X Axb, y + f (x) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>( 1 . 1 )</head><label>11</label><figDesc>has a saddle point (x * , y * ), namely,L(x * , y) ≤ L(x * , y * ) ≤ L(x, y * ), ∀ x ∈ X , ∀y ∈ Y . (1.5)Many applications can be formulated into an SPP. For instance, it includes as special cases all affinely constrained smooth convex optimization problems. To see this, let Y = R m and g ≡ 0. Then max y Axb, y = 0 if Ax = b and ∞ otherwise, and thus (1.3) becomes f * := min x∈X f (x), s.t. Ax = b .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>∀t ≤ k and then estimate the values min x∈K k- 1 f</head><label>1</label><figDesc>(x)f * , and min x∈K k-1 Axb .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Because</head><label></label><figDesc>Φ and Ψ are orthogonal matrix, the above equations indicate that Φ U HUx = U HUx, Ψ V ΛUx = V ΛUx, and Φ U Λ Vy = U Λ Vy. (3.14) Moreover, since x ∈ U K 2s-1 and y ∈ V J 2s-1 , it follows from (2.19) that x ∈ U K 2s and y ∈ V J 2s , and thus using (3.13) again and also the definition of Ũ and Ṽ, we have Ũx = UΦx = Ux, and Ṽy = VΨ y = Vy. (3.15)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Lemma 4 . 1 Proof</head><label>41</label><figDesc>Let m ≤ n and k &lt; m 2 be positive integers, and let L f &gt; 0 and L A &gt; 0. Set (H, h, A, b) as those in (2.24) with R X , R Y , and λ as in (4.2). Then the optimal objective value of the instance P(θ ; H, A) defined in Definition 3.1 satisfies φ Since λ y ≥ 0, we have φ * ≤ l * := min x∈X f (x) + max y∈Y Axb, y , (4.4) where f , X , and Y are defined in (3.1), and thus to prove (4.3), it suffices to show l * = -3L f</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Lemma 4 . 2 2 x</head><label>422</label><figDesc>Let m ≤ n and k &lt; m 2 be positive integers, and let L f &gt; 0 and L A &gt; 0. Set (H, h, A, b) as those in (2.24) with R X , R Y , and λ as in (4.2). Consider the instance P(θ ; H, A) defined in Definition 3.1, i.e., φ * := min x ≤R X φ(x) := 1 Hxh x + max y ≤R Y Axb, y -λ y .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>. 6 )</head><label>6</label><figDesc>Proof Let f , X , and Y be defined in (3.1). Observing Axb, y ≤ Axb • y , we have max y∈Y Axb, y -λ y =</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>. 14 )</head><label>14</label><figDesc>Note that the above instance can be represented as P (0, b, R X , R Y , 0); μI, A by Definition 3.1, and the data in the instance satisfy all the conditions in Proposition 3.1. Hence, we can obtain a rotated instance P (0, b, R X , R Y , 0); μI, Ã , and it has a unique optimal solution x ∈ X . Now use(3.6) and (4.14) to obtain (4.11) by recalling k = 2t + 2 and abusing x * for x.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Lower and upper complexity bounds of first-order methods for different problem classes on producing an</figDesc><table><row><cell>ε-solution</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>2k , e 2,2k , . . . , e i,2k }, R i = span{e 2k-i,2k , e 2k-i+1,2k , . . . , e 2k,2k }, Proof From the definition of B in (2.3), we have B1 2k = e 2k,2k , Be 2k,2k = e 1,2k , Be i,2k = e 2k-i+1,2ke 2k-i,2k , ∀i = 1, . . . , 2k -1.</figDesc><table><row><cell>(2.11)</cell></row><row><cell>Hence, from (2.8) and (2.11), it holds that</cell></row><row><cell>(2.9)</cell></row></table><note><p><p><p>and</p>BR i = span{e 1,2k , e 2,2k , . . . , e i+1,2k } ⊆ F i+1 , (2.10)</p>where we have used the convention e 0,2k = 0.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>we conclude (2.36a) from the above relation, and (2.36b) from (2.30b). ≥ L A , we can remove such a dependence. In particular, setting h =</figDesc><table><row><cell cols="3">Remark 2.1 The norm y  *  in (2.27) depends on the ratio tion L f L f 4 + L A 4 √ 2 e 2k,n in (2.24), we can obtain that</cell><cell>L f L A . With the assump-</cell></row><row><cell>y  *  =</cell><cell>√ k 2</cell><cell>, and min</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>.10)    where φ and φ are respectively the primal objective functions of the original instance P(θ ; H, A) and the rotated instance P(θ ; H, Ã). Let ψ be the dual objective function of the rotated instance. Then since ȳ(t) ∈ Y , it holds ψ(ȳ (t) ) ≤ ψ * ≤ φ * , where the second inequality follows from the weak duality. Therefore we have the desired result from (4.10) and by abusing the notation (φ, ψ) for ( φ, ψ). The lower bound in (4.9) has exactly the same form as the upper bound in (4.1), and they differ only on the constants. Hence, the order of the convergence rate result in (4.1) is not improvable under the Euclidean setting, and one can only improve that result by possibly decreasing the constants.</figDesc><table><row><cell>Remark 4.1</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>By "optimal", we mean that the convergence rate cannot be further improved for the considered problem class.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>f is Lipschitz continuous on a set X if there is a constant L such that | f (x 1 )f (x 2 )| ≤ L x 1x 2 for any x 1 , x 2 ∈ X .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>In fact, more general results are established in<ref type="bibr" target="#b35">[35]</ref>. It adopts general norm (that is not necessary Euclidean norm) and general prox-functions to define A , D X and D Y .</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Ouyang's research is partly supported by NSF grant DMS-1913006 and ONR award N00014-19-1-2295, and Xu's research is partly supported by NSF grant DMS-1719549.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>x (t+1) , y (t+1) , x(t+1) , ȳ(t+1) = I t θ ; Hx (0) , Ax (0) , A y (0) , . . . , Hx (t) , Ax (t) , A y (t) , ∀ t ≥ 0.</p><p>(3.11)</p><p>We start our proof with several technical lemmas. The following lemma is an elementary result of linear subspaces and will be used several times in our analysis. Lemma 3.1 Let X X ⊆ R p be two linear subspaces. Then for any x ∈ R p , there exists an orthogonal matrix V ∈ R p× p such that Vx = x, ∀x ∈ X , and Vx ∈ X .</p><p>(3.12)</p><p>Proof If x ∈ X , then we can simply choose V = I. Otherwise, we decompose x = y + z, where z ∈ X and y = 0 is in the complement subspace X ⊥ . Let s = dim(X ) and t = dim( X ) &gt; s. Assume u 1 , . . . , u s to be an orthonormal basis of X . We extend it to u 1 , . . . , u t , an orthonormal basis of X . The desired result in (3.12) is then obtained by choosing V as an orthogonal matrix such that Vu i = u i , ∀ i = 1, . . . , s, and Vy = y u s+1 .</p><p>By Lemma 3.1, we show the results below. Proof Let x ∈ U K 2s-1 and y ∈ V J 2s-1 . Since U and V are orthogonal, it holds that Ux ∈ K 2s-1 and Vy ∈ J 2s-1 . Hence, from the assumption on H, the properties of J i and K i in (2.18) and (2.19), and noting 2s -1 ≤ k -1, we have Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Affiliations</head><p>Yuyuan Ouyang  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Dimension-free iteration complexity of finite sum optimization problems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Arjevani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Shamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3540" to="3548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On the iteration complexity of oblivious first-order optimization algorithms</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Arjevani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Shamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="908" to="916" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A fast iterative shrinkage-thresholding algorithm for linear inverse problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Teboulle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Imaging Sci</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="183" to="202" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Lower bounds for finding stationary points I</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Carmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Hinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sidford</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.11606</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Carmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Hinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sidford</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.00841</idno>
		<title level="m">Lower bounds for finding stationary points II: Firstorder methods</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A first-order primal-dual algorithm for convex problems with applications to imaging</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chambolle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Imaging Vis</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="120" to="145" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Optimal primal-dual methods for a class of saddle point problems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ouyang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1779" to="1814" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Accelerated schemes for a class of variational inequalities</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ouyang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="113" to="149" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A primal-dual splitting method for convex optimization involving lipschitzian, proximable and linear composite terms</title>
		<author>
			<persName><forename type="first">L</forename><surname>Condat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optim. Theory Appl</title>
		<imprint>
			<biblScope unit="volume">158</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="460" to="479" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">First-order methods of smooth convex optimization with inexact oracle</title>
		<author>
			<persName><forename type="first">O</forename><surname>Devolder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Glineur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="37" to="75" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A general framework for a class of first order primal-dual algorithms for convex optimization in imaging science</title>
		<author>
			<persName><forename type="first">E</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Imaging Sci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1015" to="1046" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Randomized primal-dual proximal block coordinate updates</title>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Oper. Res. Soc. China</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="205" to="250" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">First-order algorithms for convex optimization with nonseparable objective and coupled constraints</title>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Oper. Res. Soc. China</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="131" to="159" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName><surname>O'donoghue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Setzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Baraniuk</surname></persName>
		</author>
		<title level="m">Fast alternating direction methods</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Imaging Sci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1588" to="1623" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On lower complexity bounds for large-scale smooth convex optimization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nemirovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Complexity</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">A primal-dual algorithm for general convex-concave saddle point problems</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Y</forename><surname>Hamedani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Aybat</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.01401</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On the O(1/n) convergence rate of the douglas-rachford alternating direction method</title>
		<author>
			<persName><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Numer. Anal</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="700" to="709" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An accelerated hpe-type algorithm for a class of composite convex-concave saddle-point problems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Monteiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="56" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Revisiting frank-wolfe: Projection-free sparse convex optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="427" to="435" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deterministic and stochastic primal-dual subgradient algorithms for uniformly convex minimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Juditsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stoch. Syst</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="80" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">The complexity of large-scale convex programming under a linear optimization oracle</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1309.5550</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Gradient sliding for composite optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">159</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="201" to="235" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Accelerated gradient sliding for structured convex optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ouyang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.04905</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Iteration-complexity of first-order augmented lagrangian methods for convex programming</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Renato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Monteiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">155</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="511" to="547" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Conditional gradient sliding for convex optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1379" to="1409" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">An optimal randomized incremental gradient method</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">171</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="167" to="215" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Complexity of variants of Tseng&apos;s modified F-B splitting and Korpelevich&apos;s methods for hemivariational inequalities with applications to saddle-point and convex optimization problems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Monteiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">F</forename><surname>Svaiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1688" to="1720" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Iteration-complexity of block-decomposition algorithms and the alternating direction method of multipliers</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Monteiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">F</forename><surname>Svaiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="475" to="507" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Prox-method with rate of convergence O(1/t) for variational inequalities with Lipschitz continuous monotone operators and smooth convex-concave saddle point problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nemirovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="229" to="251" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Robust stochastic approximation approach to stochastic programming</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nemirovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Juditsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1574" to="1609" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Problem Complexity and Method Efficiency in Optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nemirovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yudin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wiley-Interscience Series in Discrete Mathematics</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Information-based complexity of linear operator equations</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Nemirovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Complexity</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="153" to="175" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">On optimality of krylov&apos;s information when solving linear operator equations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nemirovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Complexity</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="121" to="130" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Introductory Lectures on Convex Optimization: A Basic Course</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Kluwer Academic Publisher</publisher>
			<pubPlace>Dordrecht</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Smooth minimization of non-smooth functions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="127" to="152" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Gradient methods for minimizing composite functions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="125" to="161" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">An accelerated linearized alternating direction method of multipliers</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pasiliao</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Imaging Sci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="644" to="681" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Rockafellar</surname></persName>
		</author>
		<title level="m">Convex Analysis</title>
		<meeting><address><addrLine>Princeton</addrLine></address></meeting>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">On the randomized complexity of minimizing a convex quadratic function</title>
		<author>
			<persName><forename type="first">M</forename><surname>Simchowitz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.09386</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Tight complexity bounds for optimizing composite objectives</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Woodworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3639" to="3647" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Accelerated first-order primal-dual proximal methods for linearly constrained composite convex programming</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1459" to="1484" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Iteration complexity of inexact augmented lagrangian methods for constrained convex programming</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05812</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Accelerated primal-dual proximal coordinate updating methods for constrained convex optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optim. Appl</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="128" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A new primal-dual algorithm for minimizing the sum of three functions with a linear operator</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1698" to="1717" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
