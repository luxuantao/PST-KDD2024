<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TOWARDS DEEP NEURAL NETWORK ARCHITECTURES ROBUST TO ADVERSARIAL EXAMPLES</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2015-04-09">9 Apr 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Panasonic Silicon Valley Laboratory Panasonic R&amp;D Company of America</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Luca</forename><surname>Rigazio</surname></persName>
							<email>luca.rigazio@us.panasonic.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Panasonic Silicon Valley Laboratory Panasonic R&amp;D Company of America</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">TOWARDS DEEP NEURAL NETWORK ARCHITECTURES ROBUST TO ADVERSARIAL EXAMPLES</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2015-04-09">9 Apr 2015</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1412.5068v4[cs.LG]</idno>
					<note type="submission">Accepted as a workshop contribution at ICLR 2015</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T14:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent work has shown deep neural networks (DNNs) to be highly susceptible to well-designed, small perturbations at the input layer, or so-called adversarial examples. Taking images as an example, such distortions are often imperceptible, but can result in 100% mis-classification for a state of the art DNN. We study the structure of adversarial examples and explore network topology, pre-processing and training strategies to improve the robustness of DNNs. We perform various experiments to assess the removability of adversarial examples by corrupting with additional noise and pre-processing with denoising autoencoders (DAEs). We find that DAEs can remove substantial amounts of the adversarial noise. However, when stacking the DAE with the original DNN, the resulting network can again be attacked by new adversarial examples with even smaller distortion. As a solution, we propose Deep Contractive Network, a model with a new end-to-end training procedure that includes a smoothness penalty inspired by the contractive autoencoder (CAE). This increases the network robustness to adversarial examples, without a significant performance penalty.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Deep neural networks have recently led to significant improvement in countless areas of machine learning, from speech recognition to computer vision <ref type="bibr" target="#b9">Krizhevsky et al. (2012)</ref>; <ref type="bibr" target="#b3">Dahl et al. (2012)</ref>; <ref type="bibr" target="#b18">Taigman et al. (2013)</ref>; <ref type="bibr" target="#b21">Zhang et al. (2013)</ref>. DNNs achieve high performance because deep cascades of nonlinear units allow to generalize non-locally, in data-specific manifolds <ref type="bibr" target="#b1">Bengio (2009)</ref>. While this ability to automatically learn non-local generalization priors from data is a strength of DNNs, it also creates counter-intuitive properties. In particular <ref type="bibr" target="#b17">Szegedy et al. (2014b)</ref> showed in their seminal paper that one can engineer small perturbations to the input data, called adversarial examples, that make an otherwise high-performing DNN misclassify every example. For image datasets, such perturbations are often imperceptible to the human eye, thus creating potential vulnerabilities when deploying neural networks in real environments. As an example, one could envision situations where an attacker having knowledge of the DNN parameters could use adversarial examples to attack the system and make it fail consistently. Even worse, due to the cross-model, cross-dataset generalization properties of the adversarial examples <ref type="bibr" target="#b17">Szegedy et al. (2014b)</ref> , the attacker might generate adversarial examples from independent models without full knowledge of the system and still be able to conduct a highly successful attack. This indicates there is still a significant robustness gap between machine and human perception, despite recent results showing machine vision performance closing in on human performance <ref type="bibr" target="#b18">Taigman et al. (2013)</ref>. More formally, the challenge is: can we design and train a deep network that not only generalizes in abstract manifold space to achieve good recognition accuracy, but also retains local generalization in the input space?</p><p>A main result from <ref type="bibr" target="#b17">Szegedy et al. (2014b)</ref> is that the smoothness assumption that underlies many kernel methods such as Support Vector Machines (SVMs) does not hold for deep neural networks trained through backpropagation. This points to a possible inherent instability in all deterministic, feed-forward neural network architectures. In practice, SVMs can be used to replace the final softmax layer in classifier neural networks leading to better generalization <ref type="bibr" target="#b19">Tang (2013)</ref>, but applying SVM in the manifold space does not guarantee local generalization in the input space. Recently, <ref type="bibr" target="#b5">Duvenand et al. (2014)</ref> categorize distributions of deep neural networks through deep Gaussian Process (GP) and show that in stacked architectures, the capacity of the network captures fewer degrees of freedom as the layers increase. They propose to circumvent this by connecting inputs to every layer of the network. Without this trick, the input locality is hardly preserved in higher layers due to the complexity of nonlinear mapping cascades.</p><p>A framework leveraging both approaches is Random Recursive SVM (R 2 SVM) <ref type="bibr" target="#b20">Vinyals et al. (2012)</ref>, which recursively solves a SVM whose input combines input data and outputs from the previous SVM layer, randomly projected to the same dimension as the input data. R 2 SVM avoids solving nonconvex optimization by recursively solving a SVM and demonstrates generalization on small datasets. However, performance is suboptimal compared to state-of-the-art DNNs, possibly due to lack of end-to-end training <ref type="bibr" target="#b20">Vinyals et al. (2012)</ref>; <ref type="bibr" target="#b19">Tang (2013)</ref>. Another work inspired by the recursive nature of the human perceptual system is Deep Attention Selective Network (das-Net) <ref type="bibr" target="#b15">Stollenga et al. (2014)</ref>, which dynamically fine-tunes the weight of each convolutional filter at recognition time. We speculate that the robustness of human perception is due to complex hierarchies and recursions in the wirings of the human brain <ref type="bibr" target="#b6">Felleman &amp; Van Essen (1991)</ref>; <ref type="bibr" target="#b4">Douglas et al. (1995)</ref>, since recursions provide multiple paths to input data and could retain locality information at multiple levels of representation. Such an intuition is also partially supported by the recent state-ofthe-art models for object classification and detection involving multi-scale processing <ref type="bibr" target="#b16">Szegedy et al. (2014a)</ref>. Since modeling such recursions in DNNs is notoriously hard and often relies on additional techniques such as reinforcement learning <ref type="bibr" target="#b15">Stollenga et al. (2014)</ref>; <ref type="bibr" target="#b12">Mnih et al. (2014)</ref>, we will at first investigate explicit inclusion of input generalization as an additional objective for the standard DNN training process.</p><p>It is important to note that the adversarial examples are universal and unavoidable by their definition: one could always engineer an additive noise at input to make the model misclassify an example, and it is also a problem in shallow models such as logistic regression <ref type="bibr" target="#b17">Szegedy et al. (2014b)</ref>. The question is how much noise is needed to make the model misclassify an otherwise correct example. Thus, solving the adversarial examples problem is equivalent to increasing the noticeability of the smallest adversarial noise for each example.</p><p>In this paper we investigate new training procedures such that the adversarial examples generated based on <ref type="bibr" target="#b17">Szegedy et al. (2014b)</ref> have higher distortion, where distortion is measured by</p><formula xml:id="formula_0">1 n (x ′ i − x i ) 2</formula><p>where x ′ , x ∈ R n are the adversarial data and original data respectively. First, we investigate the structure of the adversarial examples, and show that contrary to their small distortion it is difficult to recover classification performance through additional perturbations, such as Gaussian additive noises and Gaussian blur. This suggests the size of "blind-spots" are in fact relatively large, in input space volume, and locally continuous. We also show that adversarial examples are quite similar <ref type="bibr" target="#b17">Szegedy et al. (2014b)</ref>, and an autoencoder (AE) trained to denoise adversarial examples from one network generalizes well to denoise adversarials generated from different architectures. However, we also found that the AE and the classifier DNN can be stacked and the resulting network can again be attacked by creating new, adversarial examples of even smaller distortion. Because of this, we conclude that ideal architectures should be trained end-to-end and incorporate input invariance with respect to the final network output. We find that ideas from denoising autoencoder (DAE), contractive autoencoder (CAE), and most recently marginalized denoising autoencoder (mDAE) provide strong framework for training neural networks that are robust against adversarial noises <ref type="bibr" target="#b14">Rifai et al. (2011b)</ref>; <ref type="bibr" target="#b0">Alain &amp; Bengio (2012)</ref>; <ref type="bibr" target="#b2">Chen et al. (2014)</ref>. We propose Deep Contractive Networks (DCNs), which incorporate a layer-wise contractive penalty, and show that adversarials generated from such networks have significantly higher distortion. We believe our initial results could serve as the basis for training more robust neural networks that can only be misdirected by a substantial noise, in a way that is more attuned to how human perception performs. </p><formula xml:id="formula_1">x + r ∈ [0, 1] m : min r c|r| 2 + L(x + r, l)<label>(1)</label></formula><p>Instead of finding the minimum c through line-search per example, we use constant c during evaluation of a given dataset and model architecture. We find c such that for a sufficiently large subset of data of size n,</p><formula xml:id="formula_2">n−1 i=0</formula><p>r i 2 is minimized, subject to the constraint that the mean prediction error rate of f (x i + r i ) is greater than e. e is chosen as 99% throughout the experiments. Since we are interested in macro-scale evaluation of adversarial examples per dataset and model, we find this setting sufficiently simplifies and speeds up the procedure while allowing quantitative analysis of the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">DATASETS AND MODEL ARCHITECTURES</head><p>We perform our experiements on the MNIST dataset, using a number of architectures LeCun &amp; Cortes (1998); <ref type="bibr" target="#b8">Krizhevsky &amp; Hinton (2009)</ref>. Table <ref type="table" target="#tab_0">1</ref> summarizes experimental settings, baseline error rate, adversarial examples' error rate and average adversarial distortion. L 2 weight decay is applied with λ = 10 −3 , except in convolutional layers. For MNIST ConvNet has two convolutional layers, one fully-connected layer, and one softmax layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RECOVERING FROM ADVERSARIAL EXAMPLES</head><p>In order to gain insight into the properties of adversarial noises, we explore three pre-processing methods aiming at recovering from adversarial noise, as presented in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">NOISE INJECTION</head><p>Given the tiny nature of adversarial noise, we investigate a recovery strategy based on additional corruptions, in the hope that we can move the input outside the network "blind-spots", which we initially assumed to be small and localized. We experiment with additive Gaussian noise and Gaussian blurring. For Gaussian noise we averaged predictions over 20 feed-forward runs to reduce the prediction variance. Results for Gaussian additive noises are summarized in Figure <ref type="figure" target="#fig_0">1</ref>. It shows the and the trade-off between the adversarial examples recovered and the clean examples misclassified as one varies the amount of additive noises, which are added to only input layer or the input plus all the hidden layers. Results for Gaussian blurring are summarized in Table <ref type="table">2</ref>. For Gaussian additive noises, "L1" refers to the noise applied at input layer; "L*" refers to the noise applied at input layer plus all hidden layers. Gaussian blurring is only applied at input layer.</p><p>The results show that convolution seems to help with recovering from the adversarial examples. For example, for ConvNet model, applying Gaussian blur kernel of size 11 to all input data can recover more than 50% of adversarial examples, at the expense of 3% increase in the test error on clean data (Table <ref type="table">2</ref>). In addition, for ConvNet model, adding Gaussian noise of σ = 0.1 at input layer plus hidden layers allow the model to recover more than 35% at similar small loss in model performance on clean data (Figure <ref type="figure" target="#fig_0">1</ref>). However, neither Gaussian additive noises or blurring is effective in removing enough noise such that its error on adversarial examples could match that of the error on clean data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">AUTOENCODER</head><p>To assess the structure of the adversarial noise, we trained a three-hidden-layer autoencoder ( While this is a very successful experiment, we found one drawback: the autoencoder and its corresponding classifier can be stacked to form a new feed-forward neural network, then adversarial examples can again generated from this stacked network. The last row in Table <ref type="table" target="#tab_2">3</ref> and Figure <ref type="figure" target="#fig_1">2</ref> show such stacked network adversarial examples to have a significantly smaller distortion than adversarial examples from the original classifier network, suggesting that while the autoencoder effectively recovers the from the weaknesses of the original classifier network, the stacked network is then even more susceptible to adversarial noises. One possible explanation is that since the autoencoder is trained without the knowledge of the classification objective, it has more "blind-spots" with re-  spect to that final objective. This again confirms the necessity of end-to-end training in deep neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">DENOISING AUTOENCODER</head><p>In this section, a standard denoising autoencoder (DAE) is trained, without the knowledge of the adversarial noise distribution. A DAE maps corrupted input data to clean input data. At each training batch, each pixel in the input data is corrupted by adding independent Gaussian noise with 0 mean and σ standard deviation. Table <ref type="table" target="#tab_3">4</ref> summarizes the results indicating that a standard denoising autoencoder can still recover a significant portion of the adversarial noises. In particular, a denoising auto-encoder with σ = 0.1 Gaussian noise could denoise adversarial examples almost as well as an autoencoder trained on actual adversarials noises, as shown in Table <ref type="table" target="#tab_2">3</ref>. However, this model also suffers the same deficiency as in Section 3.2, that a stacked network is more susceptible to adversarials. In this case, this deficiency likely arises due to imperfect training of DAE itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">DISCUSSION</head><p>Our experiments have shown that the adversarial noise is fairly robust against local perturbations such as additive Gaussian noise, suggesting that the size of "blind-spots" is relatively large. In the image data case, the effect of adversarial examples can be significantly reduced by low-pass filtering, such as Gaussian blurring, suggesting that adversarial noise mostly resides in high-frequency domain. Moreover, the success of the autoencoder and the denoising autoencoder experiment shows adversarial noise to have simple structure that is easily exploitable.</p><p>A key observation about the adversarial examples is that they are unavoidable and intrinsic property of any feed-forward architecture. For any pre-processing, it is always possible to backpropagate the error signal through the additional functions and find new adversarial examples, not only for deterministic pre-processing steps such as Gaussian blurring and autoencoders. Surprisingly, our experiments show that the distortion of adversarials from stacked network is even lower than the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DEEP CONTRACTIVE NETWORK</head><p>In this section, we formulate Deep Contractive Network, which imposes a layer-wise contractive penalty in a feed-forward neural network. The layer-wise penalty approximately minimizes the network outputs variance with respect to perturbations in the inputs, enabling the trained model to achieve "flatness" around the training data points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">CONTRACTIVE AUTOENCODER</head><p>Contractive autoencoder (CAE) is a variant of an autoencoder (AE) with an additional penalty for minimizing the squared norm of the Jacobian of the hidden representation with respect to input data <ref type="bibr" target="#b14">Rifai et al. (2011b)</ref>. A standard AE consists of an encoder and a decoder. The encoder maps input data to the hidden representation, and the decoder attempts to reconstruct the input from the hidden representation. Formally, given input x ∈ R dx and hidden representation h ∈ R d h , the encoder parametrized by d h × d x matrix W e and bias vector b h ∈ R d h and the decoder parametrized by d x × d h matrix W d and bias vector b y ∈ R d h , the output y ∈ R dx is given by:</p><formula xml:id="formula_3">y = σ d (W d h + b y ) = σ d (W d σ e (W e x + b h ) + b y )<label>(2)</label></formula><p>where σ e and σ d are non-linear activation functions for the encoder and decoder respectively. Given m training data points, the AE is trained by finding the model parameters θ = {W e , W d , b h , b y } that minimize the following objective function:</p><formula xml:id="formula_4">J AE (θ) = m i=1 L(x (i) , y (i) )<label>(3)</label></formula><p>For CAE, the objective function has an additional term:</p><formula xml:id="formula_5">J CAE (θ) = m i=1 (L(x (i) , y (i) ) + λ ∂h (i) ∂x (i) 2 ) (4)</formula><p>λ is a scaling factor that trades off reconstruction objective with contractive objective. ∂h (i) ∂x (i) 2 is the Frobenius norm of the Jacobian matrix of h (i) with respect to x (i) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">DEEP CONTRACTIVE NETWORKS</head><p>A Deep Contractive Network (DCN) is a generalization of the contractive autoencoder (CAE) to a feed-forward neural network that outputs y ∈ R dy with a target t ∈ R dy . For a network with H hidden layers, let f i denote the function for computing hidden representation h i ∈ R d h i at hidden layer i: h i = f i (h i−1 ), i = 1...H + 1, h 0 = x and h H+1 = y. Ideally, the model should penalize the following objective: However, such a penalty is computationally expensive for calculating partial derivatives at each layer in the standard back-propagation framework. Therefore, a simplification is made by approximating the objective with the following:</p><formula xml:id="formula_6">J DCN (θ) = m i=1 (L(t (i) , y (i) ) + λ ∂y (i) ∂x (i) 2 ) (5)</formula><formula xml:id="formula_7">J DCN (θ) = m i=1 (L(t (i) , y (i) ) + H+1 j=1 λ j ∂h (i) j ∂h (i) j−1 2 )<label>(6)</label></formula><p>This layer-wise contractive penalty enables partial derivatives to be computed in the same way as in a contractive autoencoder, and is easily incorporated into the backpropagation procedure. This objective does not guarantee global optimality for the solution to Eq. 5, and also limits the capacity of the neural network. However, it is a computationally efficient way to greedily propagate input invariance through a deep network.</p><p>Note that for a neural network with additive Gaussian noise N (0, σ 2 I) added to input during the training, if we let σ → 0, the training objective is equivalent to Eq. 5 <ref type="bibr" target="#b0">Alain &amp; Bengio (2012)</ref>. However, such stochastic penalties require many passes of data to train the model effectively. For efficiency, we decided to employ a deterministic penalty instead <ref type="bibr" target="#b14">Rifai et al. (2011b)</ref>; <ref type="bibr" target="#b0">Alain &amp; Bengio (2012)</ref>; <ref type="bibr" target="#b2">Chen et al. (2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">EXPERIMENTS AND RESULTS</head><p>The experiments involve applying a contractive penalty to the models in Table <ref type="table" target="#tab_0">1</ref>. The models were trained until they achieved nearly the same accuracy as the original models which lacked a contractive penalty. The adversarial examples are generated following the method defined in Section 2.1.</p><p>Table <ref type="table" target="#tab_4">5</ref> shows that the contractive penalty successfully increases the minimum distortion of the adversarial noises.  A further study should be conducted to evaluate the performance loss due to layer-wise penalties as opposed to global contractive objectives as defined in Eq. 5. In addition, exploring non-Euclidean adversarial examples, e.g. small affine transformation on images, and varying contractivity at higher layers of the network could lead to insights into semantic attributes of features learned at high levels of representation. For example, explicitly learning instantiation parameters as previously attempted by models such as Transforming Autoencoder <ref type="bibr" target="#b7">Hinton et al. (2011)</ref>.</p><p>Our work also bridges supervised learning with unsupervised representation learning, by introducing the penalty from DAE and CAE to standard DNN. Such penalty not only acts as practical regularizers, but also is a highly efficient way to learn obvious information from the training data, such as local generalization in the input space. Recent progress in deep neural networks is driven by both end-to-end supervised training and various modes of unsupervised feature learning <ref type="bibr" target="#b9">Krizhevsky et al. (2012)</ref>; <ref type="bibr" target="#b1">Bengio (2009)</ref>, and thus we believe the merge of the two could likely enable new milestones in the field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSIONS</head><p>We tested several denoising architectures to reduce the effects of the adversarial examples, and conclude that while the simple and stable structure of adversarial examples makes them easy to remove with autoencoders, the resulting stacked network is even more sensitive to new adversarial examples. We conclude that neural network's sensitivity to adversarial examples is more related to intrinsic deficiencies in the training procedure and objective function than to model topology.</p><p>The crux of the problem is then to come up with an appropriate training procedure and objective function that can efficiently make the network learn flat, invariant regions around the training data.</p><p>We propose Deep Contractive Networks to explicitly learn invariant features at each layer and show some positive initial results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Noise Injection (Gaussian additive noise): Test error on clean data (Left) and on adversarial data (Right) vs. standard deviation of Gaussian additive noise</figDesc><graphic url="image-1.png" coords="4,108.24,81.99,193.88,146.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: 1st column is the original data. 2nd and 3rd are the adversarial examples and their noises for the original model. 4th and 5th are for the stacked model of AE + the original net.</figDesc><graphic url="image-3.png" coords="5,208.44,235.56,195.00,117.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: 1st column is the original data. 2nd and 3rd are the adversarials and noises for the original model. 4th and 5th are the adversarials and noises for the model trained with contractive penalty.</figDesc><graphic url="image-4.png" coords="8,209.04,81.84,193.80,117.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Model architectures, datasets, and baseline error-rates Model Name Dataset Description Train err. Test err. Adv. err. We follow the procedure outlined in Szegedy et al. (2014b) for generating adversarial examples from the classifier neural network, with a slight modification for computational efficiency. Using the same notation, we denote the classifier by f : R m −→ {1...k} and its associated continuous loss function by L : R</figDesc><table><row><cell>Av. distortion</cell></row></table><note>m × {1...k} −→ R + . Then, for a given image x ∈ R m , whose m pixels normalized to [0, 1], and target label l ∈ {1...k}, the minimal adversarial noise r is approximated by optimizing the following problem, given c &gt; 0 and subject to</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>784- 256-128-256-784 neurons)  on mapping adversarial examples back to the original data samples. An important detail is that we also train the model to map original training data back to itself, so that the autoencoder preserves the original data if the non-adversarial data samples are fed in; this allows us to stack several autoencoders. We train the autoencoder using adversarial examples from the training set only, and test generalization capabilities on adversarial examples from the test set across different model topologies. Table3shows generalization performance of autoencoders trained on adversarial examples from different models. Columns indicate whose adversarial data the autoencoder is trained on, rows indicate whose adversarial test data the autoencoder is used to denoise. Entries correspond to error rates when the outputs from the autoencoder is fed into the model identified by the row labels. We observe that autoencoders generalize very well on adversarial examples from different models. All autoencoders are able to recover at least 90% of adversarial errors, regardless of the model from which it originates.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Cross-model autoencoder generalization test. Error-rates on adversarial test data. Last two rows shows the error-rates on clean test data and the average minimal distortion of adversarial examples generated from stacked network, respectively. The error-rates on the adversarial test data without the autoencoder preprocessing is approximately 100% as shown in Table1.</figDesc><table><row><cell></cell><cell cols="4">N-100-100-10 N200-200-10 AE-400-10 ConvNet</cell></row><row><cell>N-100-100-10</cell><cell>2.3%</cell><cell>2.4%</cell><cell>2.3%</cell><cell>5.2%</cell></row><row><cell>N-200-200-10</cell><cell>2.3%</cell><cell>2.2%</cell><cell>2.2%</cell><cell>5.4%</cell></row><row><cell>AE400-10</cell><cell>3.6%</cell><cell>3.5%</cell><cell>2.7%</cell><cell>9.2%</cell></row><row><cell>ConvNet</cell><cell>7.7%</cell><cell>7.6%</cell><cell>8.3%</cell><cell>2.6%</cell></row><row><cell>Test error (clean)</cell><cell>2.1%</cell><cell>1.9%</cell><cell>2.1%</cell><cell>1.1%</cell></row><row><cell cols="2">Avg adv distortion 0.049</cell><cell>0.051</cell><cell>0.043</cell><cell>0.038</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Denoising autoencoder test. Error on the adversarial test data. from the original classifier network. Furthermore, Table4also hints that even a simple Gaussian additive noise, often used in data augmentation, effectively creates flat, invariant regions around the input data points. Based on these results and observations, we thus postulate that solving the adversarial problem should correspond to finding new training procedures and objective functions so as increase the distortion of the smallest adversarial examples. Therefore, in Section 4, we formulate a new model that could propagate the input invariance toward the final network outputs and be trained in end-to-end.</figDesc><table><row><cell cols="4">N-100-100-10 N200-200-10 AE-400-10 ConvNetM</cell></row><row><cell>DAE, σ = 0.1 5.0%</cell><cell>4.9%</cell><cell>11.5%</cell><cell>9.1%</cell></row><row><cell>DAE, σ = 0.5 10.0%</cell><cell>10.6%</cell><cell>16.3%</cell><cell>15.3%</cell></row><row><cell>distortion of adversarials</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>The error-rates on clean test data and the average distortion of adversarial examples generated from the original model (orig) and the same model with contractive penalty (DCN). The error-rates on the adversarial examples are 100%.</figDesc><table><row><cell cols="5">Model Name DCN error DCN adv. distortion orig. error orig. adv. distortion</cell></row><row><cell cols="2">N100-100-10 2.3%</cell><cell>0.107</cell><cell>1.8%</cell><cell>0.084</cell></row><row><cell cols="2">N200-200-10 2.0%</cell><cell>0.102</cell><cell>1.6%</cell><cell>0.087</cell></row><row><cell>AE400-10</cell><cell>2.0%</cell><cell>0.106</cell><cell>2.0%</cell><cell>0.098</cell></row><row><cell>ConvNet</cell><cell>1.2%</cell><cell>0.106</cell><cell>0.9%</cell><cell>0.095</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>The error-rates on clean test data and the average distortion on adversarial examples from N200-200-10 models with different training conditions. "GN" refers to Gaussian additive noise during training.</figDesc><table><row><cell>Training Condition</cell><cell cols="2">Test error Av. distortion</cell></row><row><cell>DCN</cell><cell>2.0%</cell><cell>0.102</cell></row><row><cell>GN,L1,σ = 0.1</cell><cell>1.8%</cell><cell>0.095</cell></row><row><cell>GN,L*,σ = 0.1</cell><cell>2.0%</cell><cell>0.099</cell></row><row><cell cols="2">DCN+GN,L1,σ = 0.1 2.2%</cell><cell>0.108</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Table 6 shows the comparison of the Deep Contractive Network penalty against stochastic noise addition. Deep Contractive Networks are more robust than a standard neural network trained with Gaussian input noise, and can be easily augmented by adding Gaussian input noise to further increase the minimum distortion of adversarial noises.</figDesc><table /><note>4.4 DISCUSSIONS AND FUTURE WORKResults show that Deep Contractive Networks can successfully be trained to propagate contractivity around the input data through the deep architecture, without significant loss in final accuracies. The model can be improved by augmenting the layer-wise contractive penalty based on Higher-Order Contractive autoencoders<ref type="bibr" target="#b13">Rifai et al. (2011a)</ref>, and marginalized Denoising autoencoders Chen et al.</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors thank Nitish Srivastava for releasing his DeepNet Library, and Volodymyr Mnih for his CUDAMat Library <ref type="bibr" target="#b11">Mnih (2009)</ref>.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">What regularized auto-encoders learn from the data generating distribution</title>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Alain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1211.4246</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning deep architectures for ai</title>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations and trends R in Machine Learning</title>
				<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Marginalized denoising autoencoders for nonlinear representations</title>
		<author>
			<persName><forename type="first">Minmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><surname>Kilian</surname></persName>
		</author>
		<author>
			<persName><surname>Sha</surname></persName>
		</author>
		<author>
			<persName><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1476" to="1484" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition. Audio, Speech, and Language Processing</title>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Acero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="30" to="42" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Recurrent excitation in neocortical circuits</title>
		<author>
			<persName><forename type="first">Rodney</forename><forename type="middle">J</forename><surname>Douglas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christof</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><surname>Mahowald</surname></persName>
		</author>
		<author>
			<persName><surname>Misha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Humbert</forename><forename type="middle">H</forename><surname>Suarez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">269</biblScope>
			<biblScope unit="issue">5226</biblScope>
			<biblScope unit="page" from="981" to="985" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">David</forename><surname>Duvenand</surname></persName>
		</author>
		<author>
			<persName><surname>Rippel</surname></persName>
		</author>
		<author>
			<persName><surname>Oren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1402.5836</idno>
		<title level="m">Avoiding pathologies in very deep networks</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Distributed hierarchical processing in the primate cerebral cortex</title>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">J</forename><surname>Felleman</surname></persName>
		</author>
		<author>
			<persName><surname>Van Essen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>David</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cerebral cortex</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Transforming auto-encoders</title>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Neural Networks and Machine Learning-ICANN 2011</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="44" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>Computer Science Department, University of Toronto, Tech. Rep</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><surname>Ilya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The mnist database of handwritten digits</title>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Cudamat: a cuda-based matrix class for python</title>
		<author>
			<persName><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tech. Rep. UTML TR</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Toronto</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Recurrent models of visual attention</title>
		<author>
			<persName><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><surname>Volodymyr</surname></persName>
		</author>
		<author>
			<persName><surname>Heess</surname></persName>
		</author>
		<author>
			<persName><surname>Nicolas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno>CoRR, abs/1406.6247</idno>
		<ptr target="http://arxiv.org/abs/1406.6247" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Higher order contractive auto-encoder</title>
		<author>
			<persName><surname>Rifai</surname></persName>
		</author>
		<author>
			<persName><surname>Salah</surname></persName>
		</author>
		<author>
			<persName><surname>Mesnil</surname></persName>
		</author>
		<author>
			<persName><surname>Grégoire</surname></persName>
		</author>
		<author>
			<persName><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><surname>Pascal</surname></persName>
		</author>
		<author>
			<persName><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><surname>Xavier</surname></persName>
		</author>
		<author>
			<persName><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><surname>Yoshua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011a</date>
			<biblScope unit="page" from="645" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Contractive autoencoders: Explicit invariance during feature extraction</title>
		<author>
			<persName><surname>Rifai</surname></persName>
		</author>
		<author>
			<persName><surname>Salah</surname></persName>
		</author>
		<author>
			<persName><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><surname>Pascal</surname></persName>
		</author>
		<author>
			<persName><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><surname>Xavier</surname></persName>
		</author>
		<author>
			<persName><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><surname>Xavier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning (ICML-11)</title>
				<meeting>the 28th International Conference on Machine Learning (ICML-11)</meeting>
		<imprint>
			<date type="published" when="2011">2011b</date>
			<biblScope unit="page" from="833" to="840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Deep networks with internal selective attention through feedback connections</title>
		<author>
			<persName><forename type="first">Marijn</forename><surname>Stollenga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faustino</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juergen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1407.3068</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><surname>Yangqing</surname></persName>
		</author>
		<author>
			<persName><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><surname>Pierre</surname></persName>
		</author>
		<author>
			<persName><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName><surname>Dragomir</surname></persName>
		</author>
		<author>
			<persName><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><surname>Dumitru</surname></persName>
		</author>
		<author>
			<persName><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.4842</idno>
		<title level="m">Going deeper with convolutions</title>
				<imprint>
			<date type="published" when="2014">2014a</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Intriguing properties of neural networks</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><surname>Wojciech</surname></persName>
		</author>
		<author>
			<persName><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><surname>Ilya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><surname>Dumitru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014b</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deepface: Closing the gap to human-level performance in face verification</title>
		<author>
			<persName><forename type="first">Yaniv</forename><surname>Taigman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><forename type="middle">'</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><surname>Aurelio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1701" to="1708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Yichuan</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1306.0239</idno>
		<title level="m">Deep learning using support vector machines</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning with recursive perceptual representations</title>
		<author>
			<persName><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><surname>Oriol</surname></persName>
		</author>
		<author>
			<persName><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><surname>Yangqing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2825" to="2833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">Ning</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName><surname>Manohar</surname></persName>
		</author>
		<author>
			<persName><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Darrell</forename><surname>Marc'aurelio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lubomir</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1311.5591</idno>
		<title level="m">Panda: Pose aligned networks for deep attribute modeling</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
