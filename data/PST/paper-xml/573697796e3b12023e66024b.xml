<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Redundant Memory Mappings for Fast Access to Large Memories</title>
				<funder>
					<orgName type="full">University of Wisconsin</orgName>
				</funder>
				<funder>
					<orgName type="full">FPU</orgName>
				</funder>
				<funder ref="#_zY8kD38 #_ZPApDcU">
					<orgName type="full">European Union</orgName>
				</funder>
				<funder ref="#_PXVxEPk">
					<orgName type="full">Google</orgName>
				</funder>
				<funder ref="#_3ZhjPZZ">
					<orgName type="full">National Science Foundation</orgName>
				</funder>
				<funder>
					<orgName type="full">Spanish MEC</orgName>
				</funder>
				<funder ref="#_gG2Jy4S #_T7X7jKj">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Vasileios</forename><surname>Karakostas</surname></persName>
							<email>vasilis.karakostas@bsc.es</email>
							<affiliation key="aff0">
								<orgName type="department">Barcelona Supercomputing Center</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Universitat Politecnica de Catalunya</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jayneel</forename><surname>Gandhi</surname></persName>
							<email>jayneel@cs.wisc.edu</email>
							<affiliation key="aff5">
								<orgName type="institution">University of Wisconsin</orgName>
								<address>
									<settlement>Madison</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Furkan</forename><surname>Ayar</surname></persName>
							<email>frkn.ayar@gmail.com</email>
							<affiliation key="aff2">
								<orgName type="department">Dumlupinar University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Adri?n</forename><surname>Cristal</surname></persName>
							<email>adrian.cristal@bsc.es</email>
							<affiliation key="aff0">
								<orgName type="department">Barcelona Supercomputing Center</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Universitat Politecnica de Catalunya</orgName>
							</affiliation>
							<affiliation key="aff6">
								<orgName type="institution">Spanish National Research Council (IIIA-CSIC</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
							<email>markhill@cs.wisc.edu</email>
							<affiliation key="aff5">
								<orgName type="institution">University of Wisconsin</orgName>
								<address>
									<settlement>Madison</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kathryn</forename><forename type="middle">S</forename><surname>Mckinley</surname></persName>
							<email>mckinley@microsoft.com</email>
							<affiliation key="aff3">
								<orgName type="department">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mario</forename><surname>Nemirovsky</surname></persName>
							<email>mario.nemirovsky@bsc.es</email>
							<affiliation key="aff4">
								<orgName type="department">Barcelona Supercomputing Center</orgName>
								<orgName type="institution">ICREA</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
							<email>swift@cs.wisc.edu</email>
							<affiliation key="aff5">
								<orgName type="institution">University of Wisconsin</orgName>
								<address>
									<settlement>Madison</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Osman</forename><surname>?nsal</surname></persName>
							<email>osman.unsal@bsc.es</email>
							<affiliation key="aff0">
								<orgName type="department">Barcelona Supercomputing Center</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Redundant Memory Mappings for Fast Access to Large Memories</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/2749469.2749471</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Page-based virtual memory improves programmer productivity, security, and memory utilization, but incurs performance overheads due to costly page table walks after TLB misses. This overhead can reach 50% for modern workloads that access increasingly vast memory with stagnating TLB sizes.</p><p>To reduce the overhead of virtual memory, this paper proposes Redundant Memory Mappings (RMM), which leverage ranges of pages and provides an efficient, alternative representation of many virtual-to-physical mappings. We define a range be a subset of process's pages that are virtually and physically contiguous. RMM translates each range with a single range table entry, enabling a modest number of entries to translate most of the process's address space. RMM operates in parallel with standard paging and uses a software range table and hardware range TLB with arbitrarily large reach. We modify the operating system to automatically detect ranges and to increase their likelihood with eager page allocation. RMM is thus transparent to applications.</p><p>We prototype RMM software in Linux and emulate the hardware. RMM performs substantially better than paging alone and huge pages, and improves a wider variety of workloads than direct segments (one range per program), reducing the overhead of virtual memory to less than 1% on average.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Virtual memory provides the illusion of a private and very large address space to each process. Its benefits include improved security due to process isolation and improved programmer productivity, since the operating system and hardware manage the mapping from per-process virtual addresses to physical addresses. Page-based implementations of virtual memory are ubiquitous in modern hardware. They divide physical memory into fixed-size pages, use a page table to map virtual pages to physical pages, and accelerate address lookups using Translation Lookaside Buffers (TLBs). When paging was introduced, it also delivered high performance, since TLBs serviced the vast majority of address translations.</p><p>Unfortunately, the performance of paging is suffering due to stagnant TLB sizes, whereas modern memory capacities continue to grow. Because TLB address translation is on the processors' critical path, it requires low access times which constrain TLB size and thus the number of pages that experience this access time. On a TLB miss, the system must walk the page table, which may incur additional cache misses. This problem is called limited TLB reach. Recent studies show that modern workloads can experience execution-time overheads of up to 50% due to page table walks <ref type="bibr" target="#b8">[10,</ref><ref type="bibr" target="#b10">12,</ref><ref type="bibr" target="#b29">31]</ref>. This overhead is likely to grow, because physical memory sizes are still growing. Furthermore, many modern applications have an insatiable desire for memory-they increase their data set sizes to consume all available memory for each new generation of hardware <ref type="bibr" target="#b8">[10,</ref><ref type="bibr" target="#b19">21]</ref>.</p><p>Previous research has focused on solving this problem by improving the efficiency of paging in the following three ways. 1. Multipage mappings use one TLB entry to map multiple pages (e.g., 8-16 pages per entry) <ref type="bibr" target="#b36">[38,</ref><ref type="bibr" target="#b37">39,</ref><ref type="bibr" target="#b45">47]</ref>. Mapping multiple pages per entry increases TLB reach by a small fixed amount, but has alignment restrictions, and still leaves TLB reach far below modern gigabyte-to-terabyte physical memory sizes. 2. Huge pages map much larger fixed size regions of memory, on the orders of 2 MB to 1 GB on x86-64 architectures. Use of huge pages (THP <ref type="bibr" target="#b4">[6]</ref> and libhugetlbfs <ref type="bibr" target="#b0">[1]</ref>) increase TLB reach substantially, but also suffer from size and alignment restrictions and still have limited reach. 3. Direct segments provide a single arbitrarily large segment and standard paging for the remaining virtual address space <ref type="bibr" target="#b8">[10,</ref><ref type="bibr" target="#b21">23]</ref>. For applications that can allocate and use a single segment for the majority of their memory accesses, direct segments eliminate most of the paging cost. However, direct segments only support a single segment and require that application writers explicitly allocate a segment during startup.  The goal of our work is to provide a robust virtual memory mechanism that is transparent to applications and improves translation performance across a variety of workloads.</p><p>We introduce Redundant Memory Mappings (RMM) a novel hardware/software co-designed implementation of virtual memory. RMM adds a redundant mapping, in addition to page tables, that provides a more efficient representation of translation information for ranges of pages that are both physically and virtually contiguous. RMM exploits the natural contiguity in address space and keeps the complete page table as a fall-back mechanism.</p><p>RMM relies on the concept of range translation. Each range translation maps a contiguous virtual address range to contiguous physical pages, and uses BASE, LIMIT, and OFF-SET values to perform translation of an arbitrary sized range. Range translations are only base-page-aligned and redundant to paging; the page table still maps the entire virtual address space. Figure <ref type="figure" target="#fig_0">1</ref> illustrates an application with two ranges mapped redundantly with paging as well as range translations.</p><p>Analogous to paging, we add a software managed range table to map virtual ranges to physical ranges and a hardware range TLB in parallel with the last-level page TLB to accelerate their address translation. Because range tables are redundant to page tables, RMM offers all the flexibility of paging and the operating system may use or revert solely to paging when necessary.</p><p>To increase contiguity in range translations, we extend the OS's default lazy demand page allocation strategy to perform eager paging. Eager paging instantiates pages in physical memory at allocation request time, rather than at first-access time as with demand paging. The resulting OS automatically maps most of process's virtual address space with orders of magnitude fewer ranges than paging with Transparent Huge Pages <ref type="bibr" target="#b4">[6]</ref>. On a wide variety of workloads consuming between 350 MB -75 GB of memory, we find that RMM has the potential to map more than 99% of memory for all workloads with 50 or fewer range translations (see Section 3's Table <ref type="table" target="#tab_2">2</ref>).</p><p>To evaluate this design, we implement RMM software support in Linux kernel v3.15.5. We emulate the hardware using a combination of hardware performance counters from an x86 execution and functional TLB simulation in BadgerTrap <ref type="bibr" target="#b20">[22]</ref>the same methodology as in prior TLB studies <ref type="bibr" target="#b8">[10,</ref><ref type="bibr" target="#b10">12,</ref><ref type="bibr" target="#b21">23]</ref>. We compare RMM to standard paging, Clustered TLBs, huge (2 MB and 1 GB) pages, and direct segments (one range per program). RMM robustly performs substantially better than the former three alternatives on various workloads, and almost as fast as Direct segments when one range is applicable. However with RMM, more applications enjoy reductions in translation overhead without programmer intervention. Overall, RMM reduces the overhead of virtual memory to less than 1% on average.</p><p>In summary, the main contributions of this paper are: ? We show that diverse workloads exhibit an abundance of contiguity in their virtual address space. ? We propose Redundant Memory Mappings, a hardware/ software co-design, which includes a fast and redundant translation mechanism for ranges of contiguous virtual pages mapped to contiguous physical pages, and operating system modifications that detect and manage ranges. ? We prototype RMM in Linux and evaluate it on a broad range of workloads. Our results show that a modest number of ranges map most of memory. Consequently, the range TLB achieves extremely high hit rates, eliminating the vast majority of costly page-walks compared to virtual memory systems that use paging alone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background</head><p>This section and Table <ref type="table" target="#tab_0">1</ref> overview the closely related approaches to reducing paging overheads and compare them to RMM. Section 9 discusses related work more generally.</p><p>Multipage Mapping approaches, such as sub-blocked TLBs <ref type="bibr" target="#b45">[47]</ref>, CoLT <ref type="bibr" target="#b37">[39]</ref> and Clustered TLBs <ref type="bibr" target="#b36">[38]</ref>, pack multiple Page  multiple of translations (e.g., 8-16) per entry, which limits their potential to reduce page-walks for large working sets.</p><p>Huge Pages using Transparent Huge Pages (THP) <ref type="bibr" target="#b4">[6]</ref> and libhugetlbfs <ref type="bibr" target="#b0">[1]</ref> increase the TLB reach by mapping very large regions with a single entry. The x86-64 architecture supports mixing 4 KB with 2 MB and 1 GB pages, while other architectures support more sizes <ref type="bibr" target="#b33">[35,</ref><ref type="bibr" target="#b39">41,</ref><ref type="bibr" target="#b42">44]</ref>. The effectiveness of huge pages is limited by the size-alignment requirement: huge pages must have size-aligned physical addresses, and thus the OS can only allocate them when the available memory is size-aligned and contiguous <ref type="bibr" target="#b36">[38,</ref><ref type="bibr" target="#b37">39]</ref>. In addition, many commodity processors provide limited numbers of large page TLB entries, which further limits their benefit <ref type="bibr" target="#b8">[10,</ref><ref type="bibr" target="#b21">23,</ref><ref type="bibr" target="#b29">31]</ref>.</p><p>Direct segments <ref type="bibr" target="#b8">[10]</ref> are a hardware/software approach that map a single unlimited range of contiguous virtual memory to contiguous physical memory using a single hardware segment, while the rest of the virtual address space uses standard paging. A virtual address is mapped by a direct segment or paging, but never both. Direct segments introduce BASE, LIMIT, and OFFSET registers to eliminate the page-walks within the segment. However, the mechanism requires that (i) applications explicitly allocate a direct segment during startup, and (ii) the OS can reserve a single large contiguous range of physical memory for a segment. Thus, direct segments are only suitable for big-memory workloads and require application changes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Redundant Memory Mappings</head><p>We observe that many applications naturally exhibit an abundance of contiguity in their virtual address space and the number of ranges needed to represent this contiguity is low.</p><p>Abundance of address contiguity. We quantify address contiguity by executing applications on x86-64 hardware (see Section 7 for workload and methodology details), and periodically scan the page table, measuring the size of virtual address ranges where all pages are mapped with the same permissions. Table <ref type="table" target="#tab_2">2</ref> shows the minimum number of ranges of contiguous virtual pages that the OS could map to contiguous physical pages. The workloads require between 16 to 112 ranges to map their entire virtual address space. However, the number of ranges to cover 99% of the application's memory space falls to fewer than 50. Although a single range maps 90% or more of the virtual memory for 5 of the 14 workloads, the rest require multiple ranges. These results suggest that a small number of range translations have the potential to efficiently perform address translation for the majority of virtual memory addresses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Overview</head><p>The above measurements motivate the RMM approach. (i)</p><p>The OS uses best-effort allocation to detect and map contiguous virtual pages to contiguous physical pages in a range  Most addresses fall in ranges and hit in the range TLB, but if needed, the system can revert to the flexibility and reduced fragmentation benefits of paging. Definition: A range translation is a mapping between contiguous virtual pages mapped to contiguous physical pages with uniform protection bits (e.g., read/write). A range translation is of unlimited size and base-page-aligned. A range translation is identified by BASE and LIMIT addresses. To translate a virtual range address to physical address, the hardware adds virtual address to the OFFSET of the corresponding range.</p><p>Figure <ref type="figure">2</ref> shows how RMM maps parts of the process's address space with both range translations and pages. Redundant Memory Mappings (RMM) use range translations to perform address translation much more efficiently than paging for large regions of contiguous physical addresses. We introduce three novel components to manage ranges: (i) range TLBs, (ii) range tables, and (iii) eager paging allocation. Table 3 summarizes these new components and their relationship to paging. The range TLB hardware stores range translations and is accessed in parallel to the last-level page TLB (e.g., L2 TLB). The address translation hardware accesses the range and page TLBs in parallel after a miss at the previous-level TLB (e.g., L1 TLB). If the request hits in the range TLB or in the page TLB, the hardware installs a 4 KB TLB entry in the previous-level TLB, and execution continues. In the uncommon case that a request misses in both range TLB and page TLB, and the address maps to a range translation, the hardware fetches the page table entry to resume execution and optionally fetches a range table entry in the background.</p><p>RMM performance depends on the range TLB achieving a high hit ratio with few entries. To maximize the size of each range, RMM extends the OS page allocator to improve contiguity with an eager paging mechanism that instantiates a contiguous range of physical pages at allocation time, rather than the on-demand default, which instantiates pages in physical memory upon first access. The OS always updates both the page table and the range table to consistently manage the entire memory at both the page and range granularity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Architectural Support</head><p>The RMM hardware primarily consists of the range TLB, which holds multiple range translations, each of which translates for an unlimited-size range. Below, we describe RMM as an extension to the x86-64 architecture, but the design applies to other architectures as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Range TLB</head><p>The range TLB is a hardware cache that holds multiple range translations. Each entry maps an unlimited range of contiguous virtual pages to contiguous physical pages. The range TLB is accessed in parallel with the last-level page TLB (e.g., the L2 TLB) and in case of hit, it generates the corresponding 4 KB entry in the previous-level page TLB (e.g., the L1 TLB).</p><p>We design the range TLB as a fully associative structure, because each range can be any size making standard indexing for set-associative structure hard. The right side of Figure <ref type="figure" target="#fig_1">3</ref> illustrates the range TLB and its logic with N (e.g., 32) entries. Each range TLB entry consists of a virtual range and translation. The virtual range stores the BASE i and LIMIT i of the virtual address range map. The translation stores the OFFSET i that holds the start of the range in physical memory minus BASE i , and the protection bits (PB). Additionally, each range TLB entry includes two comparators for lookup operations.</p><p>Figure <ref type="figure" target="#fig_1">3</ref> illustrates accessing the range TLB in parallel with the L2 TLB, after a miss at the L1 TLB. The hardware compares the virtual page number that misses in the L1 TLB, testing BASE i ? virtual page number &lt; LIMIT i for all ranges in parallel in the range TLB. On a hit, the range TLB returns the OFFSET i and protection bits for the corresponding range translation and calculates the corresponding page table entry for the L1 TLB. It adds the requested virtual page number to the hit OFFSET i value to produce the physical page number and copies the protection bits from the range translation. On a miss, the hardware fetches the corresponding range translation-if it exists-from the range table. We explain this operation in Section 4.3 after discussing the range table in more detail.</p><p>The range TLB is accessed in parallel with the last-level page TLB and must return the lookup result (hit/miss) within the TLB access latency, which for the L2 TLB on recent Intel processors is ~7 cycles <ref type="bibr" target="#b26">[28]</ref>. Unlike a page TLB, the range TLB is similar to N fully-associative copies of direct segment's base/limit/offset logic <ref type="bibr" target="#b8">[10]</ref> or a simplified version of the range cache <ref type="bibr" target="#b46">[48]</ref>: it performs two comparisons per entry instead of a single equality test. Our design can achieve this performance because the range TLB contains only a few entries and it can use fast comparison circuits <ref type="bibr" target="#b30">[32]</ref>. Our results in Section 8 show that a 32-entry fully-associative range TLB eliminates more than 99% of the page-walks for most of our applications, at lower power and area cost than simply increasing the size of the corresponding L2 TLB. Note that our approach of accessing the range TLB in parallel to the last-level page TLB can be extended to the other translation levels closer to the processor (e.g., in parallel to the L1 TLB); we leave such analysis for future work. Optimization. To reduce the dynamic energy cost of the fully associative lookups, we introduce an optional MRU Pointer that stores the most-recently-used range translation and thus reduces associative searches of the range TLB. The range TLB</p><formula xml:id="formula_0">[V47 V46 ??? V12] [V11 ?? .. V0] L1 D-TLB Lookup Hit ? Y [P47 P46 ??? P12] [P11 ??.. P0] N L2 D-TLB Lookup Y Hit ? Range TLB Hit ? Y N N Page+Range Table Walk BASE 0 LIMIT 0 ? &gt; BASE 1 LIMIT 1 ? &gt; Ent ry 0 Ent ry 1 BASE N-1 LIMIT N-1 ? &gt; Ent ry N-1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Encoder</head><p>Range TLB miss first checks the MRU Pointer and in case of a hit, skips the other entries. Otherwise, the range TLB checks all valid entries in parallel. Note that the MRU Pointer can serve translation requests faster than the corresponding page TLB and may further boost performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Range table</head><p>The range table is an architecturally visible per-process data structure that stores the process's range translations in memory.</p><p>The role of the range table is similar to that of the page table . A hardware walker loads range translations from the range table on a range TLB miss, and the OS manages range table entries based on the application's memory management operations.</p><p>We propose using a B-Tree data structure with (BASE i , LIMIT i ) as keys and OFFSET i and protection bits as values to store the range table. B-trees are cache friendly and keep the data sorted to perform search and update operations in logarithmic time. Since a single B-Tree node may have multiple ranges and children, it is a dense representation of ranges.</p><p>The number of ranges per range table node defines the depth of the tree and the average number of node lookups to perform a search/update operation. Figure <ref type="figure">4</ref> shows how the range translations are stored in the range table and the design of each node. Each node accommodates four range translations and points to five children, e.g., up to 124 range translations in three levels. Since each range translation is represented at page-granularity with the BASE (48 architectural bits -12 bits per page=36 bits), the LIMIT (36 bits), and the OFFSET and protection bits together (64-bits conventional PTE size), thus each range table node fits in two cache-lines. This design ensures the traversal of the range table is cache-friendly, accesses only a few cache lines per operation, and maintains the dense representation. Note that the range table is much smaller than a page table: a single 4 KB page stores 128 range translations, which is more than enough for almost all our workloads (Table <ref type="table" target="#tab_17">7</ref>). All the pointers to the children are physical addresses, which facilitate walking the range table in hardware.</p><p>Analogous to the page table pointer register (CR3 in x86-64), RMM requires a CR-RT register to point to the physical address of the range table root to perform address translation, as we will explain next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Handling misses in the range TLB</head><p>On a miss to the range TLB and corresponding page TLB, the hardware must fetch a translation from the memory. Two design issues arise with RMM at this point. First, should address translation hardware use the page table to fetch only the missing PTE or the range table to fetch the range translation? Second, how does the hardware determine if the missing translation is part of a range translation and avoid unnecessary lookups in the range table? Because ranges are redundant, there are several options. Miss-handling order. RMM first fetches the missing translation from the page table, as all valid pages are guaranteed to be present, and installs it in the previous-level TLB so that the processor can continue executing the pending operation. This choice avoids additional latency from accessing the range table for pages that are not redundantly mapped. In the background, the range table walker hardware resolves whether the address falls in a range and if it does, updates the range table with the range table entry. Thus when both the range table and page TLB miss, the miss incurs the cost of a page-walk. Any updates to the range TLB occur off the critical path. Identifying valid range translations. To identify whether a miss in the range TLB can be resolved to a range or not, RMM adds a range bit to the PTE, which indicates whether a page is part of a range Shootdown. The OS uses the INVLPG instruction to invalidate stale virtual to physical translations (including changes in the protection bits) during the TLB shootdown process <ref type="bibr" target="#b14">[16]</ref>. To ensure correct functionality, RMM modifies the INVLPG instruction to invalidate all TLB entries and any range TLB entry that contains the corresponding virtual page. The modified OS may thus use this instruction to keep all TLBs and the range TLB coherent through the TLB shootdown process. The OS may also associate each range TLB entry with an address space identifier, similar to TLB entries, to perform context switches without flushing the range TLB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Operating System Support</head><p>RMM requires modest operating system (OS) modifications. The OS must create and manage range table entries in software and coordinate them with the page table. We modify the OS to increase the size of ranges with an eager paging allocation mechanism. We prototype these changes in Linux, but the design is applicable to other OSes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Managing range translations</head><p>Similar to paging, the process control block in RMM stores a range table pointer (RT pointer) with the physical address of the root node of the range table. When the OS creates a process, it allocates space for the range table and sets the RT pointer. On every context switch, the OS copies the RT pointer to the CR-RT register and then the range table walker uses it to walk the range table.</p><p>The OS updates the range table when the application allocates or frees memory or the OS reclaims a page. The OS analyzes the contiguity of the affected page(s). Based on a contiguity threshold (e.g., 8 pages), the OS adds, updates, or removes a range translation from the range table. The OS avoids creating small range translations that could cause thrashing in the range TLB. The OS can modify the contiguity threshold dynamically, based on the current number and size of range translations, and the performance of the range TLB (option not explored). The OS updates the range bit in all the corresponding PTEs for the range to keep them consistent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Contiguous memory allocation</head><p>Achieving a high hit ratio in the range TLB and thus low virtual memory overheads requires a small number of very large range translations that satisfy most virtual address translation requests. To this end, RMM modifies the OS memory allocation mechanism to use eager paging, which strives to allocate the largest possible range of contiguous virtual pages to contiguous physical pages. Eager paging requires modest changes to Linux's default buddy page allocator. Default buddy allocator. The buddy allocator splits physical memory in blocks of 2 order pages, and manages the blocks using separate free-lists per block size. A kernel compile-time parameter defines the maximum size of memory blocks (2 max_order ) and hence the total number of the free-lists. The buddy allocator organizes each free-list in power-of-two blocks and satisfies requests from the free-list of the smallest size. If a block of the desired 2 i size is not available (i.e., free-list[i] is empty), the OS finds the next larger 2 i+k size free block, going from k = 1, 2, ... until it finds the smallest free block large enough to satisfy the request. The OS then iteratively splits a block in two, until it creates a free block of the desired 2 i size. It then assigns one free block to the allocation and adds any other free blocks it creates to the appropriate free-lists. When the application later frees a 2 i block, the OS examines its corresponding buddy block (identified by its address). If this block is free, the OS coalesces the two blocks, resulting in a 2 i+1 block. The buddy allocator thus easily splits and merges blocks during allocations and deallocations respectively.</p><p>Despite contiguous pages in the buddy heap, in practice most allocations are of a single page because of demand paging. Operating systems use demand paging to reduce allocation latency by deferring page instantiation until the application actually references the page. Therefore, the application's allocation does not trigger OS allocation, but rather when the application first writes or reads a page, the OS allocates a single page (from free-list[0]). Demand allocation at accesstime degrades contiguity, because (i) it allocates single pages even when large regions of physical memory are available, and because (ii) the OS may assign pages accessed out-oforder to non-contiguous physical pages even though there are contiguous free pages. Eager paging. Eager paging improves the generation of large range translations by allocating consecutive physical pages to consecutive virtual pages eagerly at allocation, rather than lazily on demand at access time.  (e.g., when the application performs an mmap, mremap or brk call), if the request is larger than the range threshold, the OS establishes one or more range translations for the entire request and updates the corresponding range and page table entries. We note that demand paging replaced eager paging in early systems. However, one motivation for demand paging was to limit unnecessary swapping in multiprogrammed workloads, which modern large memories make less common <ref type="bibr" target="#b8">[10]</ref>. We find that the high cost of TLB misses, makes eager paging a better choice with RMM hardware in most cases.</p><p>Eager paging increases latency during allocation and may induce fragmentation, because the OS must instantiate all pages in memory, even those the application never uses. However unused memory is not permanently wasted. The OS could monitor memory use in range translations and reclaim ranges and pages with standard paging mechanisms, but we leave this exploration for future work. Allocating memory at request-time generates larger range translations compared to the access-time policy of demand paging and improves the effectiveness of RMM hardware.</p><p>Algorithm. Figure <ref type="figure" target="#fig_2">5</ref> shows simplified pseudocode for eager paging. If the application requests an allocation of size N?pages, eager paging allocates the 2 i block, as described above. This simple algorithm only provides contiguity up to the maximum managed block size. If the application requests more memory than the maximum managed block, the OS will allocate multiple maximum blocks. Two optimizations further improve contiguity. First, eager paging could sort the blocks in the free-lists, to coalesce multiple blocks and generate range translations larger than the maximum block. Second, to generate large range translations from allocations that are smaller than the maximum block, eager paging could request a block from a larger size free-list, assign the necessary pages, and return the remaining blocks to the corresponding smaller sized free-lists. These enhancements introduce additional trade-offs that warrant more investigation. Note that in our RMM prototype, we did not implement these two enhancements. Nonetheless, the simple eager paging algorithm generates large range translations for a variety of block sizes and exploits the clustering behavior of the buddy allocator <ref type="bibr" target="#b36">[38,</ref><ref type="bibr" target="#b37">39]</ref>.</p><p>Finally, eager paging is only effective when memory fragmentation remains low and there is ample space to populate ranges at request time. If memory fragmentation or pressure increases, the OS may fall back to its default paging allocation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion</head><p>This section discusses some of the hardware and operating systems issues that a production implementation should consider, but leaves the implications for automatic and explicit memory management and for applications as future work. TLB friendly workloads. If an application has small memory footprint and experiences a low page TLB miss rate, the range TLB may provide little performance benefit while increasing the dynamic energy due to range TLB accesses. The OS can monitor the memory footprint and then dynamically enable and disable the range TLB. The OS would still allocate ranges and populate the range table, but then it could selectively enable the range TLB based on performance-counter measurements and workload memory allocation.</p><p>Accessed &amp; Dirty bits. The TLB in x86 processors is responsible for setting the accessed bit in the corresponding PTE in memory on the first access to a page and the dirty bit on the first write. The range TLB does not store per-page accessed/dirty bits for the individual pages that compose a range translation. Thus, on a range TLB hit, the range TLB cannot determine whether it should set the accessed or dirty bit. The OS may address this issue by setting the accessed and dirty bits for all the individual pages of a range translation eagerly at allocation time, instead of at access or write time. If the OS needs to reclaim or swap a page in an active range because of memory pressure, it may. Because the OS manages physical memory at the page-granularity-not at the range granularity-it may reclaim and swap individual pages by dissolving a range completely and then evicting and swapping  pages individually. Another option is for the OS to break a range in to multiple smaller ranges and dissolve one of the resulting ranges.</p><p>Copy-on-write. Copy-on-write is a virtual memory optimization in which processes initially share pages and the OS only creates separate individual pages when one of the processes modifies the page. This mechanism ensures that these changes are only visible to the owning process and to no other process.</p><p>To implement this functionality, copy-on-write uses per-page protection bits that trigger a fault when the page is modified. On a fault, the OS copies the page and updates the protection bits in the page table. With RMM, the range translations hold the protection bits at range granularity, not on individual pages. One simple approach is to use range translations for read-only shared ranges, but dissolve a range into pages when a process writes to any of its pages. Alternatively, the OS could copy the entire range translation on a fault.</p><p>Fragmentation. Long-running server and desktop systems will execute multiple processes at once and a variety of workload mixes. Frequent memory management requests from complex workloads may cause physical memory fragmentation and limit the performance of RMM. If the OS cannot find a sufficiently large range of free pages in memory, it should default to paging-only and disable the range TLB. However, abundant memory capacity coupled with fragmentation is not uncommon, since a few pages scattered throughout memory can cause considerable fragmentation <ref type="bibr" target="#b16">[18]</ref>. In this case, the OS could perform full compaction <ref type="bibr" target="#b8">[10,</ref><ref type="bibr" target="#b37">39]</ref>, or partial compaction with techniques adapted from garbage collection <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b16">18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Methodology</head><p>To evaluate virtual memory system performance on large memory workloads, we implement our OS modifications in Linux, define RMM hardware with respect to a recent Intel x86-64 Xeon core, and report overheads using a combination of hardware performance counters from application executions and functional TLB simulation.  RMM operating system prototype. We prototype the RMM operating system changes in Linux x86-64 with kernel v3.15.5. We implement the management of the range tables by intercepting all kernel memory-management operations. We implement range creation and eager paging by modifying the mmap, brk and mremap system calls. For our prototype range table, we implement a simple linked list rather than a B-tree. Because our applications spend only a tiny fraction of their time in the OS and the range TLB refill is not on the processor's critical path, this simplification does not affect our results. We use a contiguity threshold of 32 KB (8 pages) to define the minimum size of a range translation. To increase the maximum size of a range, we increase the maximum allocation size in the buddy allocator to 2 GB, up from 4 MB by modifying the max_order parameter of the buddy allocator from 11 to 20. Because the default glibc memory management implementation does not coalesce allocations into fixed-size virtual ranges, we instead use the TCMalloc library [5]. In addition, we modify TCMalloc to increase the maximum allocation size from 256 KB to 32 MB. RMM hardware emulation. We evaluate the RMM hardware described in Section 4 with Intel Sandy Bridge core shown in Table <ref type="table" target="#tab_13">5</ref>. We choose a 32-entry fully associative range TLB accessed in parallel with the L2 page TLB, since we estimate that it can meet the L2's timing constraints.</p><p>To measure the overheads of RMM, we combine performance counter measurements from native executions with TLB performance emulation using a modified version of Bad-gerTrap <ref type="bibr" target="#b20">[22]</ref>. Compared to cycle-accurate simulation on these workloads, this approach reduces weeks of simulation time by orders of magnitude. Previous virtual memory system performance studies use this same approach <ref type="bibr" target="#b8">[10,</ref><ref type="bibr" target="#b10">12,</ref><ref type="bibr" target="#b21">23]</ref>.</p><p>BadgerTrap instruments x86-64 TLB misses. We add a functional range TLB simulator in the kernel that BadgerTrap invokes. On each page L2 TLB miss, BadgerTrap performs a range TLB lookup. Note that the actual implementation would perform the range TLB lookup in parallel, rather than after the L2 TLB miss. This emulation may thus underestimate the benefit of the range TLB, because the real hardware will install  a missing page table entry, even if the virtual address hits in the range TLB. The actual RMM implementation reduces traffic to the L2 page TLB on range TLB hits, freeing up page TLB entries and potentially making it more effective. This simulation methodology may itself perturb TLB behavior. To minimize this problem, we allocate a 2 MB page in the kernel for the simulator itself, which reduces the differences with an unmodified kernel to less than 5%. Performance model. We estimate the impact of RMM on system performance with the following methodology. First, we run the applications on the real system (Table <ref type="table" target="#tab_13">5</ref>) with realistic input sets until completion and collect processor and TLB statistics using hardware performance counters. We use the Linux perf utility <ref type="bibr" target="#b3">[4]</ref> to read the performance counters. We collect total execution cycles, misses for L2 TLB, and cycles spent in page-walks. Based on these measurements we calculate (i) the ideal execution time (no virtual memory overhead), (ii) the measured overhead spent in page-walks, and (iii) the estimated overhead with the simulated hardware mechanisms based on the fraction of reduced page-walks, using a simple linear model <ref type="bibr" target="#b8">[10,</ref><ref type="bibr" target="#b21">23]</ref> given in Table <ref type="table" target="#tab_14">6</ref>.</p><p>Benchmarks. RMM is designed for a wide range of applications from desktop applications to big-memory workloads executing on scale-out servers. To evaluate the effectiveness of RMM, we select workloads with poor TLB performance from SPEC 2006 <ref type="bibr" target="#b23">[25]</ref>, BioBench <ref type="bibr" target="#b5">[7]</ref>, Parsec <ref type="bibr" target="#b13">[15]</ref> and big-memory workloads <ref type="bibr" target="#b8">[10]</ref> as summarized in Table <ref type="table" target="#tab_11">4</ref>. We execute each application sequentially on a single test machine without rebooting between experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Results</head><p>This section evaluates the cost of address translation, the impact of eager paging, and implications on energy of RMM, and shows substantial improvements in performance over current and proposed systems. We compare RMM performance to the following systems. (i) We measure the virtual memory overheads of a commodity x86-64 processor (see Table <ref type="table" target="#tab_13">5</ref>) with 4 KB pages, 2 MB pages with transparent huge pages, and 1 GB pages with libhugetlbfs using hardware performance counters. (ii) We emulate multipage mappings in BadgerTrap. We implement the Clustered TLB approach <ref type="bibr" target="#b36">[38]</ref> of Pham et al., configured with 512 fullyassociative entries. Each entry indexes up to an 8-page cluster, shown best by Clustered TLB <ref type="bibr" target="#b36">[38]</ref>. We use eager paging to increase the opportunities to form multipages, improving on the original implementation. (iii) We emulate the performance of ideal direct segments. We assume all fixed-size memory regions that live for more than 80% of a program's execution time can be coalesced in a single contiguous range, which can be used to estimate the reduction in TLB misses with direct segment hardware <ref type="bibr" target="#b8">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.">Performance analysis</head><p>Figure <ref type="figure" target="#fig_4">6</ref> shows the overhead spent in page-walks for RMM compared to other techniques. The 4 KB, 2 MB Transparent Huge Pages (THP) <ref type="bibr" target="#b4">[6]</ref> and 1 GB <ref type="bibr" target="#b0">[1]</ref> configurations show the measured overhead for the three different page sizes available on x86-64 processors. All other configurations are emulated. The CTLB bars show Clustered TLB <ref type="bibr" target="#b36">[38]</ref> results. The DS bars show direct segments <ref type="bibr" target="#b8">[10]</ref> results and the RMM bars show the 32-entry range TLB results.</p><p>RMM performs well on all configurations for all workloads, improving substantially over all the other approaches, except direct segments. RMM eliminates the vast majority of pagewalks, significantly outperforms the Clustered TLB (CTLB), huge pages (THP and 1GB) and achieves similar or better performance to direct segments, but has none of its limitations. On average, RMM reduces the overhead of virtual memory to less than 1%.</p><p>For most workloads, the base page size (4 KB) incurs high overheads. For example, mcf, cactusADM, and graph500 spend 42%, 39% and 29% of execution time in page-walks due to TLB misses. Even the applications with smaller working sets, such as astar, omnetpp, and mummer, still suffer substantial paging overheads using 4 KB pages.</p><p>Clustered TLB (CTLB) only offers limited reductions in overhead and only for small-memory workloads. CTLB performs better than 4 KB pages on small-memory workloads, such as cactusADM, canneal, and omnetpp. However, CTLB provides little benefit on big-memory workloads and performs worse than THP overall.</p><p>Huge pages (THP and 1 GB) reduce virtual memory overheads for all workloads but still leave room for improvement. The limited hardware support for huge pages (e.g., few TLB entries), poor application memory locality, and the mismatch of their sizes with the virtual memory contiguity all contribute to the remaining overheads.</p><p>Direct segments achieve negligible overheads on bigmemory workloads and some small-memory workloads. But, direct segments poorly serve workloads that require multiple ranges, such as omnetpp, canneal, or those that use memorymapped files such as mummer. Compared to direct segments, RMM is a better choice because it achieves similar or better performance on all workloads.</p><p>Redundant Memory Mappings achieve negligible overheadessentially eliminating virtual memory overheads for many workloads. Only one workload has greater than 2% overhead, GUPS. As our sensitivity analysis in the next section shows,  GUPS requires at least a 64-entry range TLB to achieve less than 1% overhead. Overall, RMM performs consistently better than the alternatives and in many cases eliminates the performance cost of address translation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.">Range TLB sensitivity analysis</head><p>To achieve high performance, the range TLB must be large enough to satisfy most L1 TLB misses. Figure <ref type="figure" target="#fig_6">7</ref> shows the range TLB miss ratio as a function of the numbers of entries. We observe that a handful of workloads, such as cactusADM, memcached, tigr, and GUPS, suffer from high miss ratios with a 16-entry range TLB. Overall, a 32-entry range TLB eliminates more than 99% of misses for most workloads (97.9% on average), delivering a good trade-off of performance for the required area and power. We also note that a single-entry range TLB is insufficient to eliminate virtual memory overheads. Most applications require multiple range table entries, especially those with large working sets, such as cactusADM, GemsFDTD and GUPS, and those with large numbers of ranges, such as memcached, mummer, and tigr. However, the single-entry results illustrate that the optional MRU Pointer would be effective at saving dynamic energy and latency in many cases. It reduces accesses to the range TLB by more than 50% for astar, omnetpp, canneal, streamcluster, and graph500.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3.">Impact of eager paging</head><p>Eager paging increases range size by instantiating physical pages when the application allocates memory, rather than when the application first writes or reads a page. Table <ref type="table" target="#tab_17">7</ref> shows the effect of eager paging on the number and size of range, and on time and memory overheads, compared to default demand paging. Default demand paging includes forming THPs, which we translate to ranges.</p><p>The first two sections of Table <ref type="table" target="#tab_17">7</ref> (demand paging and eager paging) compare the number of ranges, the percentage of the memory footprint covered by ranges with a contiguity threshold of 8 pages, and the range sizes (median, average, maximum) in terms of pages, created by demand and eager paging. Eager paging (i) lowers the median range size for small-memory workloads because it allocates fewer mediumsized ranges (the median for demand paging is usually 512, i.e., 2 MB regions, due to THP), (ii) increases the median range for big-memory workloads because it allocates fewer small and medium-sized ranges, and (iii) increases the average    and maximum range size for all workloads because it allocates larger blocks from the buddy allocator. Overall eager paging generates orders of magnitude fewer ranges that cover a larger percentage of memory for all applications compared to demand paging. Thus eager paging assists in achieving high range TLB hit ratio with few entries. Eager paging alters execution by changing when and how pages, even used pages, are allocated to physical memory. We measure execution overhead due to eager paging by running applications with the eager paging operating system support, but without the hardware emulation. Table <ref type="table" target="#tab_17">7</ref> shows that the execution time for most applications is relatively unchanged. A few get faster: mcf and memcached improve by 4.1% and 3.9%. However, GemsFDTD degrades by 11%. In this case, the changes in physical page allocation affect cache indexing, increasing cache conflicts. Various orthogonal mechanisms address this problem <ref type="bibr" target="#b17">[19,</ref><ref type="bibr" target="#b41">43]</ref>.</p><p>Eager paging anticipates that the application will use the requested memory regions and may thus increase the memory footprint. The last column of Table <ref type="table" target="#tab_17">7</ref> reports the memory footprint increase with eager paging. Eager paging increases memory by a small amount for three of the big-memory workloads, and by less than 10% for 7 of the remaining 10 workloads. Eager paging increases memory substantially on cactusADM and NPB:CG (the percentage is low, but totals 2.3 GB), mainly because of instantiating memory that these applications request but never use, and because of modifying TCMalloc to increase contiguity. Thus RMM trades increased memory for better performance, a common tradeoff when memory is cheap and plentiful. Note that the OS can convert a range to pages or abandon ranges altogether under memory pressure as discussed in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4.">Energy</head><p>The primary RMM effect on energy is executing the application faster, which improves static energy of system. According to our performance model, RMM improves performance by 2-84% and thus saves a similar ratio of static energy.</p><p>Secondary effects include the static and dynamic energy of the additional RMM hardware. The system accesses the range TLB in parallel with the L2 TLB, consuming dynamic energy on a L1 TLB miss. The dynamic energy of a 32entry range TLB is relatively small with respect to the entire chip, and lower than of a fully-associative 128-entry L1 TLB (e.g., SPARC M7 <ref type="bibr" target="#b38">[40]</ref>). Furthermore, replacing misses in the L2 TLB with hits in the range TLB saves dynamic energy by avoiding a page-walk that performs up to four memory operations. The OS can identify workloads for which the range TLB provides little benefit and disable the range TLB (see Section 6), eliminating its dynamic energy.</p><p>To further explore power and energy impact of the range TLB on the address translation path, we implemented a 32entry range TLB and a 512-entry L2 page TLB with search latency of six cycles in Bluespec. We then synthesized both designs with the Cadence RTL Compiler using 45nm technology (tsmc45gs standard cell library) at 3.49GHz under typical conditions. We specified that timing should be prioritized over area and power.* This analysis shows that the range TLB adds power that is less than half (39.6%) of L2 TLB's power. Moreover, the range TLB area is only 13% of the L2 TLB area. These results and the high range TLB hit ratio indicate that simply increasing the number of entries in the L2 TLB, which would also incur a cycle penalty on the critical path, at the same power and area budget will not be as effective as the RMM design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Related Work</head><p>Virtual memory remains an active area of research. Previous work shows that limited TLB reach results in costly pagewalks that degrade application performance, often substan-tially <ref type="bibr" target="#b8">[10,</ref><ref type="bibr" target="#b11">13,</ref><ref type="bibr" target="#b12">14,</ref><ref type="bibr" target="#b21">23,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b29">31]</ref>. Section 2 described the qualitative differences between RMM and the most closely related work on multipage mappings (sub-blocked TLBs <ref type="bibr" target="#b45">[47]</ref>, CoLT <ref type="bibr" target="#b37">[39]</ref>, Clustered TLBs <ref type="bibr" target="#b36">[38]</ref>), huge pages <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">6,</ref><ref type="bibr" target="#b34">36]</ref>, and direct segments <ref type="bibr" target="#b8">[10,</ref><ref type="bibr" target="#b21">23]</ref>, and Section 8 showed quantitatively that RMM substantially improves over them. Below we discuss other mechanisms that help reduce the overhead of TLB misses, and how they relate to RMM.</p><p>One common way to reduce the cost of a TLB miss is through accelerating the page-walks. Commodity processors cache Page Table Entries (PTEs) in data caches to accelerate page-walks <ref type="bibr" target="#b26">[28]</ref>. Software-defined TLB structures, such as TSBs in SPARC <ref type="bibr" target="#b44">[46]</ref> and software-managed sections of TLB in Intel Itanium <ref type="bibr" target="#b2">[3]</ref>, pin entries in the TLB to improve performance. MMU caches also reduce latency of page-walks by caching intermediate levels of the page table, skipping one or more memory references during the page-walk <ref type="bibr" target="#b6">[8,</ref><ref type="bibr" target="#b10">12,</ref><ref type="bibr" target="#b25">27]</ref>. RMM is orthogonal to these approaches since it eliminates some page-walks altogether. When page-walks are required in RMM, these mechanisms can accelerate them.</p><p>Virtual memory overhead can also be reduced by lowering the number of TLB misses. For instance, the hardware can prefetch PTEs in to the TLB in advance of their use <ref type="bibr" target="#b12">[14,</ref><ref type="bibr" target="#b28">30,</ref><ref type="bibr" target="#b40">42]</ref>. However, the effectiveness of prefetching is limited by the predictability of the memory access patterns. Alternatively, Barr et al. <ref type="bibr" target="#b7">[9]</ref> proposed speculative translation based on huge pages. Similar to prefetching, this mechanism depends on the TLB behavior and favors sequential patterns. Last-level shared TLBs <ref type="bibr" target="#b11">[13,</ref><ref type="bibr" target="#b32">34]</ref> and cooperative TLBs <ref type="bibr" target="#b43">[45]</ref> increase the TLB reach and reduce the number of page-walks. Similarly, Papadopoulou et al. <ref type="bibr" target="#b35">[37]</ref> proposed a prediction mechanism that allows all page sizes to share a single setassociative TLB. In addition, Du et al. <ref type="bibr" target="#b18">[20]</ref> proposed mechanisms to allow huge pages to be formed even in the presence of retired physical pages. However, the total TLB reach is still limited for memory intensive applications since each TLB entry maps a single page unless ranges are used <ref type="bibr" target="#b29">[31]</ref>. In contrast to these approaches, RMM generates and caches translations for arbitrarily large ranges. Thus RMM is less susceptible to irregularities in the application's access patterns and improves address translation for large memories.</p><p>Commercial processors have also used segmentation to implement virtual memory. The Burroughs B5000 <ref type="bibr" target="#b31">[33]</ref> was an early user of pure segments. The 8086 <ref type="bibr" target="#b1">[2]</ref> and iAPX 432 <ref type="bibr" target="#b24">[26]</ref> processors also supported pure segmentation without paging. Later IA-32 processors provided segments on top of paging <ref type="bibr" target="#b27">[29]</ref>, but without any translation benefits for segments. In contrast to previous segmentation approaches, RMM combines the flexibility and robustness of paging while enjoying the translation performance of segmentation.</p><p>Prior work also proposes virtual caches to reduce the performance and energy overheads of the TLB by only translating after a cache miss <ref type="bibr" target="#b9">[11,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b48">50]</ref>. However for those workloads that suffer many TLB misses due to poor locality, virtual caches just shift the translation to a lower level of the cache hierarchy while increasing the complexity of the system.</p><p>Finally, our proposed architecture resembles prior works in fine-grained memory protection <ref type="bibr" target="#b22">[24,</ref><ref type="bibr" target="#b46">48,</ref><ref type="bibr" target="#b47">49]</ref>, in the sense that both exploit range behavior. However, instead of exploiting only the contiguity of fine-grained protection rights across memory regions, RMM enhances and exploits the contiguity in memory allocation to accelerate address translation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">Summary</head><p>We propose Redundant Memory Mappings, a novel and robust translation mechanism, that improves performance by reducing the cost of virtual memory across all our workloads. RMM efficiently represents ranges of arbitrarily-many pages that are virtually and physically contiguous and layers this representation and its hardware redundantly to page tables and paging hardware. RMM requires only modest changes to existing hardware and operating systems. The resulting system delivers a virtual memory system that is high performance, flexible, and completely transparent to applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Range translation: an efficient representation of contiguous virtual pages mapped to contiguous physical pages.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: RMM hardware support consists primarily of a range TLB that is accessed in parallel with the last-level page TLB.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: RMM memory allocator pseudocode for an allocation request of number of pages. When memory fragmentation is low, RMM uses eager paging to allocate pages at requesttime, creating the largest possible range for the allocation request. Otherwise, RMM uses default demand paging to allocates pages at access-time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>T ideal = T 2M -C 2M Average page-walk cost AvgC 4K/2M = C 4K/2M /M 4K/2M Measured page-walk overhead Over 4K/2M = C 4K/2M /T ideal Simulated page-walk overhead Over SIM = M SIM * AvgC 4K /T ideal T: Total execution cycles M 4K/2M : page-walks with 4K/2M C: Cycles spent in page-walks M SIM : Simulated page-walks</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Execution time overheads due to page-walks for SPEC 2006 and PARSEC (top) big-memory and BioBench (bottom) workloads. GUPS uses the right y-axis and thus shaded separately. 1GB pages are only applicable to big-memory workloads.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Range TLB miss ratio as a function of the number of range TLB entries.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 : Comparison of Redundant Memory Mappings with previous approaches for reducing virtual memory overhead.</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>BASE 1</cell><cell>LIMIT 1</cell><cell>BASE 2</cell><cell>LIMIT 2</cell></row><row><cell>Virtual Address</cell><cell cols="2">Space</cell><cell></cell></row><row><cell cols="3">Range</cell><cell>OFFSET 1</cell><cell>OFFSET 2</cell><cell>Range Translation 2</cell></row><row><cell cols="3">Translation 1</cell><cell></cell></row><row><cell cols="2">Physical Address</cell><cell>Space</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 : Total translation entries mapping the application's memory with: (i) Transparent Huge Pages of 4 KB and 2 MB pages [6] and (ii) ideal RMM ranges of contiguous virtual pages to contiguous physical pages. (iii) Number of ranges that map 99% of the application's memory, and (iv) percentage of application memory mapped by the single largest range.</head><label>2</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell>summarizes the characteristics of these approaches and</cell></row><row><cell>compares them to RMM. RMM is completely transparent to</cell></row><row><cell>applications and maps multiple ranges with no size-alignment</cell></row><row><cell>restrictions, where each range contains an unrestricted amount</cell></row><row><cell>of memory.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Page Table Physical Address Space Range Translation 2</head><label></label><figDesc></figDesc><table><row><cell>Range Table</cell><cell></cell><cell></cell><cell></cell></row><row><cell>(BASE1, LIMIT1) ?</cell><cell></cell><cell></cell><cell></cell></row><row><cell>(OFFSET1 + Protection)</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Range Tanslation 1</cell><cell></cell><cell></cell></row><row><cell>BASE 1</cell><cell>LIMIT 1</cell><cell>BASE 2</cell><cell>LIMIT 2</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Virtual</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Address</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Space</cell></row><row><cell>OFFSET 1</cell><cell></cell><cell>OFFSET 2</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Figure 2: Redundant Memory Mappings design. The appli- cation's memory space is represented redundantly by both pages and range translations.</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 : Overview of Redundant Memory Mapping</head><label>3</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>The range table stores the range translations for a process in memory. The OS manages the range table entries based on the applications memory management operations.</head><label></label><figDesc>table entry. The page table walker fetches the PTE, and if the range bit is set, accesses the range table in the background. Without this hint, available from redundancy, the range table walker would have to check the range table on every TLB miss. Alternatively, hardware could use prediction to decide whether to access the range table, which requires no changes to page table entries, but we did not evaluate this option. Walking the range table. Similar to the page table walker, RMM introduces the range table walker that consists of two comparators and a hardware state machine. The range table walker walks the range table in the background starting from the CR-RT register. The walker compares the missing address with the range translations in each range table node and follows the child pointers until it finds the corresponding range translation and installs it in the range TLB. To simplify the hardware, an OS handler could perform the range table lookup.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Range Translation or</cell></row><row><cell></cell><cell>47</cell><cell cols="2">Range Table Entry 12 47</cell><cell>12</cell></row><row><cell>CR-RT</cell><cell>RTEC RTED RTEF RTEG</cell><cell>BASE</cell><cell>LIMIT</cell></row><row><cell></cell><cell></cell><cell cols="2">OFFSET + Protection</cell></row><row><cell></cell><cell></cell><cell>64</cell><cell>0</cell></row><row><cell>RTEA RTEB</cell><cell>RTEE</cell><cell>RTEH RTEI</cell><cell></cell></row><row><cell>Figure 4:</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>At allocation request time</figDesc><table><row><cell>compute the memory fragmentation;</cell></row><row><cell>if memory fragmentation ? threshold then</cell></row><row><cell>// use eager paging;</cell></row><row><cell>while number of pages &gt; 0 do</cell></row><row><cell>for (i = MAX_ORDER-1; i ? 0; i-) do</cell></row><row><cell>if freelist[i] ? 0 and 2 i ? number of pages</cell></row><row><cell>then</cell></row><row><cell>allocate block of 2 i pages;</cell></row><row><cell>for all 2 i pages of the allocated block do</cell></row><row><cell>construct and set the PTE;</cell></row><row><cell>end</cell></row><row><cell>add the block to the range table;</cell></row><row><cell>number of pages -= 2 i ;</cell></row><row><cell>break;</cell></row><row><cell>end</cell></row><row><cell>end</cell></row><row><cell>end</cell></row><row><cell>else</cell></row><row><cell>// high memory fragmentation -use demand paging;</cell></row><row><cell>for (i = 0; i &lt; number of pages; i++) do</cell></row><row><cell>allocate the PTE;</cell></row><row><cell>set the PTE as invalid so that the first access will</cell></row><row><cell>trigger a page fault and the page will get</cell></row><row><cell>allocated;</cell></row><row><cell>end</cell></row><row><cell>end</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 4 : Workload description and memory footprint.</head><label>4</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 5 : System configurations and per-core TLB hierarchy.</head><label>5</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 6 : Performance model based on hardware performance counters and BadgerTrap.</head><label>6</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 7 : Impact of eager paging on ranges, time, and memory compared to demand paging (with Transparent Huge Pages).</head><label>7</label><figDesc></figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We thank our anonymous reviewers and <rs type="person">Dan Gibson</rs> for their insightful comments and feedback on the paper. We thank <rs type="institution">Wisconsin Computer Architecture Affiliates</rs> for their feedback on an early version of the work. We thank <rs type="person">Oriol Arcas</rs> and <rs type="person">Ivan Ratkovic</rs> for the Bluespec implementation and the synthesis results of the range TLB.</p><p>This work is supported in part by the <rs type="funder">European Union</rs> (<rs type="programName">FEDER funds</rs>) under contract <rs type="grantNumber">TIN2012-34557</rs>, the <rs type="funder">European Union</rs>'s <rs type="programName">Seventh Framework Programme</rs> (<rs type="grantNumber">FP7/2007-2013</rs>) under the <rs type="projectName">ParaDIME</rs> project (GA no. <rs type="grantNumber">318693</rs>), the <rs type="funder">National Science Foundation</rs> (<rs type="grantNumber">CCF-1218323</rs>, <rs type="grantNumber">CNS-1302260</rs> and <rs type="grantNumber">CCF-1438992</rs>), <rs type="funder">Google</rs>, and the <rs type="funder">University of Wisconsin</rs> (Kellett award and Named professorship to Hill). Furkan Ayar's contribution to the paper occurred while on internship at <rs type="institution">Barcelona Supercomputing Center. Vasilis Karakostas</rs> is also supported by an <rs type="funder">FPU</rs> research grant from the <rs type="funder">Spanish MEC</rs>. Hill has a significant financial interest in AMD.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_zY8kD38">
					<idno type="grant-number">TIN2012-34557</idno>
					<orgName type="program" subtype="full">FEDER funds</orgName>
				</org>
				<org type="funded-project" xml:id="_ZPApDcU">
					<idno type="grant-number">FP7/2007-2013</idno>
					<orgName type="project" subtype="full">ParaDIME</orgName>
					<orgName type="program" subtype="full">Seventh Framework Programme</orgName>
				</org>
				<org type="funding" xml:id="_3ZhjPZZ">
					<idno type="grant-number">318693</idno>
				</org>
				<org type="funding" xml:id="_gG2Jy4S">
					<idno type="grant-number">CCF-1218323</idno>
				</org>
				<org type="funding" xml:id="_T7X7jKj">
					<idno type="grant-number">CNS-1302260</idno>
				</org>
				<org type="funding" xml:id="_PXVxEPk">
					<idno type="grant-number">CCF-1438992</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Huge Pages Part 1 (Introduction)</title>
		<ptr target="http://lwn.net/Articles/374424/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Intel 8086 -Wikipedia</title>
		<ptr target="http://en.wikipedia.org/wiki/Intel_8086" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
		<ptr target="http://www.intel.com/content/www/us/en/processors/itanium/itanium-architecture-s-oftware-developer-rev-2-3-vol-2-manual.html" />
	</analytic>
	<monogr>
		<title level="j">Intel R itanium R architecture developer&apos;s manual</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<ptr target="https://perf.wiki.kernel.org/index.php/Main_Page" />
		<title level="m">Linux profiling with performance counters</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Transparent Huge Pages in 2.6.38</title>
		<ptr target="http://lwn.net/Articles/423584/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">BioBench: A Benchmark Suite of Bioinformatics Applications</title>
		<author>
			<persName><forename type="first">K</forename><surname>Albayraktaroglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jaleel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Symposium on Performance Analysis of Systems and Software</title>
		<meeting>the IEEE International Symposium on Performance Analysis of Systems and Software</meeting>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="page" from="2" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Translation Caching: Skip, Don&apos;T Walk (the Page Table)</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rixner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th Annual International Symposium on Computer Architecture</title>
		<meeting>the 37th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="48" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">SpecTLB: A Mechanism for Speculative Address Translation</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rixner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th Annual International Symposium on Computer Architecture</title>
		<meeting>the 38th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="307" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Efficient Virtual Memory for Big Memory Servers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual International Symposium on Computer Architecture</title>
		<meeting>the 40th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="237" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Reducing Memory Reference Energy with Opportunistic Virtual Caching</title>
		<author>
			<persName><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th Annual International Symposium on Computer Architecture</title>
		<meeting>the 39th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="297" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Large-reach Memory Management Unit Caches</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 46th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="383" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Shared Last-level TLBs for Chip Multiprocessors</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lustig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th IEEE International Symposium on High Performance Computer Architecture</title>
		<meeting>the 17th IEEE International Symposium on High Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="62" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Characterizing the TLB Behavior of Emerging Parallel Workloads on Chip Multiprocessors</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on Parallel Architectures and Compilation Techniques</title>
		<meeting>the 18th International Conference on Parallel Architectures and Compilation Techniques</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="29" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Benchmarking Modern Multiprocessors</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bienia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011-01">January 2011</date>
		</imprint>
		<respStmt>
			<orgName>Princeton University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Translation Lookaside Buffer Consistency: A Software Approach</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Rashid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<meeting>the Third International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="113" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Immix: A Mark-region Garbage Collector with Space Efficiency, Fast Collection, and Mutator Performance</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Blackburn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Mckinley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM SIGPLAN Conference on Programming Language Design and Implementation</title>
		<meeting>the 2008 ACM SIGPLAN Conference on Programming Language Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="22" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Limitations of partial compaction: Towards practical bounds</title>
		<author>
			<persName><forename type="first">N</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Petrank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGPLAN Not</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="309" to="320" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Inter-array Data Regrouping</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Workshop on Languages and Compilers for Parallel Computing</title>
		<meeting>the 12th International Workshop on Languages and Compilers for Parallel Computing</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="149" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Supporting superpages in non-contiguous physical memory</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Childers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Melhem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st IEEE International Symposium on High Performance Computer Architecture</title>
		<meeting>the 21st IEEE International Symposium on High Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2015-02">Feb 2015</date>
			<biblScope unit="page" from="223" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Clearing the Clouds: A Study of Emerging Scale-out Workloads on Modern Hardware</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Adileh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kocberber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Volos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alisafaee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jevdjic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kaynak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<meeting>the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="37" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">BadgerTrap: A Tool to Instrument x86-64 TLB Misses</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGARCH Comput. Archit. News</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="20" to="23" />
			<date type="published" when="2014-09">Sep. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Efficient Memory Virtualization: Reducing Dimensionality of Nested Page Walks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO-47: Proceedings of the 47th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="178" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Case for Unlimited Watchpoints</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Greathouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Austin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<meeting>the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="159" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">SPEC CPU2006 Benchmark Descriptions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Henning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGARCH Comput. Archit. News</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2006-09">Sep. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Introduction to the iAPX 432 Architecture</title>
		<imprint>
			<date type="published" when="1981">1981</date>
			<biblScope unit="page" from="171821" to="171821" />
		</imprint>
		<respStmt>
			<orgName>Intel Corporation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">TLBs, Paging-Structure Caches and their Invalidation</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="317080" to="317083" />
		</imprint>
		<respStmt>
			<orgName>Intel Corporation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Intel R 64 and IA-32 Architectures Optimization Reference Manual</title>
		<imprint>
			<date type="published" when="2012-04">April 2012</date>
			<biblScope unit="page" from="248966" to="248992" />
		</imprint>
		<respStmt>
			<orgName>Intel Corporation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Virtual Memory in Contemporary Microprocessors</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mudge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="60" to="75" />
			<date type="published" when="1998-07">Jul. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Going the Distance for TLB Prefetching: An Application-driven Study</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Kandiraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sivasubramaniam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual International Symposium on Computer Architecture</title>
		<meeting>the 29th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="195" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Performance Analysis of the Memory Management Unit under Scale-out Workloads</title>
		<author>
			<persName><forename type="first">V</forename><surname>Karakostas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">S</forename><surname>Unsal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nemirovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cristal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Swift</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 IEEE International Symposium on Workload Characterization</title>
		<meeting>the 2014 IEEE International Symposium on Workload Characterization</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Bitwise Competition Logic for Compact Digital Comparator</title>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 IEEE Asian Solid-State Circuits Conference</title>
		<meeting>the 2007 IEEE Asian Solid-State Circuits Conference</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Design of the b 5000 system</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lonehgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Datamation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="1961-05">May 1961</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">TLB Improvements for Chip Multiprocessors: Inter-Core Cooperative Prefetchers and Shared Last-Level TLBs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lustig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Archit. Code Optim</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="2" />
			<date type="published" when="2013-04">Apr. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">MIPS32 Architecture for Programmers Volume iii: The MIPS Privileged Resource Architecture</title>
		<author>
			<orgName type="collaboration">MIPS Technologies</orgName>
		</author>
		<idno>MD00090</idno>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note>Incorporated. Revision 0.95</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Practical, Transparent Operating System Support for Superpages</title>
		<author>
			<persName><forename type="first">J</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Druschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Symposium on Operating Systems Design and implementation</title>
		<meeting>the 5th Symposium on Operating Systems Design and implementation</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="89" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Prediction-based superpage-friendly TLB designs</title>
		<author>
			<persName><forename type="first">M.-M</forename><surname>Papadopoulou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st IEEE International Symposium on High Performance Computer Architecture</title>
		<meeting>the 21st IEEE International Symposium on High Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2015-02">Feb 2015</date>
			<biblScope unit="page" from="210" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Increasing TLB reach by exploiting clustering in page translations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Eckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Loh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th IEEE International Symposium on High Performance Computer Architecture</title>
		<meeting>the 20th IEEE International Symposium on High Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="558" to="567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">CoLT: Coalesced Large-Reach TLBs</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vaidyanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jaleel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 45th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 2012 45th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="258" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">M7: Next Generation SPARC</title>
		<author>
			<persName><forename type="first">S</forename><surname>Phillips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Hot Chips: A Symposium on High Performance Chips</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">IBM Power Systems Performance Guide Implementing and Optimizing</title>
		<author>
			<persName><forename type="first">D</forename><surname>Quintero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chabrolles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dhandapani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Holloway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jadhav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kurian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Resende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Roden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zanatta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Recency-based TLB Preloading</title>
		<author>
			<persName><forename type="first">A</forename><surname>Saulsbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dahlgren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stenstr?m</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th Annual International Symposium on Computer Architecture</title>
		<meeting>the 27th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="117" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A Case for Two-way Skewed-associative Caches</title>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Annual International Symposium on Computer Architecture</title>
		<meeting>the 20th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="169" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Golla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Grohoski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Barreh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Levinsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Luttrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Samoail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Smittle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ziaja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sparc T4: A Dynamically Threaded Server-on-a-Chip</title>
		<imprint>
			<date type="published" when="2012-03">Mar. 2012</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Synergistic TLBs for High Performance Address Translation in Chip Multiprocessors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Srikantaiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kandemir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 43rd Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="313" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">UltraSPARC T2 Supplement to the UltraSPARC Architecture</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>Sun Microsystems</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Surpassing the TLB Performance of Superpages with Less Operating System Support</title>
		<author>
			<persName><forename type="first">M</forename><surname>Talluri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<meeting>the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="171" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A Small Cache of Large Ranges: Hardware Methods for Efficiently Searching, Storing, and Updating Big Dataflow Tags</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tiwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mysore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Valamehr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sherwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 41st Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="94" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Mondrian Memory Protection</title>
		<author>
			<persName><forename type="first">E</forename><surname>Witchel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Asanovi?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<meeting>the 10th International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="304" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">An In-cache Address Translation Mechanism</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Eggers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Pendleton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Annual International Symposium on Computer Architecture</title>
		<meeting>the 13th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="358" to="365" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
