<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Under review as a conference paper at ICLR 2021 FAIRFIL: CONTRASTIVE NEURAL DEBIASING METHOD FOR PRETRAINED TEXT ENCODERS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<title level="a" type="main">Under review as a conference paper at ICLR 2021 FAIRFIL: CONTRASTIVE NEURAL DEBIASING METHOD FOR PRETRAINED TEXT ENCODERS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Pretrained text encoders, such as BERT, have been applied increasingly in various natural language processing (NLP) tasks, showing significant performance gains. However, recent studies have demonstrated the existence of social bias in these pretrained NLP models. Although prior works have made progress on word-level debiasing, improved sentence-level fairness of pretrained encoders still lacks exploration. In this paper, we proposed the first neural debiasing method for a pretrained sentence encoder, which transforms the pretrained encoder outputs into debiased representations via a fair filter (FairFil) network. To learn the Fair-Fil, we introduced a contrastive learning framework that not only minimizes the correlation between filtered embeddings and bias words but also preserves rich semantic information of the original sentences. On real-world datasets, our FairFil effectively reduces the bias degree of pretrained text encoders, while continuously showing desirable performance on downstream tasks. Moreover, our post-hoc method does not require any retraining of the text encoders, which further enlarges FairFil's application scenarios.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>A text encoder, which maps raw-text data into low-dimensional embeddings, has become one of the fundamental tools for extensive tasks in natural language processing <ref type="bibr">(Mikolov et al., 2013b;</ref><ref type="bibr" target="#b23">Kiros et al., 2015;</ref><ref type="bibr" target="#b27">Lin et al., 2017)</ref>. With the development of deep learning, large-scale neural sentence encoders pretrained on massive text corpora, such as Infersent <ref type="bibr" target="#b11">(Conneau et al., 2017)</ref>, <ref type="bibr">ELMo (Peters et al., 2018)</ref>, BERT <ref type="bibr" target="#b13">(Devlin et al., 2019)</ref>, and GPT <ref type="bibr" target="#b41">(Radford et al., 2018)</ref>, have become the mainstream to extract the sentence-level text representations, and shown desirable performance on many NLP downstream tasks <ref type="bibr" target="#b30">(MacAvaney et al., 2019;</ref><ref type="bibr" target="#b46">Sun et al., 2019;</ref><ref type="bibr" target="#b53">Zhang et al., 2019)</ref>. Although these pretrained models have been studied comprehensively from many perspectives, such as performance <ref type="bibr" target="#b20">(Joshi et al., 2020)</ref>, efficiency <ref type="bibr" target="#b42">(Sanh et al., 2019)</ref>, and robustness <ref type="bibr" target="#b28">(Liu et al., 2019)</ref>, the fairness of pretrained text encoders has not received significant research attention.</p><p>The fairness issue is also broadly recognized as social bias, which denotes the unbalanced model behaviors with respect to some socially sensitive topics, such as gender, race, and religion <ref type="bibr" target="#b26">(Liang et al., 2020)</ref>. For data-driven NLP models, social bias is an intrinsic problem mainly caused by the unbalanced data of text corpora <ref type="bibr" target="#b3">(Bolukbasi et al., 2016)</ref>. To quantitatively measure the bias degree of models, prior works proposed several statistical tests <ref type="bibr" target="#b6">(Caliskan et al., 2017;</ref><ref type="bibr" target="#b7">Chaloner &amp; Maldonado, 2019;</ref><ref type="bibr" target="#b5">Brunet et al., 2019)</ref>, mostly focusing on word-level embedding models. To evaluate the sentence-level bias in embedding spaces, <ref type="bibr" target="#b32">May et al. (2019)</ref> extended the Word Embedding Association Test (WEAT) <ref type="bibr" target="#b6">(Caliskan et al., 2017)</ref> into a Sentence Encoder Association Test (SEAT). Based on the SEAT test, <ref type="bibr" target="#b32">May et al. (2019)</ref> claimed the existence of social bias in the pretrained sentence encoders.</p><p>Although related works have discussed the measurement of social bias in sentence embeddings, how to debias the pretrained sentence encoders remains a challenge. Previous word embedding debiasing methods <ref type="bibr" target="#b3">(Bolukbasi et al., 2016;</ref><ref type="bibr" target="#b21">Kaneko &amp; Bollegala, 2019;</ref><ref type="bibr" target="#b31">Manzini et al., 2019)</ref> have limited assistance to sentence-level debiasing, because even if the social bias is eliminated at the word level, the sentence-level bias can still be caused by the unbalanced combination of words in the training text. Besides, retraining the state-of-the-art sentence encoder for debiasing requires a massive amount of computational resources, especially for large-scale deep models like BERT <ref type="bibr" target="#b13">(Devlin et al., 2019)</ref> and GPT <ref type="bibr" target="#b41">(Radford et al., 2018)</ref>. To the best of our knowledge, <ref type="bibr" target="#b26">Liang et al. (2020)</ref> proposed the only sentence-level debiasing method (Sent-Debias) for the pretrained text encoders, in which the embeddings are revised by subtracting the latent biased direction vectors learned by Principal Component Analysis (PCA) <ref type="bibr" target="#b52">(Wold et al., 1987)</ref>. However, Sent-Debias makes a strong assumption on the linearity of the bias in the sentence embedding space. Further, the calculation of bias directions depends highly on the embeddings extracted from the training data and the number of principal components, which prevents the method from adequate generalization.</p><p>In this paper, we proposed the first neural debiasing method for pretrained sentence encoders. For a given pretrained encoder, our method learns a fair filter (FairFil) network, whose inputs are the original embeddings of the encoder, and outputs are the debiased embeddings. Inspired by the multi-view contrastive learning <ref type="bibr" target="#b8">(Chen et al., 2020)</ref>, for each training sentence, we first generate an augmentation that has the same semantic meaning but in a different potential bias direction. We contrastively train our FairFil by maximizing the mutual information between the debiased embeddings of the original sentences and corresponding augmentations. To further eliminate bias from sensitive words in sentences, we introduce a debiasing regularizer, which minimizes the mutual information between debiased embeddings and the sensitive words' embeddings. In the experiments, our Fair-Fil outperforms Sent-Debias <ref type="bibr" target="#b26">(Liang et al., 2020)</ref> in terms of the fairness and the representativeness of debiased embeddings, indicating our FairFil not only effectively reduces the social bias in the sentence embeddings, but also successfully preserves the rich semantic meaning of input text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARIES</head><p>Mutual Information (MI) is a measure of the "amount of information" between two variables <ref type="bibr" target="#b24">(Kullback, 1997)</ref>. The mathematical definition of MI is</p><formula xml:id="formula_0">I(x; y) := E p(x,y) log p(x, y) p(x)p(y) ,<label>(1)</label></formula><p>where p(x, y) is the joint distribution of two variables (x, y), and p(x), p(y) are the marginal distributions of x, y respectively. Recently, mutual information has achieved considerable success when applied as a learning criterion into diverse deep learning tasks, such as conditional generation <ref type="bibr" target="#b9">(Chen et al., 2016)</ref>, domain adaptation <ref type="bibr" target="#b15">(Gholami et al., 2020)</ref>, representation learning <ref type="bibr" target="#b8">(Chen et al., 2020)</ref>, and fairness <ref type="bibr" target="#b44">(Song et al., 2019)</ref>. However, the calculation of exact MI in (1) is well-recognized as a challenge, because the expectation w.r.t p(x, y) is always intractable, especially when only samples from p(x, y) are provided. To this end, several upper and lower bounds have been introduced to estimate the MI value with samples. For MI maximization tasks <ref type="bibr" target="#b19">(Hjelm et al., 2018;</ref><ref type="bibr" target="#b8">Chen et al., 2020</ref><ref type="bibr" target="#b36">), Oord et al. (2018)</ref> derived a powerful MI estimator InfoNCE based on the noise contrastive estimation (NCE) <ref type="bibr" target="#b17">(Gutmann &amp; Hyv?rinen, 2010)</ref>. Given a batch of sample pairs {(x i , y i )} N i=1 , the InfoNCE estimator is defined with a learnable score function f (x, y):</p><formula xml:id="formula_1">I NCE := 1 N N i=1 log exp(f (x i , y i )) 1 N N j=1 exp(f (x i , y j ))</formula><p>.</p><p>(2)</p><p>For MI minimization tasks <ref type="bibr" target="#b0">(Alemi et al., 2017;</ref><ref type="bibr" target="#b44">Song et al., 2019)</ref>, <ref type="bibr" target="#b10">Cheng et al. (2020)</ref> introduced a contrastive log-ratio upper bound (CLUB) based on a variational approximation q ? (y|x) of conditional distribution p(y|x):</p><formula xml:id="formula_2">I CLUB := 1 N N i=1 log q ? (y i |x i ) - 1 N N j=1</formula><p>log q ? (y j |x i ) .</p><p>(3)</p><p>In the following, we will use the above two MI estimators to induce the sentence encoder eliminating the biased information and preserving the semantic information from the original raw text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHOD</head><p>Suppose E(?) is a pretrained sentence encoder, which can encode a sentence x into low-dimensional embedding z = E(x). Each sentence x = (w 1 , w 2 , . . . , w L ) is a sequence of words. The embedding space of z has been recognized to have social bias in a series of studies <ref type="bibr" target="#b32">(May et al., 2019;</ref><ref type="bibr" target="#b25">Kurita et al., 2019;</ref><ref type="bibr" target="#b26">Liang et al., 2020)</ref>. To eliminate the social bias in the embedding space, we aim to learn a fair filter network f (?) on top of the sentence encoder E(?), such that the output embedding of our fair filter d = f (z) can be debiased. To train the fair filter, we design a multi-view contrastive learning scheme, which consists of three steps. First, for each input sentence x, we generate an augmented sentence x that has the same semantic meaning as x but in a different potential bias direction. Then, we maximize the mutual information between the original embedding z = f (x) and the augmented embedding z = f (x ) with the InfoNCE (Oord et al., 2018) contrastive loss. Further, we design a debiasing regularizer to minimize the mutual information between d and sensitive attribute words in x. In the following, we discuss these three steps in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">DATA AUGMENTATIONS WITH SENSITIVE ATTRIBUTES</head><p>We first describe the sentence data augmentation process for our FairFil contrastive learning. Denote a social sensitive topic as</p><formula xml:id="formula_3">T = {D 1 , D 2 , . . . , D K }, where D k (k = 1, . . . , K</formula><p>) is one of the potential bias directions under the topic. For example, if T represents the sensitive topic "gender", then T consists two potential bias directions {D 1 , D 2 } = {"male", "female"}. Similarly, if T is set as the major "religions" of the world, then T could contain {D 1 , D 2 , D 3 , D 4 } = {"Christianity", "Islam", "Judaism", "Buddhism"} as four components.</p><p>For a given social sensitive topic T = {D 1 , . . . D K }, if a word w is related to one of the potential bias direction D k (denote as w ? D k ), we call w a sensitive attribute word of D k (also called bias attribute word in <ref type="bibr" target="#b26">Liang et al. (2020)</ref>). For a sensitive attribute word w ? D k , suppose we can always find another sensitive attribute word u ? D j , such that w and u has the equivalent semantic meaning but in a different bias direction. Then we call u as a replaceable word of w in direction D j , and denote as u = r j (w). For the topic "gender" = {"male", "female"}, the word w = "boy" is in the potential bias direction D 1 = "male"; a replaceable word of "boy" in "female" direction is r 2 (w) = "girl" ? D 2 .</p><p>With the above definitions, for each sentence x, we generate an augmented sentence x such that x has the same semantic meaning as x but in a different potential bias direction. More specifically, for a sentence x = (w 1 , w 2 , . . . , w L ), we first find the sensitive word positions as a index set P, such that each w p (p ? P) is a sensitive attribute words in direction D k . We further make a reasonable assumption that the embedding bias of direction D k is only caused by the sensitive words {w p } p?P in x. To sample an augmentation to x, we first select another potential bias direction D j , and then replace all sensitive attribute words by their replaceable words in the direction D j . That is, x = {v 1 , v 2 , . . . , v L }, where v l = w l if l / ? P, and v l = r j (w l ) if l ? P. In Table <ref type="table" target="#tab_0">1</ref>, we provide an example for sentence augmentation under the "gender" topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">CONTRASTIVE LEARNING FRAMEWORK</head><p>After obtaining the sentence pair (x, x ) with the augmentation strategy from Section 3.1, we construct a contrastive learning framework to learn our debiasing fair filter f (?). As shown in the Figure <ref type="figure" target="#fig_1">1</ref>(a), our framework consists of the following two steps:</p><p>(1) We encode sentences (x, x ) into embeddings (z, z ) with the pretrained encoder E(?). Since x and x have the same meaning but different potential bias directions, the embeddings (z, z ) will have different bias directions, which are caused by the sensitive attributed words in x and x .  </p><formula xml:id="formula_4">I NCE = 1 N N i=1 log exp(g(d i , d i )) 1 N N j=1 exp(g(d i , d j )) .<label>(4)</label></formula><p>By maximize I NCE , we encourage the difference between the positive pair score g(d i , d i ) and the negative pair score g(d i , d j ), so that d i can share more semantic information with d i than other embeddings d j =i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">DEBIASING REGULARIZER</head><p>Practically, the contrastive learning framework in Section 3.2 can already show encouraging debiasing performance (as shown in the Experiments). However, the embedding d can contain extra biased information from z, that only maximizing I(d; d ) fails to eliminate. To encourage no extra bias in d, we introduce a debiasing regularizer which minimizes the mutual information between embedding d and the potential bias from embedding z. As the discussion in Section 3.1, in our framework the potential bias of z is supposed to come from the sensitive attribute words in x. Therefore, we should reduce the bias word information from the debiased representation d. Let w p be the embedding of a sensitive attribute word w p in sentence x. The word embedding w p can always be obtained from the pretrained text encoders <ref type="bibr">(Bordia &amp; Bowman, 2019)</ref>. We then minimize the mutual information I(w p ; d). We use the CLUB mutual information upper bound <ref type="bibr" target="#b10">(Cheng et al., 2020)</ref> to estimate I(w p ; d) with embedding samples. Given a batch of embedding pairs {(d i , w p )} N i=1 , we can calculate the debiasing regularizer as:</p><formula xml:id="formula_5">I CLUB = 1 N N i=1 log q ? (w p i |d i ) - 1 N N j=1 log q ? (w p j |d i ) ,<label>(5)</label></formula><p>where q ? is a variational approximation to ground-truth conditional distribution p(w|d). We parameterize q ? with another neural network. As proved in <ref type="bibr" target="#b10">Cheng et al. (2020)</ref>, the better q ? (w|d) approximates p(w|d), the more accurate I CLUB serves as the mutual information upper bound. Therefore, besides the loss in (5), we also maximize the log-likelihood of q ? (w|d) with samples {(d i , w p i )} N i=1 . Based on the above sections, the overall learning scheme of our fair filter (FairFil) is described in Algorithm 1. Also, we provide an intuitive explanation to the two loss terms in our framework. In Figure <ref type="figure" target="#fig_1">1</ref> Algorithm 1 Updating the FairFil with a sample batch Begin with the pretrained text encoder E(?), and a batch of sentences {x i } N i=1 . Find the sensitive attribute words {w p } and corresponding embeddings {w p }. Generate augmentation x i from x i , by replacing {w p } with {r j (w p )}.</p><formula xml:id="formula_6">Encode (x i , x i ) into embeddings d i = f (E(x i )), d i = f (E(x i )). Calculate I NCE with {(d i , d i )} N</formula><p>i=1 and score function g. if adding debiasing regularizer then Update the variational approximation q ? (w|d) by maximizing log-likelihood with {(d i , w p i )} Calculate I CLUB with q ? (w|d) and {(d i , w p i )} N i=1 . Learning loss L = -I NCE + ?I CLUB . else</p><p>Learning loss L = -I NCE . end if Update FairFil f and score function g by gradient descent with respect to L.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">BIAS IN NATURAL LANGUAGE PROCESSING</head><p>Recently, social bias has been recognized as a rising issue in natural language processing (NLP) systems. The studies on bias in NLP are mainly classified into two categories: bias in the embedding spaces, and bias in downstream tasks <ref type="bibr" target="#b1">(Blodgett et al., 2020)</ref>. For bias in downstream tasks, the analyses cover comprehensive topics, including machine translation <ref type="bibr" target="#b45">(Stanovsky et al., 2019)</ref>, language modeling <ref type="bibr">(Bordia &amp; Bowman, 2019)</ref>, sentiment analysis <ref type="bibr" target="#b22">(Kiritchenko &amp; Mohammad, 2018)</ref> and toxicity detection <ref type="bibr" target="#b14">(Dixon et al., 2018)</ref>. The social bias in embedding spaces has been studied from two important perspectives: bias measurements and and debiasing methods. To measure the bias in an embedding space, <ref type="bibr" target="#b6">Caliskan et al. (2017)</ref> proposed a Word Embedding Association Test (WEAT), which compares the similarity between two sets of target words and two sets of attribute words. <ref type="bibr" target="#b32">May et al. (2019)</ref> further extended the WEAT to a Sentence Encoder Association Test (SEAT), which replaces the word embeddings by sentence embeddings encoded from pre-defined biased sentence templates. For debiasing methods, most of the prior works focus on word-level representations <ref type="bibr" target="#b3">(Bolukbasi et al., 2016;</ref><ref type="bibr">Bordia &amp; Bowman, 2019)</ref>. The only sentence-level debiasing method is proposed by <ref type="bibr" target="#b26">Liang et al. (2020)</ref>, which learns bias directions by PCA and subtracts them in the embedding space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">CONTRASTIVE LEARNING</head><p>Contrastive learning is a broad class of training strategies that learns meaningful representations by making positive and negative embedding pairs more distinguishable. Usually, contrastive learning requires a pairwise embedding critic as a similarity/distance of data pairs. Then the learning objective is constructed by maximizing the margin between the critic values of positive data pairs and negative data pairs. Previously contrastive learning has shown encouraging performance in extensive tasks, including metric learning <ref type="bibr" target="#b51">(Weinberger et al., 2006;</ref><ref type="bibr" target="#b12">Davis et al., 2007)</ref>, word representation learning <ref type="bibr">(Mikolov et al., 2013a)</ref>, graph learning <ref type="bibr" target="#b47">(Tang et al., 2015;</ref><ref type="bibr" target="#b16">Grover &amp; Leskovec, 2016)</ref>, etc. Recently, contrastive learning has been applied to the unsupervised visual representation learning task, and significantly reduced the performance gap between supervised and unsupervised learning <ref type="bibr" target="#b18">(He et al., 2020;</ref><ref type="bibr" target="#b8">Chen et al., 2020;</ref><ref type="bibr" target="#b40">Qian et al., 2020)</ref>. Among these unsupervised methods, <ref type="bibr" target="#b8">Chen et al. (2020)</ref> proposed a simple multi-view contrastive learning framework (SimCLR). For each image data, SimCLR generates two augmented images, and then the mutual information of the two augmentation embeddings is maximized within a batch of training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>We first describe the experimental setup in detail, including the pretrained encoders, the training of FairFil, and the downstream tasks. Then, we report and analyze the results of our FairFil along with the previous Sent-Debias method. In general, we evaluate our neural debiasing method from two perspectives: (1) fairness: we compare the bias degree of the original and debiased sentence embeddings for debiasing performance (2) representativeness: we apply the debiased embeddings into downstream tasks, and compare the performance with original embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">BIAS EVALUATION METRIC</head><p>To evaluate the bias in sentence embeddings, we use the Sentence Encoder Association Test (SEAT) <ref type="bibr" target="#b32">(May et al., 2019)</ref>, which is an extension of the Word Embedding Association Test (WEAT) <ref type="bibr" target="#b6">(Caliskan et al., 2017)</ref>. The WEAT test measures the bias in word embeddings by comparing the distances of two sets of target words to two sets of attribute words. More specifically, denote X and Y as two sets of target word embeddings (e.g., X includes "male" words such as "boy" and "man"; Y contains "female" words like "girl" and "woman"). The attribute sets A and B are selected from some social concepts that should be "equal" to X and Y (e.g., career or personality words). Then the bias degree w.r.t attributes (A, B) of each word embedding t is defined as:</p><formula xml:id="formula_7">s(t, A, B) = mean a?A cos(t, a) -mean b?B cos(t, b),<label>(6)</label></formula><p>where cos(?, ?) is the cosine similarity. Based on ( <ref type="formula" target="#formula_7">6</ref>), the normalized WEAT effect size is:</p><formula xml:id="formula_8">d WEAT = mean x?X s(x, A, B) -mean y?Y s(y, A, B) std t?X ?Y s(t, A, B) . (<label>7</label></formula><formula xml:id="formula_9">)</formula><p>The SEAT test extends WEAT by replacing the word embeddings with sentence embeddings. Both target words and attribute words are converted into sentences with several semantically bleached sentence templates (e.g., "This is &lt;word&gt;"). Then the SEAT statistic is similarly calculated with (7) based on the embeddings of converted sentences. The closer the effect size is to zero, the more fair the embeddings are. Therefore, we report the absolute effect size as the bias measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">PRETRAINED ENCODERS</head><p>We test our neural debiasing method on BERT <ref type="bibr" target="#b13">(Devlin et al., 2019)</ref>. Since the pretrained BERT requires the additional fine-tuning process for downstream tasks, we report the performance of our FairFil under two scenarios: (1) pretrained BERT: we directly learn our FairFil network based on pretrained BERT without any additional fine-tuning; (2) BERT post tasks: we fix the parameters of the FairFil network learned on pretrained BERT, then fine-tune the BERT+FairFil together on task-specific data. Note that when fine-tuning, our FairFil will no longer update, which satisfies a fair comparison to Sent-Debias <ref type="bibr" target="#b26">(Liang et al., 2020)</ref>.</p><p>For the downstream tasks of BERT, we follow the setup from Sent-Debias <ref type="bibr" target="#b26">(Liang et al., 2020)</ref> and conduct experiments on the following three downstream tasks: (1) SST-2: A sentiment classification task on the Stanford Sentiment Treebank (SST-2) dataset <ref type="bibr" target="#b43">(Socher et al., 2013)</ref>, on which sentence embeddings are used to predict the corresponding sentiment labels; (2) CoLA: Another sentiment classification task on the Corpus of Linguistic Acceptability (CoLA) grammatical acceptability judgment <ref type="bibr" target="#b50">(Warstadt et al., 2019)</ref>; (3) QNLI: A binary question answering task on the Question Natural Language Inference (QNLI) dataset <ref type="bibr" target="#b49">(Wang et al., 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">TRAINING OF FAIRFIL</head><p>We parameterize the fair filter network with one-layer fully-connected neural networks with the ReLU activation function. The score function g in the InfoNCE estimator is set to a two-layer fully-connected network with one-dimensional output. The variational approximation q ? in CLUB estimator is parameterized by a multi-variate Gaussian distribution q ? (w|d</p><formula xml:id="formula_10">) = N (?(d), ? 2 (d)),</formula><p>where ?(?) and ?(?) are also two-layer fully-connected neural nets. The batch size is set to 128. The learning rate is 1 ? 10 -5 . We train the fair filter for 10 epochs.</p><p>For an appropriate comparison, we follow the setup of Sent-Debias <ref type="bibr" target="#b26">(Liang et al., 2020)</ref> and select the same training data for the training of FairFil. The training corpora consist 183060 sentences from the following five datasets: WikiText-2 <ref type="bibr">(Merity et al.,</ref><ref type="bibr">201y)</ref>, Stanford Sentiment Treebank <ref type="bibr" target="#b43">(Socher et al., 2013)</ref>, Reddit (V"olske et al., 2017), MELD <ref type="bibr" target="#b39">(Poria et al., 2019)</ref> and POM <ref type="bibr" target="#b37">(Park et al., 2014)</ref>. Following <ref type="bibr" target="#b26">Liang et al. (2020)</ref>, we mainly select "gender" as the sensitive topic T , and use the same pre-defined word sets of sensitive attribute words and their replaceable words as Sent-Debias did.</p><p>The word embeddings for training the debiasing regularizer is selected from the token embedding of the pretrained BERT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">DEBIASING RESULTS</head><p>In Tables <ref type="table" target="#tab_1">2</ref> and<ref type="table" target="#tab_2">3</ref> we report the evaluation results of debiased embeddings on both the absolute SEAT effect size and the downstream classification accuracy. For the SEAT test, we follow the  <ref type="bibr" target="#b6">Caliskan et al. (2017)</ref>. The column name Origin refers to the original BERT results, and Sent-D is short for Sent-Debias <ref type="bibr" target="#b26">(Liang et al., 2020)</ref>. FairFil -and FairFil (as FairF -and FairF in the tables) are our method without/with the debiasing regularizer in Section 3.3. The best results of effect size (the lower the better) and classification accuracy (the higher the better) are bold among Sent-D, FairFil -, and FairFil. Since the pretrained BERT does not correspond to any downstream task, the classification accuracy is not reported for it.  <ref type="bibr" target="#b2">(Bojanowski et al., 2017)</ref> 0.565 BERT word <ref type="bibr" target="#b3">(Bolukbasi et al., 2016)</ref> 0.861 BERT simple <ref type="bibr" target="#b32">(May et al., 2019)</ref> 0.298 Sent-Debias <ref type="bibr" target="#b26">(Liang et al., 2020)</ref> 0.256</p><p>FairFil -(Ours) 0.179 FairFil (Ours) 0.150</p><p>From the SEAT test results, our contrastive learning framework effectively reduces the gender bias for both pretrained BERT and fine-tuned BERT under most test scenarios. Comparing with Sent-Debias, our FairFil reaches a lower bias degree on the majority of the individual SEAT tests. Considering the average of absolute effect size, our FairFil is distinguished by a significant margin to Sent-Debias. Moreover, our FairFil achieves higher downstream classification accuracy than Sent-Debias, which indicates learning neural filter networks can preserve more semantic meaning than subtracting bias directions learned from PCA.</p><p>For the ablation study, we also report the results of FairFil without the debiasing regularizer as in FairF -. Only with the contrastive learning framework, FairF -already reduces the bias effectively and even achieves better effect size than the FairF on some of the SEAT tests. With the debiasing regularizer, FairF has better average SEAT effect sizes but slightly loses in terms of the downstream performance. However, the overall performance of FairF and FairF -shows a trade-off between fairness and representativeness of the filter network.</p><p>We also compare the debiasing performance on a broader class of baselines including word-level debiasing methods, and report the average absolute SEAT effect size on the pretrained BERT encoder. Both FairF -and FairF achieve a lower bias degree than other baselines. The word-level debiasing methods (FastText <ref type="bibr" target="#b2">(Bojanowski et al., 2017)</ref> and BERT word <ref type="bibr" target="#b3">(Bolukbasi et al., 2016)</ref>) have the  To further study output debiased sentence embedding, we visualize the relative distances of attributes and targets of SEAT before/after our debiasing process. We choose the target words as "he" and "she". Attributes are selected from different social domains. We first contextualize the selected words into sentence templates as described in Section 5.1. Then, we average the original/debiased embeddings of these sentence template and plot the t-SNE <ref type="bibr" target="#b29">(Maaten &amp; Hinton, 2008)</ref> in Figure <ref type="figure" target="#fig_4">3</ref>. From the t-SNE, the debiased encoder provides more balanced distances from gender targets "he/she" to the attribute concepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>This paper has developed a novel debiasing method for large-scale pretrained text encoder neural networks. We proposed a fair filter (FairFil) network, which takes the original sentence embeddings as input and outputs the debiased sentence embeddings. To train the fair filter, we constructed a multi-view contrast learning framework, which maximizes the mutual information between each sentence and its augmentation. The augmented sentence is generated by replacing sensitive words in the original sentence with words in a similar semantic but different bias directions. Further, we designed a debiasing regularizer that minimizes the mutual information between the debiased embeddings and the corresponding sensitive words in sentences. Experimental results demonstrate the proposed FairFil not only reduces the bias in sentence embedding space, but also maintains the semantic meaning of the embeddings. This post-hoc method does not require access to the training corpora, or any retraining process of the pretrained text encoder, which enhances its applicability.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>( 2 )</head><label>2</label><figDesc>We then feed the sentence embeddings (z, z ) through our fair filter f (?) to obtain the debiased embedding outputs (d, d ). Ideally, d and d should represent the same semantic meaning without social bias. Inspired by SimCLR (Chen et al., 2020), we encourage the overlapped semantic information between d and d by maximizing their mutual information I(d; d ). However, the calculation of I(d; d ) is practically difficult because only embedding samples of d and d are available. Therefore, we use the InfoNCE mutual information estimator (Oord et al., 2018) to minimize the lower bound of I(d; d ) instead. Based on a learnable score function g(?, ?),</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: (a) Contrastive learning framework of FairFil: Sentence x and its augmentation x are encoded into embeddings d and d respectively. w p is the embedding of a sensitive attribute word selected from x. I NCE maximizes the mutual information between d and d ; I CLUB eliminates the bias information of w p from d. (b) Illustration of information in d and d : The blue and red circles represent the information in d and d , respectively. The intersection is the mutual information between d and d . The shadow area represents the bias information of both embeddings.</figDesc><graphic url="image-1.png" coords="4,127.80,81.86,356.40,120.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(b), the blue and red circles represent d and d respectively in the embedding space. The intersection I(d; d ) is the common semantic information extracted from sentences x and x , while the two shadow parts are the extra bias. Note that the perfect debiased embeddings lead to coincided circles. By maximizing I NCE term, we enlarge the overlapped area of d and d ; by minimizing I CLUB , we shrink the biased shadow parts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Influence of the training data proportion to debias degree of BERT.</figDesc><graphic url="image-2.png" coords="8,116.66,81.86,376.19,107.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: T-SNE plots of sentence embedding mean of each words contextualized in templates. The left-hand side is from the original pretrained BERT; the right-hand side is from our FairFil.worst debiasing performance, which validates our observation that the word-level debiasing methods cannot reduce sentence-level social bias in NLP models.5.5 ANALYSISTo test the influence of data proportion on the model's debiasing performance, we select WikiText-2 with 13750 sentences as the training corpora following the setup in<ref type="bibr" target="#b26">Liang et al. (2020)</ref>. Then we randomly divide the training data into 5 equal-sized partitions. We evaluate the bias degree of the sentence debiasing methods on different combinations of the partitions, specifically with training data proportions (20%, 40% 60%, 80%, 100%). Under each data proportion, we repeat the training 5 times to obtain the mean and variance of the absolute SEAT effect size. In Figure2, we plot the bias degree of BERT post tasks with different training data proportions. In general, both Sent-Debias and FairFil achieve better performance and smaller variance when the proportion of training data goes larger. Under 20% training proportion, our FairFil can better remove bias in text encoder, which shows FairFil has better data efficiency with the contrastive learning framework.</figDesc><graphic url="image-4.png" coords="8,166.02,211.96,134.00,94.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Examples of generating an augmentation sentence under the sensitive topic "gender".</figDesc><table><row><cell></cell><cell cols="3">Bias direction Sensitive Attribute words Text content</cell></row><row><cell>Original</cell><cell>male</cell><cell>he, his</cell><cell>{He} is good at playing {his} basketball.</cell></row><row><cell cols="2">Augmentation female</cell><cell>she, her</cell><cell>{She} is good at playing {her} basketball.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Performance of debiased embeddings on Pretrained BERT and BERT post SST-2.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Pretrained BERT</cell><cell></cell><cell></cell><cell cols="2">BERT post SST-2</cell><cell></cell></row><row><cell></cell><cell cols="8">Origin Sent-D FairF -FairF Origin Sent-D FairF -FairF</cell></row><row><cell>Names, Career/Family</cell><cell>0.477</cell><cell>0.096</cell><cell cols="2">0.218 0.182</cell><cell>0.036</cell><cell>0.109</cell><cell cols="2">0.237 0.218</cell></row><row><cell>Terms, Career/Family</cell><cell>0.108</cell><cell>0.437</cell><cell cols="2">0.086 0.076</cell><cell>0.010</cell><cell>0.057</cell><cell cols="2">0.376 0.377</cell></row><row><cell>Terms, Math/Arts</cell><cell>0.253</cell><cell>0.194</cell><cell cols="2">0.133 0.124</cell><cell>0.219</cell><cell>0.221</cell><cell cols="2">0.301 0.263</cell></row><row><cell>Names, Math/Arts</cell><cell>0.254</cell><cell>0.194</cell><cell cols="2">0.101 0.082</cell><cell>1.153</cell><cell>0.755</cell><cell cols="2">0.084 0.099</cell></row><row><cell>Terms, Science/Arts</cell><cell>0.399</cell><cell>0.075</cell><cell cols="2">0.218 0.204</cell><cell>0.103</cell><cell>0.081</cell><cell cols="2">0.133 0.127</cell></row><row><cell>Names, Science/Arts</cell><cell>0.636</cell><cell>0.540</cell><cell cols="2">0.320 0.235</cell><cell>0.222</cell><cell>0.047</cell><cell cols="2">0.017 0.005</cell></row><row><cell>Avg. Abs. Effect Size</cell><cell>0.354</cell><cell>0.256</cell><cell cols="2">0.179 0.150</cell><cell>0.291</cell><cell>0.212</cell><cell cols="2">0.191 0.182</cell></row><row><cell>Classification Acc.</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>92.7</cell><cell>89.1</cell><cell>91.7</cell><cell>91.6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Performance of debiased embeddings on BERT post CoLA and BERT post QNLI.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">BERT post CoLA</cell><cell></cell><cell></cell><cell cols="2">BERT post QNLI</cell><cell></cell></row><row><cell></cell><cell cols="8">Origin Sent-D FairF -FairF Origin Sent-D FairF -FairF</cell></row><row><cell>Names, Career/Family</cell><cell>0.009</cell><cell>0.149</cell><cell cols="2">0.273 0.034</cell><cell>0.261</cell><cell>0.054</cell><cell cols="2">0.196 0.103</cell></row><row><cell>Terms, Career/Family</cell><cell>0.199</cell><cell>0.186</cell><cell cols="2">0.156 0.119</cell><cell>0.155</cell><cell>0.004</cell><cell cols="2">0.050 0.206</cell></row><row><cell>Terms, Math/Arts</cell><cell>0.268</cell><cell>0.311</cell><cell cols="2">0.008 0.092</cell><cell>0.584</cell><cell>0.083</cell><cell cols="2">0.306 0.323</cell></row><row><cell>Names, Math/Arts</cell><cell>0.150</cell><cell>0.308</cell><cell cols="2">0.060 0.101</cell><cell>0.581</cell><cell>0.629</cell><cell cols="2">0.168 0.288</cell></row><row><cell>Terms, Science/Arts</cell><cell>0.425</cell><cell>0.163</cell><cell cols="2">0.245 0.249</cell><cell>0.087</cell><cell>0.716</cell><cell cols="2">0.500 0.245</cell></row><row><cell>Names, Science/Arts</cell><cell>0.032</cell><cell>0.192</cell><cell cols="2">0.102 0.127</cell><cell>0.521</cell><cell>0.443</cell><cell cols="2">0.378 0.167</cell></row><row><cell>Avg. Abs. Effect Size</cell><cell>0.181</cell><cell>0.217</cell><cell cols="2">0.141 0.120</cell><cell>0.365</cell><cell>0.321</cell><cell cols="2">0.266 0.222</cell></row><row><cell>Classification Acc.</cell><cell>57.6</cell><cell>55.4</cell><cell>56.5</cell><cell>56.5</cell><cell>91.3</cell><cell>90.6</cell><cell>91.0</cell><cell>90.8</cell></row><row><cell cols="9">setup in Liang et al. (2020), and test the sentence templates of Terms/Names under different domains</cell></row><row><cell>designed by</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell cols="2">: Comparison of average debiasing per-</cell></row><row><cell>formance on pretrained BERT</cell><cell></cell></row><row><cell>Method</cell><cell>Bias Degree</cell></row><row><cell>BERT origin (Devlin et al., 2019)</cell><cell>0.354</cell></row><row><cell>FastText</cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep variational information bottleneck</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Alexander A Alemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">V</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Language (technology) is power: A critical survey of&quot; bias</title>
		<author>
			<persName><forename type="first">Lin</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Solon</forename><surname>Blodgett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hal</forename><surname>Barocas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iii</forename><surname>Daum?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanna</forename><surname>Wallach</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.14050</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">in nlp. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Man is to computer programmer as woman is to homemaker? debiasing word embeddings</title>
		<author>
			<persName><forename type="first">Tolga</forename><surname>Bolukbasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Venkatesh</forename><surname>Saligrama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><forename type="middle">T</forename><surname>Kalai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="4349" to="4357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Identifying and reducing gender bias in word-level language models</title>
		<author>
			<persName><forename type="first">Shikha</forename><surname>Bordia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
		<meeting>the 2019 Conference of the North American Chapter<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Student Research Workshop</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="7" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Understanding the origins of bias in word embeddings</title>
		<author>
			<persName><forename type="first">Marc-Etienne</forename><surname>Brunet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colleen</forename><surname>Alkalay-Houlihan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashton</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="803" to="811" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Semantics derived automatically from language corpora contain human-like biases</title>
		<author>
			<persName><forename type="first">Aylin</forename><surname>Caliskan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joanna</forename><forename type="middle">J</forename><surname>Bryson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">356</biblScope>
			<biblScope unit="issue">6334</biblScope>
			<biblScope unit="page" from="183" to="186" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Measuring gender bias in word embeddings across domains and discovering new gender bias word categories</title>
		<author>
			<persName><forename type="first">Kaytlin</forename><surname>Chaloner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alfredo</forename><surname>Maldonado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Gender Bias in Natural Language Processing</title>
		<meeting>the First Workshop on Gender Bias in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th international conference on Machine learning</title>
		<meeting>the 37th international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Infogan: Interpretable representation learning by information maximizing generative adversarial nets</title>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rein</forename><surname>Houthooft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2172" to="2180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Club: A contrastive log-ratio upper bound of mutual information</title>
		<author>
			<persName><forename type="first">Pengyu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weituo</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuyang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiachang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Carin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th international conference on Machine learning</title>
		<meeting>the 37th international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Supervised learning of universal sentence representations from natural language inference data</title>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lo?c</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Information-theoretic metric learning</title>
		<author>
			<persName><forename type="first">Jason V</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prateek</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suvrit</forename><surname>Sra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inderjit S</forename><surname>Dhillon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th international conference on Machine learning</title>
		<meeting>the 24th international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="209" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
		<meeting>the 2019 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Measuring and mitigating unintended bias in text classification</title>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Dixon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Sorensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nithum</forename><surname>Thain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucy</forename><surname>Vasserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society</title>
		<meeting>the 2018 AAAI/ACM Conference on AI, Ethics, and Society</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="67" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unsupervised multi-target domain adaptation: An information theoretic approach</title>
		<author>
			<persName><forename type="first">Pritish</forename><surname>Behnam Gholami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ognjen</forename><surname>Sahu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantinos</forename><surname>Rudovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName><surname>Pavlovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="3993" to="4002" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="855" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Noise-contrastive estimation: A new estimation principle for unnormalized statistical models</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyv?rinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the Thirteenth International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="297" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning deep representations by mutual information estimation and maximization</title>
		<author>
			<persName><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karan</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Spanbert: Improving pre-training by representing and predicting spans</title>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Daniel S Weld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><surname>Levy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="64" to="77" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Gender-preserving debiasing for pre-trained word embeddings</title>
		<author>
			<persName><forename type="first">Masahiro</forename><surname>Kaneko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danushka</forename><surname>Bollegala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.00742</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Examining gender and race bias in two hundred sentiment analysis systems</title>
		<author>
			<persName><forename type="first">Svetlana</forename><surname>Kiritchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saif</forename><surname>Mohammad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the Seventh Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="43" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Skip-thought vectors</title>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Russ R Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raquel</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanja</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3294" to="3302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Information theory and statistics</title>
		<author>
			<persName><forename type="first">Solomon</forename><surname>Kullback</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>Courier Corporation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Measuring bias in contextualized word representations</title>
		<author>
			<persName><forename type="first">Keita</forename><surname>Kurita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nidhi</forename><surname>Vyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayush</forename><surname>Pareek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Gender Bias in Natural Language Processing</title>
		<meeting>the First Workshop on Gender Bias in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="166" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Towards debiasing sentence representations</title>
		<author>
			<persName><forename type="first">Paul Pu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irene</forename><forename type="middle">Mengze</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis-Philippe</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><surname>Morency</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5502" to="5515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">A structured self-attentive sentence embedding</title>
		<author>
			<persName><forename type="first">Zhouhan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minwei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cicero</forename><surname>Nogueira Dos Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.03130</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><surname>Roberta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11">Nov. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Cedr: Contextualized embeddings for document ranking</title>
		<author>
			<persName><forename type="first">Sean</forename><surname>Macavaney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nazli</forename><surname>Goharian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1101" to="1104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Manzini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulia</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName><surname>Black</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.04047</idno>
		<title level="m">Black is to criminal as caucasian is to police: Detecting and removing multiclass bias in word embeddings</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">On measuring social biases in sentence encoders</title>
		<author>
			<persName><forename type="first">Chandler</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shikha</forename><surname>Bordia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><surname>Rudinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="622" to="628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Pointer sentinel mixture models</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Merity</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In ICLR, 201y</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<title level="m">Representation learning with contrastive predictive coding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Computational analysis of persuasiveness in social multimedia: A novel dataset and multimodal prediction approach</title>
		<author>
			<persName><forename type="first">Sunghyun</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suk</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moitreya</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenji</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis-Philippe</forename><surname>Sagae</surname></persName>
		</author>
		<author>
			<persName><surname>Morency</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on Multimodal Interaction</title>
		<meeting>the 16th International Conference on Multimodal Interaction</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="50" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Matthew E Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">MELD: A multimodal multi-party dataset for emotion recognition in conversations</title>
		<author>
			<persName><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devamanyu</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navonil</forename><surname>Majumder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="527" to="536" />
		</imprint>
	</monogr>
	<note>Gautam Naik, Erik Cambria, and Rada Mihalcea</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">Rui</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianjian</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huisheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.03800</idno>
		<title level="m">Spatiotemporal contrastive video representation learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Improving language understanding by generative pre-training</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter</title>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01108</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 conference on empirical methods in natural language processing</title>
		<meeting>the 2013 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning controllable fair representations</title>
		<author>
			<persName><forename type="first">Jiaming</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pratyusha</forename><surname>Kalluri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengjia</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 22nd International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2164" to="2173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Evaluating gender bias in machine translation</title>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1679" to="1684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Bert4rec: Sequential recommendation with bidirectional encoder representations from transformer</title>
		<author>
			<persName><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changhua</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1441" to="1450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Line: Large-scale information network embedding</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingzhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th international conference on world wide web</title>
		<meeting>the 24th international conference on world wide web</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1067" to="1077" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">TL;DR: Mining Reddit to learn automatic summarization</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Michael V"olske</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shahbaz</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benno</forename><surname>Syed</surname></persName>
		</author>
		<author>
			<persName><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on New Frontiers in Summarization</title>
		<meeting>the Workshop on New Frontiers in Summarization</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="59" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Glue: A multi-task benchmark and analysis platform for natural language understanding</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</title>
		<meeting>the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="353" to="355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Neural network acceptability judgments</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Warstadt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><surname>Samuel R Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="625" to="641" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Distance metric learning for large margin nearest neighbor classification</title>
		<author>
			<persName><forename type="first">John</forename><surname>Kilian Q Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><forename type="middle">K</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1473" to="1480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Principal component analysis</title>
		<author>
			<persName><forename type="first">Svante</forename><surname>Wold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Esbensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Geladi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemometrics and intelligent laboratory systems</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="37" to="52" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varsha</forename><surname>Kishore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName><surname>Bertscore</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.09675</idno>
		<title level="m">Evaluating text generation with bert</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
