<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On-road Vehicle Detection Using Evolutionary Gabor Filter Optimization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zehang</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Computer Vision Laboratory</orgName>
								<orgName type="institution">University of Nevada</orgName>
								<address>
									<settlement>Reno</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">George</forename><surname>Bebis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Computer Vision Laboratory</orgName>
								<orgName type="institution">University of Nevada</orgName>
								<address>
									<settlement>Reno</settlement>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Ronald</forename><surname>Miller</surname></persName>
							<email>rmille47@ford.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Vehicle Design R &amp; A Department, Ford Motor Company</orgName>
								<address>
									<settlement>Dearborn</settlement>
									<region>MI</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">On-road Vehicle Detection Using Evolutionary Gabor Filter Optimization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C3F9C4384A1370898E65DBEC13CD605D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Vehicle Detection</term>
					<term>Gabor Filters</term>
					<term>Genetic Algorithms</term>
					<term>Support Vector Machines</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Past work on vehicle detection has emphasized the issues of feature extraction and classification, however, less attention has been given on the critical issue of feature selection. The focus of this paper is on improving the performance of on-road vehicle detection by employing a set of Gabor filters that have been specifically customized for the problem of vehicle detection. The key idea is optimizing the parameters of Gabor filters such that they respond stronger to features present in vehicles than to non-vehicles, therefore, improving discrimination between the two classes. Specifically, we propose a systematic and general evolutionary Gabor filter optimization (EGFO) approach with the objective of producing a more optimal set of filters for vehicle detection. The EGFO approach unifies filter design and filter selection by integrating Genetic Algorithms (GAs) with an incremental clustering approach. Filter design is performed using GAs, a global optimization approach that encodes the parameters of Gabor filters in a chromosome and uses genetic operators to optimize them. Filter selection is performed by grouping together filters having similar characteristics using an incremental clustering approach in the parameter space. This step eliminates redundant filters, leading to a compact, optimized set of filters. The resulted filters are evaluated using an application-oriented fitness criterion based on Support Vector Machines (SVMs). We have tested the proposed framework using real data collected in Dearborn, Michigan in Summer and Fall 2001, using Ford's proprietary low light camera. Our experimental results demonstrate that the set of Gabor filters, specifically optimized for the problem of vehicle detection, are more sensitive to local features present in vehicles and yield better performance than using traditional Gabor filter banks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Introduction</head><p>Recognizing that vehicle safety is a primary concern for motorists, many national and international companies have lunched multi-year research projects to investigate new technologies for improving safety and accident prevention <ref type="bibr" target="#b0">[1]</ref>.</p><p>Vehicle accident statistics disclose that the main threats drivers are facing when driving a vehicle are from other vehicles. Consequently, on-board automotive driver assistance systems -aiming to alert a driver about driving environments, possible collision with other vehicles, or take control of the vehicle to enable collision avoidance and mitigation -have attracted more and more attention lately. In these systems, robust and reliable vehicle detection is a required critical step.</p><p>The most common approach to vehicle detection is using active sensors such as lidar, millimeter-wave radars, and lasers <ref type="bibr" target="#b0">[1]</ref>. Prototype vehicles employing active sensors have shown promising results. However, active sensors have several drawbacks, such as low spatial resolution, slow scanning speed, and high cost. Moreover, when there is a large number of vehicles moving simultaneously in the same direction, interference among sensors of the same type poses a big problem. Passive sensors on the other hand, such as cameras, offer a more affordable solution and can be used to track more effectively cars entering a curve or moving from one side of the road to another. Moreover, visual information can be very important in a number of related applications, such as lane detection, traffic sign recognition, or object identification (e.g., pedestrians, obstacles), without requiring any modifications to road infrastructures. Our emphasis in this paper is on improving vehicle detection using optical sensors.</p><p>Robust and reliable vehicle detection from images acquired by a moving vehicle (i.e., on-road vehicle detection) has numerous applications including driver assistance systems and autonomous, self-guided vehicles. In general, vehicle detection using optical sensors is very challenging due to huge within class variabilities. For example, vehicles may vary in shape (Fig. <ref type="figure" target="#fig_1">1</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Vehicle Detection Overview</head><p>Optical-based vehicle detection systems follow two basic steps: (1) Hypothesis Generation (HG) where the locations of possible vehicles in an image are hypothesized, and (2) Hypothesis Verification (HV) where tests are performed to verify the presence of vehicles in an image (see Fig. <ref type="figure" target="#fig_2">2</ref>). The objective of HG step is to provide some candidate locations horizontal/vertical edges <ref type="bibr" target="#b8">[9]</ref>[10] <ref type="bibr">[11][12]</ref>, and (e) color <ref type="bibr" target="#b12">[13]</ref>[14] <ref type="bibr" target="#b14">[15]</ref>. Stereo-based approaches take advantage of the Inverse Perspective Mapping (IPM) <ref type="bibr" target="#b15">[16]</ref>[17] <ref type="bibr" target="#b17">[18]</ref> to estimate the locations of vehicles and obstacles in images. Motion-based methods detect vehicles and obstacles using dense optical flow <ref type="bibr">[19][20]</ref> or "sparse optical flow" based on image features, such as corners <ref type="bibr" target="#b20">[21]</ref> or local minima and maxima <ref type="bibr" target="#b21">[22]</ref>.</p><p>During HV, tests are performed to verify the correctness of each hypothesis. HV approaches can be classified into two main categories: (1) template-based, and (2) appearance-based. Template-based methods use predefined patterns of the vehicle class and perform correlation between an input image and the template. Betke et al. <ref type="bibr" target="#b22">[23]</ref> proposed a multiple-vehicle detection approach using deformable gray-scale template matching. In <ref type="bibr" target="#b23">[24]</ref>, a deformable model was formed from manually sampled data using PCA. Both the structure and pose of a vehicle were recovered by fitting the In <ref type="bibr" target="#b8">[9]</ref>, PCA was used for feature extraction and NNs for classification. Goerick et al. <ref type="bibr" target="#b24">[25]</ref> used a method called Local Orientation Coding (LOC) to extract edge information. The histogram of LOC within the area of interest was then provided to a NN for classification. A statistical model for vehicle detection was investigated by Schneiderman et al.</p><formula xml:id="formula_0">PCA</formula><p>[26] <ref type="bibr" target="#b26">[27]</ref>. A view-based approach based on multiple detectors was used to cope with viewpoint variations. The statistics of both object and "non-object" appearance were represented using the product of two histograms with each histogram representing the joint statistics of a subset of PCA features in <ref type="bibr" target="#b25">[26]</ref> or Haar wavelet features in <ref type="bibr" target="#b26">[27]</ref> and their position on the object. A different statistical model was investigated by Weber et al. <ref type="bibr" target="#b27">[28]</ref>. They represented each vehicle image as a constellation of local features and used the Expectation-Maximization (EM) algorithm to learn the parameters of the probability distribution of the constellations. An interest operator, followed by clustering, was used to identify important local features in vehicle images. Papageorgiou et al. <ref type="bibr" target="#b28">[29]</ref> have proposed using the Haar wavelet transform for feature extraction and Support Vector Machines (SVMs) for classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Proposed Approach</head><p>Our emphasis in this work is on improving the performance of the HV step. In our recent work, we have investigated the application of Gabor features for vehicle detection, demonstrating their superiority compared to other features including PCA and wavelet features <ref type="bibr">[30][31]</ref>[32] <ref type="bibr" target="#b11">[12]</ref>. Like others, we employed a generic Gabor filter bank for feature extraction. To improve pattern classification performance, however, it would be critical selecting an optimum set of features and, consequently, an optimum set of Gabor filters. This raises the problem of Gabor filter optimization.</p><p>Despite considerable amount of work on the application of Gabor filters in various pattern classification tasks, their design and selection have not been systematic. Existing techniques are either only suitable for a small number of filters or less problem-oriented.</p><p>A systematic and general EGFO approach that yields a more optimal, problem-specific, set of filters is proposed in this paper. The EGFO approach unifies filter design with filter selection by integrating GAs with an incremental clustering approach. GAs allow for searching the space of filter parameters efficiently while clustering removes redundant filters.</p><p>Specifically, filter design is performed using GAs, a global optimization approach that encodes the parameters of the Gabor filters in a chromosome and uses genetic operators to optimize them. Filter selection is performed by grouping together filters having similar characteristics (i.e., similar parameters) using incremental clustering in the parameter space. Each group of filters is represented by a single filter whose parameters correspond to the average parameters of the filters in the group. This step eliminates redundant filters, leading to a compact, optimized set of filters. The average filters are evaluated using an application-oriented fitness criterion based on SVMs.</p><p>The EGFO approach is suitable for optimizing any number of filters for a given application. The search space of our method is much larger than those of the existing methods (see next Section) for a review), providing a higher likelihood of getting close to the optimal solution. Moreover, we represent filter optimization as a closed-loop learning problem.</p><p>The search for an optimal solution is guided by the performance of a classifier on features extracted from the responses of the Gabor filters. We use SVMs in this paper. An earlier version of this work has appeared in <ref type="bibr" target="#b32">[33]</ref>.</p><p>The rest of the paper is organized as follows: In Section II, we present a brief review Gabor filters, their design, and optimization methods. Section III presents our evolutionary Gabor filter optimization approach in detail. The</p><p>Gabor filter feature extraction method and the learning engine used in our experiments are described in Section IV.</p><p>Experiments and results are presented in Section VI. A discussion of our experimental results is given in Section VII.</p><p>Finally, Section VIII contains our conclusions and directions for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. Gabor Filter Design</head><p>Motivated by biological findings on the similarity of 2-D Gabor filters and receptive fields of neurons in the visual cortex <ref type="bibr" target="#b33">[34]</ref>, there has been increased interest in deploying Gabor filters in various computer vision applications. One of their most important properties is that they have optimal joint localization both in the spatial and frequency domains <ref type="bibr" target="#b33">[34]</ref>. They have been successfully applied to various image analysis applications including edge detection <ref type="bibr" target="#b34">[35]</ref>, image coding <ref type="bibr" target="#b33">[34]</ref>, texture analysis <ref type="bibr" target="#b35">[36]</ref>[37] <ref type="bibr" target="#b37">[38]</ref>, handwritten number recognition <ref type="bibr" target="#b38">[39]</ref>, face recognition <ref type="bibr" target="#b39">[40]</ref>, vehicle detection <ref type="bibr" target="#b31">[32]</ref>, and image retrieval <ref type="bibr" target="#b40">[41]</ref>.</p><p>The general functional of the two-dimensional Gabor filter family can be represented as a Gaussian function modulated by a complex sinusoidal signal. Specifically, a two dimensional Gabor filter g(x, y) can be formulated as:</p><formula xml:id="formula_1">g(x, y) = 1 2πσ x σ y exp[- 1 2 ( x2 σ 2 x + ỹ2 σ 2 y )] exp[2πjW x]<label>(1)</label></formula><formula xml:id="formula_2">       x = x cos θ + ysinθ ỹ = -x sin θ + ycosθ (2)</formula><p>where σ x and σ y are the scaling parameters of the filter and determine the effective size of the neighborhood of a pixel in which the weighted summation takes place. θ(θ ∈ [0, π)) specifies the orientation of the Gabor filters. W is the radial frequency of the sinusoid. A filter will respond stronger to a bar or an edge with a normal parallel to the orientation θ of the sinusoid. The Fourier transform of the Gabor function in Eq. 1 is given by:</p><formula xml:id="formula_3">G(u, v) = exp[- 1 2 ( (u -W ) 2 σ 2 u + v 2 σ 2 v )]<label>(3)</label></formula><p>where  that different parameter settings will lead to quite different filter responses, an important issue in pattern classification problems. Each filter is fully determined by choosing the four parameters in Φ. Therefore, choosing a filter for a particular application involves optimizing these four parameters. Assuming that N filters are needed in an application, 4N parameters need to be optimized. Solving this high dimensional multivariate optimization problem is very difficult in general.</p><formula xml:id="formula_4">σ u = 1 2 πσ x , σ v = 1 2 πσ y .</formula><p>Previous efforts in designing Gabor filters follow two main directions: the "Filter-design approach" and the "Filterbank approach" <ref type="bibr">[42][36]</ref>. In the "filter-design approach" the filter parameters are chosen by considering the data available, that is, the parameters are appropriate for the problem at hand only. In one of the pioneering studies on the design of Gabor filters conducted by Bovik et al. <ref type="bibr" target="#b42">[43]</ref>, the peak detection technique was used. Okombi-Diba et al. <ref type="bibr" target="#b43">[44]</ref> implemented a multi-iteration peak detection method for a texture segmentation problem. Dunn et al. <ref type="bibr" target="#b44">[45]</ref> investigated an exhaustive search to find the center frequency. Due to the exhaustive search, this method is quite time-consuming.</p><p>A more computationally efficient method was described in <ref type="bibr" target="#b41">[42]</ref>[36], using a segmentation-error criterion similar to <ref type="bibr" target="#b44">[45]</ref>.</p><p>In the "filter-bank approach" the filter parameters are chosen in a data independent way. Then, a subset of filters is selected for a particular application. Turner <ref type="bibr" target="#b45">[46]</ref> used 32 filters(4 frequencies × 4 orientations × 2 phase pairs) in a texture discrimination problem. Jain et al. <ref type="bibr" target="#b36">[37]</ref> chose the filter parameters such that the radial frequencies were one octave apart. To reduce the computational burden, a greedy filter selection method was employed. To reduce the redundancy in the Gabor feature representation, Manjunath et al. <ref type="bibr" target="#b40">[41]</ref> proposed a design method to ensure that the half-peak magnitude support of the filter responses in the frequency domain touch each other. For fast image browsing, they implemented an "adaptive filter selection algorithm", where spectrum difference information was used to select filters with better performance. In the context of handwritten number recognition, Hamamoto et al. <ref type="bibr" target="#b38">[39]</ref> optimized the filters by checking the error rate for all possible combinations of filter parameters and then choosing those minimizing the error rates.</p><p>Although good performances have been reported in the literature, certain limitations still exist. "Filter-design approaches", for example, divide the design process into two stages: pre-filter and post-filter. Several pre-filter design approaches have been investigated, however, an explicit methodology for selecting an appropriate post-filter step for a given pre-filter step has not been suggested. Moreover the selection of the bandwidth parameter is done mostly heuristically. The design stage in the "filter-bank approach" is mostly problem-independent. Different pattern classification problems, however, might require selecting an optimum set of features and, consequently, an optimum set of Gabor filters. We would not expect, for example, that a set of Gabor filters optimized for a vehicle classification application (compact car v.s. truck) would work well in a vehicle detection application (vehicle v.s. non-vehicle), since more detailed information is required in the former case than in the later.</p><p>Many researchers have realized that this is a serious problem and have suggested filter selection schemes to deal with it, however, filters are selected from an original small pool of filters that might not be suitable for the problem at hand (e.g., Hamamoto et al. <ref type="bibr" target="#b38">[39]</ref> performed filter selection using a pool of 100 predefined filters). The main issue with this approach is that there is no guarantee that the optimum set of filters would be included in the predefined pool of filters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. Evolutionary Gabor Filter Optimization</head><p>In this section, we describe the proposed evolutionary Gabor filter optimization approach. Gabor filter optimization corresponds to selecting the proper values for each of the four parameters in the parameter set Φ = {θ, W, σ x , σ y }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. A brief review of GAs</head><p>GAs are a class of optimization procedures inspired by the biological mechanisms of reproduction. In the past, they have been used to solve various problems including target recognition <ref type="bibr" target="#b46">[47]</ref>, object recognition <ref type="bibr" target="#b47">[48]</ref>[49], face recognition <ref type="bibr" target="#b49">[50]</ref>, and face detection/verification <ref type="bibr" target="#b50">[51]</ref>. This section contains a brief summary of the fundamentals of GAs. Goldberg <ref type="bibr" target="#b51">[52]</ref> provides a great introduction to GAs and the reader is referred to this source, as well as to the survey paper of Srinivas et al. <ref type="bibr" target="#b52">[53]</ref> for further information.</p><p>GAs operate iteratively on a population of structures, each one of which represents a candidate solution to the problem at hand, properly encoded as a string of symbols (e.g., binary). A randomly generated set of such strings forms the initial population from which the GA starts its search. In summary, selection probabilistically filters out solutions that perform poorly, choosing high performance solutions to concentrate on or exploit. Crossover and mutation, through string operations, generate new solutions for exploration.</p><p>Given an initial population of elements, GAs use the feedback from the evaluation process to select fitter solutions, eventually converging to a population of high performance solutions. GAs do not guarantee a global optimum solution.</p><p>However, they have the ability to search through very large search spaces and come to nearly optimal solutions fast.</p><p>Their ability for fast convergence is explained by the schema theorem (i.e., short-length bit patterns in the chromosomes with above average fitness, get exponentially growing number of trials in subsequent generations <ref type="bibr" target="#b51">[52]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Parameter Encoding/Decoding</head><p>Using a binary encoding scheme, each Gabor filter is represented by M bits that encode its four parameters. To design N filters, we use a chromosome of length M N bits. Each of the four parameters in Φ is encoded using n = M/4 bits as illustrated in Fig. <ref type="figure" target="#fig_6">4</ref>. It is worth mentioning that the encoding scheme is quite flexible, and allows us to encode any number of filters by simply varying the length of the chromosome. The numbers of bits associated with each parameter need not to be the same, we can make the search for a particular parameter finer of coarser by simply adding or removing bits for this parameter. If we need to fix certain parameter(s) using prior knowledge, we can remove the parameter(s) from the chromosome. In this case, the GA will optimize the remaining parameters. Each of the parameters in Φ has its own constraints and ranges. The encoding/deconding scheme was designed to ensure that the generated filters satisfy these requirements.</p><p>The orientation parameter θ should satisfy: θ ∈ [0, π). If D θ denotes the decimal number corresponding to the chunk of bits associated with θ (see Fig. <ref type="figure" target="#fig_6">4</ref>) then the value of θ is computed by</p><formula xml:id="formula_5">θ = D θ * π/2 n . (<label>4</label></formula><formula xml:id="formula_6">)</formula><p>which always satisfies the range requirement.</p><p>W is the radial frequency of the Gabor filter, which is application dependent. Using some prior knowledge, we can limit the range of W into [W min , W max ]. Then the decoding formula is given by</p><formula xml:id="formula_7">W = W min + (W max -W min ) * D W /2 n (5)</formula><p>where D W is the decimal number corresponding to the chunk of bits associated with W . In this study, we have used W min = 0 and W max = 0.5. σ x , and σ y are essentially the effective sizes of the Gaussian functions and are within the range [σ min , σ max ]. The upper limit σ max is determined by the mask width w <ref type="bibr" target="#b53">[54]</ref>. A relation between σ max and the mask size w can be obtained by imposing that w subtends most of the energy of the Gaussian. An adequate choice is σ max &lt; w/5, which subtends 98.76% of the energy of the Gaussian filter. The lower limit can be derived using the Sampling Theorem. If the pixel width is taken as our unit step, we cannot reconstruct completely a signal containing frequencies higher than 0.5pixel -1 from its samples, which means that any frequency component at |ω| &gt; ω c = 2π(0.5) = π is distorted. The ω c is determined by the pixelization, not by the signal. To avoid aliasing, the best we can do is to keep most of the energy of the Gaussian function within the interval [-π, π]. Applying the "98.86% of the energy" criterion, we find σ min &gt; 0.796.</p><p>To meet the range constraint ([σ min , σ max ]), our decoding scheme follows:</p><formula xml:id="formula_8">σ x = σ min + (σ max -σ min ) * D σx /2 n (6)</formula><p>for σ x and</p><formula xml:id="formula_9">σ y = σ min + (σ max -σ min ) * D σy /2 n (7)</formula><p>for σ y . D σx and D σy are again the decimal numbers corresponding to the chunk of bits associated with σ x and σ y correspondingly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Eliminating Redundant Filters Through Clustering</head><p>During parameter optimization, some of the Gabor filters encoded in a chromosome might end up being very similar to each other or even identical. These filters will result in similar/identical responses, therefore, introducing great redundancy and increasing time requirements. To eliminate redundant filters, we perform filter selection, implemented through filter clustering in the parameter space. An incremental clustering algorithm <ref type="bibr" target="#b54">[55]</ref> has been adopted in this paper for its simplicity. A high level description of the clustering algorithm is given below:</p><p>1. Assign the first Gabor filter to a cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Compute the distance of the next Gabor filter from the centroid of each cluster.</head><p>3. Find the smallest distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">If the distance is less than a threshold, assign the filter to the corresponding cluster;</head><p>5. Repeat step 2-4 for each of the remaining filters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Represent the filters in each cluster by a single filter whose parameters correspond to the cluster's centroid.</head><p>The optimized filters are evaluated using the fitness function defined in Section III-D. In our implementation, clustering is carried out in the parameter domain. Representing the parameters of a Gabor filter with {θ n , W n , σ n x , σ n y } and the centroids of the clusters with</p><formula xml:id="formula_10">{θ i , W i , σ i x , σ i y } with i ∈ [1 N ],</formula><p>where N is the number of currently existing clusters, we assign the filter to the ith cluster only if all of the following conditions are satisfied:</p><formula xml:id="formula_11">θ i - 1 2 × T hr θ ≤ θ n ≤ θ i + 1 2 × T hr θ (8) W i - 1 2 × T hr W ≤ W n ≤ W i + 1 2 × T hr W (9) σ i x - 1 2 × T hr σ ≤ σ n x ≤ σ i x + 1 2 × T hr σ (<label>10</label></formula><formula xml:id="formula_12">)</formula><formula xml:id="formula_13">σ i y - 1 2 × T hr σ ≤ σ n y ≤ σ i y + 1 2 × T hr σ (11)</formula><p>Otherwise, the filter is assigned to a new cluster. The above conditions are quite strict to make sure that filters falling in the same cluster are very similar to each other. We can always relax the criterion by increasing the predefined thresholds. The following thresholds were used in our experiments:</p><formula xml:id="formula_14">Φ = {θ, W, σ x , σ y } are T hr θ = π/K, T hr W = (W max -W min )/K, and T hr σ x = T hr σ y = T hr σ = (σ max -σ min )/K.</formula><p>Depending on different applications and desired trade-off between model compactness and accuracy, K can be set to different values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Fitness evaluation</head><p>Each individual's fitness will determine whether or not it will survive in subsequent generations. The fitness value used here is the performance of a SVM classifier on a validation set using features extracted from the responses of the selected Gabor filters. In this way, the Gabor filter optimization design is implemented as a closed-loop learning scheme, which is more powerful, more problem-specific, and less heuristic than in previous approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Initial Population</head><p>The initial population is generated randomly, (e.g., each bit in an individual is set by flipping a coin). In all of our experiments, we used a population size of 700 and 100 generations. In most cases, the GA converged in less than 100 generations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Selection</head><p>Our selection strategy was cross generational. Assuming a population of size N , the offspring double the size of the population and we select the best N individuals from the combined parent-offspring population <ref type="bibr" target="#b55">[56]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Crossover</head><p>There are three basic types of crossovers: one-point crossover, two-point crossover, and uniform crossover. For onepoint crossover, the parent chromosomes are split at a common point chosen randomly and the resulting sub-chromosomes are swapped. For two-point crossover, the chromosomes are thought of as rings with the first and last gene connected (i.e., wrap-around structure). In this case, the rings are split at two common points chosen randomly and the resulting sub-rings are swapped. Uniform crossover is different from the above two schemes. In this case, each gene of the offspring is selected randomly from the corresponding genes of the parents. Since we do not know in general how parameters from different filters depend on each other, if dependent parameters are far apart in the chromosome, it is very likely that traditional one-point or two-point crossover will destroy the schemata. To avoid this problem, uniform crossover is used here. The crossover probability used in all of our experiments was 0.66.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. Mutation</head><p>We use the traditional mutation operator which just flips a specific bit with a very low probability. The mutation probability used in all of our experiments was 0.03.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. Gabor feature extraction and classification</head><p>Designing an optimal set of Gabor filters is the first step in building a pattern classification algorithm. Then, we need to extract features using the responses of the selected filters and train a classifier using those features. To demonstrate the proposed filter design approach, redundant statistical Gabor features and SVMs are utilized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Gabor Filter Features</head><p>Given an input image I(x, y), Gabor feature extraction is performed by convolving I(x, y) with a set of Gabor filters:</p><formula xml:id="formula_15">r(x, y) = I(ξ, η)g(x -ξ, y -η)dξdη (12)</formula><p>Although the raw responses of the Gabor filters could be used directly as features, some kind of post-processing is usually applied (e.g., Gabor-energy features, thresholded Gabor features, and moments based on Gabor features <ref type="bibr" target="#b56">[57]</ref>).</p><p>In this study, we use moments derived from Gabor filter outputs on subwindows defined on subimages extracted from the whole input image. First, each sub-image is scaled to a fixed size of 32 × 32. Then, it is divided into 9 overlapping 16 × 16 sub-windows.</p><p>Each sub-image consists of 16 8 × 8 patches as shown in Figure <ref type="figure" target="#fig_7">5</ref>(a), patches 1,2,5,and 6 comprise the first 16 × 16 sub-window, 2,3,6 and 7 the second, 5, 6, 9, and 10 the fourth, and so forth. The Gabor filters are then applied on each sub-window separately. The motivation for extracting -possibly redundant -Gabor features from several overlapping sub-windows is to compensate for the error due to the sub-window extraction step (e.g. sub-images containing partially extracted objects or background information), making feature extraction more robust.</p><p>The magnitudes of the Gabor filter responses are collected from each sub-window and represented by three moments:</p><p>the mean µ ij , the standard deviation σ ij , and the skewness κ ij where i corresponds to the i-th filter and j corresponds to the j-th sub-window. Using moments implies that only the statistical properties of a group of pixels is taken into consideration, while position information is discarded. This is particularly useful to compensate for errors in the extraction of the sub-images. Suppose we are using N = 6 filters. Applying the filter bank on each of the 9 sub-windows, yields a feature vector of size 162, having the following form:</p><formula xml:id="formula_16">[µ 11 σ 11 κ 11 , µ 12 σ 12 κ 12 • • • µ 69 σ 69 κ 69 ]<label>(13)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. SVM classifier</head><p>SVMs are primarily two-class classifiers that have been shown to be an attractive and more systematic approach to learning linear or non-linear decision boundaries <ref type="bibr">[58] [59]</ref>. Given a set of points, which belong to either one of the two classes, SVM finds the hyperplane leaving the largest possible fraction of points of the same class on the same side, while maximizing the distance of either class from the hyperplane. This is equivalent to performing structural risk minimization to achieve good generalization <ref type="bibr">[58] [59]</ref>. Given l examples from two classes</p><formula xml:id="formula_17">(x 1 , y 1 )(x 2 , y 2 )...(x l , y l ), x i ∈ R N , y i ∈ {-1, +1}<label>(14)</label></formula><p>finding the optimal hyper-plane implies solving a constrained optimization problem using quadratic programming. The optimization criterion is the width of the margin between the classes. The discriminating hyperplane is defined as:</p><formula xml:id="formula_18">f (x) = l i=1 y i a i k(x, x i ) + b (<label>15</label></formula><formula xml:id="formula_19">)</formula><p>where k(x, x i ) is a kernel function and the sign of f (x) indicates the membership of x. Constructing the optimal hyperplane is equivalent to finding all the nonzero a i . Any data point x i corresponding to a nonzero a i is a support vector of the optimal hyperplane.</p><p>Kernel functions, which satisfy the Mercer's condition, can be expressed as a dot product in some space <ref type="bibr" target="#b57">[58]</ref>. By using different kernels, SVMs implement a variety of learning machines (e.g., a sigmoidal kernel corresponds to a two-layer sigmoidal neural network while a Gaussian kernel corresponds to a radial basis function (RBF) neural network). The Gaussian radial basis kernel, which is used in this study, is given by</p><formula xml:id="formula_20">k(x, x i ) = exp(- x -x i 2 2δ 2 )<label>(16)</label></formula><p>Our experiments with different kernels have shown that the Gaussian kernel outperforms the others in the context of our application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. Vehicle detection using optimized Gabor filters</head><p>In this section, we consider the problem of vehicle detection from gray-scale images. The first step in vehicle detection is usually to hypothesize the vehicle locations in an image. Then, verification is applied to test the hypotheses, as we discussed in Section I . Our emphasis here is on improving the performance of the verification step by optimizing the Gabor filters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Vehicle Data</head><p>The sub-images were extracted manually(see Figure <ref type="figure" target="#fig_10">6</ref>). In <ref type="bibr" target="#b28">[29]</ref>, the sub-images were aligned by warping the bumpers to approximately the same position. However we have not attempted to align the data since alignment requires detecting certain features on the vehicle accurately. Moreover, we believe that some variability in the extraction of the sub-images can actually improve performance. Each sub-image in the training and test sets was scaled to a size of 32 × 32 and preprocessed to account for different lighting conditions and contrast using the method suggested in <ref type="bibr" target="#b50">[51]</ref>.</p><p>To evaluate the performance of the proposed approach, the error rates (ER) are recorded using a three-fold cross-  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. Experimental results</head><p>For comparison purposes, we also report the detection error rates using two different Gabor filter banks without optimization: one with 4 scales and 6 orientations Fig. <ref type="figure" target="#fig_7">5</ref>(b), the other with 3 scales and 5 orientations Fig. <ref type="figure" target="#fig_7">5(c</ref>). These filter banks were designed by following the method proposed in <ref type="bibr" target="#b40">[41]</ref>.  SVMs for classification. Using the feature extraction method described in Section IV-A, the size of each Gabor feature vector was 405 in this experiment. The average error rate was found to be 10.38%, (see Table <ref type="table" target="#tab_1">I</ref>). Then, we tested a</p><p>Gabor filter bank with 4 scales and 6 orientations which yielded features vectors of size 648. The error rate in this case was 9.09% which is slightly better than before.</p><p>Second, we used the EGFO approach to customize a group of filters, up to 24, for the vehicle detection problem. We limited the number of filters to 24 to make the comparison with the traditional filter bank design methods fair. Each parameter in Φ = {θ, W, σ x , σ y } was encoded using 4 bits. The total length of the chromosome was 384(4 × 4 × 24), which corresponds to a large search space (i.e., 2 384 ). The threshold factor K for the clustering was set to 3 in our experiments. The average error rate in this case was 6.36%, and the average number of customized filters was 19. We also ran the filter optimization method without clustering on the same data sets, using the same parameters, the final 24 shown in Fig. <ref type="figure" target="#fig_11">7</ref>. The average error rate was 6.19%, slightly better than that yielded by the method with clustering. Because we are using only three-fold cross-validation, the difference is not statistically significant. It is obvious, from the results, clustering has the advantage of producing a more compact set of filters (i.e., 19 v.s. 24).</p><p>To get an idea regarding the effectiveness of the clustering subcomponent, we performed more experiments using different threshold settings for the factor k = 2. The average error rate was 8.23%, and the average number of customized filter was 14.7. The 15 filters generated for data Set3 are shown in Fig. <ref type="figure">9</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. Discussion</head><p>To get a better idea about the filter parameters chosen by the EGFO approach, we computed a histogram for each of the parameters(Fig. <ref type="figure" target="#fig_15">11</ref>), showing the average distribution of its values over the three data sets. In each graph, the x-axis corresponds to a parameter from Φ = {θ, W, σ x , σ y }, and has been divided into 10 bins to compute the histogram. The y-axis corresponds to the average number of Gabor filters whose parameters are within a given interval. For example,  (1) The Gabor filters customized using the proposed approach yielded better results in vehicle detection: The most important reason for this improvement is probably that the Gabor filters were designed specifically for the pattern classification problems at hand (i.e., the proposed method is more application-specific than existing filter design methods).</p><p>(2)The orientation parameters of the filters optimized by the GA were tuned to exploit the implicit information available in vehicle data: A Gabor filter is essentially a bar, edge, or grating detector, and will respond most strongly if the filter's orientation is consistent with the orientation of specific features in an image (i.e., bar, edge, etc.). We can see that horizontal, 45 o , and 135 o structures appear more often in a rear view of a vehicle image, which explains why most of the filter orientations chosen were close to 0 o , 45 o , and 135 o (see Fig. <ref type="figure" target="#fig_16">11(a)</ref>).</p><p>(3) The radial frequency parameters (W ) of the filters found by the GA approach were also tuned to encode the implicit information present in vehicle images: Generally speaking, we have more filters with lower radial frequencies than with higher radial frequencies (see Fig. <ref type="figure" target="#fig_16">11(b</ref>)). This is reasonable given that vehicle images contain large structures (windows, bumper, etc.), requiring filters with lower radial frequencies.</p><p>(4) The parameters σ x , σ y were also tuned to respond to the basic structures of a vehicle: Fig. <ref type="figure" target="#fig_16">11(c</ref>) and Fig. <ref type="figure" target="#fig_16">11(d)</ref> show that the σ y parameter has bigger values than the σ x parameter. Bigger σ y values implies a wider Gaussian mask in the y direction. This is consistent with the observation that horizontal structures in vehicle images spread more widely than structures in vertical direction.</p><p>(</p><formula xml:id="formula_21">)<label>5</label></formula><p>The EGFO approach provides a good base for compromising between model compactness and performance accuracy:</p><p>By setting the threshold factor to 2, we ended up with 14.7 filters on average. The error rate went up to 8.23% from 6.36%, which is still better than using the traditional Gabor filter bank with 3 scales and 5 orientations. When we build a pattern classification system, among other factors, we need to find the best balance point between model compactness and performance accuracy. Under some scenarios, we prefer the best performance, no matter what the cost might be.</p><p>Under different situations, we might favor speed over accuracy, as long as the accuracy is within a satisfactory range.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. Conclusions</head><p>We have considered the problem of vehicle detection using Gabor filter optimization. In particular, we presented a systematic EGFO approach that yields a more optimal, problem-specific, set of filters. The EGFO approach unifies filter design with filter selection by integrating GAs with an incremental clustering approach. The resulted filters were evaluated using an application-oriented fitness criterion based on SVMs. Our experimental results showed that the set of Gabor filters, specifically optimized for the problem of vehicle detection, yield better performance than using traditional filter banks. The proposed EGFO framework is general and can be applied in other areas requiring filter customization such as in face detection. For future work, we plan to evaluate this framework using different data sets, and different types of filters. We also plan to test different filter selection schemes by encoding selection in the chromosome explicitly.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(a)), size, and color. Also, vehicle appearance depends on its pose (Fig. 1(b)) and is affected by nearby objects. Complex outdoor environments (e.g. illumination conditions (Fig. 1(c)), cluttered background, and unpredictable interactions between traffic participants (Fig. 1(d)) are difficult to control.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The variety of vehicle appearances poses a big challenge for vehicle detection</figDesc><graphic coords="2,68.54,471.11,112.36,77.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Illustration of the two-step vehicle detection strategy</figDesc><graphic coords="3,173.04,68.65,252.57,109.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>model to the image. Appearance-based methods learn the characteristics of the vehicle class from a set of training images which capture the variability in vehicle appearance. Usually, the variability of the non-vehicle class is also modelled to improve performance. First, each training image is represented by a set of local or global features. Then, the decision boundary between the vehicle and non-vehicle classes is learned either by training a classifier (e.g., Neural Network (NN)) or by modelling the probability distribution of the features in each class (e.g., using the Bayes rule assuming Gaussian distributions).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>The Fourier domain representation in Eq. 3 specifies the amount by which the filter modifies each frequency component of the input image.Gabor filters act as local bandpass filters. Fig.3shows four Gabor filters with different parameter settings in frequency domain. The light areas of the power spectrum indicate frequencies and wave orientations. It is obvious from Fig.3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The Gabor filter with different parameter Φ = {θ, W, σx, σy} in frequency domain(the Fourier transform of the Gabor functions with different parameters) . (a) Φ a = {0 o , 0.0961, 0.0204, 0.01219}, (b) Φ b = {0 o , 0.3129, 0.06, 0.359}, (c) Φ b = {90 o , 0.3129, 0.06, 0.359}, (d) Φ c = {90 o , 0.3921, 0.0503, 0.3066}</figDesc><graphic coords="6,125.10,68.01,83.49,83.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Encoding scheme</figDesc><graphic coords="9,215.24,165.12,168.45,90.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. (a) feature extraction patches; (b) Gabor filter bank with 4 scales and 6 orientations; (c) Gabor filter bank with 3 scales and 5 orientations;</figDesc><graphic coords="13,127.01,67.61,111.98,111.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>images used in our experiments were collected in Dearborn, Michigan in two different sessions, one in the Summer of 2001 and one in the Fall of 2001. To ensure a good variety of data in each session, the images were captured at different times of different days and on five different highways. The training set contains sub-images of rear vehicle views and non-vehicles, which were extracted manually from the Fall 2001 data set. A total of 1051 vehicle and 1051 non-vehicle</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>validation procedure. Specifically, we sample the training dataset randomly three times (Set1, Set2 and Set3) by keeping 280 of the vehicle sub-images and 280 of the non-vehicle sub-images for training. 300 sub-images (150 vehicle sub-images and 150 non-vehicle sub-images) are used for validation during the filter optimization design. For testing, we used a fixed set of 231 vehicle and non-vehicle sub-images which were extracted from the Summer 2001 data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Examples of vehicle and nonvehicle images used for training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. 24 Gabor filters for the vehicle detection problem without clustering</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 8 . 3 Fig. 9 .</head><label>839</label><figDesc>Fig. 8. 19 optimized Gabor filters for the vehicle detection problem with K = 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>3 .</head><label>3</label><figDesc>Fig.8in the frequency domain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Vehicle detection error rate. 3 × 5: the Gabor filter bank with 3 scales and 5 orientations; 4 × 6: 4 scales and 6 orientations; NC: EGFO method without clustering; K=3: EGFO method with K=3; and K=2: EGFO with K=2.</figDesc><graphic coords="17,187.17,431.79,224.51,167.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11.a shows the average distribution of θ, where the width of each bin is 18 o , given θ ∈ [0 180 o ). The bar associated with the first bin indicates that there were 4 filters (average number over the three training data sets) in the optimized Gabor filter set, whose orientation parameter satisfies: θ ∈ [0 18 o ). The only difference for the rest parameters is the bin size, for instance, the ith bin in Fig. 11(b) corresponds to the interval [(i -1) * ST EP W i * ST EP W ), where ST EP W = (W max -W min /10).</figDesc><graphic coords="18,128.75,234.62,168.32,110.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Distributions of the Gabor filter parameters for vehicle Detection. (a) θ; (b) W ; (c) σ x ; (d) σ y</figDesc><graphic coords="18,128.69,403.18,168.45,93.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I</head><label>I</label><figDesc>Vehicle detection error rates using different filters. The numbers in the parentheses indicate the number of optimized</figDesc><table><row><cell cols="2">filters</cell><cell></cell></row><row><cell>3 × 5</cell><cell>4 × 6</cell><cell>EGFO</cell></row><row><cell cols="2">Data Set1 10.82% 9.09%</cell><cell>6.93%(21)</cell></row><row><cell cols="2">Data Set2 11.69% 11.26%</cell><cell>7.79%(18)</cell></row><row><cell>Data Set3 8.66%</cell><cell>6.93%</cell><cell>4.33%(19)</cell></row></table><note><p><p><p>Average</p>10.38% 9.09% 6.36%</p>(19.3)    </p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements: This research was supported by Ford Motor Company under grant No.2001332R, the University of Nevada, Reno under an Applied Research Initiative (ARI) grant, and in part by NSF under CRCD grant No.0088086.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Building safer cars</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Spectrum</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="82" to="85" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Using symmetry for detecting and locating objects in a picture</title>
		<author>
			<persName><forename type="first">G</forename><surname>Marola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision, Graphics, and Image Processing</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="179" to="195" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Symmetry-based recognition for vehicle rears</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kuehnle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="249" to="258" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Intensity and edge-based symmetry detection with an application to car-following</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zielke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brauckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">V</forename><surname>Seelen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVGIP:Image Understanding</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="177" to="190" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Shadow and rhythm as sign patterns of obstacle detection</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Charkai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on industrial exlectronics</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="271" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The seeing passenger car &apos;vamors-p</title>
		<author>
			<persName><forename type="first">E</forename><surname>Dickmanns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Intelligent Vehicles&apos;94</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="24" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Vehicle detection in traffic secens using shadows</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tzomakas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">V</forename><surname>Seelen</surname></persName>
		</author>
		<idno>98-06</idno>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>Institut fur Neuroinformatik</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Internal Report</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A texture-based object detection and an adaptive model-based classification</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kalinke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tzomakas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">V</forename><surname>Seelen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Intelligent Vehicles</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="143" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Vehicle detection and recognition in greyscale imagery</title>
		<author>
			<persName><forename type="first">N</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Charnley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Harris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Control Engineering Practice</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="473" to="479" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A feature-based recognition scheme for traffic scenes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Parodi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Piccioli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intelligent Vehicles Symposium</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="229" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A real-time precrash vehicle detection system</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bebis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dimeo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Workshop on Application of Computer Vision</title>
		<imprint>
			<date type="published" when="2002-12">Dec., 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Monocular pre-crash vehicle detection: Features and classifiers</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bebis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>under review</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Color vision for road following</title>
		<author>
			<persName><forename type="first">J</forename><surname>Crisman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Thorpe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE Conference on Mobile Robots</title>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="246" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Color machine vision for autonomous vehicles</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Buluswar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Draper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal for Engineering Applications of Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="245" to="256" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Color modeling by spherical influence field in sensing driving environment</title>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fraichard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Laugier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intelligent Vehicle Symposium</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="249" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Inverse perspective mapping simplifies optical flow computation and obstacle detection</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mallot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bulthoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Little</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bohrer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="177" to="185" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Obstacle detection by vision system for autonomous vehicle</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shini'chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intelligent Vehicle Symposium</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="31" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Gold: A parallel real-time stereo vision system for generic obstacle and lane detection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bertozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Broggi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="62" to="81" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The use of optical flow for road navigation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Giachetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Campani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Torre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on robotics and automation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="34" to="48" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Real-time estimation and tracking of optical flow vectors for obstacle detection</title>
		<author>
			<persName><forename type="first">W</forename><surname>Kruger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Enkelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rossle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intelligent vehicle symposium</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="304" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Matching two perspective views</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="806" to="825" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Algorithm characterization of vehicle trajectories from image sequences by motion verbs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Heinze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nagel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="90" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multiple vehicle detection and tracking in hard real time</title>
		<author>
			<persName><forename type="first">M</forename><surname>Betke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Haritaglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intelligent Vehicles Symposium</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="351" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A generic deformable model for vehicle recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ferryman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Worrall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of British Machine Vision Conference</title>
		<meeting>British Machine Vision Conference</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="127" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Artificial neural networks in real-time car detection and tracking applications</title>
		<author>
			<persName><forename type="first">C</forename><surname>Goerick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Detlev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Werner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="335" to="343" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Probabilistic modeling of local appearance and spatial relationships for object recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Schneiderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="45" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">A statistical approach to 3D object detection applied to faces and cars</title>
		<author>
			<persName><forename type="first">H</forename><surname>Schneiderman</surname></persName>
		</author>
		<idno>CMU-RI-TR-00-06</idno>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Unsupervised learning of models for recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Comptuer vision</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="18" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A trainable system for object detection</title>
		<author>
			<persName><forename type="first">C</forename><surname>Papageorgiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="33" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">On-road vehicle detection using gabor filters and support vector machines</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bebis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Digital Signal Processing</title>
		<meeting><address><addrLine>Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-07">July, 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Quantized wavelet features and support vector machines for on-road vehicle detection</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bebis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Seventh International Conference on Control, Automation, Robotics and Vision</title>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-12">December, 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Improving the performance of on-road vehicle detection by combining gabor and wavelet features</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bebis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Fifth International Conference on Intelligent Transportation Systems</title>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-09">September, 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Evolutionary gabor filter optimization with application to vehicle detection</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bebis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Data Mining</title>
		<imprint>
			<date type="published" when="2003-11">November 2003</date>
			<biblScope unit="page" from="307" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Complete discrete 2-d gabor transforms by neural network for image analysis and compression</title>
		<author>
			<persName><forename type="first">J</forename><surname>Daugman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1169" to="1179" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Gabor filter-based edge detection</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Namuduri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ranganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1479" to="1493" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Efficient gabor filter design for texture segmentation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Weldon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dunn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2005" to="2015" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Unsupervised texture segementation using gabor filters</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Farrokhnia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1167" to="1186" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Unsupervised texture segmentation in a deterministic annealing framework</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="803" to="818" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A gabor filter-based method for recognizing handwritten numerals</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hamamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Uchimura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yasuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mitani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tomota</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="395" to="400" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Face recognition using independent component analysis og gabor filter responses</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IAPR Workshop on machine vision applications</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="331" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Texture features for browsing and retrieval of image data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Manjunath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="837" to="842" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Gabor filter desing for multiple texture segmentation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Weldon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dunn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optical Engineering</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2852" to="2863" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Multichannel texture analysis using localized spatial filters</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Geisler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="55" to="73" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Edge-based segmentation of textured images uing otimally selected gabor filters</title>
		<author>
			<persName><forename type="first">B</forename><surname>Okombi-Diba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Miyamichi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shoji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IAPR Workshop on machine vision applications</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="267" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Optimal gabor filters for texture segementation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Higgins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="947" to="964" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Texture discrimination by gabor functions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="71" to="82" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Generating image filters for target recognition by genetic learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Thrift</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="906" to="910" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Genetic object recognition using combinations of views</title>
		<author>
			<persName><forename type="first">G</forename><surname>Bebis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Varol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yfantis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="132" to="146" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Genetic algorithms for object recognition in a complex scene</title>
		<author>
			<persName><forename type="first">D</forename><surname>Swets</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Punch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="595" to="598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Evolutionary pursuit and its application to face recognition</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wechsler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="570" to="582" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Face detection and verification using genetic search</title>
		<author>
			<persName><forename type="first">G</forename><surname>Bebis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Uthiram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Georgiopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal on Artificial Intelligence Tools</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="225" to="246" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Goldberg</surname></persName>
		</author>
		<title level="m">Genetic Algorithms in Search, Optimization, and Machine Learning</title>
		<imprint>
			<publisher>Addison Wesley</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Genetic algorithms: a survey</title>
		<author>
			<persName><forename type="first">M</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Patnaik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computers</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="17" to="26" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Introductory Techniques for 3-D Computer Vision</title>
		<author>
			<persName><forename type="first">E</forename><surname>Trucco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Verri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Prentice Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Data clustering: A review</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Murty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Flynn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="265" to="323" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">The chc adaptive search algoruthm: How to have safe search when engaging in non-traditional genetic recombination</title>
		<author>
			<persName><forename type="first">L</forename><surname>Eshelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Foundation of Genetic Algorithms Workshop</title>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Comparison of texture features based on gabor filters</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kuizinga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Petkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Grigorescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Image Analysis and Processing</title>
		<meeting>the 10th International Conference on Image Analysis and Processing</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="142" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">The Nature of Statistical Learning Theory</title>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Springer Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Tutorial on support vector machines for pattern recognition</title>
		<author>
			<persName><forename type="first">C</forename><surname>Burges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="955" to="974" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
