<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Scale Selection for Classification of Point-sampled 3-D Surfaces</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jean-Franc Â¸ois</forename><surname>Lalonde</surname></persName>
							<email>jlalonde@ri.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ranjith</forename><surname>Unnikrishnan</surname></persName>
							<email>ranjith@ri.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nicolas</forename><surname>Vandapel</surname></persName>
							<email>vandapel@ri.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Martial</forename><surname>Hebert</surname></persName>
							<email>hebert@ri.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Scale Selection for Classification of Point-sampled 3-D Surfaces</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6C4C09362DBBB57E2E5C9401EF0B0F20</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Three-dimensional ladar data are commonly used to perform scene understanding for outdoor mobile robots, specifically in natural terrain. One effective method is to classify points using features based on local point cloud distribution into surfaces, linear structures or clutter volumes. But the local features are computed using 3-D points within a support-volume. Local and global point density variations and the presence of multiple manifolds make the problem of selecting the size of this support volume, or scale, challenging. In this paper we adopt an approach inspired by recent developments in computational geometry <ref type="bibr" target="#b4">[5]</ref> and investigate the problem of automatic data-driven scale selection to improve point cloud classification. The approach is validated with results using data from different sensors in various environments classified into different terrain types (vegetation, solid surface and linear structure) 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Autonomous navigation in vegetated terrain remains a challenging problem in robotics due to the difficulties in modeling the high variability of outdoor environments. In this effort, laser range-finders have proven to be invaluable due to their high speed and direct sensing of depth information in the form of unorganized 3-D point clouds from objects in the scene. Depth cues allow more natural modeling of smooth, porous and linear surfaces as 3-D textures. Labeled data can then be used to compute 3-D features and train classifiers for distinguishing load-bearing surfaces, vegetation and linear structures respectively.</p><p>However the perspective sensing geometry of laser-range finders introduces significant variation in spatial density of observed points, both over the field-of-view as well as within the objects of interest. This poses the question of 1 Prepared through collaborative participation in the Robotics Consortium sponsored by the U.S Army Research Laboratory under the Collaborative Technology Alliance Program, Cooperative Agreement DAAD19-01-209912. how to select the size of the support region, or scale of observation, for computing 3-D features that are representative of the local geometry. Scale theory has a rich literature for 2-D and 3-D images but no equivalent exists for unorganized point-sampled data. One method to circumvent this problem is to use a fixed scale that is satisfactory over the entire dataset. This however compromises feature computation both in regions where data is sparse as well as near the spatial boundaries between neighboring data belonging to two different classes. Sensor noise also confounds the feature computation process as a larger support region size may be needed to compensate for noise. This paper presents a technique for determining the scale of observation of point-sampled data by computing the optimal size of the support region for computing surface normals as illustrated in Figure <ref type="figure" target="#fig_0">1</ref>. Spatial features are then computed at this support size and used in a Bayes classifier for 3-D data segmentation. The method implicitly assumes that the scale that is representative of local geometry at a point is also the one that best discriminates its true class in feature space. We validate this assumption through exten-sive experiments and detail our approach and its limitations in the sections that follow.</p><p>The next section presents various approaches followed previously to try to address the scale selection issue. The third section details the approach proposed for optimal scale selection to perform terrain classification. Results from various terrains sensed by three different ladar are presented in the next to last section. It is followed by concluding remarks and a discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>It is widely accepted that real world objects appear as meaningful entities at different scales of observation. This has driven the need for rigorous, data-driven formalisms to identify representative scales in data, both for data representation as well as identification.</p><p>Pioneering work by Lindeberg <ref type="bibr" target="#b2">[3]</ref> equated analysis of continuous signals at successive scales to the suppression of local extrema, and showed that successive smoothing of the signal by gaussian convolution satisfied this property. By this principle, the scale at which the signal response to a normalized differential operator achieves local extrema is a characteristic length of the structure in the signal. This methodology has been extended to discrete signals in 1-D, 2-D and N-D lattices <ref type="bibr" target="#b1">[2]</ref>. The scale-invariance property has since been exploited extensively in computer vision as a technique to extract regions with sizes that accommodate scaling of the image and from which invariant features can be computed. However this body of work has focused solely on functions defined on a regular lattice and its applicability to unorganized point samples is unclear.</p><p>In the domain of point sampled data, efforts have been made to address the problem of scale for surface reconstruction and feature extraction. The tensor voting framework in <ref type="bibr" target="#b6">[7]</ref> equated scale to the region of influence of each tensor, and used it for fine-to-coarse analysis for surface reconstruction. However, no direct relation could be drawn between a choice of region size for tensor voting and that for computing a representative feature for classification. Work in <ref type="bibr" target="#b0">[1]</ref> uses k-neighborhoods to compensate for differences in sampling rate before computing eigenvalue-based features for detecting surfaces, creases and borders. However, no guarantee was given that a certain fixed choice of k would be representative of the underlying surface at all points.</p><p>Tang et al. <ref type="bibr" target="#b7">[8]</ref> use a Kalman filter-based discontinuity preserving line-smoother to detect junctions in 2-D scans. Successive iterations of the smoothing algorithm defined increasing scales of data. However, the method was focused to data modeled as piecewise lines and not applicable to classification. Work in <ref type="bibr" target="#b5">[6]</ref> classifies points based on eigenvalues of the local covariance matrix in its n-neighborhood.</p><p>It defines a measure of deviation from planarity at a point that is a function of the eigen-values. The value of the scale (n) that maximizes the measure for 1-D sinusoidal signals is observed to be related to the wavelength of the signal. The scale corresponding to the maximum value is then chosen for computing the feature. However no theoretical guarantees were made regarding suitability of the proposed measure for 3-D surfaces or its optimality for classification.</p><p>In contrast, this paper proposes to use a neighborhood size consistent with the estimate of local geometry at a point. We make use of recent work in computational geometry <ref type="bibr" target="#b4">[5]</ref>[4] and compute a neighborhood size that minimizes an upper bound on expected angular error between the normal estimated at a point through PCA and the true normal. The quality of this estimate is improved with knowledge of sensor geometry and error characteristics. A by-product of this process is an estimate of the local covariance matrix that is most consistent with the surface geometry. The eigen-values of this covariance matrix are used in a Bayes classifier to perform point-wise classification of the scene.</p><p>Section 3 details the estimation of the support size and our proposed algorithm. In Section 4 we present classification results on real outdoor data, and then summarize the contributions in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Normal Estimation in 3-D</head><p>This section details the analysis of normal estimation on surfaces in 3-D point cloud data (PCD) as summarized in <ref type="bibr" target="#b4">[5]</ref> <ref type="bibr" target="#b3">[4]</ref>. We start with a set of N p points, p i = x i y i z i T , drawn at random from a surface in R 3 . The goal is to compute the normal at each point of a point cloud with greatest accuracy. This is done by choosing a spatial neighborhood size r that minimizes the expected angular deviation of the computed normal at a point from its true normal. In contrast to the analysis in <ref type="bibr" target="#b4">[5]</ref>, we express the unknown parameters explicitly in terms of data dependent quantities and record their dependence on the data distribution and sensor model. The total least-squares (TLS) estimate of the normal to a set of k points p i is given by the eigen-vector corresponding to the smallest eigen-value of the covariance matrix</p><formula xml:id="formula_0">M = 1 k k â i=1 (p i -p)(p i -p) T = ï£® ï£° m 11 m 12 m 13 m 12 m 22 m 23 m 13 m 23 m 33 ï£¹ ï£»<label>(1)</label></formula><p>where p = 1 k â k i=1 p i . Note that M is always symmetric positive semi-definite (M 0) and thus has non-negative eigenvalues.</p><p>The remainder of the discussion makes the following assumptions:</p><p>(A1) Centered data: Without loss of generality, the dataset is centered about the origin O which is the point of interest. The z-axis is the normal to the surface at O and the points of the PCD in the sphere of radius r around O are i.i.d samples of a topological disk R on the underlying surface. We may then model the surface as a function z = g(x, y) that is C 2 continuous over the r-disk.</p><p>(A2) Spatial density: There exists an r 0 &lt; Î³ such that a sphere of radius r 0 anywhere in R contains at least k 0 &gt; 0 points. This implies that data has no holes and has spatial density Ï &gt; Ï 0 &gt; 0 everywhere.</p><p>(A3) Term z i is observed with i.i.d. noise n i â¼ N that is identically distributed over the interval R with zero mean, variance Ï 2 n and lies in the range [-n, n].</p><p>(A4) Bounded curvature in some neighborhood around the interest point: There exists a positive constant Îº such that the Hessian H of g satisfies H 2 â¤ Îº in the rneighborhood. In Section 3.1, we show a case where this assumption is violated and we propose a modification to address it.</p><p>(A5) Noise Ï n and curvature Îº are small: This in turn implies that m 11 and m 22 are the two dominant entries in M.</p><p>We proceed by computing bounds on the values in M and then use them to compute a bound on the angular error in the estimated normal at O.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bounding entries of M By definition m</head><formula xml:id="formula_1">11 = 1 k â k i=1 (x i - x) 2 .</formula><p>The assumption of the points being evenly distributed in the xy-plane bounds m 11 in the interval:</p><formula xml:id="formula_2">Î¸ 1 r 2 â¤ m 11 â¤ r 2 (2)</formula><p>where Î¸ 1 â [0, 1]. Symmetrically, the same applies for m 22 .</p><p>Also by definition:</p><formula xml:id="formula_3">|m 12 | = 1 k k â i=1 x i y i - 1 k 2 k â i=1 x i k â i=1 y i</formula><p>We assume that x i and y i are independently drawn instances of random variables X and Y respectively. So</p><formula xml:id="formula_4">E[XY ] = E[X].E[Y ],</formula><p>and hence E[m 12 ] = 0. Since x i and y i are bounded in R, we have a trivial upper bound on variance of m 12 as V [m 12 ] â¤ 1 k Î¸ 2 r 4 . It follows from Chebyshev's inequality that with probability 1 -Îµ :</p><formula xml:id="formula_5">|m 12 | â¤ Î¸ 2 r 4 â Îµk = Î¸ 2 r 4 ÎµÏr 2 = Î¸ 2 r â ÎµÏ<label>(3)</label></formula><p>From the Taylor expansion of the surface z = g(x, y) about (0, 0), and the assumption of bounded curvature (A4), we have âx i , y i â R:</p><formula xml:id="formula_6">|z i | = |g(x i , y i )| â¤ Îº x 2 i 2 + y 2 i 2 + n i (4)</formula><p>From the definition of m 13 :</p><formula xml:id="formula_7">|m 13 | = 1 k k â i=1 x i z i - 1 k 2 k â i=1 x i k â i=1 z i â¤ 1 k k â i=1 x i z i + 1 k 2 k â i=1 x i k â i=1 z i</formula><p>Substituting Eqn. (4), and since |x i | â¤ r and |y i | â¤ r:</p><formula xml:id="formula_8">|m 13 | â¤ 2Îºr 3 + 1 k k â i=1 x i n i + r 1 k k â i=1 n i</formula><p>Under the assumption that X and N are independent, we note that 2 for some constant C. Using Chebyshev's inequality, we have that with probability 1 -Îµ:</p><formula xml:id="formula_9">E[x i n i ] = E[x i ]E[n i ] = 0 since E[n i ] = 0. Assume V (x i n i ) = (CrÏ n )</formula><formula xml:id="formula_10">|m 13 | â¤ 2Îºr 3 + Î¸ 3 Ï n â ÎµÏ<label>(5)</label></formula><p>where</p><formula xml:id="formula_11">Î¸ 3 = V (x i n i ) rÏ n + 1 ( 6 )</formula><p>Symmetrically, the same procedure applies to m 23 , by replacing x i by y i .</p><p>Finally for m 33 ,</p><formula xml:id="formula_12">m 33 = 1 k k â i=1 z 2 i - 1 k 2 k â i=1 z i 2 â¤ 1 k k â i=1 z 2 i â¤ 2Îº 2 r 4 + Î¸ 4 Ï 2 n (<label>7</label></formula><formula xml:id="formula_13">)</formula><p>where Î¸ 4 relates the noise variance Ï 2 n to the width, 2n, of the noise range. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Eigen analysis</head><formula xml:id="formula_14">M 11 M 13 M T 13 m 33 v 1 = Î» v 1</formula><p>Expanding to solve the individual equations for v and squaring gives the upper bound:</p><formula xml:id="formula_15">v 2 â¤ (M 11 -Î»I) -2 2 (I + (M 11 -Î»I) -2 M 13 M T 13 ) -1 2 Ã (M 11 -Î»I) 2 M 13 2 + M 13 2 |(m 33 -Î»)|<label>(10)</label></formula><p>It can be shown <ref type="bibr" target="#b4">[5]</ref> that</p><formula xml:id="formula_16">v 2 â¤ Î±(1 + Î±) 1 -2Î± Î» 2 Î» 1 â Î» 2 Î» 1 Î±<label>(11)</label></formula><p>for small Î±.</p><p>Hence the angle between the computed normal and the true normal is bounded from above by</p><formula xml:id="formula_17">tan -1 v 2 â¤ Î» 2 Î» 1 Î± â¤ (m 22 + |m 12 |) (m 11 -|m 12 |) Î±<label>(12)</label></formula><p>Error bound for the estimated normals From Eqns.</p><p>(2),(3),( <ref type="formula" target="#formula_10">5</ref>) and <ref type="bibr" target="#b6">(7)</ref>, we can replace each m i j term in Eqn. <ref type="bibr" target="#b8">(9)</ref> by its appropriate bound value to give:</p><formula xml:id="formula_18">Î± â¤ 2Îº 2 r 4 Î¸ 1 r 2 + Î¸ 4 Ï 2 n Î¸ 1 r 2 + 2 2Îºr 3 + Î¸ 3 Ï n â ÎµÏ Î¸ 1 r 2</formula><p>Since the values Îº, r, Ï n and Ï are always positive, by simplifying and re-arranging, we get:</p><formula xml:id="formula_19">Î± â¤ 2 Î¸ 1 Îº 2 r 2 + Î¸ 4 Î¸ 1 Ï 2 n r 2 + 4 Î¸ 1 Îºr + 2Î¸ 3 Î¸ 1 Ï n r 2 â ÎµÏ</formula><p>Let us define Î² â = m 12 /m 11 and consider cases where Î² &lt; 1/2. Since we have</p><formula xml:id="formula_20">Î» 1 Î» 2 Î± â¤ m 22 m 11 (1 + Î²) (1 -Î²) Î± â¤ KÎ± (13)</formula><p>we have from the previous lower bound</p><formula xml:id="formula_21">Î» 1 Î» 2 Î± â¤ K Î¸ 4 Î¸ 1 Ï 2 n r 2 + 4 Î¸ 1 Îºr + 2Î¸ 3 Î¸ 1 Ï n r 2 â ÎµÏ<label>(14)</label></formula><p>Differentiating Eqn.(14) w.r.t r gives the required result: </p><formula xml:id="formula_22">r = 1 Îº Î¸ 3 Ï n â ÎµÏ + Î¸ 4 2 Ï 2 n 1 3<label>(15)</label></formula><p>where the constants d 1 = Î¸ 3 and d 2 = Î¸ 4 /2, as given in <ref type="bibr" target="#b4">[5]</ref> <ref type="bibr" target="#b3">[4]</ref> are to be determined experimentally. Note that d 1 and d 2 depend only on the distribution of the PCD, since, as shown in Eqns. ( <ref type="formula" target="#formula_10">5</ref>) and ( <ref type="formula" target="#formula_12">7</ref>), Î¸ 3 is related to V (x i n i ) while Î¸ 4 is related to Ï n .</p><p>Estimating the optimal support region size The optimal r is estimated using an iterative procedure based on the suggestions in <ref type="bibr" target="#b4">[5]</ref>. An initial value of k = k (i) is used to compute a starting value of curvature Îº (i) and r (i) is taken as the distance to the k-th nearest neighbor. An estimate of density Ï (i) is also obtained from k = k (i) . The value of Ï 2 is taken from the sensor model as a fixed function of the distance of the point from the laser. The value of r (i+1) for the (i + 1)th iteration is then computed using Eqn.(15). k (i+1) is then computed as the number of points in a neighborhood sized r (i+1) and the process is continued.</p><p>We observed that the iterative procedure suggested in <ref type="bibr" target="#b4">[5]</ref>[4] had poor convergence properties when assumption (A4) is broken. Figure <ref type="figure" target="#fig_2">2</ref> shows the computed values of r (i) oscillating for points selected near regions of higher curvature, as in the case of intersecting walls in Figure <ref type="figure" target="#fig_6">5</ref>. We modify the algorithm to perform damped updates to k using a learning rate Î³ with Î³ â [0, 1] as in:</p><formula xml:id="formula_23">k (i+1) = Î³k (i+1) computed + (1 -Î³)k (i)<label>(16)</label></formula><p>This modification ensures controlled updates in each iteration and assures sensible values of r near intersections of manifolds. This is reflected in the smaller support-region size near the intersections of the two walls in Figure <ref type="figure" target="#fig_6">5</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Terrain Classification</head><p>We focus on segmentation of ladar data into 3 classes clutter to represent vegetation, linear structures to represent thin objects like wires and tree branches, and surface to capture ground, rock and tree-trunk surfaces. Our approach for classification is based on computing saliency features <ref type="bibr" target="#b8">[9]</ref> that capture the local geometry at a point in terms of spatial distribution of points in its neighborhood. The distribution of saliency features is learned using a Gaussian mixture Model (GMM) automatically using the Expectation-Maximization (EM) algorithm. Given the distribution learned off-line, we can classify new data online using a Bayes classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Saliency features</head><p>Our choice of features is inspired by the tensor voting framework in <ref type="bibr" target="#b6">[7]</ref>. However, instead of looking at the distribution of surface normals in a neighborhood, we directly inspect the local distribution of 3-D points. This is done by computing the covariance matrix M ( Eqn. ( <ref type="formula" target="#formula_0">1</ref>) ) corresponding to the scatter of the points in a local neighborhood, the support region.</p><p>The size of the support region defines the scale of the feature and is chosen to be the radius r computed in Section 3.1. Note that M is computed in the intermediate steps while estimating r, and is representative of the local geometry of the neighborhood. Let Î» 1 â¤ Î» 2 â¤ Î» 3 be the eigenvalues of M corresponding to eigen-vectors m 1 , m 2 , m 3 respectively. In case of clutter, Î» 1 â Î» 2 â Î» 3 and there is no dominant direction. For points on surfaces, Î» 3 , Î» 2 Î» 1 and e 3 , e 2 span the local plane of observations. For linear structures Î» 3 Î» 2 , Î» 1 and e 3 is the dominant direction locally. Our saliency feature is defined as a linear combination of eigen-values in the 3-vector:</p><formula xml:id="formula_24">ï£® ï£° point-ness surface-ness curve-ness ï£¹ ï£» â = ï£® ï£° Î» 1 Î» 2 -Î» 1 Î» 3 -Î» 2 ï£¹ ï£» (<label>17</label></formula><formula xml:id="formula_25">)</formula><p>Bayesian classification Using the features of Eqn. ( <ref type="formula" target="#formula_24">17</ref>) and a dataset labeled into the 3 classes, we train a GMM using the EM algorithm. Let the n i components of the Gaussian mixture in the i-th class be specified by the set of weights, means and covariances as C i = {(w (i, j) , Âµ (i, j) , Î£ (i, j) ) j=1...n i } for i = 1, 2, 3. The likelihood of a new point x with feature f (x) â R 3 computed with Eqn.(17) belonging to class C i is given by:</p><formula xml:id="formula_26">P( f (x)|C i ) = n i â j=1 w (i, j) (2Ï) 3/2 |Î£ (i, j) | 1/2 Ã e - 1 2 ( f (x)-Âµ (i, j) ) T Î£ -1 (i, j) ( f (x)-Âµ (i, j) )<label>(18)</label></formula><p>The estimated class is the maximizer of the class posterior:</p><formula xml:id="formula_27">C est = arg max i (P(C i | f (x))) = arg max i (P( f (x)|C i )P(C i )) (<label>19</label></formula><formula xml:id="formula_28">)</formula><p>where P(C i ) represents the corresponding class prior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Sensors and terrains</head><p>To validate the approach presented we used data collected with a Minolta scanner, an actuated SICK laser, a Zoller-FrÃ¶hlich high resolution scanner and the CMU autonomous helicopter. The Minolta Vivid 700 is a laser line striper that produces a 200 Ã 200-pixel range image with 8 bits resolution. A SICK LMS-291 is attached to a custom made scanning mount. The laser collects 60,000 points per scan. The angular separation between laser beams is 1   4   degree over 100 degrees field of view. The angular separation between laser sweeps is 2  3 of a degree over 115 degrees. The Zoller-FrÃ¶hlich (Z+F) LARA 21400 has a 360 o Ã Â±35 o FOV, producing 8000 Ã 1400 pixels range and reflectance images of the environment up to 21.4 m. The CMU autonomous helicopter is equipped with a modified Riegl laser range finder that is capable of collecting 3D color data, with 10 cm accuracy. We used these sensors to collect data from outdoor environments in urban settings, in natural open space and in a forest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Validation of computed normals</head><p>In this section, we validate our implementation of the algorithm proposed by <ref type="bibr" target="#b4">[5]</ref> by testing it on geometric models for which the ground truth normals are known for each point. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Aerial ladar scan</head><p>We tested this approach using data from an open space natural environment containing a 1.5 m high pile of gravel surrounded by short-cut and long grass. We collected high resolution, high density data with the Z+F laser. We also collected low-resolution aerial data for the same scene with the CMU autonomous helicopter. The two data sets are co-registered. We use the Z+F data to produce the ground truth used to estimate the normal reconstruction error in the aerial data.</p><p>Figure <ref type="figure" target="#fig_4">3-(a)</ref> shows the computed normals and the support regions for selected points in the aerial data. Figure <ref type="figure" target="#fig_4">3-(b)</ref> shows the normal and support regions for the same points but overlaid on top of the high-resolution ground data. Points in Figure <ref type="figure" target="#fig_4">3-(a</ref>) are color-coded by the difference between the error in estimated normals and the lowest possible error obtainable for any choice of support region in the aerial data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Validation of support regions</head><p>Outdoor ground scan In some situations, the density varies with the distance to the sensor and may become very low. This is illustrated in Figure <ref type="figure" target="#fig_5">4</ref>, which shows a scan of the ground taken by the SICK laser. The ground truth is defined as normals pointing along the positive z-axis. The noise standard deviation Ï n is computed using calibration data, and depends on the distance to the sensor. Its value ranges from Ï min = 0.0037 at 1 meter, and Ï max = 0.0125 at 60 meters. As expected, the support region size grows with the distance to the sensor. Moreover, the discontinuities located at the boundaries of the laser FOV represent a second important difference and break the assumptions stated in Section 3.1. In this case, it doesn't affect the performance of the algorithm because all the points lie in the same plane.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scan of wall corner</head><p>This dataset is a scan of walls made using the SICK laser, and the sensor was placed at a distance of approximately 30 meters from the scene. Again, Ï n is computed using calibration data, and the same parameters are used in the algorithm. The scene presents a sharp change in curvature at the junction of both walls. This implies the presence of two different manifolds in the neighborhood of points located in that region. Intuitively, we would expect that the support region should be relatively small near the junction, as not to include points lying on a different manifold. However, Figure <ref type="figure" target="#fig_6">5</ref> shows that it is not the case with the original algorithm. Undamped iterations cause the algorithm to stop at arbitrary values after a fixed number of iterations, with no guarantee of convergence. This results in significant error in normal estimation, especially around the Outdoor natural terrain This dataset was obtained using the SICK scanner and by looking at outdoor natural terrain, comprised of ground, trees and vegetation. Again, we would expect the support region to be small near sharp angles in the geometry of the scene, and larger if the scene is flat, or if the density is small. For this dataset, no ground truth is available, therefore the results are evaluated visually. Figure <ref type="figure" target="#fig_0">1</ref> shows the support region determined by our algorithm for different points chosen at interesting locations in the scene. For example, the support regions of points located near the boundary of tree trunks and ground are much smaller than those in the center of the ground. This corresponds to the expected behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ground-based ladar classification of natural terrain</head><p>In this section, we use the algorithm with the classifier described in Section 3.2. The dataset is divided into cubic voxels with 10 cm edges. The classifier is then trained at scales ranging from 0.1 m to 2 m using manually labeled data. The best scale is chosen by applying our method and rounding the resulting support region radius to the nearest subdivision. Figure <ref type="figure" target="#fig_8">6-(a)</ref> shows the classification results using the fixed support region size (radius of 40 cm, determined to be the best fixed scale experimentally) currently in use in our system. Obvious misclassification errors are made near the junction of the leftmost tree and the ground, and on the ground at a distance. Figure <ref type="figure" target="#fig_8">6-(b)</ref> shows the improvement over the old strategy. We also present classification results on data collected with the Riegl scanner, as shown in Figure <ref type="figure" target="#fig_8">6-(c/d</ref>). The data was manually labeled to produce ground truth classification. In performance evaluation, we only consider points that were misclassified using the fixed-scale strategy. The new strategy is found to give a 30% improvement in classification rate for the previously misclassified points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Comparison with multi-scale approach</head><p>A naÃ¯ve alternative to the proposed algorithm is to train a different classifier for each scale in the set of considered scales, evaluate a test point on all the classifiers, and simply assign it the label returned with most confidence (highest posterior probability). However, when applying this strategy (with scales ranging from 0.1 m to 2 m) to outdoor natural terrain such as the one shown in Figure <ref type="figure" target="#fig_8">6</ref>, we obtain a mere 45% of correctly classified points, as opposed to 84% with the method presented in this paper. As expected, the naÃ¯ve strategy incorrectly favors very large support regions that include a large number of out-of-class points to give the commonly incorrect label of "vegetation" with high confidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions and Discussion</head><p>This paper presented a geometry-driven approach for choosing the scale of observation for classifying pointsampled surfaces in outdoor range data. Extensive experiments with outdoor and synthetic datasets confirm our hypothesis that feature computation at scales that are optimal in terms of inferred local geometry improve the quality of classification.</p><p>One implicit hypothesis of the proposed approach is that there exists at least one scale at which the data is classified correctly. Closer analysis of points misclassified in  this hypothesis is violated. We attribute this to (1) the introduction of edge-effects in the chosen features (Eqn. ( <ref type="formula" target="#formula_24">17</ref>)) causing them to be undescriptive of the local geometry, and</p><p>(2) the possibly poor discriminative ability of the classifier.</p><p>The assumption of an underlying surface of bounded curvature at each point is also violated for scattered point clouds.</p><p>In some regions this results in a reduction of confidence for the vegetation class. The design of more representative shape features as well as eigen-analysis for curved and porous geometry is the subject of our current research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Support region sizes for selected points in outdoor vegetated terrain. Points are color-coded by height.</figDesc><graphic coords="1,320.50,216.97,210.04,157.27" type="vector_box" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Let Î» 1 â¤</head><label>1</label><figDesc>We may write the covariance matrix M as M = ï£® ï£° m 11 m 12 m 13 m 12 m 22 m 23 m 13 m 23 m 33 Î» 2 be the eigen-values of M 11 . Using the Gershgorin Circle Theorem (GCT), we have that m 11 -|m 12 | â¤ Î» 1 â¤ Î» 2 â¤ m 22 -|m 12 | Let us define a new dimensionless quantity Î± as: Î± â = |m 13 | + |m 23 | + m 33 m 11 -|m 12 | (9) Let Î» be the smallest eigen-value of M. Using GCT again gives Î» â¤ |m 13 | + |m 23 | + m 33 = Î±(m 11 -|m 12 |) â¤ Î±Î» 1 . If we take the eigen-vector corresponding to the minimum eigen-value of M as [ v T , 1] T , then</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Plot of estimated support region size (r) at each iteration showing improvement with damped updates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>and in the region where the tree trunks meet the ground in Figure 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Normal estimation for the aerial data. Normal estimation and corresponding support region for selected points overlaid on top of the aerial data (a) (see text for explanation of the color coding) and ground data (b) with the elevation color coded.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Plot of ground points with estimated support region size (r). Note the significant decrease in spatial density and corresponding increase in r with distance from the laser position</figDesc><graphic coords="6,61.84,73.12,211.33,145.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Estimate of support region size for wall corner (a) without and (b) with damped updates to k in each iterations.</figDesc><graphic coords="7,91.76,248.66,152.91,128.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Figure 6-(b/d) in the boundary regions of the dataset show that</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Outdoor terrain classification: (a-b) from the data set using in Figure 1 and (c-d) from data collected with the Riegl laser scanner. Points are colored green (vegetation), red (surface) or blue (linear structure). Darker shades indicate higher confidence in the estimated label. (a/c) Former strategy. (b/d) New strategy.</figDesc><graphic coords="8,98.06,244.41,196.50,147.38" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Proceedings of the Fifth International Conference on 3-D Digital Imaging and Modeling (3DIM'05) 1550-6185/05 $20.00 Â© 2005 IEEE</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>Proceedings of the Fifth International Conference on 3-D Digital Imaging and Modeling (3DIM'05)</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Feature extraction from point clouds</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gumhold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Macleod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Intl. Meshing Roundtable</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Scale-space for discrete signals</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lindeberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Scale-space theory: A basic tool for analysing structures at different scales</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lindeberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Statistics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Estimating surface normals in noisy point cloud data</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symp. on Computational Geometry</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Estimating surface normals in noisy point cloud data. Intl</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Geometry and Applications</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multi-scale feature extraction on point-sampled surfaces</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pauly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Keiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">First order augmentations to tensor voting for boundary inference and multiscale analysis in 3-d</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Medioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mordohai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Pose invariant, robust feature extraction from range data with a modified scale space approach</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ibanez-Guzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wijesoma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intl. Conf. on Robotics and Automation</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Natural terrain classification using 3-d ladar data</title>
		<author>
			<persName><forename type="first">N</forename><surname>Vandapel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kapuria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intl. Conf. on Robotics and Automation</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
