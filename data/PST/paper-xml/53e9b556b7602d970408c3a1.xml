<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Island Model Based Ant System with Lookahead for the Shortest Supersequence Problem</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ren~</forename><surname>Michel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Applied Computer Science and Formal Description Methods</orgName>
								<orgName type="institution">University of Karlsruhe</orgName>
								<address>
									<postCode>D-76128</postCode>
									<settlement>Karlsruhe</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Martin</forename><surname>Middendorf</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Applied Computer Science and Formal Description Methods</orgName>
								<orgName type="institution">University of Karlsruhe</orgName>
								<address>
									<postCode>D-76128</postCode>
									<settlement>Karlsruhe</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An Island Model Based Ant System with Lookahead for the Shortest Supersequence Problem</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">39FABCCA2A599786DCD5D841F878E7DA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we introduce an Ant Colony Optimisation (ACO) algorithm for the Shortest Common Supersequence (SCS) problem, which has applications in production system planning, mechanical engineering and molecular biology. The ACO algorithm is used to find good parameters for a heuristic for the SCS problem. An island model with several populations of ants is used for the ACO algorithm. Besides we introduce a lookahead function which makes the decisions of the ants dependent on the state arrived after the decision.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The Shortest Common Supersequence (SCS) problem is a problem with applications in areas like production system planning, mechanical engineering and computational molecular biology (see e.g. <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14]</ref>). Formally, the problem is: Given a set L of strings over an alphabet ~, find a string of minimal length that is a supersequence of each string in L. A string S is a supersequence of a string T if S can be obtained from T by inserting zero or more characters. As an example consider the set L = {abba, acca, cbbc, abca} for which the string acbbca is a shortest supersequenee.</p><p>The SCS problem is NP-complete even for quite restricted problem instances over an alphabet of size 2 ( <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b11">12]</ref>). Dynamic programming algorithms as well as Branch-and-Bound algorithms for SCS have been studied by Fraser <ref type="bibr" target="#b7">[8]</ref>. However, the dynamic programming algorithms are successful only for a very small number of strings, because otherwise, their space requirement is too large. Branch-and-Bound algorithms need to much time to be practical, except for strings over very small alphabets. Several heuristics have also been investigated for SCS <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref>. A genetic algorithm for SCS was proposed in <ref type="bibr" target="#b0">[1]</ref>.</p><p>In this paper we propose an Ant Colony Optimisation (ACO) approach for the SCS problem. ACO is a population based approach for finding good solutions to combinatorial optimisation problems. The idea of ACO was initiated by Dorigo, Maniezzo, and Colorni in <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6]</ref> and has already been applied to several problems like the Travelling Salesman (TSP) problem <ref type="bibr" target="#b5">[6]</ref>, the Vehicle Routing problem <ref type="bibr" target="#b1">[2]</ref>, and the Quadratic Assignment problem <ref type="bibr" target="#b4">[5]</ref>.</p><p>ACO imitates the behaviour of real ants searching for food. Initially, ants search their environment for food in a random manner. As soon as an ant detects a source of food, it evaluates the quality and quantity of the food and carries some of it back to the nest. On its return trip it lays a chemical pheromone trail on the ground. The quantity of that pheromone trail depends on the ants evaluation of the food source and is meant to guide other ants to the discovered source of food and back to the nest. Since other ants will be attracted by the pheromone and also lay their pheromone onto the trail it will become stronger the more ants use it. This has the effect that the closer a source of food is to the nest the stronger the pheromone trail to that source will grow because this trail is frequented more often. Due to the evaporation of the pheromone the trails will not overload. Evaporation is also necessary to keep that system adaptive to changes of the environment and the detection of new food sources. When talking about an algorithmic framework for this mechanism, the set of feasible solutions to the combinatorial problem corresponds to the real ants search area, the objective function corresponds to the amount/quality of the found food, and the pheromone trail has its analogy in an adaptive memory.</p><p>A more detailed explanation on how to put these analogies to work in the case of the TSP and some other problems can be found in <ref type="bibr" target="#b5">[6]</ref>. To apply ACO to a combinatorial problem Dorigo, Maniezzo, and Colorni propose the following steps (see <ref type="bibr" target="#b5">[6]</ref> for detailes): 1. Defining an appropriate graph representation of the problem which ants can search, 2. Defining the autocatalytic feedback process, 3. Defining a constructive heuristic for the problem which works on the graph representation, 4. Defining a constraint satisfaction method.</p><p>Here we propose a different approach which was inspired by the way Branke, Middendorf, and Schneider <ref type="bibr" target="#b0">[1]</ref> put a genetic algorithm for the SCS problem to work: Instead of looking for a graph representation we directly use the string representation of our problem. To each character of a string we associate a parameter and its value guides a fast constructive heuristic that is used by the ants to build up a supersequence. Thus, the paraineter values function as trail information. Not depending on a special graph representation one can hope that this approach can also be applied to other problems. But the advantage of not having to find an appropriate graph representation and a heuristic working on it may lead to problems later: It can be difficult to find an appropriate way of updating the trail information such that ants are guided to good solutions.</p><p>In our ant system we use an island model, i.e. different populations of ants work on the same problem. Every population lays its own pheromone trail which is not accessible to ants of other populations. The populations work not totally independently but exchange trail information after every certain number of iterations.</p><p>We also introduce a lookahead function to our ant system. This makes the choice of which symbol to append next. to the supersequence not only dependent on the heuristic values of the current iteration but. also takes into consideration the influence of that choice on the next iteration. Therefore when deciding whether or not to append some symbol s we do not only have to calculate the probability according to the chosen heuristic but also have to simulate this possible choice and evaluate the resulting state in some way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Heuristics for the SCS Problem</head><p>A well known greedy heuristic for SCS is the Majority Merge (MM) heuristic <ref type="bibr" target="#b6">[7]</ref>. Given a set L of strings MM builds a supersequence starting from the empty string as follows: It looks at the first characters of every string in L (i.e. the front), appends the most frequent symbol, say a to the supersequence and then removes a from the front of the strings. This process is repeated until all strings are exhausted.</p><p>One problem with the MM heuristic, especially when applied to random strings, is that MM does not take into account the possibly different lengths of the strings. Clearly, it makes sense to focus on the long strings when deciding which symbol in the front is chosen next. In <ref type="bibr" target="#b0">[1]</ref> a weighted variant LM of MM was proposed that takes these lengths into account. For each character of a string a weight is assigned which is the length of the remaining string (length of the shortest suffix which contains that character). Formally, for a character si of a string S = sis2...s,~, i E [1 : n] its weight wi is n -i. The heuristic LM works similar to MM but always chooses that symbol of the front whose sum of the weights of all its occurrences in the front is maximal. For ease of description we consider MM in the following as a heuristic that uses a weight of 1 for every character of a string.</p><p>To make the heuristics MM and LM parameter dependent we use an idea from <ref type="bibr" target="#b0">[1]</ref>. To each character si of a string S = sis2 ...s,,, i G [1 : n] we assign a parameter value Ti. The heuristics now choose always that symbol s from the front of the strings for which the sum of the products of the weight and the parameter value of each occurrence of s is maximal.</p><p>Example. Consider the strings in Figure <ref type="figure" target="#fig_3">2</ref> where each character has an associated parameter value. MM would choose an a as the next symbol to append to the supersequence. This is because the sum of the parameter values (times 1) of the a's in the front is 0.25 while the parameter value of the b in the front is 0. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">AS-SCS-MM</head><p>This section provides a more detailed description of AS-SCS-MM, an ACO algorithm which makes use of the MM heuristic described above.</p><p>Let $1, $2,..., Sn denote the n given input strings over an alphabet ~ and sij E Z the character at position j of string i. Each character sij has an associated parameter value rij which has the function of the pheromone trail. During initialisation each 7"ij is set to 1. Let there be m ants searching the solution space. At a given iteration ant k E {1,2,...,m} uses its state vector vk = (vkl, vk~ .... , vkn) to keep track of the progress of the computation of its supersequence $~. vk describes the front of the strings as introduced in chapter 2. For example in a 2-string problem a vector <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b4">5)</ref> would describe a state where the 2 leading characters of the first string and the 4 leading characters of the second string are already embedded in Sk, whereas the third character of string 1 and the fifth character of string 2 are still waiting for a suitable extension of Sk before they can be embedded.</p><p>At the beginning of each iteration these vectors are set to 1. The computation of a supersequence Sk is finished when vk = Vyin where Vyin : (ISll + 1, IS21 + 1,..., IS~l + 1). The candidate-set Ck = {s E 2? I 3i : s = siva,} denotes the set of symbols which are occurring in the actual front of the strings and therefore are possible candidates to be appended to S~ next.</p><p>In the following we describe one iteration of the algorithm from the point of view of some arbitrary ant k. Initially, state vector vk is set to (1, 1,..., 1), Sk is the empty string, and Ck contains exactly those symbols occurring at the beginning of the input strings. As long as the state vector v~ is different from Vyin the following steps are repeated: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&amp; = &amp;s</head><p>(2)</p><p>3. The new state vector vk has to be calculated. Let ,Mk(],Sk]) be the set of characters sivk, in the front for which sivk, = s holds. Vi E {1,..., n} set</p><formula xml:id="formula_0">{ v~i + 1 9 if Sly,, C M~(]$k]) vk~ = ' (3) Vki ; else</formula><p>Now Sk is a valid supersequence of the given input strings and our ant has to calculate the values AT/~ to contribute to the update of the pheromone trail:</p><p>1 which is a measure of quality of the found 1. It calculates the value O = supersequence. 2. Now it can calculate its contribution to the update of the trail. The idea is that the total amount of pheromone added for the characters in a set Mk(l), I C [1 : ISkl] depends on l-the smaller 1 is the more pheromone is added because for small 1 the characters in fl4k(1) should be chosen early. To each character in one set Mk(/) the same amount of pheromone is added.</p><p>Formally, for all l E {1, 2,..., ]Ski} and each character si%i E .Adk(l):</p><formula xml:id="formula_1">0 [Ski-l+ 1 ~ : IM~(l)l I&amp;l (<label>4</label></formula><formula xml:id="formula_2">)</formula><p>At the end of the iteration when all ants have performed the steps described above the overall amount of new trail can be calculated as follows:</p><p>ryt k=l</p><p>The update of the trail values vij is done according to the following formula:</p><formula xml:id="formula_3">7:ij = fl" 7ij + 7ATij (6)</formula><p>where 7 is a parameter which allows to scale the amount of pheromone put onto the trail and p ~ [0, 1] is a value with determines the persistence of the trail information. Low values of p mean only a short time of influence of the pheromone due to evaporation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">AS-SCS-LM</head><p>Instead of the MM heuristic we can also use the LM heuristic to guide the ants on their way to good solutions. All we have to do is to change formula (1) to:</p><formula xml:id="formula_4">1 Ot E ~k : 8ivki ----8 J ;(~,vk) = .<label>(7)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Z [ Z rivki ([Si[-vki+l)] s reck iEI.k :Sivki =s ~</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Lookahead Fhlnction</head><p>To improve the solution quality we propose to use a lookahead funclion which takes into account the influence of the choice of the next symbol to append on the next iteration. Therefore when deciding whether or not to append some symbol s we do not only calculate the probability according to the chosen heuristic but also simulate this possible choice and evaluate the resulting state in some way. In this work we compute the maximum of the sum of products of parameter values and weight for the occurrences of the characters in the resulting state:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>/~(vk,s)= max ( ~ ri%i ) s' E Ok i EIk : Siiki = st (8)</head><p>where ~?k (Ck, Ik) denotes the state vector (candidate-set, index set) that would derive from the vector vk (Ck,Ek) if symbol s was chosen.</p><p>To make use of this lookahead function p the calculation of the transition probabilities is changed accordingly. In the case of AS-SCS-MM formula ( <ref type="formula">1</ref>) is changed to (the parameter fl controls the influence #): Ill the case of AS-SCS-LM fornmla ( <ref type="formula" target="#formula_4">7</ref>) to be changed analogously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">The Pseudo-Random-Proportional Action Choice Rule</head><p>As a possibility to improve the solution quality we used the pseudo-randomproportional action choice rule as introduced by Dorigo and Gambardella <ref type="bibr" target="#b2">[3]</ref>.</p><p>The way an ant determines the next symbol to append to its supersequence now depends on a value q chosen randomly with uniform distribution in [0, 1] and a threshold parameter q0 E [0, 1]: If q _&lt; q0 the symbol s for which p(s, vk) = max p(s/, vk) is chosen to be appended next and otherwise s is chosen according s~ECk to the probability distribution p. The parameter q0 has the effect that the higher q0 is the smaller is the probability to make a random choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Elitist Strategy</head><p>An idea taken from genetic algorithms is the elitist strategy, i.e. to let the best solution found so far contribute to the trail update in every iteration. So the ants search more in the neighbourhood of that solution, in hope of further improving it. For a more detailed explanation of elitist strategy in ACO see <ref type="bibr" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Island Model</head><p>In this paper we introduce an island model approach for ACO. The island model is a concept that is often used for genetic algorithms. In our ACO we have different populations of ants working on the same problem instance independently. This means every population lays its own pheromone trail which is not accessible to ants of other populations. After a certain number of iterations some exchange of best solutions between the populations is done so the populations influence each other via an elitist strategy. In our ACO algorithm every population receives the overall best solution found so far.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>The ACO algorithm was tested on problem instances of different alphabet sizes, different number of strings and also different types of strings. We compare the results with the heuristic LM and with the GA of <ref type="bibr" target="#b0">[1]</ref> that is based on the parameterised version of LM. The used parameter settings are: c~ = 9 and trail persistence p = 0.5, in the case of enabled lookahead function fl = 9, threshold value q0 = 0.9, number of populations was 8 with 2 ants plus two elitist ants in each population, and information exchange took place every 4 iterations. For each test run the ACO algorithms were allowed to perform 150 iterations. The tests were done on a dual-board machine with two Pentium-II 30OMHz processors. The running times of the test runs were up to 20 minutes for larger problem instances (16 strings of length 160 over an alphabet of size 16). In the following tables AS-SCS-LM + (AS-SCS-MM +) denotes AS-SCS-LM (resp. AS-SCS-MM) with lookahead function described in 3.3. Each value is averaged over 5 instances (the same as have been used in <ref type="bibr" target="#b0">[1]</ref>) and 5 runs per instance.</p><p>Table <ref type="table" target="#tab_0">1</ref> shows the results for sets of 16 random strings of length 160 over alphabets of sizes 2, 4, and 16. For all instances AS-SCS-LM + gave better results than AS-SCS-MM + , AS-SCS-LM, GA, and LM. Heuristic LM showed always the worst performance. While the difference in performance are not large for smaller alphabets of size 2 or 4, AS-SCS-LM + clearly outperforms the other algorithms for the alphabet of size 16. Although heuristic MM alone is worse than LM (see <ref type="bibr" target="#b0">[1]</ref>) AS-SCS-MM + with lookahead function performs better than AS-SCS-LM without lookahead function. The results for sets of random strings with different lengths are shown in Table 2. The results are similar to the results for random strings of equal lengths. Again AS-SCS-LM + outperforms AS-SCS-LM and GA for strings over an alphabet of size 16. Since MM is not a good heuristic for strings of different lengths and in contrast to the result for equal length strings, AS-SCS-LM, and the GA perform better than AS-SCS-MM +. Since in many applications the strings to be merged are often interdependent and quite similar we also tested the algorithms on sets of similar strings. These strings were generated as randomly chosen subsequences (of length 80 or 90) of a random string of length 100 over an alphabet of size 4. Observe that it is quite likely that the original supersequence of length 100 is a shortest supersequence.</p><p>Table <ref type="table" target="#tab_2">3</ref> shows that on the "easier" instances of length 90 AS-SCS-LM +, AS-SCS-LM, and the GA could nearly always find a supersequence of length 100 which supposedly is optimal. Heuristic LA performs slightly worse in this case and is much worse for the similar strings of length 80. But also AS-SCS-LM + and especially AS-SCS-LM and AS-SCS-MM + are worse than the GA which could even in this case always find a supersequence of length 100.</p><p>Figure <ref type="figure" target="#fig_3">2</ref> shows the influence of the islands, the Pseudo-Random-Proportional action choice rule, and the trail information on the quality of the solution. In the figure "random proportional" means that the parameter q0 was set to 0, "no is-  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper we presented an Ant Colony Optimisation (ACO) algorithm for the Shortest Common Supersequence (SCS) problem. Instead of using a graph representation of the problem we directly used the string representation of the problem and assigned a pheromone value to each character of the strings. These values guide the ants when applying a heuristic to find a short supersequence. A lookahead function which evaluates the quality of next possible states also influences the decision of the ants. The ACO algorithm was based on an island model where several populations of ants work on the same problem instance independently but exchange their best solution after every certain number of iterations. Our test results show that the ACO algorithm improves the bare heuristic and compares favorably with a genetic algorithm for the SCS problem.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Example parameter assignment</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 .</head><label>1</label><figDesc>Our ant chooses a symbol s E Ck according to the following probability distribution: i E Zk : 8ivki = S t where Zk denotes the set of indices for which vki ~ ISi]+ 1. The parameter a is a mean to control the variance of the distribution. 2. The symbol s is appended to the supersequence:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(v,~')]~ J k i E ~. : sivki ~ J</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Best string length found: 16 random strings of length 80 over an alphabet of size 16, averaged over 15 runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Best string length found: 16 random strings of length 160</figDesc><table><row><cell></cell><cell>LM</cell><cell>GA</cell><cell cols="3">AS-SCS-LM AS-SCS-MM + AS-SCS-LM +</cell></row><row><cell>2</cell><cell cols="2">246.6 241.8</cell><cell>242.2</cell><cell>242.1</cell><cell>241.4</cell></row><row><cell>4</cell><cell cols="2">387.6 377.2</cell><cell>377.1</cell><cell>373.6</cell><cell>371.0</cell></row><row><cell>16</cell><cell cols="2">985.2 965.5</cell><cell>943.4</cell><cell>885.4</cell><cell>876.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Best string length found: 4 random strings of length 80, 4 of length 40</figDesc><table><row><cell></cell><cell>LM</cell><cell>GA</cell><cell cols="3">AS-SCS-LM AS-SCS-MM + AS-SCS-LM +</cell></row><row><cell>2</cell><cell cols="2">112.6 107.9</cell><cell>109.8</cell><cell>111.4</cell><cell>109.4</cell></row><row><cell>4</cell><cell cols="2">159.4 145.5</cell><cell>149.4</cell><cell>152.5</cell><cell>145.6</cell></row><row><cell>16</cell><cell cols="2">296.8 260.2</cell><cell>259.5</cell><cell>263.5</cell><cell>247.6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 . Best string length found:16 similar strings</head><label>3</label><figDesc></figDesc><table><row><cell>Length</cell><cell>LM</cell><cell>GA</cell><cell cols="3">AS-SCS-LM AS-SCS-MM + AS-SCS-LM +</cell></row><row><cell>90</cell><cell cols="2">105.2 100.0</cell><cell>100.6</cell><cell>100.0</cell><cell>100.0</cell></row><row><cell>80</cell><cell cols="2">166.8 100.0</cell><cell>130.0</cell><cell>121.6</cell><cell>116.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>lands" runs were done with only one population containing 16 ants and 16 elitist ants, and the "no trail" curve shows how solution quality developed when ants ignored the trail values. The figure shows clearly that trail information is quite important for finding a good solution. Also the Pseudo-Random-Proportional action choice rule can improve solution quality significantly. For a few number of iterations (&lt; 20) the island model performs slightly worse than the ACO algorithm while it was slightly better for a larger number of iterations (&gt; 20). These results fit well to those obtained in [11] for a genetic algorithm with an island model on several test problems. Since the differences in solution quality between the island model ACO and the "no islands" ACO are quite small, to decide whether the island model is a real advantage over the "no islands" model deserves further investigation.</head><label></label><figDesc></figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Improved heuristics and a genetic algorithm for finding short supersequences</title>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Middendorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OR-Spektrum</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="39" to="46" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Applying the ant system to the vehicle routing problem</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bullnheimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Hartl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Straufl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">end lnt. Conference on Metaheuristics -MIC97</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Ant-Q: A reinforcement learning approach to the traveling salesman problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ML-95, Twelfth Intern. Conf. on Machine Learning</title>
		<meeting>ML-95, Twelfth Intern. Conf. on Machine Learning</meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="252" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">An autocatalytic optimizing process</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Maniezzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Colorni</surname></persName>
		</author>
		<idno>No. 91-016</idno>
		<imprint>
			<date type="published" when="1991">1991</date>
			<pubPlace>Politecnico di Milano, Italy</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The ant system applied to the quadratic assignment problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Maniezzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Colorni</surname></persName>
		</author>
		<idno>No. IRIDIA/94-28</idno>
		<imprint>
			<date type="published" when="1994">1994</date>
			<pubPlace>Belguim</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Universite Libre de Bruxelles</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The ant. system: Optimization by a colony of cooperating agents</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Maniezzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Colorni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Systems, Man, and Cybernetics -Part B</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="41" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Theory and algorithms for plan merging</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Foulser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="143" to="181" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Subsequences and Supersequences of Strings</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Fraser</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
		<respStmt>
			<orgName>Dept. of Computer Science, University of Glasgow</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Approximation algorithms for the shortest common supersequence</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Irving</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nordic Journal of Computing</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="303" to="325" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On the approximation of shortest common supersequences and longest common subsequences</title>
		<author>
			<persName><forename type="first">T</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1122" to="1139" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Experiences with fine-grained parallel algorithms</title>
		<author>
			<persName><forename type="first">U</forename><surname>Kohlmorgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schmeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Haase</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
	<note>to appear in Annals of Operations Research</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">More on the complexity of common superstring and supersequence problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Middendorf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoret. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page" from="205" to="228" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The shortest common supersequence problem over binary alphabet is NP-complete</title>
		<author>
			<persName><forename type="first">K.-J</forename><surname>R~ih~i</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ukkonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoret. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="187" to="198" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Complexity of common subsequence and supersequence problems and related problems</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">G</forename><surname>Timkovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cybernetics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="565" to="580" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
