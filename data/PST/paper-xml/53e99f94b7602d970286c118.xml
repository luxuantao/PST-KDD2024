<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Family of Dissimilarity Measures between Nodes Generalizing both the Shortest-Path and the Commute-time Distances</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yen</forename><surname>Luh</surname></persName>
							<email>luh.yen@uclouvain.be</email>
						</author>
						<author>
							<persName><forename type="first">Marco</forename><surname>Saerens</surname></persName>
							<email>marco.saerens@uclouvain.be</email>
						</author>
						<author>
							<persName><forename type="first">Amin</forename><surname>Mantrach</surname></persName>
							<email>amantrac@ulb.ac.be</email>
						</author>
						<author>
							<persName><forename type="first">Masashi</forename><surname>Shimbo</surname></persName>
							<email>shimbo@is.naist.jp</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">ISYS Unit</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Université catholique de Louvain</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="laboratory">Laboratory</orgName>
								<orgName type="institution">IRIDIA</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Université Libre de Bruxelles</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Graduate School of Information Science Nara Institute of Science and Technology</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<address>
									<addrLine>Las Vegas</addrLine>
									<postCode>2008</postCode>
									<settlement>Nevada</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Family of Dissimilarity Measures between Nodes Generalizing both the Shortest-Path and the Commute-time Distances</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D50A18E6F9C2167E7009A8AA6D1BC272</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.2.8 [Database Management]: Database applications -Data mining</term>
					<term>G.2.2 [Discrete Mathematics]: Graph theory -Graph algorithms</term>
					<term>G.3 [Probability and Statistics]: Markov processes</term>
					<term>I.2.6 [Learning]: Knowledge acquisition Algorithms</term>
					<term>theory</term>
					<term>experimentation Graph mining, biased random walk, kernel on a graph, shortest path, resistance distance, commute-time distance</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work introduces a new family of link-based dissimilarity measures between nodes of a weighted directed graph. This measure, called the randomized shortest-path (RSP) dissimilarity, depends on a parameter θ and has the interesting property of reducing, on one end, to the standard shortest-path distance when θ is large and, on the other end, to the commute-time (or resistance) distance when θ is small (near zero). Intuitively, it corresponds to the expected cost incurred by a random walker in order to reach a destination node from a starting node while maintaining a constant entropy (related to θ) spread in the graph. The parameter θ is therefore biasing gradually the simple random walk on the graph towards the shortest-path policy. By adopting a statistical physics approach and computing a sum over all the possible paths (discrete path integral), it is shown that the RSP dissimilarity from every node to a particular node of interest can be computed efficiently by solving two linear systems of n equations, where n is the number of nodes. On the other hand, the dissimilarity between every couple of nodes is obtained by inverting an n × n matrix. The proposed measure can be used for various graph mining tasks such as computing betweenness centrality, finding dense communities, etc, as shown in the experimental section.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Network link analysis is an important research topic that has been the subject of much recent work in various fields of science: applied mathematics <ref type="bibr" target="#b35">[35]</ref>, social science <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b63">63]</ref>, physics <ref type="bibr" target="#b42">[42]</ref>, computer science <ref type="bibr" target="#b15">[15]</ref>. Within this framework, one key issue is the proper definition of a similarity/dissimilarity measure between the nodes of the network, taking both direct and indirect links into account. Such a meaningful measure should consider two nodes as similar if there are many short paths connecting them (for a short survey of the different link-based dissimilarity measures proposed in the literature, see the related work section below). Once such a dissimilarity matrix has been defined, it can be exploited for various mining tasks, for instance finding communities, outliers, important nodes, etc.</p><p>This paper proposes such a measure of dissimilarity between nodes, together with algorithms for computing it, by applying and extending ideas that appeared in <ref type="bibr" target="#b52">[52]</ref> in the context of routing. The proposed measure will be called the randomized shortest-path (RSP) dissimilarity and has three interesting properties. First, it has a clear, intuitive, interpretation in terms of a biased random walk on the graph. Second, it nicely generalizes the shortest-path and the commute-time distances (also called the resistance distance) by computing an intermediate dissimilarity depending on one parameter θ (the inverse temperature). When θ is large, the dissimilarity reduces to the standard shortest-path distance while for θ = 0, it reduces to the commute-time distance, also called the resistance distance <ref type="bibr" target="#b18">[18,</ref><ref type="bibr" target="#b30">30]</ref>. Third, the dissimilarity between a particular node and all the other nodes can be computed efficiently by solving two linear systems of n equations where n is the number of nodes. On the other hand, all-pairs of nodes dissimilarity can be computed by inverting an n × n square matrix. Notice, however, that while being a distance metric for θ → 0 and θ → ∞, the proposed dissimilarity measure need not satisfy the triangle inequality for intermediate values 0 &lt; θ &lt; ∞, and is therefore not necessarily a distance metric.</p><p>The definition of this dissimilarity measure relies on a model inspired by the work of Akamatsu in transportation networks <ref type="bibr" target="#b3">[3]</ref>, and extended recently by Saerens et al. in <ref type="bibr" target="#b52">[52]</ref> in the framework of network routing. Consider a graph or network G where a positive cost is associated to each arc connecting two nodes. Consider further the infinite set of all possible paths (including cycles) between two nodes of interest. We define a biased random walk on the graph that favors short paths by associating a high probability of following these short paths and a low probability of following long paths. A Boltzmann probability distribution controlled by a parameter θ, having exactly this property, is assigned to this set of paths. It is shown that this choice minimizes the expected cost for reaching node j from node i when a constant cross-entropy with respect to the natural, unbiased, random walk is spread in the graph.</p><p>In this biased random walk model, the expected cost d(j|i) incurred when reaching node j from node i can be computed efficiently by using standard linear algebra. We regard this quantity d(j|i) as the directed dissimilarity between nodes i and j. The randomized shortest-path (RSP) dissimilarity between nodes i and j is defined as the symmetrized quantity d(i, j) = (d(j|i) + d(i|j))/2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related work</head><p>This section provides a short survey of the related work aiming to define meaningful link-based similarities between the nodes of a graph, and taking the form of a dissimilarity measure or a kernel matrix. Similarity between nodes is also called relatedness in the literature and the most well-known quantities measuring relatedness are co-citation <ref type="bibr" target="#b58">[58]</ref> and bibliographic coupling <ref type="bibr" target="#b29">[29]</ref>.</p><p>More sophisticated measures have been proposed as well. In their pioneering work, Klein &amp; Randic <ref type="bibr" target="#b30">[30]</ref> proposed to use the effective resistance between two nodes as a meaningful distance measure. They call this quantity the resistance distance between nodes. Indeed, it can be shown that the effective resistance is a Euclidean distance <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b20">20,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b37">37]</ref>. The close link between the effective resistance and the commute time of a random walker on the graph was established in <ref type="bibr" target="#b10">[10]</ref> while the links between the Laplacian matrix and the commute-time (as well as the Fiedler vector) were studied in <ref type="bibr" target="#b53">[53]</ref>. Therefore, the resistance distance is sometimes called the commute-time distance.</p><p>Chebotarev &amp; Shamis proposed in <ref type="bibr" target="#b11">[11,</ref><ref type="bibr" target="#b12">12]</ref> a similarity measure between nodes integrating indirect paths, based on the matrix-forest theorem. Interestingly, this quantity, called the "regularized Laplacian kernel" <ref type="bibr" target="#b18">[18]</ref>, defines a kernel matrix and is related to the Laplacian matrix of the graph. Ito et al. <ref type="bibr" target="#b25">[25]</ref> further propose the modified regularized Laplacian kernel, an extension of the regularized Laplacian kernel, by introducing a new parameter controlling importance and relatedness. Moreover, in <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b57">57]</ref> it is shown that the regularized Laplacian kernel overcomes some limitations of the von Neumann kernel <ref type="bibr" target="#b27">[27]</ref>, when ranking linked documents. This modified regularized Laplacian kernel is also closely related to a graph regularization framework introduced by Zhou &amp; Schölkopf in <ref type="bibr" target="#b69">[69]</ref>. The exponential and von Neumann diffusion kernels, based this time on the adjacency matrix, are introduced in <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b56">56]</ref>. The defined kernel matrices are computed through a power series of the adjacency matrix of the graph; they are therefore closely related to graph regularization models <ref type="bibr" target="#b31">[31]</ref>.</p><p>Moreover, some authors recently considered similarity measures based on random-walk or electrical concepts. For instance, Harel &amp; Koren <ref type="bibr" target="#b24">[24]</ref> investigated the possibility of clustering data according to some random-walk related quantities, such as the probability of visiting a node before returning to the starting node. They showed that their algorithm is able to cluster arbitrary nonconvex shapes. White &amp; Smyth <ref type="bibr" target="#b64">[64]</ref> investigated the use of the average first-passage time as a similarity measure between nodes. Their purpose was to generalize the random-walk approach of Page et al. <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b43">43]</ref> by capturing a concept of "relative centrality" of a given node with respect to some other node of interest. A recent study, comparing several measures (including the average first-passage time) for analyzing the proximity of nodes in a graph in the framework of co-authorship networks, is presented in <ref type="bibr" target="#b36">[36]</ref>.</p><p>On the other hand, Kondor &amp; Lafferty <ref type="bibr" target="#b31">[31]</ref> as well as Smola &amp; Kondor <ref type="bibr" target="#b59">[59]</ref> defined a graph regularization model related to the graph PCA introduced in <ref type="bibr" target="#b53">[53]</ref>. This model results in the definition of a family of kernels on a graph that provide similarities between nodes, just as any other graph kernel <ref type="bibr" target="#b56">[56]</ref>. An interesting attempt to learn the regularization operator in the context of semi-supervised learning can be found in <ref type="bibr" target="#b72">[72]</ref>. The result is a kernel on a graph maximizing kernel alignment to the labeled data. Still another approach has been investigated by Palmer &amp; Faloutsos <ref type="bibr" target="#b44">[44]</ref> who define a similarity function between categorical attributes, called "refined escape probability", based on random walks and electrical networks. They show that this quantity provides a reasonably good measure for clustering and classifying categorical attributes.</p><p>The "commute-time" (CT) kernel has been introduced in <ref type="bibr" target="#b18">[18,</ref><ref type="bibr" target="#b53">53]</ref> and was inspired by the already mentioned work of Klein &amp; Randic <ref type="bibr" target="#b30">[30]</ref> and Chandra et al. <ref type="bibr" target="#b10">[10]</ref>. It takes its name from the average commute time, which is defined as the average number of steps a random walker, starting from a given node, will take before entering another node for the first time, and go back to the starting node. The CT kernel is defined as the inner product in a Euclidean space where the nodes are exactly separated by the commute-time distance. An interesting method allowing to efficiently compute truncated commute-time neighbors appears in <ref type="bibr" target="#b54">[54]</ref>.</p><p>Almost at the same period, Qiu &amp; Hancock <ref type="bibr" target="#b47">[47,</ref><ref type="bibr" target="#b48">48]</ref>, Ham, Lee, Mika &amp; Schölkopf <ref type="bibr" target="#b23">[23]</ref>, Yen et al. <ref type="bibr" target="#b67">[67]</ref> as well as Brand <ref type="bibr" target="#b8">[8]</ref> defined the same CT embedding, preserving the commute-time distance, and applied it to image segmentation and multi-body motion tracking <ref type="bibr" target="#b47">[47,</ref><ref type="bibr" target="#b48">48]</ref>, to dimensionality reduction of manifolds <ref type="bibr" target="#b23">[23]</ref>, to clustering <ref type="bibr" target="#b67">[67]</ref> as well as to collaborative filtering <ref type="bibr" target="#b8">[8]</ref>, with interesting results. On the other hand, Zhou <ref type="bibr" target="#b70">[70,</ref><ref type="bibr" target="#b71">71]</ref> uses the average first passage time between two nodes as a dissimilarity index in order to cluster them. He studies various greedy clustering techniques based on this dissimilarity index. Another similarity measure related to the average fist-passage time appears in <ref type="bibr" target="#b62">[62]</ref>. It is defined as the escape probability, that is the probability that a random walker starting from one node will visit the other node, before returning to the starting node. The resulting similarity is directed and closely related to the effective conductance between the two nodes. Also related is the measure investigated by Koren et al. <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b33">33]</ref>. In this work, the authors propose to replace the effective conductance by a cycle-free effective conductance.</p><p>In two recent papers <ref type="bibr" target="#b39">[39,</ref><ref type="bibr" target="#b40">40]</ref>, Nadler et al. as well as Latapy et al. <ref type="bibr" target="#b46">[46]</ref> proposed a well-formulated distance measure between nodes of a graph based on a diffusion process, called the "diffusion distance". A valid kernel, called the "Markov diffusion kernel" has been derived from this diffusion distance in <ref type="bibr" target="#b19">[19]</ref>. An application of the diffusion distance to dimensionality reduction and graph visualization appears in <ref type="bibr" target="#b34">[34]</ref>. The natural embedding induced by the diffusion distance is called the "diffusion map" by Nadler et al. <ref type="bibr" target="#b39">[39,</ref><ref type="bibr" target="#b40">40]</ref>. Moreover, in <ref type="bibr" target="#b46">[46]</ref>, Pons &amp; Latapy defined a hierarchical clustering approach for clustering the nodes according to the squared diffusion distance.</p><p>Two recent PageRank-inspired attempts to define meaningful similarities between nodes appear in <ref type="bibr" target="#b22">[22,</ref><ref type="bibr" target="#b45">45,</ref><ref type="bibr" target="#b61">61]</ref>. In these two last works, the authors propose a random walk with restart procedure while in the first work, Gori and Pucci define a random walk pro-cess starting from the node of interest, controlled by some precomputed correlation matrix between nodes. These two algorithms are thus inspired from the well-known PageRank procedure <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b43">43]</ref>, adapted in order to provide relative similarities between nodes. Yet another PageRank-inspired algorithm defining similarities between nodes was proposed in <ref type="bibr">[6]</ref>. It provides a general way of computing similarities between the nodes of two different graphs. Applying this procedure to the same graph allows to find self-similarities, that is, similarities between nodes of the same graph. Finally, a similarity between nodes based on the number of different paths connecting two nodes, and therefore on the maximum flow/minimum cut, is studied in <ref type="bibr" target="#b38">[38]</ref>. This measure has been tested in two collaborative recommendation tasks <ref type="bibr" target="#b18">[18]</ref>, but did not perform well in this context. Finally, Tahbaz-Salehi &amp; Jadbabaie <ref type="bibr" target="#b60">[60]</ref> introduce a oneparameter family of algorithms that, as the algorithm developed in this work, recover both the Bellman-Ford procedure for finding shortest paths as well as the iterative algorithm for computing the average fist-passage time. However, it is based on heuristic grounds and not on a well-defined cost function to optimize.</p><p>There are also several attempts to generalize graph kernels to directed graphs. Indeed, not all of the above mentioned similarity measures are applicable to directed graphs. For instance, an extension of the Laplacian matrix to directed graphs is proposed in <ref type="bibr" target="#b14">[14]</ref> while an extension of the regularized Laplacian kernel to directed graphs appears in <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b2">2]</ref>. Zhou et al. <ref type="bibr" target="#b69">[69]</ref> used the regularized normalized Laplacian matrix defined in <ref type="bibr" target="#b14">[14]</ref> in the context of semisupervised classification of labeled nodes of a directed graph while Chen et al. <ref type="bibr" target="#b13">[13]</ref> used the same kernel matrix, but this time unnormalized, for directed graph embedding. Zhao et al. <ref type="bibr" target="#b68">[68]</ref> propose a directed contextual distance and define a directed graph from which the Laplacian matrix is computed. It is then used for ranking and clustering images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Contributions &amp; organization</head><p>This work has three main contributions: (i) the randomized shortest-path (RSP) dissimilarity, generalizing both the shortest-path and the commute-time distances, is introduced; (ii) it is shown that the RSP dissimilarity can be computed efficiently from the cost or adjacency matrix of the graph, and (iii) the RSP dissimilarity is applied to two graph mining tasks, namely computing betweenness centrality and nodes clustering.</p><p>Section 2 develops the model as well as the procedure for computing the directed dissimilarity between two nodes, from which the RSP dissimilarity is derived as its symmetrized version. Section 3 describes an algorithm for computing the RSP dissimilarity between every pair of nodes. Section 4 presents some simple experiments on clustering and betweenness to demonstrate the properties of the dissimilarity. Section 5 is the conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">THE RSP DISSIMILARITY MEASURE</head><p>The basis of the dissimilarity measure we propose is a new, biased, random walk model in which each path between two nodes of interest is assigned an independent probability of being followed, such that the incurred expected cost-to-go from one node to the other is minimized under a fixed degree of randomness. The dissimilarity measure will then be defined in terms of this expected cost-to-go, or the expected energy. We first introduce the notation and the natural (or unbiased) random walk on the graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Graph and natural random walk</head><p>Consider a weighted directed graph or network, G, with a finite set of n nodes (or vertices) V and a set of arcs (or edges) E, without self-loops. To each arc linking node k and node k (denoted as k → k ), we associate a weight c kk &gt; 0 representing the immediate cost of following this arc. If there is no arc from k to k , we simply consider that c kk takes a large value, denoted by ∞. The cost matrix C is the matrix containing the immediate costs c kk .</p><p>Given this cost matrix, a natural random walk on the graph will be defined in the following obvious way. The choice to follow an arc k → k will be made according to the transition probability of jumping from node k to its successor node k ∈ S(k), where S(k) = {k | (k → k ) ∈ E} is the set of successors of k. The transition probabilities defined on each node k will be denoted as p kk = P(k |k) for k ∈ S(k). For nodes k ∈ S(k), the corresponding transition probabilities are set to zero, so p kk = 0. The natural random walk will be defined by</p><formula xml:id="formula_0">p ref kk = (1/c kk )/( n k =1 (1/c kk )</formula><p>) and the corresponding transition probability matrix containing the p ref kk is P ref .</p><p>In other words, the random walker chooses to follow an arc with a probability proportional to the inverse of the immediate cost, therefore locally favoring arcs having a low cost. If, instead of C, we are given an affinity (adjacency) matrix with elements a kk indicating the affinity between node k and node k , the corresponding costs are computed from c kk = 1/a kk and the transition probabilities associated to each node are simply proportional to the affinities (and then normalized). Notice that other relations (not only the inverse relation) between affinity and cost could be considered as well. These transition probabilities corresponding to the natural random walk will be used as reference probabilities later; hence the addition of the superscript "ref" on the transition probability matrix P ref .</p><p>The rest of Section 2 deals with the problem of measuring the dissimilarity between a fixed pair of nodes. The computation of all-pairs dissimilarities will be discussed in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Dissimilarity measures based on minimum expected cost/energy</head><p>Suppose we are interested in the dissimilarity between a fixed pair of nodes i and j. We consider a random walk starting from node i and eventually reaching node j, at which point the walk is terminated. Thus node i is called the initial node, and j the destination node. To ensure termination upon reaching node j, we modify the graph structure and make j an absorbing node having no outgoing arcs (i.e., c jk = ∞, ∀k ∈ V ). We also assume a problem structure (the graph and costs) such that any natural random walk will eventually reach the destination node j with probability one; i.e., termination is inevitable. The conditions for which this is true are, basically, related to the fact that the destination node can be reached in a finite number of steps from any potential initial node, hence this assumption does not restrict the applicability of the model severely. For a rigorous treatment, see for instance <ref type="bibr" target="#b5">[5]</ref>.</p><p>Let R be the set of all paths (including cycles) from node i to node j in the modified graph (with node j absorbing). R is generally an infinite (but countable) set. We define a probability distribution over set R representing the probability P(℘) of choosing path ℘ among all the paths from node i to j. Our idea is to seek the probability distribution minimizing the expected cost-to-go among all the probability distributions having a fixed relative cross-entropy with respect to the natural random walk on the graph. This choice naturally defines a probability distribution on the set of paths such that long (with a high cost) paths between i and j occur with a low probability while short paths (with a low cost) occur with a high probability. We then use this expected cost as a dissimilarity measure.</p><p>Let us denote the total cost associated to path ℘ as E(℘), henceforth, following the statistical physics terminology, referred to as the energy of that path. We assume that the total cost associated to a path is additive, i.e., for a path</p><formula xml:id="formula_1">℘ = (i = k 0 , k 1 , . . . , k τ (℘) = j) represented as a sequence of nodes, E(℘) = τ (℘) t=1 c k t-1 k t .</formula><p>Here, recall that ℘ ∈ R is a valid path from node i to node j in the modified graph in which j is made an absorbing node. Hence the path is finite, and every k t = j for any t = τ (℘). Moreover, c k t-1 k t = ∞ along that path.</p><p>We now derive the path probability distribution minimizing the expected energy for reaching node j from i, and subject to a fixed relative entropy (Kullback-Leibler divergence; see for instance <ref type="bibr" target="#b16">[16]</ref>) with respect to the reference probability. To be precise, we seek the solution (probability distribution) P(℘) to the following constrained optimization problem:</p><formula xml:id="formula_2">minimize ℘∈R P(℘)E(℘) subject to ℘∈R P(℘) ln P(℘) P ref (℘) = J0 (<label>1</label></formula><formula xml:id="formula_3">)</formula><p>where P ref (℘) represents the probability of following path ℘ when walking according to the natural random walk, i.e., when using transition probabilities p ref kk . J 0 is provided a priori by the user, according to the desired degree of randomness he is willing to concede. In this work, the value of J 0 will be a parameter fixed by the user; when J0 tends to 0, we recover the natural random walk while as J0 increases, the path probability distribution will be more and more peaked around the shortest paths. By defining the Lagrange function</p><formula xml:id="formula_4">L = ℘∈R P(℘)E(℘) + λ ℘∈R P(℘) ln P(℘) P ref (℘) -J0 + µ ℘∈R P(℘) -1<label>(2)</label></formula><p>and observing that its derivative with respect to the path probabilities should vanish at the minimum, we obtain the following probability distribution</p><formula xml:id="formula_5">P(℘) = P ref (℘) exp [-θE(℘)] ℘∈R P ref (℘) exp [-θE(℘)]<label>(3)</label></formula><formula xml:id="formula_6">= exp -θE(℘) + ln P ref (℘) ℘∈R exp -θE(℘) + ln P ref (℘)<label>(4)</label></formula><p>where θ = 1/λ is called the inverse temperature in statistical physics. Thus, as expected, short paths (having small E(℘)) are favored in that they have a large probability of being followed. In other words, the random walk is more and more biased towards the shortest path as θ increases.</p><p>With the probability distribution minimizing the expected energy at hand, we define the directed dissimilarity between i and j exactly as this minimum expected energy, and denote it by d(j|i). In other words, d(j|i) is the expected cost incurred when reaching node j from node i, according to the probability distribution P(℘) provided by Equation (4). We can also define a symmetric dissimilarity measure d(i, j) through d(i, j) = (d(j|i) + d(i|j))/2. We call d(i, j) the symmetric randomized shortest-path (RSP) dissimilarity, or symmetric dissimilarity for short.</p><p>These dissimilarity measures depend on the parameter θ. Equation (3) implies that when θ is large, the probability distribution on the paths is peaked on the shortest path. On the other hand, when θ is near zero, the exponential in Equation (3) tends to 1 and the Markov chain reduces to the natural random walk defined previously. In this case, the directed dissimilarity simply becomes the expected cost for reaching the destination node. Indeed, for θ = 0, it has been shown that this expected cost d(j|i) can be computed from the elements of the pseudoinverse of the Laplacian matrix of the graph for the natural random walk; see Equation <ref type="bibr" target="#b18">(18)</ref> in <ref type="bibr" target="#b18">[18]</ref>. A little calculus shows that the symmetric quantity d(i, j) = (d(j|i) + d(i|j))/2 becomes independent of the costs cij and is proportional to the commute-time between nodes i and j. Therefore, the symmetric dissimilarity d(i, j) provides the commute-time distance, up to a proportional factor, when θ = 0. Notice that the symmetric RSP dissimilarity is a Euclidean distance when θ is near zero (commute-time distance), a distance when θ is large (shortest-path distance), but it is not necessarily a distance for intermediate values of θ. We indeed observed experimentally that the triangular inequality could not be respected for intermediate values of θ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Partition function</head><p>We defined the directed dissimilarity d(j|i) as the expected energy for reaching the destination node j from the initial node i, under the probability distribution given by Equation ( <ref type="formula" target="#formula_6">4</ref>). We show that this expected energy can be computed from a quantity, Z, defined as</p><formula xml:id="formula_7">Z = ℘∈R exp -θE(℘) + ln P ref (℘) , (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>and which corresponds to the partition function in statistical physics (see <ref type="bibr" target="#b26">[26]</ref> or any textbook in statistical physics; for instance <ref type="bibr" target="#b50">[50,</ref><ref type="bibr" target="#b55">55]</ref>). The expected energy E = ℘∈R P(℘)E(℘) can be obtained in terms of the partition function via</p><formula xml:id="formula_9">E = ∂(-ln(Z)) ∂θ = ℘∈R exp -θE(℘) + ln P ref (℘) Z E(℘).</formula><p>(6) The partition function is related to other quantities of interest as well <ref type="bibr" target="#b52">[52]</ref>. For instance, the expected number of transition steps through arc k → k is given by</p><formula xml:id="formula_10">η kk = 1 θ ∂(-ln(Z)) ∂c kk (7) = ℘∈R exp -θE(℘) + ln P ref (℘) Z δ(℘; k, k )<label>(8)</label></formula><p>where δ(℘; k, k ) indicates the number of times arc k → k is present in path ℘, and thus the number of times the arc is traversed. The expected number of passages in node k is then provided by</p><formula xml:id="formula_11">η k = n l=1 η lk (<label>9</label></formula><formula xml:id="formula_12">)</formula><p>which corresponds to the expected number of incoming transitions. We will use η kk to compute the betweenness centrality measures <ref type="bibr" target="#b41">[41,</ref><ref type="bibr" target="#b63">63]</ref> in Section 3. Notice that the definition for the partition function (Equation ( <ref type="formula" target="#formula_7">5</ref>)) involves summation over (generally an infinite number of) paths in R. In Section 2.4, we will discuss how to compute the partition function efficiently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Efficient computation of the partition function</head><p>By applying the ideas introduced by Akamatsu <ref type="bibr" target="#b3">[3]</ref>, let us show how the partition function Z can be computed from the cost matrix.</p><p>Recall that we have changed the costs c jk to ensure that the random walk terminates at the destination node j (see Section 2.2). The cost matrix after this change, denoted by C, is identical to the original cost matrix C except that elements of row j consist entirely of ∞. Consequently, the modified cost matrix takes the following form</p><formula xml:id="formula_13">C=   Qc ∞ T R c   . . . j . . .<label>(10)</label></formula><p>The corresponding transition-probabilities matrix for the natural random walk will be denoted by P ref ; it is obtained from P ref by replacing row j with 0 T . From the modified cost matrix C, we build a new matrix W, given by</p><formula xml:id="formula_14">W = P ref • exp -θ C = exp -θ C + ln P ref , (<label>11</label></formula><formula xml:id="formula_15">)</formula><p>where the logarithm/exponential functions are taken elementwise and the operator • is the elementwise (Hadamard) matrix product. Now, since ln</p><formula xml:id="formula_16">P ref (℘) = τ (℘) t=1 ln p ref k t-1 k t , we easily observe that element (i, j) of the matrix W t ( W to the power t) is [ W t ] ij = ℘∈R(t) exp[-θE(℘) + ln P ref (℘)]</formula><p>where R(t) is the set of paths connecting the initial node i to the destination node j in exactly t steps. Consequently, the partition function is</p><formula xml:id="formula_17">Z = ∞ t=1 ℘∈R(t) exp -θE(℘) + ln P ref (℘) = ∞ t=1 W t ij .</formula><p>Thus element i of the jth column of the matrix ∞ t=1 W t corresponds to the partition function when starting from node i. Computing this infinite series for the problem at hand is relatively easy: the series of powers of W provides ∞ t=1 W t = (I -W) -1 -I, which converges if the spectral radius of W, ρ( W), is less than 1. Thus Z can be computed thanks to (we assume i = j in the sequel)</p><formula xml:id="formula_18">Z = (I -W) -1 -I ij = e T i (I -W) -1 e j . (<label>12</label></formula><formula xml:id="formula_19">)</formula><p>Now, if we pose Z = (I -W) -1 , the partition function is Z = [ Z] ij = z ij . Thus, the matrix Z plays a role similar to the fundamental matrix in the theory of finite Markov chains <ref type="bibr" target="#b28">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Computing the main quantities</head><p>From Equations ( <ref type="formula">6</ref>) and ( <ref type="formula" target="#formula_10">8</ref>), we see that in order to obtain the quantities of interest, namely E and η kk , we have to compute the derivatives of Z, provided by Equation ( <ref type="formula" target="#formula_18">12</ref>), with respect to θ and c kk (the calculus is quite similar to the one appearing in <ref type="bibr" target="#b52">[52]</ref>; see that paper for details). To compute these quantities, we only need the ith row and the jth column of matrix Z, which are given by the column vectors 1 z i = Z T e i and z j = Ze j . These vectors can be obtained by solving the following linear systems of equations</p><formula xml:id="formula_20">(I -W) T z i = e i and (I -W) z j = e j . (<label>13</label></formula><formula xml:id="formula_21">)</formula><p>Let us denote the elements of Z by z kk = [ Z] kk . By definition, we have</p><formula xml:id="formula_22">z ik = [ z i ] k and z kj = [ z j ] k for any k. In particular, Z = zij = [ zi]j = [ zj]i.</formula><p>1 In order to keep the notations as simple as possible, the two vectors are differentiated by their indexes, i and j, which, we concede, is not very orthodox.</p><p>Algorithm 1 Computation of the directed dissimilarity between node i and node j.</p><p>Input: Node i is the initial node while node j is the destination node. The graph has one single connected component containing n nodes. θ &gt; 0: the parameter controlling randomness. C: the n × n cost matrix. P ref : the n × n reference transition-probabilities matrix. Output: The directed dissimilarity between nodes i and j, d(j|i).</p><p>1. In matrix C, replace each entry of row j by ∞ and denote the resulting matrix by C (j) . 2. W (j) = P ref • exp -θ C (j) , where • is the elementwise product, and the exponential is taken elementwise.</p><formula xml:id="formula_23">3. if ρ( W (j) ) ≥ 1 then 4.</formula><p>return "The spectral radius is greater than one." 5. end if 6. Solve I -W (j) T z</p><formula xml:id="formula_24">(j) i = ei and I -W (j) z (j) j = ej</formula><p>with respect to z (j) i and z</p><p>(j)</p><formula xml:id="formula_25">j . 7. return d(j|i) = - ( z (j) i ) T C (j) • W (j) z (j) j [ z (j) i ] j</formula><p>Now, for the expected energy or expected cost, we obtain, after differentiating Z provided by Equation ( <ref type="formula" target="#formula_18">12</ref>),</p><formula xml:id="formula_26">E = ∂(-ln Z) ∂θ = - z T i ( C • W) zj z ij . (<label>14</label></formula><formula xml:id="formula_27">)</formula><p>The expected number of passages through arc k → k is</p><formula xml:id="formula_28">η kk = 1 θ ∂(-ln Z) ∂ c kk = z ik z k j exp -θ c kk + ln p ref kk z ij (<label>15</label></formula><formula xml:id="formula_29">)</formula><p>for k = j. The expected number of passages through node k is</p><formula xml:id="formula_30">η k = z k j zij n k=1 z ik exp -θ c kk + ln p ref kk = z ik z k j zij (<label>16</label></formula><formula xml:id="formula_31">)</formula><p>for k = j. The variables z ik and z k j are therefore similar to the forward/backward variables when estimating transition probabilities in a hidden Markov model <ref type="bibr" target="#b49">[49]</ref>. The difference here is that we are dealing with general graphs and not with acyclic graphs (lattices), as in hidden Markov models. As stated earlier, the directed dissimilarity between node i and node j is defined as the expected cost incurred when reaching node j from node i: d(j|i) = E. In Algorithm 1, we present the pseudocode for computing the directed dissimilarity between node i and node j. In the pseudocode, we added the superscript (j) to variables C, W, zi, and zj, to stress their dependence on the destination node j.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">COMPUTING DISSIMILARITIES BETWEEN EVERY PAIR OF NODES</head><p>We now discuss how to compute the directed dissimilarity between every pair of nodes. Thus our objective is to compute the directed dissimilarity matrix D whose elements are given by [D] ij = d(j|i). Notice that instead of fixing the entropy, we fix the parameter θ which is kept constant for every pair of nodes. A straightforward approach would be to apply Algorithm 1 repeatedly for every pair of nodes i and j. But a better approach is desirable, as each run of Algorithm 1 involves solving (I -W) T z i = e i and (I -W) z j = e j (Equation ( <ref type="formula" target="#formula_20">13</ref>)), with different W for different j. Let us first restate Equation ( <ref type="formula" target="#formula_26">14</ref>) for a given pair of i and j, with an explicit superscript (j) added to variables to represent their dependence on j:</p><formula xml:id="formula_32">d(j|i) = - ( z (j) i ) T ( C (j) • W (j) ) z (j) j z (j) ij . (<label>17</label></formula><formula xml:id="formula_33">)</formula><p>By defining</p><formula xml:id="formula_34">Z (j) = (I -W (j) ) -1 , z<label>(j) i and z</label></formula><p>(j) j are computed from z (j) i = ( Z (j) ) T e i and z</p><formula xml:id="formula_35">(j) j = Z (j) e j . (<label>18</label></formula><formula xml:id="formula_36">) Let W = P ref • exp [-θC].</formula><p>It is easy to see that W (j) can be computed from W by replacing its jth row by zeroes (a zero row, 0 T ). Equivalently, C (j) is computed from C by replacing its jth row by a ∞ T row. By defining w j = row j (W), where row j returns the column vector containing the transpose of row j, W and W (j) are related by W (j) = W -e j w T j . Finally, we show how to compute efficiently all the entries of D in terms of Z = (I -W) -1 . This is a simple application of the Sherman-Morrison formula <ref type="bibr" target="#b21">[21]</ref>,</p><formula xml:id="formula_37">(A + cd T ) -1 = A -1 - A -1 cd T A -1 1 + d T A -1 c , (<label>19</label></formula><formula xml:id="formula_38">)</formula><p>which allows to compute</p><formula xml:id="formula_39">Z (j) = (I -W (j) ) -1 in terms of Z = (I -W) -1 . Indeed, from W (j) = W -ejw T j , we have (I - W (j) ) = (I -W) + e j w T j .</formula><p>By setting A = (I -W), c = e j and d = w j in Equation ( <ref type="formula" target="#formula_37">19</ref>), we obtain</p><formula xml:id="formula_40">Z (j) = Z - Ze j w T j Z 1 + w T j Ze j = I - z j w T j 1 + w T j z j Z<label>(20)</label></formula><p>From Equation ( <ref type="formula" target="#formula_26">14</ref>), once the matrix Z (j) has been computed, the column j of the dissimilarity matrix D, dj = colj(D), is</p><formula xml:id="formula_41">dj = -( Z (j) ( C (j) • W (j) ) Z (j) ej) ÷ ( Z (j) ej)<label>(21)</label></formula><p>where ÷ is the elementwise division. In Algorithm 2, the procedure for computing the similarity between every node i and node j is detailed. The directed dissimilarity matrix is then defined by D = d1 d2 • • • dn . The symmetrized dissimilarity that will be used in the experiments and which reduces to the commutetime distance for a small θ is simply</p><formula xml:id="formula_42">D RSP = (D + D T )/2.</formula><p>Moreover, it is not hard to show that the expected number of passages through each arc and node can be computed by the same trick. For instance, let N (j) be the matrix containing as elements [ N (j) ] ik , the expected number of passages through node k when starting from node i and ending in node j (absorbing node). Using the same notation as in Algorithm 2, this matrix can be computed by</p><formula xml:id="formula_43">N (j) = (Diag( z (j) j )) -1 Z (j) Diag( z (j) j )<label>(22)</label></formula><p>From the expected number of passages through each arc when starting from node i and ending in j, η (j) kk (i, j) (see Equation ( <ref type="formula" target="#formula_30">16</ref>)), a betweenness centrality measure can easily be computed in the same spirit as the random-walk betweenness proposed by Newman in <ref type="bibr" target="#b41">[41]</ref>. The RSP betweenness centrality of a node k will therefore be defined as the net flux entering in node k for all possible pairs of initial and destination nodes:</p><formula xml:id="formula_44">b k = 1 2(n -1)(n -2) i,j:i =j =k k ∈N (k) |η (j) k k (i, j) -η (j) kk (i, j)|</formula><p>Algorithm 2 Computation of the symmetric RSP dissimilarity matrix between all pairs of nodes. Input: The graph has one single connected component containing n nodes. θ &gt; 0: the parameter controlling randomness. C: the n × n cost matrix. P ref : the n × n reference transition-probabilities matrix. Output: The symmetric RSP dissimilarity matrix D RSP .</p><p>1.</p><formula xml:id="formula_45">W = P ref • exp [-θC],</formula><p>where • is the elementwise product, and the exponential is taken elementwise. 2. if ρ( W (j) ) ≥ 1 then 3.</p><p>return "The spectral radius is greater than one." 4. end if 5. Z = (I -W) -1 6. for j = 1 to n do 7.</p><p>In matrix C, replace each entry of row j by ∞ and denote the resulting matrix as C (j) . 8.</p><p>In matrix W, replace each entry of row j by 0 and denote the resulting matrix as W (j) . 9.</p><p>Define wj = rowj(W) and zj = colj(Z).</p><p>10.</p><formula xml:id="formula_46">Z (j) = I - z j w T j 1 + w T j z j Z 11. z (j) j = col j ( Z (j) ) 12. dj = -( Z (j) ( C (j) • W (j) ) z (j) j ) ÷ z (j)</formula><p>j where ÷ is the elementwise division. 13. end for</p><formula xml:id="formula_47">14. D = d 1 d 2 • • • d n 15. return D RSP = (D + D T )/2</formula><p>where N (k) is the set of nodes adjacent to k. This betweenness reduces to Freeman's betweenness <ref type="bibr" target="#b63">[63]</ref> based on shortest paths when θ → ∞ and is very similar in spirit to Newman's betweenness <ref type="bibr" target="#b41">[41]</ref> when θ → 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTAL RESULTS</head><p>The experimental section aims to answer two important research questions, namely (1) Does the RSP dissimilarity behave correctly, according to our intuition. For instance, the dissimilarity should be highly correlated with the shortest-path distance when θ → ∞ and with the commute-time distance when θ → 0. (2) Do the results obtained by using the RSP dissimilarity differ significantly from the results obtained when using the shortest-path and the commutetime distances. In other words, does the RSP dissimilarity show some added value in graph mining tasks. In order to investigate these questions, we performed three simple experiments.</p><p>First experiment. This first experiment aims at computing the linear correlation between the RSP dissimilarity, the shortest-path distance and the commute-time distance for various graphs. Two examples of such correlations study are shown in Figures <ref type="figure" target="#fig_1">1(a)-(b)</ref>, for the graph constructed from documents belonging to five newsgroups (figure a; for details about the dataset and the graph construction, see <ref type="bibr" target="#b65">[65]</ref>) and for the IMDb graph (figure b; described in <ref type="bibr" target="#b66">[66]</ref>). Notice that various other graphs were analyzed as well (Zachary karate club, dolphins network, Florentine families, netscience co-authorship network, etc); the results and conclusions were similar but are not reported here. From Figures <ref type="figure" target="#fig_1">1 (a)-(b)</ref>, we clearly observe that the RSP dissimilarity is highly correlated with the commute-time distance when θ → 0 and with the shortest-path distance when θ → ∞ (actually, it is already met when θ = 15). We also observe that for intermediate values of θ, the RSP dis-   . similarity still remains correlated with both the shortest-path and the commute-time distances. However, in a range of θ values of about [10 -3 , 1], the correlation of the RSP dissimilarity with the shortest-path distance, and more obviously with the commute-time distance, tend to stagnate and even eventually decrease. This somewhat counter-intuitive behavior could be explained by the fact that some high-probability paths promoted by the shortest-path and the commute-time policy could be conflicting, which results in a decrease in correlation.</p><p>Second experiment. This second experiment aims to compare the clustering results obtained on a graph node clustering task, for various values of θ. In this experiment, we used exactly the same methodology and datasets as in <ref type="bibr" target="#b65">[65,</ref><ref type="bibr" target="#b66">66]</ref>. In summary, a kernel k-means is performed on various graphs in order to retrieve the clusters, as detailed in <ref type="bibr" target="#b65">[65,</ref><ref type="bibr" target="#b66">66]</ref>. Due to the lack of space, only the results on a newsgroup as well as on the IMDb datasets will be presented. To this aim, a similarity matrix on a graph is derived from the RSP dissimilarity matrix, KRSP = - 1  2 HDRSPH, where H = I -ee T /n is the centering matrix and e is a column vector full of ones. This is the standard way for deriving a similarity from a dissimilarity <ref type="bibr" target="#b7">[7]</ref> when the dissimilarity matrix contains square distances. Indeed, the commute-time distance is the square of the Euclidean commute-time distance, which is Euclidean (see <ref type="bibr" target="#b18">[18,</ref><ref type="bibr" target="#b53">53]</ref> for details). Thus, when θ is small, the commute-time kernel, the natural kernel associated to the Euclidean commute-time distancewhich takes the form of the pseudoinverse of the Laplacian matrix <ref type="bibr" target="#b18">[18]</ref> -is obtained. Notice that the matrix KRSP is not necessarily semi-positive definite; for instance, the shortest-path distance is not Euclidean. In Figures <ref type="figure" target="#fig_1">1 (c</ref>) and (d), the correct classification rate, averaged on 20 runs, is displayed in terms of parameter θ for the newsgroup and the IMDb datasets respectively. The results are reported for two different settings of the clustering algorithm: with and without the computation of a sigmoid transform of the kernel matrix. Indeed, it has been observed that the sigmoid transform on the commute-time kernel allows to improve the performances of the clustering <ref type="bibr" target="#b65">[65,</ref><ref type="bibr" target="#b66">66]</ref>. First, we observe that when θ → 0, the clustering performances of the basic algorithm are poor. But the application of the sigmoid transform allows to smoothen the curve and raise the performance for small values of θ to a competitive clustering rate. Second, we observe that the best results are obtained for an intermediate value of θ, where the dissimilarity need not to be a distance and thus K RSP is not actually a valid kernel matrix. The results obtained for intermediate values of θ are usually better or comparable to those obtained with the commute-time (θ → 0) and the shortest-path (θ → ∞) kernels. Finally, it can be observed that the kernel associated to the shortest-path distance also offers good performances, despite the fact that the distance is not Euclidean, which was unexpected. Tests on various other datasets show that the value of θ for which the clustering rate is the highest strongly depends on the properties and the structure of the graph. But, in general, the best performances are obtained for θ ∈ [10 -3 , 1].</p><p>Third experiment. The last experiment aims to compare the RSP betweenness (see the end of Section 3), computed for various values of θ, with the well-known Freeman's <ref type="bibr" target="#b63">[63]</ref> betweenness as well as with Newman's <ref type="bibr" target="#b41">[41]</ref> betweenness. The linear correlation between the RSP betweenness and Freeman's + Newman's betweenness are reported in Figure <ref type="figure" target="#fig_1">1</ref> (e)-(f) for two datasets, the dolphins graph and the netscience co-authorship network. The same test has been performed on various other networks, with comparable results. By examining the figures, we observe that the correlations vary smoothly when θ varies in the range ]0, 20]. Moreover, it is clear that the RSP betweenness comprises both Freeman's and Newman's betweenness. However, since the results of the three be-tweenness measures remain highly correlated, the added value of our RSP betweenness is somewhat questionable in this context.</p><p>Discussion of the results. Let us now come back to our research questions. The experiments clearly show that the symmetric RSP dissimilarity behaves as expected, although the fact that the correlation between the RSP dissimilarity and the commute-time distance is not always monotonically decreasing when θ increases is somewhat counter-intuitive and deserves further investigations. It also appears that the parameter θ influences significantly the results and could be considered as a meta-parameter to be tuned. For instance, the clustering benefits from the tuning of θ. However, this is less clear for the RSP betweenness centrality measure, for which the betweenness based on the shortest-path and the betweenness based on the natural random walk are already highly correlated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS</head><p>This work introduced a new family of dissimilarity measures between the nodes of a weighted, directed, graph that generalizes both the shortest-path and the commute-time distances. It depends on a meta-parameter, θ, biasing gradually the simple random walk on the network towards the shortest path policy. Simple experiments involving graph mining tasks showed that performances could be improved by tuning the meta-parameter θ.</p><p>In future work, comparisons between this dissimilarity measure and other popular choices mentioned in Section 1.1 will be performed on collaborative recommendation and semi-supervised classification tasks. We will also try to tackle Markov decision processes through the sum-over-paths statistical physics framework. Still another application of this formalism results in the definition of a correlation measure between nodes of the graph. Indeed, the second-order derivative of the partition function with respect to the immediate costs provides a covariance measure between nodes. In short, two nodes are correlated if they often occur in the same path. Finally, links between the proposed sum-over-paths framework and the matrix-forest theorem <ref type="bibr" target="#b11">[11]</ref> as well as the generating function approach to random walks <ref type="bibr" target="#b51">[51]</ref> will be investigated.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: (a)-(b) Linear correlation between the RSP dissimilarity, the commute-time distance (plain line) and the shortest-path distance (dashed line), obtained on the Newsgroup (left) and the IMDb (right) datasets, for 0 &lt; θ ≤ 20. (c)-(d) Correct clustering rates (averaged on 20 runs) obtained by the RSP kernel k-means (plain line) and the sigmoid RSP kernel k-means (dashed line), for the Newsgroup (left) and the IMDb (right) datasets, in function of 0 &lt; θ ≤ 20. (e)-(f) Linear correlation between RSP, Newman's (plain line) and Freeman's (dashed line) betweenness measures, obtained on the Dolphins (left) and the Netscience (right) datasets, for 0 &lt; θ ≤ 20..</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>This work was supported by the STRATEGO project funded by the Region wallonne and by a grant from the Université catholique de Louvain, which permitted M. Shimbo to visit UCL. Marco Saerens is also a research follow of the IRIDIA Laboratory, Université Libre de Bruxelles.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The Matrix of Maximum Out Forests of a Digraph and Its Applications</title>
		<author>
			<persName><forename type="first">R</forename><surname>Agaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chebotarev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automation and Remote Control</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1424" to="1450" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Spanning Forests of a Digraph and Their Applications</title>
		<author>
			<persName><forename type="first">R</forename><surname>Agaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chebotarev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automation and Remote Control</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="443" to="466" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cyclic flows, Markov process and stochastic traffic assignment</title>
		<author>
			<persName><forename type="first">T</forename><surname>Akamatsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research B</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="369" to="386" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Resistance distance in graphs</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Bapat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Mathematics Student</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="87" to="98" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dynamic Programming and Optimal Control</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Athena Scientific</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A measure of similarity between graph vertices, with application to synonym extraction and web searching</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">D</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">V</forename><surname>Dooren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Review</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="647" to="666" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Modern multidimensional scaling: Theory and applications</title>
		<author>
			<persName><forename type="first">I</forename><surname>Borg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Groenen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A random walks perspective on maximizing satisfaction and profit</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 SIAM International Conference on Data Mining</title>
		<meeting>the 2005 SIAM International Conference on Data Mining</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The anatomy of a large-scale hypertextual Web search engine</title>
		<author>
			<persName><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Networks and ISDN Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1-7</biblScope>
			<biblScope unit="page" from="107" to="117" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The electrical resistance of a graph captures its commute and cover times</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Ruzzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Smolensky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tiwari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual ACM Symposium on Theory of Computing</title>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="574" to="586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The matrix-forest theorem and measuring relations in small social groups</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chebotarev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shamis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automation and Remote Control</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1505" to="1514" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On proximity measures for graph vertices</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chebotarev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shamis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automation and Remote Control</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1443" to="1459" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Directed graph embedding</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>the International Joint Conference on Artificial Intelligence (IJCAI)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="2707" to="2712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Laplacians and the Cheeger inequality for directed graphs</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Chung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Combinatorics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Mining graph data</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Holder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Wiley and Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thomas</surname></persName>
		</author>
		<title level="m">Elements of Information Theory</title>
		<imprint>
			<publisher>Wiley and Sons</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Exploratory Social Network Analysis with Pajek</title>
		<author>
			<persName><forename type="first">W</forename><surname>De Nooy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mrvar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Batagelj</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Random-walk computation of similarities between nodes of a graph, with application to collaborative recommendation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Fouss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pirotte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Renders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saerens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="355" to="369" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An experimental investigation of graph kernels on a collaborative recommendation task</title>
		<author>
			<persName><forename type="first">F</forename><surname>Fouss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pirotte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saerens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Data Mining (ICDM 2006)</title>
		<meeting>the 6th International Conference on Data Mining (ICDM 2006)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="863" to="868" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Random walks on graphs</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gobel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Jagers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Stochastic Processes and their Applications</title>
		<imprint>
			<date type="published" when="1974">1974</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="311" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F V</forename><surname>Loan</surname></persName>
		</author>
		<title level="m">Matrix Computations</title>
		<imprint>
			<publisher>Johns Hopkins University Press</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A random-walk based scoring algorithm with application to recommender systems for large-scale e-commerce</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A kernel view of the dimensionality reduction of manifolds</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Machine Learning (ICML2004)</title>
		<meeting>the 21st International Conference on Machine Learning (ICML2004)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="369" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">On clustering using random walks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Harel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on the Foundations of Software Technology and Theoretical Computer Science</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the conference on the Foundations of Software Technology and Theoretical Computer Science</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">2245</biblScope>
			<biblScope unit="page" from="18" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Application of kernels to link analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shimbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eleventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the eleventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="586" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Information theory and statistical mechanics</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Jaynes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="620" to="630" />
			<date type="published" when="1957">1957</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning semantic similarity</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kandola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cristianini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="657" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Kemeny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Snell Finite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markov</forename><surname>Chains</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1976">1976</date>
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Bibliographic coupling between scientific papers</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Kessler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Documentation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="25" />
			<date type="published" when="1963">1963</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Resistance distance</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Randic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Chemistry</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="81" to="95" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Diffusion kernels on graphs and other discrete structures</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">I</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on Machine Learning</title>
		<meeting>the 19th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="315" to="322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Measuring and extracting proximity in networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="245" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Measuring and extracting proximity graphs in networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Volinsky</surname></persName>
		</author>
		<idno>12:1-12:30</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery in Data</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Diffusion maps and coarse-graining: A unified framework for dimensionality reduction, graph partitioning, and data set parameterization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lafon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1393" to="1403" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Google&apos;s PageRank and Beyond: The Science of Search Engine Rankings</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Langville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Meyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Princeton University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The link-prediction problem for social networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liben-Nowell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1019" to="1031" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Random walks on graphs: A survey</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lovasz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Combinatorics: Paul Erdos is eighty</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="353" to="397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Node similarity in the citation graph</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Janssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Milos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Japkowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and Information Systems</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="129" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Diffusion maps, spectral clustering and eigenfunctions of Fokker-Planck operators</title>
		<author>
			<persName><forename type="first">B</forename><surname>Nadler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lafon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Coifman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kevrekidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="955" to="962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Diffusion maps, spectral clustering and reaction coordinate of dynamical systems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Nadler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lafon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Coifman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kevrekidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied and Computational Harmonic Analysis</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="113" to="127" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A measure of betweenness centrality based on random walks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Networks</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="54" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">The structure and dynamics of networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Newman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Princeton University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">The PageRank citation ranking: Bringing order to the web</title>
		<author>
			<persName><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
		<idno>1999-0120</idno>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
		<respStmt>
			<orgName>Computer Science Department, Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Electricity based external similarity of categorical attributes</title>
		<author>
			<persName><forename type="first">C</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD&apos;03)</title>
		<meeting>the 7th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD&apos;03)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="486" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Automatic multimedia cross-modal correlation discovery</title>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Duygulu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM SIGKDD international conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 10th ACM SIGKDD international conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="653" to="658" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Computing communities in large networks using random walks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Pons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Latapy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Graph Algorithms and Applications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="191" to="218" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Image segmentation using commute times</title>
		<author>
			<persName><forename type="first">H</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Hancock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th British Machine Vision Conference (BMVC 2005)</title>
		<meeting>the 16th British Machine Vision Conference (BMVC 2005)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="929" to="938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Clustering and embedding using commute times</title>
		<author>
			<persName><forename type="first">H</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Hancock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1873" to="1890" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Fundamentals of speech recognition</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rabiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-H</forename><surname>Juang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Prentice Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Reichl</surname></persName>
		</author>
		<title level="m">A modern course in statistical physics</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Rudnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gaspari</surname></persName>
		</author>
		<title level="m">Elements of the random walk</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Randomized shortest-path problems: Two seemingly unrelated problems. Manuscript submitted for publication</title>
		<author>
			<persName><forename type="first">M</forename><surname>Saerens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Achbany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fouss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">The principal components analysis of a graph, and its relationships to spectral clustering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Saerens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fouss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dupont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th European Conference on Machine Learning</title>
		<title level="s">Lecture Notes in Artificial Intelligence</title>
		<meeting>the 15th European Conference on Machine Learning<address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="volume">3201</biblScope>
			<biblScope unit="page" from="371" to="383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A tractable approach to finding closest truncated-commute-time neighbors in large graphs</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Conference on Uncertainty in Artificial Intelligence (UAI)</title>
		<meeting>the 23rd Conference on Uncertainty in Artificial Intelligence (UAI)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Schrodinger</surname></persName>
		</author>
		<title level="m">Statistical thermodynamics</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1952">1952</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>nd ed.</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Kernel Methods for Pattern Analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cristianini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Kernels as link analysis measures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shimbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ito</surname></persName>
		</author>
		<editor>Mining Graph Data, D. Cook and L. Holder</editor>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>John Wiley &amp; Sons</publisher>
			<biblScope unit="page" from="283" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Co-citation in the scientific literature: a new measure of the relationship between two documents</title>
		<author>
			<persName><forename type="first">H</forename><surname>Small</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="265" to="269" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Kernels and regularization on graphs</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kondor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Learning Theory (COLT)</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Warmuth</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</editor>
		<meeting>the Conference on Learning Theory (COLT)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="144" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A one-parameter family of distributed consensus algorithms with boundary: from shortest paths to mean hitting times</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tahbaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jadbabaie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Decision and Control</title>
		<meeting>IEEE Conference on Decision and Control</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="4664" to="4669" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Random walk with restart: fast solutions and applications</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and Information Systems</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>To appear in</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Fast direction-aware proximity for graph mining</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGKDD international conference on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>the ACM SIGKDD international conference on Knowledge Discovery and Data Mining (KDD)</meeting>
		<imprint>
			<biblScope unit="page" from="747" to="756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Wasserman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Faust</surname></persName>
		</author>
		<title level="m">Social Network Analysis: Methods and Applications</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Algorithms for estimating relative importance in networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Smyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ninth ACM SIGKDD International Conference on Knowledge Discovery and Data mining</title>
		<meeting>the ninth ACM SIGKDD International Conference on Knowledge Discovery and Data mining</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="266" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Graph nodes clustering based on the commute-time kernel</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fouss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Decaestecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Francq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saerens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Pacific-Asia Conference on Knowledge Discovery and Data Mining</title>
		<title level="s">Lecture notes in Computer Science</title>
		<meeting>the 11th Pacific-Asia Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>PAKDD</publisher>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="volume">4426</biblScope>
			<biblScope unit="page" from="1037" to="1045" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Link-based community detection based on the sigmoid commute-time kernel</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fouss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Decaestecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Francq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saerens</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>Manuscript submitted for publication</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Clustering using a random walk-based distance measure</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vanvyve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wouters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fouss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Verleysen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saerens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th European Symposium on Artificial Neural Networks (ESANN2005)</title>
		<meeting>the 13th European Symposium on Artificial Neural Networks (ESANN2005)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="317" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Contextual Distance for Data Perception</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">O</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the Eleventh IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<title level="m">Proceedings of the 22nd International Conference on Machine Learning (ICML)</title>
		<meeting>the 22nd International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1041" to="1048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Distance, dissimilarity index, and network community structure</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<date type="published" when="2003">061901. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Network landscape from a Brownian particle perspective</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<date type="published" when="2003">041908. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Graph kernels by spectral transforms</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kandola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Semi-supervised learning</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Zien</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="277" to="291" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
