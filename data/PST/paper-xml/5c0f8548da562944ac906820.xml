<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Global and Local Surrogate-Assisted Differential Evolution for Expensive Constrained Optimization Problems With Inequality Constraints</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Yong</forename><surname>Wang</surname></persName>
							<email>ywang@csu.edu.cn</email>
							<idno type="ORCID">0000-0001-7670-3958</idno>
						</author>
						<author>
							<persName><forename type="first">Da-Qing</forename><surname>Yin</surname></persName>
							<email>yindaqing@csu.edu.cn</email>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Shengxiang</forename><surname>Yang</surname></persName>
							<email>syang@dmu.ac.uk</email>
							<idno type="ORCID">0000-0001-7222-4917</idno>
						</author>
						<author>
							<persName><forename type="first">Guangyong</forename><surname>Sun</surname></persName>
							<email>guangyong.sun@sydney.edu.au</email>
						</author>
						<author>
							<persName><surname>Wang</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science and Engineering</orgName>
								<orgName type="institution">Central South University</orgName>
								<address>
									<postCode>410083</postCode>
									<settlement>Changsha</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Electronic Engineering</orgName>
								<orgName type="institution">University of Essex</orgName>
								<address>
									<postCode>CO4 3SQ</postCode>
									<settlement>Colchester</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">School of Information Science and Engineering</orgName>
								<orgName type="institution">Central South University</orgName>
								<address>
									<postCode>410083</postCode>
									<settlement>Changsha</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Centre for Computational Intelligence</orgName>
								<orgName type="department" key="dep2">School of Computer Science and Informatics</orgName>
								<orgName type="institution">De Montfort University</orgName>
								<address>
									<postCode>LE1 9BH</postCode>
									<settlement>Leicester</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">College of Information Engineering</orgName>
								<orgName type="institution">Xiangtan University</orgName>
								<address>
									<postCode>411105</postCode>
									<settlement>Xiangtan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department" key="dep1">School of Aerospace, Mechanical and Mechatronic Engineering</orgName>
								<orgName type="department" key="dep2">Faculty of Engineering</orgName>
								<orgName type="institution">University of Sydney</orgName>
								<address>
									<postCode>2006</postCode>
									<settlement>Sydney</settlement>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="laboratory">State Key Laboratory of Advanced Design and Manufacture for Vehicle Body</orgName>
								<orgName type="institution">Hunan University</orgName>
								<address>
									<postCode>410082</postCode>
									<settlement>Changsha</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Global and Local Surrogate-Assisted Differential Evolution for Expensive Constrained Optimization Problems With Inequality Constraints</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4C17DC8FD2D470405FD3592FD650CA2D</idno>
					<idno type="DOI">10.1109/TCYB.2018.2809430</idno>
					<note type="submission">received November 15, 2017; revised February 16, 2018; accepted February 21, 2018.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Differential evolution (DE)</term>
					<term>expensive constrained optimization problems (ECOP)</term>
					<term>global search</term>
					<term>local search</term>
					<term>surrogate model</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For expensive constrained optimization problems (ECOPs), the computation of objective function and constraints is very time-consuming. This paper proposes a novel global and local surrogate-assisted differential evolution (DE) for solving ECOPs with inequality constraints. The proposed method consists of two main phases: 1) global surrogate-assisted phase and 2) local surrogate-assisted phase. In the global surrogate-assisted phase, DE serves as the search engine to produce multiple trial vectors. Afterward, the generalized regression neural network is used to evaluate these trial vectors. In order to select the best candidate from these trial vectors, two rules are combined. The first is the feasibility rule, which at first guides the population toward the feasible region, and then toward the optimal solution. In addition, the second rule puts more emphasis on the solution with the highest predicted uncertainty, and thus alleviates the inaccuracy of the surrogates. In the local surrogate-assisted phase, the interior point method coupled with radial basis function is utilized to refine each individual in the population. During the evolution, the global surrogate-assisted phase has the capability to promptly locate the promising region and the local Manuscript</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>I N MANY science and engineering areas such as com- putational fluid dynamics (CFD) <ref type="bibr" target="#b0">[1]</ref>, computational structural mechanics <ref type="bibr" target="#b1">[2]</ref>, and computational electromagnetics <ref type="bibr" target="#b2">[3]</ref>, optimization problems always include one objective function and various constraints. Moreover, for some of them, the computation of objective function and constraints is extremely expensive (for example, one simulation of typical computational electromagnetics may take 20 min <ref type="bibr" target="#b3">[4]</ref>). This kind of optimization problems is considered to be expensive constrained optimization problems (ECOPs). An ECOP with inequality constraints can be formulated as follows: minimize: f ( x) Subject to: g j ( x) ≤ 0, j = 1, . . . , p</p><p>where x = (x 1 , . . . , x D ) ∈ S is the decision vector, L i ≤ x i ≤ U i (i ∈ {1, . . . , D}) is the ith decision variable, D is the number of decision variables, L i and U i are the lower and upper bounds of x i , respectively, S = D i=1 [L i , U i ] is the search space or decision space, f ( x) is the objective function, g j ( x) is the jth inequality constraint, and p is the number of inequality constraints. Due to the existence of constraints, when evaluating a decision vector x, we need to consider its degree of constraint violation. The degree of constraint violation of x on the jth constraint can be computed as follows:</p><p>G j ( x) = max 0, g j ( x) , j = 1, . . . , p.</p><p>(</p><p>Afterward, G( x) = p j=1 G j ( x) denotes the degree of constraint violation of x on all constraints.</p><p>Evolutionary algorithms (EAs) are a class of populationbased heuristic search approaches, which have been successfully applied to solve different types of optimization problems.</p><p>2168-2267 c 2018 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/ redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p><p>EAs usually implement crossover, mutation, and selection operators to improve the quality of each individual in the population generation by generation. In general, EAs need a large number of fitness evaluations (FEs) to obtain the global optimum of an optimization problem.</p><p>In the evolutionary computation research community, how to deal with expensive unconstrained optimization problems (EUOPs) has attracted much attention. Owing to the computationally expensive nature, applying EAs to solve EUOPs in a straightforward way is highly time-consuming and even impractical. Over the past 15 years, surrogateassisted EAs (SAEAs) have been widely accepted as one of the most popular methods for solving EUOPs. The basic idea behind SAEAs is to build a surrogate model to approximate the original expensive objective function. Since the surrogate model is much more computationally efficient than the original objective function, the computational cost can be reduced significantly. At present, a variety of surrogate models has been developed, such as polynomial regression, Gaussian process (GP), radial basis function (RBF), artificial neural network, and support vector machine (SVM). In order to find the global optimum within a limited budget of FEs, SAEAs should combine the surrogate model with the original objective function in an effective way. There are three kinds of methods, namely evolution control, surrogateassisted prescreening method, and surrogate-assisted local search, to address the above issue. Evolution control, proposed by Jin et al. <ref type="bibr" target="#b4">[5]</ref>, is a simple yet popular framework for managing surrogates, which includes individual-based control and generation-based control. In individual-based control, some of individuals are evaluated with the original objective function and the remaining individuals are evaluated with surrogates at each generation. In contrast, with respect to generation-based control, all individuals in the population are evaluated with surrogates in some generations, while in the rest of generations the original objective function is used for evaluating all individuals. For surrogate-assisted prescreening methods <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, surrogates are used to preselect a subset of promising individuals among a number of trial offspring. Afterward, the chosen individuals are re-evaluated with the original objective function. Regarding surrogate-assisted local search <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, the surrogate of objective function and its gradient information are utilized to generate an offspring in each iteration. Finally, the resulting offspring is re-evaluated with the original objective function. In 2011, Jin <ref type="bibr" target="#b9">[10]</ref> carried out a comprehensive survey on SAEAs.</p><p>On the other hand, recent two decades have witnessed the significant development of constraint-handling techniques for inexpensive constrained optimization problems. The current popular constraint-handling techniques can be classified into three categories <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b12">[13]</ref>: 1) methods based on penalty functions <ref type="bibr" target="#b13">[14]</ref>- <ref type="bibr" target="#b15">[16]</ref>; 2) methods based on the preference of feasible solutions over infeasible solutions <ref type="bibr" target="#b16">[17]</ref>- <ref type="bibr" target="#b19">[20]</ref>; and 3) methods based on multiobjective optimization <ref type="bibr" target="#b20">[21]</ref>- <ref type="bibr" target="#b24">[25]</ref>. For the methods based on penalty functions, an infeasible solution is penalized according to its degree of constraint violation. With respect to the methods based on the preference of feasible solutions over infeasible solutions, either objective function or the degree of constraint violation is used to compare the individuals in the population. Moreover, in this kind of methods, the search is biased toward the feasible region. In terms of the methods based on multiobjective optimization, the constraints are treated as one or more objective functions. The interested reader is referred to a recent survey paper on constraint-handling techniques <ref type="bibr" target="#b25">[26]</ref>.</p><p>Although EUOPs and constraint-handling techniques have been actively investigated, not much work has been done to solve ECOPs in the evolutionary computation research community. When solving ECOPs by EAs, most of the current methods adopt global surrogates or local surrogates individually; therefore, their effectiveness and efficiency are limited. Additionally, how to improve the quality of surrogates during the evolution and how to combine surrogates with constrainthandling techniques have not been studied in depth. Motivated by the above considerations, this paper proposes a global and local surrogate-assisted differential evolution (DE) called GLoSADE for solving ECOPs with inequality constraints. To the best of our knowledge, GLoSADE is the first attempt to combine both global and local surrogates in expensive constrained evolutionary optimization. GLoSADE consists of two important phases: 1) global surrogate-assisted phase and 2) local surrogate-assisted phase.</p><p>The main contributions of this paper can be summarized as follows.</p><p>1) The global surrogate-assisted phase makes use of DE to generate multiple trial vectors and the generalized regression neural network (GRNN) to evaluate them. It is worth noting that the training procedure of GRNN is one-passing learning, and the computational cost is thus very low. Subsequently, two rules are combined to select the most potential candidate from the trial vectors. The first rule, named the feasibility rule <ref type="bibr" target="#b16">[17]</ref>, selects the best infeasible solution if the population only contains infeasible solutions or the best feasible solution if the population contains at least one feasible solution, with the aim of at first guiding the population toward the feasible region, and then toward the optimal solution. The second rule, called the uncertainty-based rule, chooses the individual with the highest predicted uncertainty, which can improve the quality of surrogates. 2) In the local surrogate-assisted phase, the interior point method refines each individual in the population in an iterative manner. In each iteration, RBF is used to construct a gradient descent direction and a step size to create a new solution. 3) Because of the powerful global search ability of DE and the good generalization performance of GRNN, the global surrogate-assisted phase is capable of locating the promising region promptly. On the other hand, the local surrogate-assisted phase is able to speed up the convergence. Hence, GLoSADE attempts to strike a balance between the effectiveness and efficiency. 4) Systematic experiments have been conducted to study the performance of GLoSADE and compare it with three other state-of-the-art methods on the benchmark test functions at IEEE CEC2006 <ref type="bibr" target="#b26">[27]</ref>, IEEE CEC2010 <ref type="bibr" target="#b27">[28]</ref>,</p><p>and IEEE CEC2017 <ref type="bibr" target="#b28">[29]</ref>. Moreover, GLoSADE has been successfully applied to solve two practical ECOPs, i.e., the optimal shape design of transonic airfoil and the topology optimization of energy-absorbing component. The rest of this paper is organized as follows. Section II briefly introduces DE and surrogates. Section III describes the related work. The proposed method, GLoSADE, is elaborated in Section IV. Sections V and VI present the experimental studies on benchmark test functions from three test suites and two real-world applications, respectively. Finally, Section VII concludes this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. DIFFERENTIAL EVOLUTION AND SURROGATES</head><p>A. Differential Evolution DE, proposed by Storn and Price <ref type="bibr" target="#b29">[30]</ref>, is a very popular EA paradigm for solving complex optimization problems. In this paper, DE is employed as the search engine. Similar to other EAs, DE is also a population-based optimizer <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>. Suppose that P = { x 1 , . . . , x NP } denotes the population and x k = (x k,1 , . . . , x k,D ) is the kth individual (also called the kth target vector) in P. Over the course of evolution, DE consists of three main operators, i.e., mutation, crossover, and selection.</p><p>First, the mutant vector</p><formula xml:id="formula_2">v k = (v k,1 , . . . , v k,D</formula><p>) is generated by a mutation operator for each target vector x k . The commonly used mutation operators are listed as follows.</p><p>1) DE/rand/1</p><formula xml:id="formula_3">v k = x r 1 + F × x r 2 -x r 3 .<label>(3)</label></formula><p>2) DE/best/1</p><formula xml:id="formula_4">v k = x best + F × x r 1 -x r 2 . (<label>4</label></formula><formula xml:id="formula_5">)</formula><p>3) DE/current-to-rand/1</p><formula xml:id="formula_6">v k = x k + F × x r 1 -x k + F × x r 2 -x r 3 . (5) 4) DE/current-to-best/1 v k = x k + F × ( x best -x k ) + F × x r 1 -x r 2<label>(6)</label></formula><p>where r 1 , r 2 , and r 3 are three mutually different integers uniformly generated from {1, . . . , k -1, k + 1, . . . , D}, x best is the best individual in the population, and F is the scaling factor. Afterward, the crossover operator is implemented on x k and v k to generate the trial vector u k = (u k,1 , . . . , u k,D ). The binomial crossover is expressed as follows:</p><formula xml:id="formula_7">u k,j = v k,j , if rand j ≤ CR or j = j rand x k,j , otherwise , j = 1, . . . , D (7)</formula><p>where rand j is a random number on the interval [0, 1], j rand is a integer randomly selected form {1, . . . , D}, and CR ∈ [0, 1] is the crossover control parameter. Finally, the selection operator chooses the better one between x k and u k into the next generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Surrogates</head><p>In this paper, GRNN and RBF are used to construct the global and local surrogates, respectively. Next, we give a brief introduction to them.</p><p>1) Generalized Regression Neural Network: GRNN, proposed by Specht <ref type="bibr" target="#b32">[33]</ref>, is a memory-based neural network, which can approximate any underlying regression surface in theory. Unlike other neural networks, such as back-propagation neural network, GRNN is a one-pass learning algorithm. Thus, the time-saving GRNN is very suitable for dealing with expensive optimization problems. Assuming that f ( x, y) denotes the joint probability density function of a random vector x and a random variable y. The conditional mean of y on x is given by</p><formula xml:id="formula_8">E y| x = ∞ -∞ yf ( x, y)dy ∞ -∞ f ( x, y)dy . (<label>8</label></formula><formula xml:id="formula_9">)</formula><p>Given the data points {( x i , y i )| x i ∈ D , i = 1, . . . , N}, the joint probability density function can be estimated by Parzen nonparametric estimator <ref type="bibr" target="#b33">[34]</ref> as follows:</p><formula xml:id="formula_10">f ( x, y) = 1 N(2π) (D+1)/2 σ D+1 × N i=1 exp - ( x -x i )( x -x i ) T 2σ 2 exp - (y -y i ) 2 2σ 2 (9)</formula><p>where σ is a user-defined smoothness parameter. By combining ( <ref type="formula" target="#formula_8">8</ref>) with ( <ref type="formula">9</ref>), the conditional mean of y can be calculated as</p><formula xml:id="formula_11">E y| x = N i=1 y i exp -( x-x i )( x-x i ) T 2σ 2 N i=1 exp -( x-x i )( x-x i ) T 2σ 2 . (<label>10</label></formula><formula xml:id="formula_12">)</formula><p>As a result, when point x is given, the predicted output on x is equal to E[y| x].</p><p>2) Radial Basis Function: RBF is a kind of interpolation model and has been widely applied to various scientific and engineering fields. RBF uses a weighted sum of simple basis functions to interpolate the scatter points. Given the data points{( x i , y i )| x i ∈ D ,i = 1, . . . , N},RBF approximates the underlying function as follows:</p><formula xml:id="formula_13">f ( x) = N i=1 ω i φ( x -x i ) (<label>11</label></formula><formula xml:id="formula_14">)</formula><p>where ω i is the weight coefficient and φ(•) is a basis function. Many forms of the basis function can be used here. The cubic form φ(r) = r 3 is chosen in this paper. The previous studies have revealed that the cubic form outperforms the other kinds of basis function <ref type="bibr" target="#b34">[35]</ref>. In addition, the weight vector ω = (ω i , . . . , ω N ) T can be computed as follows:</p><formula xml:id="formula_15">ω = ( T ) -1 T y (<label>12</label></formula><formula xml:id="formula_16">)</formula><p>where y = (y 1 , . . . , y N ) T is the output vector and is the following matrix:</p><formula xml:id="formula_17">= ⎡ ⎢ ⎣ φ( x 1 -x 1 ) • • • φ( x 1 -x N ) . . . . . . . . . φ( x N -x 1 ) • • • φ( x N -x N ) ⎤ ⎥ ⎦.<label>(13)</label></formula><p>III. RELATED WORK Solving ECOPs by EAs is one of the most important challenges in the evolutionary computation research community. This section presents a brief review of EAs for ECOPs from two aspects: 1) surrogate-assisted prescreening methods and 2) surrogate-assisted local search.</p><p>The primary idea of the surrogate-assisted prescreening methods is the following. First, a number of trial offspring are generated by EA operators. Second, surrogates are utilized to evaluate the trial offspring and a selection strategy is presented to preselect some desired candidates from the trial offspring. Finally, these candidates are re-evaluated with the original objective function and constraints. For example, Krempser et al. <ref type="bibr" target="#b35">[36]</ref> proposed a DE assisted by surrogates for structural optimization problems. In this method, four DE variants are adopted to generate four trial offspring for each individual in one generation. Afterward, the similarity-based surrogate is applied to evaluate the trial offspring to reduce the number of FEs. Mezura-Montes et al. <ref type="bibr" target="#b36">[37]</ref> developed a fitness inheritance-based evolution strategy for constrained optimization problems. To perform the fitness inheritance well, they also introduced two important parameters, i.e., inheritance ratio which determines the percentage of offspring to use the fitness inheritance mechanism and replacement ratio which determines the percentage of offspring with inherited fitness values to survive into the next generation. Moreover, the feasibility rule is chosen as the constraint-handling technique. Runarsson <ref type="bibr" target="#b37">[38]</ref> constructed two surrogates, one for the objective function and the other for the penalty function. After the trial offspring are generated by (μ, λ)-evolution strategy, stochastic ranking <ref type="bibr" target="#b18">[19]</ref> is employed to select the best individual from the trial offspring. Büche et al. <ref type="bibr" target="#b38">[39]</ref> proposed a novel method based on GP. In this method, GP is constructed only in the neighborhood of the current best individual.To balance the exploration and exploitation, a merit function proposed by <ref type="bibr">Torczon and Trosset [40]</ref> is used to choose the best candidate among the trial offspring. Emmerich et al. <ref type="bibr" target="#b40">[41]</ref> proposed an efficient search method based on EA assisted by local Gaussian random field metamodels. In this approach, a merit function proposed by Schonlau et al. <ref type="bibr" target="#b41">[42]</ref> is used to rank the trial offspring and then prescreen the promising trial offspring. Regis <ref type="bibr" target="#b42">[43]</ref> developed an RBF-assisted evolutionary programming for high-dimensional constrained expensive black-box optimization problems. This method makes use of the mutation operator of evolutionary programming to generate a very large number of trial offspring for each parent and RBF to evaluate them. Subsequently, the feasibility rule selects the best candidate among the trial offspring. Based on the work in <ref type="bibr" target="#b43">[44]</ref>, Bagheri et al. <ref type="bibr" target="#b44">[45]</ref> self-adjusted the parameters in RBF approximation for ECOPs.</p><p>The surrogate-assisted local search improves the quality of each individual in the population in an iterative manner. During the evolution, the local search exploits the information provided by surrogates of the original objective function and constraints to produce a sequence of offspring. After that, the original objective function and constraints are used to re-evaluate the final offspring. For instance, Ong et al. <ref type="bibr" target="#b45">[46]</ref> proposed a surrogate-assisted parallel evolutionary optimization algorithm to solve ECOPs. In this method, the local search, named feasible sequential quadratic programming <ref type="bibr" target="#b46">[47]</ref>, is integrated with EA in the spirit of Lamarckian learning. Moreover, a trust-region approach is employed in the local search for interleaving use of the original objective function and constraints with the RBF surrogates. Goh et al. <ref type="bibr" target="#b47">[48]</ref> proposed a surrogate-assisted memetic coevolutionary framework to solve ECOPs, where the population is divided into several subpopulations with random decomposition. After the offspring are generated in the co-evolutionary optimization phase, the surrogate-assisted local search is applied to each offspring. Moreover, a multiobjective ranking scheme is designed to handle constraints. Handoko et al. <ref type="bibr" target="#b48">[49]</ref> proposed an SVM-assisted memetic algorithm for the constrained optimization problems with single equality constraint. In this method, SVM is used to predict the relative position of individuals with respect to the boundary of the feasible region, and then the local search is only applied to the individuals located near the boundary. Handoko et al. <ref type="bibr" target="#b49">[50]</ref> further developed an effective chaperone for constrained memetic algorithm, called feasibility structure modeling. In this approach, SVM identifies the location of an individual in the search space as follows: deep inside the infeasible region, near the feasibility boundary, or deep inside the feasible region. Subsequently, the location information is utilized to determine whether or not the local search should be applied to an individual. Regis <ref type="bibr" target="#b50">[51]</ref> designed a trust region-like approach to improve the best solution at the end of each generation.</p><p>From the above introduction, it is clear that the surrogateassisted prescreening methods usually employ global surrogates. Although global surrogates are able to enhance the global search ability by exploring the whole search space, the accuracy of the obtained solutions may be low. In addition, the surrogate-assisted local search usually takes advantage of local surrogates. Local surrogates can speed up the convergence by probing a relatively small search region; however, they may ignore some promising regions in the search space. Therefore, the capabilities of the current methods to converge to the global optimum and keep a fast convergence speed simultaneously are limited, especially when the fitness landscape of the search space or the structure of the feasible region is complicated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. PROPOSED APPROACH</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Motivation</head><p>As discussed in Section III, the current methods either employ global surrogates to explore the search space or utilize local surrogates to accelerate the convergence. An interesting question is whether we can integrate the advantages of both global surrogates and local surrogates. We have observed, however, that the above issue has not yet been systematically investigated in the community of expensive constrained evolutionary optimization. In addition, to prevent the population from being misled by a false optimum introduced by surrogates, it is necessary to refine the quality of surrogates gradually. In principle, when solving ECOPs by EAs, constraint-handling technique and surrogates are two critical components. Therefore, the performance of a method will depend strongly on the way of how to integrate them.</p><p>Based on the above considerations, we propose a global and local surrogate-assisted DE which is the first attempt to synthesize global and local surrogates to solve ECOPs. GLoSADE consists of two important phases at each generation: 1) global surrogate-assisted phase and 2) local surrogate-assisted phase. In the former, on the one hand, DE/rand/1/bin generates many trial vectors for each individual with a probability 0.5. Then GRNN is used to evaluate these trial vectors and the best trial vector is selected based on the feasibility rule. The aim of the above process is to locate the promising region quickly. On the other hand, DE/current-to-rand/1 is another choice to produce multiple trial vectors for each individual with a probability 0.5. Afterward, the uncertainties of these trial vectors are calculated and the trial vector with the highest uncertainty is chosen, with the purpose of improving the quality of surrogates. Additionally, in the latter, the interior point method and RBF are performed as the local search on each individual in the population, thus enhancing the accuracy of solution. It is necessary to emphasize that GRNN and RBF are both multioutput models. A multioutput model can approximate multiple functions at the same time. In this paper, we separately approximate the original objective function and each constraint by surrogates throughout the evolutionary process. 1 On the whole, GLoSADE also provides an effective combination of surrogates and constraint-handling techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. GLoSADE</head><p>The framework of GLoSADE is given in Fig. <ref type="figure" target="#fig_0">1</ref>. First, the initial population P 0 is produced by Latin hypercube design <ref type="bibr" target="#b51">[52]</ref> and the initial archive A is constructed. At each generation, both the global surrogate-assisted phase and the local surrogate-assisted phase are performed for each individual in the population. In the global surrogate-assisted phase, GRNN is constructed as the global surrogate to approximate the original objective function and constraints. Afterward, an offspring g k,t is generated for each individual x k,t in P t through the global surrogate-assisted search as explained in Section IV-C. g k,t is re-evaluated with the original objective function and constraints and its information is stored into A. Subsequently, g k,t is compared with x k,t based on the feasibility rule and the better one survives into Q t . In the local surrogate-assisted phase, an offspring l k,t is generated for each individual x k,t in Q t via the local surrogate-assisted search as explained in Section IV-D. Then, l k,t is re-evaluated with the original objective function and constraints and its information is also stored into A. Subsequently, the better one between l k,t and x k,t is selected based on the feasibility rule and put into P t+1 . The above procedure is repeated until the maximum number of FEs is reached. 1 There are two ways to approximate constraints: 1) approximating all the constraints by making use of the degree of constraint violation G( x) and 2) approximating each of the constraints. The former can easily compute the feasibility of an individual; however, it cannot identify the structure of each constraint and reflect the property of the boundaries of the feasible region. As a result, we choose the latter in this paper. Surrogates play a crucial role in solving ECOPs by EAs. Lim et al. <ref type="bibr" target="#b52">[53]</ref> pointed out that SAEAs work on two major tasks: 1) alleviating the curse of uncertainty and 2) benefiting from the "blessing of the uncertainty." The curse of uncertainty can be briefly defined as the phenomenon where SAEAs search to stall or converge to a false optimum due to the approximation error of a surrogate. The blessing of uncertainty means that the approximation error of a surrogate can be helpful to smooth the rough fitness landscape and promptly locate the promising region. It is clear that both the curse of uncertainty and the blessing of the uncertainty are related to the approximation error of a surrogate, which represents the shortcoming and advantage of the approximation error of a surrogate, respectively. To alleviate the curse of uncertainty, it is expected to build an accurate surrogate to approximate the fitness landscape in the specified search region, thus reducing the approximation error. Under this condition, the surrogate is always computationally expensive. However, the blessing of uncertainty implies that we can use an inaccurate and cheap surrogate to benefit from the approximation error. Obviously, the above two aspects lead to a contradiction. To address this contradiction, in this paper, we employ cheap GRNN to construct a global surrogate and expensive RBF to construct multiple local surrogates. The training time complexity of GRNN and RBF is O(DN) and O(DN 3 ), respectively, where N denotes the size of training data. GRNN is a regression model which does not model the training data exactly but gets as close as possible to the training data on average; thereby it is capable of smoothing the rugged fitness landscape. In contrast, RBF is an interpolation model. During the modeling, RBF passes through each of the training data; hence, it is able to approximate the fitness landscape accurately. As a result, by combining GRNN in the global surrogate-assisted phase and RBF in the local surrogate-assisted phase, this paper strikes a balance between the curse of uncertainty and the blessing of the uncertainty.</p><p>As shown in step 8) of Fig. <ref type="figure" target="#fig_0">1</ref>, all the individuals in archive A are used to construct a GRNN in the global surrogate-assisted phase. It is because we would like to identify the fitness landscape in the whole search space by taking advantage of all the historical data. Since local search is performed on each individual, a more reasonable way is to construct a RBF for each individual in the local surrogate-assisted phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Global Surrogate-Assisted Search</head><p>The global surrogate-assisted search is a surrogate-assisted prescreening method. For each target vector x k,t in P t , it involves two strategies to produce multiple trial vectors, evaluate these trial vectors, and select the best candidate g k,t from these trial vectors. These two strategies are applied with the same probability (i.e., 0.5).</p><p>In the first strategy, DE/rand/1/bin is adopted to generate λ trial vectors for each target vector in the population, because of its good exploration capability. Afterward, GRNN evaluates these trial vectors and the best candidate is selected according to the feasibility rule <ref type="bibr" target="#b16">[17]</ref>. The feasibility rule compares pairwise individuals as follows.</p><p>1) When comparing two solutions that are predicted to be feasible, the one with the better predicted objective function value is chosen. 2) When comparing a solution that is predicted to be feasible with a solution that is predicted to be infeasible, the former is chosen. 3) When comparing two solutions that are predicted to be infeasible, the one with the lower predicted degree of constraint violation is chosen. It is evident that if the trial vectors only contain infeasible solutions, the feasibility rule selects the best infeasible solution to guide the population toward the feasible region, which is the first promising region needed to be located. On the other hand, if the trial vectors contain at least one feasible solution, the feasibility rule selects the best feasible solution so as to guide the population toward the region containing the optimum, which is another promising region needed to be located.</p><p>In the first strategy, first, DE/rand/1/bin explores the search space by generating multiple trial vectors. Subsequently, GRNN evaluates these trial vectors and filters some trial vectors in the unpromising region because GRNN can smooth the rugged fitness landscape. Lastly, the feasibility rule selects the best candidate among the trial vectors. Thus, through the above steps, the first strategy achieves the quick locating of the promising region.</p><p>Since the computation of the original objective function and constraints is extremely expensive in ECOPs, it is desirable to evaluate the individuals with the original objective function and constraints as less as possible, which results in the limited training data for modeling. Obviously, the above phenomenon has a side effect on the quality of a surrogate. It is noteworthy that the surrogate with the wrong global optimum will definitely mislead the evolutionary search. In order to prevent the above phenomenon, an uncertainty-based rule is proposed in this paper to improve the quality of surrogates including GRNN and RBF. It selects a candidate with the highest uncertainty from the trial vectors. The uncertainty-based rule is inspired by the concept of active learning <ref type="bibr" target="#b53">[54]</ref>, where the training data are selected actively to improve the quality of a surrogate. The uncertainty measures the prediction confidence of a surrogate at a given point. The commonly used way to measure the uncertainty is the variance of the prediction value. The larger the variance, the more sparse the sample points around a given point, so the more inaccurate the prediction of a surrogate at this point. Among the regression models, the Bayesian regression <ref type="bibr" target="#b54">[55]</ref> can calculate the variance of a surrogate. Note, however, that the Bayesian regression contains some problem-dependent hyper-parameters. Therefore, to overcome the dependence of problem-specific prior knowledge, we assume that the noise error of the Bayesian regression is zero and choose the cubic form function as the basis function. Finally, the variance is computed in the form of RBF as follows:</p><formula xml:id="formula_18">σ 2 ( x) = -φ( x) -1 φ( x) T (<label>14</label></formula><formula xml:id="formula_19">)</formula><p>where φ( x) = (φ( xx 1 ), . . . , φ( xx N )) and has the same definition as in <ref type="bibr" target="#b12">(13)</ref>. In this paper, ( <ref type="formula" target="#formula_18">14</ref>) is used to measure the uncertainty of a surrogate at a given point. To save the computational time, the uncertainty of a surrogate in x k,t is computed with the η nearest points in archive A to x k,t . In this paper, η = 100. In the second strategy, DE/current-to-rand/1 is used to generate λ trial vectors. It is necessary to emphasize that the binomial crossover is not applied to DE/current-to-rand/1 and it thus exhibits the rotation-invariant feature <ref type="bibr" target="#b55">[56]</ref>. In DE/current-to-rand/1, each target vector x k,t in P t learns the information from other individuals randomly. Moreover, the center of all the trial vectors is the target vector, which means that all the trial vectors are distributed around the target vector. Thus, the trial vector with the highest uncertainty has the most potential to enhance the quality of surrogates in the neighborhood of the target vector. At the early stage of evolution, the trial vectors in the population scatter in the search space and the diversity of the population is good. Under this condition, the trial vectors with the highest uncertainty can be used to improve the quality of surrogates in the entire search space. In addition, at the middle and later stages of evolution, the target vectors in the population gather in a small search region near the optimal solution. Accordingly, the trial vectors chosen by the uncertainty-based rule has the capability to refine the quality of surrogates in the neighborhood of the optimal solution. Therefore, combining DE/current-torand/1 with the uncertainty-based rule is able to improve the quality of surrogates over the course of evolution.</p><p>The implementation of the global surrogate-assisted search is shown in Fig. <ref type="figure" target="#fig_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Local Surrogate-Assisted Search</head><p>To further accelerate the convergence, the interior point method <ref type="bibr" target="#b56">[57]</ref>, a popular local search method, is incorporated into the local surrogate-assisted search. For each individual x k,t in Q t , the interior point method solves an optimization problem with the following form:</p><formula xml:id="formula_20">minimize: f ( x) subject to: ĝj ( x) ≤ 0, j = 1, . . . , p Li ≤ x i ≤ Ũi , i = 1, . . . , D<label>(15)</label></formula><p>where f ( x) and ĝj ( x) are the RBF surrogates built with the K nearest points in archive A to x k,t for the original objective function and the jth constraint, respectively, and Li and Ũi are the minimum and maximum values of the ith dimension of the K nearest points in archive A to x k,t , respectively. In this paper, K = max((D + 1)(D + 2)/2, 100). 2  In the local surrogate-assisted search, the interior point method iteratively minimizes the optimization problem in <ref type="bibr" target="#b14">(15)</ref> on the approximated landscape, starting with the initial solution y 0 y 0 = x k,t . In the rth iteration, a gradient descent 2 As pointed out in <ref type="bibr" target="#b57">[58]</ref>, when establishing a quadratic interpolation model, at least (D + 1)(D + 2)/2 sample points are required to determine its parameters. As we know, the quadratic interpolation model is a basic nonlinear model. Therefore, when we build a more complex model, it is natural that the number of sample points should be greater than or equal to (D + 1)(D + 2)/2. direction p r and a step size α r are constructed by making use of f ( x), ĝ1 ( x), . . . , ĝp ( x). As a result, a new solution y r+1 is generated: y r+1 = y r + α r p r . The interior point method ends when 300 iterations are exhausted. With the termination of the interior point method, the resultant solution (denoted as l k,t ) is considered as the best candidate generated by the local surrogate-assisted search.</p><p>Remark 1: Recently, researchers have proposed several surrogate-assisted DE for tackling EUOPs <ref type="bibr" target="#b58">[59]</ref>, <ref type="bibr" target="#b59">[60]</ref>. However, to the best of knowledge, this paper presents the first attempt to integer DE with surrogates for dealing with ECOPs. Moreover, in this paper we suggest a global and local surrogate-assisted DE framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTAL STUDY</head><p>The benchmark test functions with only inequality constraints collected in IEEE CEC2006 <ref type="bibr" target="#b26">[27]</ref>, IEEE CEC2010 <ref type="bibr" target="#b27">[28]</ref>, and IEEE CEC2017 <ref type="bibr" target="#b28">[29]</ref> were employed to demonstrate the capability of GLoSADE. We assume that the computation of their objective functions and constraints is expensive in this empirical study. The main characteristics of these test functions are reported in Tables S1-S3 in the supplementary material.</p><p>GLoSADE includes five main parameters: the population size (NP); the number of trial vectors generated for each target vector in the global surrogate-assisted search (λ); the scaling factor and the crossover control parameter of DE/rand/1/bin (F 1 and CR 1 ); and the scaling factor of DE/current-to-rand/1 (F 2 ). These parameters were set as follows: NP = 80, λ = 100, F 1 = 0.8, CR 1 = 0.4, and F 2 = 0.4. For each test function, 25 independent runs were executed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Comparison With mViE on Test Functions Collected in IEEE CEC2006</head><p>Firstly, the performance of GLoSADE was compared with that of mViE <ref type="bibr" target="#b60">[61]</ref> on 13 benchmark test functions from IEEE CEC2006. mViE is an outstanding method recently proposed by Maesani et al. for solving constrained optimization problems. Maesani et al. <ref type="bibr" target="#b60">[61]</ref> compared mViE with several popular and representative methods in constrained evolutionary optimization, such as ε-DE <ref type="bibr" target="#b61">[62]</ref>, ε-RDE <ref type="bibr" target="#b62">[63]</ref>, PSO <ref type="bibr" target="#b63">[64]</ref>, ASRES <ref type="bibr" target="#b64">[65]</ref>, (μ + λ)-CDE <ref type="bibr" target="#b65">[66]</ref>, and ICDE <ref type="bibr" target="#b66">[67]</ref>. The experimental results confirm that mViE outperforms them. For the above compared methods, ε-RDE and ASRES belong to SAEAs. Note that the main advantage of mViE is its efficiency. As reported in <ref type="bibr" target="#b60">[61]</ref>, mViE can find the optimal solutions within a very limited number of FEs for these 13 benchmark test functions.</p><p>Two performance metrics were used to compare GLoSADE with mViE. <ref type="foot" target="#foot_0">3</ref>1) The first performance metric is the successful rate (SR), which represents the percentage of the successful runs. A run is considered as successful if it can find a feasible solution satisfying the successful condition (f ( x best )f ( x * ) &lt; 0.0001) within the given maximum where MSFEs mViE and MSFEs GLoSADE denote the mean SFEs derived from mViE and GLoSADE, respectively. Table <ref type="table" target="#tab_0">I</ref> summarizes the statistics of SR and SFEs provided by mViE and GLoSADE. As shown in Table <ref type="table" target="#tab_0">I</ref>, both mViE and GLoSADE can successfully solve these 13 test functions in all 25 runs. Overall, GLoSADE can succeed in satisfying the successful condition within a small number of FEs. Specifically, for six test functions (i.e., CEC2006 01 , CEC2006 04 , CEC2006 06 , CEC2006 07 , CEC2006 08 , and CEC2006 24 ), GLoSADE takes less than 1000 FEs on average to reach the global optimum at the precision of 0.0001. For three test functions (i.e., CEC2006 12 , CEC2006 16 , and CEC2006 18 ), GLoSADE consumes less than 1500 FEs on average to satisfy the successful condition. It is worth noting that CEC2006 18 contains 13 nonlinear constraints and the feasibility ratio is approximate to zero, which reveals that GLoSADE has the capability to solve ECOPs with many nonlinear constraints and extremely small feasible region. For three test functions (i.e., CEC2006 09 , CEC2006 10 , and CEC2006 <ref type="bibr" target="#b18">19</ref> ), the mean SFEs is less than 2900. CEC2006 02 is a high-dimensional constrained optimization problem with one highly nonlinear objective function and one highly nonlinear constraint. Moreover, CEC2006 02 contains many local optima. Owing to the high dimensionality, high nonlinearity, and limited training data, it is very likely to build a surrogate with the wrong global optimum for CEC2006 02 , thus misleading the evolutionary search. Although CEC2006 02 is such a complex constrained optimization problem, GLoSADE consistently achieves the successful condition with not very big SFEs in 25 runs.</p><p>To detect the statistical difference between mViE and GLoSADE, the t-test at a 0.05 significance level was performed based on the average SFEs. In Table <ref type="table" target="#tab_0">I</ref>, "+," "-," and "∼" denote that the performance of mViE is better than, worse than, and similar to that of GLoSADE, respectively. It can be seen from Table <ref type="table" target="#tab_0">I</ref> that GLoSADE performs significantly better than mViE on all the test functions except for CEC2006 08 . As far as AR is concerned, GLoSADE reduces on average 70.04% FEs to reach the optimal solution, compared with mViE. Moreover, on six test functions (i.e., CEC2006 01 , CEC2006 04 , CEC2006 07 , CEC2006 10 , CEC2006 18 , and CEC2006 19 ), GLoSADE converges on average more than 80% faster than mViE toward the optimal solution. In particular, for CEC2006 01 , GLoSADE saves the number of FEs up to 98.22% compared with mViE.</p><p>The above comparison suggests that GLoSADE shows better convergence speed than mViE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Comparison With (μ + μ)-CEP-RBF and FROFI on Test Functions Collected in IEEE CEC2006, IEEE CEC2010, and IEEE CEC2017</head><p>Subsequently, we compared GLoSADE against (μ + μ)-CEP-RBF <ref type="bibr" target="#b42">[43]</ref> and FROFI <ref type="bibr" target="#b10">[11]</ref> on 13 test functions from IEEE CEC2006 <ref type="bibr" target="#b26">[27]</ref>, six test functions with 10D and 30D from IEEE CEC2010 <ref type="bibr" target="#b27">[28]</ref>, and nine test functions with 10D and 30D from IEEE CEC2017 <ref type="bibr" target="#b28">[29]</ref>. (μ + μ)-CEP-RBF is a RBF-assisted evolutionary programming proposed by Regis for high-dimensional black-box ECOPs. (μ + μ)-CEP-RBF has demonstrated its excellent performance in solving some benchmark and practical high-dimensional black-box ECOPs. In addition, FROFI is a very recent constrained optimization To compare the performance of GLoSADE with that of (μ + μ)-CEP-RBF and FROFI, we reimplemented the codes of (μ + μ)-CEP-RBF and FROFI provided by Regis <ref type="bibr" target="#b42">[43]</ref> and Wang et al. <ref type="bibr" target="#b10">[11]</ref>, respectively. All the parameter settings of (μ+μ)-CEP-RBF and FROFI were consistent with the original papers. It is necessary to emphasize that in <ref type="bibr" target="#b42">[43]</ref> the initial population must have at least one feasible individual. In contrast, GLoSADE does not have any specific requirements for the initial population. For a fair comparison, the initial population of (μ + μ)-CEP-RBF, FROFI, and GLoSADE were generated with the same method, i.e., Latin hypercube design. The experimental results of (μ + μ)-CEP-RBF, FROFI, and GLoSADE are summarized in Table <ref type="table" target="#tab_1">II</ref>, and Tables <ref type="table">S4</ref> and<ref type="table">S5</ref> in the supplementary material, under the condition that MaxFEs = 3000. In Table <ref type="table" target="#tab_1">II</ref>, Table <ref type="table">S4</ref>, and Table <ref type="table">S5</ref>, if a method cannot consistently find at least one feasible solution in the final population over 25 independent runs, we only reported the number of feasible trials. In addition, the Wilcoxon's rank sum test at a 0.05 significance level was used to test the statistical significance between GLoSADE and each of (μ + μ)-CEP-RBF and FROFI.</p><p>Next, we give the detailed performance comparison from two aspects.</p><p>1) For the 13 test functions from IEEE CEC2006, their optimal solutions have been reported in <ref type="bibr" target="#b26">[27]</ref>. Thus, Table <ref type="table" target="#tab_1">II</ref>  ). Moreover, for eight out of these nine test functions, GLoSADE is able to provide 100% SR. For the remaining four test functions, GLoSADE provides the same SR with (μ+μ)-CEP-RBF. In addition, FROFI shows the worst performance among the three compared methods. To be specific, it performs worse than GLoSADE on all the 13 test functions with the exception of CEC2006 12 . For CEC2006 12 , there is no significant difference between FROFI and GLoSADE. Moreover, FROFI fails to consistently find feasible solutions for two test functions, i.e., CEC2006 10 and CEC2006 18 , and successfully solves only one test function, i.e., CEC2006 08 . The poor performance of FROFI signifies that a method which aims at solving the general constrained optimization problems cannot achieve competitive performance on ECOPs due to the limited number of FEs. 2) For the six test functions with 10D and 30D from IEEE CEC2010, and the nine test functions with 10D and 30D from IEEE CEC2017, their optimal solutions cannot be known a priori. As a result, we recorded the average and standard deviation of objective function values resulting from the three compared methods over 25 runs in Tables <ref type="table">S4</ref> and<ref type="table">S5</ref> in the supplementary material. It is necessary to point out that these test functions include some extremely complex properties: highly nonlinear objective functions and/or constraints, rotated objective function, nonseparable decision variables, large search space, etc. Consequently, they pose a grand challenge to the three compared methods. However, as can be seen from Tables <ref type="table">S4</ref> and<ref type="table">S5</ref>, GLoSADE still shows better overall performance than the two competitors.</p><formula xml:id="formula_21">(a)<label>(b) (c) (d)</label></formula><p>In  . The horizontal axis represents the number of FEs and the vertical axis represents the average function error value. As shown in Fig. <ref type="figure" target="#fig_2">3</ref>, (μ + μ)-CEP-RBF tends to converge very fast in the early stage of evolution. Note, however, that it suffers from stagnation in the middle and later stages of evolution. The above phenomenon can be explained as follows. In (μ + μ)-CEP-RBF, the best candidate is preselected from a huge number of trial offspring [i.e., min(1000 × D, 10 000) trial offspring], which leads to the dramatic decrease of diversity of the population. Whereas, GLoSADE selects the best candidate from just 100 trial offspring. Moreover, the uncertainty-based rule of GLoSADE is also beneficial to increase the diversity of the population.</p><p>The above comparison demonstrates that GLoSADE outperforms (μ + μ)-CEP-RBF and FROFI in terms of the solution quality on three test suites.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Effectiveness of Some Components in GLoSADE</head><p>In this section, additional experiments were conducted to investigate the effectiveness of some components in GLoSADE. The 13 test functions from IEEE CEC2006 were chosen to produce the experimental results over 25 independent runs with MaxFEs = 3000. Moreover, the Wilcoxon's rank sum test at a 0.05 significance level was performed between GLoSADE and each competitor.</p><p>1) Effectiveness of the Uncertainty-Based Rule: The uncertainty-based rule is designed in this paper to alleviate the inaccuracy of surrogates. To study the effectiveness of this rule, we considered another variant of GLoSADE, called GLoSADE_WoU, in which the uncertainty-based rule was removed from GLoSADE. The mean and standard deviation of function error values resulting from GLoSADE and GLoSADE_WoU are summarized in Table <ref type="table">S6</ref> in the supplementary material. As shown in Table <ref type="table">S6</ref>, GLoSADE surpasses GLoSADE_WoU on nine test functions. In contrast, GLoSADE_WoU is better than GLoSADE on only one test function (i.e., CEC2006 09 ). The reasons why the performance of GLoSADE_WoU is better than GLoSADE on CEC2006 09 are twofold: 1) the convergence speed of both GLoSADE_WoU and GLoSADE is very fast for CEC2006 09 and 2) the uncertainty-based rule in GLoSADE aims at putting more emphasis on the sparse regions and adding the diversity of the population; thus, the accuracy of the solution provided by GLoSADE is slightly worse than that provided by GLoSADE_WoU. In addition, the performance improvement provided by GLoSADE against GLoSADE_WoU is quite significant on seven test functions (i.e., CEC2006 06 , CEC2006 07 , CEC2006 08 , CEC2006 10 , CEC2006 12 , CEC2006 18 , and CEC2006 <ref type="bibr" target="#b18">19 )</ref>.</p><p>The above analysis verifies that the uncertainty-based rule can enhance the quality of the surrogates and thus improve the performance of GLoSADE.</p><p>2) Effectiveness of the Global Surrogate-Assisted Phase and the Local Surrogate-Assisted Phase: GLoSADE consists of two important phases: global surrogate-assisted phase and local surrogate-assisted phase. In order to analyze the role of each phase in GLoSADE, two variants of GLoSADE, namely GLoSADE_Global and GLoSADE_Local, were considered. In GLoSADE_Global, the local surrogateassisted phase was removed from GLoSADE. In addition, in GLoSADE_Local, the global surrogate-assisted phase was eliminated from GLoSADE. Table <ref type="table">S7</ref>, in the supplementary material, summarizes the mean and standard deviation of function error values derived from GLoSADE_Global, GLoSADE_Local, and GLoSADE. Besides, Fig. <ref type="figure" target="#fig_3">4</ref> shows the convergence curves of the three compared methods on three representative test functions (i.e., CEC2006 04 , CEC2006 08 , and CEC2006 12 ). From Table <ref type="table">S7</ref>, GLoSADE exhibits superior performance against GLoSADE_Global and GLoSADE_Local on 13 and 11 test functions, respectively. However, GLoSADE_Global and GLoSADE_Local cannot beat GLoSADE on any test functions. More importantly, both GLoSADE_Global and GLoSADE_Local cannot consistently find feasible solutions on one test function. The poor performance of GLoSADE_Global and GLoSADE_Local could be attributed to the following facts: 1) without the local surrogate-assisted phase, GLoSADE_Global suffers from slow convergence speed and 2) due to the lack of sufficient sampling in the search space, GLoSADE_Local is prone to converge to a local attraction basin very fast and then fall into stagnation during the subsequent evolution. Fig. <ref type="figure" target="#fig_3">4</ref> further verifies the above analysis.</p><p>Based on the results provided in the above experiments, we can conclude that both kinds of surrogate-assisted phases are certainly important for the performance of GLoSADE.</p><p>3) Effectiveness of GRNN in the Global Surrogate-Assisted Phase: In GLoSADE, following the guideline of blessing of the uncertainty, GRNN was used to construct the global surrogate in the global surrogate-assisted phase. However, there are also other popular techniques, such as RBF and GP, to fit global surrogates. One may be interested in what will happen to the performance of GLoSADE if we use RBF or GP instead of GRNN in the global surrogate-assisted phase. To this end, we replaced GRNN with RBF and GP, and the resultant methods are denoted as GLoSADE_RBF and GLoSADE_GP. Table <ref type="table">S8</ref>, in the supplementary material, records the experimental results of GLoSADE_RBF, GLoSADE_GP, and GLoSADE.</p><p>The first observation from Table <ref type="table">S8</ref> is that GLoSADE, GLoSADE_RBF, and GLoSADE_GP show overall similar performance, in terms of the function error value. Specifically, GLoSADE outperforms GLoSADE_RBF and GLoSADE_GP on three and four test functions, respectively, and GLoSADE_RBF and GLoSADE_GP perform better than GLoSADE on two and five test functions, respectively. However, as far as the runtime is concerned, the performance difference among them is quite significant. <ref type="foot" target="#foot_1">4</ref> It can be seen that GLoSADE is on average 1.9 times and 18.5 times faster than GLoSADE_RBF and GLoSADE_GP, respectively. It is because the computational time complexity of RBF and GP is much higher than that of GRNN. To be specific, the computational time complexity of RBF is O(DN 3 ) as introduced in Section IV-B, and the computational time complexity of a typical learning algorithm for GP is O(TDN 3 ) <ref type="bibr" target="#b3">[4]</ref>, where T is the number of iterations, D is the number of decision variables, and N denotes the size of training data.</p><p>Therefore, GRNN is a good choice for the global surrogateassisted phase. It can achieve competitive performance with a less computational cost.</p><p>Remark 2: The effect of the parameter settings of GLoSADE was given in Section S-I in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. REAL-WORLD APPLICATIONS</head><p>GLoSADE was further applied to solve two practical ECOPs, i.e., the optimal shape design of transonic airfoil and the topology optimization of energy-absorbing component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Optimal Shape Design of Transonic Airfoil</head><p>The optimal shape design of transonic airfoil is a complex and expensive task, which needs numerous CFD simulations. Herein, we performed an optimal shape design of a 2-D transonic airfoil, the initial geometry of which is the NACA0012 airfoil in transonic inviscid flow (shown in Fig. <ref type="figure" target="#fig_3">S4</ref> in the supplementary material). The shape of the 2-D transonic airfoil is parameterized by a set of Hicks-Henne bump functions based on the initial geometry NACA0012. Hicks-Henne bump functions involve 38 design variables and the range of each design variable is [-0.02, 0.02]. By changing the parameters of Hicks-Henne bump functions, different shapes of the airfoil can be obtained. In this application, the objective is to minimize the drag of the airfoil with lift, moment, and thickness constraints minimize: drag( x) subject to: lift( x) &gt; 0.327 moment( x) &gt; 0 thickness( x) &gt; 0.12.</p><p>The CFD simulations of aerodynamic performance were undertaken by SU2 <ref type="bibr" target="#b67">[68]</ref>, which is a piece of open-source software. The resources (i.e., the configuration file and the mesh file) of this application for simulation are  available in the directory of SU2. SU2 takes around 14 s to run one simulation of the transonic airfoil in our computer. Fig. <ref type="figure" target="#fig_4">S5</ref>, in the supplementary material, shows the convergence of the mean of the best feasible objective function value for the shape design of a 2-D transonic airfoil obtained by (μ + μ)-CEP-RBF and GLoSADE after 500 FEs over 25 independent runs. The population size of (μ + μ)-CEP-RBF and GLoSADE was set to 10 in this application. As shown in Fig. <ref type="figure" target="#fig_4">S5</ref>, GLoSADE exhibits better convergence performance. Specifically, the mean drag values resulting from (μ+μ)-CEP-RBF and GLoSADE are 1.61E-06 and 4.05E-07, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Topology Optimization of Energy-Absorbing Component</head><p>The design of energy-absorbing component in vehicles is an important part of lightweight, and the topological structure of the energy-absorbing component has a significant impact on the crashworthiness of vehicles. Indeed, the design of energy-absorbing component is a very expensive optimization problem. Recently, Sun et al. <ref type="bibr" target="#b68">[69]</ref> proposed an integer-coded genetic algorithm (ICGA) to design an energy-absorbing component with multicell structure. The schematic of the multicell structure used in <ref type="bibr" target="#b68">[69]</ref> is shown in Fig. <ref type="figure" target="#fig_4">5</ref>, where the length of tube (H) is 150 mm, the cross-sectional dimension (L×L) is 80 mm × 80 mm, and the initial thickness of Web walls (T) is 1 mm. In addition, Fig. <ref type="figure" target="#fig_5">6</ref> depicts the variable distribution of this multicell structure. As shown in Fig. <ref type="figure" target="#fig_5">6</ref>, the structure is 1/8 symmetric; hence, the thicknesses of nine Web walls are considered as the design variables: x 1 , . . . , x 9 , where x i ∈ {0.0, 0.1, . . . , 1.2}(i = 1, . . . , 9). In the design of energy-absorbing component, the energy absorption (EA) and the peak crushing force (PCF) are commonly used to  </p><p>The nonlinear explicit finite element code, LS-DYNA, was utilized to simulate the crashing process of the multicell structure. It needs about 23 min to run one simulation of the crashing process of the multicell structure in our computer. Due to the fact that this application is extremely computationally expensive, ICGA and GLoSADE were independently run five times. According to the report in <ref type="bibr" target="#b68">[69]</ref>, the maximum EA found by ICGA is 3.66. Table <ref type="table" target="#tab_5">III</ref> presents the average number of FEs needed by ICGA and GLoSADE to reach this EA value over five runs. From Table <ref type="table" target="#tab_5">III</ref>, ICGA consumes on average 1610 FEs. In contrast, GLoSADE only takes on average 412 FEs. Thus, GLoSADE saves 74.4% FEs and reduces (1610-412)*23/60∼459.2 h compared with ICGA. Fig. <ref type="figure" target="#fig_6">7</ref> plots the convergence curves and the best variable distribution derived from ICGA and GLoSADE.</p><p>The above experiments reveal that GLoSADE could be an effective tool to solve ECOPs in the real-world applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION</head><p>Combination of global search and local search has been proven to be very successful in solving different kinds of optimization problems in the evolutionary computation research community <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b69">[70]</ref>. However, few attempts have been made along this line to investigate the solution of ECOPs, in which the evaluation of the objective function and constraints could be extremely computationally expensive. This paper attempts to introduce a novel global and local surrogate-assisted DE for solving ECOPs with inequality constraints, called GLoSADE. It consists of two main phases: 1) global surrogate-assisted phase and 2) local surrogate-assisted phase. In the global surrogate-assisted phase, GRNN is used to construct the global surrogates. Afterward, DE/rand/1/bin is combined with the feasibility rule to locate the promising area quickly, and DE/current-torand/1 is integrated with the uncertainty-based rule to improve the quality of surrogates to a certain degree. In addition, the local surrogate-assisted phase makes use of RBF to build the local surrogates and the interior point method to refine the quality of each individual, with the aim of speeding up the convergence. Overall, GLoSADE reaches a tradeoff between effectiveness and efficiency.</p><p>From the comparative study on benchmark test functions chosen from IEEE CEC2006, IEEE CEC2010, and IEEE CEC2017, the performance GLoSADE is better than that of three other well-known methods in terms of the selected performance metrics. Moreover, GLoSADE has been applied to two real-world cases to verify its capability.</p><p>Currently, very few methods provide the experimental results for ECOPs with equality constraints. It is because it is very hard for surrogates to approximate equality constraints, in particular, nonlinear equality constraints. In principle, when dealing with ECOPs, the aim of surrogates is to approximate objective function and constraints. However, nonlinear equality constraints pose a grand challenge to such approximation. In the future, we will study how to improve the performance of GLoSADE on ECOPs with nonlinear equality constraints. Additionally, the feasibility rule <ref type="bibr" target="#b16">[17]</ref> is adopted as the constraint-handling technique in this paper. Further investigation of other constraint-handling techniques (such as multiobjective optimization-based constraint-handling techniques) under the framework of GLoSADE will be an interesting and promising part of our future work.</p><p>The MATLAB source code of GLoSADE can be downloaded from Y. Wang's homepage: http://www.escience.cn/ people/yongwang1/index.html.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Framework of GLoSADE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Global surrogate-assisted search.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Evolution of the mean function error values of (μ+μ)-CEP-RBF and GLoSADE on four test functions. (a) CEC2006 01 . (b) CEC2006 02 . (c) CEC2006 08 . (d) CEC2006 12 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Evolution of the mean function error values of GLoSADE_Global, GLoSADE_Local, and GLoSADE on three test functions. (a) CEC2006 04 . (b) CEC2006 08 . (c) CEC2006 12 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Geometrical configuration of multicell structure.</figDesc><graphic coords="12,119.87,212.45,108.38,102.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Variable distribution of multicell structure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Convergence curves and the best variable distribution derived from ICGA and GLoSADE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I EXPERIMENTAL</head><label>I</label><figDesc>RESULTS OF MVIE AND GLOSADE IN TERMS OF SR, SFES, AND AR OVER 25 INDEPENDENT RUNS ON 13 TEST FUNCTIONS WITH ONLY INEQUALITY CONSTRAINTS FROM IEEE CEC2006number of FEs (MaxFEs), where x best is the best feasible solution found and x * is the best known solution.In the experiments, MaxFEs in GLoSADE was set to 7000 for all the test functions expect for CEC2006 02 . Due to the fact that it is very difficult to find the optimal solution of CEC2006 02 , the corresponding MaxFEs was set to 40 000. 2) For the second performance metric, the number of FEs required to reach the successful condition is recorded (denoted as SFEs) in each run, which is used to assess</figDesc><table><row><cell cols="4">the convergence speed. Furthermore, the acceleration</cell></row><row><cell cols="4">rate (AR) between mViE and GLoSADE is calculated</cell></row><row><cell cols="2">for each test function</cell><cell></cell><cell></cell></row><row><cell>AR =</cell><cell>MSFEs mViE -MSFEs GLoSADE MSFEs mViE</cell><cell>× 100%</cell><cell>(16)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II EXPERIMENTAL</head><label>II</label><figDesc>RESULTS OF (μ + μ)-CEP-RBF, FROFI, AND GLOSADE WITH 3000 FES OVER 25 INDEPENDENT RUNS ON 13 TEST FUNCTIONS WITH ONLY INEQUALITY CONSTRAINTS FROM IEEE CEC2006. (#) DENOTES THE NUMBER OF TRIALS IN WHICH AT LEAST ONE FEASIBLE SOLUTION IS FOUND IN THE FINAL POPULATION OVER 25 INDEPENDENT RUNS EA, which incorporates objective function information into the feasibility rule.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>records the mean and standard deviation of the function error value (f ( x best )f ( x * )) provided by the three compared methods over 25 runs on these 13 test functions. From TableII, GLoSADE outperforms (μ + μ)-CEP-RBF on all the 13 test functions except for CEC2006 24 according to the Wilcoxon's rank sum test at a 0.05 significance level, in terms of the average function error value. For CEC2006 CEC2006 01 , CEC2006 06 , CEC2006 07 , CEC2006 08 , CEC2006 09 , CEC2006 10 , CEC2006 18 , and CEC2006 19 ). This may be because the local surrogate-assisted search of GLoSADE enhances the accuracy of individuals by the interior point method. Moreover, we further computed SR based on the function error value. We can also observe from Table II that GLoSADE provides higher SR than (μ + μ)-CEP-RBF on nine test functions (i.e., CEC2006 01 , CEC2006 06 , CEC2006 07 , CEC2006 08 , CEC2006 09 , CEC2006 10 , CEC2006 12 , CEC2006 18 , and CEC2006 19</figDesc><table /><note><p><p><ref type="bibr" target="#b23">24</ref> </p>, (μ + μ)-CEP-RBF performs better than GLoSADE. Note that the mean function error values of GLoSADE are several orders of magnitude lower than that of (μ + μ)-CEP-RBF on eight test functions (i.e.,</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE III EXPERIMENTAL</head><label>III</label><figDesc>RESULTS OF ICGA AND GLOSADE OVER FIVE INDEPENDENT RUNS ON TOPOLOGY OPTIMIZATION OF ENERGY-ABSORBING COMPONENT</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>To ensure a fair comparison, the experimental results of mViE were directly taken from the original paper<ref type="bibr" target="#b60">[61]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>The runtime was recorded on Intel machine with Core i5-4590 CPU @3.30 GHz and 8 GB of RAM.</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the Innovation-Driven Plan in Central South University under Grant 2018CX010, in part by the National Natural Science Foundation of China under Grant 61673397 and Grant 61673331, in part by the EU Horizon 2020 Marie Sklodowska-Curie Individual Fellowships under Project 661327, in part by the Engineering and Physical Sciences Research Council of U.K. under Grant EP/K001310/1, in part by the Hunan Provincial Natural Science Fund for Distinguished Young Scholars under Grant 2016JJ1018, and in part by the Science Fund of State Key Laboratory of Advanced Design and Manufacturing for Vehicle Body under Grant 31715006. This paper was recommended by Associate Editor P. N. Suganthan.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Da-Qing Yin received the B.S. degree in automation and the M.S. degree in control science and engineering from Central South University, Changsha, China, in 2014 and 2017, respectively.</p><p>He is researching on intelligent search development with Huawei 2012 Laboratory, Shenzhen, China. His current research interests include expensive constrained evolutionary optimization, machine learning, and natural language processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shengxiang</head><p>Yang (M'00-SM'14) received the Ph.D. degree in systems engineering from Northeastern University, Shenyang, China, in 1999.</p><p>He is currently a Professor of computational intelligence and the Director of the Centre for Computational Intelligence, School of Computer Science and Informatics, De Montfort University, Leicester, U.K. He has over 240 publications. His current research interests include evolutionary computation, swarm intelligence, computational intelligence in dynamic and uncertain environments, artificial neural networks for scheduling, and relevant real-world applications.</p><p>Dr. Yang serves as an Associate Editor/Editorial Board Member of seven international journals, such as the IEEE TRANSACTIONS ON CYBERNETICS, Information Sciences, Evolutionary Computation, and Soft Computing. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Optimization using surrogate models and partially converged computational fluid dynamics simulations</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I J</forename><surname>Forrester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">W</forename><surname>Bressloff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Keane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Roy. Soc. A Math. Phys. Eng. Sci</title>
		<imprint>
			<biblScope unit="volume">462</biblScope>
			<biblScope unit="page" from="2177" to="2204" />
			<date type="published" when="2006">2071. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Structural optimization using evolution strategies and neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Papadrakakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lagaros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tsompanakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Methods Appl. Mech. Eng</title>
		<imprint>
			<biblScope unit="volume">156</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="309" to="333" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Genetical swarm optimization: Self-adaptive hybrid evolutionary algorithm for electromagnetics</title>
		<author>
			<persName><forename type="first">F</forename><surname>Grimaccia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mussetta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Zich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Antennas Propag</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="781" to="785" />
			<date type="published" when="2007-03">Mar. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Gaussian process surrogate model assisted evolutionary algorithm for medium scale expensive optimization problems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G E</forename><surname>Gielen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="180" to="192" />
			<date type="published" when="2014-04">Apr. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A framework for evolutionary optimization with approximate fitness function</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Olhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sendhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="481" to="494" />
			<date type="published" when="2002-10">Oct. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Local function approximation in evolutionary algorithms for the optimization of costly functions</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Regis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Shoemaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="490" to="505" />
			<date type="published" when="2004-10">Oct. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Metamodel-Assisted evolution strategies</title>
		<author>
			<persName><forename type="first">M</forename><surname>Emmerich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Giotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Özdemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bäck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Giannakoglou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Parallel Problem Solving Nat</title>
		<meeting>Parallel Problem Solving Nat</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">VII</biblScope>
			<biblScope unit="page" from="361" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Memetic algorithm using multi-surrogates for computationally expensive optimization problems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Comput</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="957" to="971" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Combining landscape approximation and local search in global optimization</title>
		<author>
			<persName><forename type="first">K.-H</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Newton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Congr</title>
		<meeting>Congr<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1514" to="1520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Surrogate-assisted evolutionary computation: Recent advances and future challenges</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="61" to="70" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Incorporating objective function information into the feasibility rule for constrained evolutionary optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2938" to="2952" />
			<date type="published" when="2016-12">Dec. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A variable reduction strategy for evolutionary algorithms handling equality constraints</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mallipeddi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="774" to="786" />
			<date type="published" when="2015-12">Dec. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Using variable reduction strategy to accelerate evolutionary optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="283" to="293" />
			<date type="published" when="2017-12">Dec. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">ASCHEA: New results using adaptive segregational constraint handling</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Hamida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schoenauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Congr</title>
		<meeting>Congr<address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="884" to="889" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adaptive penalty methods for genetic optimization of constrained combinatorial problems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wcoit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Esmith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mtate</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">INFORMS J. Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="173" to="182" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Self-adaptive fitness formulation for constrained optimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Farmani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="445" to="455" />
			<date type="published" when="2003-10">Oct. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An efficient constraint handling method for genetic algorithms</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Methods Appl. Mech. Eng</title>
		<imprint>
			<biblScope unit="volume">186</biblScope>
			<biblScope unit="issue">2-4</biblScope>
			<biblScope unit="page" from="311" to="338" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A simple multimembered evolution strategy to solve constrained optimization problems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mezura-Montes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2005-02">Feb. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Stochastic ranking for constrained evolutionary optimization</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Runarsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="284" to="294" />
			<date type="published" when="2000-09">Sep. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Search biases in constrained evolutionary optimization</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Runarsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. C, Appl. Rev</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="233" to="243" />
			<date type="published" when="2005-05">May 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Treating constraints as objectives for single-objective evolutionary optimization</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eng. Optim</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="275" to="308" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Constraint-handling using an evolutionary multiobjective optimization technique</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Civil Eng. Environ. Syst</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="319" to="346" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A multiobjective optimization-based evolutionary algorithm for constrained optimization</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="658" to="675" />
			<date type="published" when="2006-12">Dec. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multiobjective optimization and hybrid evolutionary algorithm to solve constrained optimization problems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B, Cybern</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="560" to="575" />
			<date type="published" when="2007-06">Jun. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An adaptive tradeoff model for constrained evolutionary optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="80" to="92" />
			<date type="published" when="2008-02">Feb. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Constraint-handling in natureinspired numerical optimization: Past, present and future</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mezura-Montes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="173" to="194" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Problem definitions and evaluation criteria for the CEC 2006 special session on constrained real-parameter optimization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nanyang Technol. Univ</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<pubPlace>Singapore, Rep.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Problem definitions and evaluation criteria for the CEC 2010 competition on constrained real-parameter optimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mallipeddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nanyang Technol. Univ</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<pubPlace>Singapore, Rep.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Problem definitions and evaluation criteria for the CEC 2017 competition and special session on constrained single objective real-parameter optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mallipeddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nanyang Technol. Univ</title>
		<imprint>
			<date type="published" when="2016-11">Nov. 2016</date>
			<pubPlace>Singapore, Rep</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Differential evolution-A simple and efficient heuristic for global optimization over continuous spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Glob. Optim</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Differential evolution with multi-population based ensemble of mutation strategies</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mallipeddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">329</biblScope>
			<biblScope unit="page" from="329" to="345" />
			<date type="published" when="2016-02">Feb. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Ensemble of differential evolution variants</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">423</biblScope>
			<biblScope unit="page" from="172" to="186" />
			<date type="published" when="2018-01">Jan. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A general regression neural network</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Specht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="568" to="576" />
			<date type="published" when="1991-11">Nov. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">On estimation of a probability density function and mode</title>
		<author>
			<persName><forename type="first">E</forename><surname>Parzen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Math. Stat</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1065" to="1076" />
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Global convergence of radial basis function trust-region algorithms for derivative-free optimization</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Wild</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shoemaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="349" to="371" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Differential evolution assisted by surrogate models for structural optimization problems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Krempser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Bernardino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J C</forename><surname>Barbosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C C</forename><surname>Lemonge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th Int</title>
		<meeting>8th Int<address><addrLine>Stirling, U.K</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A preliminary study of fitness inheritance in evolutionary constrained optimization</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mezura-Montes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Muñoz-Dávila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Nature Inspired Cooperative Strategies for Optimization</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Krasnogor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Nicosia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Pavone</surname></persName>
		</editor>
		<editor>
			<persName><surname>Pelta</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Constrained evolutionary optimization by approximate ranking and surrogate models</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Runarsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Parallel Problem Solving Nat</title>
		<meeting>Parallel Problem Solving Nat</meeting>
		<imprint>
			<publisher>VII</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="401" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Accelerating evolutionary algorithms with Gaussian process fitness function models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Büche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Schraudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Koumoutsakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. C, Appl. Rev</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="183" to="194" />
			<date type="published" when="2005-05">May 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Using approximations to accelerate engineering design optimization</title>
		<author>
			<persName><forename type="first">V</forename><surname>Torczon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Trosset</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th AIAA/USAF/NASA/ISSMO Symp</title>
		<meeting>7th AIAA/USAF/NASA/ISSMO Symp<address><addrLine>Reston, VA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="738" to="748" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Singleand multiobjective evolutionary optimization assisted by Gaussian random field metamodels</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T M</forename><surname>Emmerich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Giannakoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Naujoks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="421" to="439" />
			<date type="published" when="2006-08">Aug. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Global versus local search in constrained optimization of computer models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schonlau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Welch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">New Developments and Applications in Experimental Design</title>
		<editor>
			<persName><forename type="first">W</forename><surname>Flournoy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Rosenberger</surname></persName>
		</editor>
		<editor>
			<persName><surname>Wong</surname></persName>
		</editor>
		<meeting><address><addrLine>Hayward, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="11" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Evolutionary programming for high-dimensional constrained expensive black-box optimization using radial basis functions</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Regis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="326" to="347" />
			<date type="published" when="2014-06">Jun. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Constrained optimization by radial basis function interpolation for high-dimensional expensive black-box problems with infeasible initial points</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Regis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eng. Optim</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="218" to="243" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">SACOBRA: Self-adjusting constrained black-box optimization with RBF</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bagheri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 25th Workshop Comput</title>
		<meeting>25th Workshop Comput<address><addrLine>Dortmund, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="87" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Evolutionary optimization of computationally expensive problems via surrogate modeling</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Keane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIAA J</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="687" to="696" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A computationally efficient feasible sequential quadratic programming algorithm</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Tits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1092" to="1118" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A surrogateassisted memetic co-evolutionary algorithm for expensive constrained optimization problems</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Dutta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CEC</title>
		<meeting>CEC<address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="744" to="749" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Classification-assisted memetic algorithms for equality-constrained optimization problems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Handoko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Kwoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Adv</title>
		<meeting>Adv<address><addrLine>Melbourne, VIC, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="391" to="400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Feasibility structure modeling: An effective chaperone for constrained memetic algorithms</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Handoko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Kwoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Ong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="740" to="758" />
			<date type="published" when="2010-10">Oct. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Trust regions in surrogate-assisted evolutionary programming for constrained expensive black-box optimization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Regis</surname></persName>
		</author>
		<editor>Evolutionary Constrained Optimization, R. Datta and K. Deb</editor>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="51" to="94" />
			<pubPlace>New Delhi, India</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Large sample properties of simulations using latin hypercube sampling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="143" to="151" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Generalizing surrogateassisted evolutionary computation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sendhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="329" to="355" />
			<date type="published" when="2010-06">Jun. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Information-based objective functions for active data selection</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J C</forename><surname>Mackay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="590" to="604" />
			<date type="published" when="1992-07">Jul. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<title level="m">Gaussian Processes for Machine Learning</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Differential evolution with composite trial vector generation strategies and control parameters</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="66" />
			<date type="published" when="2011-02">Feb. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Interior-point methods</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Potra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Appl. Math</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="281" to="302" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A stochastic radial basis function method for the global optimization of expensive functions</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Regis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Shoemaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">INFORMS J. Comput</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="497" to="509" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A surrogate-assisted differential evolution algorithm with dynamic parameters selection for solving expensive optimization problems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Sarker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CEC</title>
		<meeting>CEC<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1062" to="1068" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">An evolving surrogate model-based differential evolution algorithm</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mallipeddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="770" to="787" />
			<date type="published" when="2015-09">Sep. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Memetic viability evolution for constrained optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Maesani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Iacca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Floreano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="125" to="144" />
			<date type="published" when="2016-02">Feb. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Constrained optimization by the ε constrained differential evolution with an archive and gradient-based mutation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Takahama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sakai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CEC</title>
		<meeting>CEC<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Efficient constrained optimization by the ε constrained rank-based differential evolution</title>
		<author>
			<persName><forename type="first">T</forename><surname>Takahama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sakai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CEC</title>
		<meeting>CEC<address><addrLine>Brisbane, QLD, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Constrained single-objective optimization using particle swarm optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zielinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Laur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CEC</title>
		<meeting>CEC<address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="443" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Approximate evolution strategy using stochastic ranking</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Runarsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CEC</title>
		<meeting>CEC<address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="745" to="752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Constrained evolutionary optimization by means of (μ + λ)-differential evolution and improved adaptive trade-off model</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="249" to="285" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">An improved (μ + λ)-constrained differential evolution for constrained optimization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">222</biblScope>
			<biblScope unit="page" from="302" to="322" />
			<date type="published" when="2013-02">Feb. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">SU2: An open-source suite for multiphysics simulation and design</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Economon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Palacios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Copeland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Lukaczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Alonso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIAA J</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="828" to="846" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Configurational optimization of multi-cell topologies for multiple oblique loads</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Struct. Multidiscipl. Optim</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="469" to="488" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Memetic computation-Past, present &amp; future [research frontier]</title>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Intell. Mag</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="24" to="31" />
			<date type="published" when="2010-05">May 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">He is currently a Professor with the School of Information Science and Engineering, CSU. His current research interests include the theory, algorithm design, and interdisciplinary applications of computational intelligence</title>
		<author>
			<persName><forename type="first">Yong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013, the 2015 IEEE Computational Intelligence Society Outstanding Ph.D. Dissertation Award, the Hunan Provincial Natural Science Fund for Distinguished Young Scholars</title>
		<meeting><address><addrLine>Wuhan, China; Changsha, China; China; China; China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006 and 2011. 2016. 2016. 2017</date>
		</imprint>
		<respStmt>
			<orgName>Wuhan Institute of Technology ; EU Horizon 2020 Marie Sklodowska-Curie Fellowship ; Researcher in Computer Science by Clarivate Analytics</orgName>
		</respStmt>
	</monogr>
	<note>Wang was a recipient of the Hong Kong Scholar by the Mainland-Hong Kong Joint Post-Doctoral Fellows Program. He is currently serving as an Associate Editor for the Swarm and Evolutionary Computation</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
