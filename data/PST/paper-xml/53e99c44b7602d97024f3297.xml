<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Lazy Random Walks for Superpixel Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Jianbing</forename><surname>Shen</surname></persName>
							<email>shenjianbing@bit.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Yunfan</forename><surname>Du</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wenguan</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Xuelong</forename><surname>Li</surname></persName>
							<email>xuelong_li@opt.ac.cn</email>
						</author>
						<author>
							<persName><roleName>Prof</roleName><forename type="first">Jean-Philippe</forename><forename type="middle">J</forename><surname>Thiran</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">W</forename><surname>Du</surname></persName>
						</author>
						<author>
							<persName><surname>Wang</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">Beijing Laboratory of Intelli-gent Information Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<postCode>100081</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Center for OPTical IMagery Analysis and Learning</orgName>
								<orgName type="department" key="dep2">Xi&apos;an Institute of Optics and Precision Mechanics</orgName>
								<orgName type="laboratory">State Key Laboratory of Transient Optics and Photonics</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>710119</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Center for Optical Imagery Analysis and Learning</orgName>
								<orgName type="department" key="dep2">State Key Laboratory of Transient Optics and Photonics</orgName>
								<orgName type="department" key="dep3">Xi&apos;an Institute of Optics and Precision Mechanics</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Lazy Random Walks for Superpixel Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">09E28FA8B2B7CBF6BBC4DAF3D9A7AE79</idno>
					<idno type="DOI">10.1109/TIP.2014.2302892</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Lazy random walk</term>
					<term>commute time</term>
					<term>optimization</term>
					<term>superpixel</term>
					<term>texture</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a novel image superpixel segmentation approach using the proposed lazy random walk (LRW) algorithm in this paper. Our method begins with initializing the seed positions and runs the LRW algorithm on the input image to obtain the probabilities of each pixel. Then, the boundaries of initial superpixels are obtained according to the probabilities and the commute time. The initial superpixels are iteratively optimized by the new energy function, which is defined on the commute time and the texture measurement. Our LRW algorithm with self-loops has the merits of segmenting the weak boundaries and complicated texture regions very well by the new global probability maps and the commute time strategy. The performance of superpixel is improved by relocating the center positions of superpixels and dividing the large superpixels into small ones with the proposed optimization algorithm. The experimental results have demonstrated that our method achieves better performance than previous superpixel approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>image primitives and improves the representative efficiency. Furthermore, it is more convenient and effective to compute the region based visual features by superpixels, which will provide the important benefits for the vision tasks such as object recognition <ref type="bibr" target="#b9">[10]</ref>.</p><p>There is a large amount of literature on automatic superpixel algorithms, for example, normalized cuts <ref type="bibr" target="#b6">[7]</ref>, mean shift algorithm <ref type="bibr" target="#b4">[5]</ref>, graph-based method <ref type="bibr" target="#b10">[11]</ref>, Turbopixels <ref type="bibr" target="#b16">[17]</ref>, SLIC superpixels <ref type="bibr" target="#b20">[21]</ref> and optimization-based superpixels <ref type="bibr" target="#b18">[19]</ref>. However, each superpixel method has its own advantage and drawback that may be better suited for a particular application. It is still challenging to develop a high quality superpixel algorithm, which avoids the under-segmentation and locally groups the pixels respecting the intensity boundaries. The desired properties of an ideal superpixel algorithm should not only adhere well to object boundaries of image, but also maintain the compact constrains in the complicated texture regions. In order to satisfy these desired requirements, we develop a new image superpixel segmentation method by the lazy random walk (LRW) and energy optimization algorithm to achieve better performance than the previous approaches.</p><p>Our image superpixel segmentation algorithm is based on the generalized random walk (RW) algorithms <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b21">[22]</ref>. However, the original RW algorithm depends on the local relationship between the pixel and its corresponding seeds with the first arrival probability. This may lead to the irregular shape of the final non-uniform superpixel results. By considering the global relationships between all the pixels and the seed points, we then develop a novel superpixel algorithm using the LRW with the compactness constraints. Our LRW algorithm with self-loops effectively solves the segmentation problem in weak boundary and complex texture regions. On the other hand, the LRW based superpixel algorithm may suffer from the sensitiveness of the initial seed positions. In order to overcome these limitations and improve the performance, we further develop a new superpixel optimization approach by introducing an energy optimization framework. Our superpixel optimization strategy is essentially a compactness constraint, which ensures the resulting superpixels to distribute uniformly with the homogeneous size by relocation and splitting mechanism. Our energy function is composed of two items, the first data item adaptively optimizes the positions of seed points to make the superpixel boundaries adhere to the object boundaries well, and the second smooth item adaptively divides the large superpixels into small ones to make the superpixels more homogeneous. According to these relocated seed positions and newly created seeds by the splitting scheme, our LRW algorithm is executed again to optimize the initial superpixels, which makes the boundaries of final superpixels adhere to object boundaries very well. Our source code and other supplementary materials will be publicly available online. 1   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>A plenty of papers have proposed various image superpixel methods during the last decade, and we will briefly review these works in this section. The existing superpixel approaches can be roughly classified into two categories. The first category is the algorithms that do not consider the compactness constrains during the superpixels generation procedure, such as meanshift <ref type="bibr" target="#b4">[5]</ref>, and graph based <ref type="bibr" target="#b10">[11]</ref> algorithms. In order to avoid the superpixels crossing the object boundaries, these segmentation algorithms generally produce the superpixels by over-segmenting the image. Since these algorithms do not consider the compactness constrains, which may produce the superpixels of highly irregular shapes and sizes. The second category of superpixel algorithms considers the compactness constrains, such as normalized cuts <ref type="bibr" target="#b6">[7]</ref>, lattice cut <ref type="bibr" target="#b15">[16]</ref>, TurboPixels <ref type="bibr" target="#b16">[17]</ref>, and graph cut <ref type="bibr" target="#b18">[19]</ref> approaches. Ren and Malik <ref type="bibr" target="#b6">[7]</ref> proposed an image superpixel approach to segment the image into a large number of small compact and homogeneous regions by the normalized cuts. The NCuts method is very powerful in feature extraction for obtaining the regular superpixels in size and shape. However, the computational cost of NCuts superpixel approach is very high and expensive when the number of superpixels or the size of image increases greatly. Levinshtein et al. <ref type="bibr" target="#b16">[17]</ref> presented an efficient TurboPixel superpixel algorithm using the level set based geometric flow evolution from the uniformly placed seeds in the image. However, it exhibited relatively poor boundary adherence because of its numerical stability issues especially with complicated textures. Veksler et al. <ref type="bibr" target="#b18">[19]</ref> developed an image superpixel approach by the graph cut optimization, and the superpixels were obtained by stitching each pixel that belonged to only one of the overlapping image patches.</p><p>There are other important superpixel approaches that have been proposed to fulfill the need of increasing applications, such as the algorithms in <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, and <ref type="bibr" target="#b32">[33]</ref>. Moore et al. <ref type="bibr" target="#b19">[20]</ref> used a single graph cut method to construct an optimal solution in either the horizontal or vertical direction, which took into account both the edges and the coherence of resulting superpixel lattices. Xiang et al. <ref type="bibr" target="#b23">[24]</ref> proposed a lattice-like structure of superpixel regions with uniform size by learning the eigen-images from the input image, which improved the evolution speed in the TurboPixel framework. Achanta et al. <ref type="bibr" target="#b20">[21]</ref> presented a simple linear iterative clustering (SLIC) superpixel algorithm, and adopted the k-means clustering approach to generate the superpixels with relatively lower computational cost. Liu et al. <ref type="bibr" target="#b27">[28]</ref> formulated the superpixel segmentation problem as an objective function on the entropy rate in the graph. The entropy rate can help to cluster the compact and homogeneous regions, which also favors the superpixels to overlap with a single object on the perceptual boundaries. Zeng et al. <ref type="bibr" target="#b29">[30]</ref> presented a structuresensitive image superpixel technique by exploiting the 1 http://cs.bit.edu.cn/shenjianbing/lrw.htm geodesic distance. Recently, Wang et al. <ref type="bibr" target="#b32">[33]</ref> proposed an edge-weighted centroidal voronoi tessellations (EWCVTs)-based superpixel algorithm, which generated the uniform superpixels and preserved the image boundaries well.</p><p>In addition, another important related work with our paper is the RW algorithm and its applications in image processing <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>. The RW algorithm developed by Grady <ref type="bibr" target="#b11">[12]</ref> is a very popular and leading approach for interactive image segmentation using the foreground and background seeds by the user. The RW algorithm achieves the better interactive image segmentation performance than the graph cut based segmentation method with the same user interactions. Grady and Schwartz <ref type="bibr" target="#b12">[13]</ref> also presented a novel isoperimetric graph partitioning approach with a small isoperimetric constant and achieved high quality segmentations by solving a linear system, which was an effective seedless version of the RW algorithm. Sinop et al. <ref type="bibr" target="#b13">[14]</ref> further extended the RW algorithm by incorporating a nonparametric probability density model to locate the disconnected objects for segmentation. However, the RW algorithm for interactive image segmentation lacks a global color distribution model, which will make the segmentation result sensitive to the positions and quantities of the user-defined seeds on the image objects. In order to provide more intelligent ways to understand the intention of user inputs, Yang et al. <ref type="bibr" target="#b21">[22]</ref> proposed a constrained RW algorithm to facilitate the multiple user inputs with an interactive editing framework. Their method created precise contour refinement of the segmentation results. Couprie et al. <ref type="bibr" target="#b28">[29]</ref> developed a power watershed segmentation framework, which contained the RW, shortest path optimization and graph cuts. We refer the interested reader to a recent book by Grady and Polimeni <ref type="bibr" target="#b25">[26]</ref> for more about the RW algorithm by discrete calculus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. OUR APPROACH</head><p>The goal of superpixel is to over-segment the input image into small compact regions with homogenous appearance. The superpixel segmentation can be considered as a pixel labeling problem where each superpixel is assigned to a unique label. Our approach begins with placing the initialized seeds of the assigned superpixels. Then, we use the LRW algorithm to obtain the initial superpixels and their boundaries. In order to further make the superpixels more compact and their boundaries more consistent with the object boundaries in image, we develop a novel energy optimization algorithm to optimize the seed positions and split the large superpixels. Fig. <ref type="figure" target="#fig_0">1</ref> illustrates the workflow and gives the procedure of the proposed LRW superpixel optimization algorithm. Our superpixel approach consists of two main steps. The first step is to obtain the superpixels using the LRW algorithm with initial seed points [Fig. <ref type="bibr">1(b)</ref>]. In order to improve the superpixel performance, we optimize the initial superpixels by the new energy function in the second step. Our energy includes two items: the data item makes the superpixels more homogenous with regular size by relocating the seed positions [Fig. <ref type="figure" target="#fig_0">1(c)]</ref>, and the smooth item makes the superpixels more adhering to the texture edges by dividing the large irregular superpixels into small regular ones [Fig. <ref type="figure" target="#fig_0">1(f)</ref>]. Then, our LRW algorithm is performed again to obtain the better boundaries of superpixels with these new seed positions [Fig. <ref type="figure" target="#fig_0">1(d)</ref>]. Finally, our superpixel optimization and LRW steps are executed iteratively so as to achieve the final satisfying superpixel results [Fig. <ref type="figure" target="#fig_0">1(g)</ref>]. In the following subsections, we will discuss in detail the LRW algorithm, LRW-based superpixel initialization and optimization algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Lazy Random Walk Algorithm</head><p>The RW algorithm has been used extensively for interactive image segmentation in the image processing and computer vision literatures <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b21">[22]</ref>. The RW algorithm computes the first arrival probability that a random walk starts at one pixel first reaches one of the seeds with each label, and then that pixel is denoted as the same label with maximum probability of the corresponding seed. A random walk starts from a pixel must first arrive at the position of the prelabeled seed, and thus it only considers the local relationship between the current pixel and its corresponding seed. This first arrival probability ignores the whole relationship between the current pixel and other seeds. As denoted by Grady <ref type="bibr" target="#b11">[12]</ref>, these limitations of the original RW method give the reason that it suffers from the weak boundary and complex texture segmentations.</p><p>In order to make full use of the global relationship between the pixel and all the seeds, we add the self-loop over the graph vertex to make the RW process lazy, which is inspired by the original LRW concept <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b11">[12]</ref>. However, the original LRW was initially proposed for the website data classifying and mining applications in <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b7">[8]</ref>, and <ref type="bibr" target="#b8">[9]</ref>. In our application, we need to further develop the original LRW algorithm to be suitable for our image superpixel segmentation application. As shown in Fig. <ref type="figure" target="#fig_2">2</ref>, the main contribution of our LRW based superpixel algorithm is two-fold. On one hand, the self-loop [Fig. <ref type="figure" target="#fig_2">2(b)</ref>] is added on each vertex to ensure the boundary constrain for superpixels. Since a vertex with a heavy self-loop is more likely to absorb its neighboring pixels than the one with light self-loop, which makes the vertex to absorb and capture both the weak boundary and texture information with self-loops. On the other hand, instead of starting from the pixels to the seed points as the original RW algorithm does [Fig. <ref type="figure" target="#fig_2">2</ref> For describing the LRW algorithm, a graph G = (V, E) is first defined on a given image I (x i ), which represents a weighted graph containing a set of nodes V and edges E⊆V ×V . Then every pixel x i is identified uniquely by a node vertex v i ∈ V in our undirected graph, where the degree of each vertex is computed as d i = j w i j for all the edges that incident on v i . We adopt a commonly used edge-weight computation method in many graph-based image segmentation approaches <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b22">[23]</ref> to represent the image intensity changes. This edge-weight measures the similarity between two neighboring nodes v i and v j , and thus we define w i j as the following Gaussian weighting function:</p><formula xml:id="formula_0">w i j = ex p(- ||g i -g j || 2 2σ 2 ) (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where g i and g j denote the image intensity values at two nodes 2 http://www.cns.bu.edu/˜lgrady/random_walker_matlab_code.zip Image segmentation result by our LRW algorithm has the better performance than the one by classic RW method <ref type="bibr" target="#b11">[12]</ref> with the same user scribbles (green for foreground and blue for background), especially in the leg regions of wolf and the flower parts.</p><p>v i and v j , and σ is the user defined parameter. The value of 2σ 2 is fixed to 1/30 in all the experiments. As described in <ref type="bibr" target="#b11">[12]</ref> and <ref type="bibr" target="#b31">[32]</ref>, the Gaussian function has the property of geodesic distance as the edge-weights, which works well for the proposed LRW algorithm. Comparing to the traditional RW algorithm, our LRW graph has the property that there is a non-zero likelihood that a lazy random walk remains at the same node by adding a self-loop to each vertex v i , The new adjacency matrix is defined as</p><formula xml:id="formula_2">W i j = ⎧ ⎨ ⎩ 1 -α if i=j, α • w i j if i ∼ j , 0 otherwise,<label>(2)</label></formula><p>where i ∼ j means node v i and node v j are the adjacent nodes, and α is a control parameter in the range (0, 1). W is a sparse and symmetric banded matrix whose nonzero elements are positive.</p><p>After row-normalizing the adjacency matrix, we obtain the transition probability matrix as follows:</p><formula xml:id="formula_3">P i j = ⎧ ⎨ ⎩ 1 -α if i=j, α • w i j /d i if i ∼ j , 0 otherwise,<label>(3)</label></formula><p>The above equation can also be written as</p><formula xml:id="formula_4">P = (1 -α)I + αD -1 W (see Lemma 1 in Appendix A)</formula><p>where D is a diagonal matrix and D ii is the degree of the i -th vertex v i . This means the current position v i in our LRW algorithm will have the probability (1 -α) to stay at the current position and the probability α to walk out along arbitrary edge. α is the sum of the weights of all the edges that incident to v i .</p><p>According to the spectral graph theory <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b3">[4]</ref>, the LRW algorithm converges to a unique stationary distribution π, which satisfies the following balance equation (see Lemma 2 in Appendix A):</p><formula xml:id="formula_5">π i = d i / N=|V | i=1 d i (4)</formula><p>From Equation (2), we define the following graph Laplacian matrix:</p><formula xml:id="formula_6">L i j = ⎧ ⎨ ⎩ d i if i = j , -αw i j if i ∼ j , 0 otherwise,<label>(5)</label></formula><p>Equation ( <ref type="formula" target="#formula_6">5</ref>) can also be written as L = D -αW. We then use CT i j to denote the expected quantities of steps for a lazy random walk that starts at node v i to reach node v j and then return to v i . CT i j is called the commute time <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref> between v i and v j , which is defined as follows:</p><formula xml:id="formula_7">CT i j = L -1 ii + L -1 j j -L -1 i j -L -1 j i if i = j , 1/π i if i = j , (<label>6</label></formula><formula xml:id="formula_8">)</formula><p>where L -1 denotes the inverse of the matrix L. CT i j is the corresponding Euclidean norm derived from the inner product of L -1 i j . L -1 can also be considered as a Gram matrix that assigns an inner product on the vertices set.</p><p>The classic RW algorithm <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b24">[25]</ref> is essentially a stochastic process formed by successive summation of independent and identically distributed random variables, which usually formulates the path of a random walker with successive random steps on a discrete graph. The main reason of using the normalized Laplacian matrix is to be more consistent with the eigenvalues of adjacency matrices in spectral geometry and in stochastic process <ref type="bibr" target="#b0">[1]</ref>. Grady <ref type="bibr" target="#b11">[12]</ref> treated the RW probabilities algorithm as the Dirichlet problem by first decomposing the Laplacian matrix L into four sub-matrices and then converting it into a linear system. Our approach requires to solve the inverse of normalized Laplacian matrix to calculate the commute time.</p><p>From the definition of Laplacian matrix, we can see that L and L -1 are both the symmetric matrix and L -1</p><formula xml:id="formula_9">i j = L -1 j i .</formula><p>We then obtain the normalized Laplacian matrix L = (I -αD -1/2 WD -1/2 ) by normalizing the commute time to one that is the sum of commute time from a node to other nodes. We use CT to denote the normalized CT , then</p><formula xml:id="formula_10">CT i j = 1 -L -1 i j if i = j , 1 if i = j ,<label>(7)</label></formula><p>According to the property of the commute time that is inversely proportion to the probability, we now get the likelihood probabilities of label l as f l = L -1 i j = 1 -CT i j . By defining S = D -1/2 WD -1/2 , the likelihoods f l is written as the following closed-form solution:</p><formula xml:id="formula_11">f l = (I -αS) -1 y l (<label>8</label></formula><formula xml:id="formula_12">)</formula><p>where I is the identity matrix and f l : V → is a N × 1 vector, and the probabilities of the nodes are assigned the label l.</p><p>And y l is a N × 1 column vector as 0, 0, • • •, 0, 1, 0, • • •, 0 where all the elements are zero except the seed pixels as 1. Then y l (x i ) = 1 if x i is labeled with l and y l (x i ) = 0 otherwise. α is chosen empirically in this work and we set α = 0.99 through this paper to produce the sufficient good results in both the boundary adherence and superpixel homogenous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. LRW Based Superpixel Initialization</head><p>Our method begins by placing the initial superpixel seeds on the input image where we follow the similar seed initialization strategy as in <ref type="bibr" target="#b16">[17]</ref>. Our goal is to make the superpixels to be evenly distributed over the whole image as much as possible. We first place K circular seeds in a lattice formation, and the distance between lattice neighbors is equal to √ N/K where N is the total number of pixels in the image. This strategy ensures that the superpixels will be evenly distributed on the whole image. However, this placement strategy may cause some seeds to occasionally close to a strong edge because these images are not completely uniform distribution. Thus, the initial seed position is perturbed by moving it along its gradient direction according to the seed density.</p><p>After we have finished the seed initialization stage, we then use the LRW algorithm (in Section I I I.A) to compute the Algorithm 1 LRW Based Superpixel Initialization Algorithm boundaries of superpixels. At each step, the LRW algorithm transmits to its neighborhood with the probability which is proportional to the aforementioned edge-weight w i j . The LRW algorithm will converge at a pixel x i with the boundary likelihood probabilities f l k (x i ) of superpixels as Equation <ref type="bibr" target="#b7">(8)</ref>. Finally, we obtain the labeled boundaries of superpixels from the commute time as follows:</p><formula xml:id="formula_13">R(x i ) = argmi n l k CT (c l k , x i ) = argmax l k f l k (x i ) (<label>9</label></formula><formula xml:id="formula_14">)</formula><p>where c l k denotes the center of the l-th superpixel, and the label l k is assigned to each pixel x i to obtain the boundaries of superpixels.</p><p>As shown in Fig. <ref type="figure" target="#fig_3">3</ref>, the commute time in our LRW algorithm computes the return time from the seeds to pixels, which is a proper probability measurement on the graph by considering the global information. Our LRW method can find the optimal path among all the possible LRW paths from the seed to the pixel [Fig. <ref type="figure" target="#fig_3">3(b)</ref>]. Then the label of the seed with the minimal commute time is assigned to the corresponding pixel as the final superpixel label. Algorithm 1 gives the main steps of our LRW based superpixel initialization algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Superpixel Optimization</head><p>As described in the previous paragraphs, the main principle of an ideal superpixel algorithm should contain that the superpixel boundaries adhere well to image intensity boundaries and also make the superpixels to be regular with uniform size in the complicated texture regions. By considering the compactness constraints, we further improve the performance of superpixels with the following energy optimization function:</p><formula xml:id="formula_15">E = l (Ar ea(S l ) -Ar ea( S)) 2 + l W x CT (c n l , x) 2 (10)</formula><p>where the first term is the data item and the second term is the smooth item. The data item makes the texture information of image to be distributed uniformly in the superpixels, which produces more homogeneous superpixels. The smooth item makes the boundaries of superpixels to be more consistent with the object boundaries in the image. Ar ea(S l ) is the area of superpixel and Ar ea( S) defines the average area of superpixels. W x is a penalty function for the superpixel label inconsistency, and we set W x = e -CT (c l ,x)/β in our paper where β is a normalization factor. When the commute time CT (c l , x) between seed point c l and pixel x is small, W x will be a large value. This makes the optimized superpixel to be more compact and more homogeneous in texture regions. Zeng et al. <ref type="bibr" target="#b29">[30]</ref> also adopts the similar relocation and splitting strategies to refine the oversegmentation results using the geodesic distance algorithm <ref type="bibr" target="#b14">[15]</ref>. In contrast, our approach is intrinsically different from their method. We use LRW algorithm and the commute time to develop a novel unified energy function framework to optimize the initial superpixels. Moreover, our approach uses the local binary pattern texture measurements to define the energy items.</p><p>We choose the iterative method to solve the above energy optimization because this energy function is nonconvex. In the first step, our energy function in Equation ( <ref type="formula">10</ref>) minimizes the smooth energy term to find the optimal relocation center positions of superpixels. After the first derivative with the above Equation (10) on the variable c n l , we obtain the new relocation center position by minimizing the data item as:</p><formula xml:id="formula_16">∂ E ∂c n l = 2 l W x CT (c n l , x)∇CT (c n l , x) ≈ 2 l W x CT (c n-1 l , x) x -c n l ||x -c n-1 l || = 0 (<label>11</label></formula><formula xml:id="formula_17">)</formula><p>where n represents the number of iterations and c 0 l is the initial center positions.</p><p>For the computational convenience, we use the commute time of the (n -1)-th iteration to approximate the commute time of the n-th iteration, and we then use the item</p><formula xml:id="formula_18">x-c n l ||x-c n-1 l ||</formula><p>to substitute the item ∇CT (c n l , x). Therefore, we can rewrite the above equation in a similar way to compute the center of superpixel S l . Thus the new center relocates to:</p><formula xml:id="formula_19">c n l = l W x CT (c n-1 l , x) ||x -c n-1 l || x l W x CT (c n-1 l , x) ||x -c n-1 l ||<label>(12)</label></formula><p>In the second step, after the first derivative with the above Equation ( <ref type="formula">10</ref>) on the variable Ar ea(S l ), we get the minimizing solution of the data item as:</p><formula xml:id="formula_20">∂ E ∂ Ar ea(S l ) = 2 l (Ar ea(S l ) -Ar ea( S)) = 0 (<label>13</label></formula><formula xml:id="formula_21">)</formula><p>It is obvious that the above energy has the minimal value when Ar ea(S l ) equals to Ar ea( S). The value of Ar ea(S l ) represents the texture information in the superpixel S l . The energy reaches the minimal value when the texture is evenly distributed in each superpixel. Therefore, our energy prefers to split the large superpixels with abundant texture information into small superpixels in the optimization stage, which makes the final superpixels to be more homogeneous in the complicated texture regions.</p><p>In order to make the superpixel results adapt to the texture structure in the image, we adopt the texture feature of local binary pattern (LBP) <ref type="bibr" target="#b5">[6]</ref> to measure the texture information. The LBP value of each pixel is defined as follows:</p><formula xml:id="formula_22">L B P q,r i = q-1 t =0 s(g t -g i )2 t (<label>14</label></formula><formula xml:id="formula_23">)</formula><p>where q is the gray level of LBP, r is the radius of the circle around pixel i , and g means the gray value of image. We set q = 8 and r = 1 throughout this paper in our implementation.</p><p>Based on the LBP texture feature, the area of superpixel is then defined as follows:</p><formula xml:id="formula_24">Ar ea(S l ) = i∈S l L B P i , Ar ea( S) = i∈S l L B P i N sp (<label>15</label></formula><formula xml:id="formula_25">)</formula><p>where Ar ea( S) is the average area of superpixels, and N sp is the user defined number of superpixels. The area of superpixel is large when it contains much texture information. The parameter T h controls the number of iterations in superpixel optimization process. The larger T h is, the more iterations are required, and the better superpixels results will be achieved. The reason is that it forces the creation of more superpixels. Typically, when T h is in the range of T h ∈ (1.0, 1.4), our method achieves the good superpixel results according to our experiments. When Ar ea(S l )/Ar ea( S) ≥ T h, the large superpixel is divided into two small superpixels. Then the principal components analysis method is used to split the superpixel along the direction with the largest variation of commute time and superpixel shape, which is determined by (xc l )•s = 0 and s denotes the corresponding eigenvector with the largest eigenvalue. This direction is the same direction of the eigenvector with the largest eigenvalue of the covariance matrix. The covariance matrix is defined as:</p><formula xml:id="formula_26">{x|x∈S l ,x =c l } CT (c l , x) 2 ||x -c l || 2 (x -c l )(x -c l ) T (<label>16</label></formula><formula xml:id="formula_27">)</formula><p>After the splitting procedure, we get the two new superpixels and the corresponding two new centers c l new ,1 and c l new ,2 as follows:</p><formula xml:id="formula_28">c l new ,1 = {(x-c l )•s&gt;0} W x CT (c l , x) ||x -c l || x {(x-c l )•s&gt;0} W x CT (c l , x) ||x -c l || c l new ,2 = {x|x∈S l ,(x-c l )•s&lt;0} W x CT (c l , x) ||x -c l || x {x|x∈S l ,(x-c l )•s&lt;0} W x CT (c l , x) ||x -c l ||<label>(17)</label></formula><p>Algorithm 2 Superpixel Optimization Algorithm We now give a summary description of our superpixel optimization and refinement algorithm [Algorithm 2] according to the former analysis and presentation where N sp denotes the number of final superpixels.</p><p>Since the LRW method considers the global relationship well between all the seeds and each pixel, it can solve the weak boundary and complex texture problems very well and obtain the superpixels with good performance. The superpixel results by our LRW algorithm [before and after optimization, Fig. <ref type="figure" target="#fig_4">4(b)</ref> and<ref type="figure">(d)</ref>] are better than the results by the original RW algorithm <ref type="bibr" target="#b11">[12]</ref> [before and after optimization, Fig. <ref type="figure" target="#fig_4">4(a)</ref> and<ref type="figure">(c)</ref>]. Furthermore, our superpixel optimization algorithm plays an important role to relocate the seed positions and create the new seeds after splitting process, which further makes the regularity and boundary adherence of final superpixels by our LRW algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL RESULTS</head><p>In this section, we evaluate the proposed LRW algorithm on the Berkeley segmentation database (BSD), 3 which contains three hundred test images with human segmentations as the ground-truth data <ref type="bibr" target="#b1">[2]</ref>. The superpixel results are analyzed to explain the influence with different parameter settings. The proposed superpixel algorithm is then qualitatively tested with several representative examples in BSD benchmark. In order 3 http://www.cs.berkeley.edu/projects/vision/grouping/segbench/ to obtain an objective and intuitive comparison, we quantitatively evaluate our algorithm by three different error metric measurements. We further compare our algorithm to other four well-known algorithms: Turbopixel <ref type="bibr" target="#b16">[17]</ref>, GraphCut <ref type="bibr" target="#b18">[19]</ref>, SLIC <ref type="bibr" target="#b20">[21]</ref>, and RW <ref type="bibr" target="#b11">[12]</ref>. The superpixel results by GraphCut and SLIC in all experiments are generated by directly using the implementations from their webpages 4,5 in our comparison. The results of Turbopixel algorithm is also generated by the Matlab implementation provided by their website. <ref type="foot" target="#foot_2">6</ref> In order to give a relatively fair superpixel quality comparison with other algorithms, we run their programs by adjusting the parameter settings for obtaining the best superpixel performances in all our experiments. Finally, we present other comparison results between RW method and our LRW algorithm before and after optimization, and analyze the computational complexity of the representative superpixel algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Parameter Analysis and Results</head><p>The threshold parameter T h controls the number of iterations that are required to achieve the convergence. The number of superpixels will increase after iterations by splitting large superpixels into small ones until reaching the convergence. In the splitting process, the parameter T h helps to determine whether the current superpixel needs to be split or not. The splitting operator will be performed to the superpixel S l if Ar ea(S l )/Ar ea( S) &gt; T h where Ar ea(S l ) is the sum of LBP values of S l as defined in Equation <ref type="bibr" target="#b9">(10)</ref>. The purpose of splitting process is to decrease the area of large superpixel to the average area Ar ea( S), which can be viewed as the optimal size of superpixel area. Therefore, our algorithm will split the superpixel whose area is larger than the threshold area. As the value of T h increases, it will spend more iterations by relocation and splitting process to obtain the target number N sp of superpixels. Fig. <ref type="figure" target="#fig_5">5</ref> gives the plot of the number of iterations versus the threshold value of T h where T h varies from 1.0 to 1.4. When we use the small value of T h, the required iterations of obtaining the desired superpixel results will decrease accordingly. Our algorithm achieves the satisfying superpixel results when we set T h from 1.0 to 1.4. The optimization process will take more time to converge when the value of T h is set too large. However, the superpixels will be Fig. <ref type="figure">6</ref>. Superpixel results obtained by the proposed LRW and optimization algorithm on various natural images from the BSD benchmark.</p><p>over-split and the regularity performance of them will decrease when Th is set too small (T h &lt; 1.0) through our extensive experiments. We have empirically found that T h = 1.3 is sufficient to produce good superpixels in our experiments.</p><p>Fig. <ref type="figure">6</ref> gives a qualitative evaluation for the superpixel results, which are generated by the proposed LRW and optimization algorithm for the natural images from the BSD benchmark. All the examples are partitioned into roughly 400 superpixels in Fig. <ref type="figure">6</ref>. We have observed that the superpixel boundaries by our approach adhere to the object boundaries very well, and the superpixels also possess the uniform and regular shape in size. As we have explained in Section I I I.C, our optimization strategy guarantees the boundaries of superpixels to adhere well to the object boundaries in image, such as the weak boundaries and complex texture regions in Fig. <ref type="figure">6</ref> (third and bottom rows). Furthermore, our superpixel optimization algorithm makes the size of superpixel as regular and uniform as possible. However, the superpixels inside the texture region will be further optimized to fit the boundaries of texture patterns. As shown in Fig. <ref type="figure">6</ref> (first row), the shape of superpixels in coral region is optimized to the quadrilaterals, which describes the striped texture pattern nicely.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Quantitative Comparison With Other Algorithms</head><p>There are three commonly used evaluation measures to evaluate the performance of superpixel algorithms. These measures include the under segmentation error (UE), the boundary recall (BR), and the achievable segmentation accuracy (ASA) <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b32">[33]</ref>. In order to quantitatively compare our superpixel algorithm to the existing algorithms, we adopt these three metric measures to evaluate our algorithm. We use GT = {g 1 , g 2 , • • • , g K } to denote the segmentation of the ground truth image, and use SG = {s 1 , s 2 , • • • , s L } to represent the results by the superpixel algorithms.</p><p>1) Under-Segmentation Error: A good superpixel algorithm should try to avoid the under-segmentation areas in the Our algorithm performs better than the other four algorithms (GC, SLIC, TB and RW) in both the UE and ASA measurements from lower superpixel densities to higher superpixel densities. Note that we abbreviate GraphCut superpixel <ref type="bibr" target="#b18">[19]</ref> (GC) and Turbopixel superpixel <ref type="bibr" target="#b16">[17]</ref> algorithm (TB). segmentation results. In other words, we need to make sure that a superpixel only overlaps one object. This evaluation measurement checks the deducting area by the superpixel that overlaps the given ground-truth segmentation, which is calculated by the following equation <ref type="bibr" target="#b20">[21]</ref>:</p><formula xml:id="formula_29">U E = i s j ||s j ∩g i |&gt;0 |s j -g i | i g i (18)</formula><p>Equation <ref type="bibr" target="#b17">(18)</ref> defines the UE of an image by averaging this quantity over all the ground truth segmentations. Fig. <ref type="figure" target="#fig_6">7(a)</ref> gives the under-segmentation error of superpixel results produced by Turbopixel <ref type="bibr" target="#b16">[17]</ref>, GraphCut <ref type="bibr" target="#b18">[19]</ref>, SLIC <ref type="bibr" target="#b20">[21]</ref> and RW <ref type="bibr" target="#b11">[12]</ref> algorithms. All of these plots are produced by averaging the three hundred images from the BSD benchmark. As shown in Fig. <ref type="figure" target="#fig_6">7</ref>(a), the plot of UE shows that the performance of our LRW algorithm achieves better performance than the other four algorithms. The reason is that both the GraphCut and SLIC algorithms lack a compact constraint, which may lead to the superpixel to grow from the highly irregular boundaries especially in the complicated texture regions.</p><p>2) Boundary Recall: Precise boundary is an important metric for measuring the performance of superpixel algorithms by considering the boundary adherence. A superpixel algorithm with good ability to adhere well to the object boundaries would improve the segmentation performance. Boundary recall measurement computes the ratio of the ground truth boundaries that fall within the nearest superpixel boundaries. We use a standard measure of boundary recall <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b20">[21]</ref>, which is defined as follows:</p><formula xml:id="formula_30">B R = i∈GT b logi cal(mi n j ∈SG b x i -x j &lt; 2) GT b (<label>19</label></formula><formula xml:id="formula_31">)</formula><p>where GT b and SG b denote the boundary results obtained from the ground truth and the superpixel results, respectively. For the boundary recall measurement, our superpixel method outperforms the GraphCut, Turbopixel and RW algorithms from the lower superpixel densities to the higher superpixel densities as shown in Fig. <ref type="figure" target="#fig_6">7(b)</ref>. The SLIC algorithm does not constrain its superpixel to be compact and uniform, which helps to capture the good boundaries of irregular regions. Our algorithm achieves the comparable performance of BR with the SLIC algorithm. However, our LRW superpixel method considers the compact constrain well and achieves the better performance of both UE and ASA measurements than the SLIC method.</p><p>3) Achievable Segmentation Accuracy: This metric measures whether the objects in the image are correctly recognized, which is also used in <ref type="bibr" target="#b27">[28]</ref>. In other words, ASA computes the highest achievable accuracy by labeling each superpixel with the label of ground truth segmentation that has the biggest overlap area. Then the metric is defined as:</p><formula xml:id="formula_32">AS A = j argmax i |s j ∩g i | i |g i | (20)</formula><p>Our algorithm outperforms the other four algorithms in Fig. <ref type="figure" target="#fig_6">7</ref>(c), while the other four algorithms present the similar ASA performance. Our LRW superpixel approach generates the most correct overlap regions that share the same label between the superpixel results and the ground truth segmentations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Comparison With Some Well-Known Approaches</head><p>Fig. <ref type="figure" target="#fig_7">8</ref> illustrates the comparison results of superpixel segmentations of different natural images between our LRW algorithm and the other well-known algorithms <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b20">[21]</ref>. We can clearly see from Fig. <ref type="figure" target="#fig_7">8</ref> that our superpixel results have the uniform size in complex texture regions. Since we use LBP texture measurement to compute the energy function, our algorithm finds the accurate object boundaries in complex texture regions and simultaneously keeps the superpixels homogeneous very well. The superpixels by GraphCut algorithm adhere well to the important boundaries, but their method fails to keep superpixel homogeneous in size [Fig. <ref type="figure" target="#fig_7">8(a)</ref>]. Because the GraphCut method only sets the upper bound of superpixel size, which leads to the generated superpixel with different size [Fig. <ref type="figure" target="#fig_7">8(a)</ref>]. The superpixels by Turbopixel algorithm are homogeneous and regular in size, but their boundaries do not fit to the object edges well in the image [Fig. <ref type="figure" target="#fig_7">8(b)</ref>]. The boundaries of superpixels by SLIC algorithm fit the object boundaries well in image, but the shapes of superpixels are very irregular such as the small narrow superpixels in the complex texture regions [Fig. <ref type="figure" target="#fig_7">8(c)</ref>]. However, the main purpose of the SLIC algorithm is to provide a fast superpixel implementation by employing the k-means clustering method, which may sacrifice some performance such as the uniform size of superpixels. In contrast, our LRW algorithm exhibits the advantages in both preserving the uniform size and boundary adherence of superpixels very well, especially the quadrilateral shape of superpixels in zebra regions in the complicated texture regions [Fig. <ref type="figure" target="#fig_7">8(d)]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. More Discussions</head><p>In general, the good superpixel algorithms can improve the performance of the image segmentation and computer vision applications where the superpixels are usually employed as a pre-processing step. Two important issues that we need to consider in designing the high quality superpixel algorithms are the boundary adherence and the uniform size of superpixels. In order to fully satisfy these two requirements, we first employ the proposed LRW algorithm to produce the initial superpixels and then improve them by minimizing an energy function. As shown in Fig. <ref type="figure" target="#fig_8">9</ref>, we give the comparison results before and after the superpixel optimization stage between RW and our LRW algorithm where the input images contain both the weak boundaries and complicated texture regions. It is obvious that the performance of superpixels is improved after optimization, especially in both preserving the regular shape and adhering to the intensity boundaries well. Our LRW algorithm performs well in the image containing the complex texture regions [Fig. <ref type="figure" target="#fig_8">9(d)</ref>]. However, the superpixel results by the RW algorithm before and after optimization exhibit the limitations such as irregular size and small broken superpixels where the boundaries adherence is also not satisfying [Fig. <ref type="figure" target="#fig_8">9</ref>(a) and (c)]. Our termination conditions are either the changes of energy values between two successive iterations or the user defined number of superpixels.</p><p>The proposed LRW algorithm will degenerate to the classic RW algorithm when α is set to one in Equations ( <ref type="formula" target="#formula_2">2</ref>) and ( <ref type="formula" target="#formula_3">3</ref>). We now further analyze the computational complexity of our algorithm. The complexity of both SLIC and TurboPixel algorithm is approximately O(N) where N is the total number of pixels in the image, and the complexity of GraphCut algorithm is about O(N 2 ). We use the symmetric and highly sparse Laplacian graph to compute the LRW algorithm by solving the large sparse linear system. The complexity of our full superpixel algorithm is about O(n N 2 ) where n is the number of the iterations. We refer the reader to <ref type="bibr" target="#b17">[18]</ref> for more details about the algorithm complexity analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>We have presented a novel image superpixel approach using the LRW and energy optimization algorithm in this paper. Our method first runs the LRW algorithm to obtain the initial superpixel results by placing the seed positions on input image. Then we further optimize the labels of superpixels to improve the regularity and boundary adherence performance by relocating the center positions of superpixels and dividing the large superpixels into small uniform ones in an energy optimization framework. The experimental results have demonstrated that our superpixel algorithm achieves better performance than the previous well-known superpixel approaches. Our algorithm is capable of obtaining the good boundary adherence in the complicated texture and weak boundary regions, and the proposed optimization strategy significantly improves the quality of superpixels.</p><p>APPENDIX A Lemma 1. The transition probability matrix of our LRW algorithm is formulated as P i j = (1 -α)I + αD -1 W i j . Proof. The traditional RW method is determined by the following transition probability matrix:</p><formula xml:id="formula_33">P i j = D -1 W i j (<label>21</label></formula><formula xml:id="formula_34">)</formula><formula xml:id="formula_35">W i j = w i j if i ∼ j , 0 otherwise, (<label>22</label></formula><formula xml:id="formula_36">)</formula><p>where W i j is an adjacency matrix, and its element w i j denotes the weight of edges connecting nodes v i and v j with w ii = 0. Then the transition probability from v i to v j is calculated as follows:</p><formula xml:id="formula_37">P i j = w i j d i (<label>23</label></formula><formula xml:id="formula_38">)</formula><p>In contrast, the new transition probability matrix P i j of our LRW is defined by a new adjacency matrix W on the graph. The difference between W and traditional adjacency matrix W is that we set w ii = α in our LRW with self-loops and w ii = 0 in original RW.</p><formula xml:id="formula_39">W i j = ⎧ ⎨ ⎩ η if i = j , w i j if i ∼ j , 0 otherwise,<label>(24)</label></formula><p>From the above equation, the new diagonal matrix D is defined with the new degree d i = d i + η. Then the new transition probability of our LRW algorithm is computed as:</p><formula xml:id="formula_40">P i j = ⎧ ⎨ ⎩ η d i if i = j , w i j d i if i ∼ j (<label>25</label></formula><formula xml:id="formula_41">)</formula><p>Let α = d i d i be the probability of transiting from the current node to other nodes, while (1 -α) is the probability to stay at the current node. Therefore, we obtain the new transition probability matrix P as follows:</p><formula xml:id="formula_42">P = (1 -α)I + αD -1 W (<label>26</label></formula><formula xml:id="formula_43">)</formula><p>Lemma 2. There exists a unique probability distribution π = {π 1 , π 2 , • • • , π N } for the LRW algorithm that satisfies the balance equation</p><formula xml:id="formula_44">π i = d i / N=|V | i=1 d i .</formula><p>Proof. Since LRW is guaranteed to converge to a stationary distribution. Then the LRW algorithm on graph G satisfies the following distribution:</p><formula xml:id="formula_45">1DP = 1D((1 -α)I + αD -1 W) = (1 -α)1D + α1DD -1 W = (1 -α)1D + α1W = (1 -α)1D + αD = 1D<label>(27)</label></formula><p>where 1 denotes a 1×N vector with all the elements equal to 1. Therefore the stationary probability distribution for any initial distribution is obtained as:</p><formula xml:id="formula_46">π = 1D/ i D ii (<label>28</label></formula><formula xml:id="formula_47">)</formula><p>Let d i = D ii , we obtain the discrete representation of the above equation as follows: <ref type="bibr" target="#b28">(29)</ref> </p><formula xml:id="formula_48">π i = d i / N=|V | i d i</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The workflow of our LRW based superpixel method. (a) Input image; (b) initial superpixels by LRW and seed points (red "o"); (c) seeds relocation by superpixels optimization (yellow "+" is the relocated seeds from the original positions in (b), and yellow arrow "→" denotes the motion of some seed); (d) superpixel refinement by our LRW method with updated center positions (red "+"); (e) seeds relocation and newly created superpixels with their center positions (green "+") by superpixels optimization; (f) superpixel refinement by LRW; (g) final superpixels. Note that steps (c) to (f) (rectangle with dash lines) are performed iteratively until the final superpixels are obtained.</figDesc><graphic coords="3,97.19,57.41,421.58,202.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a)], our LRW algorithm computes the commute time from the seed points to other pixels [Fig. 2(b)]. The probability maps by our LRW approach [Fig. 2(e)] give more confident separation than the ones by RW method [Fig. 2(d)]. Therefore, our LRW algorithm significantly outperforms the original RW algorithm on the test images [Fig. 2(c)] with the same background and foreground seed scribbles. We use the RW implementation 2 to produce the RW segmentation results [Fig. 2(f)]. The segmentation result by our LRW algorithm [Fig. 2(g)] achieves the better foreground objects separation than the result by RW method [Fig. 2(f)].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Illustration the structure of RW and LRW algorithms with their comparison results. (a) Traditional RW method without self-loops; (b) our LRW algorithm with self-loops; (c) input images with user seeds (scribbles); (d) and (e) are the probability maps by RW and LRW algorithms; (f) and (g) are the segmentation results by RW and our LRW method.Image segmentation result by our LRW algorithm has the better performance than the one by classic RW method<ref type="bibr" target="#b11">[12]</ref> with the same user scribbles (green for foreground and blue for background), especially in the leg regions of wolf and the flower parts.</figDesc><graphic coords="4,74.51,272.69,462.74,79.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Illustration of computing the commute time C T (c l k , x i ). Here, c l k means the k-th seed point, and x i denotes a pixel in the image. The possible paths { p 1 , p 2 , • • • , p n } denote all the possible LRW paths from the seed c l k to the pixel x i , and the commute time C T (c l k , x i ) denotes the average travel time of all the possible paths from c l k to x i and return.</figDesc><graphic coords="5,329.51,58.73,216.02,72.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Comparison results of image superpixels by RW and LRW algorithms.(a) superpixels by RW [12]; (b) superpixels by our LRW; (c) superpixels by RW and optimization; (d) superpixels by our LRW and optimization. Note that the superpixels by our LRW algorithms have the better performance such as the uniform size and good boundary adherence.</figDesc><graphic coords="7,59.03,265.61,105.50,70.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Illustration of superpixel results with different values of parameter T h. The number of iterations N is plotted versus the value of threshold T h.</figDesc><graphic coords="7,337.86,57.89,199.17,118.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Performance evaluation: (a) the curves of UE; (b) the curves of BR; (c) the curves of ASA.Our algorithm performs better than the other four algorithms (GC, SLIC, TB and RW) in both the UE and ASA measurements from lower superpixel densities to higher superpixel densities. Note that we abbreviate GraphCut superpixel<ref type="bibr" target="#b18">[19]</ref> (GC) and Turbopixel superpixel<ref type="bibr" target="#b16">[17]</ref> algorithm (TB).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Visual comparison between our algorithm and the other three well-known algorithms. (a) Results by GraphCut algorithm [19]; (b) results by TurboPixel algorithm [17]; (c) results by SLIC algorithm [21]; (d) our superpixel results.</figDesc><graphic coords="9,69.47,236.57,473.06,319.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Comparisons between RW and LRW algorithms before and after the superpixel optimization process. (a) and (c) are the initial superpixels results using RW and our LRW algorithm (without optimization), respectively; (b) and (d) are the final superpixels results after optimization by RW and our LRW algorithm, respectively.</figDesc><graphic coords="10,69.47,58.73,472.94,240.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="8,63.95,58.85,483.26,436.22" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>http://www.csd.uwo.ca/faculty/olga/Code/superpixels1pt1.zip</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1"><p>http://ivrg.epfl.ch/supplementary_material/RK_SLICSuperpixels/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2"><p>http://www.cs.toronto.edu/ babalex/turbopixels_code.tar.gz</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the National Basic Research Program of China (973 Program) under Grant 2013CB328805, in part by the Key Program of NSFC Guangdong Union Foundation under Grant U1035004, in part by the National Natural Science Foundation of China under Grants 61272359 and 61125106, in part by the Program for New Century Excellent Talents in University under Grant NCET-11-0789, in part by the Shaanxi Key Innovation Team of Science and Technology under Grant 2012KCT-04, in part by the Beijing Higher Education Young Elite Teacher Project, and in part by the Specialized Fund for Joint Building Program of Beijing Municipal Education Commission.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Jianbing Shen (M'11-SM <ref type="bibr">'12)</ref> is currently a Full Professor with the School of Computer Science, Beijing Institute of Technology, Beijing, China. He has published more than 40 refereed papers in journals and conference proceedings. His current research interests include computer vision and computer graphics.</p><p>Yunfan Du is currently pursuing the M.S. degree with the School of Computer Science, Beijing Institute of Technology, Beijing, China. His current research interests include image segmentation using random walks.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R K</forename><surname>Chung</surname></persName>
		</author>
		<title level="m">Spectral Graph Theory</title>
		<meeting><address><addrLine>Providence, RI, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Amer. Math. Soc</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics</title>
		<author>
			<persName><forename type="first">D</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th IEEE ICCV</title>
		<meeting>8th IEEE ICCV<address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-07">Jul. 2001</date>
			<biblScope unit="page" from="416" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Reversible Markov Chains and Random Walks on Graphs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Aldous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fill</surname></persName>
		</author>
		<ptr target="http://stat-www.berkeley.edu/users/aldous/RWG/book.html" />
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On spectral clustering: Analysis and an algorithm</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="849" to="856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Mean shift: A robust approach toward feature space analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Comaniciu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="603" to="619" />
			<date type="published" when="2002-05">May 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multiresolution gray scale and rotation invariant texture analysis with local binary patterns</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mäenpää</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="971" to="987" />
			<date type="published" when="2002-07">Jul. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning a classification model for segmentation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 9th IEEE ICCV</title>
		<meeting>9th IEEE ICCV</meeting>
		<imprint>
			<date type="published" when="2003-10">Oct. 2003</date>
			<biblScope unit="page" from="10" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A kernel view of the dimensionality reduction of manifolds</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 21st ICML</title>
		<meeting>21st ICML</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning from labeled and unlabeled data using random walks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. DAGM</title>
		<meeting>DAGM</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="237" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Recovering human body configurations: Combining segmentation and recognition</title>
		<author>
			<persName><forename type="first">G</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2004-07">Jul. 2004</date>
			<biblScope unit="page" from="326" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Efficient graph-based image segmentation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Huttenlocher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="181" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Random walks for image segmentation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Grady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach Intell</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1768" to="1783" />
			<date type="published" when="2006-11">Nov. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Isoperimetric graph partitioning for image segmentation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Grady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="469" to="475" />
			<date type="published" when="2006-03">Mar. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A seeded image segmentation framework unifying graph cuts and random walks which yields a new algorithm</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Sinop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Grady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICCV</title>
		<meeting>IEEE ICCV</meeting>
		<imprint>
			<date type="published" when="2007-10">Oct. 2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A geodesic framework for fast interactive image and video segmentation and matting</title>
		<author>
			<persName><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 11th ICCV</title>
		<meeting>IEEE 11th ICCV</meeting>
		<imprint>
			<date type="published" when="2007-10">Oct.2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Superpixel lattices</title>
		<author>
			<persName><forename type="first">A</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Prince</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Warrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2008-06">Jun. 2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Turbopixels: Fast superpixels using geometric flows</title>
		<author>
			<persName><forename type="first">A</forename><surname>Levinshtein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Stere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kutulakos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dickinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Siddiqi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2290" to="2297" />
			<date type="published" when="2009-12">Dec. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Watkins</surname></persName>
		</author>
		<title level="m">Fundamentals of Matrix Computations</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>3rd ed</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Superpixels and supervoxels in an energy optimization framework</title>
		<author>
			<persName><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mehrani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="211" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Lattice cut-Constructing superpixels using layer constraints</title>
		<author>
			<persName><forename type="first">A</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Prince</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Warrel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2010-06">Jun. 2010</date>
			<biblScope unit="page" from="2117" to="2124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">SLIC superpixels</title>
		<author>
			<persName><forename type="first">R</forename><surname>Achanta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fsua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sässtrunk</surname></persName>
		</author>
		<idno>149300</idno>
	</analytic>
	<monogr>
		<title level="j">EPFL</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<pubPlace>Lausanne, Switzerland</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">User-friendly interactive image segmentation through unified combinatorial user inputs</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2470" to="2479" />
			<date type="published" when="2010-09">Sep. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Random walks on graphs for salient object detection in images</title>
		<author>
			<persName><forename type="first">V</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3232" to="3242" />
			<date type="published" when="2010-12">Dec. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">TurboPixel segmentation using eigen-images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3024" to="3034" />
			<date type="published" when="2010-11">Nov. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">PRandom Walk: A Modern Introduction</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Lawler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Limic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Cambridge Univ. Press</publisher>
			<pubPlace>Cambridge, U.K.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Discrete Calculus: Applied Analysis on Graphs for Computational Science</title>
		<author>
			<persName><forename type="first">L</forename><surname>Grady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Polimeni</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Superpixels via pseudo-Boolean optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">I</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mashford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Burn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICCV</title>
		<meeting>IEEE ICCV</meeting>
		<imprint>
			<date type="published" when="2011-11">Nov. 2011</date>
			<biblScope unit="page" from="1387" to="1394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Entropy rate superpixel segmentation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ramalingam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2011-06">Jun. 2011</date>
			<biblScope unit="page" from="2097" to="2104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Power watershed: A unifying graph-based optimization framework</title>
		<author>
			<persName><forename type="first">C</forename><surname>Couprie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Grady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Najman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Talbot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1384" to="1399" />
			<date type="published" when="2011-07">Jul. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Structure-sensitive superpixels via geodesic distance</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICCV</title>
		<meeting>IEEE ICCV</meeting>
		<imprint>
			<date type="published" when="2011-11">Nov. 2011</date>
			<biblScope unit="page" from="447" to="454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Segmentation using superpixels: A bipartite graph partitioning approach</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2012-06">Jun. 2012</date>
			<biblScope unit="page" from="789" to="796" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Segmentation of stochastic images with a stochastic random walker method</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pätz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Preusser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2424" to="2433" />
			<date type="published" when="2012-05">May 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">VCells: Simple and efficient superpixels using edge-weighted centroidal Voronoi tessellations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1241" to="1247" />
			<date type="published" when="2012-06">Jun. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
