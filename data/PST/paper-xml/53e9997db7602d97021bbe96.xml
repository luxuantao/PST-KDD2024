<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Wavelet Coding of Volumetric Medical Datasets</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><roleName>Member, IEEE</roleName><forename type="first">Peter</forename><surname>Schelkens</surname></persName>
							<email>peter.schelkens@vub.ac.be</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electronics and Information Processing (ETRO)</orgName>
								<orgName type="institution">Vrije Universiteit Brussel</orgName>
								<address>
									<addrLine>Pleinlaan 2</addrLine>
									<postCode>B-1050</postCode>
									<settlement>Brussels</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Adrian</forename><surname>Munteanu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electronics and Information Processing (ETRO)</orgName>
								<orgName type="institution">Vrije Universiteit Brussel</orgName>
								<address>
									<addrLine>Pleinlaan 2</addrLine>
									<postCode>B-1050</postCode>
									<settlement>Brussels</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joeri</forename><surname>Barbarien</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electronics and Information Processing (ETRO)</orgName>
								<orgName type="institution">Vrije Universiteit Brussel</orgName>
								<address>
									<addrLine>Pleinlaan 2</addrLine>
									<postCode>B-1050</postCode>
									<settlement>Brussels</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mihnea</forename><surname>Galca</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electronics and Information Processing (ETRO)</orgName>
								<orgName type="institution">Vrije Universiteit Brussel</orgName>
								<address>
									<addrLine>Pleinlaan 2</addrLine>
									<postCode>B-1050</postCode>
									<settlement>Brussels</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xavier</forename><surname>Giro-Nieto</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electronics and Information Processing (ETRO)</orgName>
								<orgName type="institution">Vrije Universiteit Brussel</orgName>
								<address>
									<addrLine>Pleinlaan 2</addrLine>
									<postCode>B-1050</postCode>
									<settlement>Brussels</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ieee</forename><surname>Member</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electronics and Information Processing (ETRO)</orgName>
								<orgName type="institution">Vrije Universiteit Brussel</orgName>
								<address>
									<addrLine>Pleinlaan 2</addrLine>
									<postCode>B-1050</postCode>
									<settlement>Brussels</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Jan</forename><surname>Cornelis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electronics and Information Processing (ETRO)</orgName>
								<orgName type="institution">Vrije Universiteit Brussel</orgName>
								<address>
									<addrLine>Pleinlaan 2</addrLine>
									<postCode>B-1050</postCode>
									<settlement>Brussels</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Wavelet Coding of Volumetric Medical Datasets</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E6866856FCCD9C8157AF22498BECDF38</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Volumetric coding</term>
					<term>medical image compression</term>
					<term>lossless compression</term>
					<term>embedded coding</term>
					<term>quadtree coding</term>
					<term>layered zero coding</term>
					<term>progressive image transmission</term>
					<term>JPEG2000</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Several techniques based on the 3D Discrete Cosine Transform (DCT) have been proposed for volumetric data coding. These techniques fail to provide lossless coding coupled with quality and resolution scalability, which is a significant drawback for medical applications. This paper gives an overview of several state-of-the-art 3D wavelet coders that do meet these requirements, and proposes new compression methods exploiting the quadtree and block-based coding concepts, layered zerocoding principles and context-based arithmetic coding. Additionally, a new 3D DCT-based coding scheme is designed, and used for benchmarking. The proposed wavelet-based coding algorithms produce embedded data streams that can be decoded up to the lossless level, and support the desired set of functionality constraints. Moreover, objective and subjective quality evaluation on various medical volumetric datasets shows that the proposed algorithms provide competitive lossy and lossless compression results when compared to the state-of-theart.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>I N many medical applications compression is indispensable to guarantee interactivity during the consultation of large sets of images (e.g. volumetric data sets, time sequences of images, image databases), for probing context dependent detailed image structures, and/or quantitative analysis of the measurements. As a consequence, trading-off image quality and/or implementation complexity against bit-rate introduces specific constraints. On one hand it is intolerable to drop any information when handling medical data. Discarding small image details that might be an indication of pathology could alter a diagnosis, causing severe human and legal consequences <ref type="bibr" target="#b0">[1]</ref>. For example, images obtained from projection radiography may reveal lesions by image details that are extremely sensitive to lossy compression since they are small or have poorly defined borders (e.g. some microcalcifications in mammograms, the trabecular pattern of bone, the edge of a pneumothorax, etc.), and are only distinguishable by subtle changes in the contrast <ref type="bibr" target="#b0">[1]</ref>.</p><p>On the other hand a concept like progressive data transmission <ref type="bibr" target="#b1">[2]</ref> -and thus inherently support for lossy coding -is equally important. This methodology allows for example to prioritize low-resolution versions of the requested images and to progressively refine the resolution of the visualized data by transferring additional data. This scalability mode is often referred to as resolution scalability. In a quality scalability scheme, the images are decoded immediately to the full resolution but with a reduced visual quality. Additionally, by selecting regions that are relevant for the medical diagnosis -i.e. the regions-of-interest (ROIs) -parts of the image can be evaluated in a very early transmission stage at full quality. Meanwhile, the background information will be further refined.</p><p>Moreover, it should be clear that we target optimal ratedistortion performance over the complete range of bit-rates that is requested by the application. For example, JPEG2000 <ref type="bibr" target="#b2">[3]</ref> (based on the wavelet transform) clearly outperforms its predecessor JPEG (based on the discrete cosine transform) <ref type="bibr" target="#b3">[4]</ref> at low bit-rates and has as important property its lossy-tolossless coding functionality; that is the capability to start from lossy compression at a very high compression ratio and to progressively refine the data by sending detail information, eventually up to the stage where a lossless decompression is obtained.</p><p>Systems based on other technologies than the wavelet transform have been proposed, but they only partially facilitate the requested set of functionalities. Nonetheless, those techniques perform excellent for the subclass of applications they are designed for. Examples are contextbased predictive coding (CALIC) <ref type="bibr" target="#b4">[5]</ref> for lossless image compression, and region-based image coding <ref type="bibr" target="#b6">[6]</ref> for very low bit-rate coding. Although these coders are competitive in their application domain, they lack support for the other functionalities.</p><p>Additionally, the increasing use of three-dimensional imaging modalities, like Magnetic Resonance Imaging (MRI), Computerised Tomography (CT), Ultrasound (US), Single Photon Emission Computed Tomography (SPECT) and Positron Emission Tomography (PET) triggers the need for efficient techniques to transport and store the related volumetric data. In the classical approach, the image volume is considered as a set of slices, which are successively compressed and stored or transmitted. Since contemporary transmission techniques require the use of concepts like rate scalability, quality-and resolution scalability, multiplexing mechanisms need to be introduced to select from each slice the correct layer(s) to support the actually required Quality-of-Service (QoS) level. However, a disadvantage of the slice-byslice mechanism is that potential 3D correlations are neglected.</p><p>In the past, volumetric coding using Discrete Cosine Transform (DCT) based techniques have been proposed (e.g. <ref type="bibr" target="#b7">[7,</ref><ref type="bibr" target="#b8">8]</ref>). However, these systems hardly meet the requirements imposed by the scalability paradigm as reflected earlier.</p><p>Hence, we have evaluated and developed other methods that meet the above-mentioned requirements. Typical examples are octave zero-tree based wavelet coding <ref type="bibr" target="#b9">[9]</ref><ref type="bibr" target="#b10">[10]</ref><ref type="bibr" target="#b12">[11]</ref><ref type="bibr" target="#b13">[12]</ref> and layered zero wavelet coding <ref type="bibr" target="#b14">[13]</ref>. Currently, these coder types deliver the best performance for lossy-to-lossless coding. In this paper, we present new approaches for volumetric wavelet coding. A first new coder uses the cube-splitting (CS) algorithm <ref type="bibr" target="#b15">[14,</ref><ref type="bibr" target="#b16">15]</ref>, which is based on the quadtree coding algorithm presented in <ref type="bibr" target="#b17">[16]</ref>. A second new coder called the 3D Quadtree Limited (3D QT-L) coder combines the basic principles of quadtree coding <ref type="bibr" target="#b17">[16,</ref><ref type="bibr" target="#b18">17]</ref> and block-based coding of the significance maps <ref type="bibr" target="#b19">[18]</ref>. Finally, a third new coder <ref type="bibr" target="#b20">[19]</ref> integrates both Cube-Splitting (CS) and Layered Zero Coding (LZC) principles <ref type="bibr" target="#b14">[13,</ref><ref type="bibr" target="#b21">20,</ref><ref type="bibr" target="#b22">21]</ref>. LZC is the core element of the JPEG2000 image compression standard (i.e. EBCOT: Embedded Block Coding by Optimized Truncation) and was used in the IW44 algorithm of AT&amp;T's DjVu document compression system. The performance of the proposed coding schemes will be compared against an implementation of 3D Set Partitioning in Hierarchical Trees (SPIHT) <ref type="bibr" target="#b10">[10]</ref><ref type="bibr" target="#b12">[11]</ref><ref type="bibr" target="#b13">[12]</ref>, 3D SuBband-based Set Partitioned Embedded bloCK coding (SB-SPECK) <ref type="bibr" target="#b23">[22]</ref> JPEG2000 <ref type="bibr" target="#b2">[3]</ref> and an original 3D JPEG-alike coding approach.</p><p>The paper is structured as follows. Section II revises several 2D wavelet-based embedded image coding algorithms, including two well-known representatives of the family of inter-band coders, namely the Embedded Zerotree Wavelet coding (EZW) and SPIHT algorithms. It also focuses on two algorithms from the family of intra-band coders, namely the square partitioning (SQP) and the EBCOT coders, and describes the new QT-L coder. The proposed 3D DCT coder and the 3D wavelet-based coding algorithms are presented in Section III. The lossless and lossy coding results obtained for five volumetric data sets recorded with different imaging modalities are reported in Section IV. Finally, Section V summarizes the conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. 2D CODING TECHNIQUES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. EZW and SPIHT Coding</head><p>A popular image coding technique supporting progressive data transmission is EZW, introduced by Shapiro in <ref type="bibr" target="#b24">[23]</ref>. This coding scheme uses a simple, yet general model to characterize the inter-band dependencies among wavelet coefficients located in subbands with similar orientations. The model is based on the "zerotree" hypothesis, which assumes that if a wavelet coefficient at a certain scale is insignificant with respect to a given threshold T , i.e. w w T &lt; , then all the coefficients of the same orientation in the same spatial location at finer scales are also insignificant with respect to the threshold T . This hypothesis is well confirmed for piecewise smooth images <ref type="bibr" target="#b24">[23]</ref>, which include medical images obtained with different imaging modalities.</p><p>EZW applies successive approximation quantization (SAQ) to provide a multiprecision representation of the wavelet coefficients and to facilitate the embedded coding. With SAQ, the significance of the wavelet coefficients with respect to a monotonically decreasing series of thresholds is recorded into a set of binary maps, called significance maps. It is proven in <ref type="bibr" target="#b24">[23]</ref> that even for optimally chosen wavelet transform, quantizer and entropy coder, the cost of encoding the significance maps represents an important portion of the total encoding cost. Hence, improving the coding of the significance maps can result in a significant over-all coding gain. The technique used in <ref type="bibr" target="#b24">[23]</ref> to encode the significance maps is zerotree coding, which allows for an efficient coding of insignificant coefficients across the scales. With this technique, the cost of encoding the significance maps is reduced by grouping the insignificant coefficients in trees growing exponentially across the scales, and by coding them with zerotree symbols.</p><p>A more complex and efficient algorithm for coding of the significance maps is the Set Partitioning into Hierarchical Trees (SPIHT) coder proposed by Said and Pearlman in <ref type="bibr" target="#b25">[24]</ref>. This algorithm uses the same underlying model as EZW to characterize the inter-band dependencies among the wavelet coefficients. The basic principles used by the SPIHT algorithm are partial ordering by magnitude of the wavelet coefficients (resulting from SAQ), set partitioning into hierarchical trees (i.e. at every applied threshold the trees are sorted, based on their significance), and ordered bit-plane transmission of the refinement bits (i.e. the magnitude of each significant coefficient is progressively refined). The essential difference of the SPIHT coding process with respect to EZW is the way trees of coefficients are partitioned and sorted <ref type="bibr" target="#b25">[24]</ref>: during the sorting pass SPIHT splits -as its name suggests -the data into hierarchical sets based on the significance of the parent node, the immediate offspring nodes, and the remaining nodes of the tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Inter-band versus Intra-band Coding</head><p>EZW, SPIHT and the algorithms falling in the same category <ref type="bibr" target="#b26">[25,</ref><ref type="bibr" target="#b27">26]</ref> are zerotree-based coders, and their efficiency comes from exploiting inter-band dependencies between the wavelet coefficients. As already mentioned, this is done by grouping the insignificant coefficients in trees spanning exponentially across the scales, and by coding them with "zero" symbols ("zerotree" symbols in the terminology of <ref type="bibr" target="#b24">[23]</ref>). The main disadvantage of this approach is the fact that the zero regions in the significance maps are approximated as a highly constrained set of tree structured regions. As a consequence, certain zero regions that are not aligned with the tree structure, may be expensive to code, and some portions of zero regions may not be included in zerotrees at all <ref type="bibr" target="#b18">[17]</ref>.</p><p>In contrast to EZW, SPIHT and their related algorithms <ref type="bibr" target="#b26">[25,</ref><ref type="bibr" target="#b27">26]</ref>, the coding algorithms presented in the following sections, including the standard JPEG2000-EBCOT coding algorithm <ref type="bibr" target="#b28">[27]</ref>, exploit only the intra-band dependencies. Basically, these techniques employ either a fixed-size, block-based decomposition of the significance maps (e.g. the Lattice Partitioning algorithm <ref type="bibr" target="#b19">[18]</ref> and the JPEG2000-EBCOT algorithm) either a variable-size block-based decomposition, i.e. a quadtree decomposition (e.g. the SQP coder <ref type="bibr" target="#b17">[16]</ref>), either a combination of the two (e.g. the nested quadtree coding (NQS) <ref type="bibr" target="#b29">[28]</ref> and the EBCOT coder <ref type="bibr" target="#b21">[20]</ref>). These algorithms abandon the cross-subband tree-structure grouping of the wavelet coefficients of its predecessors and this prevents them from making use of the inter-band dependencies. However, intra-band redundancies are exploited to a larger extent. The zero regions in the significance maps are represented by a union of independent rectangular zero regions of fixed or variable sizes. This simple model accounts for the fact that the significant coefficients are clustered in certain areas in the wavelet domain, corresponding to the edges and textural regions in the image. Therefore, by using this model, one can isolate interesting non-zero details in the significance maps by immediately eliminating large insignificant regions from further consideration <ref type="bibr" target="#b17">[16,</ref><ref type="bibr" target="#b18">17]</ref>. The coding gain resulting from the use of this model compensates (to say the least) for the losses incurred by not explicitly exploiting the inter-band dependencies. An argument is the theoretical proof given in <ref type="bibr" target="#b19">[18]</ref>, which shows that the number of symbols needed to code the zero regions with a fixed-size block-based method is lower than the number of zerotree symbols, for block sizes confined to some theoretical bounds. And as a second argument, the excellent rate-distortion performance and the competitive lossless compression results <ref type="bibr" target="#b17">[16]</ref><ref type="bibr" target="#b18">[17]</ref><ref type="bibr" target="#b19">[18]</ref><ref type="bibr" target="#b29">28]</ref> of the fixed/variable size block-based coders obtained in both 2D photographic and medical image coding indicate that exploiting intra-band redundancies offers a better coding gain than exploiting interband redundancies.</p><p>There is even one more indication that intra-band models should be favored over the inter-band models in wavelet image coding, as explained in the following. Define X as a random variable representing the value of an arbitrary wavelet coefficient, X N as a predefined neighborhood of X (excluding X ) and X P as the parent of X defined in the sense of Shapiro <ref type="bibr" target="#b24">[23]</ref>. Define by ( ) , I X Y the mutual information <ref type="bibr" target="#b30">[29]</ref> between two random variables , X Y , and by the summarizing function given by: Ψ</p><formula xml:id="formula_0">2 , i i i X X Ψ = ∈ ∑ X N</formula><p>The mutual information is used in <ref type="bibr" target="#b31">[30]</ref> as a mathematical tool to quantify the inter-band and intra-band dependencies between the wavelet coefficients in empirical data. The results reported in <ref type="bibr" target="#b31">[30]</ref> and extensive experimental results obtained on a variety of images with several types of wavelet filters including Daubechies wavelets, symmlets, coiflets, and the biorthogonal family of wavelets reported in <ref type="bibr" target="#b32">[31]</ref>, indicate that the estimated mutual information values satisfy:</p><formula xml:id="formula_1">( ) ( ) ( ˆˆ; ; ; ; ) I X X I X I X X &lt; Ψ &lt; Ψ P P</formula><p>This inequality is constantly satisfied <ref type="bibr" target="#b31">[30,</ref><ref type="bibr" target="#b32">31]</ref> for different non-parametric density estimators including the log-scale histogram method, the adaptive partitioning method <ref type="bibr" target="#b33">[32,</ref><ref type="bibr" target="#b34">33]</ref>, and the wavelet shrinkage method <ref type="bibr" target="#b35">[34,</ref><ref type="bibr" target="#b36">35]</ref>. Moreover, the experiments show that ( ) ˆ; ; I X X Ψ P is always significantly larger than ( ) ˆ; I X X P and slightly larger than I X <ref type="bibr" target="#b31">[30,</ref><ref type="bibr" target="#b32">31]</ref>. This observation indicates that the intra-band models capture most of the dependencies between the wavelet coefficients, and that only minor gains can be obtained with composite models that capture both types of dependencies. It is important to note though that quantization further reduces the mutual information, and this might explain why in comparison with the coding results obtained with the interband models, the coding gains attained with the intra-band models are not as large as this information-theoretic analysis might indicate.</p><formula xml:id="formula_2">( ˆ; Ψ )</formula><p>Nevertheless, triggered by the set of observations mentioned above, we focused our attention on several wavelet coders that exploit the intra-band dependencies between the wavelet coefficients, and we propose three algorithms yielding competitive results in the lossy and lossless compression of 3D medical data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Square Partitioning Coding</head><p>SQuare Partitioning coding (SQP) <ref type="bibr" target="#b17">[16]</ref>, Nested Quadtree Splitting (NQS) <ref type="bibr" target="#b29">[28]</ref>, and Set Partitioned Embedded Block Coding (SPECK) <ref type="bibr" target="#b37">[36]</ref> -all researchers independently developed similar embedded coders, which are based on successive approximation quantization -make use of the quadtree coding of the significance maps and encode each bitplane in the two classical stages: a "significance" or "dominant" pass and a refinement pass. However, these coders do not employ the same quadtree decomposition of the significance maps as the family of zerotree-based coders does, as we will see from the brief description of the SQP coder, given in the following.</p><p>Denote by T the maximum threshold used for successive approximation quantization (SAQ) of the wavelet coefficients, and by T the threshold applied by using SAQ at a certain coding step . Denote by Q a quadrant with top-left coordinates and of size , where v and v are the quadrant's width and height respectively. To simplify the subsequent discussion, we )</p><formula xml:id="formula_3">1 max p p p ≤ ≤ k 2 ( ) , k v ) ( 1 2 , k k = ( 1 2 , v v = v</formula><p>assume that the quadrant dimensions v and v are identical powers of 2, i.e. for some J . The corresponding quadrant delimiting binary elements in the significance map is denoted by Q . Finally, we consider that the wavelet image is a matrix of W H elements, denoted by , with 0 and . The significance of a quadrant Q for a given threshold T is determined by the significance operator :</p><formula xml:id="formula_4">1 p b ) V ( 2 1 2 2 J v v = = W ( , Q = W 0 ( ) p ( , k v ) ) ) × ) ) (0, 0 ( , k v = ( ) ( , W H = V p σ ( ) p ( ) ( ) ( ) 1, 0,          w , l k l k 1, max p : ,<label>:</label></formula><formula xml:id="formula_5">( ) 1 p 2 2 p p ≥ max p x , p Q σ k v ( ) w l p σ ( ) max p σ = W ( ) max , p b Q 0 V if w Q if w Q ∃ ∈ ∀ ∈ = ( ) l w w v v max = &lt; l l l ma p 2 = ( ) max , ,<label>2</label></formula><formula xml:id="formula_6">p i b Q V k ( ) ( ) max p Q σ l 1 max 1 p - max 1 p S - ( ) ( 1 p Q σ + k v ( 1 p Q σ + 1 = ( ) k v 4 i ( ) ( ) p w σ = l 0 ) 1 0 p = ≤ ≤ max , = ) , i k x 1 - 1 p R ma p ( )<label>(1)</label></formula><p>with being the wavelet coefficient at position in the wavelet image W . Note that for v , the significance operator will determine the significance of a single wavelet coefficient .</p><p>During the first partitioning pass S , the significance of the wavelet image W is tested for its highest bit-plane (thus the applied SAQ threshold is T</p><p>). If</p><p>, the significance map of the wavelet image is split into four quadrants</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1</head><p>, each having half the size, with indicating the origin of each quadrant. The descendent "significant" quadrant(s) is (are) then further spliced until the significant leaf nodes (i.e. pixels) are isolated. Thus, the significance pass registers the positions l of all the leaf nodes newly identified as significant, using a recursive tree structure of quadrants (or a quad-tree structure).</p><p>Once the positions and the signs of the significant leaf nodes are encoded during the significance pass, is set to and the subsequent refinement pass is activated for the significant leaf nodes. Next, the significance pass is restarted to update the entire quadtree structure by identifying the new significant leaf nodes. During this stage, only the significance of the previously nonsignificant nodes/quadrants, i.e. those for which , is encoded, while the significant ones, i.e. , are ignored since the decoder has already received this information. Thus, the entire significance coding procedure can actually be seen as a tree growing process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>,</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>=</head><p>The described procedure is repeated, until the complete wavelet image is encoded, i.e.</p><p>, or until the target bitrate is met. Simple adaptive arithmetic encoding has been used in the SQP coder to encode the significance, refinement and sign information, but the achieved gains are marginal in comparison with the results obtained without entropy coding <ref type="bibr" target="#b17">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. QT -Limited</head><p>This section presents a new quadtree-based coding algorithm, which originates from the previously developed SQP coding algorithm described in <ref type="bibr" target="#b17">[16]</ref>. Similar to the SQP coder, the algorithm presented in this section builds quadtrees corresponding to each significance map : the partitioning rule <ref type="bibr" target="#b17">[16]</ref> explained briefly in the previous section is applied recurrently on quadrants selecting sets of binary elements in the significance map and, correspondingly, sets of coefficients of the wavelet transform matrix. Encoding the significance maps (i.e. the positions of the significant coefficients) is equivalent with the encoding of the corresponding quadtrees. The first main difference with respect to the SQP coder is that the partitioning process is limited so that quadtrees are not built up to the pixel level. Once the area of the current node in the quadtree is lower than a predefined minimal quadrant area, the splitting process is stopped and the entropy coding of the coefficients within the quadrant</p><formula xml:id="formula_7">( , k v p b Q ) ( ) , k v Q is activated.</formula><p>Similar to the SQP coder, depth-first scanning is applied for scanning of the quadtrees corresponding to each significance map.</p><p>There is yet another aspect that differentiates this algorithm and the SQP coder. Apart of the two coding steps, i.e. the significance pass and the refinement pass that are used in SQP, a new coding stage called the non-significance pass is introduced. Basically, during the significance pass S corresponding to an arbitrary coding step , the coordinates of the coefficients found as non-significant are appended into a list, called the list of non-significant coefficients (LNC). During the next coding steps k k</p><formula xml:id="formula_8">p max , 0 p p p &lt; ≤ , 0 p ≤ &lt;</formula><p>the significance of the coefficients recorded in the LNC is coded first. This choice is motivated by the following two facts: (1) the coefficients recorded in the list of non-significant coefficients are located in the neighborhood of the coefficients that have been already found as significant at the current or previous coding steps, and (2) there is a high probability for these coefficients to become significant at the next coding steps, due to the clustering property the quadtree coders are based on <ref type="bibr" target="#b17">[16]</ref>.</p><p>After encoding the significance of the coefficients in the LNC, the encoder performs the next two coding passes that are similar with those of the SQP coder, namely the significance and the refinement passes. The detailed description of the coding algorithm including the three main coding passes is given in Fig. <ref type="figure" target="#fig_2">1</ref>. In the figure, the coding operations performed at a coding stage corresponding to the current threshold ( )</p><formula xml:id="formula_9">max p p ≠ T p</formula><p>are illustrated; for only the significance pass is performed. The "SGN" and "NSG" are the acronyms for the significant and nonsignificant symbols respectively, and indicates the bound below which no quadtree decomposition max p p = is performed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>_ ted Area Limi</head><p>The third main difference with respect to the SQP coder is the more elaborated context-conditioning phase and context based entropy coding of the symbols generated in the three coding passes. Since simple memoryless models are usually not efficient enough, context-based arithmetic encoding should be used to improve the coding performance. This technique exploits the dependencies between the symbols to be encoded (the signal) and the neighboring symbols (the context). Context conditioning reduces the entropy and improves the coding performance <ref type="bibr" target="#b30">[29]</ref>.</p><p>Four different sets of models are used to , <ref type="bibr" target="#b0">1</ref> 4</p><formula xml:id="formula_10">i S i ≤ ≤</formula><p>encode the symbols generated by this coding algorithm, and the encoder automatically selects the appropriate set at each coding stage, as shown in Fig. <ref type="figure" target="#fig_2">1</ref>. These sets include: (1) the "Quadrant_Significance" set ( ) used to encode the significance of the nodes in the quadtrees, (2) the "Pixel_Significance" ( ) and "Pixel_Sign" ( ) sets used to code the significance and the signs respectively of the coefficients in the non-significance and significance passes, and (4) the "Pixel_Refinement" set ( ), used to entropy code the refinement information generated in the refinement pass. </p><formula xml:id="formula_11">1 ,     x tot S s tot N N N odels i  ≤  1 S m m N 1   -⋅   Q N</formula><p>The encoder assigns a number N of context models (or states) C , , for each set of models . To each context state C corresponds a different probability model and thus the generated symbols are entropy coded with an adaptive arithmetic coder having the appropriate context model derived in the context-conditioning phase. Our algorithm assigns each coefficient/quadrant to one of the several possible contexts depending on the values of the previously quantized coefficients. The basic idea for the context conditioning adopted in this coder is to quantize into a context number m (corresponding to a given context model ), the number of significant neighborhood coefficients for a given coefficient position. The quantization performed for the sets S is described by the following expression:</p><formula xml:id="formula_12">ls i n 4 i , 1 i 0 i S mode n N ≤ &lt; ≤ , 1 i S ≤ ≤ i m C i n ( ) 2 i g n m m N  = -⋅ ≤  , (<label>2</label></formula><formula xml:id="formula_13">)</formula><formula xml:id="formula_14">4</formula><p>where is the number of the neighboring coefficients declared as significant at the previous coding steps, N is the total number of neighbors, and is the integer part of . The total number of neighbors in ( <ref type="formula" target="#formula_5">2</ref>) is set to 8 in 2D coding.</p><p>sgn</p><formula xml:id="formula_15">N tot  x</formula><p>The same principle is used to derive the contexts used to entropy code the significance of the quadrants, as one notices from the following expression:</p><formula xml:id="formula_16">1 1 , 0 S m models C m N ≤ &lt; ( ) ( ) , 1<label>2</label></formula><formula xml:id="formula_17">sgn odels v v = ⋅ k v ,<label>(3)</label></formula><formula xml:id="formula_18">   </formula><p>where</p><formula xml:id="formula_19">( ) k, Q sgn N</formula><p>v is the number of significant coefficients found at the previous coding steps in an arbitrary quadrant Q .</p><p>( )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>, k v</head><p>This context-conditioning scheme is far simpler than the context selection system adopted by the EBCOT coder in <ref type="bibr" target="#b21">[20]</ref> and detailed in the following section. We compared the coding results obtained with our coder implementing the above entropy coding scheme with the results obtained by using the context models and context assignment scheme of the EBCOT coder. The gains provided by the latter are marginal <ref type="bibr" target="#b32">[31]</ref>. Moreover, given its coding performance, this entropy coding technique is clearly a better option than the simple adaptive fixed-context arithmetic encoding of the symbols generated in the significance pass and adaptive zero-order model of the symbols generated in the refinement pass adopted in the original version of the SQP coder <ref type="bibr" target="#b17">[16]</ref>. In the next sections, this coding algorithm is identified as the QuadTree-Limited (QT-L) coder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Embedded Block Coding by Optimised Truncation (EBCOT)</head><p>The quantization module and entropy coder adopted by the JPEG2000 standard <ref type="bibr" target="#b28">[27]</ref>, which went to International Standard (IS) in December 2000, is based on the EBCOT coder ("Embedded Block Coding by Optimized Truncation") as proposed in a recent paper by David Taubman <ref type="bibr" target="#b21">[20]</ref>. However, its history goes back in 1994 to a paper published by Taubman and Zakhor concerning layered zero-coding for video <ref type="bibr" target="#b22">[21]</ref>.</p><p>The EBCOT coding module consists of two main units. In a first phase, Tier 1 (T1), the wavelet data is partitioned in separate, equally sized blocks, called the code-blocks B and each block is separately encoded, making use of layered zerocoding principles. This results in separate embedded bitstreams for each code-block. Because multiple coding passes are necessary to obtain a layered representation of the codeblock data, each coding pass applied on code-block can be associated with a rate contribution R . Additionally, the distortion introduced in the reconstructed image for truncation point n and code-block B , is denoted as D .</p><formula xml:id="formula_20">i i n i i i i n i</formula><p>After having encoded all code-blocks, a post-processing operation determines where each code-block's embedded stream should be truncated in order to achieve a pre-defined bit-rate, distortion bound or visual quality level. This bitstream rescheduling module is referred to as the Tier 2. It establishes a multi-layered representation of the final bitstream, installing an optimal performance at several bit-rates, resolutions and/or visual quality levels. In the next paragraphs, we will shortly discuss the different modules of the JPEG2000, EBCOT-based coder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Tier 1 -Coding Operations for Embedded Block Coding</head><p>The T1 coder exists out of a fractional bit-plane encoder, which encodes each bit-plane in three passes: the significance propagation pass</p><p>, the magnitude refinement pass , and the normalization pass . The three coding passes are ordered in such a way that most relevant data are encoded first, consequently generating potential truncation points in the bit-stream. The data of each code-block is scanned applying a stripe-wise scanning pattern: the elements are read in groups of four vertically aligned elements. When a complete stripe is processed (4 lines), the subsequent stripe is processed.</p><formula xml:id="formula_21">1 i p P 2 i p P 3 i p P i B</formula><p>Additionally, these coding passes call several coding operations (primitives), i.e. the zero coding (ZC), sign coding (SC), magnitude refinement (MR) and run-length coding (RLC) primitives, which will not be discussed here in detail and for which we refer to <ref type="bibr" target="#b38">[37]</ref>. These primitives enable the selection of suitable context models for the subsequent arithmetic coding and/or run-length coding stages. The chosen adaptive arithmetic encoder is the MQ coder <ref type="bibr" target="#b39">[38]</ref>.</p><p>An element w is encoded with the significance propagation pass , if it has been previously classified as non-significant ( ( )</p><formula xml:id="formula_22">k 1 i p P ( ) (</formula><p>)</p><formula xml:id="formula_23">1 i p + 0 w = k σ</formula><p>), and if it has at least one significant element in its preferred neighborhood Θ , i.e.</p><p>. The preferred neighborhood Θ refers to the eight wavelet coefficients surrounding the element being coded. k w ( )</p><formula xml:id="formula_24">1 1 i p σ + Θ = k k ( ) k</formula><p>The magnitude refinement pass ( P ) encodes refinement information for those elements that have been marked significant in previous bit-planes, . Finally, the normalization pass ( P ) scans for the new significant elements without considering the preferred neighborhood Θ .</p><p>This pass can be understood as a "garbage" collector, because it processes all these elements that have not been visited yet by the significance propagation and magnitude refinement passes.</p><formula xml:id="formula_25">2 i p 1 i p + ( ) ( ) 1 w σ = k 3 i p k</formula><p>For each bit-plane, the significance propagation pass, the magnitude refinement pass and the normalization pass are called, except for the first bit-plane where the first two passes are discarded. The latter is trivial since no significance information has yet been encoded. The philosophy of the coding pass ordering is to improve first the already identified significant areas in the wavelet image by adding extra points with the aid of the significance propagation pass, before introducing new isolated structures (Fig. <ref type="figure" target="#fig_4">2</ref>). Thereafter, previously detected significant coefficients are refined in the magnitude refinement pass. Only then, the process is activated to look for new isolated significant elements with the normalization pass. In principle, defining more coding passes for each bit-plane, causes a higher granularity of the embedded bit-stream, and a better approximation of the optimal rate-distortion curve.</p><p>2) Tier 2 -Layer Formation At the end of the Tier 1 coding pass a separate bit-stream has been generated for each code-block B , without utilizing information from the other blocks. As already mentioned, these local embedded bit-streams have the desirable property that they can be truncated in several potential truncation points . The Tier 2 (T2) component of EBCOT optimizes the truncation process, and tries to reach the desired bit-rate while minimizing the introduced distortion, utilizing Lagrangian rate allocation (LRA) principles. The followed procedure is known as Post-Compression Rate-Distortion (PCRD) optimization <ref type="bibr" target="#b21">[20]</ref> and the basic principle is extensively discussed in Everett's paper <ref type="bibr" target="#b40">[39]</ref>.</p><formula xml:id="formula_26">i i n</formula><p>While the PCRD optimization delivers a maximized support for one quality layer, successive application of PCRD will result in the support for several quality layers. Each quality layer corresponds to the rates ,</p><formula xml:id="formula_27">q i n i R [ ] 0, q Q ∈</formula><p>. Furthermore, the code-block contributions to one quality layer are divided according to the resolution level l they are contributing to.</p><p>The algorithm also provides support for multiple components (e.g. color). The different bit-stream chunks are grouped in separate packets , each packet contributing to one quality layer , one resolution level l and one image component c . This type of data organization is very practical: it allows easy rescheduling of the data. The end-user can specify easily the scalability set-up that is required by the application: for example resolution scalability (illustrated in Fig. <ref type="figure" target="#fig_5">3</ref>) or SNR scalability.</p><p>, l c q K q Each packet contains a header and a body. The header contains information about code-blocks, whose compressed stream is included in the body of the packet. The header describes which code-blocks contribute to the subband and quality level covered by the packet. In addition, the maximum bit-depth , the number of new coding passes (or truncations points), and the number of encoded bytes are transmitted for each code-block. The code-block inclusion information is encoded using the tag-tree concept <ref type="bibr" target="#b21">[20]</ref>. The basic idea is to build a tree whose leaf nodes correspond to the code-blocks. The quantities to be encoded and associated with every leaf node, describe the quality layer in which the code-block is first included. The tag tree is constructed from the leaves up to the root by grouping leave nodes in blocks of 2x2 quantities. The information associated with every intermediate node is the minimal mutual quantity of all descendent nodes. The process is repeated until the root node is reached. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. 3D DCT Coding</head><p>The first coder introduced in the 3D test bed is a JPEGalike, 3D DCT-based coder. This coder was designed in order to have a good reference for DCT-based systems. The 3D JPEG-based coder is composed of a discrete cosine transform, followed by a scalar quantizer and finally a combination of run-length coding and adaptive arithmetic encoding. The basic principle is simple: the volume is divided in cubes of 8x8x8 pixels (</p><p>) and each cube is separately 3D DCTtransformed, similar to a classical JPEG-coder (see Fig. <ref type="figure" target="#fig_6">4</ref>.a-b):</p><formula xml:id="formula_28">8 N = ( ) ( ) ( ) ( ) 1 2 3 1 1 1 3 1 0 0 0 2 1 cos 2 N N N i i i x x x DCT x i f C u u N π - - - = = = = =  +    ∑ ∑ ∑ ∏ u x    <label>(4)</label></formula><p>with ( )</p><formula xml:id="formula_29">1 0 2 0 i i i u u N    =  =  &gt;     N C u    </formula><p>Thereafter, the DCT-coefficients are quantized using a quantization matrix. In order to derive this matrix, one has to consider two options. One option is to construct quantization tables that produce an optimized visual quality based on psycho-visual experiments. It is worthwhile mentioning that JPEG uses such quantization tables, but this approach would require elaborate experiments to come-up with reasonable quantization tables for volumetric data. The simplest solution, adopted in this work, is to create a uniform quantization matrix -as reported in <ref type="bibr" target="#b15">[14,</ref><ref type="bibr" target="#b16">15,</ref><ref type="bibr" target="#b41">40]</ref>. This option is motivated by the fact that uniform quantization is optimum or quasioptimum for most of the distributions <ref type="bibr" target="#b42">[41]</ref>. Actually, the uniform quantizer is optimum for Laplacian and exponential input distributions; otherwise the differences with respect to an optimal quantizer are marginal <ref type="bibr" target="#b42">[41]</ref>. A second possibility involving quantizers that are optimal in rate-distortion sense is discussed elsewhere <ref type="bibr" target="#b43">[42]</ref>.</p><p>The quantized DCT-coefficients are scanned using a 3D space-filling curve, i.e. a 3D instantiation of the Morton-curve <ref type="bibr" target="#b44">[43]</ref>, to allow for the grouping of zero-valued coefficients and hence to improve the performance of the run-length coding (Fig. <ref type="figure" target="#fig_6">4</ref>.c). This curve was opted for, due to its simplicity compared to that of 3D zigzag curves <ref type="bibr" target="#b45">[44]</ref>. The non-zero coefficients are encoded using the same classification system as for JPEG. The coefficient values are grouped in 16 main magnitude classes (ranges), which are subsequently encoded with an arithmetic encoder <ref type="bibr" target="#b46">[45]</ref>. Finally, the remaining bits to refine the coefficients within one range are added without further entropy coding.</p><p>The adopted entropy coding system shown in Fig. <ref type="figure" target="#fig_7">5</ref> is partially based on the JPEG architecture <ref type="bibr" target="#b3">[4]</ref>, although the Huffman coder is replaced by an adaptive arithmetic encoder <ref type="bibr" target="#b46">[45]</ref>. Consequently, the large look-up tables mentioned in annex K of the standard <ref type="bibr" target="#b3">[4]</ref> are superfluous and moreover, adaptive arithmetic encoding tends to have a higher coding efficiency.</p><p>The DC coefficients are encoded with a predictive scheme:  apart from the first DC coefficient, the entropy coding system encodes the difference between the current DC coefficient and the previous one. For this difference, the range is determined and encoded with an arithmetic encoder that has a DC model supporting 16 ranges. Simply transmitting the remaining bits of the coefficient refines the range specification without any further entropy coding. The latter is possible since the probability distribution of all possible values can be seen as uniform, hence entropy coding will not be able to further reduce the bit consumption.</p><p>The AC coefficients are encoded by specifying first the amount of zeros preceding the encoded symbol, i.e. the run. The runs of zeros are encoded using an arithmetic encoder with a separate model. Runs of up to 15 zeros are supported. Note that to indicate the situations in which 16 or more zeros precede a significant AC coefficient, an extra symbol "OVF" (overflow) is used. After encoding this symbol, the remaining zeros are immediately encoded to avoid confusing situations involving a succession of several OVF encodings. Finally, the range of the encountered significant symbol is encoded, using an arithmetic encoder with a similar (AC) model as in the case of the DC coefficients, followed by the necessary refinement bits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. The 3D Wavelet Transform</head><p>Before describing in the following sections the proposed 3D wavelet-based techniques, it is important to notice that these techniques support lossless coding, all the required scalability modes as well as ROI coding, and this is a significant difference with respect to the 3D DCT-technique presented above, which is not able to provide these features.</p><p>For all the 3D wavelet-based coders included in this study, a common wavelet transform module was designed that supports lossless integer lifting filtering, as well as finiteprecision floating-point filtering. A heterogeneous selection of filter types and a different amount of decomposition levels for each spatial direction (x-, y-or z-direction) are supported by this module. This allows for adapting the size of the wavelet pyramid (Fig. <ref type="figure" target="#fig_8">6</ref>.a) in each spatial direction in case the spatial resolution is limited. For example, fewer levels will be required along the slice axis if the amount of slices or the resolution along the axis is limited.</p><p>The supported lossless integer lifting filters include the (S+P), (4,2), (5,3), and (9,7) integer wavelet transforms. This selection is based on recent publications <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b47">46]</ref>, as well as investigations performed in the context of the JPEG2000 compression standard.</p><p>A typical problem encountered with 3D lossless integer wavelet transforms is the complexity needed to make them unitary, which is not the case for floating-point transforms. This property is necessary in order to achieve a good lossy coding performance. By calculating the L norm of the lowand high-pass filters, the normalization factors can be determined. In 2D this is not a problem, since the typical scaling factors to obtain a unitary transform are approximately powers of two <ref type="bibr" target="#b48">[47]</ref>. However, in 3D the problem pops up again, and it only disappears if one takes care that the sum of all decompositions influencing each individual wavelet coefficient (i.e. decompositions in both slice directions and in the axial direction) is an even number. Hence, some proposals have been formulated <ref type="bibr" target="#b10">[10,</ref><ref type="bibr" target="#b13">12]</ref> that make use of a wavelet packet transform <ref type="bibr" target="#b49">[48]</ref> to achieve this goal (Fig. <ref type="figure" target="#fig_8">6</ref>.b), while assuming that the -based normalization factors for the supported kernels scale-up with</p><formula xml:id="formula_30">2 2 L</formula><p>2 for the low-pass and 1 2 for the high-pass kernels. In practice this seems to be an acceptable approximation. Nevertheless, in the presented study, whenever possible, unitary transforms will be used (and it will be explicitly mentioned if not).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. 3D Set Partitioning in Hierarchical Trees</head><p>In the test set of wavelet coders, a 3D SPIHT encoder <ref type="bibr" target="#b12">[11]</ref> was included as a reference. An early version of this coder <ref type="bibr" target="#b13">[12]</ref> has already proven to beat the performance of a contextbased octave zero-tree coder <ref type="bibr" target="#b9">[9]</ref>. The source code was made available by the authors so it could be equipped with the proposed wavelet transform front-end.</p><p>The SPIHT implementation in this study uses balanced 3D spatial orientation trees. Therefore, the same number of recursive wavelet decompositions is required for all spatial orientations. If this is not respected, several tree nodes do not refer to or be linked with the same spatial location, and consequently the dependencies between different tree-nodes are destroyed and hence the compression performance is reduced. Thus, a packet-based transform is not usable to obtain a unitary transform with this embedded coding system. Therefore, the SPIHT coder was equipped with a non-unitary transform. It is however worthwhile mentioning that solutions have been proposed utilizing unbalanced spatio-temporal orientation trees in the context of video coding <ref type="bibr" target="#b50">[49]</ref>.  The examined 3D SPIHT algorithm <ref type="bibr" target="#b12">[11]</ref> follows the same procedure as its 2D homologous algorithm, with the exception that the states of the tree nodes -each embracing eight wavelet coefficients -are encoded with a context-based arithmetic coding system during the significance pass. The selected context models are based on the significance of the individual node members, as well as on the state of their descendents. Consequently, for each node coefficient four state combinations are possible. In total 164 different context models are used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Cube Splitting</head><p>The cube-splitting technique is derived from the 2D square partitioning coder (SQP) proposed in section II.C. In the context of volumetric encoding, the SQP technique was extended to a third dimension: from square splitting towards cube splitting. Cube-splitting is applied on the wavelet image in order to isolate smaller entities, i.e. sub-cubes, possibly containing significant wavelet coefficients. Fig. <ref type="figure">7</ref> illustrates the cube-splitting process.</p><p>During the first significance pass S , the significance of the wavelet image (volume) is tested for its highest bitplane with the significance operator . If</p><p>, the wavelet image is spliced in eight sub-cubes (or octants)</p><formula xml:id="formula_31">max p W W max p ( ) = W p σ max 1 p σ max 2 b v (k k k = k , p q    k 1 q q q        2 3</formula><p>, , q q Q , , with topleft coordinates and of size</p><formula xml:id="formula_32">1 q ≤ ≤ ) 8 1 2 v v  3 , , 2 2 2 2 q q q q v     =      v max p σ  ( ) ( )= k max p</formula><p>. The descendent "significant" cube (or cubes) is (are) then further spliced until the significant wavelet coefficients are isolated. Thus, the significance pass registers sub-cubes and wavelet coefficients, newly identified as significant, using a recursive tree structure of octants (cfr. Fig. <ref type="figure">7</ref>.a-c). The result is an octtree-structured description of the data significance against a given threshold (Fig. <ref type="figure">7</ref>.d). As might be noticed, equal importance weights are given to all the branches. When a significant coefficient is isolated, also its sign -for which two code symbols are preserved -is immediately encoded. </p><formula xml:id="formula_33">q p q j Q σ +       =          v k ,</formula><p>are checked for significance, and the significant ones, i.e.</p><formula xml:id="formula_34">0 j J &lt; ≤ 1 ,<label>2</label></formula><formula xml:id="formula_35">q p q j Q +       =          v k 0 p = 1 σ</formula><p>are ignored since the decoder already received this information. The described procedure is repeated, until the complete wavelet image is encoded, i.e.</p><p>or until the desired bit-rate is obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>W</head><p>To encode the generated symbols efficiently, a contextbased arithmetic encoder was integrated. The context model is simple. For the significance pass four context models are distinguished, namely one for the symbols generated at the intermediate cube nodes, one for the pixel nodes having nonsignificant neighbors for the previous threshold, one for the pixel nodes having at least one significant neighbor for the previous threshold and finally one for encoding the sign of the isolated significant pixel nodes. Only two contexts are used Fig. <ref type="figure">7</ref> When a significant wavelet coefficient is encountered, the cube (a) is spliced in eight sub-cubes (b), and further on (c) up to the pixel level. The result is an octtree structure (d) (SGN = significant node; NS = non-significant node). In the next significance pass, the non-significant nodes that contain significant wavelet coefficients are further refined.</p><p>for the refinement pass: one for the pixel nodes having nonsignificant neighbors for the previous threshold, one for the pixel nodes having at least one significant neighbor for the previous threshold.</p><p>Other 2D techniques, like NQS <ref type="bibr" target="#b29">[28]</ref> and Subband Block (SB) SPECK <ref type="bibr" target="#b23">[22]</ref>, have been proposed that use similar quadtree decomposition techniques. These coders divide the wavelet space in blocks and activate for each block separately a quadtree coding mechanism. In case of SB-SPECK, the block sizes are also depending on the subband sizes, forcing each block to reside in one subband. Each block is separately encoded, and thereafter an EBCOT-alike rescheduling takes place to restore the scalability functionality. SB-SPECK was also partially extended to 3D -i.e. 3D SB-SPECK coding <ref type="bibr" target="#b23">[22]</ref> -by equipping the coder with a 3D wavelet transform front-end. The transform is activated on discrete chunks of slices (GOFs: Groups of Frames), to maintain the accessibility of the data (typical GOF sizes are 8, 16 or 32 planes). The option is not implemented in the coders we designed. SB-SPECK does not use arithmetic encoding. However, the 3D SB-SPECK coder delivers competitive results, and we will refer to it whenever possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. 3D QT-L</head><p>The QT-L coder proposed in Section II.D has also been extended towards 3D coding. The octtrees corresponding to each bit-plane are constructed following a similar strategy as for the cube-splitting coder. However, the partitioning process is limited in such a way that once the volume of a node</p><formula xml:id="formula_36">3 1 2 q i n j i v V = = ∏ th ,</formula><p>becomes smaller than a predefined threshold V , the splitting process is stopped, and the entropy coding of the coefficients within such a significant leaf node</p><formula xml:id="formula_37">0 j J &lt; ≤ , 2 q p q j Q σ       =          v k i B</formula><p>1 is activated. Similar to the 2D version, the octtrees are scanned using depth-first scanning. In addition, for any given node, the eight descendant nodes are scanned using a 3D instantiation of the Morton-curve <ref type="bibr" target="#b44">[43]</ref>. For each bit-plane, the coding process consists of the nonsignificance, significance and refinement passes of Fig. <ref type="figure" target="#fig_2">1</ref> adapted for 3D coding; also, for the highest bit-plane, the coding process consists of the significance pass only. The context-conditioning scheme and the context-based entropy coding are similar with their 2D counterparts described in section II.D. Notice that the total number of neighbors in (2) is set to 26 in 3D coding.</p><p>tot N</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. 3D CS-EBCOT</head><p>The CS-EBCOT coding <ref type="bibr" target="#b20">[19]</ref> combines the principles utilized in the cube-splitting coder with a 3D instantiation of the EBCOT coder <ref type="bibr" target="#b21">[20]</ref>. In the next paragraphs the interfacing of the cube-splitting coder with a version of EBCOT adapted to 3D is discussed.</p><p>To start with, the wavelet coefficients are partitioned EBCOT-wise in separate, equally sized cubes, called codeblocks . Typically, the initial size of the code-blocks is 64x64x64 elements. Other sizes (even different ones for each dimension) can be selected, depending on the image characteristics and the application requirements. The coding module -CS-EBCOT -again consists of two main units, the Tier 1 and Tier 2 parts. The Tier 1 of the proposed 3D coding architecture is a hybrid module combining two coding techniques: cubesplitting and fractional bit-plane coding using context-based arithmetic encoding. The Tier 2 part is identical to the one used in the 2D coding system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Cube Splitting</head><p>The cube-splitting pass S is derived from the cube-splitting technique presented in section III.D. In the proposed coding system, the cube-splitting is applied on the individual codeblocks in order to isolate smaller entities, i.e. sub-cubes, possibly containing significant wavelet coefficients. The smallest sub-cube size that is supported is 4x4x4. We will refer to these smallest sub-cubes as the leaf nodes.</p><p>During the first cube-splitting (CS) pass S , the significance of code-block is tested for its highest bitplane with the significance operator σ . If , the code-block is spliced until the significant leaf nodes</p><formula xml:id="formula_38">max i p p i B max i p ( ) i B = max 1 i p σ i B max , 2 i p b   v q G    q    k Q are isolated, where G</formula><p>specifies the maximum amount of cube splitting levels. When all significant leaf nodes are isolated, the fractional bit-plane coding part is activated for the current bit-plane and only for the significant leaf-nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head> </head><p>When the complete bit-plane is encoded utilizing the fractional bit-plane coding, is set to and the subsequent CS pass, S is activated. The described procedure is repeated, until the complete block is encoded, i.e.</p><p>. Due to the limited amount of code-symbols and their distribution, arithmetic coding is not applied.</p><formula xml:id="formula_39">i p 1 - max 1 i p - max i p 0 i p =</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Fractional Bit-plane Coding</head><p>The fractional bit-plane coder encodes only those leaf nodes that have been identified as significant during the Cube-Splitting pass. Three passes are defined per bit-plane like in the 2D case: the significance propagation pass</p><p>, the magnitude refinement pass , and the normalization pass (Fig. <ref type="figure">8</ref>). Additionally, these coding passes call several coding operations (primitives), i.e. the zero coding (ZC), sign coding (SC), magnitude refinement (MR) and run-length coding (RLC) primitives. These primitives enable the selection of suitable 3D context models for the subsequent arithmetic coding or run-length coding stages. The chosen adaptive arithmetic encoder is based on an implementation by Said &amp; Pearlman of the algorithm proposed by I.H. Witten et al. <ref type="bibr" target="#b46">[45]</ref>, which is identical to those utilized in the previously mentioned encoders. The data residing in each leaf-node is scanned applying a slice-by-slice scanning pattern. Within one slice the pattern is identical to the JPEG2000 scanning: the voxels are read in groups of four vertically aligned voxels. When a complete slice is stripe-wise processed, the subsequent slice is processed (Fig. <ref type="figure" target="#fig_12">9</ref>).</p><p>The fractional coding passes behave in an identical way as for the original EBCOT implementation. However, the preferred neighborhood refers now to the twenty-six voxels around the voxel being coded (i.e. the immediate neighbors). For each bit-plane, successively the significance propagation pass, the magnitude refinement pass, the cubesplitting pass and the normalization pass are called, except for the first bit-plane where the first two passes are discarded.</p><formula xml:id="formula_40">Θ k k</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Coding Primitives</head><p>As for EBCOT, four coding primitives are defined to support the encoding process in the different coding passes: the zero coding (ZC) primitive, the run-length coding (RLC) Fig. <ref type="figure">8</ref>. Representation of one bit-plane. For each bit-plane, successively the significance pass, the magnitude refinement pass, the cube-splitting pass and the normalisation pass are called, except in the case of the first bit-plane, where the first two passes are discarded.</p><p>primitive, the sign coding primitive (SC) and the magnitude refinement (MR) primitive. For arithmetic encoding, the context-model selection is based on the state of the neighboring voxels of the voxel being encoded, i.e. the preferred neighborhood Θ , and the subband type in which the voxel is located. The preferred neighborhood is divided in 7 orthogonal subsets according to their position to the voxel <ref type="bibr" target="#b20">[19,</ref><ref type="bibr" target="#b43">42]</ref>. Each coding primitive has got its own look-up table to identify the probability model that has to be utilized by the arithmetic coder for a given context situation <ref type="bibr" target="#b20">[19,</ref><ref type="bibr" target="#b43">42]</ref>. Additionally, we have to remark that the complexity of this part of the coding engine increases heavily compared to the original 2D implementations, due to the enlarged preferred neighborhood (from 8 to 26 neighbors) and consequently the augmented intricacy of the look-up tables <ref type="bibr" target="#b20">[19]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Tier 2 -Layer Formation</head><p>The followed procedure, i.e. Post-Compression Rate-Distortion (PCRD) optimization <ref type="bibr" target="#b21">[20]</ref>, is identical to the original one. However, we have to mention one aspect that is of key importance. The PCRD routine allows compensating for the fact that a non-unitary transform has been used. By correcting the calculated distortions for each pass n with a scaling factor , the coding system will perform as if a unitary transform was used (or approximated when using integer powers of</p><formula xml:id="formula_41">i i b ς 2 )</formula><p>. Hence, the distortion will be now described by: ,</p><formula xml:id="formula_42">[ ] [ ] ( 2 ˆî i i i n n i i i b B D s s ζ ∈ = - ∑ k k k )<label>(5)</label></formula><p>where [ ] Nevertheless, the different bit-stream chunks are now grouped into separate packets, each packet contributing to one quality layer and one resolution level. The code-block inclusion information is again encoded using the tag-tree concept. The only change that has been made was extending the tag-tree concept to the third dimension, i.e. moving from a quadtree structure to an octtree structure.</p><formula xml:id="formula_43">k [ ] ˆi n i k i IV. EXPERIMENTAL ASSESSMENT</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Lossless Coding</head><p>The lossy and lossless compression performances of the proposed coders were evaluated on a set of volumetric data obtained with different imaging modalities, including: positron-emission tomography -PET (128x128x39x15bits), computerised tomography -CT1 (512x512x100x12bits), CT2 (512x512x44x12bits), ultrasound -US (256x256x256x8bpp), and MRI data -MRI (256x256x200x12bpp).</p><p>Lossless coding results are reported for most of the techniques discussed up to now: CS, 3D QT-L, 3D SPIHT, 3D SB-SPECK (only for the CT2 and MRI data based on results reported in <ref type="bibr" target="#b23">[22]</ref>), CS-EBCOT and JPEG2000. Obviously, we did not include the 3D DCT coder in the lossless compression test due to the lossy character of its DCT front-end. Additionally, the coding results obtained with the JPEG2000 coder equipped with a 3D wavelet transform (JPEG2K-3D) are reported. The latter is one of the functionalities provided by the latest Verification Model software (from V7.0 on), which was added to support multi-spectral image coding. For all the tests performed in lossless coding (as well as for lossy coding later), typically a 5-level wavelet transform (with a lossless 5x3 lifting kernel) was applied in all spatial dimensions, except for the low-resolution PET image (4 levels). The same number of decompositions in all dimensions was used to allow a fair comparison with the 3D SPIHT algorithm. As mentioned earlier, a non-balanced decomposition would lead to the destruction of the dependencies within the spatial orientation trees of the 3D SPIHT coder, due to the balanced character of the latter. It is evident that the other coders are not limited by such drawbacks, but to ensure a fair comparison, we applied the same restriction for them too. Fig. <ref type="figure" target="#fig_14">10</ref> shows the increase in terms of percentage of the bitrate achieved in lossless compression, with the reference technique taken as the algorithm yielding the best coding results for each test volume.</p><p>We notice that for the US and PET volumes, the 3D QT-L coder delivers the best coding performance, while for the other three volumetric data, the CS-EBCOT performs better. If one refers to the average increase in percentage taking the CS-EBCOT coder as the reference, then one can notice that the 3D QT-L yields similar performance, since the average difference between the two is only 0.1%. The CS coder follows it, with a difference of 1.45%. The 3D SPIHT and the JPEG2K-3D coders provide similar results, with an average difference of 3.56% and 3.65% respectively. Finally, the average difference increases up to 7.07% and 12.78% for the 3D SB-SPECK and JPEG2K coders.</p><p>One notices also from Fig. <ref type="figure" target="#fig_14">10</ref> that the relative performance of the several techniques is heavily dependant on the data set involved. For example, 3D SPIHT delivers excellent results for the US, CT1 and MRI sets, while for the other ones the performance is relatively poor. JPEG2000 yields the worst coding results for all, except for the CT2 image, which has a low axial resolution. One notices that activating the 3D wavelet transform facility of JPEG2000 boosts the lossless coding performance of the JPEG2000 coder (except again for CT2). The results of the 3D SB-SPECK have been reported in <ref type="bibr" target="#b23">[22]</ref> only for the CT2 and MRI data sets, and the results are situated in between JPEG2K and JPEG2K-3D for the MRI volume.</p><p>In summary, these results lead to the following important observations for lossless coding: -CS-EBCOT and 3D QT-L deliver the best lossless coding results on all images; -The 3D wavelet transform as such significantly boosts the coding performance; -As spatial resolution and consequently inter-slice dependency diminishes, the benefit of using a 3D decorrelating transform and implicitly a 3D coding system decreases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Lossy coding</head><p>Lossy coding experiments were carried out on the five volumetric data sets for the aforementioned coders, and in addition, the 3D DCT-based coding engine is included. The peak signal-to-noise ratio (PSNR) is measured at seven different bit-rates: 2, 1, 0.5, 0.25, 0.125, 0.0625 and 0.03125 bits-per-pixel (bpp). Due to space limitations this paper does not contain all the obtained results, hence we refer to <ref type="bibr" target="#b51">[50]</ref> for a complete report.</p><p>Similar to the lossless coding experiments, the performance of the wavelet coders is evaluated using a wavelet transform with a lossless 5x3 filter kernel. To simulate a unitary transform, the CS-EBCOT, JPEG2000, JPEG2K-3D and SB-SPECK intrinsically compensate the non-unitariness by applying an additional scaling factor in the rate-distortion optimization process -see equation <ref type="bibr" target="#b4">(5)</ref>. Unfortunately, this approach is not possible for the 3D SPIHT and CS algorithms. Hence, the reported results for these coders are sub-optimal, since they are overemphasizing the high frequency components during encoding. To overcome this problem, a sub-optimal solution used to approximate (roughly) a unitary transform was adopted for the 3D QT-L coder. Integer scaling factors of the form 2 , have been used to approximate the theoretical scaling factors of the form</p><formula xml:id="formula_44">k k + ∈ Z ( ) { 2 2 , , 0,1 m p p p ∈ ≥ - Z } 1, 1, m - ∈</formula><p>that yield a unitary (but not integer anymore) 3D wavelet transform. These integer scaling factors have been used in the same manner as suggested by Said and Pearlman in <ref type="bibr" target="#b48">[47]</ref>. Fig. <ref type="figure" target="#fig_15">11</ref> illustrates the peak signal-to-noise ratios (PSNR's) in decibels calculated for the US, PET, CT1, CT2 and MRI data sets as a function of bit-rate. This set of experiments delivers surprising results. If we exclude the results for the CT2 and PET data set in a first evaluation, we observe that despite its sub-optimal approximation of unitariness, the 3D QT-L coder outperforms all the other wavelet coders in the whole range of bit-rates. For example, the 3D QT-L coder  yields on the US data set at 1.00 bpp a PSNR of 38.75dB, which is 0.5 dB better than the JPEG2K-3D, and with 1.43 dB better than CS-EBCOT. At higher rates (2bpp) the differences between them increases up to 0.88 dB and 1.45 dB for the JPEG2K-3D and CS-EBCOT coders respectively. The 3D QT-L and the JPEG2K-3D algorithms perform equally well at low rates (0.125bpp) on the US data set, and outperform the CS-EBCOT coder with 0.37 dB and 0.25 dB respectively. A similar ranking according to their performance can be done by taking into account the result obtained on the MRI data set (Fig. <ref type="figure" target="#fig_15">11</ref>). At 0.125bpp the results are in order 52.01 dB, 51.61 dB and 51.17 dB for the 3D QT-L, JPEG2K-3D, and CS-EBCOT respectively. Note that at lower rates CS-EBCOT gives slightly better results (0.03125bpp -46.52 dB) than JPEG2K-3D (0.03125bpp -46.22 dB) but still less than those provided by 3D QT-L with 46.75 dB at the same rate. Similarly, the 3D QT-L outperforms on the CT1 data set the next rated wavelet coder JPEG2K-3D, but the differences between them are smaller: from 0.27 dB at 1bpp, to 0.57 dB at 0.03125bpp.</p><p>The results obtained on the PET volumetric data indicate that at rates below 0.25 bpp the 3D QT-L coder outperforms all the other coders; for example at 0.0625 bpp, 3D QT-L yields a PSNR of 40.59 dB in comparison to 39.74 dB and 39.42 dB provided by the JPEG2K-3D and CS-EBCOT respectively. However, at higher rates the JPEG2K-3D outperforms the 3D QT-L coder on this data, with a difference of 0.52 dB and 0.33 dB at 1bpp and 2 bpp respectively.</p><p>Note also from Fig. <ref type="figure" target="#fig_15">11</ref> the unexpectedly good compression results provided by the 3D DCT coder. At high rates (e.g. 2bpp) the PSNR figures provided by this coder are higher than those obtained with the 3D QT-L coder on the US, CT1, and MRI data sets; however, this situation changes on the PET data, for which both JPEG2K-3D and 3D QT-L coders are better. Note also that at low bit-rates the performance of 3D DCT tends to decrease fast, as it is also observed for its 2D counterparts.</p><p>If one refers to the standard JPEG2000, one notices that this coder typically delivers poor coding results on the PET, US volumes and MRI data; on CT1 it yields good results at rates higher than 0.25bpp, but the results are modest at lower rates. However for CT2, JPEG2000 is the best coder at high bitrates, and is only beaten by JPEG2K-3D and SB-SPECK at low-bit-rates. At that moment JPEG2000 equals the performance of CS-EBCOT. Once again this illustrates the effect of the inter-slice correlation (and consequently resolution). To further demonstrate this, a small experiment was carried out. Four subsampled instantiations (along the slice axis) of the MRI data set were created (decimation factors 2, 4, 8 and 16). Thereafter, on each of these data sets the coding performance of JPEG2000 (with &amp; without 3D wavelet transform) and CS-EBCOT was evaluated. Fig. <ref type="figure" target="#fig_10">12</ref> illustrates the results for the original volume and the one subsampled with a factor of 16 along the slice axis. As expected, the coding performance of the two volumetric coding engines dropped down significantly, while the one of JPEG2000 was less affected. For high and intermediate bitrates, JPEG2000 even performs better for the highly subsampled MRI data set.</p><p>To handle appropriately a limited axial resolution, we can adapt the wavelet kernels consistently as suggested indirectly in <ref type="bibr" target="#b52">[51]</ref>. In case of a reduced axial resolution (corresponding to more singularities in the slice axis direction), the support size of the wavelet function must be reduced to avoid large wavelet coefficients. In the opposite case -i.e. an increased axial resolution -wavelet filters with longer support sizes should be used in the slice axis direction.</p><p>If one refers to the other two algorithms, namely the CS and the 3D SPIHT, one notices that on the US, CT1, and MRI data sets they are constantly performing worse than the 3D QT-L, JPEG2K-3D and CS-EBCOT algorithms at all rates. These poor results are caused by the fact that these coders were equipped with a non-unitary wavelet transform. In order to assess the importance of this aspect, we performed a second experiment in which a lossy 9x7 lifting-based wavelet transform ( L -normalized) has been used for the CS, CS-EBCOT, 3D SPIHT and JPEG2000. JPEG2000 with a 3D transform was excluded from the test, since VM8.0 was not devised with lossy 9x7 support in the slice axis direction. The PSNR versus bit-rate results obtained for the CT1, CT2, and MRI data sets reported in <ref type="bibr" target="#b51">[50]</ref> show that for CT1 and MRI the 3D SPIHT implementation was superior to the other techniques, closely followed by CS (for CT1) and then by CS-EBCOT. Only at high bit-rates the 3D DCT can compete with these techniques. The performance of JPEG2000 was poorer, especially for MRI, having a high inter-slice correlation. For CT2, JPEG2000 delivered the best coding performance, as it was the case for the lossless 5x3 lifting kernel. Remark however, that the techniques evaluated with the lossy 9x7 lifting-based wavelet transform do not beat JPEG2000 at low bit-rates.   Fig. <ref type="figure" target="#fig_10">14</ref> shows the visual results of the encoding process for the CT2 data set. The CT2 images illustrate that PSNR is not a sufficient criterion to evaluate image quality. At 0.03125 bpp JPEG2000 provides a high PSNR, while the perceived image quality is much poorer than that of the other wavelet-based methods (relatively large ringing artefacts). Additionally, it can be observed that 3D SPIHT performs worse than CS and CS-EBCOT. With CS-EBCOT the inter-ventricular septum can still be observed at 0.03125 bpp (Fig. <ref type="figure" target="#fig_10">14</ref>.e), while also the other anatomical structures are well maintained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. DISCUSSION AND CONCLUSIONS</head><p>This paper gives an overview of several state-of-the-art 3D wavelet coders and proposes three new coding algorithms including the CS coder, the 3D QT-L coder and the CS-EBCOT coder. Their coding performance was compared with several state-of-the-art coding techniques, including JPEG2000, JPEG2K-3D, 3D SPIHT and 3D SB-SPECK. Based on a test bench of 5 volumetric data sets it was shown that CS-EBCOT and 3D QT-L deliver in all cases the best lossless coding performance. JPEG2000 typically delivers the worst results of all.</p><p>In lossy coding, 3D QT-L tends to deliver the best overall lossy coding performance for a lossless 5x3-lifting kernel. At low rates CS-EBCOT competes with JPEG2K-3D. With a lossy 9x7-lifting kernel, 3D SPIHT typically yields the best performance followed closely by CS and CS-EBCOT.</p><p>Visual quality assessments demonstrate that the 3D techniques deliver comparable visual rates over the complete bit-range, with the remark that CS and CS-EBCOT preserve better low-frequency spatial structures.</p><p>Overall, one may conclude that the proposed coders demonstrate excellent lossless compression performance, while in lossy compression they provided competitive lossy coding results when compared to the hybrid techniques (3D SB-SPECK and JPEG2K-3D). Moreover, it becomes apparent that the 3D techniques are sensitive to a reduced spatial resolution along the slice axis. A reduction of this resolution works to the advantage of the classical 2D techniques (JPEG2000).</p><p>Since it falls out of the scope of this paper, we did not evaluate the implementation complexity and the computational load of the 3D compression schemes. However, we can observe that the computational complexity of the 3D techniques is significantly higher than that of their 2D counterparts when applied on the same data. Typical bottlenecks are the required memory bandwidths and memory sizes. A major problem is the coincident access of axially related data, causing huge jumps in the memory and consequently cache failure, with as a result long execution times. Fortunately, data transfer and storage optimised versions of their 2D counterparts have been proposed in the past (e.g. <ref type="bibr" target="#b43">[42,</ref><ref type="bibr" target="#b53">[52]</ref><ref type="bibr" target="#b54">[53]</ref><ref type="bibr" target="#b55">[54]</ref><ref type="bibr" target="#b56">[55]</ref>) of which the issued principles can be transferred to 3D. For example, the realization a 3D instantiation of the local wavelet transform <ref type="bibr" target="#b57">[56]</ref> will significantly improve the memory access and consumption behavior of the presented algorithms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>p</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Pseudo-code describing the three coding passes performed by the QT-L coder.</figDesc><graphic coords="5,93.84,51.18,437.94,570.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. Illustration of the activity of the coding operation for the specified bit-plane. Notice that the forward significance pass is active in regions where previously significant pixels were detected.</figDesc><graphic coords="7,120.96,540.78,379.68,155.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Illustration of a packet ordering supporting a resolution progressive bit-stream ( ) , l c q K</figDesc><graphic coords="8,61.38,185.70,222.96,120.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. In the 3D DCT coder the volume is decomposed in blocks of 8-by-8-by-8 pixels (a-b), and each block is independently transformed using a 3D DCT (b). Thereafter for each DCT block the transformed coefficients are scanned according to the Morton curve, quantized and run-length/arithmetically encoded.</figDesc><graphic coords="8,102.12,564.96,411.07,138.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Run-length/arithmetic encoding system of the 3D DCT-based coder.</figDesc><graphic coords="9,130.62,54.66,354.49,170.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. (a) A two-level 3D wavelet transform using a Mallat decomposition scheme. (b) A two-level wavelet packet transform that produces a unitary decomposition with dyadic scaling factors. Each subband in the Mallat configuration has been subject to an extra transform along the slice axis. For example, d was decomposed into d and d .</figDesc><graphic coords="10,84.06,377.94,177.60,170.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>S 1 -</head><label>1</label><figDesc>When the complete bit-plane is encoded with the significance pass S , is set to p and the refinement pass R is initiated for this bit-plane, refining all coefficients marked as significant in the octtree.Thereafter, the significance pass is restarted to update the octtree by identifying the new significant wavelet coefficients for the current bit-plane. During this stage, only the previously non</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. The slice-by-slice scanning pattern shown for an 8x8x8 leaf node.</figDesc><graphic coords="13,96.54,254.64,152.64,147.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>representation of that element associated with truncation point n . This correction enables support for a unitary transform without obstructing the possibility of lossless coding, a problem that does occur with classical zerotree-based coders. The original 2D algorithms support multiple components (e.g. color), but this feature is not retained in the proposed 3D implementation. Hence, only gray-scale images (volumes) are supported.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. The increase of the lossless bit-rate in terms of percentage, with the reference technique taken as the algorithm yielding the best coding results for each test volume. All techniques use a lossless 5x3-lifting kernel in the wavelet transform.</figDesc><graphic coords="14,153.42,450.78,314.61,262.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. US, PET, CT1, CT2 and MRI compressed with JPEG2000, JPEG2K-3D, 3D DCT, CS-EBCOT, CS, 3D QT-L and 3D SPIHT. All wavelet-based methods use a 5-level transform (except PET: 4-levels) with a lossless 5x3 lifting kernel. Except for CS and 3D SPIHT the transforms were unitary, or approximately unitary (3DQT-L).</figDesc><graphic coords="15,183.24,379.86,255.12,159.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>2 Fig. 12 .</head><label>212</label><figDesc>Fig.12. MRI (set 1/1) and a subsampled (1/16) version of MRI compressed with JPEG2000, JPEG2K-3D and CS-EBCOT, using a 5-level transform with a lossless 5x3 lifting kernel.</figDesc><graphic coords="16,88.20,474.78,433.02,255.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. MRI compressed at (1) 0.125 bpp and (2) 0.03125 bpp using (a) JPEG2000, (b) JPEG2K-3D, (c) 3D DCT and (d) CS-EBCOT. All wavelet-based methods use a 5-level transform with a lossless 5x3 lifting kernel. Slice 45 is depicted.</figDesc><graphic coords="17,54.18,54.78,507.20,284.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 13</head><label>13</label><figDesc>Fig.13illustrates the visual performance of JPEG2000, JPEG2K-3D, CS-EBCOT and 3D DCT for one slice taken from the MRI data set. At 0.125 bpp the quality of the images compressed with JPEG2000 clearly deviates from the other techniques, due to the blurring. For the 3D DCT-based technique, blocking artifacts distort the visual quality (although less disturbing) and slight smoothing effects occur for JPEG2K-3D and CS-EBCOT. At very low bit-rates (e.g. 0.03215 bpp), it is practically impossible to distinguish a visual quality difference between CS-EBCOT and JPEG2K-3D. Both methods have a superior quality compared to the other techniques.Fig.14shows the visual results of the encoding process for the CT2 data set. The CT2 images illustrate that PSNR is not a sufficient criterion to evaluate image quality. At 0.03125 bpp JPEG2000 provides a high PSNR, while the perceived image quality is much poorer than that of the other wavelet-based methods (relatively large ringing artefacts). Additionally, it can be observed that 3D SPIHT performs worse than CS and CS-EBCOT. With CS-EBCOT the inter-ventricular septum can still be observed at 0.03125 bpp (Fig.14.e), while also the other anatomical structures are well maintained.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="11,135.00,60.84,345.77,223.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="18,54.00,318.78,519.49,374.28" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>The authors would like to thank William A. Pearlman and Frederick W. Wheeler of Rensselaer Polytechnic Institute for their support in relation to the 3D SPIHT and 3D SB-SPECK coders.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Manuscript received September 29, 2001. This work was supported in part by the Flemish Institute for the Promotion of Innovation by Science and Technology (IWT-980302), the Ministry of the Flemish Community "Science, Innovation and Media Department" (BIL99/61), the Federal Office for Scientific, Technical and Cultural Affairs (IAP Phase V -Mobile Multimedia) and the EC Socrates Student Exchange program. Schelkens has a post-doctoral fellowship with the Fund for Scientific Research -Flanders (FWO), Egmontstraat 5, B-1000 Brussels, Belgium.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Peter Schelkens (M'99) was born in Willebroek, Belgium in 1969. He received his Electronic Engineering degree in VLSI-design from the Industriële Hogeschool Antwerpen-Mechelen (IHAM), Campus Mechelen in 1991. Thereafter, he obtained the Electrical Engineering degree (M.Sc.) in applied physics in 1994, the Biomedical Engineering degree (medical physics) in 1995, and the Ph.D. degree in Applied Sciences in 2001 from the Vrije Universiteit Brussel (VUB). Since October 1994, he is a member of the Department of Electronics and Information Processing (ETRO) at VUB. Since October 2002, he holds a postdoctoral fellowship with the Fund for Scientific Research -Flanders (FWO), Belgium. Peter Schelkens is also affiliated as visiting researcher to the DESICS department of the Interuniversity Microelectronics Institute (IMEC) in Leuven, Belgium. Since 2000, he is coordinating a research team in the field of image and video compression, and related multimedia technologies. This team is participating to the ISO/IEC JTC1/SC29/WG1 (JPEG2000) and WG11 (MPEG-4) standardization activities. Peter Schelkens is the Belgian head of delegation for the ISO/IEC JPEG standardization committee, and coeditor of part 10 of JPEG2000: "Extensions for Three-Dimensional and Floating Point Data". Dr. Peter Schelkens is the author/co-author of more than 60 scientific publications and patent applications. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adrian Munteanu was born in</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">DICOM requirements for JPEG2000</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hamid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISO/IEC JTC1/SC</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note>Report N</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Progressive image transmission: a review and comparison of techniques</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Tzou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optical Engineering</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="581" to="589" />
			<date type="published" when="1987-07">July 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">JPEG2000 Verification model 8.5</title>
		<author>
			<persName><forename type="first">C</forename><surname>Christopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISO/IEC JTC1/SC</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2000-09">Sep. 2000</date>
		</imprint>
	</monogr>
	<note type="report_type">Report N1878</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">JPEG still image data compression standard</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Pennebaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mitchell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Van Nostrand Reinhold</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">High-order context modeling and embedded conditional entropy coding of wavelet coefficients for image compression</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Asilomar Conference on Signals, Systems &amp; Computers</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1378" to="13827" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Second-generation image coding techniques</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ikonomopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kocher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1985-04">Apr. 1985</date>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="549" to="574" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Compression of hyperspectral imagery using the 3-D DCT and hybrid DPCM/DCT</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Abousleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Marcellin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Hunt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="26" to="34" />
			<date type="published" when="1995-01">Jan. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">New compression techniques for storage and transmission of 2D and 3D medical images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vlaicu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lungu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Crisan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Persa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE Advanced Image and Video Communications and Storage Technologies</title>
		<meeting>SPIE Advanced Image and Video Communications and Storage Technologies</meeting>
		<imprint>
			<date type="published" when="1995-02">Feb. 1995</date>
			<biblScope unit="volume">2451</biblScope>
			<biblScope unit="page" from="370" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Three-dimensional compression with integer wavelet transform</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bilgin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zweig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Marcelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Optics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1799" to="1814" />
			<date type="published" when="2000-04">Apr. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Lossless volumetric medical image compression</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Pearlman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE Conference on Applications of Digital</title>
		<meeting>SPIE Conference on Applications of Digital</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">bpp using (a) 3D DCT, (b) JPEG2000, (c) CS, (d) 3D SPIHT, and (e) CS-EBCOT. All wavelet-based methods use a 5-level transform with a lossy 9x7 lifting kernel supporting a unitary transform. Slice 13 is depicted</title>
		<idno>14. CT2 compressed at 0.03125</idno>
	</analytic>
	<monogr>
		<title level="j">Image Processing</title>
		<imprint>
			<biblScope unit="volume">XXII</biblScope>
			<biblScope unit="page" from="305" to="312" />
			<date type="published" when="1999-07">July 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Stripe-based SPIHT lossy Compression of volumetric medical images for low memory usage and uniform reconstruction quality</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Pearlman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2000-06">June 2000</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="2031" to="2034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Progressive coding of medical volumetric data using three-dimensional integer wavelet packet transform</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Y</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Pearlman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE Conference on Visual Communications</title>
		<meeting>SPIE Conference on Visual Communications</meeting>
		<imprint>
			<date type="published" when="1999-01">Jan. 1999</date>
			<biblScope unit="volume">3653</biblScope>
			<biblScope unit="page" from="327" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Model-based coding of multi-dimensional data with applications to medical imaging</title>
		<author>
			<persName><forename type="first">G</forename><surname>Menegaz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<pubPlace>Lausanne</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Biomedical Imaging Group, Swiss Federal Institute of Technology (EPFL</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD Thesis</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Volumetric data compression based on cube-splitting</title>
		<author>
			<persName><forename type="first">P</forename><surname>Schelkens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Barbarien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cornelis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 21st Symposium on Information Technology in the Benelux</title>
		<meeting>21st Symposium on Information Technology in the Benelux</meeting>
		<imprint>
			<date type="published" when="2000-05">May 2000</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="93" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Compression of volumetric medical data based on cube-splitting</title>
		<author>
			<persName><forename type="first">P</forename><surname>Schelkens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Barbarien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cornelis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE Conference on Applications of Digital Image Processing</title>
		<meeting>SPIE Conference on Applications of Digital Image essing</meeting>
		<imprint>
			<date type="published" when="2000-08">July-Aug. 2000</date>
			<biblScope unit="volume">XXIII</biblScope>
			<biblScope unit="page" from="91" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Waveletbased lossless compression scheme with progressive transmission capability</title>
		<author>
			<persName><forename type="first">A</forename><surname>Munteanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cornelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Van Der Auwera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cristea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Imaging Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="76" to="85" />
			<date type="published" when="1999-01">Jan. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Wavelet image compression -the quadtree coding approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Munteanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cornelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Van Der Auwera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cristea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Technol. Biomed</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="176" to="185" />
			<date type="published" when="1999-09">Sep. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Wavelet-based lossless compression of coronary angiographic images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Munteanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cornelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cristea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="272" to="281" />
			<date type="published" when="1999-03">Mar. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">3D Compression of medical data based on cube-splitting and embedded block coding</title>
		<author>
			<persName><forename type="first">P</forename><surname>Schelkens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Giro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Barbarien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cornelis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ProRISC/IEEE Workshop</title>
		<meeting>ProRISC/IEEE Workshop</meeting>
		<imprint>
			<date type="published" when="2000-12">Dec. 2000</date>
			<biblScope unit="page" from="495" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">High performance scalable image compression with EBCOT</title>
		<author>
			<persName><forename type="first">D</forename><surname>Taubman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1158" to="1170" />
			<date type="published" when="2000-07">July 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multirate 3-D subband coding of video</title>
		<author>
			<persName><forename type="first">D</forename><surname>Taubman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zakhor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="572" to="588" />
			<date type="published" when="1994-09">Sep. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Trellis source coding and memory constrained image coding</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">W</forename><surname>Wheeler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Renselaer Polytechnical Institute</publisher>
			<pubPlace>Troy, New York, PhD</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Electrical, Computer and Systems Engineering</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Embedded image coding using zerotrees of wavelet coefficients</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Shapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="3445" to="3462" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A new fast and efficient image codec based on set partitioning in hierarchical trees</title>
		<author>
			<persName><forename type="first">A</forename><surname>Said</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pearlman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="243" to="250" />
			<date type="published" when="1996-06">June 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Image compression using the 2-D wavelet transform</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Knowles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="244" to="250" />
			<date type="published" when="1992-04">Apr. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">CREW: compression with reversible embedded wavelets</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boliek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Data Compression Conference (DCC)</title>
		<meeting>Data Compression Conference (DCC)</meeting>
		<imprint>
			<date type="published" when="1995-03">Mar. 1995</date>
			<biblScope unit="page" from="212" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">ISO/IEC JTC1/SC29/WG1 IS 15444-1</title>
		<imprint>
			<date type="published" when="2000-12">Dec. 2000</date>
		</imprint>
	</monogr>
	<note>JPEG 2000 Image Coding System</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">System and method for nested split coding of sparse data sets</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Chui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998-05">May 1998</date>
			<publisher>Teralogic Inc</publisher>
			<pubPlace>Menlo Park, California</pubPlace>
		</imprint>
	</monogr>
	<note>Patent US:005748116A</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Elements of information theory</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Wiley Series in Telecommunications</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York, NT, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Analysis of interscale and intrascale dependencies between image wavelet coefficients</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Moulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICIP</title>
		<meeting>ICIP</meeting>
		<imprint>
			<date type="published" when="2000-09">Sep. 2000</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="669" to="671" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Quantifying dependencies in the wavelet domain and new developments in 2D/3D intraband wavelet image coding</title>
		<author>
			<persName><forename type="first">M</forename><surname>Galca</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<pubPlace>Brussel</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department ETRO, Vrije Universiteit Brussel</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">MSc Thesis</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An estimator of the mutual information based on a criterion for independence</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Darbellay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Statistics and Data Analysis</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Estimation of the information by an adaptive partitioning of the observation space</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Darbellay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Vajda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="1315" to="1321" />
			<date type="published" when="1999-05">May 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Minimax estimation via wavelet shrinkage</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Johnstone</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
		<respStmt>
			<orgName>Dept. Stat., Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">De-noising via soft thresholding</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Johnstone</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
		<respStmt>
			<orgName>Dept. Stat., Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">An embedded and efficient lowcomplexity hierarchical image coder</title>
		<author>
			<persName><forename type="first">A</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Pearlman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE Visual Communications and Image Processing</title>
		<meeting>SPIE Visual Communications and Image essing</meeting>
		<imprint>
			<date type="published" when="1999-01">Jan. 1999</date>
			<biblScope unit="volume">3653</biblScope>
			<biblScope unit="page" from="284" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">JPEG2000 -Image compression: fundamentals, standards and practice</title>
		<author>
			<persName><forename type="first">D</forename><surname>Taubman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Marcellin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Hingham, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">JPEG2000 Part I final draft international standard</title>
		<author>
			<persName><forename type="first">M</forename><surname>Boliek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Christopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Majani</surname></persName>
		</author>
		<idno>ISO/IEC JTC1/SC29/WG1</idno>
		<imprint>
			<date type="published" when="2000-09">Sep. 2000</date>
		</imprint>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Generalized Lagrange multiplier method for solving problems of optimum allocation of resources</title>
		<author>
			<persName><forename type="first">H</forename><surname>Everett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="399" to="417" />
			<date type="published" when="1963">1963</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Compression of medical volumetric data</title>
		<author>
			<persName><forename type="first">P</forename><surname>Schelkens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Giro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Barbarien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Munteanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cornelis</surname></persName>
		</author>
		<ptr target="ISO/IECJTC1/SC29/WG1,N1712" />
		<imprint>
			<date type="published" when="2000-07">July 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Optimal quantizers and permutation codes</title>
		<author>
			<persName><forename type="first">T</forename><surname>Breger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="759" to="765" />
			<date type="published" when="1972-11">Nov. 1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Multidimensional wavelet coding -algorithms and implementations</title>
		<author>
			<persName><forename type="first">P</forename><surname>Schelkens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Department of Electronics and Information Processing</title>
		<meeting><address><addrLine>Brussel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>Vrije Universiteit Brussel</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD Thesis</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A computer oriented geodetic data base and a new technique in file sequencing</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Morton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Ltd</title>
		<imprint>
			<date type="published" when="1966">1966</date>
			<pubPlace>Ottawa, Canada</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Quantization of 3D-DCT coefficients and scan order for video compression</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K W</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Adjeroh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visual Communications and Image Representation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="405" to="422" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Arithmetic coding for data compression</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Cleary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="520" to="540" />
			<date type="published" when="1987-06">June 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Reversible integer-to-integer wavelet transforms for image compression: performance evaluation and analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Faouzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1010" to="1024" />
			<date type="published" when="2000-06">June 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">An image multiresolution representation for lossless and lossy compression</title>
		<author>
			<persName><forename type="first">A</forename><surname>Said</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pearlman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1303" to="1310" />
			<date type="published" when="1996-09">Sep. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Wavelet packet image coding using space-frequency quantization</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramchandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Orchard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="892" to="898" />
			<date type="published" when="1998-06">June 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Low-delay embedded 3-D wavelet color video coding with SPIHT</title>
		<author>
			<persName><forename type="first">B.-J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Pearlman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">3309</biblScope>
			<biblScope unit="page" from="955" to="964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">An overview of volumetric coding technologies</title>
		<author>
			<persName><forename type="first">P</forename><surname>Schelkens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Munteanu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002-07">July 2002</date>
		</imprint>
	</monogr>
	<note>ISO/IEC JTC1/SC29/WG1, WG1N2613</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">A wavelet tour of signal processing</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Mallat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Academic Press</publisher>
			<pubPlace>San Diego</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Implementation of wavelet transform image compression algorithms using associative computing based DSP chips</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sariel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Pearlman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE Conference on Wavelet Applications VI</title>
		<meeting>SPIE Conference on Wavelet Applications VI</meeting>
		<imprint>
			<date type="published" when="1999-04">Apr. 1999</date>
			<biblScope unit="volume">3723</biblScope>
			<biblScope unit="page" from="224" to="238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A zerotree wavelet video coder</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Martucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sodagar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="109" to="118" />
			<date type="published" when="1997-02">Feb. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A scalable architecture for MPEG-4 wavelet quantization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Vanhoof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Peón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lafruit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bormans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nachtergaele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Bolsens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of VLSI Signal Processing Systems for Signal, Image, and Video Technology</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="93" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Efficient implementation of embedded zero-tree wavelet encoding</title>
		<author>
			<persName><forename type="first">P</forename><surname>Schelkens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Decroos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lafruit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Catthoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cornelis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Electronics, Circuits and Systems (ICECS)</title>
		<meeting>IEEE International Conference on Electronics, Circuits and Systems (ICECS)</meeting>
		<imprint>
			<date type="published" when="1999-09">Sep.1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1155" to="1158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Optimal memory organization for scalable texture codecs in MPEG-4</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lafruit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nachtergaele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bormans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Engels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Bolsens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="218" to="243" />
			<date type="published" when="1999-03">Mar. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
