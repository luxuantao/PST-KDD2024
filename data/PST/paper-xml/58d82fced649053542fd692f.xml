<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2017-08-05">5 Aug 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Eric</forename><surname>Jang</surname></persName>
							<email>ejang@google.com</email>
						</author>
						<author>
							<persName><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ben</forename><surname>Poole</surname></persName>
							<email>poole@cs.stanford.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Cambridge MPI Tübingen</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2017-08-05">5 Aug 2017</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1611.01144v5[stat.ML]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Categorical variables are a natural choice for representing discrete structure in the world. However, stochastic neural networks rarely use categorical latent variables due to the inability to backpropagate through samples. In this work, we present an efficient gradient estimator that replaces the non-differentiable sample from a categorical distribution with a differentiable sample from a novel Gumbel-Softmax distribution. This distribution has the essential property that it can be smoothly annealed into a categorical distribution. We show that our Gumbel-Softmax estimator outperforms state-of-the-art gradient estimators on structured output prediction and unsupervised generative modeling tasks with categorical latent variables, and enables large speedups on semi-supervised classification.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Stochastic neural networks with discrete random variables are a powerful technique for representing distributions encountered in unsupervised learning, language modeling, attention mechanisms, and reinforcement learning domains. For example, discrete variables have been used to learn probabilistic latent representations that correspond to distinct semantic classes <ref type="bibr" target="#b10">(Kingma et al., 2014)</ref>, image regions <ref type="bibr" target="#b27">(Xu et al., 2015)</ref>, and memory locations <ref type="bibr" target="#b5">(Graves et al., 2014;</ref><ref type="bibr" target="#b4">Graves et al., 2016)</ref>. Discrete representations are often more interpretable <ref type="bibr" target="#b1">(Chen et al., 2016)</ref> and more computationally efficient <ref type="bibr" target="#b18">(Rae et al., 2016)</ref> than their continuous analogues.</p><p>However, stochastic networks with discrete variables are difficult to train because the backpropagation algorithm -while permitting efficient computation of parameter gradients -cannot be applied to non-differentiable layers. Prior work on stochastic gradient estimation has traditionally focused on either score function estimators augmented with Monte Carlo variance reduction techniques <ref type="bibr" target="#b16">(Paisley et al., 2012;</ref><ref type="bibr" target="#b14">Mnih &amp; Gregor, 2014;</ref><ref type="bibr" target="#b7">Gu et al., 2016;</ref><ref type="bibr" target="#b6">Gregor et al., 2013)</ref>, or biased path derivative estimators for Bernoulli variables <ref type="bibr" target="#b0">(Bengio et al., 2013)</ref>. However, no existing gradient estimator has been formulated specifically for categorical variables. The contributions of this work are threefold:</p><p>1. We introduce Gumbel-Softmax, a continuous distribution on the simplex that can approximate categorical samples, and whose parameter gradients can be easily computed via the reparameterization trick.</p><p>2. We show experimentally that Gumbel-Softmax outperforms all single-sample gradient estimators on both Bernoulli variables and categorical variables.</p><p>3. We show that this estimator can be used to efficiently train semi-supervised models (e.g. <ref type="bibr" target="#b10">Kingma et al. (2014)</ref>) without costly marginalization over unobserved categorical latent variables.</p><p>The practical outcome of this paper is a simple, differentiable approximate sampling mechanism for categorical variables that can be integrated into neural networks and trained using standard backpropagation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">THE GUMBEL-SOFTMAX DISTRIBUTION</head><p>We begin by defining the Gumbel-Softmax distribution, a continuous distribution over the simplex that can approximate samples from a categorical distribution. Let z be a categorical variable with class probabilities π 1 , π 2 , ...π k . For the remainder of this paper we assume categorical samples are encoded as k-dimensional one-hot vectors lying on the corners of the (k − 1)-dimensional simplex, ∆ k−<ref type="foot" target="#foot_0">1</ref> . This allows us to define quantities such as the element-wise mean E p [z] = [π 1 , ..., π k ] of these vectors.</p><p>The Gumbel-Max trick <ref type="bibr" target="#b8">(Gumbel, 1954;</ref><ref type="bibr" target="#b12">Maddison et al., 2014)</ref> provides a simple and efficient way to draw samples z from a categorical distribution with class probabilities π:</p><formula xml:id="formula_0">z = one_hot arg max i [g i + log π i ]<label>(1)</label></formula><p>where g 1 ...g k are i.i.d samples drawn from Gumbel(0, 1) 1 . We use the softmax function as a continuous, differentiable approximation to arg max, and generate k-dimensional sample vectors y ∈ ∆ k−1 where</p><formula xml:id="formula_1">y i = exp((log(π i ) + g i )/τ ) k j=1 exp((log(π j ) + g j )/τ ) for i = 1, ..., k.<label>(2)</label></formula><p>The density of the Gumbel-Softmax distribution (derived in Appendix B) is:</p><formula xml:id="formula_2">p π,τ (y 1 , ..., y k ) = Γ(k)τ k−1 k i=1 π i /y τ i −k k i=1 π i /y τ +1 i<label>(3)</label></formula><p>This distribution was independently discovered by <ref type="bibr" target="#b13">Maddison et al. (2016)</ref>, where it is referred to as the concrete distribution. As the softmax temperature τ approaches 0, samples from the Gumbel-Softmax distribution become one-hot and the Gumbel-Softmax distribution becomes identical to the categorical distribution p(z). the expected value of a Gumbel-Softmax random variable approaches the expected value of a categorical random variable with the same logits. As the temperature increases (τ = 1.0, τ = 10.0), the expected value converges to a uniform distribution over the categories. (b) Samples from Gumbel-Softmax distributions are identical to samples from a categorical distribution as τ → 0. At higher temperatures, Gumbel-Softmax samples are no longer one-hot, and become uniform as τ → ∞.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">GUMBEL-SOFTMAX ESTIMATOR</head><p>The Gumbel-Softmax distribution is smooth for τ &gt; 0, and therefore has a well-defined gradient ∂y /∂π with respect to the parameters π. Thus, by replacing categorical samples with Gumbel-Softmax samples we can use backpropagation to compute gradients (see Section 3.1). We denote this procedure of replacing non-differentiable categorical samples with a differentiable approximation during training as the Gumbel-Softmax estimator.</p><p>While Gumbel-Softmax samples are differentiable, they are not identical to samples from the corresponding categorical distribution for non-zero temperature. For learning, there is a tradeoff between small temperatures, where samples are close to one-hot but the variance of the gradients is large, and large temperatures, where samples are smooth but the variance of the gradients is small (Figure <ref type="figure" target="#fig_0">1</ref>). In practice, we start at a high temperature and anneal to a small but non-zero temperature.</p><p>In our experiments, we find that the softmax temperature τ can be annealed according to a variety of schedules and still perform well. If τ is a learned parameter (rather than annealed via a fixed schedule), this scheme can be interpreted as entropy regularization <ref type="bibr" target="#b25">(Szegedy et al., 2015;</ref><ref type="bibr" target="#b17">Pereyra et al., 2016)</ref>, where the Gumbel-Softmax distribution can adaptively adjust the "confidence" of proposed samples during the training process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">STRAIGHT-THROUGH GUMBEL-SOFTMAX ESTIMATOR</head><p>Continuous relaxations of one-hot vectors are suitable for problems such as learning hidden representations and sequence modeling. For scenarios in which we are constrained to sampling discrete values (e.g. from a discrete action space for reinforcement learning, or quantized compression), we discretize y using arg max but use our continuous approximation in the backward pass by approximating ∇ θ z ≈ ∇ θ y. We call this the Straight-Through (ST) Gumbel Estimator, as it is reminiscent of the biased path derivative estimator described in <ref type="bibr" target="#b0">Bengio et al. (2013)</ref>. ST Gumbel-Softmax allows samples to be sparse even when the temperature τ is high.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RELATED WORK</head><p>In this section we review existing stochastic gradient estimation techniques for discrete variables (illustrated in Figure <ref type="figure" target="#fig_1">2</ref>). Consider a stochastic computation graph <ref type="bibr" target="#b24">(Schulman et al., 2015)</ref> with discrete random variable z whose distribution depends on parameter θ, and cost function f (z).</p><p>The objective is to minimize the expected cost</p><formula xml:id="formula_3">L(θ) = E z∼p θ (z) [f (z)] via gradient descent, which requires us to estimate ∇ θ E z∼p θ (z) [f (z)].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">PATH DERIVATIVE GRADIENT ESTIMATORS</head><p>For distributions that are reparameterizable, we can compute the sample z as a deterministic function g of the parameters θ and an independent random variable , so that z = g(θ, ). The path-wise gradients from f to θ can then be computed without encountering any stochastic nodes:</p><formula xml:id="formula_4">∂ ∂θ E z∼p θ [f (z))] = ∂ ∂θ E [f (g(θ, ))] = E ∼p ∂f ∂g ∂g ∂θ<label>(4)</label></formula><p>For example, the normal distribution z ∼ N (µ, σ) can be re-written as µ + σ • N (0, 1), making it trivial to compute ∂z /∂µ and ∂z /∂σ. This reparameterization trick is commonly applied to training variational autooencoders with continuous latent variables using backpropagation <ref type="bibr" target="#b9">(Kingma &amp; Welling, 2013;</ref><ref type="bibr" target="#b21">Rezende et al., 2014b)</ref>. As shown in Figure <ref type="figure" target="#fig_1">2</ref>, we exploit such a trick in the construction of the Gumbel-Softmax estimator.</p><p>Biased path derivative estimators can be utilized even when z is not reparameterizable. In general, we can approximate ∇ θ z ≈ ∇ θ m(θ), where m is a differentiable proxy for the stochastic sample.</p><p>For Bernoulli variables with mean parameter θ, the Straight-Through (ST) estimator <ref type="bibr" target="#b0">(Bengio et al., 2013)</ref> approximates m = µ θ (z), implying ∇ θ m = 1. For k = 2 (Bernoulli), ST Gumbel-Softmax is similar to the slope-annealed Straight-Through estimator proposed by <ref type="bibr" target="#b2">Chung et al. (2016)</ref>, but uses a softmax instead of a hard sigmoid to determine the slope. Rolfe ( <ref type="formula">2016</ref>) considers an alternative approach where each binary latent variable parameterizes a continuous mixture model. Reparameterization gradients are obtained by backpropagating through the continuous variables and marginalizing out the binary variables.</p><p>One limitation of the ST estimator is that backpropagating with respect to the sample-independent mean may cause discrepancies between the forward and backward pass, leading to higher variance. Gumbel-Softmax avoids this problem because each sample y is a differentiable proxy of the corresponding discrete sample z.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">SCORE FUNCTION-BASED GRADIENT ESTIMATORS</head><p>The score function estimator (SF, also referred to as REINFORCE <ref type="bibr" target="#b26">(Williams, 1992)</ref> and likelihood ratio estimator <ref type="bibr" target="#b3">(Glynn, 1990</ref>)) uses the identity ∇ θ p θ (z) = p θ (z)∇ θ log p θ (z) to derive the following unbiased estimator:</p><formula xml:id="formula_5">∇ θ E z [f (z)] = E z [f (z)∇ θ log p θ (z)]<label>(5)</label></formula><p>SF only requires that p θ (z) is continuous in θ, and does not require backpropagating through f or the sample z. However, SF suffers from high variance and is consequently slow to converge. In particular, the variance of SF scales linearly with the number of dimensions of the sample vector <ref type="bibr" target="#b20">(Rezende et al., 2014a)</ref>, making it especially challenging to use for categorical distributions.</p><p>The variance of a score function estimator can be reduced by subtracting a control variate b(z) from the learning signal f , and adding back its analytical expectation</p><formula xml:id="formula_6">µ b = E z [b(z)∇ θ log p θ (z)]</formula><p>to keep the estimator unbiased:</p><formula xml:id="formula_7">∇ θ E z [f (z)] = E z [f (z)∇ θ log p θ (z) + (b(z)∇ θ log p θ (z) − b(z)∇ θ log p θ (z))] (6) = E z [(f (z) − b(z))∇ θ log p θ (z)] + µ b (7)</formula><p>We briefly summarize recent stochastic gradient estimators that utilize control variates. We direct the reader to <ref type="bibr" target="#b7">Gu et al. (2016)</ref> for further detail on these techniques.</p><p>• NVIL <ref type="bibr" target="#b14">(Mnih &amp; Gregor, 2014)</ref> uses two baselines: (1) a moving average f of f to center the learning signal, and (2) an input-dependent baseline computed by a 1-layer neural network fitted to f − f (a control variate for the centered learning signal itself). Finally, variance normalization divides the learning signal by max(1, σ f ), where σ 2 f is a moving average of Var[f ].</p><p>• DARN <ref type="bibr" target="#b6">(Gregor et al., 2013)</ref> </p><formula xml:id="formula_8">uses b = f (z) + f (z)(z − z)</formula><p>, where the baseline corresponds to the first-order Taylor approximation of f (z) from f (z). z is chosen to be 1 /2 for Bernoulli variables, which makes the estimator biased for non-quadratic f , since it ignores the correction term µ b in the estimator expression. • MuProp <ref type="bibr" target="#b7">(Gu et al., 2016</ref>) also models the baseline as a first-order Taylor expansion:</p><formula xml:id="formula_9">b = f (z) + f (z)(z − z) and µ b = f (z)∇ θ E z [z].</formula><p>To overcome backpropagation through discrete sampling, a mean-field approximation f M F (µ θ (z)) is used in place of f (z) to compute the baseline and derive the relevant gradients. • VIMCO <ref type="bibr" target="#b15">(Mnih &amp; Rezende, 2016</ref>) is a gradient estimator for multi-sample objectives that uses the mean of other samples b = 1 /m j =i f (z j ) to construct a baseline for each sample z i ∈ z 1:m . We exclude VIMCO from our experiments because we are comparing estimators for single-sample objectives, although Gumbel-Softmax can be easily extended to multisample objectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">SEMI-SUPERVISED GENERATIVE MODELS</head><p>Semi-supervised learning considers the problem of learning from both labeled data (x, y) ∼ D L and unlabeled data x ∼ D U , where x are observations (i.e. images) and y are corresponding labels (e.g. semantic class). For semi-supervised classification, <ref type="bibr" target="#b10">Kingma et al. (2014)</ref> propose a variational autoencoder (VAE) whose latent state is the joint distribution over a Gaussian "style" variable z and a categorical "semantic class" variable y (Figure <ref type="figure" target="#fig_7">6</ref>, Appendix). The VAE objective trains a discriminative network q φ (y|x), inference network q φ (z|x, y), and generative network p θ (x|y, z) end-to-end by maximizing a variational lower bound on the log-likelihood of the observation under the generative model. For labeled data, the class y is observed, so inference is only done on z ∼ q(z|x, y). The variational lower bound on labeled data is given by:</p><formula xml:id="formula_10">log p θ (x, y) ≥ −L(x, y) = E z∼q φ (z|x,y) [log p θ (x|y, z)] − KL[q(z|x, y)||p θ (y)p(z)]<label>(8)</label></formula><p>For unlabeled data, difficulties arise because the categorical distribution is not reparameterizable. <ref type="bibr" target="#b10">Kingma et al. (2014)</ref> approach this by marginalizing out y over all classes, so that for unlabeled data, inference is still on q φ (z|x, y) for each y. The lower bound on unlabeled data is:</p><formula xml:id="formula_11">log p θ (x) ≥ −U(x) = E z∼q φ (y,z|x) [log p θ (x|y, z) + log p θ (y) + log p(z) − q φ (y, z|x)] (9) = y q φ (y|x)(−L(x, y) + H(q φ (y|x)))<label>(10)</label></formula><p>The full maximization objective is:</p><formula xml:id="formula_12">J = E (x,y)∼D L [−L(x, y)] + E x∼D U [−U(x)] + α • E (x,y)∼D L [log q φ (y|x)] (<label>11</label></formula><formula xml:id="formula_13">)</formula><p>where α is the scalar trade-off between the generative and discriminative objectives.</p><p>One limitation of this approach is that marginalization over all k class values becomes prohibitively expensive for models with a large number of classes. If D, I, G are the computational cost of sampling from q φ (y|x), q φ (z|x, y), and </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL RESULTS</head><p>In our first set of experiments, we compare Gumbel-Softmax and ST Gumbel-Softmax to other stochastic gradient estimators: Score-Function (SF), DARN, MuProp, Straight-Through (ST), and Slope-Annealed ST. Each estimator is evaluated on two tasks: (1) structured output prediction and</p><p>(2) variational training of generative models. We use the MNIST dataset with fixed binarization for training and evaluation, which is common practice for evaluating stochastic gradient estimators <ref type="bibr" target="#b23">(Salakhutdinov &amp; Murray, 2008;</ref><ref type="bibr" target="#b11">Larochelle &amp; Murray, 2011)</ref>.</p><p>Learning rates are chosen from {3e−5, 1e−5, 3e−4, 1e−4, 3e−3, 1e−3}; we select the best learning rate for each estimator using the MNIST validation set, and report performance on the test set. Samples drawn from the Gumbel-Softmax distribution are continuous during training, but are discretized to one-hot vectors during evaluation. We also found that variance normalization was necessary to obtain competitive performance for SF, DARN, and MuProp. We used sigmoid activation functions for binary (Bernoulli) neural networks and softmax activations for categorical variables. Models were trained using stochastic gradient descent with momentum 0.9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">STRUCTURED OUTPUT PREDICTION WITH STOCHASTIC BINARY NETWORKS</head><p>The objective of structured output prediction is to predict the lower half of a 28 × 28 MNIST digit given the top half of the image (14×28). This is a common benchmark for training stochastic binary networks (SBN) <ref type="bibr" target="#b19">(Raiko et al., 2014;</ref><ref type="bibr" target="#b7">Gu et al., 2016;</ref><ref type="bibr" target="#b15">Mnih &amp; Rezende, 2016)</ref>. The minimization objective for this conditional generative model is an importance-sampled estimate of the likelihood objective, E h∼p θ (hi|xupper) 1 m m i=1 log p θ (x lower |h i ) , where m = 1 is used for training and m = 1000 is used for evaluation.</p><p>We trained a SBN with two hidden layers of 200 units each. This corresponds to either 200 Bernoulli variables <ref type="bibr">(denoted as 392-200-200-392)</ref> or 20 categorical variables (each with 10 classes) with binarized activations (denoted as 392-(20 × 10)-(20 × 10)-392).</p><p>As shown in Figure <ref type="figure" target="#fig_3">3</ref>, ST Gumbel-Softmax is on par with the other estimators for Bernoulli variables and outperforms on categorical variables. Meanwhile, Gumbel-Softmax outperforms other estimators on both Bernoulli and Categorical variables. We found that it was not necessary to anneal the softmax temperature for this task, and used a fixed τ = 1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">GENERATIVE MODELING WITH VARIATIONAL AUTOENCODERS</head><p>We train variational autoencoders <ref type="bibr" target="#b9">(Kingma &amp; Welling, 2013)</ref>, where the objective is to learn a generative model of binary MNIST images. In our experiments, we modeled the latent variable as a single hidden layer with 200 Bernoulli variables or 20 categorical variables (20×10). We use a learned categorical prior rather than a Gumbel-Softmax prior in the training objective. Thus, the minimization objective during training is no longer a variational bound if the samples are not discrete. In practice, we find that optimizing this objective in combination with temperature annealing still minimizes actual variational bounds on validation and test sets. Like the structured output prediction task, we use a multi-sample bound for evaluation with m = 1000.</p><p>The temperature is annealed using the schedule τ = max(0.5, exp(−rt)) of the global training step t, where τ is updated every N steps. N ∈ {500, 1000} and r ∈ {1e−5, 1e−4} are hyperparameters for which we select the best-performing estimator on the validation set and report test performance.</p><p>As shown in Figure <ref type="figure" target="#fig_4">4</ref>, ST Gumbel-Softmax outperforms other estimators for Categorical variables, and Gumbel-Softmax drastically outperforms other estimators in both Bernoulli and Categorical variables.  We apply the Gumbel-Softmax estimator to semi-supervised classification on the binary MNIST dataset. We compare the original marginalization-based inference approach <ref type="bibr" target="#b10">(Kingma et al., 2014)</ref> to single-sample inference with Gumbel-Softmax and ST Gumbel-Softmax.</p><formula xml:id="formula_14">Bound (nats)<label>(a) Bound (nats) (b)</label></formula><p>We trained on a dataset consisting of 100 labeled examples (distributed evenly among each of the 10 classes) and 50,000 unlabeled examples, with dynamic binarization of the unlabeled examples for each minibatch. The discriminative model q φ (y|x) and inference model q φ (z|x, y) are each implemented as 3-layer convolutional neural networks with ReLU activation functions. The generative model p θ (x|y, z) is a 4-layer convolutional-transpose network with ReLU activations. Experimental details are provided in Appendix A.</p><p>Estimators were trained and evaluated against several values of α = {0.1, 0.2, 0.3, 0.8, 1.0} and the best unlabeled classification results for test sets were selected for each estimator and reported in Table <ref type="table" target="#tab_1">2</ref>. We used an annealing schedule of τ = max(0.5, exp(−3e−5 • t)), updated every 2000 steps.</p><p>In <ref type="bibr" target="#b10">Kingma et al. (2014)</ref>, inference over the latent state is done by marginalizing out y and using the reparameterization trick for sampling from q φ (z|x, y). However, this approach has a computational cost that scales linearly with the number of classes. Gumbel-Softmax allows us to backpropagate directly through single samples from the joint q φ (y, z|x), achieving drastic speedups in training without compromising generative or classification performance. (Table <ref type="table" target="#tab_1">2</ref>, Figure <ref type="figure" target="#fig_6">5</ref>). In Figure <ref type="figure" target="#fig_6">5</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>The primary contribution of this work is the reparameterizable Gumbel-Softmax distribution, whose corresponding estimator affords low-variance path derivative gradients for the categorical distribution. We show that Gumbel-Softmax and Straight-Through Gumbel-Softmax are effective on structured output prediction and variational autoencoder tasks, outperforming existing stochastic gradient estimators for both Bernoulli and categorical latent variables. Finally, Gumbel-Softmax enables dramatic speedups in inference over discrete latent  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B DERIVING THE DENSITY OF THE GUMBEL-SOFTMAX DISTRIBUTION</head><p>Here we derive the probability density function of the Gumbel-Softmax distribution with probabilities π 1 , ..., π k and temperature τ . We first define the logits x i = log π i , and Gumbel samples We perform a change of variables with v = e −g k , so dv = −e −g k dg k and dg k = −dv e g k = dv/v, and define u k = 0 to simplify notation:</p><formula xml:id="formula_15">p(u 1 , ..., u k,−1 ) = δ(u k = 0) ∞ 0 dv 1 v ve x k −v k−1 i=1 ve xi−ui−x k −ve x i −u i −x k (15) = exp x k + k−1 i=1 (x i − u i ) e x k + k−1 i=1 e xi−ui −k Γ(k)<label>(16)</label></formula><p>= Γ(k) exp Note that the final coordinate probability y k is fixed given the first k − 1, as k i=1 y i = 1:</p><formula xml:id="formula_16">y k =   1 + k−1 j=1 exp(u j /τ )   −1 = 1 − k−1 j=1 y j<label>(20)</label></formula><p>We can thus compute the probability of a sample from the Gumbel-Softmax using the change of variables formula on only the first k − 1 variables: p(y 1:k ) = p h −1 (y 1:k−1 ) det ∂h −1 (y 1:k−1 ) ∂y 1:k−1 (21)</p><p>Thus we need to compute two more pieces: the inverse of h and its Jacobian determinant. The inverse of h is:</p><formula xml:id="formula_17">h −1 (y 1:k−1 ) = τ ×   log y i − log   1 − k−1 j=1 y j     = τ × (log y i − log y k )<label>(22)</label></formula><p>with Jacobian ∂h −1 (y 1:k−1 ) where e is a k − 1 dimensional vector of ones, and we've used the identities: det(AB) = det(A)det(B), det(diag(x)) = i x i , and det(I + uv T ) = 1 + u T v.</p><formula xml:id="formula_18">∂y 1:k−1 = τ × diag 1 y 1:k−1 + 1 y k =      1 y1 + 1 y k 1 y k . . . 1 y k 1 y k 1 y2 + 1 y k . . .</formula><p>We can then plug into the change of variables formula (Eq. 21) using the density of the centered <ref type="bibr">Gumbel (Eq.15)</ref>, the inverse of h (Eq. 22) and its Jacobian determinant (Eq. 26):</p><p>p(y 1 , .., y k ) = Γ(k) </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: The Gumbel-Softmax distribution interpolates between discrete one-hot-encoded categorical distributions and continuous categorical densities. (a) For low temperatures (τ = 0.1, τ = 0.5), the expected value of a Gumbel-Softmax random variable approaches the expected value of a categorical random variable with the same logits. As the temperature increases (τ = 1.0, τ = 10.0), the expected value converges to a uniform distribution over the categories. (b) Samples from Gumbel-Softmax distributions are identical to samples from a categorical distribution as τ → 0. At higher temperatures, Gumbel-Softmax samples are no longer one-hot, and become uniform as τ → ∞.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Gradient estimation in stochastic computation graphs. (1) ∇ θ f (x) can be computed via backpropagation if x(θ) is deterministic and differentiable. (2) The presence of stochastic node z precludes backpropagation as the sampler function does not have a well-defined gradient. (3) The score function estimator and its variants (NVIL, DARN, MuProp, VIMCO) obtain an unbiased estimate of ∇ θ f (x) by backpropagating along a surrogate loss f log p θ (z), where f = f (x) − b and b is a baseline for variance reduction. (4) The Straight-Through estimator, developed primarily for Bernoulli variables, approximates ∇ θ z ≈ 1. (5) Gumbel-Softmax is a path derivative estimator for a continuous distribution y that approximates z. Reparameterization allows gradients to flow from f (y) to θ. y can be annealed to one-hot categorical variables over the course of training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>p θ (x|y, z) respectively, then training the unsupervised objective requires O(D + k(I + G)) for each forward/backward step. In contrast, Gumbel-Softmax allows us to backpropagate through y ∼ q φ (y|x) for single sample gradient estimation, and achieves a cost of O(D + I + G) per training step. Experimental comparisons in training speed are shown in Figure 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Test loss (negative log-likelihood) on the structured output prediction task with binarized MNIST using a stochastic binary network with (a) Bernoulli latent variables (392-200-200-392) and (b) categorical latent variables (392-(20 × 10)-(20 × 10)-392).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Test loss (negative variational lower bound) on binarized MNIST VAE with (a) Bernoulli latent variables (784 − 200 − 784) and (b) categorical latent variables (784 − (20 × 10) − 200).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>, we show how Gumbel-Softmax versus marginalization scales with the number of categorical classes. For these experiments, we use MNIST images with randomly generated labels. Training the model with the Gumbel-Softmax estimator is 2× as fast for 10 classes and 9.9× as fast for 100 classes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Gumbel-Softmax allows us to backpropagate through samples from the posterior q φ (y|x), providing a scalable method for semi-supervised learning for tasks with a large number of classes. (a) Comparison of training speed (steps/sec) between Gumbel-Softmax and marginalization (Kingma et al., 2014) on a semi-supervised VAE. Evaluations were performed on a GTX Titan X R GPU. (b) Visualization of MNIST analogies generated by varying style variable z across each row and class variable y across each column.</figDesc><graphic url="image-1.png" coords="8,319.76,351.81,163.30,97.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figures 6</head><label>6</label><figDesc>Figures 6 and 7 describe the architecture used in our experiments for semi-supervised classification (Section 4.3).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Semi-supervised generative model proposed by Kingma et al. (2014). (a) Generative model p θ (x|y, z) synthesizes images from latent Gaussian "style" variable z and categorical class variable y. (b) Inference model q φ (y, z|x) samples latent state y, z given x. Gaussian z can be differentiated with respect to its parameters because it is reparameterizable. In previous work, when y is not observed, training the VAE objective requires marginalizing over all values of y. (c) Gumbel-Softmax reparameterizes y so that backpropagation is also possible through y without encountering stochastic nodes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>TO A GUMBEL-SOFTMAX Given samples u 1 , ..., u k,−1 from the centered Gumbel distribution, we can apply a deterministic transformation h to yield the first k − 1 coordinates of the sample from the Gumbel-Softmax:y 1:k−1 = h(u 1:k−1 ), h i (u 1:k−1 ) = exp(u i /τ ) u j /τ ) ∀i = 1, . . . , k − 1 (19)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The Gumbel-Softmax estimator outperforms other estimators on Bernoulli and Categorical latent variables. For the structured output prediction (SBN) task, numbers correspond to negative log-likelihoods (nats) of input images (lower is better). For the VAE task, numbers correspond to negative variational lower bounds (nats) on the log-likelihood (lower is better).</figDesc><table><row><cell></cell><cell>SF</cell><cell cols="2">DARN MuProp</cell><cell>ST</cell><cell cols="3">Annealed ST Gumbel-S. ST Gumbel-S.</cell></row><row><cell cols="2">SBN (Bern.) 72.0</cell><cell>59.7</cell><cell>58.9</cell><cell>58.9</cell><cell>58.7</cell><cell>58.5</cell><cell>59.3</cell></row><row><cell>SBN (Cat.)</cell><cell>73.1</cell><cell>67.9</cell><cell>63.0</cell><cell>61.8</cell><cell>61.1</cell><cell>59.0</cell><cell>59.7</cell></row><row><cell cols="3">VAE (Bern.) 112.2 110.9</cell><cell>109.7</cell><cell>116.0</cell><cell>111.5</cell><cell>105.0</cell><cell>111.5</cell></row><row><cell cols="3">VAE (Cat.) 110.6 128.8</cell><cell>107.0</cell><cell>110.9</cell><cell>107.8</cell><cell>101.5</cell><cell>107.8</cell></row><row><cell cols="6">4.3 GENERATIVE SEMI-SUPERVISED CLASSIFICATION</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Marginalizing over y and single-sample variational inference perform equally well when applied to image classification on the binarized MNIST dataset<ref type="bibr" target="#b11">(Larochelle &amp; Murray, 2011)</ref>. We report variational lower bounds and image classification accuracy for unlabeled data in the test set.</figDesc><table><row><cell></cell><cell>ELBO Accuracy</cell></row><row><cell>Marginalization</cell><cell>-106.8 92.6%</cell></row><row><cell>Gumbel</cell><cell>-109.6 92.4%</cell></row><row><cell cols="2">ST Gumbel-Softmax -110.7 93.6%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">The Gumbel(0, 1) distribution can be sampled using inverse transform sampling by drawing u ∼ Uniform(0, 1) and computing g = − log(− log(u)).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We sincerely thank Luke Vilnis, Vincent Vanhoucke, Luke Metz, David Ha, Laurent Dinh, George Tucker, and Subhaneil Lahiri for helpful discussions and feedback.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Published as a conference paper at ICLR 2017 y, z Figure <ref type="figure">7</ref>: Network architecture for (a) classification q φ (y|x) (b) inference q φ (z|x, y), and (c) generative p θ (x|y, z) models. The output of these networks parameterize Categorical, Gaussian, and Bernoulli distributions which we sample from. g 1 , ..., g k , where g i ∼ Gumbel(0, 1). A sample from the Gumbel-Softmax can then be computed as:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 CENTERED GUMBEL DENSITY</head><p>The mapping from the Gumbel samples g to the Gumbel-Softmax sample y is not invertible as the normalization of the softmax operation removes one degree of freedom. To compensate for this, we define an equivalent sampling process that subtracts off the last element, (x k + g k )/τ before the softmax:</p><p>To derive the density of this equivalent sampling process, we first derive the density for the "centered" multivariate Gumbel density corresponding to:</p><p>where g i ∼ Gumbel(0, 1). Note the probability density of a Gumbel distribution with scale parameter β = 1 and mean µ at z is: f (z, µ) = e µ−z−e µ−z . We can now compute the density of this distribution by marginalizing out the last Gumbel sample, g k :</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Estimating or propagating gradients through stochastic neurons for conditional computation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Léonard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1308.3432</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Infogan: Interpretable representation learning by information maximizing generative adversarial nets</title>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rein</forename><surname>Houthooft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<idno>CoRR, abs/1606.03657</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.01704</idno>
		<title level="m">Hierarchical multiscale recurrent neural networks</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Likelihood ratio gradient estimation for stochastic systems</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Glynn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="75" to="84" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Hybrid computing using a neural network with dynamic external memory</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Grabska-Barwińska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Colmenarejo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ramalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Agapiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">538</biblScope>
			<biblScope unit="issue">7626</biblScope>
			<biblScope unit="page" from="471" to="476" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Neural turing machines</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<idno>CoRR, abs/1410.5401</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1310.8499</idno>
		<title level="m">Deep autoregressive networks</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">MuProp: Unbiased Backpropagation for Stochastic Neural Networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><surname>Mnih</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Statistical theory of extreme values and some practical applications: a series of lectures</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Gumbel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Number</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="1954">1954</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<title level="m">Auto-encoding variational bayes</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Semi-supervised learning with deep generative models</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3581" to="3589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The neural autoregressive distribution estimator</title>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A* sampling</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Minka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3086" to="3094" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016-11">November 2016</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Neural variational inference and learning in belief networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Variational inference for monte carlo objectives</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.06725</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Variational Bayesian Inference with Stochastic Search</title>
		<author>
			<persName><forename type="first">J</forename><surname>Paisley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012-06">June 2012</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Regularizing neural networks by penalizing confident output distributions</title>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Pereyra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<title level="m">Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes</title>
				<imprint>
			<date type="published" when="2016-10">October 2016</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Berglund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Alain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.2989</idno>
		<title level="m">Techniques for learning binary stochastic feedforward neural networks</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1401.4082</idno>
		<imprint>
			<date type="published" when="2014">2014a</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 31st International Conference on Machine Learning</title>
				<meeting>The 31st International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2014">2014b</date>
			<biblScope unit="page" from="1278" to="1286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Discrete Variational Autoencoders</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Rolfe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016-09">September 2016</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On the quantitative analysis of deep belief networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
				<meeting>the 25th international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="872" to="879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Gradient estimation using stochastic computation graphs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3528" to="3536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.00567</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Show, attend and tell: Neural image caption generation with visual attention</title>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno>CoRR, abs/1502.03044</idno>
	</analytic>
	<monogr>
		<title level="m">A SEMI-SUPERVISED CLASSIFICATION MODEL</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
