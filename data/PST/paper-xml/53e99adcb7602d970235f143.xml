<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The beta exponential distribution</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2005-08-01">1 August 2005</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Saralees</forename><surname>Nadarajah</surname></persName>
							<email>snadaraj@math.iupui.edu</email>
						</author>
						<author>
							<persName><forename type="first">Samuel</forename><surname>Kotz</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Engineering Management and Systems Engineering</orgName>
								<orgName type="institution">The George Washington University</orgName>
								<address>
									<postCode>20052</postCode>
									<settlement>Washington</settlement>
									<region>DC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">University of Nebraska</orgName>
								<address>
									<postCode>68583</postCode>
									<settlement>Lincoln</settlement>
									<region>NE</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The beta exponential distribution</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2005-08-01">1 August 2005</date>
						</imprint>
					</monogr>
					<idno type="MD5">A01C997542EFAD0D8EDA9FE0661C5B86</idno>
					<idno type="DOI">10.1016/j.ress.2005.05.008</idno>
					<note type="submission">Received 21 March 2005; accepted 19 May 2005</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Beta exponential distribution</term>
					<term>Kurtosis</term>
					<term>Re ´nyi entropy</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The exponential distribution is perhaps the most widely applied statistical distribution for problems in reliability. In this note, we introduce a generalization-referred to as the beta exponential distribution-generated from the logit of a beta random variable. We provide a comprehensive treatment of the mathematical properties of the beta exponential distribution. We derive expressions for the moment generating function, characteristic function, the first four moments, variance, skewness, kurtosis, mean deviation about the mean, mean deviation about the median, Re ´nyi entropy, Shannon entropy, the distribution of sums and ratios, and the asymptotic distribution of the extreme order statistics. We also discuss simulation issues, estimation by the methods of moments and maximum likelihood and provide an expression for the Fisher information matrix. We hope that this generalization will attract wider applicability in reliability.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The exponential distribution is perhaps the most widely applied statistical distribution for problems in reliability. In this note, we propose a generalization of the exponential distribution with the hope it will attract wider applicability in reliability. The generalization is motivated by the following general class: If G denotes the cumulative distribution function (cdf) of a random variable then a generalized class of distributions can be defined by denotes the incomplete beta function. This class of distributions came to prominence after the recent paper by Jones <ref type="bibr" target="#b0">[1]</ref>. Eugene et al. <ref type="bibr" target="#b1">[2]</ref> introduced what is known as the beta normal distribution by taking G in (1.1) to be the cdf of the normal distribution with parameters m and s. The only properties of the beta normal distribution known are some first moments derived by Eugene et al. <ref type="bibr" target="#b1">[2]</ref> and some more general moment expressions derived by Gupta and Nadarajah <ref type="bibr" target="#b2">[3]</ref>. More recently, Natarajah and Kotz <ref type="bibr" target="#b3">[4]</ref> introduced what is known as the beta Gumbel distribution by taking G in (1.1) to be the cdf of the Gumbel distribution with parameters m and s. This distribution is a little more tractable than the beta normal distribution in that Natarajah and Kotz <ref type="bibr" target="#b3">[4]</ref> were able to provide closed-form expressions for the moments, the asymptotic distribution of the extreme order statistics and the estimation procedure. Another distribution that happens to belong to (1.1) class is the log F (or beta logistic) distribution. This distribution appears reasonably tractable partly because it has been around for over 20 years <ref type="bibr" target="#b4">[5]</ref>, but it did not originate directly from (1.1) idea.</p><p>In the light of the above remarks, it is natural to ask: what is the most tractable distribution that can be obtained out of (1.1)? One of the simplest distributions in statistics is the exponential distribution. Thus, we are motivated to introduce the beta exponential (BE) distribution by taking G in (1.1) to be the cdf of an exponential distribution with parameter l. respectively. This distribution contains the exponentiated exponential distribution <ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref> as a particular case for bZ1.</p><p>The exponential distribution (with parameter bl) is contained as the particular case for aZ1. Some other particular cases of (1.2) are: We show in the sequel that beta exponential distribution is the most tractable distribution (to date) that comes out of (1.1). We derive the most comprehensive list of properties to a known distribution out of (1.1). We believe that these properties can be 'transformed back' to provide the corresponding results for other members of (1.1). For example, if X has the pdf (1.3) then noting that YZmK s log(lX) has the beta Gumbel distribution will help to obtain the corresponding results.</p><formula xml:id="formula_0">FðxÞ Z X n iZa n i ! expfKðn K iÞlxgf1 K expðKlxÞg i</formula><p>Besides being of mathematical interest, the beta exponential distribution can be used as an improved model for failure time data. It exhibits both increasing and decreasing failure rates and the shape of the failure rate function depends only on the parameter a-see below. The Gumbel distribution is commonly used as a model for extreme value data <ref type="bibr" target="#b11">[12]</ref> and thus the beta Gumbel distribution may not be a better choice to model failure time data.</p><p>The rest of this paper provides a comprehensive treatment of the mathematical properties of (1.3). In particular, expressions are derived for † the shape of the pdf and the hazard rate function (Section 2); † the moment generating function, characteristic function and the cumulant generating function (Section 3); † the first four moments, variance, skewness and kurtosis (Section 4); † the mean deviation about the mean and the mean deviation about the median (Section 5); † Re ´nyi and Shannon entropies (Section 6); † the distribution of sums and ratios (Section 7); † the asymptotic distribution of the extreme order statistics (Section 8); † estimation by the methods of moments and maximum likelihood, Fisher information matrix and simulation issues (Section 9).</p><p>Finally, in Section 10, we provide conclusions and suggestions for future work.</p><p>In addition to the special functions mentioned above, the calculations of this paper make use of the Euler's psi function defined by J(x)Zd log G(x)/dx. The properties of these special functions can be found in <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Shape</head><p>Firstly, consider the shapes of (1.3) and (1.4). Note from (1.3) that f(x)wl a x aK1 /B(a,b) as x/0 and that f(x)wl exp(Kblx)/B(a,b) as x/N. The first and the second derivatives of log f(x) are</p><formula xml:id="formula_1">d log f ðxÞ dx Z ða K 1Þl expðKlxÞ 1 K expðKlxÞ K bl (2.1)</formula><p>and</p><formula xml:id="formula_2">d 2 log f ðxÞ dx 2 Z ð1 K aÞl 2 expðKlxÞ f1 K expðKlxÞg 2 (2.2)</formula><p>Thus, if a!1 then (log f) 0 (x) is an increasing function with (log f) 0 (N)ZKbl!0. This implies in turn that f(x) monotonically decreases if a!1. On the other hand, if aO1 then (log f) 0 (x) is a decreasing function with (log f) 0 (0)ZN and (log f) 0 (0)ZKbl. This implies that if aO1 then f(x) has a unique mode at xZx 0 with f(x) increasing for x!x 0 and f(x) decreasing for xOx 0 . Here, xZx 0 is the root of the equation</p><formula xml:id="formula_3">lða K 1ÞexpðKlxÞ 1 K expðKlxÞ Z bl</formula><p>Note from (1.4) that l(x)wl a x aK1 /B(a,b) as x/0 and that l(x)/lb as x/N. If aZ1 then l(x) is a constant taking the value lb. If a!1 (respectively, aO1) then l(x) monotonically decreases (respectively, increases) with x. The last statement follows from Lemmas 5.8 and 5.9 in <ref type="bibr" target="#b14">[15]</ref>-which note the connection between monotonicity of l(x) and log-concavity/convexity of f(x)-since (Klog f) 00 (x)O0 (respectively (Klog f) 00 (x)!0) if a!1 (respectively, aO1). See also Section 6.3.1 in <ref type="bibr" target="#b0">[1]</ref>. Graphical illustrations of (1.3) and (1.4) are shown in Figs. <ref type="figure">1</ref> and<ref type="figure" target="#fig_2">2</ref>, respectively.</p><p>It is interesting to note that shapes of both f(x) and l(x) depend only on the parameter a (and not on the parameter b). The reason for this is evident from (2.1) and (2.2). Jones <ref type="bibr" target="#b0">[1]</ref> noted this in his discussion paper: "It seems to me to be unusual for the failure rate properties of a family of distributions with two shape parameters to be so simple and to depend on only one of them. This could be an attractive property of log(beta) distributions as a family of lifetime distributions." This suggests that one might consider using the exponentiated exponential distribution (particular case of (1.3) for bZ1) without loosing much flexibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Characteristic function</head><p>Here, we derive the moment generating and the characteristic functions for a random variable X having the pdf (1.3). Its moment generating function (mgf) defined by M(t)ZE(exp(tX)) is given by MðtÞ Z l Bða; bÞ</p><formula xml:id="formula_4">ð N 0 expfðt K blÞxgf1 K expðKlxÞg aK1 dx</formula><p>On substituting yZexp(Klx), the integral on the right reduces to</p><formula xml:id="formula_5">1 l ð 1 0 y bKt=lK1 ð1 K yÞ aK1 dy Z 1 l B b K t l ; a Thus, it is immediate that MðtÞ Z B b K t l ; a À Á Bða; bÞ (3.1)</formula><p>Hence, the characteristic function of X defined by f(t)Z E(exp(itX)) takes the form</p><formula xml:id="formula_6">fðtÞ Z B b K it l ; a À Á Bða; bÞ</formula><p>where iZ ffiffiffiffiffiffi K1 p is the complex number.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Moments</head><p>It is immediate from (3.1) that the nth moment of X can be written as In particular, the first four moments can be worked out as</p><formula xml:id="formula_7">EðX n Þ Z ðK1Þ n l n Bða; bÞ v n vp n Bða; 1 C p K aÞ pZaCbK1</formula><formula xml:id="formula_8">EðXÞ Z fJða C bÞ K JðbÞg=l (4.1) EðX 2 Þ ZfJ 0 ðbÞ K J 0 ða C bÞ C J 2 ðbÞ K 2JðbÞJða C bÞ C J 2 ða C bÞg l 2 ð4:2Þ EðX 3 Þ ZK ½J 00 ðbÞ K J 00 ða C bÞ C 3JðbÞJ 0 ðbÞ K 3Jða C bÞJ 0 ðbÞ K 3JðbÞJ 0 ða C bÞ C 3Jða C bÞJ 0 ða C bÞ C J 3 ðbÞ K 3J 2 ðbÞJða C bÞ C 3JðbÞJ 2 ða C bÞ K J 3 ða C bÞ l 3</formula><p>and EðX 4 Þ Z ½J 000 ðbÞ K 3J 000 ða C bÞ C 4JðbÞJ 00 ðbÞ K 4Jða C bÞJ 00 ðbÞ K 4JðbÞJ 00 ða C bÞ</p><formula xml:id="formula_9">C 4Jða C bÞJ 00 ða C bÞ C 3fJ 0 ðbÞg 2 K 6J 0 ðbÞJ 0 ða C bÞ C 3fJ 0 ða C bÞg 2 C 6J 2 ðbÞJ 0 ðbÞ K 12JðbÞJða C bÞJ 0 ðbÞ C 6J 2 ða C bÞJ 0 ðbÞ K 6J 2 ðbÞJ 0 ða C bÞ C 12JðbÞJða C bÞJ 0 ða C bÞ K 6J 2 ða C bÞJ 0 ða C bÞ C J 4 ðbÞ K 4J 3 ðbÞJða C bÞ C 6J 2 ðbÞJ 2 ða C bÞ K 4JðbÞJ 3 ða C bÞ C J 4 ða C bÞ l 4</formula><p>Further calculations show that the first three central moments, skewness and the kurtosis of X can be given by VarðXÞ Z J 0 ðbÞ K J 0 ða C bÞ l 2 (4.3)</p><formula xml:id="formula_10">E½fX K EðXÞg 3 Z J 00 ða C bÞ K J 00 ðbÞ l 3 (4.4)</formula><p>E½fX KEðXÞg 4 Z 3fJ 0 ðbÞg 2 K6J 0 ðbÞJ 0 ðaCbÞC3fJ 0 ðaCbÞg 2 CJ 000 ðbÞKJ 000 ðaCbÞ 4  ; SkewnessðXÞZ J 00 ðaCbÞKJ 00 ðbÞ fJ 0 ðbÞKJ 0 ðaCbÞg 3=2 ð4:5Þ and KurtosisðXÞZ 3fJ 0 ðbÞg 2 K6J 0 ðbÞJ 0 ðaCbÞC3fJ 0 ðaCbÞg 2 CJ 000 ðbÞKJ 000 ðaCbÞ fJ 0 ðbÞKJ 0 ðaCbÞg 2 (4.6)</p><p>respectively. Note that the skewness and kurtosis measures depend only on a and b. Fig. <ref type="figure" target="#fig_3">3</ref> shows how they vary with respect to a and b.</p><p>It is evident that both measures decrease monotonically with a and b.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Mean deviations</head><p>The amount of scatter in a population is evidently measured to some extent by the totality of deviations from the mean and median. These are known as the mean deviation about the mean and the mean deviation about the median-defined by</p><formula xml:id="formula_11">d 1 ðXÞ Z ð N 0 jx K mjf ðxÞdx and d 2 ðXÞ Z ð N 0 jx K Mjf ðxÞdx</formula><p>respectively, where mZE(X) and M denotes the median. These measures can be calculated using the relationships that</p><formula xml:id="formula_12">d 1 ðXÞ Z ð m 0 ðm K xÞf ðxÞdx C ð N m ðx K mÞf ðxÞdx Z 2 ð m 0 ðm K xÞf ðxÞdx Z 2 mFðmÞ K ð m 0 xf ðxÞdx &amp; '<label>(5.1)</label></formula><p>and</p><formula xml:id="formula_13">d 2 ðXÞ Z ð M 0 ðM K xÞf ðxÞdx C ð N M ðx K MÞf ðxÞdx Z 2MFðMÞ K M K ð M 0 xf ðxÞdx C ð N M xf ðxÞdx Z EðXÞ C 2MFðMÞ K M K 2 ð M 0 xf ðxÞdx (5.2)</formula><p>Using the series representation It can be verified that in the particular case aZ1, d 1 (X) reduces to 2/(ebl), which is the mean deviation for an exponential distribution (see, for example, Chapter 19 of <ref type="bibr" target="#b15">[16]</ref>).</p><formula xml:id="formula_14">ð1 C zÞ a Z X N jZ0 Gða C 1Þ Gða K j C 1Þ z j j!<label>(5.3</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Re ´nyi and shannon entropies</head><p>An entropy of a random variable X is a measure of variation of the uncertainty. Re ´nyi entropy is defined by</p><formula xml:id="formula_15">J R ðgÞ Z 1 1 K g log Ð f g ðxÞdx È É (6.1)</formula><p>where gO0 and gs1 <ref type="bibr" target="#b16">[17]</ref>. For the BE pdf given by (1.3)</p><formula xml:id="formula_16">ð N 0 f g ðxÞdxZ l g B g ða;bÞ ð N 0 expðKgblxÞf1KexpðKlxÞg gaKg dx</formula><p>On substituting yZexp(Klx), the right-hand side reduces to l gK1 B g ða; bÞ ð 1 0 y gaKg ð1 K yÞ gbK1 dy Z l gK1 Bðga K g C 1; gbÞ B g ða; bÞ</p><p>Hence, (6.1) takes the expression</p><formula xml:id="formula_17">J R ðgÞ Z Klog l C 1 1 K g log Bðga K g C 1; gbÞ B g ða; bÞ ! (6.2)</formula><p>Shannon entropy defined by E[Klog f(X)] is the particular case of (6.1) for g[1. Limiting g[1 in (6.2) and using L'Hospital's rule, one obtains E½Klog f ðXÞ Z Klog l C log Bða; bÞ</p><formula xml:id="formula_18">C ða C b K 1ÞJða C bÞ K ða K 1ÞJðaÞ K bJðbÞ</formula><p>Song <ref type="bibr" target="#b17">[18]</ref> observed that the gradient of the Re ´nyi entropy J 0 R ðgÞZ ðd=dgÞJ R ðgÞ is related to the loglikelihood by J 0 R ð1ÞZKð1=2ÞVar½logðf ðXÞÞ. This equality and the fact that the quantity KJ 0 R ð1Þ remains invariant under location and scale transformations motivated Song to propose K2 J 0 R ð1Þ as a measure of the shape of a distribution. From (6.2), the first derivative is</p><formula xml:id="formula_19">J 0 R ðgÞ Z ða K 1ÞJðga K g C 1Þ C bJðgbÞ K ða C b K 1ÞJðga C gb K g C 1Þ K log Bða; bÞ 1 K g C 1 ð1 K gÞ 2 log Bðga K g C 1; gbÞ B g ða; bÞ &amp; '</formula><p>Using L'Hospital's rule again, one gets the expression K2J 0 R ð1ÞZðaK1Þ 2 J 0 ðaÞCb 2 J 0 ðbÞKðaCbK1Þ 2 J 0 ðaCbÞ (6.3)</p><p>for the measure proposed by Song <ref type="bibr" target="#b17">[18]</ref>. When f(x) has a finite fourth moment, this measure plays a similar role as the kurtosis measure in comparing the shapes of various densities and measuring heaviness of tails. Song <ref type="bibr" target="#b17">[18]</ref> provided a detailed discussion including examples to show in general that his measure is better: "it measures more than what kurtosis measures. Kurtosis is often regarded as a measure of tail heaviness of a distribution relative to that of the normal distribution and a measure of deviation from normality depending on the relative frequency of values either near the mean or far from it to values an intermediate distance from the mean. However, one of the problems with the kurtosis measure is that in many situations of interest when the tails of a distribution are heavy, the fourth moments may not exist or, even worse, the mean may not exist. this illustrates the limitation of the moments as indicators of distributional shape. However, our shape parameter is almost always applicable in virtually all situations encountered in practice. It does not require restrictions like symmetry assumption and may be applied to distributions with heavy tails such as Cauchy, Cramer, Levy or Pareto distributions." Fig. <ref type="figure" target="#fig_3">3</ref> shows how the kurtosis measure and Song's measure (given by (4.6) and (6.3), respectively) compare for the beta exponential distribution. From (4.6) and ( <ref type="formula">6</ref>.3), it is clear that Song's measure is simpler since it requires only the first derivative of the Euler psi function. The figure shows that Song's measure is much more sensitive to the parameters a and b then kurtosis is. This might help to quantify the tail behavior more accurately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Sums and ratios</head><p>It is well known that the sum of two exponential random variables with common parameter l has the gamma distribution while their ratio has the F distribution. In this section we explore how these results generalize to the BE distribution. Let X i , iZ1, 2 be independent random variables having the BE distribution with aKa i , bZb i and lZl i . Denote the corresponding pdf and cdf by f i and F i , respectively. Define RZX 1 CX 2 and WZX 1 CX 2 . Then the pdf of R is</p><formula xml:id="formula_20">f ðrÞ Z ð r 0 f 1 ðxÞf 2 ðr K xÞdx Z K ð r 0 expfðb 2 l 2 K b 1 l 1 Þxg !f1 K expðKl 1 xÞg a 1 K1 ½1 K expfKl 2 ðr K xÞg a 2 K1 dx (7.1)</formula><p>where KZl 1 l 2 exp(Kb 2 l 2 r)/{B(a 1 ,b 1 )B(a 2 ,b 2 )}. Using the series expansion (5.3), the last term in (7.1) can be expanded to yield:</p><formula xml:id="formula_21">f ðrÞ Z KGða 2 Þ X N iZ0 ðK1Þ i expðKil 2 rÞ i!Gða 2 K iÞ Iði; rÞ<label>(7.2)</label></formula><p>where I(i, r) denotes the integral</p><formula xml:id="formula_22">Iði;rÞZ ð r 0 expfðl 2 iCb 2 l 2 Kb 1 l 1 Þxgf1KexpðKl 1 xÞg a 1 K1 dx<label>(7.3)</label></formula><p>On substituting yZexp(Kl 1 x), (7.3) can be re-expressed as</p><formula xml:id="formula_23">Iði;rÞZ 1 l 1 ð 1 expðKl 1 rÞ y b 1 Kðl 2 ðb 2 CiÞ=l 1 Þ ð1KyÞ a 1 K1 dy Z 1 l 1 B 1KexpðKl 1 rÞ a 1 ;b 1 K l 2 ðb 2 CiÞ l 1 (7.4)</formula><p>Combining (7.2) and (7.4), one can see the pdf of R is the infinite sum of incomplete beta functions:</p><formula xml:id="formula_24">f ðrÞZ K l 1 Gða 2 Þ X N iZ0 ðK1Þ i expðKil 2 rÞ i!Gða 2 KiÞ B 1KexpðKl 1 rÞ ! a 1 ;b 1 K l 2 ðb 2 CiÞ l 1 ð7:5Þ</formula><p>In the particular case a 1 Za 2 Z1 it can be verified that this reduces to a gamma pdf. The pdf of W is</p><formula xml:id="formula_25">f ðwÞZ ð N 0 xf 1 ðxwÞf 2 ðxÞdx ZK ð N 0 xexpfðb 1 l 1 wCb 2 l 2 Þxgf1 KexpðKl 1 xwÞg a 1 K1 f1KexpðKl 2 xÞg a 2 K1 dx (7.5)</formula><p>where KZl 1 l 2 /{B(a 1 ,b 1 )B(a 2 , b 2 )}. Again using the series expansion (5.3), the last term in (7.5) can be expanded to yield</p><formula xml:id="formula_26">f ðwÞZKGða 2 Þ X N iZ0 ðK1Þ i JðiÞ i!Gða 2 KiÞ (7.6)</formula><p>where J(i) denotes the integral JðiÞZ</p><formula xml:id="formula_27">ð N 0 x expfKðb 1 l 1 wCb 2 l 2 Cil 2 Þxg</formula><p>!f1KexpðKl 1 xwÞg a 1 K1 dx Note that J(i) is proportional to the expectation of a random variable having the BE distribution. Thus, using (4.1), one obtains</p><formula xml:id="formula_28">JðiÞZ Bða 1 ;b 1 Þ l 2 1 w 2 J b 1 C ðb 2 CiÞl 2 wl 1 &amp; KJ a 1 Cb 1 C ðb 2 CiÞl 2 wl 1 ' ð7:<label>7Þ</label></formula><p>Combining (7.6) and (7.7), one can see the pdf of W is:</p><formula xml:id="formula_29">f ðwÞZ KGða 2 ÞBða 1 ;b 1 Þ l 2 1 w 2 X N iZ0 ðK1Þ i i!Gða 2 KiÞ ! J b 1 C ðb 2 CiÞl 2 wl 1 KJ a 1 Cb 1 C ðb 2 CiÞl 2 wl 1 &amp; '</formula><p>In the particular case a 1 Za 2 Z1 it can be verified that this reduces to the pdf of an F distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Asymptotics</head><p>If X 1 ,.,X n is a random sample from <ref type="bibr">(1.3)</ref>  as n/N. The form of the norming constants can also be determined. For instance, using Corollary 1.6.3 in <ref type="bibr" target="#b18">[19]</ref>, one can see that a n Zb l and b n ZK(1/(bl))log{bB(a,b)/n}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Estimation and simulation</head><p>Here, we consider estimation and simulation issues. First, consider estimation by two methods: the method of moments and the method of maximum likelihood. Let x 1 ,.,x n be a random sample from <ref type="bibr">(1.3)</ref>. Under the method of moments, equating E(X), Var(X) and E[{XKE(X)}] 3 in (4.1), (4.3) and (4.4), respectively, with the corresponding sample estimates</p><formula xml:id="formula_30">s 1 Z 1 n X n iZ1 x i s 2 Z 1 n X n iZ1 ðx i K s 1 Þ 2 and s 3 Z 1 n X n iZ1 ðx i K s 1 Þ 3</formula><p>respectively, one obtains the system of equations Jða C bÞ K JðbÞ l Z s 1 (9.1)</p><formula xml:id="formula_31">J 0 ðbÞ K J 0 ða C bÞ l 2 Z s 2<label>(9.2)</label></formula><p>and J 00 ða C bÞ K J 00 ðbÞ l 3 Z s 3 (9.3) Combining (9.1) with (9.2) and (9.1) with (9.3), one obtains the equations J 0 ðbÞ K J 0 ða C bÞ fJðbÞ K Jða C bÞg 2 Z s 2 s 2 1 and J 00 ðbÞ K J 00 ða C bÞ fJðbÞ K Jða C bÞg 3 Z s 3 s 3 1 which can be solved simultaneously to give estimates for a and b. The estimate for l can then be obtained directly from (9.1). Note that if aZ1 then (9.1) gives lZ 1=ðbs 1 Þ, which is the usual estimator for l under the exponential model.</p><p>The log-likelihood for a random sample x 1 ,.,x n from (1.3) is:</p><formula xml:id="formula_32">log Lða; b; lÞ Z n log l K n log Bða; bÞ K bl X n iZ1 x i ða K 1Þ ! X n iZ1 logf1 K expðKlx i Þg</formula><p>The derivatives of this log-likelihood with respect to a, b and l are:</p><formula xml:id="formula_33">v log L va Z KnJðaÞ C nJða C bÞ C X n iZ1 logf1 K expðKlx i Þg v log L vb Z KnJðbÞ C nJða C bÞ K l X n iZ1 x i and v log L vl Z n l K b X n iZ1 x i C ða K 1Þ X n iZ1 x i expðKlx i Þ 1 K expðKlx i Þ</formula><p>which can be solved simultaneously for a, b and l.</p><p>For interval estimation of (a,b,l) and tests of hypothesis, one requires the Fisher information matrix. The elements of this matrix can be easily derived using the results in (4.1) and (4.2). One obtains</p><formula xml:id="formula_34">E K v 2 log L v 2 a Z nJ 0 ðaÞ K nJ 0 ða C bÞ E K v 2 log L vavb Z KnJ 0 ða C bÞ E K v 2 log L vavl Z K nb ða K 1Þl fJða C bÞ K Jðb C 1Þg !ðprovided aO 1Þ E K v 2 log L v 2 b Z nJ 0 ðbÞ K nJ 0 ða C bÞ E K v 2 log L vbvl Z n l fJða C bÞ K JðbÞg and E K v 2 log L v 2 l Z n l 2 1 C bða C b K 1Þ a K 2 fJ 0 ðb C 1Þ KJ 0 ða C b K 1Þ C J 2 ðb C 1Þ K 2Jðb C 1Þ !Jða C b K 1Þ C J 2 ða C b K 1Þg ! (provided aO2).</formula><p>Simulation from (1.3) is easy: note from (1.2) that if U is a random number from a beta distribution with parameters a and b then XZK(1/l)log(1KU) will follow the pdf (1.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">Conclusions</head><p>We have studied a class of distributions-referred to as the beta exponential distributions-which arise by taking G in (1.1) to be exponential. We have derived various properties of the beta exponential distributions, including the moment generating function, characteristic function, cumulant generating function, mean, variance, skewness, kurtosis, the mean deviation about the mean, the mean deviation about the median, Re ´nyi and Shannon entropies, the distribution of sums and ratios, the asymptotic distribution of the extreme order statistics, the estimation procedures by the methods of moments and maximum likelihood and the Fisher information matrix. We have shown that beta exponential distributions are the most tractable of all the known distributions out of <ref type="bibr">(1.1)</ref>. This statement also holds as a model for failure time data. The results presented in this paper can be used as a reference to obtain the corresponding results for other distributions belonging to <ref type="bibr">(1.1)</ref>.</p><p>Another distribution from (1.1) that would be of interest is the beta Weibull distribution. By setting GðxÞ Z expfKðlxÞ a g into (1.1) we note that the pdf of the beta Weibull distribution is f ðxÞ Z al a Bða; bÞ x aK1 expfKaðlxÞ a g½1 K expfKðlxÞ a g bK1 (10.1) for xO0, aO0, bO0, aO0 and lO0. Unfortunately, the mathematical properties of (10.1) are not very tractable. The particular case of (10.1) for bZ1, the exponentiated Weibull distribution, has been studied in some detail <ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref>. Even the moments for the exponentiated Weibull distribution are not known in a closed form.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FðxÞ</head><label></label><figDesc>Z I GðxÞ ða; bÞ (1.1) for aO0 and bO0, where I y ða; bÞ Z B y ða; bÞ Bða; bÞ denotes the incomplete beta function ratio, and B y ða; bÞ Z ð y 0 w aK1 ð1 K wÞ bK1 dw</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>for bZnKaC1 and integer values of a</head><label></label><figDesc>aZ1/2 and bZ1/2. The particular cases in (1.5) and (1.6) have been previously noted by Jones[1, p. 8].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The beta exponential hazard rate function (1.4) for bZ1 and lZ1. Fig. 1. The beta exponential pdf (1.3) for bZ1 and lZ1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Variation of skewness (top plot), kurtosis (lower surface of bottom plot) and Song's measure (upper surface of bottom plot) for aZ1,1.5,.,10 and bZ1,1.5,.,10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>) one can evaluate the integral term in (5.1) and (5into (5.1) and (5.2), one obtains the following expressions for the mean deviations:d1 ðXÞ Z2 mI 1KexpðKlmÞ ða; bÞK GðaÞ lBða; bÞ &amp; ! X N iZ0 ðK1Þ i ½1Kf1CðbCiÞlmgexpfKðbCiÞlmg i!ðb CiÞ 2 Gða KiÞ )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The cdf of the BE distribution becomes</figDesc><table><row><cell cols="3">FðxÞ Z I 1KexpðKlxÞ ða; bÞ</cell><cell>(1.2)</cell></row><row><cell cols="4">for xO0, aO0, bO0 and lO0. The corresponding</cell></row><row><cell cols="4">probability density function (pdf) and the hazard rate</cell></row><row><cell cols="3">function associated with (1.2) are:</cell><cell></cell></row><row><cell>f ðxÞ Z</cell><cell>l Bða; bÞ</cell><cell>expðKblxÞf1 K expðKlxÞg aK1</cell><cell>(1.3)</cell></row><row><cell>and</cell><cell></cell><cell></cell><cell></cell></row><row><cell>lðxÞ Z</cell><cell cols="2">l expðKblxÞf1 K expðKlxÞg aK1 B expðKlxÞ ðb; aÞ</cell><cell>(1.4)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Sometimes one would be interested in the asymptotics of the extreme values M n Zmax(X 1 ,.,X n ) and m n Zmin(X 1 ,.,X n ).Hence, it follows from Theorem 1.6.2 in<ref type="bibr" target="#b18">[19]</ref> that there must be norming constants a n O0, b n , c n O0 and d n such that Prfa n ðM n K b n Þ% xg/ expfKexpðKxÞg and Prfc n ðm n K d n Þ% xg/ 1 K expfKx a g</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>and if</cell><cell>XZ</cell></row><row><cell cols="7">ðX 1 C/C X n Þ=n denotes the sample mean then by the usual central limit theorem ffiffi ffi n p ð XK EðXÞÞ= ffiffiffiffiffiffiffiffiffiffiffiffiffiffi VarðXÞ p approaches</cell></row><row><cell cols="7">the standard normal distribution as n/N. Note from</cell></row><row><cell cols="7">(1.3) that 1KF(t)wexp(Kblt)/{bB(a,b)} as t/N and that</cell></row><row><cell cols="7">F(t)wl(t) a /{aB(a,b)} as t/0. Thus, it can be seen using</cell></row><row><cell cols="6">L'Hospital's rule that</cell></row><row><cell>lim t/N</cell><cell cols="3">1 K F t C x bl À 1 K FðtÞ</cell><cell>Á</cell><cell>Z lim t/N</cell><cell>expfKðx C bltÞg expðKbltÞ</cell><cell>Z expðKxÞ</cell></row><row><cell>and</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>lim t/0</cell><cell>FðxtÞ FðtÞ</cell><cell>Z lim t/0</cell><cell cols="4">ðxtÞ a t a Z x a</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>S. Nadarajah, S. Kotz / Reliability Engineering and System Safety 91 (2006) 689-697</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors would like to thank the referee and the Editor-in-Chief for carefully reading the paper and for their great help in improving the paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Families of distributions arising from distributions of order statistics</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Test</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1" to="43" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Beta-normal distribution and its applications</title>
		<author>
			<persName><forename type="first">N</forename><surname>Eugene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Famoye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun Statist-Theory Methods</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="497" to="512" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On the moments of the beta normal distribution</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nadarajah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun Statist-Theory Methods</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The beta Gumbel distribution</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nadarajah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kotz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math Probab Eng</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="323" to="332" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The log F: a distribution for all seasons</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Spears</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Levy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Statist</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="47" to="58" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Modeling failure time data by Lehman alternatives</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun Statist-Theory Methods</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="887" to="904" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Generalized exponential distributions</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kundu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Aust NZ J Statist</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="173" to="188" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Exponentiated exponential family: an alternative to gamma and Weibull distributions</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kundu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrical J</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="117" to="130" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Generalized exponential distribution: different method of estimations</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kundu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Statist Comput Simulat</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="315" to="337" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Closeness of gamma and generalized exponential distribution</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kundu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun Statist-Theory Methods</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="705" to="721" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Discriminating between Weibull and generalized exponential distributions</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kundu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Statist Data Anal</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="179" to="196" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Extreme value distributions: theory and applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kotz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nadarajah</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Imperial College Press</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Integrals and series</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Prudnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">A</forename><surname>Brychkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">I</forename><surname>Marichev</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>Gordon and Breach Science Publishers</publisher>
			<pubPlace>Amsterdam</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Table of integrals, series, and products. 6th ed</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Gradshteyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Ryzhik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Academic Press</publisher>
			<pubPlace>San Diego</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Statistical theory of reliability and life testing: probability models</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Barlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Proschan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<publisher>Holt, Rinehart and Winston</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">2nd ed Continuous univariate distributions</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">L</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kotz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Balakrishnan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>Wiley</publisher>
			<biblScope unit="volume">2</biblScope>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On measures of entropy and information</title>
		<author>
			<persName><forename type="first">A</forename><surname>Re</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourth Berkeley symposium on mathematical statistics and probability</title>
		<meeting>the fourth Berkeley symposium on mathematical statistics and probability<address><addrLine>Berkeley</addrLine></address></meeting>
		<imprint>
			<publisher>University of California Press</publisher>
			<date type="published" when="1961">1961</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="547" to="561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Re ´nyi information, loglikelihood and an intrinsic distribution measure</title>
		<author>
			<persName><forename type="first">K-S</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Statisst Plan Inference</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="51" to="69" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Rootze ´n H. Extremes and related properties of random sequences and processes</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Leadbetter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lindgren</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The exponentiated Weibull family</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Mudholkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Freimer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="436" to="445" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The exponentiated Weibull family: some properties and a flood data application</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Mudholkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Hutson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun Statist-Theory Methods</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="3059" to="3083" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On the exponentiated Weibull distribution</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Nassar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">H</forename><surname>Eissa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun Statist-Theory Methods</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1317" to="1336" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On the moments of the exponentiated Weibull distribution</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nadarajah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun Statist-Theory Methods</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="253" to="256" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
