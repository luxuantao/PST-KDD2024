<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dynamic psychological games</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2008-05-17">17 May 2008</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Pierpaolo</forename><surname>Battigalli</surname></persName>
							<email>pierpaolo.battigalli@unibocconi.it</email>
							<affiliation key="aff0">
								<orgName type="institution">Bocconi University</orgName>
								<address>
									<addrLine>Via Sarfatti 25</addrLine>
									<postCode>20136</postCode>
									<settlement>Milan</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Martin</forename><surname>Dufwenberg</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Arizona</orgName>
								<address>
									<settlement>Tucson</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Dynamic psychological games</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2008-05-17">17 May 2008</date>
						</imprint>
					</monogr>
					<idno type="MD5">E50A6B5FAE26284BB9B7FED0345FD1AB</idno>
					<idno type="DOI">10.1016/j.jet.2008.01.004</idno>
					<note type="submission">Received 30 November 2007; accepted 31 January 2008</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>JEL classification: C72</term>
					<term>C73 Psychological games</term>
					<term>Belief-dependent motivation</term>
					<term>Extensive-form solution concepts</term>
					<term>Dynamic interactive epistemology</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The motivation of decision makers who care for various emotions, intentions-based reciprocity, or the opinions of others may depend directly on beliefs (about choices, beliefs, or information). Geanakoplos, Pearce and Stacchetti [J. Geanakoplos, D. Pearce, E. Stacchetti, Psychological games and sequential rationality, Games Econ. Behav. 1 (1989) 60-79] point out that traditional game theory is ill-equipped to address such matters, and they pioneer a new framework which does. However, their toolbox -psychological game theory -incorporates several restrictions that rule out plausible forms of belief-dependent motivation. Building on recent work on dynamic interactive epistemology, we propose a more general framework. Updated higher-order beliefs, beliefs of others, and plans of action may influence motivation, and we can capture dynamic psychological effects (such as sequential reciprocity, psychological forward induction, and regret) that were previously ruled out. We develop solution concepts, provide examples, explore properties, and suggest avenues for future research.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>We develop a framework for analyzing strategic interaction when players have 'beliefdependent' motivations, generalizing the theory of extensive form psychological games proposed by Geanakoplos, Pearce and Stacchetti <ref type="bibr" target="#b35">[36]</ref> (hereafter GPS, see also Gilboa and Schmeidler <ref type="bibr" target="#b36">[37]</ref>). The rest of this Introduction motivates in more detail.</p><p>Traditional game theory is not a rich enough toolbox to adequately describe many psychological or social aspects of motivation and behavior. The traditional approach assumes utilities depend only on which actions are chosen, but if decision makers are emotional or care for the intentions, opinions, or emotions of others utilities may depend also on which beliefs (about choices, beliefs, or information) players harbor. The following examples illustrate:</p><p>1. When Abi takes a taxi ride she tips as much as she expects that the driver (Ben) expects to get. She suffers from guilt if she tips less. 2. Cleo suddenly pushes Dan over. Should Dan splash a bucket of water over Cleo in return?</p><p>Maybe she actually tried to hug him? If so, Dan would rather forgive (maybe even hug) Cleo. 3. Eva is unemployed. Her neighbor, Fred, observes the effort with which she tries to get a job.</p><p>Fred's taxes pay for Eva's unemployment benefits, so Eva's choice has externalities the size of which depends on her talent translating effort to probability of getting a job (low effort is costlier to Fred if Eva is talented and could have gotten a job had she tried harder). Eva's talent is known only to her, but Fred makes inferences observing her effort. This determines the social respect he bestows on Eva, and since she cares about respect this influences her effort. 4. Gwen is anxious about her health. Hal, her doctor, has diagnosed a serious illness. He is concerned with Gwen's health and anxiety. Should he prescribe the most appropriate treatment and thus reveal to Gwen how bad is her situation?</p><p>Abi's tip, Dan's hug/soak choice, Eva's effort, and Hal's prescription each pins down an outcome. Yet the preferred choice depends on a belief. 1  The point that belief-dependent motivation may be important for strategic decision making is made by GPS, who present several intriguing examples involving various emotions. They show the inadequacy of traditional methods to represent the involved preferences, and develop an extension (in the normal as well as in the extensive form) of traditional game theory to deal with the matter. A literature has emerged which either draws on or which can be related to GPS' framework. Contributions include applications to specific economic problems, 2 models of certain forms of belief-dependent preferences (like reciprocity or guilt), 3 and experimental studies that have provided support for such models. <ref type="foot" target="#foot_0">4</ref> By now a quite large set of economists argue that beliefdependent motivation is relevant to economic behavior. 5  While GPS' paper is a source of inspiration for all work on belief-dependent motivation, and an applicable toolbox for some work, a careful scrutiny reveals that their approach is too restrictive to handle many plausible forms of belief-dependent motivation (this is acknowledged by GPS themselves; see pp. <ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b77">[78]</ref><ref type="bibr">[79]</ref>. There are several reasons including the following four: R1 (updated beliefs): GPS only allow initial beliefs to enter the domain of a player's utility, while many seemingly important forms of belief-dependent motivation require updated beliefs to matter. R2 (others' beliefs): GPS only allow a player's own beliefs to enter the domain of his utility function, while there are conceptual and technical reasons to let others' beliefs matter. R3 (dependence on plans): GPS follow the traditional extensive games approach of letting strategies influence utilities only insofar as they influence terminal histories, but many forms of belief-dependent motivation become compelling in particular in conjunction with preferences that depend on strategies in ways not captured by terminal histories. R4 (non-equilibrium analysis): GPS restrict attention to equilibrium analysis, but in many strategic situations there is little compelling reason to expect players to coordinate on an equilibrium and one may wish to explore alternative assumptions.</p><p>This list deserves backup by examples, but we postpone this until the next section. Here we just note that items in the list have lead some researchers to deviate from GPS' framework, in developing specific examples or models with belief-dependent motivation. However almost no papers are concerned with developing the overall framework of psychological game theory. 6 We attempt to fill this gap, using R1-R4 as guiding principles.</p><p>Our approach crucially draws on Battigalli and Siniscalchi's <ref type="bibr" target="#b9">[10]</ref> work on how to represent hierarchies of conditional beliefs. This is essential for R1, and figures in the background of R2-R4 which are all related to updated beliefs. We define a large class of psychological games, which contains (in a particular sense) GPS' games and traditional games as special cases. Our main goal is to develop this basic framework, and to illustrate some solution concepts that can be meaningfully developed for it. While one could imagine a variety of interesting solution concepts, we choose to extend two basic concepts of classical game theory to our setting: sequential equilibrium and (extensive form) rationalizability. We prove related theorems, and illustrate how the concepts work in examples. berg <ref type="bibr" target="#b22">[23]</ref>, Bouckaert and Dhaene <ref type="bibr" target="#b16">[17]</ref>, Dufwenberg, Gaechter and Hennig-Schmidt <ref type="bibr" target="#b25">[26]</ref>, Tadelis <ref type="bibr" target="#b76">[77]</ref>, as well as the survey Attanasi and Nagel <ref type="bibr" target="#b2">[3]</ref>. 5 Add some (not many) decision-theorists to this list: Machina <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b58">59]</ref> presents examples which concern beliefdependent forms of disappointment. Robin Pope has written extensively (since the early 80's) about how conventional decision theory excludes various forms of belief-dependent motivation; Pope <ref type="bibr" target="#b65">[66]</ref> expounds her program and give further references and Albers, Pope, Selten and Vogt <ref type="bibr" target="#b0">[1]</ref> report on a related experiment. Bell <ref type="bibr" target="#b12">[13]</ref>, Loomes and Sugden <ref type="bibr" target="#b56">[57]</ref>, Karni <ref type="bibr" target="#b43">[44]</ref>, Karni and Schlee <ref type="bibr" target="#b44">[45]</ref>, and Caplin and Leahy <ref type="bibr" target="#b20">[21]</ref> develop single decision-maker models in which utility may depend directly on beliefs. 6 Kolpin <ref type="bibr" target="#b46">[47]</ref> explores an alternative route to GPS' games, where players 'choose beliefs.' Segal and Sobel <ref type="bibr" target="#b72">[73]</ref> analyze simultaneous move games, and assume preferences over material consequences depend on the equilibrium probability distribution over actions. They observe that their approach can be regarded as a reformulation of GPS' normal form games.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R1-R4</head><p>do not exhaust the good reasons to generalize GPS, but in the name of pedagogical clarity we only deal with R1-R4 in most sections of this paper <ref type="bibr" target="#b1">(2)</ref><ref type="bibr" target="#b2">(3)</ref><ref type="bibr" target="#b3">(4)</ref><ref type="bibr" target="#b4">(5)</ref>. Section 2 surveys these conceptual issues. Section 3 develops the general framework, up to the definition of a psychological game. Section 4 concerns sequential equilibrium. Section 5 concerns interactive epistemology and rationalizability. Section 6 contains a discussion as well as extensions beyond R1-R4. We compare our approach to that of GPS in more depth, consider imperfect information, chance moves, asymmetric information, own-plan dependence, dynamic inconsistency, and multi-self utility, and finally offer remarks regarding solutions concept we did not develop. Appendix A collects most of the proofs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Overview of some conceptual issues</head><p>This section surveys the conceptual issues that motivate us. We first describe what GPS' do, and why this is 'non-standard' vis-a-vis traditional game theory (2.1). We then explain what is our own contribution, going through R1-R4 in more detail (2.2). The style is 'semi-technical,' we introduce some notation, but postpone proper treatment of details for later.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">What GPS do</head><p>The traditional approach to analyzing extensive games (with complete information) describes a player's preferences using a utility function of the form</p><formula xml:id="formula_0">u i : Z → R</formula><p>where Z is the set of terminal histories (endnodes).</p><p>Psychological games capture richer motivations than traditional games, and the payoff functions have richer domains. GPS define a set of i's initial (pre-play) beliefs about others' strategies and initial beliefs, here referred to as M i , which does not rule out any hierarchy of initial beliefs. Each element of M i is a sequence μ i = (μ 1 i , μ 2 i , . . .) where μ 1 i represents i's beliefs about the opponents' strategies, or first-order beliefs, μ 2 i represents i's joint beliefs about the opponents' strategies and first-order beliefs, and so on. 7  GPS model preferences using utility functions of the form</p><formula xml:id="formula_1">u i : Z × M i → R.</formula><p>This structure bears some superficial similarities to games of incomplete information. It is worth clarifying the differences. In a game of incomplete information some payoff-relevant exogenous parameters (e.g. players' abilities or tastes) are not commonly known. Let θ ∈ Θ denote the vector of such parameters. Players' payoffs are represented by parametrized utility functions v i : Z × Θ → R. Note that θ does not specify strategic choices. A player has beliefs about θ (comprising her private information about θ ), beliefs about the beliefs of others concerning θ , etc. Following Harsanyi <ref type="bibr" target="#b40">[41]</ref>, such first-and higher-order beliefs can be represented in an elegant, albeit implicit, form by assuming that each player i is characterized by a 'type' t i ∈ T i and each t i corresponds to a probability measure p t i over the set of payoff-relevant parameters and opponents' types, i.e.</p><formula xml:id="formula_2">p t i ∈ Δ(Θ × T -i ).</formula><p>It can be shown that p t i corresponds to an infinite 7 More formally, first-order beliefs are elements of Δ(S -i ) (where S -i is the set of strategy profiles of i's co-players), second-order beliefs elements of Δ(S -i × j =i Δ(S -j )), etc. (see <ref type="bibr" target="#b17">[18]</ref> and <ref type="bibr" target="#b60">[61]</ref>). Upper-bars distinguish initial beliefs from systems of conditional beliefs, the main object of our analysis. We will be more precise in Section 3.</p><p>hierarchy of beliefs (p 1 t i , p 2 t i , . . .) where p 1 t i ∈ Δ(Θ) is the marginal of p t i on Θ, p 2 t i is a joint belief about θ and the opponents' beliefs about θ , and so on. Taking conditional expectations, the payoff functions of the incomplete information game can be represented as V i : Z × j T j → R, where</p><formula xml:id="formula_3">V i (z, t i , t -i ) = v i (z, θ )p t i (dθ |t -i ).</formula><p>Thus, both psychological games and incomplete information games can be described so that payoffs depend not only on how the game is played (z ∈ Z) but also on hierarchical beliefs. However, we are talking about different beliefs in the two cases. In psychological games payoffs at endnodes depend on beliefs about strategies, beliefs about such beliefs, and so on. The modeler explains/predicts, such beliefs via some solution concept. Hence payoffs at a given endnode are endogenous. On the other hand, players' hierarchical beliefs about the parameter vector θ are as exogenous as θ itself. Hence payoffs at a given terminal history of an incomplete information game are exogenous as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Extension of GPS</head><p>GPS' approach can capture interesting forms of belief-dependent motivation. Example 1 of the Introduction, e.g., could be handled by assuming that Abi's utility equals wm -2 max{μm, 0}, where w is her pre-tip wealth, m ∈ {0, 1, . . . , w} her tip, and μ her expectation of Ben's expectation of m, a function of her second-order belief. Abi maximizes her utility by choosing m = μ.</p><p>However, the issues R1-R4 lead us to enrich the domain of utilities further. We consider payoff functions of the form</p><formula xml:id="formula_4">u i : Z × M i × j =i (M j × S j ) → R</formula><p>where M j (with j = i or j = i) is the set of j 's possible conditional beliefs about others' strategies and conditional beliefs, S j is the set of (pure) strategies of j . The conditioning in M j is done for every history, building on Battigalli and Siniscalchi <ref type="bibr" target="#b9">[10]</ref> who show how to represent hierarchies of conditional beliefs without ruling out any hierarchy. M j is (isomorphic to) a subspace of M j , so the payoff functions we consider are more general than those assumed by GPS. <ref type="foot" target="#foot_1">8</ref>Issues R1-R4 will be related to different arguments of u i as we go.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R1: updated beliefs</head><p>Rabin's <ref type="bibr" target="#b66">[67]</ref> reciprocity theory, in which a player's preferences over material payoff distributions depends on the co-players intentions, is perhaps the most well-known application of GPS' theory. Rabin works in the normal form. His goal is to highlight key qualitative features of reciprocity, and he does not address issues of dynamic decision making although he points out that this is important for applied work (p. 1296). <ref type="foot" target="#foot_2">9</ref> Dufwenberg and Kirchsteiger <ref type="bibr" target="#b28">[29]</ref> pick up from there, and develop a reciprocity theory for extensive games. In motivating their exercise, they argue that it is necessary to deviate from GPS' extensive form framework: GPS only allow initial beliefs to enter the domain of a player's utility, while the modeling of reciprocal response at  various ventures of a game tree requires that (intentions-based) kindness be re-evaluated using updated belief. The argument is an instance of R1.</p><p>Reciprocity theory does not provide the easiest route to illustrating the key issues involved though. Instead, we consider the motivation of guilt aversion, applied to the trust game Γ 1 in Fig. <ref type="figure" target="#fig_0">1</ref>. 10 Payoffs are in dollars and do not necessarily represent preferences. Therefore, we call them 'material payoffs.'</p><p>We now modify Γ 1 to incorporate a guilt sentiment of Bob's: To make our point, let us first specify what it means that 'Bob lets Ann down.' Ann is let down if the material payoff she gets is less than what she expected. Let α be the probability that Ann (initially) assigns to Bob's strategy Share if Trust. Bob suffers from guilt to the extent that he believes he lets Ann down. The higher is α the more let down she will be if he chooses Grab. Bob does not know what α is, as this belief is in the mind of Ann. However, he has a belief about α. Let β be Bob's expectation of α, conditional on Ann choosing Trust. We can model guilt aversion assuming that Bob's utility at the terminal history (Trust, Grab) is decreasing in β. See Γ 2 in Fig. <ref type="figure" target="#fig_1">2</ref>. What appears at the terminal histories should be thought of as utilities, not material payoffs although the notions coincide for all but one terminal histories. 11  Γ 2 is not a psychological game in GPS' class, because β (being an updated belief) is not captured by any element of M i . This in itself illustrates R1. However, in order to appreciate the 10 Battigalli and Dufwenberg <ref type="bibr" target="#b7">[8]</ref> use the framework of the present paper to develop a general model of (two forms of) guilt aversion for extensive game forms. For the specific context of trust games, related sentiments have previously been considered by Huang and Wu <ref type="bibr" target="#b41">[42]</ref>, Dufwenberg <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25]</ref>, Dufwenberg and Gneezy <ref type="bibr" target="#b26">[27]</ref>, Guerra and Zizzo <ref type="bibr" target="#b38">[39]</ref>, Charness and Dufwenberg <ref type="bibr" target="#b22">[23]</ref>, and Bacharach, Guerra and Zizzo <ref type="bibr" target="#b4">[5]</ref>. 11 There is no special significance to the "5" in Fig. <ref type="figure" target="#fig_1">2</ref>; we could have chosen many other numbers to make the upcoming point. Similar remarks apply to all examples below. significance of this issue, it is useful to note that one can draw compelling (we think) conclusions about behavior that hinge crucially on the fact that β is an updated belief.</p><p>Following Dufwenberg <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25]</ref>, consider the following (for the time being intuitive) 'psychological forward induction' argument: Suppose Ann chooses Trust. If she is rational, she must believes the probability that Bob would choose Share (after Trust) is at least 1 2 , i.e., α 1 2 . Since we can figure this out, presumably Bob can too. Even if he is uncertain regarding the value of α, he infers it is at least 1 2 . Hence β 1 2 . Since 4 -5β &lt; 2 if β 1 2 , he prefers Share. Since we can figure this out, presumably Ann can too. Hence she chooses Trust, fully expecting Bob to Share (so α = 1). Bob figures this out (so that β = 1), which further reinforces his preference to Share. The path (Trust, Share) is predicted!</p><p>The argument depends on belief β being conditional on Ann choosing Trust. It cannot be recast using GPS' theory, since M i contains only initial beliefs, but it can be captured in our framework, since M i contains conditional beliefs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R2: others' beliefs</head><p>There are two independent justifications for letting a player's utility depend on others' beliefs. First, this may be an adequate description of how certain social rewards operate. Refer back to Example 3 from the Introduction, where Eva's preferences over effort depends on Fred's inferences. It is taken from Dufwenberg and Lundholm <ref type="bibr" target="#b29">[30]</ref>. A related example is Bernheim's <ref type="bibr" target="#b15">[16]</ref> model of social conformity. Another example is Caplin and Leahy's <ref type="bibr" target="#b21">[22]</ref> story of an information providing doctor concerned about the belief-dependent anxiety of a patient. 12 These authors develop models where a player's utility depends on others' beliefs (although only Caplin and Leahy explicitly refer to psychological games). 13  The second justification concerns convenience in modeling. Refer back to the discussion of Γ 2 , including the definition of α and β. We modeled Bob's guilt feelings by letting his psychological payoff depend on β, an updated second order belief. It turns out that there is an equivalent modeling choice. One can assume that Bob's utility at ( , L) depends directly on α, rather than on β, although Bob is uncertain about the true value of α. He uses probability assessments to weigh the different possibilities. We get Γ 3 in Fig. <ref type="figure" target="#fig_2">3</ref>. 12 For related work see Caplin <ref type="bibr" target="#b18">[19]</ref>, Caplin and Eliaz <ref type="bibr" target="#b19">[20]</ref>, and Kőszegi <ref type="bibr" target="#b47">[48]</ref> from whom Example 4 of the Introduction is taken. 13 The models can be interpreted as psychological games with asymmetric information where the utility of a player depends on the terminal beliefs of another player (cf. Section 6.2). After Trust, when Bob has to make a choice he compares 2, the payoff of action Share, with the conditional expected payoff of action Grab, that is E 2 [4 -5α|Trust] = 4 -5β; thus, we obtain the same results as with Γ 2 . <ref type="foot" target="#foot_3">14</ref>This illustrates an important point: some belief-dependent motivations can be modeled replacing a conditional own belief of a certain 'order' (meaning: how many layers of beliefs about beliefs/choices are involved) with another object involving one degree lower order. This may allow one to work with utilities u i : Z × j =i (M j × S j ) → R, where M i is not a factor of the domain. This has two advantages. First, it may seem easier to represent preferences with lower order beliefs (like α in Γ 3 rather than β in Γ 2 ). Second, and most importantly, one is lead to clearly distinguish between the carriers of utility (i.e., elements of Z × j =i (M j × S j )) and how a player deals with uncertainty by making updated probabilistic predictions (described by elements of M i ). By contrast, when the domain of i's utility is Z × M i × j =i (M j × S j ) elements of M i serve both purposes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R3: dependence on plans</head><p>Many forms of belief-dependent motivation require preferences to depend on overall strategies, beyond how strategies cause terminal histories when they are carried out. <ref type="foot" target="#foot_4">15</ref> Consider Γ 4 in Fig. <ref type="figure" target="#fig_3">4</ref>, a variation of Γ 1 where Ann may 'dissipate' some payoff. The payoffs of Γ 4 are material, not necessarily reflecting utilities.</p><p>Recall (from the discussion of R1) the terminology that 'Ann is let down' if the material payoff she gets is less than what she expects. In Γ 4 what she expects to get does not only depend on her beliefs about Bob, but also on how she plans to play. Suppose Ann plans to trust Bob and then keep the surplus. Then her subjectively expected material payoff is 2α, where α is the probability Ann assigns to Bob's strategy Share if Trust. But if she plans to trust Bob and then dissipate the surplus, her expected material payoff is zero independently of α.</p><p>Again assume that Bob suffers from guilt to the extent that he believes he lets Ann down. A natural way to model this is to let his utility at (Trust, Grab) be 4 -5α (as in Γ 3 ) if Ann plans to Keep, but 4 if she plans to Dissipate. <ref type="foot" target="#foot_5">16</ref>This example illustrates that psychological motivations may exhibit a concern for other players' intentions. Intentions depend on beliefs as well as plans, and the latter dependence goes beyond the endnodes implied by implementing such plans. Therefore, the domain of u i includes (conditional) beliefs and strategies of other players, on top of terminal histories and own beliefs.</p><p>R4: non-equilibrium analysis R1-R3 concern features of players' motivation one may wish to incorporate in a formal framework. The next step is to predict play. We propose a generalization of Kreps and Wilson's <ref type="bibr" target="#b50">[51]</ref> sequential equilibrium. We postpone illustrations until we formally introduce the concept in Section 4.</p><p>While much of economic theory presumes that players coordinate on an equilibrium, it is not always clear such an assumption is justified. For one thing, people may be quite rational, and confident in others' rationality, even if they fail to coordinate. In conventional game theory, related matters have inspired work on the implications of common belief of rationality; see e.g. Bernheim's <ref type="bibr" target="#b14">[15]</ref> and Pearce's <ref type="bibr" target="#b64">[65]</ref> work on rationalizability. This brings us to R4. There is little reason to assume that equilibrium coordination is easier in psychological games than in standard games. In fact, since psychological games often seem more complicated, and since problems of equilibrium multiplicity may be enhanced, assuming equilibrium may be assuming too much especially in psychological games. 17  Giving up the equilibrium assumption does not necessarily mean giving up on predictive power. Refer back to the psychological forward induction argument, presented for Γ 2 . Ann and Bob perform deductive reasoning regarding one another's behavior and beliefs, and a clear-cut prediction results despite that no presumption of equilibrium is made. However, the story told was informal, and specific to Γ 2 (or, equivalently, Γ 3 ). It is natural to wonder about generally applicable formalizations. In Section 5, we develop a framework for analyzing interactive epistemology in psychological games, without postulating equilibrium play. This is a relatively small step because our very definition of psychological game already provides the necessary ingredients. Building on an epistemic theme due to Battigalli and Siniscalchi <ref type="bibr" target="#b10">[11]</ref>, we extend Pearce's <ref type="bibr" target="#b64">[65]</ref> classical notion of (extensive form) rationalizability to psychological games. The concept captures psychological forward induction in simple games like Γ 2 and Γ 3 , and in more complicated games for which long chains of beliefs about beliefs are needed to get sharp predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Psychological games</head><p>In this section we introduce notation on extensive-forms (3.1), model a universal belief space that accounts for updated beliefs (3.2), and put forth and illustrate our general definition of a psychological game (3.3).</p><p>Ann's utility at (Trust, Grab) be affected by her initial beliefs and her own plan. We pursue this point and its ramifications in Section 6. 17 For more on this, see Section 6.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Extensive forms with observable actions</head><p>We first restrict attention to finite multi-stage games with observable actions, no chance moves, and complete information. These restrictions can be removed, at the cost of additional notational complexity (see <ref type="bibr">Section 6)</ref>. We assume players move simultaneously at every stage. This is without loss of generality, because the set of feasible actions of a player may depend on actions chosen in previous stages and may be singleton. Simultaneous moves games, perfect information games, and repeated games are special cases (cf. Fudenberg and Tirole <ref type="bibr" target="#b33">[34]</ref>, §3.3, Osborne and Rubinstein <ref type="bibr" target="#b62">[63]</ref>, ch. 6). We use the following notation/terminology:</p><p>An extensive form with observable actions is a tuple N, H where N = {1, . . . , n} is the player set, and H is the finite set of feasible histories. A history of length is a sequence h = (a 1 , . . . , a ) where each a t = (a t 1 , . . . , a t n ) represents the profile of actions chosen at stage t (1 t</p><p>). We assume history h becomes public information as soon as it occurs. The empty history (of length 0), denoted h 0 , is an element of H . The set of feasible actions for player i at history h is denoted A i (h) and may be singleton, meaning that i is not active at h. A i (h) is empty if and only if h is a terminal history. Z denotes the set of terminal histories.</p><p>For any given extensive form, we let S i denote the set of (pure) strategies of player i. A typical strategy is denoted by s i = (s i,h ) h∈H \Z , where s i,h is the action that would be selected by s i if history h occurred. Define S = i∈N S i and S -i = j =i S j . The set of i's strategies that allow history h is denoted S i (h). Similar notation is used for strategy profiles:</p><formula xml:id="formula_5">S(h) = i∈N S i (h); S -i (h) = j ∈N S j (h). We let ζ(s) ∈ Z denote the terminal history induced by s = (s i ) i∈N .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Conditional beliefs and infinite hierarchies of beliefs</head><p>Here we summarize the theory of hierarchies of conditional beliefs due to Battigalli and Siniscalchi <ref type="bibr" target="#b9">[10]</ref>, which should be consulted for proofs, details, and further references. Consider a decision maker DM who is uncertain about which element in a set X is true. Assume X is a compact Polish space. <ref type="foot" target="#foot_6">18</ref> DM assigns probabilities to events E, F, . . . in the Borel sigma-algebra B of X according to some (countably additive) probability measure. Let Δ(X) denote the set of all such probability measures. 19 As events unfold DM updates her beliefs. The actual and/or potential beliefs of DM are described by a conditional probability system (see Rênyi <ref type="bibr" target="#b69">[70]</ref>). Let C ⊆ B denote the collection of potentially observable events (or conditioning events). DM holds probabilistic beliefs conditional on each event F ∈ C.</p><formula xml:id="formula_6">Definition 1. A conditional probability system (cps) on (X, B, C) is a function μ(•|•) : B × C → [0, 1] such that for all E ∈ B, F, F ∈ C (1) μ(•|F ) ∈ Δ(X), (2) μ(F |F ) = 1, (3) E ⊆ F ⊆ F implies μ(E|F ) = μ(E|F )μ(F |F ).</formula><p>We regard the set of cps' on (X, B, C) as a subset of the topological space [Δ(X)] C , where Δ(X) is endowed with the topology of weak convergence of measures and [Δ(X)] C is endowed with the product topology.</p><p>From now on DM is a player i; (X, B, C) is either X = S -i (a finite set) or X = S -i × Y where Y is a compact Polish space typically representing a set of opponents' beliefs. The Borel sigma-algebra B is implicitly understood, 20 and conditioning events corresponds to histories, i.e.,</p><formula xml:id="formula_7">C = {F ⊆ S -i × Y : F = S -i (h) × Y, h ∈ H } (or C = {F ⊆ S -i : F = S -i (h), h ∈ H } if X = S -i ). The set of cps' is denoted Δ H (S -i × Y ) a subset of [Δ(S -i × Y )] H .</formula><p>If conditioning event F corresponds to history h, then we abbreviate as μ(•|F ) = μ(•|h). Note that our specification of the conditioning events relies on interpreting s j as an objective description of how j would behave at each decision node. However, we will also interpret s j as a plan in the mind of player j . The implicit assumption underlying our analysis (as well as most papers on interactive epistemology in games) is that each player has correct beliefs, given by his plan of action, about how he would choose at different histories (and there is common certainty of this). This is the reason why, like GPS (and Battigalli and Siniscalchi <ref type="bibr" target="#b10">[11]</ref>), we do not explicitly model i's beliefs about his own behavior. We will come back to this in Section 6.</p><p>The following result shows that Δ H (S -i × Y ) is a compact Polish space, just like Y . 21 It is key in our construction of hierarchical beliefs, implying that the domains of higher-and lower-order uncertainty have the same structural properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 2. Δ H (S</head><formula xml:id="formula_8">-i ) is a compact Polish space. Furthermore, if Y is a compact Polish space, also Δ H (S -i × Y ) is a compact Polish space.</formula><p>Hierarchies of cps' are defined recursively as follows:</p><formula xml:id="formula_9">• X 0 -i = S -i (i ∈ N ), • X k -i = X k-1 -i × j =i Δ H (X k-1 -j ) (i ∈ N ; k = 1, 2, . . .).</formula><p>By repeated applications of Lemma 2, each X k -i is a cross-product of compact Polish spaces, hence compact Polish itself. 22 </p><formula xml:id="formula_10">A cps μ k i ∈ Δ H (X k-1 -i ) is called k-order cps. For k &gt; 1, μ k</formula><p>i is a joint cps on the opponents' strategies and (k -1)-order cps'. A hierarchy of cps' is a countably infinite sequence of cps'</p><formula xml:id="formula_11">μ i = (μ 1 i , μ 2 i , . . .) ∈ k&gt;0 Δ H (X k-1 -i</formula><p>). μ i is coherent if the cps' of distinct orders assign the same conditional probabilities to lower-order events:</p><formula xml:id="formula_12">μ k i (•|h) = marg X k-1 -i μ k+1 i (•|h) (k = 1, 2, . . . ; h ∈ H ).</formula><p>It can be shown that a coherent hierarchy μ i induces a cps ν i on the cross-product of S -i with the sets of hierarchies of cps' of i's opponents, a compact Polish space. However, ν i may assign positive probability (conditional on some h) to opponents' incoherence. To rule this out, say that a coherent hierarchy μ i satisfies belief in coherency of order 1 if the induced cps ν i is such that each ν i (•|h) (h ∈ H ) assigns probability one to the opponents' 20 B obtains from the product of the discrete topology on S -i and the topology of Y . 21 This depends on two facts: (1) the collection of conditioning events for player i (corresponding to H ) is at most countable (indeed finite), and (2) each conditioning event</p><formula xml:id="formula_13">S -i (h) × Y (or S -i (h) if X = S -i ) is both closed</formula><p>and open, as we consider the discrete topology on S -i . 22 The cross-product of countably many compact Polish spaces is also compact Polish. coherency; μ i satisfies belief in coherency of order k if it satisfies belief in coherency of order k -1 and the induced cps ν i is such that each ν i (•|h) (h ∈ H ) assigns probability one the opponents' coherency of order k -1; μ i is collectively coherent if it satisfies belief in coherency of order k for each positive integer k. The set of collectively coherent hierarchies of player i is a compact Polish space, denoted by M i . We let M k i denote the set of k-order beliefs consistent with collective coherency, that is, the projection of</p><formula xml:id="formula_14">M i on Δ H (X k-1 -i ), and let M k -i = j =i M k j , M -i = j =i M j , M = j ∈N M j .</formula><p>We have now defined all components of the domain of the utility functions. But is this enough for the analysis of strategic reasoning? In order to decide on the best course of action, player i may need to form (conditional) beliefs about the infinite hierarchies of (conditional) beliefs of other players, either because they affect his payoff or because his assessment of the behavior and finite-order beliefs of others is derived from assumptions, such as "common belief in rationality," involving beliefs of infinitely many orders. Does this mean that we need additional layers of beliefs? No. The following result shows that the countably infinite hierarchies of cps' defined above are sufficient for the strategic analysis;</p><formula xml:id="formula_15">M i is isomorphic to Δ H (S -i × M -i ), so each μ i ∈ M i corresponds to a cps on S -i × M -i : Lemma 3.</formula><p>For each i ∈ N there is a 1-to-1 and onto continuous function</p><formula xml:id="formula_16">f i = (f i,h ) h∈H : M i → Δ H (S -i × M -i )</formula><p>whose inverse is also continuous. Furthermore, each coordinate function f i,h is such that for all</p><formula xml:id="formula_17">μ i = (μ 1 i , μ 2 i , . . .) ∈ M i , k 1,</formula><formula xml:id="formula_18">μ k i (•|h) = marg S -i ×M 1 -i ×•••×M k-1 -i f i,h (μ i ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Psychological games</head><p>We are now ready to state our definition of a psychological game:</p><formula xml:id="formula_19">Definition 4. A psychological game based on extensive form N, H is a structure Γ = N, H, (u i ) i∈N where u i : Z × M × S -i → R is i's (measurable and bounded) psychological payoff function.</formula><p>The numerical examples examined in Section 2 fit this definition: in Γ 2 , u 2 depends on z and μ<ref type="foot" target="#foot_7">2</ref> 2 (•|Trust); 23 in Γ 3 , u 2 depends on z and 1's initial first-order belief, μ 1 1 (•|h 0 ); finally, the psychological payoff function u 2 proposed to analyze Γ 4 (a game with material payoffs) depends on z, μ 1  1 (•|h 0 ), and s 1 . In all these examples, a psychological game is obtained from a material payoff game N, H, (π i : Z → R) i∈N according to some formula. We now illustrate a few such derivations, focusing on two-player games.</p><p>Player j is 'let down' if his actual material payoff, denoted πj , is lower than the payoff he initially expected to get, E j [ π j ]. This disappointment can be measured by the following expression: <ref type="foot" target="#foot_8">24</ref>max 0, E j [ π j ] -πj .</p><p>Suppose that i likes his material payoff but dislikes disappointing j . A simple way to model such "guilt" motivation is to assume that i wants to maximize the expected value of the following expression:</p><formula xml:id="formula_20">πi -θ i max 0, E j [ π j ] -πj .</formula><p>Taking explicitly into account the material payoff game, and that E j [ π j ] is a function of j 's plan and his initial beliefs about i's plan, we obtain the following utility function:</p><formula xml:id="formula_21">u i (z, μ, s j ) = π i (z) -θ i max 0, s i μ 1 j s i h 0 π j ζ s j , s i -π j (z)</formula><p>where θ i 0 is a psychological sensitivity parameter. For the special case of material payoff game Γ 1 , we obtain psychological game Γ 3 by letting θ 1 = 0 and θ 2 = 5 2 . 25  Another motivation is the willingness to give up some material payoff to avoid feeling regret ex post. The regret of i can be captured by the distance between the actual material payoff and the maximal expected payoff that could have been obtained 'with the benefit of hindsight,' i.e., using the terminal beliefs. Formally, i's regret when he gets material payoff πi and has terminal belief τ i ∈ Δ(S j ) equals max</p><formula xml:id="formula_22">s i s j τ i s j π i ζ s i , s j -πi .</formula><p>Taking into account that the actual payoff obtains at a terminal history z, which is observed by player i with first-order cps μ 1 i , we obtain the utility function</p><formula xml:id="formula_23">u i (z, μ, s j ) = π i (z) -θ i max s i s j μ 1 i s j z π i ζ s i , s j -π i (z)</formula><p>where θ i 0 is a psychological sensitivity parameter. 26 This shows that it may be natural to let utility depend on what players believe at the end of the game (for other examples of this kind see Subsection 6.2). Note that while we allow for a general functional form with very complex arguments, u i (z, μ, s j ), the utility functions used in specific applications can be relatively simple.</p><p>we have here is a game-theoretic extension. In this section we use it as input to formulate guilt (see next paragraph). Concern for own disappointment may naturally depend on one's own plan, which is excluded under Definition 4 but considered again in Section 6.3. 25 The modeling choices here reflect the discussion of R2 in Section 2 and are in line with Battigalli and Dufwenberg's <ref type="bibr" target="#b7">[8]</ref> notion of simple guilt to whom we refer for more guilt examples (the mathematical formulation in that paper is slightly more complex, but leads to a utility with the same best response correspondence). 26 Bell <ref type="bibr" target="#b11">[12]</ref> and Loomes and Sugden <ref type="bibr" target="#b55">[56]</ref> develop theories of regret, in which a decision maker's experienced utility depends on the post-choice revelation of a state-of-nature. Our formulation preserves that spirit, but extends it to beliefdependent motivation. This is natural in a strategic setting, where players cannot perfectly observe ex post the state of the world, which includes what another player would have chosen.</p><p>So far we have illustrated three forms of belief-dependent motivation which all relied on (different forms of) first-order beliefs (own initial, others' initial, own and/or others' terminal). Of course, Definition 4 allows also for higher-order belief-dependence. One example is Battigalli and Dufwenberg's <ref type="bibr" target="#b7">[8]</ref> notion of "guilt from blame," which involves dependence on the co-player's third-order beliefs. 27 The rest of this section leads up to another class of examples, which involve infinite-order beliefs.</p><p>As we noted in Section 2, letting beliefs and strategies of others in u i may yield simpler functional forms and clarify the distinction between prediction and psychological motivation. Yet, as reflected by Γ 2 and Γ 3 it is always possible to obtain an equivalent functional form where a player's utility depends only on the terminal history and his own conditional beliefs. Given <ref type="bibr">Lemma 3)</ref>. In words, ûi (z, μ i ) is how much i values z after he has observed it. It can be shown that ûi and u i yield the same (sequential) best responses. 28  The functional form ûi has infinite hierarchy μ i as an argument, but this is just because we want an abstract and general expression. If u i depends only on beliefs of order k, then ûi depends only on beliefs of order k + 1. An example that necessarily involves infinite-order beliefdependence arises if belief-dependent motivation appears together with 'interactive altruism.' Suppose that the utility of i is given by two terms as follows</p><formula xml:id="formula_24">u i (z, μ, s -i ) let ûi (z, μ i ) := E μ i [u i |z] where E μ i [u i |z] is the conditional expectation operator given cps f i (μ i ) ∈ Δ H (S -i × M -i ) (see</formula><formula xml:id="formula_25">u i = φ i + θu j (0 &lt; θ &lt; 1), φ i = φ i z, μ 1 , s j</formula><p>(φ i could be a guilt or regret component). Then we can compute an explicit form for the expected utility conditional on z by repeated substitution, where the term that depends on (k + 2)-order beliefs has exponentially decreasing weight θ k :</p><formula xml:id="formula_26">ûi (z, μ i ) = E μ i [φ i + θu j |z] = E μ 2 i [φ i |z] + θ E μ i [u j |z] = E μ 2 i [φ i |z] + θ E μ 3 i E μ 2 j [φ j |z] z + θ 2 E μ i E μ j [u i |z] z = • • • (E μ k i [•|z] is the conditional expectation operator given cps μ k i ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Equilibrium analysis</head><p>Kreps and Wilson's sequential equilibrium has become a benchmark for the analysis of standard games. We extend this concept to the class of psychological games defined in Section 3. (The restriction to multi-stage game forms with complete information simplifies but is not essential; cf. Section 6.) We next define and interpret mixed strategies and assessments (4.1), give the main definition and provide an existence theorem (4.2), and consider examples (4.3). 27 To save space we refer to the original source for precise definitions and examples. The intuition is that i experiences guilt (judging by his terminal beliefs) to the extent that j 's terminal beliefs indicate that i intended to disappoint j . 28 See the first part of Appendix A and Lemma 17.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Randomized strategies and consistent assessments</head><p>The equilibrium concept we develop refers to randomized choices. However, in our interpretation, we exclude actual randomization. Rather, we interpret a randomized choice of a given player i as the common first-order belief of i's opponents about i (cf. Aumann and Brandenburger <ref type="bibr" target="#b3">[4]</ref>). This is akin to the following characterization of a Nash equilibrium in a standard simultaneous-move game:</p><formula xml:id="formula_27">(σ 1 , . . . , σ n ) ∈ Δ(A 1 ) × • • • × Δ(A n ) is an equilibrium if, for each i, each action in the support of σ i is a best reply to σ -i .</formula><p>We focus on behavior strategies</p><formula xml:id="formula_28">σ i = (σ i (•|h)) h∈H \Z ∈ h∈H \Z Δ(A i (h))</formula><p>, interpreting σ i as an array of common conditional first-order beliefs held by i's opponents. This interpretation is part of the notion of 'consistency' of profiles of strategies and hierarchical beliefs defined below.</p><p>Kreps and Wilson <ref type="bibr" target="#b50">[51]</ref> argue that an appropriate definition of equilibrium in extensive form games must refer to 'assessments': profiles of (behavior) strategies and conditional (first-order) beliefs. They proceed in two steps: first a 'consistency' condition for assessments is put forward, and then sequential equilibrium is defined as a consistent assessment satisfying sequential rationality. It turns out that consistency captures the assumptions that each player regards his opponents' choices at different histories as stochastically independent, and any two players have the same (prior and conditional) beliefs about any third player. In our framework an assessment is a profile (σ, μ) =(σ i , μ i ) i∈N where σ is a behavioral strategy profile and μ ∈ M. We extend the definition of consistency by adding a requirement concerning the higher-order beliefs that need to be specified in psychological games.</p><p>Let Pr σ j (•| ĥ) ∈ Δ(S j ( ĥ)) denote the probability measure over j 's strategies conditional on ĥ derived from behavior strategy σ j under the assumption of independence across histories: ∀s j ∈ S j ( ĥ), Pr σ j (s j | ĥ) := h∈H \Z:h⊀ ĥ σ j (s j,h |h) (h ⊀ ĥ means that h is not a predecessor, or prefix, of ĥ). 29 Definition 5. A profile of first-order cps'</p><formula xml:id="formula_29">μ 1 = (μ 1 i ) i∈N is derived from a behavioral strategy profile σ = (σ i ) i∈N if for all i ∈ N , s -i ∈ S -i , ĥ ∈ H , μ 1 i (s -i | ĥ) = j =i</formula><p>Pr σ j (s j | ĥ).</p><p>Clearly, if μ 1 is derived from σ then for any three players i, j , k, the beliefs of i and j about k coincide:</p><formula xml:id="formula_31">∀ ĥ ∈ H, marg S k μ 1 i (•| ĥ) = Pr σ k (•| ĥ) = marg S k μ 1 j (•| ĥ).</formula><p>We are now ready for the main definition of this subsection. 29 Cf. Kuhn <ref type="bibr" target="#b52">[53]</ref>: Pr σ j (•|h) ∈ Δ(S j (h)) is only one out of the many probability measures that induce the same outcome probabilities starting from h, for all s -j ∈ S -j (h). But note that realization-equivalent beliefs may yield different psychological utilities! (b) higher-order beliefs in μ assign probability 1 to the lower-order beliefs:</p><formula xml:id="formula_32">Definition 6. Assessment (σ, μ) is consistent if (a) μ 1 is derived from σ ,</formula><formula xml:id="formula_33">∀i ∈ N, ∀k &gt; 1, ∀h ∈ H, μ k i (•|h) = μ k-1 i (•|h) × δ μ k-1 -i</formula><p>where × denotes the product of measures and δ x is the Dirac measure assigning probability 1 to singleton {x}.</p><p>A justification of the (strong) condition (b) comes from (i) the classical interpretation of equilibrium beliefs as the end-product of a transparent reasoning process by intelligent players, and (ii) the trembling hand assumption underlying the sequential equilibrium concept. <ref type="foot" target="#foot_9">30</ref> (i) implies that any two players must share the same initial first-order beliefs about any other player, and every player comes to a correct conclusion about the (hierarchical) beliefs of his opponents because he is able to replicate their reasoning. (ii) implies that unexpected moves are explained as mistakes, not as the result of unexpected beliefs, therefore players never change their beliefs about the conditional beliefs that the opponents would hold at each h. Of course, by observing the actual play-path each player infers the current actual beliefs of his opponents, but interesting forms of learning about others' beliefs are ruled out. We offer further comments on consistency and sequential equilibrium in Section 6.4.</p><p>We also note that (b) is analogous to a condition used by GPS to define psychological Nash equilibrium, requiring that players hold common, correct beliefs about each others' beliefs. Indeed, (b) is equivalent to the requirement that, for each player i and each history h, the conditional belief on S -i × M -i induced by hierarchy μ i assigns probability one to μ -i . 31   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Sequential equilibrium assessments</head><p>We now move to the section's main definition: a consistent assessment is a sequential equilibrium if it satisfies sequential rationality. Formally, fix a hierarchy of cps' μ i a (non-terminal) history h and a strategy s i consistent with h. The expectation of u i conditional on h, given s i and μ i is</p><formula xml:id="formula_34">E s i ,μ i [u i |h] := S -i ×M -i u i ζ(s i , s -i ), μ i , μ -i , s -i f i,h (μ i )(ds -i , dμ -i ).</formula><p>(2)</p><formula xml:id="formula_35">Definition 7. An assessment (σ, μ) is a sequential equilibrium (SE) if it is consistent and for all i ∈ N , h ∈ H \Z, s * i ∈ S i (h), Pr σ i s * i |h &gt; 0 ⇒ s * i ∈ arg max s i ∈S i (h) E s i ,μ i [u i |h].<label>(3)</label></formula><p>Note that, by consistency, σ i represents the first-order beliefs of i's opponents about i, and furthermore there is common certainty of the true belief profile μ at every history; therefore the sequential rationality condition (3) can equivalently be written as</p><formula xml:id="formula_36">∀j = i, supp marg S i μ 1 j (•|h) ⊆ arg max s i ∈S i (h) s -i ∈S -i (h) μ 1 i (s -i |h)u i ζ(s i , s -i ), μ, s -i . (<label>4</label></formula><formula xml:id="formula_37">)</formula><p>This clarifies that SE is a notion of equilibrium in beliefs. Indeed we could have given an equivalent definition of SE with no reference to behavioral strategies. We can also take the point of view of an 'agent' (i, h) of player i, in charge of the move at history h, who seeks to maximize i's conditional expected utility given the consistent assessment (σ, μ). The expected utility of i conditional on h and a i ∈ A i (h) given (σ, μ) can be expressed as</p><formula xml:id="formula_38">E σ,μ [u i |h, a i ] := s -i ∈S -i (h) j =i</formula><p>Pr σ j (s j |h)</p><formula xml:id="formula_39">s i ∈S i (h,a i ) Pr σ i (s i |h, a i )u i ζ(s), μ, s -i , (<label>5</label></formula><formula xml:id="formula_40">)</formula><p>where Pr σ i (s i |h, a i ) := h ∈H \Z:h / h σ i (s i,h |h ) (h / h means that h is not h or a predecessor of h). This specification presumes that (i, h) assesses the probabilities of actions by other agents of player i in the same way as each player j = i; that is using the behavioral strategy σ i . 32 It can be shown that a version of the One-Shot-Deviation (or unimprovability) principle holds in our framework 33 :</p><formula xml:id="formula_41">Proposition 8. A consistent assessment (σ, μ) satisfies (3</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>) and hence is an SE if and only if for all</head><formula xml:id="formula_42">i ∈ N , h ∈ H \Z, supp σ i (•|h) ⊆ arg max a i ∈A i (h) E σ,μ [u i |h, a i ].<label>(6)</label></formula><p>Proof. Available on request. 2</p><p>We obtain the following existence theorem: Theorem 9. If the psychological payoff functions are continuous, there exists at least one sequential equilibrium assessment.</p><p>The proof relies on a "trembling hand" argument (cf. Selten <ref type="bibr" target="#b73">[74]</ref>). We only provide a sketch here (but details are available on request). Consider ε-perturbed games where there is strictly positive minimal probability of choosing any action at any history, i.e. ε = (ε i,h (a i , h) a i ∈A i (h) ) i∈N,h∈H is a strictly positive vector such that a i ∈A i (h) ε(a i , h) &lt; 1 for each h. For each behavior strategy profile σ , let μ = β(σ ) denote the unique profile of hierarchies of cps' such that (σ, μ) is consistent. 34 Define an (agent-form, psychological) ε-equilibrium as an ε-constrained behavior strategy profile σ ε such that for each h and each i, a pure action a i that does not maximize the expectation of u i (given h and β(σ ε )) is assigned the minimal probability ε(a i , h) &gt; 0. It can be shown by standard compactness-continuity arguments that each ε-perturbed game has an ε-equilibrium (cf. the existence proof for psychological Nash equilibria in GPS). Fix a sequence ε k → 0 and a corresponding sequence σ k of ε k -equilibrium assessments. By compactness, σ k has an accumulation point σ * . By upper-hemicontinuity of the local 32 Suppose that u i depends only on terminal histories and beliefs, not on s -i . Then we obtain the more familiar formula</p><formula xml:id="formula_43">E σ,μ [u i |h, a i ] = z Pr σ (z|h, a i )u i (z, μ),</formula><p>where Pr σ (z|h, a i ) is the probability of terminal history z conditional on (h, a i ) determined by σ . 33 See Section 6.3 for further discussion. 34 (μ 1 i ) i∈N is derived from σ via formula (1) and the infinite hierarchies of cps' are obtained by assuming correct higher order beliefs. best response correspondences, for each (i, h), σ * i (•|h) assigns positive probability only to actions that are best responses to (σ * , β(σ * )) at h. So, by Proposition 8 (σ * , β(σ * )) is a sequential equilibrium assessment.</p><p>We next show that the SE concept generalizes subgame perfect equilibrium for standard games with observable actions (recall: sequential and subgame perfect equilibrium coincide in games with observable actions). This is a corollary of a more general result for games where psychological utilities depend only on terminal nodes and beliefs: u i : Z × M → R. For any such game Γ = N, H, (u i ) i∈N and any profile of hierarchies of cps' μ = (μ i ) i∈N , we can obtain a standard game</p><formula xml:id="formula_44">Γ μ = N, H, (v μ i ) i∈N with payoff functions v μ i (z) = u i (z, μ).</formula><p>Remark 10. Suppose ∀i ∈ N , u i : Z × M → R. Then an assessment (σ, μ) is a SE if and only if it is consistent and σ is a subgame perfect (hence sequential) equilibrium of the standard game Γ μ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Examples</head><p>We illustrate the SE concept with three examples, first a simultaneous move game illustrating how we can reproduce the essence of a leading example of GPS, then two versions of the Trust Game connecting back to some of the key notions previously highlighted in Section 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.">Equilibrium beliefs in the Bravery Game</head><p>The Bravery Game is a numerical example used in GPS (p. 66) to show that a psychological game may have multiple, isolated mixed strategy equilibria even if there is only one active player, which is impossible in standard games. We consider a modified version to illustrate our definition of equilibrium in beliefs. Let A 1 = {Wait}, A 2 = {bold, timid}. Player 1 (Ann) is inactive so we can ignore her payoffs, but her beliefs matter. Player 2 (Bob) is concerned about what Ann thinks about him. Acting boldly is dangerous, but worthwhile if Ann expects Bob to act boldly. GPS model the situation with a payoff function of the form u 2 : A × M 2 → R. Specifically, let α := μ 1  1 (bold|h 0 ) denote Ann's first-order belief about Bob (a random variable from Bob's point of view), and let β := αμ 2 2 (dμ 1 1 ) denote (a feature of) the Bob's second-order beliefs. GPS' payoff function is</p><formula xml:id="formula_45">u 2 (a 2 , μ 2 ) = 2 -β, if a 2 = bold, 3(1 -β), if a 2 = timid. We modify u 2 , considering instead u 2 : A × M → R defined by u 2 (a 2 , μ) = 2 -α, if a 2 = bold, 3(1 -α), if a 2 = timid.</formula><p>Clearly, the expectation of u 2 given a 2 and Bob's second-order belief β is u 2 . There are three equilibria, with β = α = 1, β = α = 0 and β = α = 1 2 . 35   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2.">Trust game with guilt aversion</head><p>Consider Γ 3 in Fig. <ref type="figure" target="#fig_2">3</ref> (or equivalently Γ 2 ). Recall that α (a function of μ 1 1 ) is the probability Ann assigns to strategy 'Share if Trust' at the beginning of the game, and β = αμ 2 2 (dμ 1 1 |Trust) 35 These are essentially the same equilibria as those obtained by GPS. But GPS allow for actual randomization; thus the first-order beliefs of Bob are degenerate on the equilibrium (mixed) strategy of Ann, and higher-order beliefs of each player are degenerate on the equilibrium lower-order beliefs of the other player. is the relevant feature of the conditional second-order beliefs of Bob. We let τ = μ 1 2 (Trust|h 0 ) denote Bob's initial first-order belief. An assessment is summarized by (τ, α, β), where (τ, α) corresponds to a behavior strategy profile. The indifference condition for Bob is β = 2 5 , the indifference condition for Ann is α = 1 2 ; consistency yields α = β. The game has three SEs: τ = α = β = 1 (trust), τ = α = β = 0 (no trust), and τ = 0, α = β = 2 5 (insufficient trust). Note that only the first equilibrium is consistent with forward induction reasoning (as described in Section 2, and further elaborated on in Subsection 5.1 below).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3.">Trust game with reciprocity</head><p>Our framework is adequate for modeling reciprocity in extensive games. To support this claim, we show how the essence of Dufwenberg and Kirchsteiger's theory can be captured in Γ 1 : Let α, β and τ be defined as in the previous example. The key tenets of the theory concern player i's kindness to player j (K ij ), and i's belief in j 's kindness to i ( Kiji ). At each history, player i maximizes utility defined by the sum of material payoffs (as in Γ 1 ) and reciprocity payoffs equal to θ i × K ij × Kiji , where θ i is a constant measuring i's sensitivity to reciprocity. Assume that Ann's and Bob's sensitivities are θ 1 = 0 and θ 2 = 4  3 . One can show that K ij and Kiji can be reproduced in our framework and notation; in particular we need the following: -Bob's kindness following Trust = -1 for Grab and = 1 for Share, -Bob's belief in Ann's kindness following Trust = 3 2β.</p><p>Γ 5 in Fig. <ref type="figure" target="#fig_4">5</ref> displays the relevant utilities as conceived by the players when they move (Bob is not active at h 0 , so we put no utility for him following Don't): 36  Applying Definition 7, Γ 5 has a unique SE with τ = 1, α = β = 3 4 . No 'pure' SE exists, 37 just like in Dufwenberg and Kirchsteiger's theory (cf. 6.3 below).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Interactive epistemology</head><p>We argued in Section 2 that alternatives to equilibrium analysis are worth exploring. The definition of M i provides us with all the ingredients to analyze strategic reasoning by means of 36 As with Γ 2 vs. Γ 3 , we can replace Bob's conditional second-order belief β with Ann's initial first-order belief α in Bob's payoffs, and get analogous conclusions. 37 In any SE we have α = β. With θ 2 = 4  3 , the indifference condition for Bob yields β = 3 4 . If α = β &lt; 3 4 then K212 shoots up, so Bob prefers Share to Grab, which in SE would imply α = β = 1, . . . a contradiction. If α = β &gt; 3  4 then K212 goes down, so Bob prefers Grab to Share, implying α = β = 0, . . . another contradiction.</p><p>interactive epistemology, i.e., assumptions about players' rationality and what they believe about each other at any node. We show how to express such assumptions in the language of events and belief operators (5.1), and then analyze a notion of extensive form rationalizability (5.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">States of the world, events, and belief operators</head><p>A state of the world specifies, for each player i and history h, what i would do and believe if h were reached. Note the subjunctive conditional: game-theoretic analysis does not only concern the actual path of actions and beliefs, but also considers how players would react (in terms of choices and beliefs) to histories that do not actually occur at the true state. The state of a player is therefore given by his strategy and his hierarchy of cps', (s i , μ i ) (as explained in Subsection 3.2 we interpret s i both as an objective description of i's contingent behavior and as i's plan of action). The set of states for player i is denoted by Ω i = S i × M i , and the set of states of the world is Ω = n i=1 Ω i . We let Ω -i = j =i Ω j denote the set of possible states of i's opponents. With a slight abuse of notation we often write Ω = Ω i ×Ω -i with typical element ω = (ω i , ω -i ).</p><p>An event is a (Borel) subset E ⊆ Ω; its complement is denoted ¬E = Ω\E. An event about i is any set of states E = E i × Ω -i , where E i is a Borel subset of Ω i . We let E i denote the family of events about i. Events about the opponents of i are similarly defined; the collection of such events is denoted E -i .</p><p>We often use brackets to denote specific events. In particular, for any function (random variable) x : Ω → X and value x * ∈ X, we use the notation</p><formula xml:id="formula_46">[x = x * ]: = {ω: x(ω) = x * }. When x is understood, we simply write [x * ]. For example, [s * i ] = {(s i , μ i , ω -i ): s i = s * i } ∈ E i is the event "i plays s *</formula><p>i "; here it is understood that x is the projection function x(s i , μ i , ω -i ) = s i . Similarly, [h] = i∈N S i (h) × M i is the event that history h occurs.</p><p>Recall that we follow both GPS and Battigalli and Siniscalchi <ref type="bibr" target="#b10">[11]</ref> in disregarding players' beliefs about themselves. At state ω = (s i , μ i , ω -i ), player i would believe event E = Ω i × E -i ∈ E -i conditional on history h with probability f i,h (μ i )(E -i ) (cf. Section 3.2). Thus {(s i , μ i , ω -i ): f i,h (μ i )(E -i ) = 1} is the event "i would believe E conditional on h." E may concern the beliefs of i's opponents.</p><p>We use belief operators to represent events about interactive beliefs: a belief operator for player i is a mapping with domain E -i and range E i . For any given history h ∈ H , the hconditional belief operator for i is defined as follows:</p><formula xml:id="formula_47">∀E = Ω i × E -i ∈ E -i , B i,h (E) = (s i , μ i , ω -i ): f i,h (μ i )(E -i ) = 1 .</formula><p>h may be counterfactual at ω, because strategies played at ω may not induce h; in this case "i would believe E conditional on h" is a counterfactual statement about i's beliefs at ω. Clearly, B i,h (E) ∈ E i . <ref type="foot" target="#foot_10">38</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B i,h (•) satisfies monotonicity [E ⊆ F implies B i,h (E) ⊆ B i,h (F )] and conjunction [B</head><formula xml:id="formula_48">i,h (E ∩ F ) = B i,h (E) ∩ B i,h (F )]. Furthermore B i,h (E) = B i,h (E ∩ [h]) because i always believes what he observes.</formula><p>The basic event we are interested in is players' rationality. We focus on a condition that does not distinguish between realization-equivalent strategies. Say that i is rational at state </p><formula xml:id="formula_49">(s * i , μ i , ω -i ) iff</formula><formula xml:id="formula_50">s i ∈S i (h) E s i ,μ i [u i |h] . (<label>7</label></formula><formula xml:id="formula_51">)</formula><p>The event "player i is rational" is</p><formula xml:id="formula_52">R i = {(s i , μ i , ω -i ): s i ∈ r i (μ i )}.</formula><p>It can be shown that r i (μ i ) can be obtained via a backward induction algorithm and that R i is a well-defined nonempty event (cf. proof of Lemma 14 in Appendix A).</p><p>To illustrate how these concepts can be used, we re-examine two psychological versions of the Trust Game. As regards notation, we have to distinguish the event "Bob shares," which in the extensive form implies that "Ann trusts Bob," from the event "Bob would share if Ann trusted Bob" which is a subjunctive conditional, logically independent on whether Ann trusts Bob or not. Similar considerations hold for the action Grab. We use bold letters to denote subjunctive conditionals (which in this case correspond to strategies of Bob), as in [Share] and <ref type="bibr">[Grab]</ref>.</p><p>Consider the Trust Game with guilt aversion Γ 3 in Fig. <ref type="figure" target="#fig_2">3</ref>. The game can be solved by forward induction reasoning: it is rational for Ann to trust Bob only if she assigns at least 50% probability to strategy Share, i.e. only if α 1 2 , where α : M 1 → R is the random variable defined by α(μ 1 ) = μ 1  1 (Share|h 0 ). <ref type="foot" target="#foot_11">39</ref> If Bob believes in Ann's rationality when he has to move (even if he is 'surprised'), he infers from Ann's action Trust that α 1 2 . Therefore β 1 2 , where β : M 2 → R is the random variable defined by β(μ 2 ) = α(μ 1 )f 2,Trust (μ 2 )(dμ 1 ). His rational response is to share. If Ann anticipates Bob's reasoning she trusts him.</p><p>The formal counterpart of this argument is as follows (the events listed are nonempty; we rely on the monotonicity of the belief operators):</p><formula xml:id="formula_53">R 1 = (s 1 , μ 1 , ω 2 ): α(μ 1 ) &gt; 1 2 ⇒ s 1 = Trust, α(μ 1 ) &lt; 1 2 ⇒ s 1 = Don't , R 2 = (ω 1 , s 2 , μ 2 ): β(μ 2 ) &gt; 2 5 ⇒ s 2 = Share, β(μ 2 ) &lt; 2 5 ⇒ s 2 = Grab , R 1 ∩ [Trust] ⊆ α 1 2 , B 2,Trust (R 1 ) = B 2,Trust R 1 ∩ [Trust] ⊆ B 2,Trust α 1 2 ⊆ β 1 2 , R 2 ∩ B 2,Trust (R 1 ) ⊆ R 2 ∩ β 1 2 ⊆ [Share], R 1 ∩ B 1,h 0 R 2 ∩ B 2,Trust (R 1 ) ⊆ R 1 ∩ [α = 1] ⊆ [Trust].</formula><p>Now consider the Trust Game with Reciprocity Γ 5 in Fig. <ref type="figure" target="#fig_4">5</ref>. Without an equilibrium supposition, one is at loss for predictive power: if θ 2 = 4 3 , Bob's best response depends on whether β is below or above</p><formula xml:id="formula_54">( 3 2 -1 θ 2 ) = 3 4 .</formula><p>This cannot be resolved by forward induction reasoning, which yields (as explained above) β 1  2 . However, if one uses other values of θ 2 one can draw clear conclusions merely using backward induction: if</p><formula xml:id="formula_55">θ 2 &lt; 2 3 , Bob's best response (given Trust) is Grab independently of β, thus R 2 ⊆ [Grab] and R 1 ∩ B 1,h 0 (R 2 ) ⊆ [Don't]; on the other hand, if θ 2 &gt; 2, R 2 ⊆ [Share] and R 1 ∩ B 1,h 0 (R 2 ) ⊆ [Trust]</formula><p>. Furthermore, a subtle issue arises when 2 3 &lt; θ 2 &lt; 1: backward induction cannot pin down Bob's best response, which is Grab only if β ( <ref type="formula" target="#formula_35">3</ref>2 -1 θ 2 ), while forward induction yields β 1 2 . This puts an upper bound on how kind Bob believes Ann is. 40 </p><formula xml:id="formula_56">With 2 3 &lt; θ 2 &lt; 1 the best response is Grab (formally, R 2 ∩ B 2,Trust (R 1 ) ⊆ [Grab], B 1,h 0 (R 2 ∩ B 1,Trust (R 1 )) ⊆ [α = 0] and R 1 ∩ B 1,h 0 (R 2 ∩ B 1,Trust (R 1 )) ⊆ [Don't]).</formula><p>One can show that the SE prediction implies 0</p><formula xml:id="formula_57">&lt; α = β = ( 3 2 -1 θ 2 ) &lt; 1 2</formula><p>, τ = 0. Thus, SE and forward induction reasoning yield the same path, but very different predictions about how Bob would revise his beliefs off that path. 41   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Rationalizability</head><p>The basic rationalizability concept for standard games is equivalent to iterated strict dominance and is motivated by the assumption that players are rational and there is common belief in rationality. Several modifications of rationalizability have been proposed, to handle sequential rationality and to reflect alternative epistemological assumptions. 42 In psychological games payoffs are affected by hierarchical beliefs, so rationalizability has to be defined as a property of a whole state of the world rather than of strategies. One could, e.g., stipulate that a state ω = (s i , μ i ) i∈N is rationalizable if at ω players are rational and there is common belief in rationality at the beginning of the game. 43  One could go on to examine an array of modifications. That is not our goal. Rather, we wish to indicate that the class of psychological games we have defined is amenable to interactive epistemology analysis in principle, and to illustrate the potential cutting power of such an approach. We provide tools to perform a particular forward-induction analysis. Following Battigalli and Siniscalchi <ref type="bibr" target="#b10">[11]</ref>, we first define a 'strong belief operator' SB i as follows: SB i (∅) = ∅ and</p><formula xml:id="formula_58">∀E ∈ E -i \{∅}, SB i (E) = [h]∩E =∅ B i,h (E).</formula><p>In words, SB i (E) is the event "player i would believe E conditional on every history that does not contradict E" 44 ; e.g., SB i ([s j ]) is the event "player i would believe player j plays s j at each history h allowed by s j ."</p><p>We are interested in events of the form SB i (R -i ∩ E), where R -i = j =i R j is the event that i's opponents are rational and E is either Ω or some event concerning beliefs, and we consider assumptions like "everybody strongly believes that the opponents are rational." To write this concisely, we define a mutual strong belief operator. Let E denote the collection of events of the form 40 The higher β, the more Bob believes that Ann's choice to trust him is self-interested. 41 This can happen in standard games too, but for different reasons and with more complex extensive forms (see, e.g., <ref type="bibr">Reny, 1992, [69]</ref>). Furthermore, we will show in Section 6 that in some psychological games SE and forward induction yield different paths! 42 See, e.g., <ref type="bibr">Battigalli and Bonanno [6]</ref>, Asheim <ref type="bibr" target="#b1">[2]</ref>, and references therein. 43 Here is an exact definition: for every event 44 SB i (•) is not a monotone operator, and satisfies only a weak form of conjunctiveness</p><formula xml:id="formula_59">E = i∈N E i (E i ∈ E i ). For example, R = i∈N R i ∈ E. For each E = i∈N E i ∈ E , the event "mutual strong belief in E" is SB(E) = i∈N SB i ( j =i E j ). Note that SB(E) ∈ E.</formula><formula xml:id="formula_60">E = i∈N E i , E i ∈ E i , let B(E) = i∈N B i,h 0 ( j =i E j ). Require that ω ∈ R ∩ ( k 1 B k (E)), where B k (E) = B k-1 (E).</formula><formula xml:id="formula_61">[SB i (E) ∩ SB i (F ) ⊆ SB i (E ∩ F )].</formula><p>For more on this, see <ref type="bibr" target="#b10">[11]</ref>.</p><p>We explore the consequences of the following assumptions:</p><formula xml:id="formula_62">(0) each player is rational [ = R], (1) mutual strong belief in (0) [ = SB(R)], (2) mutual strong belief in (0) &amp; (1) [ = SB(R ∩ SB(R))], (3) mutual strong belief in (0), (1) &amp; (2) [ = SB(R ∩ SB(R ∩ SB(R)))],</formula><p>and so on. . . . Such assumptions are more easily expressed with formulas if we introduce an auxiliary 'correct strong belief' operator:</p><formula xml:id="formula_63">∀E ∈ E, CSB(E) = E ∩ SB(E).</formula><p>The conjunction of assumptions (0)-(k) corresponds to the event CSB k (R), where for any <ref type="foot" target="#foot_12">45</ref> Rationalizability is defined by considering the limit as k → ∞:</p><formula xml:id="formula_64">E ∈ E, CSB 0 (E) = E and CSB k (E) = CSB(CSB k-1 (E)).</formula><formula xml:id="formula_65">Definition 11. A state of the world ω is rationalizable if ω ∈ k 0 CSB k (R).</formula><p>Battigalli and Siniscalchi <ref type="bibr" target="#b10">[11]</ref> show that the strategies consistent with event CSB k (R) in standard games are those surviving the first k + 1 steps of Pearce's <ref type="bibr" target="#b64">[65]</ref> extensive-form rationalizability procedure. This explains the terminology of Definition 11. To illustrate the concept, we note that it captures the forward induction solution of the Trust Game with guilt aversion (either Γ 2 or Γ 3 ). However, that conclusion requires only two layers of mutual correct strong belief: the solution obtains at all states ω ∈ CSB 2 (R).</p><p>To illustrate the full power of Definition 11, we analyze a Generalized Trust Game with guilt aversion, reminiscent of Ben-Porath and Dekel's <ref type="bibr" target="#b13">[14]</ref> money-burning game: Ann can either (evenly) distribute the total surplus of $2 (action D), or reinvest it in one out of L projects. Project = 1, . . . , L yields 2(1 + L ). Bob controls surplus distribution. He can either Grab or (evenly) Share. Trust denotes the action of investing in project , and Share denotes the conditional choice of sharing if Ann invests in project . Let α (μ 1 ) = μ 1  1 (Share |h 0 ) and β (μ 2 ) = α (μ 1 1 )μ 2 2 (dα (μ 1 1 )|Trust ). Assume that Ann's utility is her material payoff, whereas Bob is averse to guilt. Applying the guilt formula of Subsection 3.3, the players' utilities are given by</p><formula xml:id="formula_66">u i (D) = 1, i = 1, 2, u i (Trust , Share) = 1 + L , i = 1, 2, u 1 (Trust , Grab) = 0, u 2 (Trust , Grab) = 2 1 + L -θ 2 α 1 + L ,</formula><p>Bob (strictly) prefers to share the yield of project if and only if θ 2 β &gt; 1. For L = 1 and θ 2 = 5 2 we obtain Γ 3 , and the forward induction argument works if and only if θ 2 &gt; 2. When L &gt; 1 rationalizability yields the efficient sharing outcome also for much lower values of θ 2 :</p><p>Proposition 12. In the Generalized Trust Game with guilt aversion, if</p><formula xml:id="formula_67">θ 2 &gt; 1 + 1 L then, for every rationalizable state (s 1 , μ 1 , s 2 , μ 2 ), s 1 = Trust L , s 2 = (Share ) L =1 , α (μ 1 ) = β (μ 2 ) = 1 ( = 1, . . . , L).</formula><p>Proof. Available on request. 2</p><p>Our extension of Pearce's solution concept is well behaved: Theorem 13. If psychological utilities are continuous the set k 0 CSB k (R) of rationalizable states is nonempty and compact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof. By definition</head><formula xml:id="formula_68">CSB k+1 (R) = CSB CSB k (R) = CSB k (R) ∩ SB CSB k (R) ⊆ CSB k (R).</formula><p>We prove by induction that each element CSB</p><formula xml:id="formula_69">k (R) = k =0 CSB (R) of the nested sequence {CSB k (R)} k 0 is closed and nonempty. Lemma 3 implies Ω is compact; thus, the closed sub- set k 0 CSB k (R) is compact. Furthermore, the finite intersection property of compact spaces implies k 0 CSB k (R) = ∅.</formula><p>The argument relies on three preliminary results, proved in Appendix A:</p><formula xml:id="formula_70">Lemma 14. Correspondence r i : M i S i is nonempty valued. If u i is continuous, r i has a closed graph and R i is a nonempty closed set. Lemma 15. For every closed event E ∈ E , SB(E) is closed. Lemma 16. Let {E } =k =0 be a decreasing sequence of nonempty events in E (∅ = E k ⊆ E k-1 ⊆ • • • ⊆ E 0 ), then =k =0 SB(E ) is also nonempty.</formula><p>For notational convenience let CSB -1 (E) = Ω. We prove by induction that, for each k 0, CSB k (R) is nonempty closed and can be expressed as</p><formula xml:id="formula_71">CSB k (R) = R ∩ k-1 =-1 SB CSB (R) .</formula><p>Basis step. The statement is true for k = 0 because by Lemma 14 CSB 0 (R) = R is nonempty closed, and R can be expressed as</p><formula xml:id="formula_72">R = R ∩ Ω = R ∩ CSB -1 (R).</formula><p>Inductive step. Suppose the statement is true for each = 0, . . . , k, then</p><formula xml:id="formula_73">CSB k+1 (R) = CSB CSB k (R) = CSB k (R) ∩ SB CSB k (R) = R ∩ k-1 =-1 SB CSB (R) ∩ SB CSB k (R) = R ∩ k =-1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SB CSB (R) .</head><p>By the inductive hypothesis each CSB (R) is nonempty and closed ( = 0, . . . , k). By Lemma 15 also SB(CSB (R)) is closed ( = 0, . . . , k). R is also closed (Lemma 14). Hence CSB k+1 (R) is closed. {CSB (R)} =k =0 is a decreasing sequence of nonempty events in E. Therefore Lemma 16 implies that k</p><formula xml:id="formula_74">=-1 SB(CSB (R)) = ∅. Pick any ω = (s i , μ i ) i∈N ∈ k =-1 SB(CSB (R))</formula><p>. Since the latter is just an event about beliefs, modifying the strategies in ω we obtain another state in the same event. By definition of R, i∈N r i (μ i ) × {μ i } ⊆ R. By Lemma 14, r i (μ i ) = ∅. We get</p><formula xml:id="formula_75">∅ = i∈N r i (μ i ) × {μ i } ⊆ R ∩ k =-1 SB CSB (R) .</formula><p>Hence CSB k+1 (R) = ∅. This proves the inductive step, and the theorem. 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion and extensions</head><p>We compare our approach with that of GPS (6.1), consider imperfect information, chance moves, and asymmetric information (6.2), own-plan dependence, dynamic inconsistency, and multi-self utility (6.3), and finally discuss assumptions, solution concepts, and avenues for further research (6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Comparison with GPS</head><p>In Section 2 we presented our framework as a generalization of GPS. This is not literally true. The reason is twofold. First, GPS allow for imperfect information and chance moves. As we show below, these complications can be included in our framework. Second, GPS allow for actual randomization whereas we exclude it. Prima facie, this difference may seem immaterial. GPS assume players maximize expected (psychological) utility given beliefs, and in their framework there is no incentive to randomize. It might seem that the only role played by randomization is to guarantee the existence of equilibrium, a result we obtain by looking at equilibrium in beliefs. However, unlike standard games, in psychological games there may be a difference (to a player's utility) between a belief assigning probability one to a randomized choice that, say, picks a or b with probability 1  2 , and the belief that assigns probability 1 2 to each of a and b. These beliefs are equivalent if psychological utility functions satisfy a linearity property, which is not satisfied in all applications (see e.g. Sebald <ref type="bibr" target="#b71">[72]</ref>). Note, however, that one can deal with this by adding to the game explicit moves whereby a player chooses a lottery over elementary actions (which is what Sebald does). Now look at the version of GPS that is a special case of our framework: psychological games with utilities of the form u i : Z × M i → R, where M i is the space of infinite hierarchies of initial beliefs of i, and first-order beliefs are probability measures over pure strategies of i's opponents. How much is lost by restricting the analysis to such games? We have argued that many interesting phenomena such as sequential reciprocity, psychological forward induction, and regret cannot be analyzed. However, we can prove a partial equivalence result. Suppose the initial beliefs of others enter the utility, that is, u i : Z × j ∈N M j → R. Then there is a psychological game with utilities u i : Z × M i → R that has the same sequential equilibrium assessments as the former game. <ref type="foot" target="#foot_13">46</ref> This does not mean that in this class of games conditional higher-order beliefs are irrelevant. First, the equivalence result only concerns sequential equilibria, and we argued that the non-equilibrium analysis of psychological games is important (as exemplified by psychological forward induction). Second, our very definition of sequential equilibrium makes essential use of conditional beliefs. Having such beliefs in the framework is conceptually useful as it helps understanding the epistemic assumptions underlying the SE concept.</p><p>GPS define a 'psychological subgame perfect equilibrium' concept (p-SPE) in two steps. First, they define a 'psychological Nash equilibrium' as a situation in which each player's (randomized) strategy is an ex ante best reply to his hierarchy of beliefs and beliefs of all orders are correct. Then, they define a p-SPE as a psychological equilibrium profile (σ i , μ i ) i∈N such that (σ i ) i∈N is a subgame perfect equilibrium of the standard game with utility functions u i (•, μ i ) : Z → R (i ∈ N ). Remark 10 shows that our SE coincides with p-SPE for games with utility functions à la GPS. This result can be extended to games with imperfect information (replacing p-SPE with a similarly defined 'psychological sequential equilibrium' concept).</p><p>GPS also define a 'psychological trembling-hand perfect equilibrium' (p-TPE): (σ i , μ i ) i∈N is a p-TPE if it is a psychological equilibrium and (σ i ) i∈N is a trembling-hand perfect equilibrium of the standard game with utility functions u i (•, μ i ) : Z → R (i ∈ N ). They show that some games with continuous utility functions have no p-TPE. Yet, our argument to prove existence of SE (see the sketch in Subsection 4.2) shows that continuous games always have equilibria that can be obtained as the limit of ε-equilibria with trembles. These two results are mutually consistent because, even for the special case of games à la GPS, they concern different notions of trembling-hand perfection. GPS perturb the strategies, but not the beliefs; we perturb both, as equilibrium beliefs are determined by the strategies via the consistency condition. 47   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Imperfectly observable actions, chance moves, and asymmetric information</head><p>We chose to focus on games with observable actions and no chance moves for the sake of simplicity. But our concepts and results carry over to the more general case of games where past actions need not be perfectly observed and chance may play a role (as in GPS). Let N = {c, 1, . . . , n} where index c denotes the chance player, and let H i be the partition of the finite set of histories H into information sets of player i (i = c). Assume perfect recall holds. Then the set of strategy profiles consistent with any information set h of player i must have the form</p><formula xml:id="formula_76">S(h) = S i (h) × S -i (h) [where S i (h) := h∈h S i (h), S -i (h) := h∈h S -i (h)].</formula><p>Consider, for the first-order beliefs of player i, the collection of conditioning events {F i :</p><formula xml:id="formula_77">F i = S -i (h), h ∈ H i }. Let X k-1</formula><p>-i be the space of (k -1)-order uncertainty for player i; we obtain the set of k-order cps'</p><formula xml:id="formula_78">Δ H i (X k-1 -i ), and the k-order uncertainty space X k -i = X k-1 -i × j =i,0 Δ H j (X k-1 -j ). The resulting set of infinite hierarchies of cps' M i is homeomorphic to Δ H i (S -i × M -i ) via a belief mapping f i = (f i,h ) h∈H i .</formula><p>Note that H i specifies i's information at each node/history, including those where i is inactive and in particular including the terminal nodes. This would be redundant in standard games, but is is 'common knowledge' of the hierarchical beliefs, no observation will make the players change their mind about the initial beliefs of the opponents, hence for any consistent assessment u i and u i have the same set of maximizing actions at each history. (If the game has only one stage u i and u i are fully equivalent, i.e., they have the same best response correspondences.) 47 Kolpin <ref type="bibr" target="#b46">[47]</ref> makes a related point. crucial to model some belief-dependent motivations, such as regret or blame avoidance, whereby players' conditional beliefs matter even if they are inactive. 48  Let σ c = σ c (•|h) ∈ h∈H \Z Δ o (A c (h)) denote the strictly positive 'objective' probabilities of chance moves. It is routine to define closed and compact subsets of hierarchies Mi (i = 1, . . . , n) reflecting the assumption that each players's beliefs about the chance player c are determined by σ c and there is common certainty of this. The analysis of rationalizability is easily adapted to this environment. The definition of sequential equilibrium requires some care. An assessment (σ, μ) = (σ i , μ i ) n i=1 is consistent if there is a sequence of strictly positive behavioral strategy profiles σ k → σ such that for all i = 1, . . . , n, h ∈ H i , s -i ∈ S -i (h),</p><formula xml:id="formula_79">μ 1 i (s -i |h) = lim k→∞ Pr σ c (s c ) j =i,c Pr σ k j (s j ) s -i ∈S -i (h) Pr σ c (s c ) j =i,c Pr σ k j (s j )</formula><p>(since σ c is strictly positive, the denominator is positive), 49 and furthermore for all &gt; 1, μ i assigns probability 1 to μ -1 -i (cf. Definition 6). (σ, μ) is a sequential equilibrium if it is consistent and for all i = 1, . . . , n, h ∈ H i , s * i ∈ S i (h),</p><formula xml:id="formula_80">Pr σ i s * i h &gt; 0 ⇒ s * i ∈ arg max s i ∈S i (h) E s i ,μ i [u i |h],</formula><p>where E s i ,μ i [u i |h] is given by the obvious modification of formula <ref type="bibr" target="#b1">(2)</ref>. A straightforward adaptation of the trembling-hand argument used to prove Theorem 1 shows that if the utility functions are continuous a sequential equilibrium exists. This extended framework also allows to analyze situations with incomplete information, modeling them as games with asymmetric information about an initial chance move: at the empty history h 0 the only active player is c (chance), A c (h 0 ) = Θ, where Θ ⊆ Θ 0 × Θ 1 × • • • × Θ n , each player i observes only coordinate θ i of θ = (θ 0 , θ 1 , . . . , θ n ); θ may affect payoffs, or actions sets, or the probabilities of future chance moves. 50 This extension is important for applications. Unless one models interaction within a family or amongst friends, it is probably not realistic to assume that players know one another's psychological propensities. For example, in the analysis of Γ 2 (or Γ 3 ) we assumed that Ann knows that Bob's sensitivity to guilt is θ 2 = 5 2 , which may be a stretch. 51 Another example comes up in Caplin and Leahy's <ref type="bibr" target="#b21">[22]</ref> model of doctor-patient interaction: the patient's well-being depends on his anxiety and on whether or not he likes early resolution of uncertainty; the concerned doctor wants to help the patient but is uninformed of the nature of patient's preferences regarding resolution of uncertainty. Yet another reason to allow for incomplete information is that a player may care about the ex post beliefs of others about some of his characteristics, which are not common knowledge, as in the models of Bernheim 48 For example, the terminal information partition is crucial in Battigalli and Dufwenberg's <ref type="bibr" target="#b7">[8]</ref> model of guilt from blame and Tadelis' <ref type="bibr" target="#b76">[77]</ref> analysis of shame in a Trust Game. 49 Kreps and Wilson <ref type="bibr" target="#b50">[51]</ref> have a similar condition that refers to conditional probabilities of histories/nodes. 50 We do not present a more direct formalization of incomplete information psychological games for reasons of space.</p><p>A word of caution is in order. When incomplete information is represented as imperfect, asymmetric information about an initial chance move one introduces fictitious ex ante beliefs (the initial beliefs in the imperfect information extensive game). This does not affect the equilibrium analysis of standard games, but it is known to affect the rationalizable outcomes (see Battigalli et al. <ref type="bibr" target="#b6">[7]</ref> for a discussion), and it may as well affect the analysis when players have beliefdependent preferences. 51 Ample evidence in psychology suggests emotional sensitivities differ among people. See Krohne <ref type="bibr" target="#b51">[52]</ref> for a general discussion, and Tangney <ref type="bibr" target="#b77">[78]</ref> on guilt specifically. and Dufwenberg and Lundholm and several other economic models where agents are assumed to have an intrinsic concern about their reputation. 52  One final reflection relating to imperfect and asymmetric information before we proceed. Standard games of incomplete information can be regarded as a special case of our framework. We have already clarified in Section 2.1 how psychological games are different from games of incomplete information. But one may wonder whether our framework is "too general" in the following sense: Is it possible that the same qualitative behavior explained by psychological game models can be explained using standard games of incomplete information? The answer is No, although it is possible in some cases (see, for example, Levine <ref type="bibr" target="#b53">[54]</ref>, and Gul and Pesendorfer <ref type="bibr" target="#b39">[40]</ref> who put forward models of reciprocity featuring incomplete information about "behavioral types"). 53 The best way to see this is to remember that psychological preferences may be affected by players' beliefs at information sets where they are inactive, such as their terminal information sets. Changing this information typically alters predicted behavior. This comparative statics effect (which has been demonstrated experimentally by Tadelis <ref type="bibr" target="#b76">[77]</ref>) is impossible in standard games, because behavior predicted by sequential equilibrium or rationalizability in such games depends only on the information of players when they are active. 54   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Own-plan dependence, dynamic (in)consistency, and multi-self utility</head><p>We have argued that it is natural to let a player's utility depend directly on other players' plans, but have so far assumed it does not depend directly on his own plan. This allowed us to apply standard dynamic programming techniques and prove Theorem 13. We next show that allowing for own-plan dependence is natural and gives rise to an interesting form of dynamic inconsistency.</p><p>Consider the following version of the Trust Game: Ann can either trust Bob or opt out. If she opts out no surplus is created; if she trusts Bob the total surplus is $4 and Bob can either grab $3 or let Ann allocate the surplus (action Leave). If Bob let Ann choose the allocation, she can either split the surplus or reward Bob, giving him the $3 he could have grabbed. Now assume that if Ann gets less money than she expected she feels disappointed and that the anticipation of this negative feeling affects her decisions. This is captured by the following utility function:</p><formula xml:id="formula_81">u 1 (z, μ, s 1 ) = π 1 (z) -θ s 2 μ 1 1 s 2 h 0 π 1 ζ(s 1 , s 2 ) -π 1 (z)</formula><p>where θ is a sensitivity parameter and the term in brackets in the Ann's disappointment at z. Γ 6 in Fig. <ref type="figure" target="#fig_5">6</ref> builds on u 1 , and thereby turns out to exhibit own-plan dependent utility for Ann. We let u 2 (z, μ, s) = π 2 (z).</p><p>The utility assigned by Ann to terminal history (Trust, Grab) depends on her initial belief α = μ 1 1 (Leave|h 0 ), and on how she plans to behave if Bob leaves for her to allocate the surplus. The own-plan dependence arises because Ann cannot feel disappointed if she plans to reward Bob 52 Models with an intrinsic concern for reputation are sometimes presented as a reduced forms of repeated interaction models. See, for example, Morris <ref type="bibr" target="#b61">[62]</ref> and Ottaviani and Sorensen <ref type="bibr" target="#b63">[64]</ref>. 53 Gul and Pesendorfer offer a recursive construction of a canonical space of behavioral types. 54 Battigalli and Guaitoli <ref type="bibr" target="#b8">[9]</ref> put forward a notion of conjectural (or self-confirming) equilibrium that crucially depends on the terminal information structure. But such an equilibrium concept does not apply to one-shot interactions, as it is meant to capture, with a "static" definition, stable patterns of behavior in situations of recurrent interaction. (column R), since in this case the resulting material payoff is 1 regardless of what Bob chooses. For Ann to be disappointed at terminal history (Trust, Grab) requires that she plans to split and that α &gt; 0. In this case she (initially) expects a material payoff which is larger than her material payoff at history (Trust, Grab)</p><formula xml:id="formula_82">[(1 -α) × 1 + α × 2 &gt; 1]</formula><p>. The disappointment yields utility (1θα) (column S). The expected utility of plan (Trust, Split) is thus (1α) × (1θα)+ α × 2, which could be lower than 1 (in fact, even lower than 0) if θ is large enough. In this case, the ex ante expected utility maximizing plan is (Trust, Reward) (which prevents disappointment and yields 1). However, (Trust, Reward) is not dynamically consistent because the best choice after history (Trust, Leave) is to split. As a result there is no strategy that maximizes Ann's expected utility at the beginning of the game and also at history (Trust, Leave). Ann cannot commit to rewarding Bob, so she should initially maximize under the constraint that she would split in the endgame; the resulting outcome is Out. Such 'consistent planning' <ref type="bibr">(Strotz [76]</ref>) implies that Ann's strategy be immune to one-shot deviations. Therefore, the example shows that the One-Shot-Deviation principle (cf. Proposition 8) fails with own-plan dependence. A similar kind of dynamic inconsistency arises in Caplin and Leahy's <ref type="bibr" target="#b20">[21]</ref> theory of psychological expected utility, in work by Kőszegi and Rabin <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b49">50]</ref> on reference dependent preferences, and in Mariotti's <ref type="bibr" target="#b59">[60]</ref> abstract analysis of generalized extensive form games. These papers can be shown to be consistent with our extended framework allowing own-plan dependence. We now present an example where even the multi-self equilibrium fails to exist unless we allow for uncertainty about one's own strategy.</p><p>In game Γ 7 of Fig. <ref type="figure" target="#fig_6">7</ref> a pure strategy of Bob is immune to one-shot deviations if and only if it corresponds to a pure Nash equilibrium of the following game between two selves of Bob:</p><formula xml:id="formula_83">Bob \Bob r L R L 3, 0 1, 1 R 2, 3 2, 1</formula><p>This companion game has no pure equilibrium. The unique mixed equilibrium is</p><formula xml:id="formula_84">( 2 3 L + 1 3 R , 1 2 L + 1 2 R ).</formula><p>Working backwards, Ann's best reply is . This is the unique multi-self SE of Γ 7 .</p><p>This example suggests that in order to make rationality possible in psychological games with own strategy dependence we have to allow a player to be uncertain about her own strategy. This can be done, at the cost of additional complexity, within a richer framework where player i's first-order beliefs are defined over S rather than S -i (cf. Battigalli and Siniscalchi <ref type="bibr" target="#b9">[10]</ref>). Besides own-strategy dependence, a more direct way to allow for dynamic inconsistencies is to adopt a multi-self approach and model a player's preferences with an array of 'local' utility functions (u i,h : Z ×M×S → R) h∈H \Z . The sequential equilibrium analysis of Section 4 applies to this extended framework almost verbatim.</p><p>This formulation is relevant to reciprocity theory. We have already seen how our basic framework could reproduce Dufwenberg and Kirchsteiger's theory in an example (Γ 5 ). However, to handle general games one needs a multi-selves approach, and it is then possible to (essentially) reformulate Dufwenberg and Kirchsteiger's model (details are available on request).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Discussion of solution concepts</head><p>We have explained in Section 4 that SE relies on the assumption that players never change their beliefs about the (conditional) beliefs of their opponents. This assumption is questionable in standard games, and becomes even more questionable in psychological games where players' perceptions of opponents' intentions ("What is my co-player trying to achieve?") are key.</p><p>One way to assess the opponent's intention is to draw inferences about his unobservable beliefs from his observable actions via forward induction (FI) reasoning. It is well known that FI reasoning yields beliefs inconsistent with backward induction reasoning and, more generally, with sequential equilibrium (see, e.g., <ref type="bibr">Reny [69]</ref>). Yet in (generic) standard games at least one sequential equilibrium outcome is consistent with FI reasoning. 55 The following simultaneousmove example shows that this need not be true in games with belief-dependent preferences.</p><p>Let A 1 = {U, M, D}, A 2 = { , r}. Player 1 (row) only cares about his material payoff, whereas the preferences of 2 (column) also depend on his terminal second-order beliefs. Let</p><formula xml:id="formula_85">α 1 := μ 1 1 ( |h 0 ), β 2 (a 1 ) := E μ 2 [α 1 |a 1 ]. The game is described by the following table. r U 3, 4[β 2 (U ) -β 2 (D)] 0, 1 M 2, 4[β 2 (U ) -β 2 (D)] 2, 1 D 0, 4[β 2 (U ) -β 2 (D)]</formula><p>3, 1 55 For example, in generic finite games with complete and perfect information the backward induction terminal node is the same as the terminal node implied by extensive form rationalizability and the iterated deletion of weakly dominated strategies, even though the implied conditional beliefs about continuation strategies may well be very different, as shown by Reny <ref type="bibr" target="#b68">[69]</ref>. For finite games with imperfect information see Govindan and Wilson <ref type="bibr" target="#b37">[38]</ref>.</p><p>In a sequential equilibrium β 2 (U )β 2 (D) = 0, because all conditional second order beliefs assign probability one to the true value of α 1 . Therefore the SE outcome must be (D, r).</p><p>Forward induction implies that 2 would believe whenever possible that 1 is rational (see Section 5). Note that U (D) is a best reply to α 1 iff α 1 2 3 (α 1 1 3 ). Therefore FI implies that β 2 (U )β 2 (D) 1  3 . Hence 4[β 2 (U )β 2 (D)] &gt; 1, player 2 chooses , and anticipating this 1 chooses U . The FI outcome is (U, ).</p><p>This example suggests that it is reasonable to relax the consistency condition of SE to allow players to change their higher order beliefs at least when they observe unexpected moves by the opponents. Other conditions on updated beliefs (such as strong belief in rationality) may be imposed to obtain sharp predictions.</p><p>Another reason to relax consistency is the following. Suppose that, as suggested at the end of Section 6.3, we explicitly model a player's plan as a (possibly false or uncertain) belief about his own contingent behavior. Then a player's intentions are fully determined by his beliefs about himself and others, and the consistency condition of SE implies that (in games with complete information) players never change their beliefs about the co-players' intentions, no matter what they do. This trivializes the analysis of extensive form psychological games. For example, Bob can respond unkindly to an unexpectedly generous action by Ann simply because he initially believed, and continues to believe, that Ann meant to be unkind to him.</p><p>Finally, we note that it would be interesting to approach psychological games from a learning point-of-view. Here is the main issue to be aware of if this task is addressed: It is often argued that players learn to play some equilibrium because through recurrent play they come to hold correct beliefs about the opponents' actions (see, e.g., Fudenberg and Levine <ref type="bibr" target="#b32">[33]</ref> and references therein). This may not be enough for psychological games; since payoffs depend on hierarchical beliefs, players would have to be able to learn others' beliefs, but unlike actions beliefs are typically not observable ex post. This suggests that a different notion of equilibrium is worth exploring, whereby beliefs are required to be consistent with observed outcomes, as in the conjectural/self-confirming equilibrium concept. <ref type="foot" target="#foot_14">56</ref> The interactive epistemology analysis of self-confirming equilibrium in (standard) signaling games by Battigalli and Siniscalchi <ref type="bibr" target="#b10">[11]</ref> may provide a useful starting point. tain a well-defined decision tree that can be solved by backward induction: define value functions V μ i : H → R and V μ i : (H \Z) × A i → R as follows</p><p>• For terminal histories z ∈ Z, let V μ i (z) := S -i ×M -i u i (z, μ i , μ -i , s -i )f i,z (μ i )(ds -i , dμ -i ).</p><p>• Assuming that V μ i (h, a) has been defined for the immediate successors (h, a) of history h, let</p><formula xml:id="formula_86">V μ i (h, a i ) := a -i ∈A -i (h) μ 1 i S -i (h, a -i ) h V μ i h, (a i , a -i ) ;</formula><p>for each a i ∈ A i (h); then V μ i (h) is defined as</p><formula xml:id="formula_87">V μ i (h) := max a i ∈A i (h)</formula><p>V μ i (h, a i ).</p><p>Recall that, for any strategy s i ∈ S i , H i (s i ) = {h ∈ H \Z: s i ∈ S i (h)} denotes the set of histories allowed by s i . The proof of the following result is available by request: Lemma 17. The sequential best reply correspondence r i : M i S i can be characterized as follows r i (μ i ) = s i : ∀h ∈ H (s i ), s i,h ∈ arg max</p><formula xml:id="formula_88">a i ∈A i (h) V μ i (h, a i ) .</formula><p>Proof of Lemma 14. By Lemma 17 r i (μ i ) = {s i : ∀h ∈ H (s i ), s i,h ∈ arg max a i ∈A i (h) V μ i (h, a i )}. Clearly, the RHS is nonempty. Therefore r i (•) is nonempty-valued and R i is nonempty. The belief function f i is continuous (Lemma 3). If u i is also continuous, then E s i ,μ i [u i |h] is continuous (in μ i ), which implies that R i is closed. 2 Proof of Lemma 15. We must show that for every closed event E ∈ E -i , SB i (E) is closed. SB i (∅) = ∅, a closed set, by definition. Suppose that E = Ω i × E -i where E -i is nonempty and closed. Recall that SB i (E) = h:[h]∩E =∅ B i,h (E). For each h,</p><formula xml:id="formula_89">B i,h (E) = S i × f -1 i,h Δ E -i ∩ S -i (h) × M -i × Ω -i ,</formula><p>where for any measurable space X and any F ⊆ X we let Δ(F ) denote the set of probability measures on X that assign probability one to F . Note that if F is closed, Δ(F ) is also closed. The coordinate function f i,h : M i → Δ(Ω -i ) is continuous and M -i is closed (Lemma 3); hence E -i ∩ (S -i (h) × M -i ), Δ(E -i ∩ (S -i (h) × M -i )) and f -1 i,h (Δ(E -i ∩ (S -i (h) × M -i ))) are closed. It follows that B i,h (E) (h ∈ H ) and SB i (E) are closed. 2 Proof of Lemma 16. Let {E } =k =0 be a decreasing sequence of nonempty events in E (∅ = E k ⊆ E k-1 ⊆ • • • ⊆ E 0 ); we show that =k =0 SB(E ) is also nonempty. For each and i, E ∈ E can be written E = E i × E -i , where E -i ⊆ Ω -i , and by definition of SB(•)</p><formula xml:id="formula_90">=k =0 SB E = i∈N =k =0 SB i Ω i × E -i .</formula><p>Therefore we must show that =k =0 SB i (Ω i × E -i ) = ∅ (i ∈ N ). Let Δ H (Ω -i ; E -i ) denote the set of cps' μ ∈ Δ H (Ω -i ) such that μ(E -i |h) = 1 for each h such that E -i ∩(S -i (h)×M -i ) = ∅. Note that</p><formula xml:id="formula_91">=k =0 SB i Ω i × E -i = S i × f -1 i =k =0 Δ H Ω -i ; E -i × Ω -i .</formula><p>We show below that =k =0 Δ H (Ω -i ; E -i ) = ∅. Since f i is onto (Lemma 3), it follows that f -1 i ( =k =0 Δ H (Ω -i ; E -i )) = ∅. Hence =k =0 SB i (Ω i × E -i ) = ∅. We show that =k =0 Δ H (Ω -i ; E -i ) = ∅ with a recursive construction. Say that h is 'reached' by probability measure ν ∈ Δ(Ω -i ) if ν(S -i (h) × M -i ) &gt; 0. Note that if h is reached by ν, every predecessor of h is also reached by ν. Say that μ(•|h) is 'derived' from ν, where ν reaches h, if for every Borel set</p><formula xml:id="formula_92">F -i ⊆ Ω -i μ(F -i |h) = ν(F -i ∩ (S -i (h) × M -i )) ν(S -i (h) × M -i ) .</formula><p>Pick any probability measure ν in the (nonempty) set Δ(E k -i ). For each h reached by ν let μ(•|h) be derived from ν. Thus, μ(•|h) has been defined for a nonempty set of histories closed w.r.t. precedence (that is, if h is in the set every predecessor of h is in the set), the set is nonempty because it contains the initial history h 0 . Now suppose that μ(•|h) has been defined for some set of histories Ĥ closed w.r.t. precedence. If Ĥ = H , for each h ∈ H \ Ĥ such that the immediate predecessor of h belongs to Ĥ , pick a probability measure ν h in the set Δ(E (h) -i ∩ (S -i (h) × M -i )), where (h) is the highest index ∈ {-1, 0, . . . , k} such that E -i ∩ (S -i (h) × M -i ) = ∅, and by convention we let E -1 = Ω -i . Let μ(•|h ) be derived from ν h whenever h weakly follows h and is reached by ν h . Now μ(•|h) is defined for a set of histories Ĥ closed under the precedence relation and strictly larger than Ĥ . Proceed in this way until the whole H is covered. We claim that the resulting vector of probability measures (μ(•|h)) h∈H is a cps μ ∈ =k =0 Δ H (Ω -i ; E -i ).</p><p>To see that (μ(•|h)) h∈H is a cps we only have to check that the 'chain rule' (3) in Definition 1 holds. Suppose that h precedes h . To write formulas more transparently, let C = S -i (h) × M -i , C -i = S -i (h ) × M -i , μ(•|h) = μ(•|C -i ), μ(•|h ) = μ(•|C -i ). Since h precedes h , S -i (h ) ⊆ S -i (h), hence C -i ⊆ C -i . If h is not reached by μ(•|C -i ) then (3) holds trivially as 0 = 0. If h is reached by μ(•|C -i ), then μ(•|C -i ) and μ(•|C -i ) are both derived from the same measuresay ν ∈ Δ(Ω -i ) -reaching both h and h ; thus, for every Borel set</p><formula xml:id="formula_93">F -i ⊆ C -i μ(F -i |C -i ) = ν(F -i ) ν(C -i ) = ν(F -i ) ν(C -i ) ν(C -i ) ν(C -i ) = μ F -i C -i μ C -i C -i .</formula><p>To see that μ ∈ =k =0 Δ H (Ω -i ; E -i ), note that by construction μ(E (h) |h) = 1 for all h ∈ H . Suppose that, for any index ∈ {0, . . . , k} and any h ∈ H , E -i ∩ (S -i (h) × M -i ) = ∅. Then (h) and μ(E |h) μ(E (h) |h) = 1; hence μ(E |h) = 1 as desired. 2</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Trust game Γ 1 with material payoffs.</figDesc><graphic coords="6,132.11,67.54,198.00,99.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Psychological trust game Γ 2 .</figDesc><graphic coords="6,130.61,199.44,201.06,102.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Psychological Trust Game Γ 3 .</figDesc><graphic coords="7,137.67,67.21,198.00,102.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Modified Trust Game Γ 4 with material payoffs.</figDesc><graphic coords="8,121.61,67.21,219.06,102.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Trust Game Γ 5 with reciprocity payoffs.</figDesc><graphic coords="19,106.17,67.21,260.28,102.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Psychological game Γ 6 : aversion to disappointment.</figDesc><graphic coords="29,127.16,67.45,219.06,108.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Psychological game Γ 7 .</figDesc><graphic coords="30,128.11,67.52,205.56,108.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>i . More formally, let H i (s * i ) = {h ∈ H \Z: s * i ∈ S i (h)} denote the set of non-terminal histories allowed by s * i ; we require s i ∈ r(μ i ) where</figDesc><table><row><cell>r i (μ i ) := s  *  i : ∀h ∈ H (s  *  i ), s  *  i ∈ arg max</cell></row></table><note><p><p><p>s * i maximizes i's conditional expected utility E s i ,μ i [u i |h] (defined in (</p>2</p>)) con-ditional on each history h allowed by s *</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>See Dufwenberg and Gneezy<ref type="bibr" target="#b26">[27]</ref>, Guerra and Zizzo<ref type="bibr" target="#b38">[39]</ref>, Bacharach, Guerra and Zizzo<ref type="bibr" target="#b4">[5]</ref>, Charness and Dufwen-</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_1"><p>For a more precise comparison between our framework and GPS see Subsection 6.1.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_2"><p>Rabin [68]  (see p. 23 and footnote 16) also provides a hilarious autobiographical sequential-move example reminiscent of our Example 2 of the Introduction.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_3"><p>We do not suggest that Γ 3 is interesting only in providing a convenient alternative way to analyzing Γ 2 ; the emotion modeled in Γ 3 may make sense in its own right, as a primitive assumption about preferences (akin to Examples 3 and 4 of the Introduction).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_4"><p>This point has been anticipated by Caplin and Leahy<ref type="bibr" target="#b20">[21]</ref>. Mariotti<ref type="bibr" target="#b59">[60]</ref> also makes a similar point, but not in the context of psychological games.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16" xml:id="foot_5"><p>Note also that Ann's anticipation of feeling let down might affect her initial decision. This can be modeled by letting</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="18" xml:id="foot_6"><p>A topological space X is Polish if it admits a compatible metric d such that (X, d) is a complete and separable metric space (see, e.g.,<ref type="bibr" target="#b45">[46]</ref>, p. 13).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_7"><p>(•|Trust)  is the conditional second-order belief of player 2 used to compute the expectation β of the probability α initially assigned by 1 to the strategy 'Share if Trust.'</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="24" xml:id="foot_8"><p>Bell [13]  and Loomes and Sugden<ref type="bibr" target="#b56">[57]</ref> present decision-theoretic models of belief-dependent disappointment. What</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="30" xml:id="foot_9"><p>Kreps and Wilson [51]  show that (in standard games) sequential equilibrium is generically equivalent to trembling hand perfect equilibrium.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="38" xml:id="foot_10"><p>For any Borel setΩ i × E -i , B i,h (Ω i × E -i ) is also a Borel set because the h-coordinate belief function f i,h is continuous (see Lemma 3).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="39" xml:id="foot_11"><p>In some formulas, we have to make explicit the dependence of random variable α on the state of the world. The same holds for random variable β.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="45" xml:id="foot_12"><p>For example, (0) &amp; (1) &amp; (2) is R ∩ SB(R) ∩ SB(R ∩ SB(R)) = CSB 2 (R).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="46" xml:id="foot_13"><p>The intuition is relatively simple: each initial belief hierarchy μ i induces a probability measure f i (μ i ) ∈ Δ(S -i × M -i ) which can be used to compute an expectation u i (z, μ i ) of u i (z, μ i , •). Since in a consistent assessment there</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="56" xml:id="foot_14"><p>See, for example, Battigalli and Guaitoli<ref type="bibr" target="#b8">[9]</ref> and Fudenberg and Levine<ref type="bibr" target="#b31">[32]</ref>.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Geir Asheim, Oliver Board, Adam Brandenburger, Andrew Caplin, Amanda Friedenberg, Drew Fudenberg, Georg Kirchsteiger, Botond Koszegi, Jing Li, David Pearce, Ludovic Renou, Klaus Ritzberger, Joel Sobel, and participants in several seminars for helpful discussions. For their kind hospitality, we thank the Economics Departments of the Stern School of Business at NYU, the European University Institute (Battigalli), and Göteborg University (Dufwenberg). We gratefully acknowledge financial support from Bocconi University and MIUR (Battigalli)  and from the NSF (Dufwenberg).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A</head><p>We start with some preliminaries about rationality and backward induction on belief-induced decision trees, and then prove Lemmata 14, 15 and 16. For any fixed hierarchy of cps' μ i , we ob-</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Experimental evidence for attractions to chance</title>
		<author>
			<persName><forename type="first">W</forename><surname>Albers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Selten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vogt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ger. Econ. Rev</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="113" to="130" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The Consistent Preferences Approach to Deductive Reasoning in Games</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Asheim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A survey of psychological games: Theoretical findings and experimental evidence</title>
		<author>
			<persName><forename type="first">G</forename><surname>Attanasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nagel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Games, Rationality and Behaviour. Essays on Behavioural Game Theory and Experiments</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Innocenti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Sbriglia</surname></persName>
		</editor>
		<imprint>
			<publisher>Palgrave McMillan, Houndmills</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="204" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Epistemic conditions for Nash equilibrium</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Aumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Brandenburger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="1161" to="1180" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The self-fulfilling property of trust: An experimental study</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bacharach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Guerra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Zizzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory Dec</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="349" to="388" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Recent results on belief, knowledge and the epistemic foundations of game theory</title>
		<author>
			<persName><forename type="first">P</forename><surname>Battigalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bonanno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Res. Econ</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="149" to="226" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Interactive epistemology and solution concepts for games with asymmetric information</title>
		<author>
			<persName><forename type="first">P</forename><surname>Battigalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Di Tillio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Penta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>Mimeo, Bocconi University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<author>
			<persName><forename type="first">P</forename><surname>Battigalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dufwenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Guilt in games</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="170" to="176" />
		</imprint>
	</monogr>
	<note>Amer. Econ. Rev.</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<author>
			<persName><forename type="first">P</forename><surname>Battigalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Guaitoli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conjectural equilibria and rationalizability in a game with incomplete information</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Battigalli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Montesano</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Panunzi</surname></persName>
		</editor>
		<imprint>
			<publisher>Kluwer Academic Publishers</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="97" to="124" />
		</imprint>
	</monogr>
	<note>Decisions, Games and Markets</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Hierarchies of conditional beliefs and interactive epistemology in dynamic games</title>
		<author>
			<persName><forename type="first">P</forename><surname>Battigalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Siniscalchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Theory</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="188" to="230" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Strong Belief and Forward Induction Reasoning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Battigalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Siniscalchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Theory</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="356" to="391" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Regret in decision making under uncertainty</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Bell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="961" to="981" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Disappointment in decision making under uncertainty</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Bell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Signaling future actions and the potential for sacrifice</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ben-Porath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dekel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Theory</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="36" to="51" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Rationalizable strategic behavior</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bernheim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="1007" to="1028" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A theory of conformity</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bernheim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Polit. Economy</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="841" to="877" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Sequential reciprocity in two-player, two-stages games: An experimental analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bouckaert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dhaene</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>Mimeo, University of Antwerp and Catholic University of Leuven</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Hierarchies of beliefs and common knowledge</title>
		<author>
			<persName><forename type="first">A</forename><surname>Brandenburger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dekel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Theory</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="189" to="198" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fear as a policy instrument: Economic and psychological perspectives on intertemporal choice</title>
		<author>
			<persName><forename type="first">A</forename><surname>Caplin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Time and Decision</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Loewenstein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Read</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Baumeister</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Russell Sage Foundation</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">AIDS policy and psychology: A mechanism design approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Caplin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Eliaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">RAND J. Econ</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="631" to="646" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Psychological expected utility theory and anticipatory feelings</title>
		<author>
			<persName><forename type="first">A</forename><surname>Caplin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leahy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quart. J. Econ</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="55" to="79" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The supply of information by a concerned expert</title>
		<author>
			<persName><forename type="first">A</forename><surname>Caplin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leahy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econ. J</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="487" to="505" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Promises and partnership</title>
		<author>
			<persName><forename type="first">G</forename><surname>Charness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dufwenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="1579" to="1601" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Marital investment, time consistency and emotions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dufwenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Behav. Organ</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="57" to="69" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Time-consistent Wedlock with endogenous trust, Doctoral Dissertation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dufwenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<pubPlace>Uppsala University</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Dufwenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gaechter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hennig-Schmidt</surname></persName>
		</author>
		<title level="m">The framing of games and the psychology of play</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>Mimeo, University of Arizona, University of Nottingham, and University of Bonn</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Measuring beliefs in an experimental lost wallet game</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dufwenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Gneezy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Games Econ. Behav</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="163" to="182" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Reciprocity and wage undercutting</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dufwenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kirchsteiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Europ. Econ. Rev</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="1069" to="1078" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A theory of sequential reciprocity</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dufwenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kirchsteiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Games Econ. Behav</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="268" to="298" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Social norms and moral hazard</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dufwenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lundholm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econ. J</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page" from="506" to="525" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A theory of reciprocity</title>
		<author>
			<persName><forename type="first">A</forename><surname>Falk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Fischbacher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Games Econ. Behav</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="293" to="315" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Self-confirming equilibrium</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fudenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="523" to="545" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">The Theory of Learning in Games</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fudenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Levine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">D</forename><surname>Fudenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tirole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Game</forename><surname>Theory</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">The Hangman paradox and the Newcomb&apos;s paradox as psychological games, Cowles Foundation Discussion Paper No</title>
		<author>
			<persName><forename type="first">J</forename><surname>Geanakoplos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">1128</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><surname>Geanakoplos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Stacchetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Psychological games and sequential rationality</title>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="60" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Information dependent games: Can common sense be common knowledge?</title>
		<author>
			<persName><forename type="first">I</forename><surname>Gilboa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schmeidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econ. Letters</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="215" to="221" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">On forward induction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Govindan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wilson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
		<respStmt>
			<orgName>Mimeo, Department of Economics, University of Iowa, and Stanford Business School, Stanford University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Trust responsiveness and beliefs</title>
		<author>
			<persName><forename type="first">G</forename><surname>Guerra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Zizzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Behav. Organ</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="25" to="30" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">The canonical type space for interdependent preferences</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pesendorfer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>Mimeo, Princeton University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Games of incomplete information played by Bayesian players. Parts I, II, III</title>
		<author>
			<persName><forename type="first">J</forename><surname>Harsanyi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Manage. Sci</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="486" to="502" />
			<date type="published" when="1967">1967-1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">More order without more law: A theory of social norms and organizational cultures</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-M</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Law, Econ., Organ</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="390" to="406" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Social pressure, uncertainty, and cooperation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Huck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kübler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econ. Governance</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="199" to="212" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Utility theory with probability dependent outcome valuation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Karni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Theory</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="111" to="124" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Utility theory with probability dependent outcome valuation: Extensions and applications</title>
		<author>
			<persName><forename type="first">E</forename><surname>Karni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Schlee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Risk Uncertainty</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="127" to="142" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Kechris</surname></persName>
		</author>
		<title level="m">Classical Descriptive Set Theory</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Equilibrium refinements in psychological games</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kolpin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Games Econ. Behav</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="218" to="231" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Emotional agency</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kőszegi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quart. J. Econ</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="121" to="156" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A model of reference-dependent preferences</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kőszegi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rabin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quart. J. Econ</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page" from="1133" to="1166" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Reference-dependent risk attitudes</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kőszegi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rabin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Amer. Econ. Rev</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="1047" to="1073" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Sequential equilibrium</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kreps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="863" to="894" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Individual differences in emotional reactions and coping</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Krohne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Affective Sciences</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Davidson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Goldsmith</surname></persName>
		</editor>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="698" to="725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Extensive games and the problem of information</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Contributions to the Theory of Games II</title>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Kuhn</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Tucker</surname></persName>
		</editor>
		<meeting><address><addrLine>Princeton, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="1953">1953</date>
			<biblScope unit="page" from="193" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Modeling altruism and spitefulness in experiments</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rev. Econ. Dynam</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="593" to="622" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">The power of convention: A theory of social preferences</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Behav. Organ</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="489" to="505" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Regret theory: An alternative theory of rational choice under uncertainty</title>
		<author>
			<persName><forename type="first">G</forename><surname>Loomes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sugden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econ. J</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="805" to="824" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Disappointment and dynamic consistency in choice under uncertainty</title>
		<author>
			<persName><forename type="first">G</forename><surname>Loomes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sugden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rev. Econ. Stud</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="271" to="282" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Rational&apos; decision making versus &apos;rational&apos; decision modeling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Machina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Psychology</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="163" to="175" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Dynamic consistency and non-expected utility models of choice under uncertainty</title>
		<author>
			<persName><forename type="first">M</forename><surname>Machina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Lit</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="163" to="175" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Strategic extensive form games: Definitions and comments on sequential rationality, with an application to rational procrastination</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mariotti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<pubPlace>Mimeo, Queen Mary</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of London</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Formulation of Bayesian analysis for games with incomplete information</title>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Mertens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Game Theory</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Political correctness</title>
		<author>
			<persName><forename type="first">S</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Polit. Economy</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page" from="231" to="265" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rubinstein</surname></persName>
		</author>
		<title level="m">A Course in Game Theory</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Reputational cheap talk</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ottaviani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sorensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">RAND J. Econ</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="155" to="175" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Rationalizable strategic behavior and the problem of perfection</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pearce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="1029" to="1050" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Biases from omitted risk effects in standard gamble utilities</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pope</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Health Econ</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="695" to="735" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<author>
			<persName><forename type="first">M</forename><surname>Rabin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Incorporating fairness into game theory and economics</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="1281" to="1302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Psychology and economics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rabin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Lit</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="11" to="46" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Backward induction, normal form perfection and explicable equilibria</title>
		<author>
			<persName><forename type="first">P</forename><surname>Reny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="626" to="649" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">On a new axiomatic theory of probability</title>
		<author>
			<persName><forename type="first">A</forename><surname>Renyi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Math. Acad. Sci. Hungaricae</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="285" to="335" />
			<date type="published" when="1955">1955</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Gift giving with emotions</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Ruffle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Behav. Organ</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="399" to="420" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Procedural concerns and reciprocity, ECARES Discussion Paper 2007/62</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sebald</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>Universite Libre de Bruxelles</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Tit for tat: Foundations for preferences for reciprocity in strategic settings</title>
		<author>
			<persName><forename type="first">U</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Theory</title>
		<imprint>
			<biblScope unit="volume">136</biblScope>
			<biblScope unit="page" from="197" to="216" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Re-examination of the perfectness concept for equilibrium points in extensive games</title>
		<author>
			<persName><forename type="first">R</forename><surname>Selten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Game Theory</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="25" to="55" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Interdependent preferences and reciprocity</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Lit</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="392" to="436" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Myopia and inconsistency in dynamic utility maximization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Strotz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rev. Econ. Stud</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="165" to="180" />
			<date type="published" when="1956">1956</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">The power of shame and the rationality of trust</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tadelis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Mimeo, UC Berkeley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Recent advances in the empirical study of shame and guilt</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Tangney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Amer. Behav. Sci</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1132" to="1145" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
