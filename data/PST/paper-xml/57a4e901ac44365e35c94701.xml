<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Tag-Aware Recommender Systems Based on Deep Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2016-04-06">April 6, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yi</forename><surname>Zuo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jiulin</forename><surname>Zeng</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Maoguo</forename><surname>Gong</surname></persName>
							<email>gong@ieee.org</email>
						</author>
						<author>
							<persName><forename type="first">Licheng</forename><surname>Jiao</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Tag-Aware Recommender Systems Based on Deep Neural Networks</orgName>
								<address>
									<settlement>Neurocomputing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">International Research Center for Intelligent Perception and Computation</orgName>
								<orgName type="laboratory">Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education</orgName>
								<orgName type="institution">Xidian University</orgName>
								<address>
									<postCode>710071</postCode>
									<settlement>Xi&apos;an</settlement>
									<region>Shanxi Province</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Tag-Aware Recommender Systems Based on Deep Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2016-04-06">April 6, 2016</date>
						</imprint>
					</monogr>
					<idno type="MD5">03D83A85D1F0783D20F8E2C7456045EF</idno>
					<idno type="DOI">10.1016/j.neucom.2015.10.134</idno>
					<note type="submission">Received date: 13 March 2015 Revised date: 20 October 2015 Accepted date: 22 October 2015 Preprint submitted to Elsevier</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Recommender systems</term>
					<term>tag information</term>
					<term>redundancy</term>
					<term>ambiguity</term>
					<term>deep neural networks</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Many researchers have introduced tag information to recommender systems to improve the performance of traditional recommendation techniques. However, user-dened tags will usually suer from many problems, such as sparsity, redundancy, and ambiguity. To address these problems, we propose a new recommendation algorithm based on deep neural networks. In the proposed algorithm, users' proles are initially represented by tags and then a deep neural network model is used to extract the in-depth features from tag space layer by layer. In this way, representations of the raw data will become more abstract and advanced, and therefore the unique structure of tag space will be revealed automatically.</p><p>Based on those extracted abstract features, users' proles are updated and used for making recommendations. The experimental results demonstrate the usefulness of the proposed algorithm and show its superior performance over the clustering based recommendation algorithms. In addition, the impact of network depth on the algorithm performance is also investigated.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>With the surge of Internet users and tremendous development of individual communication terminals, everyday user-generated data makes people have to face huge information, from which, nding out relevant items for a given user is a big problem to be solved urgently. Therefore, as a useful tool to lter out irrelevant information, recommender systems have attracted increasing attention <ref type="bibr" target="#b0">[1]</ref> in recent years. Adopting knowledge discovery technology, recommender systems can predict users' future preferences and behaviors according to history records. Thus far, recommendation systems have successfully found applications in diverse elds, such as book recommendations in Amazon.com <ref type="bibr" target="#b1">[2]</ref>, video recommendations in TiVo.com <ref type="bibr" target="#b2">[3]</ref>, and movie recommendations in Netix.com <ref type="bibr" target="#b3">[4]</ref>.</p><p>Many dierent prediction techniques have been proposed to generate personalized recommendations. Due to its simplicity and promising results, Collaborative Filtering (CF) has been one of the most successful and widely used methods in recommender systems <ref type="bibr" target="#b4">[5]</ref>. The core assumption of CF is that users who have expressed similar interests in the past will share common interests in the future <ref type="bibr" target="#b5">[6]</ref>. As described in <ref type="bibr" target="#b6">[7]</ref>, CF can be classied into two major types: as memory-based CF and model-based CF.</p><p>According to the exploited information, memory-based CF is categorized as user based or item based. In user-based CF, a user's rating on a target item is based on the ratings that several similar users have given to that item in the past <ref type="bibr" target="#b7">[8]</ref>. In contrast to user-based CF, item-based CF predicts the rating of the target item based on the ratings that the user has given to other similar items <ref type="bibr" target="#b7">[8]</ref>. Model-based CF uses the user-item matrix to train prediction models, such as Bayesian network model <ref type="bibr" target="#b8">[9]</ref> and matrix factorization <ref type="bibr" target="#b9">[10]</ref>. However, in real-life recommender systems, one user will only rate quite a small fraction of all items and one item is usually rated by a small proportion of all users.</p><p>Hence the rating matrix is so sparse that it is dicult to nd similar users or items because of lacking information <ref type="bibr" target="#b10">[11]</ref>.</p><p>To obtain more useful information about users, many websites introduce a kind of web-based systems, known as social tagging systems <ref type="bibr" target="#b11">[12]</ref>. The systems allow users to freely label items with arbitrary words <ref type="bibr" target="#b12">[13]</ref>, namely userdened tags. By introducing those tags, recommender systems with tag information (tag-aware recommender systems) <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref> are more useful and applied to lots of online sites, such as Del.icio.us (with tags of bookmark), Flickr (with tags of images) and Last.Fm ! (with tags of music).</p><p>User-dened tags can reect both users' preferences and evaluations on items. From this perspective, tags can be seen as bridges between users and items. Especially, different users usually assign dierent tags even to the same items, which may benet personalized recommendations a lot. In addition, tag information can help solve the coldhttp://delicious.com/ http://www.flickr.com/ ! http://www.last.fm/ start problem in recommender systems <ref type="bibr" target="#b15">[16]</ref>.</p><p>Nevertheless, not all the tags benet recommendations <ref type="bibr" target="#b16">[17]</ref>. Arbitrarily associated by users, tags may form an uncontrolled vocabulary, which usually leads to two common situations <ref type="bibr" target="#b17">[18]</ref>: (i) similar meanings are expressed with dierent words, which will be treated as dierent tags in tagging systems, such as bike and bicycle; (ii) polysemy, for example, Hummer may indicate a buzzer, while it can also represent the brand of a famous car from General Motors Corporation. These issues often cause information redundant and ambiguous and prevent from uncovering the underlying structure or relations among tags.</p><p>To solve those issues, researchers usually apply clusteringbased methods to recommender systems. By clustering <ref type="bibr" target="#b18">[19]</ref>, redundant tags will be aggregated into the same cluster. Discovering the feature of a cluster is more easily than discovering that of a single tag. In addition, the meaning of a tag is shared by the other tags in the same cluster, so the ambiguity can be alleviated at the same time. However, in tag clustering methods, computing tags' similarities accurately is an essential precondition, but intractable due to data sparsity. In addition, tag features need to be represented by extra data, such as the information of items, leading to higher complexity. Hence, it is necessary to nd a more straightforward and eective method to address the tag information.</p><p>Because of its excellent performance on extracting eective representations of raw data <ref type="bibr" target="#b19">[20]</ref>, deep neural networks have been applied in many elds, such as image classication [2123] and natural language processing <ref type="bibr">[2426]</ref>. Especially, some researchers have tried to exploit deep neural networks to improve the performance of traditional recommendation algorithms recently. For example, in <ref type="bibr" target="#b26">[27]</ref>, deep belief network (DBN) was used to music recommendation by learning features from audio data. Similarly, convolutional neural network (CNN) was introduced to music recommendation in <ref type="bibr" target="#b27">[28]</ref>.</p><p>As described in <ref type="bibr" target="#b19">[20]</ref>, deep architectures are more abstract representations and generally invariant to most local changes of the input data. Thus the extracted abstract and invariant features can detect categories in more varied phenomena and potentially have greater predictive power. In social tagging systems, although tags given by a user often change, the user's preference is usually invariant. Accordingly, with the help of deep neural networks, it is possible to learn more abstract features from user's tag space and then user's latent preference will be uncovered by those extracted features. Motivated by this, we propose a recommendation algorithm based on deep neural networks.</p><p>In the proposed algorithm, a deep neural network model is rst used to extract more abstract features form the tag information. Then, we adopt user-based CF to generate recommendations based on these features. In this paper, the sparse autoencoder <ref type="bibr" target="#b28">[29]</ref> is selected as the deep neural network model. For convenience, the proposed algorithm is denoted as CFA.</p><p>The main contribution of this paper is to exploit a deep neural network for tackling the tag information so as to improve the recommendation performance. The advantages of using the deep neural network are as follows:</p><p>X Through the deep neural network, the latent features, which are much denser, can be extracted layer by layer. Then users' proles are updated with those extracted features. Therefore, using the deep neural network can overcome the diculty of data sparsity.</p><p>X The number of neurons in the hidden layers is much smaller than that in the input layer. Accordingly, the dimensionality of the data in the hidden layers is lower than that of the input data. In the other words, using the deep neural network can reduce the dimensionality of data.</p><p>X By using the deep neural network, we can learn more abstract and representative latent features of varied tag information. Hence the redundancy and ambiguity of tag information can be diminished in some extent.</p><p>The proposed algorithm is tested on two real datasets.</p><p>Experimental results demonstrate that the deep neural network can improve the recommendation performance of traditional CF eectively. Comparison results also show that the propose algorithm outperforms the clusteringbased CF approaches. In addition, the impact of network depth in the sparse autoencoder is analyzed.</p><p>The remainder of this paper is organized as follows. Section 2 reviews some background, including some typical tag-aware recommendation models and related work on tag-aware recommendations. In section 3, the proposed recommendation algorithm based on deep neural networks is described in detail. Section 4 reports the experimental results. Finally, conclusions are given in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Tag-Aware Recommendation Models</head><p>Formally, a social tagging system typically consists three communities: users, items and tags. A folksonomy in tagaware recommender systems is usually modeled as a tuple <ref type="bibr" target="#b12">[13]</ref>:</p><formula xml:id="formula_0">F = (U, I, T, Y ),<label>(1)</label></formula><p>where U , I, T are nite sets and represent users set, items set and tags set, respectively. Y indicates the ternary relations among users, items, and tags and is denoted by a 3-order tensor (3-dimensional array):</p><formula xml:id="formula_1">Y = (y u,i,t ) ∈ R |U |×|I|×|T | (2)</formula><p>where y u,i,t = 1 if user u has assigned tag t to item i, and y u,i,t = 0 otherwise.</p><p>From the folksonomy, the model of tag-aware recommender systems can be considered in two ways <ref type="bibr" target="#b17">[18]</ref> : (i) the binary relations which are denoted by three adjacent matrices: A U I , A U T , A IT for user-item, user-tag and itemtag, respectively. (A U I ) u,i = 1 if item i is tagged with any tag by user u, otherwise (A U I ) u,i = 0 . Analogously, if tag t is adopted by user u, (A U T ) u,t will be set as 1, otherwise 0 and (A IT ) i,t = 1 if item i is tagged with tag t, otherwise 0; (ii) a ternary structure: only the complete ternary relation (u, i, t) is taken into account. Consider the ternary relation as a hypergraph and predict the unknown links by the graph theory.</p><p>Basically, the recommendations in social tagging systems have three dierent types: items, tags and users <ref type="bibr" target="#b29">[30]</ref>.</p><p>Tag recommendation predicts relevant tags of items to a target user based on the tags other users have provided for the same items. It helps users to annotate an item by providing a set of correct and unambiguous tags. The recommendation of users is to recommend friends to a target user in social tagging systems. Friends are those users who have common interests with the target user. The aim of item recommendation is to recommend relevant items to users, which is the same as in traditional recommender systems. The dierence is that tagging information can be exploited in tag-aware recommender systems. Given that the most urgent problem in information era is to lter irrelevant items for users <ref type="bibr" target="#b17">[18]</ref>, the recommendation of items based on tagging information is mainly considered in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Related Work</head><p>So far, a variety of recommendation algorithms have been proposed for social tagging systems. In traditional recommender systems, the most widely used recommendation technique is CF. However, traditional CF can only operate on second-order tensors representing a binary relation between users and items. To extend CF to social tagging systems, the ternary relation between users, items, and tags should be reduced to a lower dimensional space <ref type="bibr" target="#b30">[31]</ref>, which is the rst model of tag-aware recommender systems described above. Based on this model, a CF based tag-aware recommendation method was proposed in <ref type="bibr" target="#b31">[32]</ref>,</p><p>where the user neighborhood based on the user-tag projection matrix is rst computed and then the recommendation is generated by aggregating the items of the neighborhood. A similar idea was presented in <ref type="bibr" target="#b32">[33]</ref>, where the user-tag projection matrix is used to compute a ranked list of tags and the recommendation of items is extracted according those tags. In <ref type="bibr" target="#b33">[34]</ref>, Karen et al. proposed an approach to extend the typical user-resource matrix with tags as pseudo users and pseudo items. Then, a fusion algorithm by combining user-based CF and item-based CF methods was presented. In order to make better use of tagging information, tag clustering was adopted in CF to improve the recommendation performance <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b34">35]</ref>. To address the noisiness of tags, Liang et al. <ref type="bibr" target="#b35">[36]</ref> used dierent weights for dierent tags and combined them with traditional memory-based CF.</p><p>By representing Y as a tensor, we can exploit the underlying latent semantic structure formed by the ternary correlations between users, tags, and items <ref type="bibr" target="#b29">[30]</ref>. This can be obtained by recommendation algorithms based on tensor factorization. In <ref type="bibr" target="#b36">[37]</ref>, the higher-order singular value decomposition (HOSVD) <ref type="bibr" target="#b37">[38]</ref> is used to factorize the useritem-tag tensor to the product of three low-rank matrices and a low-rank core tensor. The results on two real data sets show signicant improvements in recall and precision metrics. Rendle et al. <ref type="bibr" target="#b38">[39]</ref> proposed RTF (ranking with tensor factorization), a method for learning an optimal factorization for the specic problem. In stead of minimizing the least-squares as in HOSVD based methods, RTF maximizes the ranking statistic AUC (area under the ROCcurve).</p><p>In graph-based recommendation algorithms, the ternary relation between users, tags, and items is considered as a hypergraph, and a tag-based network is constructed. Inspired by the well-known web search algorithm PageRank <ref type="bibr" target="#b39">[40]</ref>, Hotho et al. <ref type="bibr" target="#b12">[13]</ref> proposed FolkRank algorithm, in which an item tagged with important tags by important users becomes important itself and this principle holds for users and tags symmetrically. Based on that principle, users, items and tags will mutually reinforce each other's weights. Then several items or tags with larger weights will be recommended. Zhang et al. <ref type="bibr" target="#b40">[41]</ref> rstly proposed a tagaware diusion-based method based on the user-item-tag tripartite graph. The results demonstrate that the incorporation of the tags can enhance the accuracy and diversication of recommendations. Shang et al. <ref type="bibr" target="#b41">[42]</ref> presented two kinds of similarities between users based on tripartite graphs, which are then integrated for recommendation.</p><p>In addition, other information obtained from social tagging systems can be used to improve the recommendation performance. <ref type="bibr" target="#b42">[43]</ref> presented a comparative study on the inuence that dierent types of information available in social tagging systems, such as tags, social contacts, and user-item interaction data, have on item recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Deep Neural Networks based Tag-Aware Recommendation Algorithm</head><p>In this section, we will describe the proposed recommendation algorithm based on deep neural networks in detail.</p><p>More specically, the proposed algorithm consists three main procedures. At rst, the users' proles are modeled as vectors over tags. Then, a deep neural network is used to discover latent features from the users' tag space.</p><p>Finally, aggregate the extracted features and items information to generate recommendations. The illustration of the proposed algorithm is depicted in Fig. <ref type="figure">1</ref>. More details are presented in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Representations of Users' Proles</head><p>As reviewed above, in social tagging systems, representations of users' proles are composed of three elements: ... Based on the projection π U T Y , the prole of user u is modeled as a vector over the set of tags and represented by</p><formula xml:id="formula_2">X u = ((π U T Y ) u,1 , (π U T Y ) u,2 , ..., (π U T Y ) u,|T | ).<label>(3)</label></formula><p>Then, a deep neural network will learn the latent features in user-tag space based on Eq. (3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Processing Tag Information via Deep Neural Networks</head><p>In contrast to clustering-based recommendation algorithms, the proposed algorithm introduces the deep neural network to social tagging systems for dealing with complicated tag information. In this paper, the sparse autoencoder is adopted as the deep neural network model. In the following subsection, we describe the details about the sparse autoencoder to process tag information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Sparse Autoencoder</head><p>An autoencoder neural network is a three-layer network:</p><p>an input layer, a hidden layer and an output layer. An input layer and a hidden layer form an encoder. Symmetrically, hidden layer and output layer form a decoder, which tries to reconstruct the input data in the output layer. An illustration of an autoencoder is displayed in Fig. <ref type="figure" target="#fig_1">3</ref>. Note that the dimensionality of the output layer is equal to that of the input layer. Consider an unlabeled dataset {x (1) , x (2) , • • • , x (m) }. Through the activation function, nonlinear representations of the input data will be obtained in the hidden layer <ref type="bibr" target="#b19">[20]</ref>. For a given example x (i) , the representation is</p><formula xml:id="formula_3">h(x (i) ; W, b) = σ(W x (i) + b), (<label>4</label></formula><formula xml:id="formula_4">)</formula><p>where W is the weight matrix between the input and output layer, b is the bias of the input layer, and δ is the activation function, which is typical to be the sigmoid or the hyperbolic tangent function.</p><p>Then through the decoder, the input data is reconstructed in the output layer by minimizing the error between the input data and the output data: To learn more interpretable features for machine learning applications, sparse coding was applied to learning models <ref type="bibr" target="#b43">[44]</ref>. Sparse coding aims at representing input vectors approximately as a weighted linear combination of a small number of "basis vectors", which can capture highlevel patterns in the input data. So as to learn more eective features, Andrew et al. combined sparse coding with the autoencoder <ref type="bibr" target="#b44">[45]</ref>, namely sparse autoencoder. The key idea is to penalize the deviation between the expectation of hidden representations E[h j (x; W, b)] and a preset average activation ρ. In practice, ρ is set to be close to zero, and then hidden units will be sparsely activated. As described in <ref type="bibr" target="#b28">[29]</ref>, the sparsity penalty term is computed through Kullback-Leibler (KL) divergence <ref type="bibr" target="#b45">[46]</ref> between the expectation of hidden representations and a preferred activation ratio of hidden units.:</p><formula xml:id="formula_5">min W,b,c m ∑ i=1 ||σ(W T h(x (i) ; W, b) + c) -x (i) || 2 , (<label>5</label></formula><formula xml:id="formula_6">)</formula><formula xml:id="formula_7">P = n ∑ j=1 D KL (ρ||ρ j ),<label>(6)</label></formula><p>where</p><formula xml:id="formula_8">D KL (ρ||ρ j ) = ρ log ρ ρj + (1 -ρ) log 1-ρ 1-ρj , ρj = 1 m</formula><p>∑ m i=1 h(x (i) ; W, b), and n is the number of hidden units.</p><p>Bring the penalty term into the objective above:</p><formula xml:id="formula_9">min W,b,c m ∑ i=1 ||σ(W T h(x (i) ; W, b) + c) -x (i) || 2 + βP, (<label>7</label></formula><formula xml:id="formula_10">)</formula><p>where β controls the weight of the sparsity penalty term.</p><p>Note that the network we have discussed above just contains only one hidden layer. If more hidden layers are stacked into the network, a deep autoencoder (also called stacked autoencoders) will be established. To train the deep network, Hinton et al. <ref type="bibr" target="#b28">[29]</ref> proposed a layer-by-layer learning algorithm, which is absolutely a good way to train the stacked autoencoders. In the algorithm, rst consider the raw data as the input to train the rst hidden layer, and then treat the activation values of the rst hidden layer as the input to train the second hidden layer. Repeat this procedure until all layers have been trained well. In this paper, we will adopt this method to learn parameters in the deep network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Learning Features by Sparse Autoencoder</head><p>Firstly, representation of each user is computed by Eq.</p><p>(3). Therefore, all users' proles form a user-tag matrix.</p><p>Note that this matrix is also quite sparse. Besides, the dimensionality of the matrix is high because the number of tags is large. Secondly, the matrix is inputted into the sparse autoencoder, and then lower dimensional and more abstract representations of users will be obtained in hidden layers:</p><formula xml:id="formula_11">Xu = (a 1 , a 2 , ..., a k ),<label>(8)</label></formula><p>where a k represents the k-th latent factor and k is usually smaller than the number of tags.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Making Recommendations based on Extracted Features</head><p>Based on those extracted features of user-tag space, users' proles are updated. Traditional CF only use π U I Y or π U T Y to recommend items or tags respectively, which leads to non-occurrence of tags or items. To aggregate tags and items information, we adopt the method proposed in <ref type="bibr" target="#b31">[32]</ref>.</p><p>At rst, the user neighborhood N u of the target user u is obtained by computing similarities as follows:</p><formula xml:id="formula_12">sim u,v = &lt; Xu , Xv &gt; || Xu |||| Xv || . (<label>9</label></formula><formula xml:id="formula_13">)</formula><p>Then we can predict the rating of the target user u to item i by</p><formula xml:id="formula_14">S u,i = ∑ v∈Nu sim u,v • (π U I Y ) v,i . (10)</formula><p>Finally, according to the predicted ratings, top-n items with larger scores will be recommended. Note that the user-tag matrix is used to nd similar users and the useritem matrix is used to make recommendation of items based on the similar users in the proposed algorithm. In this way, the ternary relation between users, items, and items is exploited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Computational Complexity of The Proposed Algorithm</head><p>We denote m, l, and d as the total number of users, items, and tags, respectively. The size of the threedimensional tensor Y is thus m × l × d. The computational complexity of the proposed CFA depends on the following three steps:</p><p>(1) Computation of projection: In order to acquire the user representation based on tag information, we need to do a linear scan in Y with a complexity of O(mld).</p><p>(2) Learning features by the sparse autoencoder: The computational cost of this step is mainly consumed by optimizing the weight parameters in sparse autoencoder through L-BFGS. In L-BFGS, the gradient of the objective function needs to be computed. However, to avoid the complex matrix inverse operator, the Hessian inverse is approximated based on historical information from c previous iterations, where c is a small positive integer <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b47">48]</ref>.</p><p>The complexity of L-BFGS in one iteration is thus linear on the number of parameters to be optimized. For the rst layer of sparse autoencoder, the total number of optimized parameters is l × n 1 , where n 1 is the number of neurons in the rst layer. The complexity of this optimization pro-</p><formula xml:id="formula_15">cess is O(l × n 1 × c × iter 1 )</formula><p>, where iter 1 is the number of iterations for L-BFGS. Since the convergence speed of L-BFGS is usually fast, iter 1 is relative small. For the sparse autoencoder with k hidden layers, if we denote îter as the average number of iterations, the step of learning features by sparse autoencoder results in a complexity of O(l × c ×iter× ∑ i=k i=1 n i ).</p><p>(3) Making recommendations based on extracted features: At rst, we need to nd out the user neighborhood N u to the target user according to Eq. ( <ref type="formula" target="#formula_12">9</ref>). Computing the user similarities will result in a complexity of O(m 2 Xu ), where Xu is the scale of the extracted fea- tures. The complexity of sorting these similarities to ob-</p><formula xml:id="formula_16">tain user neighborhood N u is O(m 2 log |N u |).</formula><p>Then, the predicted scores of items are calculated by Eq. ( <ref type="formula">10</ref>) and top-n items are recommended, which will result in a com-</p><formula xml:id="formula_17">plexity of O(l |N u | log n) totally.</formula><p>Accordingly, the whole complexity of the proposed al-</p><formula xml:id="formula_18">gorithm is O(mld + l × c ×iter× ∑ i=k i=1 n i + m 2 Xu + m 2 log |N u | + l |N u | log n).</formula><p>Obviously, the complexity of traditional CF as in <ref type="bibr" target="#b31">[32]</ref> is O(mld</p><formula xml:id="formula_19">+ m 2 l + m 2 log |N u | + l |N u | log n).</formula><p>Note that additional computation cost is incurred by the step of learning feature and linear on the depth of sparse autoencoder. However, to obtain more dense and abstract features, we decrease the number of neurons layer by layer. In this way, the incurred cost is reduced and the resulting Xu will be less than l, having an eect of dimension reduction.  e) The number of neurons in the second hidden layer:</p><formula xml:id="formula_20">n 3 = 800.</formula><p>f ) The size of the user neighborhood: |N u | = 90.</p><p>For some parameters in sparse autoencoder, such as the average activation ρ and the weight of the sparsity penalty β, we use the empirical values. For other parameters, such as the number of neurons in the hidden layers, we determine their values based on experiments. For example, in sparse autoencoder, we need to determine the number of neuron in the hidden layers, since the number of neurons in the input or the output layer is equal to the total number of the used tags. At rst, the sparse autoencoder with only one hidden layer is considered. We vary the number of neurons in the hidden layer from 100 to 1000 with a step of 100, and perform the ve-fold cross validation to obtain the optimum value. Then similar implementations are conducted to nd optimum value for the number of neurons in the second layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Evaluation Metrics</head><p>In practice, users usually only consider the top-n items of the recommendation list. Precision and recall are the most popular metrics based on the length of the recommendation list <ref type="bibr" target="#b49">[50]</ref>. Precision represents the proportion of the number of relevant recommended items from the length of the recommendation list. For a given user u, the precision of the recommendation is dened as:</p><formula xml:id="formula_21">p u (L) = d u (L) L , (<label>11</label></formula><formula xml:id="formula_22">)</formula><p>where L is the length of the recommendation list for user u, and d u (L) represents the number of items which are really liked by user u in the recommendation list. Recall indicates the proportion of the number of relevant recommended items from the number of items which are relevant in the probe set. The recall of user u is dened as:</p><formula xml:id="formula_23">r u (L) = d u (L) D u , (<label>12</label></formula><formula xml:id="formula_24">)</formula><p>where D u is the number of target user's interested items in the probe set. Recall can measure the probability of users interested items in the recommendation list.</p><p>When the length of the recommendation list is not small, users will give greater importance to the items that appear in the front of the recommendation list. In other words, the mistakes incurred in these items are more serious than those in the last items on the list <ref type="bibr" target="#b49">[50]</ref>. Based on this observation, Zhou et al. <ref type="bibr" target="#b50">[51]</ref> proposed a new metric called the rank score, which is dened as:</p><formula xml:id="formula_25">rs u,i = pos i (L) B u , (<label>13</label></formula><formula xml:id="formula_26">)</formula><p>where pos i (L) indicates the position of item i in the recommendation list, and B u represents the number of items, which are uncollected by user u. For example, if there are 1000 uncollected items for the target user u, and the interested item i is the 20th in the recommendation list, then for user u, the rank score of item i is 20/1000, denoted by rs u,i = 0.02. Obviously, a good recommendation algorithm is expected to yield small rs. The rank score of a recommendation algorithm can be obtained by averaging all users' rank scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.">Comparison Results</head><p>To show the advantage of the proposed algorithm,we compare it with CFA-Layer1 with standard CF without preprocessing the tags space and the clustering-based CF (denoted by CFC). In the experiments, the sparse autoencoder with two hidden layers are used. For convenience, the proposed algorithm is denoted as CFA-Layer2. As proved in <ref type="bibr" target="#b51">[52]</ref>, the hierarchical clustering method performs better than k-means and maximal complete link in the tag space. Therefore, the hierarchical clustering method is adopted in our experiments.        The experimental results are shown in Fig. <ref type="figure">5</ref> and Tables 2-5. It can be seen that with the increase of the depth, the performance of CFA is improved gradually. Generally, more hidden layers in the neural network indicate better performance. Note that the number of neurons in each hidden layer is set as {1000, 800} and {1000, 800, 400} in CFA-Layer2 and in CFA-Layer3, respectively. As the number of neurons deceases layer by layer, the dimensionality of extracted features will be much lower than that of the input data. In addition, the extracted latent features will be much denser in the hidden layers of the deep neural network. Hence the updated data through the deep neural network will become more abstract and representative than the raw data, which is of high dimensionality and sparsity. From another perspective, information redundancy and ambiguity can be diminished layer by layer.</p><p>However, the performance may improve little when the number of hidden layers is more than two in our experiments. Especially, in some cases, CFA-Layer3 performs worse. For example, as shown in Table <ref type="table" target="#tab_1">2</ref>, CFA-Layer3 is beaten by CFA-Layer2 on Last.Fm dataset in terms of the precision metric when the length of the recommendation list is 25. Similar results are observed in Table <ref type="table" target="#tab_1">2</ref>, when the length of the recommendation list is set as 80 for Del.icio.us dataset. As discussed above, the increase of the depth in the sparse autoencoder will inevitably produce more computing cost. To balance the performance and the computational complexity, the suitable depth of the deep neural network for those two datasets is set as two. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: Illustration of CF with Stacked Autoencoders for Tag-Aware recommender systems</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Illustration of autoencoder</figDesc><graphic coords="6,95.00,53.23,406.22,713.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>items which were tagged by that user. The task of recommendation algorithms is to recommend items (artists for Last.Fm and URLs for Del.icio.us) to users based on the users' tag information. For each dataset, 80% of the whole data is selected as the training set and the remaining 20% of the data constitutes the probe set. Recommendations are generated based on the known information in the training set, and then the probe set is used to evaluate the performance of recommendation algorithms. All experiments are implemented in Matlab on an Intel (R) Core i7 computer with 2.00 GHz CPU and 8.00 GB memory.In the proposed algorithm, the cost function in sparse autoencoder is optimized by the L-BFGS method. Specically, We use the L-BFGS in minFunc by Mark Schmidt % . Note that the default values for the optimiza- tion parameters in L-BFGS, such as line search parameters, are used in the experiments. Other parameters in the proposed algorithm are set as follows. " http://www.last.fm.com # http://delicious.com $ http://ir.ii.uam.es/hetrec2011/datasets.html % http://www.cs.ubc.ca/~schmidtm a) The average activation: ρ = 0.1. b) The weight of the sparsity penalty term: β = 3. c) The depth of the sparse autoencoder: K = 2. d) The number of neurons in the rst hidden layer: n 2 = 1000.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Results of CF, CFC, and CFA-layer2 on two datasets based on precision, recall, and rank score metrics. Figures (a), (c), (e) are for Last.fm dataset, and the remaining gures for Del.icio.ous dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>× 10 -4 3.31 × 10 -4 4.75 × 10 -4 4.92 × 10 -4 5.41 × 10 -4 25 3.27 × 10 -4 3.83 × 10 -4 7.61 × 10 -4 7.87 × 10 -4 8.66 × 10 -4 50 2.95 × 10 -4 3.81 × 10 -4 5.07 × 10 -4 5.25 × 10 -4 5.26 × 10 -4 80 3.48 × 10 -4 3.83 × 10 -4 4.95 × 10 -4 5.33 × 10 -4 5.12 × 10 -4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>4 25 2 . 20 × 3 50 8 . 40 × 3 80 1 . 50 ×</head><label>422038403150</label><figDesc>× 10 -4 6.23 × 10 -4 6.08 × 10 -4 5.58 × 10 -4 5.54 × 10 -10 -3 1.80 × 10 -3 2.10 × 10 -3 2.00 × 10 -3 1.80 × 10 -10 -3 6.40 × 10 -3 6.50 × 10 -3 6.12 × 10 -3 5.81 × 10 -10 -2 1.43 × 10 -2 1.31 × 10 -2 1.22 × 10 -2 1.13 × 10 -2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>50 4. 30 × 5 80 1 . 36 ×Figure 5 :</head><label>503051365</label><figDesc>Figure 5: Results of CFA-layer1, CFA-layer2, and CFA-layer3 on two datasets based on precision, recall, and rank score metrics. Figures (a), (c), (e) are for Last.fm dataset, and the remaining gures for Del.icio.ous dataset.</figDesc><graphic coords="10,95.00,53.23,406.22,713.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Taking advantage of powerful abilities of learning representations in deep neural networks, we have proposed a new tag-aware recommendation algorithm. In the proposed algorithm, a deep neural network model, namely the sparse autoencoder, is used to discover the in-depth features of tag space. Instead of the raw data, the extracted features, which become more abstract, representative, and dense, are used for user-based CF to make recommendations. The performance of the proposed algorithm has been examined on two real datasets. Experimental results indicate that the introduction of the deep neural network can largely improve the recommendation performance of traditional user-based CF. Comparison results also show that the proposed algorithm outperforms clustering-based CF approaches in terms of three metrics, including the precision, the recall and the rank score, which reveals that the deep neural network can deal with redundant and ambiguous tag information more eectively than clustering techniques. Experiments on the proposed algorithm with dierent number of hidden layers demonstrate that deeper architectures can work better if the depth of the neural network is set appropriately.The eectiveness of processing tag information with deep neural networks has been demonstrated in this paper. However, the performance of the proposed algorithm can still be improved. Future research work is to make a further study on using deep neural networks for recommender systems, including the following aspects: 1) absorbing other deep neural networks to process tag information; 2) applying deep neural networks to deal with other information in recommender systems; 3) using the proposed algorithm to address other datasets, such as movies, books, and mobile apps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Statistic Description of Two Datasets</figDesc><table><row><cell></cell><cell>Users</cell><cell>Items</cell><cell>Tags</cell></row><row><cell>Last.Fm</cell><cell>1808</cell><cell>12212</cell><cell>2305</cell></row><row><cell>De.licio.us</cell><cell>1843</cell><cell>65877</cell><cell>3508</cell></row><row><cell cols="2">4. Experimental Studies</cell><cell></cell><cell></cell></row><row><cell cols="4">4.1. Test Datasets and Parameter Settings</cell></row><row><cell cols="4">In our experiments, we use two real website datasets, in-</cell></row><row><cell cols="4">cluding Last.fm and Del.icio.us, which are released in the</cell></row><row><cell cols="4">framework of the 2nd International Workshop on Informa-</cell></row><row><cell cols="4">tion Heterogeneity and Fusion in Recommender Systems</cell></row><row><cell cols="4">to make an evaluation [49]. The rst dataset is obtained</cell></row><row><cell cols="4">from Last.fm online music system " , which allows users to</cell></row><row><cell cols="4">tag music tracks and artists. In this dataset, the users are</cell></row><row><cell cols="4">interconnected in a social network generated from Last.fm</cell></row><row><cell cols="4">friend relations and each user has a list of most listened</cell></row><row><cell cols="4">music artists and tag assignments. Note that we only take</cell></row><row><cell cols="4">artists as items to be recommended in this dataset. The</cell></row><row><cell cols="4">second dataset is obtained from a popular social book-</cell></row></table><note><p><p><p><p>marking system, Del.icio.us # , which allows users not only to store and organize their personal bookmarks (URLs), but also to tag and share these web bookmarks. In this dataset, the users are interconnected in a social network generated from Del.icio.us mutual fan relations and each user has bookmarks and tag assignments. Both datasets can be downloaded from the website of HetRec 2011 $ .</p>To cut down the amount of calculation, we pick out those tags which are used more than 5 times in Last.Fm dataset and 15 times in Del.icio.us dataset. The statistic descriptions of the two data sets are presented in Table</p>1</p>. Note that a user is considered to be interested in those</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Precisions on Last.Fm dataset for some typical lengths of recommendation list. 10 -2 3.73 × 10 -2 3.89 × 10 -2 3.99 × 10 -2 4.05 × 10 -2 25 2.18 × 10 -2 2.29 × 10 -2 2.34 × 10 -2 2.50 × 10 -2 2.49 × 10 -2 50 1.99 × 10 -2 1.93 × 10 -2 2.04 × 10 -2 2.14 × 10 -2 2.15 × 10 -2 80 1.62 × 10 -2 1.67 × 10 -2 1.76 × 10 -2 1.91 × 10 -2 1.94 × 10 -2</figDesc><table><row><cell>Length</cell><cell>CF</cell><cell>CFC</cell><cell>CFA-Layer1</cell><cell>CFA-Layer2</cell><cell>CFA-Layer3</cell></row><row><cell>10</cell><cell>3.30 ×</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Precisions on Del.icio.us dataset for some typical lengths of recommendation list.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Rank scores on Last.Fm dataset for some typical lengths of recommendation list.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Rank scores on Del.icio.usdataset for some typical lengths of recommendation list. 10 -6 1.57 × 10 -6 1.30 × 10 -6 1.30 × 10 -7 1.09 × 10 -7 25 3.09 × 10 -5 2.58 × 10 -5 9.39 × 10 -6 8.91 × 10 -6 9.49 × 10 -6</figDesc><table><row><cell>Length</cell><cell>CF</cell><cell>CFC</cell><cell>CFA-Layer1</cell><cell>CFA-Layer2</cell><cell>CFA-Layer3</cell></row><row><cell>10</cell><cell>1.88 ×</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>This work was supported by the National Natural Science Foundation of China (Grant nos. 61273317, 61422209, 61473215), the National Top Youth Talents Program of China, the Specialized Research Fund for the Doctoral Program of Higher Education (Grant no. 20130203110011) and the Fundamental Research Fund for the Central Universities (Grant no. K5051202053).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A survey of recommendation system: research challenges</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Engineering Trends and Technology (IJETT)</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2013">2013. 19891992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Amazon. com recommendations: Item-to-item collaborative ltering</title>
		<author>
			<persName><forename type="first">G</forename><surname>Linden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>York</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internet Computing, IEEE</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">7680</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Making show recommendations using a distributed collaborative ltering architecture</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Van Stam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tivo</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the tenth ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">394401</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The netix prize</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lanning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KDD cup and workshop</title>
		<meeting>KDD cup and workshop</meeting>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="page">35</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Evaluating collaborative ltering recommender systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Herlocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Terveen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">553</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Using collaborative ltering to weave an information tapestry</title>
		<author>
			<persName><forename type="first">D</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nichols</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Oki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Terry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">6170</biblScope>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Collaborative ltering recommender systems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Ekstrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Riedl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">81173</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Collaborative ltering beyond the user-item matrix: A survey of the state of the art and future challenges</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hanjalic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Empirical analysis of predictive algorithms for collaborative ltering</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Breese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kadie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth Conference on Uncertainty in Articial Intelligence</title>
		<meeting>the Fourteenth Conference on Uncertainty in Articial Intelligence</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">4352</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">3037</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A survey of collaborative ltering techniques</title>
		<author>
			<persName><forename type="first">X</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Khoshgoftaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Articial Intelligence</title>
		<imprint>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Understanding navigability of social tagging systems</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mytkowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Hotho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jäschke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stumme</surname></persName>
		</author>
		<title level="m">Information retrieval in folksonomies: Search and ranking</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Towards tags ranking for social images</title>
		<author>
			<persName><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page">434440</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Investigating eectiveness and user acceptance of semantic social tagging for knowledge sharing</title>
		<author>
			<persName><forename type="first">S.-L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">599617</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Solving the coldstart problem in recommender systems with social tags</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Europhysics Letters)</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">28002</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>EPL</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Can all tags be used for search?</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bischo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Firan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Nejdl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Paiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM Conference on Information and Knowledge Management</title>
		<meeting>the 17th ACM Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">193202. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Tag-aware recommender systems: a state-of-the-art survey</title>
		<author>
			<persName><forename type="first">Z.-K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Science and Technology</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">767777</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Personalized recommendation in social tagging systems using hierarchical clustering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shepitsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gemmell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mobasher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Burke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM Conference on Recommender systems, ACM, 259266</title>
		<meeting>the 2008 ACM Conference on Recommender systems, ACM, 259266</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Representation learning: A review and new perspectives</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">17981828</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep self-taught learning for facial beauty prediction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="page">295303</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Greedy layerwise training of deep networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">153</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A 3D model recognition mechanism based on deep Boltzmann machines</title>
		<author>
			<persName><forename type="first">B</forename><surname>Leng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="page">593602</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">2537</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Exploiting deep neural networks for detection-based speech recognition</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Siniscalchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page">148157</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">An articial neural network approach to automatic speech processing</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Siniscalchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Svendsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="page">326338</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning Features from Music Audio with Deep Belief Networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hamel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISMIR</title>
		<imprint>
			<biblScope unit="volume">339344</biblScope>
			<date type="published" when="2010">2010</date>
			<pubPlace>Utrecht, The Netherlands</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deep contentbased music recommendation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schrauwen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page">26432651</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="issue">5786</biblScope>
			<biblScope unit="page">507</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Social tagging recommender systems</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Marinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nanopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jäschke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hotho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stumme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Symeonidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recommender systems handbook</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page">615644</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Marinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
		<title level="m">Collaborative tag recommendations, in: Data Analysis, Machine Learning and Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">533540</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Introduction to recommender systems handbook</title>
		<author>
			<persName><forename type="first">F</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rokach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shapira</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The benet of using tag-based proles</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Firan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Nejdl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Paiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Web Conference, 2007. LA-WEB 2007. Latin American</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page">3241</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Tag-aware recommender systems by fusion of collaborative ltering algorithms</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Tso-Sutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Marinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM Symposium on Applied Computing</title>
		<meeting>the 2008 ACM Symposium on Applied Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">19951999. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Personalizing navigation in folksonomies using hierarchical tag clustering</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gemmell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shepitsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mobasher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Burke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Warehousing and Knowledge Discovery</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">196 205. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Connecting users and items with weighted tags for personalized item recommendations</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st ACM conference on Hypertext and hypermedia</title>
		<meeting>the 21st ACM conference on Hypertext and hypermedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page">5160</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Tag recommendations based on tensor dimensionality reduction</title>
		<author>
			<persName><forename type="first">P</forename><surname>Symeonidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nanopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Manolopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM Conference on Recommender systems</title>
		<meeting>the 2008 ACM Conference on Recommender systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">4350</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A multilinear singular value decomposition</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">De</forename><surname>Lathauwer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>De Moor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vandewalle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM journal on Matrix Analysis and Applications</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">12531278</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Learning optimal ranking with tensor factorization for tag recommendation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Balby Marinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nanopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">727736. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Reprint of: The anatomy of a large-scale hypertextual web search engine</title>
		<author>
			<persName><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer networks</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page">38253833</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Personalized recommendation via integrated diusion on useritemtag tripartite graphs</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica A: Statistical Mechanics and its Applications</title>
		<imprint>
			<biblScope unit="volume">389</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">179186</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Collaborative ltering with diusion-based similarity on tripartite graphs</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica A: Statistical Mechanics and its Applications</title>
		<imprint>
			<biblScope unit="volume">389</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">12591264</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A comparative study of heterogeneous item recommendations in social systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bellogín</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Cantador</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Castells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">221</biblScope>
			<biblScope unit="page">142169</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Battle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems, 801808</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>Ecient sparse coding algorithms</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">On optimization methods for deep learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lahiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Prochnow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning</title>
		<meeting>the 28th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page">265272</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A practical guide to training restricted Boltzmann machines</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Momentum</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">926</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Updating quasi-Newton matrices with limited storage</title>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of computation</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">151</biblScope>
			<biblScope unit="page">773782</biblScope>
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">On the limited memory BFGS method for large scale optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical programming</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page">503528</biblScope>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Cantador</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Brusilovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kuik</surname></persName>
		</author>
		<title level="m">Second workshop on information heterogeneity and fusion in recommender systems</title>
		<imprint>
			<publisher>RecSys</publisher>
			<date type="published" when="2011">HetRec2011. 2011</date>
			<biblScope unit="page">387388</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Recommender systems survey</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bobadilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hernando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gutiérrez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page">109132</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Bipartite network projection and personal recommendation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Medo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">46115</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Personalization in folksonomies based on tag clustering</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gemmell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shepitsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mobasher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Burke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Workshop on Intelligent Techniques for Web Personalization and Recommender Systems</title>
		<meeting>the 6th Workshop on Intelligent Techniques for Web Personalization and Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">42</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Scaling learning algorithms towards AI</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Large-scale kernel machines</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">On the expressive power of deep architectures</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Delalleau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Algorithmic Learning Theory</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1836">1836, 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Almost optimal lower bounds for small depth circuits</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hastad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth Annual ACM Symposium on Theory of Computing, ACM</title>
		<meeting>the Eighteenth Annual ACM Symposium on Theory of Computing, ACM</meeting>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="volume">620</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
