<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Finding k-Dominant Skylines in High Dimensional Space</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chee-Yong</forename><surname>Chan</surname></persName>
							<email>chancy@comp.nus.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Electrical Engineering &amp; Computer Science</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Michigan</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kian-Lee</forename><surname>Tan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anthony</forename><forename type="middle">K H</forename><surname>Tung</surname></persName>
							<email>anthony@comp.nus.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhenjie</forename><surname>Zhang</surname></persName>
							<email>zhangzh2@comp.nus.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Finding k-Dominant Skylines in High Dimensional Space</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5BCB56214B49E4837B2279678C3DC656</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Given a d-dimensional data set, a point p dominates another point q if it is better than or equal to q in all dimensions and better than q in at least one dimension. A point is a skyline point if there does not exists any point that can dominate it. Skyline queries, which return skyline points, are useful in many decision making applications.</p><p>Unfortunately, as the number of dimensions increases, the chance of one point dominating another point is very low. As such, the number of skyline points become too numerous to offer any interesting insights. To find more important and meaningful skyline points in high dimensional space, we propose a new concept, called k-dominant skyline which relaxes the idea of dominance to k-dominance. A point p is said to k-dominate another point q if there are k (≤ d) dimensions in which p is better than or equal to q and is better in at least one of these k dimensions. A point that is not k-dominated by any other points is in the k-dominant skyline.</p><p>We prove various properties of k-dominant skyline. In particular, because k-dominant skyline points are not transitive, existing skyline algorithms cannot be adapted for kdominant skyline. We then present several new algorithms for finding k-dominant skyline and its variants. Extensive experiments show that our methods can answer different queries on both synthetic and real data sets efficiently.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION 1.1 Motivation</head><p>Given a d-dimensional data set, a point p is said to dominate another point q if it is better than or equal to q in all dimensions and better than q in at least one. A skyline is a subset of points in the data set that are not dominated by any other points. Skyline queries, which return skyline points, are useful in many decision making applications that involve high dimensional data sets. We give two examples here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example 1.1 Cell Phone Finder</head><p>Consider a person looking for a suitable cell phone at a website <ref type="foot" target="#foot_0">1</ref> . He/she may care about a large number of features including weight, size, talk time, standby time, screen size, screen resolution, data rate and camera quality in order to pick one that suits him/her. There are too many phones at the website for the user to examine them all manually. Computing the skyline over these cell phone features may remove a large number of cell phones whose features are "worse" than those in the skyline, hopefully leaving only a manageable number of candidates for manual evaluation.</p><p>2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example 1.2 Movie Rating</head><p>Consider a person looking for top-rated movies based on the ratings given by other users <ref type="foot" target="#foot_1">2</ref> . In this case, the rating of each user correspond to a dimension in the data set and given the large number of users, the data set being handled is obviously a high-dimensional one. The skyline of the data set will contain top-rated movies while movies that are consistently ranked worse than others in the data set are pruned away. 2</p><p>We note that in both the above cases, ranking can be done by providing some preference functions <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b8">8]</ref> and requesting users to provide some weight assignments for their preferred features or more trusted users in the latter case. However providing such weight assignments for a large number of dimensions is not always easy without any initial knowledge about the data. For example, it is not clear how weight assignments can be provided to aggregate the talk time and camera quality of a phone into one grade. In fact, as stated in the seminal paper on skyline operator <ref type="bibr" target="#b2">[2]</ref>, the aim of providing the skyline to the user is to help them to determine the weight assignment.</p><p>Computing skylines in high dimensional data sets is challenging because of the large number of skyline points <ref type="bibr">[9,</ref><ref type="bibr" target="#b14">14,</ref><ref type="bibr" target="#b17">17]</ref>. On the movie ranking website, for example, it is nearly impossible to find a movie which is ranked lower than another movie by all the users. Such a blowup in the answer set not only renders the skyline operator worthless (with respect to the desired pruning of candidates), but it also results in high computational complexity for both index and non-index methods as many pairwise comparisons are performed without effecting any pruning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">k-Dominant Skyline and its Variants</head><p>The primary cause for the skyline set size blow up is the definition of dominance, which is rather stringent in that p must be better or equal to q in all dimensions before q can be eliminated from the skyline. Using our movie rating as an example, this means that movie p is only considered better than movie q if and only if p is rated higher or equal to q by all the users. While this is quite possible when there is a small number of users (say 5 users), this is much more unlikely for a larger number of users (say 100) as all it takes is for just one outlier opinion from among the 100 to invalidate the dominance relationship.</p><p>It maybe reasonable to consider movie p better than q if say, 98 out of 100 users, consider it to be better. With this intuition, a point p is said to k-dominate another point q if there are k (≤ d) dimensions in which p is better than or equal to q and is better in at least one of these k dimensions. A point that is not k-dominated by any other points is said to be in the k-dominant skyline. Obviously, the conventional skyline is a special case of the k-dominant skyline, where k = d. The chance of a point being excluded from a k-dominant skyline is higher than the conventional skyline since more points will be k-dominated than d-dominated. By setting k to an appropriate value, we hope to find a small set of skyline points that are dominant in the sense that they remain in the skyline even with the more relaxed notion of k-dominance. Note that the set of k-dominant skyline points is a subset of the original skyline, which we will henceforth refer to as free skyline for clarity.</p><p>Unfortunately, algorithms developed for finding the original skyline are not easily adapted for finding k-dominant skyline, except for the obvious case where k = d. This is because the transitive property of the original dominance relationship no longer holds, i.e., for any k &lt; d it is possible to have three points p,q,r such that p k-dominates q, q kdominates r and r k-dominates p, forming a cyclic dominant relationship. Thus, we cannot ignore a point during processing even if it is k-dominated because that particular point might be needed to exclude another point from the skyline through another k-dominant relationship. Existing skyline computation algorithms do not satisfy this requirement.</p><p>In view of this, we propose three algorithms in this paper for finding k-dominant skyline. The first is a one-scan algorithm which uses the property that a k-dominant skyline point cannot be worse than any free skyline on more than k dimensions. This algorithm maintains the free skyline points in a buffer during a scan of the data set and uses them to prune away points that are k-dominated. As the whole set of free skyline points can be large, we avoid keeping all of them in a buffer with a two-scan algorithm. In the first scan, a candidate set of dominant skyline points is retrieved by comparing every point with a set of candidates. The second scan verifies whether these points are truly dominant skyline points. This method turns out to be much more efficient than the one-scan method. We provide some theoretical analysis on the reason for its superiority. Finally, we propose an algorithm that is motivated by the rank aggregation algorithm proposed by Fagin et al. <ref type="bibr" target="#b5">[5]</ref>, which pre-sorts data points separately according to each dimension and then "merges" these ranked lists.</p><p>A fundamental question is the choice of value for k. We prove in this paper that it is possible to have an empty k-dominant skyline even for k = d -1 due to the cyclic property. On the other hand, it is still possible to have too many k-dominant skyline points if k is too large. In order to guarantee a small but non-empty set of dominant skyline points, we propose a new type of query, called top-δ dominant skyline query. The aim is to find the smallest k such that there are more than δ k-dominant skyline points. We show that the algorithms proposed for dominant skyline query can be used to answer top-δ query easily.</p><p>In some applications, some attributes are more important than other. When the user has an opinion on the relative importance of the different dimensions, we permit the user to express this opinion in the form of relative weights. We extend the k-dominant skyline to the weighted case where d positive weights w1,...,w d are assigned to the d dimensions and a point is said to be a weighted w-dominant skyline point if there does not exist any point that can dominate it on a subset of dimensions with their sum-of-weight assignment over w.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Contributions</head><p>Our contributions in this paper are as follows:</p><p>1. We introduce a new concept, called k-dominant skyline to alleviate the effect of dimensionality curse on skyline query in high dimensional spaces (Sec. 3).</p><p>2. We propose three different algorithms to solve the kdominant skyline problem (Sec. 4).</p><p>3. We modify the k-dominant skyline algorithm to answer the top-δ dominant skyline query (Sec. 5).</p><p>4. We extend the concept of k-dominant skyline to weighted space and show how our algorithms work on such spaces (Sec. 6).</p><p>5. We show the computational efficiency benefits of these new concepts through a comprehensive experimental study (Sec. 7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>The basic idea of skyline queries came from some old research topics like contour problem <ref type="bibr" target="#b12">[12]</ref>, maximum vectors <ref type="bibr" target="#b10">[10]</ref> and convex hull <ref type="bibr" target="#b15">[15]</ref>.</p><p>Borzonyi et al. <ref type="bibr" target="#b2">[2]</ref> first introduced the skyline operator into relational database systems, and proposed three algorithms: the block nested loops (BNL), divide-and-conquer, and B-tree-based schemes.</p><p>Chomicki et al. <ref type="bibr" target="#b4">[4]</ref> proposed an algorithm named Sort-Filter-Skyline (SFS) as a variant of BNL. SFS requires the dataset to be pre-sorted according to some monotone scoring function. Since the order of the points can guarantee that no point can dominate points before it in the order, the comparisons of tuples are simplified. In <ref type="bibr" target="#b6">[6]</ref>, Godfrey et al. further improved the efficiency of this method by combining the final pass of the external pre-sort with the first skylinefilter pass.</p><p>In <ref type="bibr" target="#b16">[16]</ref>, Tan et al. proposed two progressive processing algorithms: Bitmap and Index. In the Bitmap approach, every dimension value of a point pt is represented by a few bits. By applying bit-wise and operation on these vectors, a given point can be checked if it is in the skyline without referring to other points. The Index approach partitions the whole data set into some lists, every of which contains points with smallest value on the same dimension among all the dimension values. Every list is further divided into batches according the index value of the points. Within each batch, local skyline is computed by comparing every points with global skyline and is merged into the global skyline after computation.</p><p>Kossmann et al. <ref type="bibr">[9]</ref> proposed a Nearest Neighbor (NN) method to process skyline queries progressively. By indexing the dataset by an R * -tree, the method uses the result of nearest neighbor query to partition the space recursively. The nearest neighbor to the origin in the partitioned region must be part of the skyline. Papadias et al. <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b14">14]</ref> proposed a new progressive algorithm named Branch-and-Bound Skyline (BBS) based on the best-first nearest neighbor (BF-NN) algorithm <ref type="bibr" target="#b7">[7]</ref>. Instead of searching for nearest neighbor again and again, it directly prunes using the R *tree structure.</p><p>Yuan et al. <ref type="bibr" target="#b17">[17]</ref> proposed two methods that efficiently find the skylines of all subspaces, in bottom-up and topdown manner respectively. Their studies aim to find skyline in a subset of dimensions specified by the users. This is in contrast with our work which directly determines a set of interesting skyline points from the full set of dimensions. In <ref type="bibr" target="#b11">[11]</ref>, the concept of dominance is generalized to define three types of queries called dominant relationship queries (DRQs) to support microeconomic data mining. A data cube is proposed to answer DRQs efficiently. We believe that our work here will eventually be useful for this purpose as well.</p><p>To find the top objects under some monotone aggregation function, Fagin proposed three methods, FA, TA and NRA in <ref type="bibr" target="#b5">[5]</ref> which are optimal in some cases. The FA algorithm accesses in parallel the sorted lists on every dimension. We can find the top-k points when there is a set of at least k points such that each of them has been seen in each list. The TA algorithm improves the FA algorithm by setting a threshold by the function from all the smallest value that have seen from all the lists. The algorithm stops when the current top-k points all have aggregation value larger than the threshold. The NRA algorithm works with only sorted access. The smallest values seen in all dimension lists are used to calculate the upper bound on the points not seen. We can get top-k result without exact aggregation value, when the lower bounds on the current top-k points are larger than the upper bound on the (k+1)th point.</p><p>More recently, there has been work on identifying interesting skylines to address the problem of having too many skyline points particularly when the data is high dimensional. The concept of the skyline frequency of a data point was proposed in <ref type="bibr" target="#b3">[3]</ref>, which measures the number of subspaces that a point is a skyline point. Our proposal of k-dominance offers a different notion of interestingness from skyline frequency. For example, consider two data points p and q on a 3-dimensional data space S = {s1, s2, s3}, where p is a skyline point in the four subspaces {s1}, {s1, s2}, {s1, s3}, and {s1, s2, s3}; while q is a skyline point in the four subspaces {s1, s2}, {s1, s3}, {s2, s3}, and {s1, s2, s3}. Note that although both p and q have the same skyline frequency of 4, q is "stronger" in terms of k-dominance since q is a 2dominant skyline but p is only a 3-dominant skyline. On the other hand, it is also possible for two points to be equally "strong" in terms of k-dominance but differ in their skyline frequencies. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">DEFINITION AND ANALYSIS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Definition</head><p>Given a d-dimensional space S = {s1, s2, • • • , s d }, a set of points D = {p1, p2, . . . , pn} is said to be a data set on S if every pi ∈ D is a d-dimensional data point on S. We use pi.sj to denote the j th dimension value of point pi. For each dimension si, we assume that there exists a total order relationship, denoted by i, on its domain values. Here, i can be '&lt;' or '&gt;' relationship according to the user's preference. For simplicity and without loss of generality, we assume each i represents '&gt;' in the rest of this paper.  <ref type="figure">1</ref>. There are four free skyline points in D: p1, p2, p3, and p4. Among these, only p1, p2, and p3 are also 5-dominant skyline points; p4 is 5-dominated by p2. The top-2 dominant skyline points are p1 and p2 since they are both 4-dominant skyline points while p3 is not. We will use this data set as a running example in the rest of this paper. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Analysis</head><p>In this section, we illustrate several important properties of dominant skyline points. We first formally show that lowering k will always result in smaller or equal number of k-dominant skyline points.</p><formula xml:id="formula_0">Lemma 3.5. If pi k + 1-dominates pj, then pi must k- dominate pj. Theorem 3.6. A point pi ∈ DSP (k, D, S), then pi ∈ DSP (k + 1, D, S). Corollary 3.7. |DSP (k, D, S)| ≤ |DSP (k + 1, D, S)|</formula><p>From the last corollary, we can see that the set of dominant skyline points decreases monotonically with the decrease of the parameter k and thus we are sure that a sufficiently small k can reduce the number of k-dominant skyline to a manageable size for presentation to users. However, one worries that too small a k value might find points which do not make sense semantically to users. For example, if k &lt; d/2, this will mean that a point p can k-dominate another point q even if it is only better in fewer than half the dimensions. We alleviate this worry by showing that kdominant skyline points for k &lt; (d + 2)/2 are in fact rather easy to interpret. The last theorem tells us that when k is too small, either 1) there is only one k-dominant skyline point which has very strong dominant power in that it dominates all the points on many dimensions or 2) there are multiple k-dominant skyline points which are equal on a number of dimensions and have different relative ordering on the remaining dimensions.</p><p>We will next motivate the need to look for a top-δ dominant skyline points. The following theorem shows that there may not be any k-dominant skyline point in a data set for any k &lt; d. Example 3.2 Fig. <ref type="figure">2</ref> shows an example data set that exhibits the cyclic dominance relationship when k = 3. Specifically, we have pi 3-dominates pi+1, ∀ i ∈ <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b3">3]</ref>, and p4 in turn 3-dominates p1. 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">K-DOMINANT SKYLINE ALGORITHMS</head><p>Due to the possibility of cyclic dominance relationships, the existing algorithms for computing free skylines can not be used directly for computing k-dominant skyline points. In this section, we present three novel algorithms, namely, One-Scan algorithm, Two-Scan algorithm, and Sorted Retrieval algorithm, to compute k-dominant skyline points. Each algorithm takes as input a d-dimensional data set D (over a set of dimensions S) and a parameter k, and outputs the set of k-dominant skyline points in D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">One-Scan Algorithm</head><p>Our first approach to compute k-dominant skyline points from an input data set D (over a set of dimensions S) is similar in spirit to the nested-loop approach <ref type="bibr" target="#b2">[2]</ref> in that it makes one sequential scan of the data set. The algorithm (shown in Algorithm 1) is based on the following two key properties. To determine if a point p is k-dominant, property P2 implies that it is not sufficient to use only k-dominant skyline points to compare against p since it is possible for p to be not k-dominant even though it is not k-dominated by any of the k-dominant points. On the other hand, property P1 implies that it is sufficient to compare p against the set of free skyline points (instead of all the points in D) to detect if a point p is k-dominant. Thus, based on Lemma 4.1, our algorithm computes k-dominant skyline points by actually computing the free skyline points in D and using them to eliminate non-k-dominate skyline points. Specifically, two sets of intermediate points are maintained as D is being processed: (1) R stores the set of intermediate k-dominant skyline points in D, and (2) T stores the set of intermediate skyline points in D that are not k-dominant (i.e., not in R). Together, R ∪ T gives the set of skyline points in D. Since T is used only for pruning purpose, we can minimize the size of T by storing only the unique skyline points; i.e., a new (non-k-dominant) skyline p is added to T only if p = p ∀ p ∈ T .</p><p>The details of One-Scan algorithm are as follows. For each point p in D, p is first compared against points in T (steps 5 to 11). If a point p ∈ T is dominated by p, then p (which is not a skyline) is removed from T ; otherwise, if p dominates p (i.e., p is not a skyline) or p = p (i.e., p is not unique), then p can be safely ignored. However, if p is a unique skyline, then p is further compared against the points in R (steps 13 to 22) to check if it is k-dominant. For each p ∈ R, if p k-dominates p , then p is moved from R to T ; and if p k-dominates p, then p is not k-dominant. At the end of comparing p against the points in R, p is inserted into R if p is k-dominant; otherwise, p is inserted into T since p is a unique skyline. Once all the points in D have been processed, R contains the set of all k-dominant skyline points in D.</p><p>As an additional preprocessing optimization, the points in D can be first sorted in non-ascending order of the sum of all their dimension values (step 1). The purpose of this heuristic, which was first proposed in <ref type="bibr" target="#b4">[4]</ref>, is to try to maximize the number of skyline points that occur before the non-skyline  <ref type="figure">1</ref>, points p1, p2, and p3 will each be inserted into R. However, p4 will be inserted into T since it is 5-dominated by p1. Thus, the algorithm returns {p1, p2, p3} as the set of 5-dominant skyline points. 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Two-Scan Algorithm</head><p>In the One-Scan algorithm, free skyline points (i.e., T ) need to be maintained to compute the k-dominant skyline points. Since the set of free skyline points could be much larger than the set of k-dominant skyline points, maintaining T can incur large space and computation overhead. To overcome this limitation, we present our second approach (shown in Algorithm 2) which avoids the need to maintain T by scanning D twice.</p><p>In the first scan of D (steps 1 to 10), a set of candidate k-dominant skyline points, R, is computed progressively by comparing each point p ∈ D against the computed points in R. If a point p ∈ R is k-dominated by p, then p is removed from R. At the end of the comparison against R, p is added into R if it is not k-dominated by any point in R. After the first scan of D, R contains the candidate k-dominant skyline points. Recall that false positives can exist in R due to property P2 in Lemma 4.1.</p><p>To eliminate the false positives produced by the first scan, a second scan of D (steps 11 to 14) is necessary. To determine whether a point p ∈ R is indeed k-dominant, it is sufficient to compare p against each point p ∈ D -R that occurs earlier than p in D, since those points that occur later than p in D have been already compared against p in the first scan. Note that this optimization can be implemented by associating each point with its position in D, and using this information to avoid unnecessary comparisons.</p><p>The efficiency of the Two-Scan approach is dependent on how effective are the k-dominant points in pruning non- .</p><p>The above theorem shows that when k is small enough, it is very unlikely that a dominant skyline point does not kdominate some other point. Thus, this indicates that each k-dominant skyline is likely to prune off many false positives during the first scan of D. For example, when k ≤ 3d/4, the above probability is smaller than e -2 d/ 4  . For d = 20, this probability works out to be 1.27 × 10 -14 , which is a very small number.</p><p>Example 4.2 Applying the Two-Scan algorithm (with k = 4) on the data set D in Fig. <ref type="figure">1</ref>, we note that both p1 and p2 (which are indeed 4-dominant skyline points) will be inserted into R at the end of the first scan regardless of the order of the points in D. This example demonstrates the effective pruning ability of the dominant skyline points in eliminating non-dominant skyline points. 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Sorted Retrieval Algorithm</head><p>Our third approach is inspired by the ideas in <ref type="bibr" target="#b5">[5]</ref>. The data points in D are first sorted (in non-ascending order) for each dimension si ∈ S, and each sorted set of points is stored in an array Di[1</p><formula xml:id="formula_1">• • • |D|] (steps 1 to 3) 3 . Thus, Di[j].si ≥ Di[j + 1].si, ∀ i ∈ [1, |S|], ∀ j ∈ [1, |D|).</formula><p>Each sorted array Di is associated with a cursor, denoted by ci, which is initialized to point to the first array entry (step 3). The algorithm maintains two sets: (1) R, the set of kdominant skyline points (which is initialized to empty); and</p><p>(2) T , the set of candidate k-dominant skyline points (which is initialized to D). Non-k-dominant skyline points in T are progressively eliminated from T , while k-dominant skyline points in T are progressively moved to R.</p><p>Unlike the first two approaches, which sequentially scans D to compute dominant skyline points, the Sorted Retrieval approach iteratively chooses one of the dimensions si (using a function FindNextDimensions in step 9), and processes the batch of data points in Di, denoted by D , that have the same si value as Di[ci] (steps 10 to 20). The iterative processing terminates once T becomes empty. Since each data point p ∈ D is stored a total of |S| times in the sorted arrays, each point can potentially be processed in |S| different iterations. We use a counter, denoted by count(p), to keep track of the number of times that a point p has been processed. The counter values are initialized to 0 (steps 4 and 5). In each iteration, the selected batch of points D is processed in two phases. The first phase (steps 11 to 16) uses D to eliminate points in T that are determined to be non-dominnant. Specifically, if p ∈ D is being processed for the first time (step 12), then p is used to eliminate the points in T that are k-dominated by p (steps 13 to 15). The counter for each p ∈ D is updated at the end of the first phase (step 16).</p><p>The second phase (steps 17 to 19) moves the points in T that are determined to be k-dominant skyline points to R. Specifically, a point p ∈ D is determined to be a kdominant skyline point if it satisfies two conditions: (C1) p has not yet been k-dominated by any processed point (i.e., p is still in T ); and (C2) p has been processed dk + 1 times (i.e., counter(p ) = d-k +1). The correctness of these conditions is based on the following observation: if a point p is k-dominated by some other point p, then p can be processed in an earlier batch of points than p in at most dk iterations. This is because the definition of k-dominance implies that p must be processed in an earlier batch than p or in the same batch as p in at least k iterations. Therefore, condition (C2) implies that any point p that could possibly k-dominate p would have been processed at least once, and together with condition (C1), it means that p is guaranteed to be a k-dominant skyline point. At the end of each iteration, the cursor ci is updated accordingly to beyond the last processed point in Di (step 20).</p><p>The performance of this approach depends crucially on the choice of the heuristic function FindNextDimension which selects the next dimension and hence sorted array to be processed. There are several straightforward options for this function, such as round-robin iteration and one-dimensional iteration. In Algorithm 3, we use the round-robin iteration heuristic which chooses the dimension that has been selected the least often; ties are broken by selecting the dimension with the smallest dimension index number.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example 4.3</head><p>Applying the Sorted Retrieval approach (with k = 4) on D in Fig. <ref type="figure">1</ref>, we first sort D to obtain D1, • • • , D6 as shown in Fig. <ref type="figure" target="#fig_6">3</ref>, where for clarity, points having the same si values are enclosed within braces. The first three iterations all select dimension s1. At the end of the first iteration, the points p3 and p4 (which are 4-dominated by p1) are removed from T , count(p1) = 1, and c1 = 2. At the end of the second iteration, we have count(p1) = 2, and c2 = 2. At the end of the third iteration, we have count(p1) = 3; since count(p1) = dk + 1 = 3, the algorithm concludes that p1 is a 4dominant point and p1 is moved from T to R. The point p5 is eliminated from T (as it is 4-dominated by p2) at the end of the fifth iteration. Finally, at the end of the tenth iteration, count(p2) = 3 and p2 is moved from T to R as a 4-dominant point. Since T becomes empty, the processing  </p><formula xml:id="formula_2">s i = FindNextDimension (c 1 , • • • , c |S| ) 10: let D = {D i [c i ], D i [c i + 1], • • • , D i [c i + m -1]}, where D i [c i + m].s i = D i [c i ].s i , and D i [c i ].s i = D i [c i + 1].s i = • • • = D i [c i + m -1].</formula><formula xml:id="formula_3">move p from T to R 20: c i = c i + m 21: return R Function FindNextDimension(c 1 , • • • , c |S| )</formula><p>1: return the dimension s i ∈ S with the smallest c i and smallest i terminates and the algorithm returns R = {p1, p2} as the answer. 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Analysis</head><p>In this section, we use the concept of instance optimality <ref type="bibr" target="#b5">[5]</ref> to show that our proposed round-robin iteration method is instance optimal with a constant factor.</p><p>Let A be a class of algorithms, and let D be a class of legal inputs with at most O(1) points having same value on any dimension. If the time cost of the algorithm A ∈ A on data D ∈ D is C(A, D), an algorithm Ai ∈ A is said to be instance optimal if it satisfies the following condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 4.3. [5] An algorithm Ai ∈ A is instance optimal in A on D if C(Ai, D) = O(C(Aj, D)) for any Aj ∈ A and D ∈ D.</head><p>In the following part of the section, we prove that roundrobin iteration is such an instance optimal iteration method based on the sorted arrays.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 4.4. If a point p can be pruned by any iteration method after t comparisons, it can be pruned by round-robin after at most O(td) comparisons.</head><p>Lemma 4.5. If any iteration method can assert that point p is a k-dominant skyline point after t comparisons, roundrobin method can assert it after at most O(td) comparisons. Theorem 4.6. Round-robin iteration is instance optimal in the iteration method class A and data sets D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">TOP-δ DOMINANT SKYLINE</head><p>The goal of computing k-dominant skyline points is to reduce the number of interesting points returned by the skyline operator. However, the number of dominant skyline points can still be large when k is not sufficiently small. On the other hand, if k is too small, no (or too few) k-dominant skyline points may be returned. To avoid the difficulty of choosing the right value of k, we consider instead computing top-δ dominant skyline queries, which are queries to find the smallest k such that there are at least δ number of dominant skyline points (i.e., |DSP (k, D, S)| ≥ δ).</p><p>In this section, we describe how to extend the dominant skyline algorithms in the previous section to evaluate topδ dominant skyline queries. The input parameters to each algorithm are D, S, and δ (instead of k).</p><p>Given two points p and p , we use maxDom(p, p ) to denote the largest value k ∈ [0, |S|] such that p k-dominates p .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">One-Scan Algorithm</head><p>The key idea behind the extension of One-Scan approach (shown as Algorithm 4) is to keep track, for each point p ∈ D, the maximum value of k for which p has been kdominated. We use maxkdom(p) to denote this value for p. A point is maintained in R so long as maxkdom(p) &lt; |S| (i.e., p is at least a free skyline point). At the end of processing all the points in D,</p><formula xml:id="formula_4">for each point p ∈ R, p is a k- dominant skyline point ∀ k ∈ [maxkdom(p) + 1, |S|].</formula><p>Thus, the top-δ dominant skyline points are the δ points in R with the smallest value of maxkdom(.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Two-Scan Algorithm</head><p>Since the Two-Scan algorithm maintains only candidate k-dominant skyline points but not the free skyline points that are not k-dominant, it is not possible to precisely maintain the maxkdom(.) values as in the extended One-Scan approach. Instead, we apply a binary search technique to determine the smallest k value such that |DSP (k, D, S)| ≥ δ. The details are given in Algorithm 5.</p><p>Although the Two-Scan algorithm might be invoked log(|S|) times in the worst case, when the minimum value of k for |DSP (k, D, S)| ≥ δ to hold turns out to be small (which </p><formula xml:id="formula_5">k min = k + 1 12: else 13: kmax = k -1 14: until (k min &gt; kmax) 15: return δ points in R</formula><p>is necessary when δ is small), Theorem 4.2 indicates that the Two-Scan algorithm and hence its extended variant are very efficient due to the pruning effectiveness of the dominant skyline points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Sorted Retrieval Algorithm</head><p>To extend the Sorted Retrieval approach to evaluate topδ dominant queries, we need to maintain two variables for each point p ∈ T : (1) maxkdom(p) (as defined in Section 5.1); and (2) maxkdomBound(p), which is the upper bound for maxkdom(p). The values for maxkdom(p) and maxkdomBound(p), which are initialized to 0 and |S|, respectively, are updated as points in the sorted arrays are being processed. This information enables efficient checking of whether or not a point p ∈ T is a top-δ dominant skyline point and is based on the following two properties: (P1) A point p ∈ T can not be in the answer (i.e., can be removed from T ) if maxkdom(p) is larger than the δ th smallest maxkdomBound(.) values in R ∪ T ; and (P2) A point p ∈ T can be confirmed to be in the answer (i.e., can be moved from T to R) if maxkdomBound(p) is smaller than the δ th smallest maxkdom(.) values in R ∪ T . The details of the algorithm are shown as Algorithm 6.</p><p>Example 5.1 Consider finding the top-2 dominant skyline points in D from Fig. <ref type="figure">1</ref>. Initially, each point in D has values of 0 and 6 for maxkdom(p) and maxkdomBound(p), respectively. After p1 ∈ D1 has been processed, we have maxkdom(p2) = 3, maxkdom(p3) = 4, maxkdom(p4) = 5, and maxkdom(p5) = 3. After p1 ∈ D3 has been processed, maxkdomBound(p1) is reduced to 3. The processing of p4 ∈ D4 does not affect any variable values. But after p2 ∈ D6 has been processed, the points p3, p4 and p5 can all be eliminated from T because their maxkdom(.) values are larger maxkdomBound(p2). Thus, p1 and p2 are returned as the top-2 dominant skyline points. 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">WEIGHTED DOMINANT SKYLINE</head><p>The dominant skyline problem so far gives every dimension equal importance in the result. This may not be enough in all the cases, since sometimes the user may want to give some bias to some attributes of greater interest. A simple extension from the original problem is to assign some weights to the dimensions and determine the (dominant) skyline points over some subset of dimensions with enough weights. In the basketball players' statistics data, for example, the user may want to find those exceptional players who </p><formula xml:id="formula_6">s i = FindNextDimension (c 1 , • • • , c |S| ) 11: let D = {D i [c i ], D i [c i + 1], • • • , D i [c i + m -1]}, where D i [c i + m].s i = D i [c i ].s i , and D i [c i ].s i = D i [c i + 1].s i = • • • = D i [c i + m -1].s i 12: for each p ∈ D do 13: if (count(p ) = 0) then 14:</formula><p>for each p ∈ T do <ref type="bibr" target="#b15">15</ref>:</p><formula xml:id="formula_7">maxkdom(p) = max{maxkdom(p), maxDom(p , p)} 16: maxkdom(p ) = max{maxkdom(p ), maxDom(p, p )}</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>17:</head><p>let α be the δ th smallest maxkdomBound(q), q ∈ R ∪ T let β be the δ th smallest maxkdom(q), q ∈ R ∪ T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>27:</head><p>if (p ∈ T ) and (maxkdomBound(p ) &lt; β) then 28:</p><formula xml:id="formula_8">move p from T to R 29: c i = c i + m 30: return R</formula><p>are better at defense than attack, by giving more weight to defensive attributes, such as block and steal.</p><p>To support this type of weighted query, our previous algorithms need to be extended only slightly. Specifically, when comparing two points p1 and p2, we record the weights of the dimensions on which p1 dominates p2 and sum them up. If the sum exceeds a threshold w, we say that p1 dominates p2 with weight w. A point p is said to be a w-dominant skyline if no point can dominate p on dimensions whose weight sum is over w. The following lemma shows that weighted dominant skyline shares similar properties as the original dominant skyline.</p><formula xml:id="formula_9">Lemma 6.1. Given a subset of dimensions S = {s1, s2, • • • , s d } and a corresponding positive weight set W = {w1, w2, • • • , w d }, if a point p ∈ S</formula><p>w-dominates another point q, then p also w -dominates q for w ≤ w.</p><p>From the simple lemma above, we can restate almost all of the earlier theorems in a weighted form. Since the onescan and two-scan algorithms are based on point comparison, the weight assignments for the dimensions have no impact on its correctness. The structure of these two algorithms remain largely unchanged and only the pair-wise domination comparison procedure must be modified to cater to the weights. For the sorted retrieval method, instead of counting the number of times a point has been processed from the sorted arrays, we need to sum up all the weights of the processed dimensions.</p><p>Note that these modification do not affect the computational complexities of all the proposed methods. However, having weight assignments on the dimensions can impact the effectiveness of the pruning and the frequency distribution of w-dominant skyline points with varying w. We will show how these affect the running time of the algorithms in our experimental study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">EXPERIMENTS</head><p>We have implemented all the algorithms proposed in this paper: One-Scan Algorithm (OSA), Two-Scan Algorithm (TSA) and Sorted Retrieval Algorithm (SRA). In this section, we compare their performances, and report our findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Experiment Setting</head><p>We use both synthetic data sets and real data sets in the experiments. The generation of the synthetic data sets is controlled by the parameters listed in Table <ref type="table" target="#tab_3">1</ref>.</p><p>The dimension number d is the number of attributes of the points, while the data size Size is the number of points in the data set. There are three optional distributions in the synthetic data sets: Correlated, Independent and Anti-Correlated. In the correlated data set, all dimensions are positively correlated to each other. As such, there are very few skyline points, free or k-dominant, in the data set. In the independent data set, dimensions are independent of each other. Under this assumption, points rarely dominate each other when the dimension number grows, so the free skyline set becomes large. In the anti-correlated data set, dimensions are negatively correlated. Almost all points are free skyline points in this type of data sets. In Table <ref type="table" target="#tab_4">2</ref>, we show the number of the dominant skyline points on a 15-dimensional data set with 100K points on different distributions and different constraint parameter k. This table shows that when k is close to dimension number d, the number of dominant skyline point in the anti-correlated data set is much larger than that in the independent and correlated data sets. However, when k is small, the correlated data set can still have some dominant skyline points, while no dominant skyline points can be found on the other two distributions. The constraint parameter k, w and the top dominant skyline parameter δ have the same meaning as that described in the paper. When we assign weights to the dimensions, we ensure that the sum of the weights on all dimensions is equal to the number of dimensions. In the weight generation, we use the ratio of maximum weight to minimum weight, R, to control the degree of bias on the weights. Given the ratio R, the d weights of the dimensions are generated by normalizing d random numbers between 1 and R.</p><p>The default parameter setting in our synthetic data set test is: d = 15, Size = 100K, Dist =Independent, k = 11, δ = 100, w = 11 and R = 2. We also study two different real data sets. The first is the NBA statistics data set 4 . This data set contains 17000 players' season records on 17 attributes from the first season of NBA in 1945. Every record contains the statistical value of a player's performance in one season, such as game played(GP), points(PT), rebounds(RB) and so on. One player may have several records if he played in NBA for more than one season. The second data set is Movie-Lens data set 5 , which contains 100,000 ratings (1-5) from 943 users on 1682 movies. The data was collected by the MovieLens web site from September 1997 to April 1998. All the users in this data set has rated at least 20 movies. To make the records comparable, we insert 0 to all the empty entries of the movies a user did not rate.</p><p>All the experiments are conducted on a PC with Intel Pentium 2.4GHz CPU and 2G main memory, running Linux with kernel 6.2.14.  its great advantage over TSA on k-dominant skyline query with large k.</p><p>In Table <ref type="table" target="#tab_5">3</ref>, we show the top-5 dominant skyline results on NBA data set with three different weights assignments. The first assignment is equal-weight assignment, i.e., all dimensions are assigned the same weight. With the same weight on all dimensions, we successfully find the superstars in NBA's history, such as Chamberlain and Jordan, listed in the first column. In the second weight assignment, six attributes related to defense, such as block, steal and rebound, are given weights two times more than all other dimensions. From the result of the defender biased weights in the second column of the table, we can find famous defenders in NBA. The third weight assignment concentrates on shooters, which gives shooters' strengths, such as points scored and three pointers, two times more weight than other attributes. Legendary shooters appear in the third column as expected.</p><p>Since the NBA data set is fairly correlated, especially on those attacking attributes, TSA is faster on shooter biased weights than the other weights assignments in Fig. <ref type="figure" target="#fig_7">11(c</ref>). This shows that TSA is more sensitive to weight assignment than the other two algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.2">On Movie-Lens Data Set</head><p>We also evaluate the impact of parameters on the movielens data set with equal weights in Figs. 12(a) and 12(b). Although TSA and SRA are much faster than OSA on kdominant skyline query, they cannot beat OSA on top-δ dominant skyline query because of the large dimensionality of the data set. For TSA, the binary search on large k consumes too much time to locate the best level of k. For SRA, too many different top rated movies by different users reduces its pruning efficiency.</p><p>On the movie-lens data set, we also try two different weight assignments. With the equal weight assignment to every user, five top movies are found and listed in the first column of Table <ref type="table" target="#tab_6">4</ref>. When the weights for every user is set proportional to the number of movies he or she rated, we see some different results in the second column. The difference comes about because, in the movie-lens data set, most users have rated only a small fraction of the movies. If we give equal weights to all users, a movie A has advantage over another movie B only if more users rated A, no matter how many users like B more than A. Since the data set was collected from 1997 to 1998, 4 out of 5 top dominant skyline points of equal weight are movies from 1996 to 1997, which had been just watched by the users. From the result in second With heavier weights on the users with more ratings, the computation times of TSA and SRA increase in Fig. <ref type="figure" target="#fig_12">12(c</ref>), since the data set is so sparse that those heavily weighted users can have very few common movies rated, which makes it even harder to find dominant skyline points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">CONCLUSION</head><p>The skyline operator has been used as an effective mechanism to identify "dominating" points in a multi-dimensional data set. Unfortunately, as the dimensionality of the data set grows, the skyline operator begins to lose its discriminating power and returns a large fraction of the data. In this paper, we proposed a generalization of the skyline concept, called k-dominant skyline, to overcome this difficulty. We presented three different algorithms to solve the k-dominant skyline problem. We defined notions of a top-δ dominant skyline query and a weighted (dominant) skyline query, and showed how the three algorithms for the k-dominant skyline problem could be extended to address these problems as well. Our experimental results showed that our methods can find interesting objects in the data set efficiently. In summary, the notion of k-dominant skylines proposed in this paper gracefully extends traditional skylines, and leads to both more meaningful skyline results as well as more efficient computation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Definition 3 .Problem 1 .Problem 2 .Example 3 . 1</head><label>31231</label><figDesc>1. dominate A point pi is said to dominate another point pj on S if and only if ∀ s k ∈ S, pi.s k ≥ pj.s k and ∃ st ∈ S, pi.st &gt; pj.st. Definition 3.2. skyline, SP (D, S) A point pi is a skyline point on S if and only if there does not exist a point pj = pi dominating pi. We use SP (D, S) to denote the set of skyline points in data set D on space S. Definition 3.3. k-dominate A point pi is said to k-dominate pj if and only if ∃ S ⊆ S, |S | = k, ∀ sr ∈ S , pi.sr ≥ pj.sr and ∃ st ∈ S , pi.st &gt; pj.st.Definition 3.4. k-dominant skyline, DSP (k, D, S) A point pi is a k-dominant skyline point, if and only if there does not exist any point pj = pi in the data set that pj kdominates pi. We use DSP (k, D, S) to denote the set of all k-dominant skyline points in D on space S. When k = d, the k-dominant dominance relationship is equivalent to the original dominance relationship defined in definition 3.1. The two main problems that we want to solve are as follows: Given a specified k, data set D and dimension space S, find DSP (k, D, S). Given a threshold δ, data set D and dimension space S, let k be the smallest k which satisfies |DSP (k, D, S)| ≥δ if SP (D, S) &gt; δ, otherwise k = d. We will use the term top-δ dominant skyline to refer to DSP (k , D, S). Find DSP (k , D, S). Consider the 6-dimensional data set D = {p1, • • • , p5} in Fig.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Theorem 3 . 8 .</head><label>38</label><figDesc>If k &lt; (d + 2)/2, any pair of k-dominant skyline points must have the same values on at least d-2k+2 dimensions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Theorem 3 . 9 .</head><label>39</label><figDesc>For any k &lt; d (d ≥ 2) and a d-dimensional space S, there exists a data set D with size |D| ≥ d such that DSP (k, D, S) = ∅.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Lemma 4 . 1 .</head><label>41</label><figDesc>Consider a data point p ∈ D that is not a k-dominant skyline point. Then P1. There must exist a free skyline point in D that kdominates p. P2. It is possible for p not to be k-dominated by any kdominant skyline point.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 1 Example 4 . 1</head><label>141</label><figDesc>One-Scan Algorithm (D, S, k) 1: sort D in non-ascending order of sum of point's dimension values 2: initialize set of k-dominant skyline points R = ∅ 3: initialize set of unique non-k-dominant skyline points T = ∅ 4: for every point p ∈ D do 5: initialize isUniqueSkyline = true 6: for every point p ∈ T do 7: if (p dominates p ) then 8: remove p from T 9: else if (p dominates p) or (p = p ) then 10: isUniqueSkyline = false 11: break out of inner for-loop 12: if (isUniqueSkyline) then 13: initialize isDominant = true 14: for every point p ∈ R do 15: if (p k-dominates p) then 16: isDominant = false 17: if (p k-dominates p ) then 18: move p from R to T 19: if (isDominant) then 20: insert p into R 21: else 22: insert p into T 23: return R points in D so that the non-skyline points are eliminated as early as possible thereby reducing the overhead of maintaining them before they are pruned. Applying the One-Scan algorithm (with k = 5) on the data set D in Fig.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Algorithm 2 6 := false 7 : 8 :</head><label>2678</label><figDesc>Two-Scan Algorithm (D, S, k) 1: initialize set of k-dominant skyline points R = ∅ 2: for every point p ∈ D do 3: initialize isDominant = true 4: for every point p ∈ R do 5: if (p k-dominates p) then isDominant if (p k-dominates p ) then remove p from R 9: if (isDominant) then 10: insert p into R 11: for every point p ∈ D do 12: for every point p ∈ R, p = p do 13: if (p k-dominates p ) then 14: remove p from R 15: return R dominant skyline points during the first scan. If the number of false positives produced by the first scan is small, then the performance of the second scan and hence the overall approach will be good. The following result gives an indication of the pruning ability of dominant skyline points. Theorem 4.2. Consider a d-dimensional data set D with more than 2 d points such that the dimensions are pairwise independent, and no two points in D have the same value for the same dimension. If a data point p ∈ D can not kdominate any point in D, then p is a k-dominant skyline point with probability less than e -2 d-k</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Algorithm 3</head><label>3</label><figDesc>Sorted Retrieval (D, S, k) 1: for each dimension s i ∈ S do 2: sort D in non-ascending order of each point's s i value and store the sorted points in array D i [1 • • • |D|] 3: initialize the cursor for D i , c i = 1 4: for each p ∈ D do 5: initialize count(p) = 0 6: initialize the set of k-dominant points R = ∅ 7: initialize T = D 8: while (T = ∅) do 9:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>s i 11 :</head><label>11</label><figDesc>for each p ∈ D do 12: if (count(p ) = 0) then 13: for each p ∈ T do 14: if (p k-dominates p) then 15: remove p from T 16: count(p ) = count(p ) + 1 17: for each p ∈ D do 18: if (p ∈ T ) and (count(p ) = dk + 1) then 19:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Algorithm 5 9 :</head><label>59</label><figDesc>Ext-Two-Scan Algorithm (D, S, δ) 1: initialize set of top-δ dominant skyline points R = ∅ 2: initialize k min = 1 and kmax = |S| 3: repeat 4: k = (k min + kmax)/2 5: T = Two-Scan (D, S, k) 6: if (|T | = δ) then 7: else if (|T | &gt; δ) then 10:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Algorithm 6</head><label>6</label><figDesc>Ext-Sorted Retrieval (D, S, δ) 1: for each dimension s i ∈ S do 2: sort D in non-ascending order of each point's s i value and store the sorted points in array D i [1 • • • |D|] 3: initialize the cursor for D i , c i = 1 4: for each p ∈ D do 5: initialize count(p) = 0 6: initialize maxkdom(p) = 0 and maxkdomBound(p) = |S| 7: initialize the set of top-δ dominant skyline points R = ∅ 8: initialize T = D 9: while (T = ∅) do 10:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>18: if (maxkdom(p) &gt; α) then 19: remove p from T 20: count(p ) = 1 21: if (maxkdom(p ) &lt; maxkdomBound(p )) then 22: maxkdomBound(p ) = maxkdomBound(p ) -1 23: else 24: maxkdomBound(p ) = maxkdom(p ) 25: for each p ∈ D do 26:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 8 :</head><label>8</label><figDesc>top-δ Dominant Skyline Test on varying dimension 7.3 On Real Data Sets 7.3.1 On NBA Data Set In Figs. 11(a) and 11(b), we show several experimental results on the NBA data set with equal weights on all at-tributes. When varying the constraint parameter k, TSA is the most efficient algorithm when k &lt; 14, but is worst among the three algorithms when k &gt; 15. SRA is faster than the other two when k is large. For top-δ dominant skyline query, SRA is much more efficient than TSA because of Anti-Correlated Figure 10: k-Dominant Skyline Test with different Weight Assignments</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 12 :</head><label>12</label><figDesc>Tests on Movie-Lens data setcolumn, we believe this problem is alleviated in the biased weight assignment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Figure 1: Example Data Set, D</head><label></label><figDesc></figDesc><table><row><cell>Point</cell><cell>s 1</cell><cell>s 2</cell><cell>s 3</cell><cell>s 4</cell><cell>s 5</cell><cell>s 6</cell></row><row><cell>p 1</cell><cell>4</cell><cell>4</cell><cell>4</cell><cell>2</cell><cell>2</cell><cell>2</cell></row><row><cell>p 2</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>4</cell><cell>4</cell><cell>4</cell></row><row><cell>p 3</cell><cell>3</cell><cell>3</cell><cell>3</cell><cell>1</cell><cell>3</cell><cell>3</cell></row><row><cell>p 4</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>5</cell><cell>1</cell><cell>1</cell></row><row><cell>p 5</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>3</cell><cell>3</cell><cell>3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Cyclic dominance relationship example</head><label></label><figDesc><ref type="bibr" target="#b2">2</ref> </figDesc><table><row><cell>point</cell><cell cols="4">s 1 s 2 s 3 s 4</cell></row><row><cell>p 1</cell><cell>4</cell><cell>4</cell><cell>4</cell><cell>4</cell></row><row><cell>p 2</cell><cell>8</cell><cell>3</cell><cell>3</cell><cell>3</cell></row><row><cell>p 3</cell><cell>7</cell><cell>8</cell><cell>2</cell><cell>2</cell></row><row><cell>p 4</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>1</cell></row><row><cell>Figure 2:</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 : Parameters in Experiments</head><label>1</label><figDesc></figDesc><table><row><cell>Parameter</cell><cell>Description</cell></row><row><cell>d</cell><cell>Dimension Number</cell></row><row><cell>Size</cell><cell>Data Size</cell></row><row><cell>Dist</cell><cell>Distribution</cell></row><row><cell>k</cell><cell>Constraint Parameter</cell></row><row><cell>δ</cell><cell>Top Dominant Skyline Point Number</cell></row><row><cell>w</cell><cell>Constrained Parameter in Weighted Query</cell></row><row><cell>R</cell><cell>the ratio of maximum weight to minimum weight</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 : Dominant Skyline Point Number</head><label>2</label><figDesc></figDesc><table><row><cell>k</cell><cell>Correlated</cell><cell>Independent</cell><cell>Anti-Correlated</cell></row><row><cell>8</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>9</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>10</cell><cell>8</cell><cell>3</cell><cell>0</cell></row><row><cell>11</cell><cell>24</cell><cell>61</cell><cell>33</cell></row><row><cell>12</cell><cell>57</cell><cell>960</cell><cell>3175</cell></row><row><cell>13</cell><cell>134</cell><cell>7881</cell><cell>28305</cell></row><row><cell>14</cell><cell>436</cell><cell>33087</cell><cell>67866</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 : Top-5 Dominant Skyline Results on NBA data set</head><label>3</label><figDesc></figDesc><table><row><cell>Equal Weight</cell><cell>Defender Biased</cell><cell>Shooter Biased</cell></row><row><cell>Wilt Chamberlain 1961</cell><cell>Wilt Chamberlain 1961</cell><cell>Wilt Chamberlain 1961</cell></row><row><cell>Bob Mcadoo 1974</cell><cell>Artis Gilmore 1974</cell><cell>Rick Barry 1971</cell></row><row><cell>George Mcginnis 1974</cell><cell>George Mcginnis 1974</cell><cell>Michael Jordan 1986</cell></row><row><cell cols="3">Kareem Abdul-jabbar 1975 Kareem Abdul-jabbar 1975 Michael Jordan 1987</cell></row><row><cell>Julius Erving 1975</cell><cell>Julius Erving 1975</cell><cell>Michael Jordan 1988</cell></row><row><cell>Artis Gilmore 1975</cell><cell>Michael Jordan 1987</cell><cell>Michael Jordan 1989</cell></row><row><cell>Michael Jordan 1986</cell><cell></cell><cell>Gary Payton 1999</cell></row><row><cell>Michael Jordan 1987</cell><cell></cell><cell>Kobe Bryant 2002</cell></row><row><cell>Michael Jordan 1988</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 : Top-5 Dominant Skyline Result on Movie- Lens data set</head><label>4</label><figDesc></figDesc><table><row><cell>Equal Weight</cell><cell>Rate Number Based</cell></row><row><cell>Star Wars (1977)</cell><cell>Star Wars (1977)</cell></row><row><cell>Fargo (1996)</cell><cell>Pulp Fiction (1994)</cell></row><row><cell>Contact (1997)</cell><cell>Silence of the Lambs (1991)</cell></row><row><cell cols="2">English Patient (1996) Fargo (1996)</cell></row><row><cell>Scream (1996)</cell><cell>Godfather (1972)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>http://www.phonescoop.com/phones/finder.php?m=e</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>http://movielens.umn.edu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>For space efficiency, instead of storing data points in Di, the array entries can simply store pointers to the points in D.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements Chee-Yong Chan and Kian-Lee Tan are supported in part by NUS Grant R-252-000-207-112. H.V. Jagadish is supported in part by US National Science Foundation Grant IIS-0438909.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">On Synthetic Data Sets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.1">On k-Dominant Skyline</head><p>We evaluate the computational costs of the algorithms on three different distributions with respect to the constraint parameter k. From the results in Fig. <ref type="figure">4</ref>, we observe that TSA is more efficient than the other two methods on all distributions when k &lt; 12. This is because the dominant skyline points can prune almost all other points in the first scan (as implied in Theorem 4.2). However, as k increases, TSA becomes slower than SRA since there are too many false candidates left after the first scan. It is even worse than OSA on anti-correlated data set when k = 14. The performance of OSA is stable in all cases because the computation of free skyline cannot be reduced with small k, and this computation dominates the computation time.</p><p>In Fig. <ref type="figure">5</ref>, we show the influence of dimensionality on the efficiencies of the three algorithms. When k is small, both TSA and SRA are much faster than OSA on all three distributions. When k is close to the dimensionality d, TSA is less efficient than OSA. With increasing dimensionality, this disadvantage grows so great that TSA is several times slower than the other two algorithms on 20-dimensional data set with k = 19. As shown in the figure, SRA is more scalable on high dimensional data sets.</p><p>We also study the effect of the size of the datasets on the performances of the three algorithms. The results, depicted in Fig. <ref type="figure">6</ref>, show that when the size of the data set grows from 50K to 200K, the computation time of the three algorithms all increase by about one order of magnitude. Moreover, the relative performance of the schemes remain largely the 4 http://www.basketballreference.com/ 5 http://movielens.umn.edu/ same as that in earlier experiments: TSA performs best while OSA is the most inferior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.2">On Top-δ Dominant Skyline</head><p>For top-δ dominant skyline query, the most important parameter is δ, the number of dominant skyline points desired. The efficiency of TSA on top-δ query is strongly related to the distribution of the dominant skyline points. On the 15dimensional correlated data set, for example, there are 57 dominant skyline points when k = 12 (shown in Table <ref type="table">2</ref>). When δ grows from 50 to 100, TSA has to run on k = 13 instead of k = 12 before finding all these top dominant skyline points. Since the computation time of TSA on k = 13 is much more than that on k = 12 (shown in Fig. <ref type="figure">4</ref>), it spends much more time on top-100 query than top-50 query. Using the same logic, we can explain all the sudden increase in time of TSA on Fig. <ref type="figure">7</ref>. For SRA, the increase of computation time of SRA is much smaller because fewer points in the candidate set do not improve the pruning threshold of lower bounds greatly in the early stages of SRA. Unlike the other two algorithms, OSA's efficiency is worst but it is the most stable since the final number of points desired does not have impact on its computing process until the final step.</p><p>When tested on data sets with different dimensions, we observe from Fig. <ref type="figure">8</ref> that TSA is faster on higher dimensional data set on anti-correlated distribution. This phenomenon is still related to the distribution of the dominant skyline points. When dimensionality grows, the top dominant skyline points can be obtained at a lower level of k, which contributes to TSA's efficiency. OSA and SRA cannot take advantage of this since both schemes' efficiency are proportional to the dimension number but not to the level where the top-dominant skyline can be obtained.</p><p>In Fig. <ref type="figure">9</ref>, we present the impact of data size on the efficiency of top-δ dominant skyline query. The trends of the algorithms are similar to the performance to that on k-dominant skyline query shown in Fig. <ref type="figure">6</ref>: TSA performs the best, followed by SRA, and OSA is the worst.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.3">On Weighted Dominant skyline</head><p>In this set of experiments, we examine the performance of the three algorithms on weighted dominant skyline queries. When the ratio R of the weights increases, most of the weight is assigned to a smaller fraction of the dimensions. If a point is not dominated on those dimensions with heavy weights, they are very likely to be dominant skyline points since any subspace with weight sum over w must contain some of these dimensions. This impact is not large but is still observable in Fig. <ref type="figure">10</ref>. TSA and SRA turn out to be faster on independent and anti-correlated data sets when the weight ratio is varied from 2 to 5. This improvement in efficiency is not as significant in correlated data set because the dominant skyline does not change with the variation of weights on correlated distribution. Since the dominating set is independent of dimension weights, no matter what the weights are, the OSA algorithm stays at the same level in all three types of data sets.</p><p>To summarize, from the experiments on synthetic data sets, we can conclude that when k, δ and Size are small, TSA is the most efficient algorithm. In other cases, SRA is faster than the others and has more stable performance on different data sets.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A framework for expressing and combining preferences</title>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Wimmers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The skyline operator</title>
		<author>
			<persName><forename type="first">S</forename><surname>Börzsönyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kossmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Stocker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On high dimensional skylines</title>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K H</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EDBT</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Skyline with presorting</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chomicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gryz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Optimal aggregation algorithms for middleware</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fagin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lotem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PODS</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Maximal vector computation in large data sets</title>
		<author>
			<persName><forename type="first">P</forename><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shipley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gryz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Distance browsing in spatial databases</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Hjaltason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Samet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TODS</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Foundations of preferences in database systems</title>
		<author>
			<persName><forename type="first">W</forename><surname>Kießling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Shooting stars in the sky: an online algorithm for skyline queries</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kossmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ramsak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On finding the maxima of a set of vectors</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Luccio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Preparata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JACM</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Dada: A data cube for dominant relationship analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Ooi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K H</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Drawing contours from arbitrary data points</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Mclain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Computer Journal</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1974-11">November 1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An optimal and progressive algorithm for skyline queries</title>
		<author>
			<persName><forename type="first">D</forename><surname>Papadias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Seeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Progressive skyline computation in database systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Papadias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Seeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TODS</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Computational Geometry: An Introduction</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Preparata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Shamos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient progressive skyline computation</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Eng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Ooi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Efficient computation of skyline cube</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
