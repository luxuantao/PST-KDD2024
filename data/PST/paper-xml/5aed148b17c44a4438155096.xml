<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cross-Domain Depression Detection via Harvesting Social Media</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tiancheng</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Key Laboratory of Pervasive Computing</orgName>
								<orgName type="department" key="dep2">Ministry of Education Beijing National Research Center for Information Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jia</forename><surname>Jia</surname></persName>
							<email>jjia@tsinghua.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Key Laboratory of Pervasive Computing</orgName>
								<orgName type="department" key="dep2">Ministry of Education Beijing National Research Center for Information Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Guangyao</forename><surname>Shen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Fuli</forename><surname>Feng</surname></persName>
							<email>fulifeng93@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Key Laboratory of Pervasive Computing</orgName>
								<orgName type="department" key="dep2">Ministry of Education Beijing National Research Center for Information Science and Technology</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
							<email>xiangnanhe@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
							<email>luanhuanbo@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Key Laboratory of Pervasive Computing</orgName>
								<orgName type="department" key="dep2">Ministry of Education Beijing National Research Center for Information Science and Technology</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
							<email>jietang@tsinghua.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Key Laboratory of Pervasive Computing</orgName>
								<orgName type="department" key="dep2">Ministry of Education Beijing National Research Center for Information Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thanassis</forename><surname>Tiropanis</surname></persName>
							<email>t.tiropanis@southampton.ac.uk</email>
							<affiliation key="aff3">
								<orgName type="department">Electronics and Computer Science</orgName>
								<orgName type="institution">University of Southampton</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wendy</forename><surname>Hall</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Electronics and Computer Science</orgName>
								<orgName type="institution">University of Southampton</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Cross-Domain Depression Detection via Harvesting Social Media</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Depression detection is a significant issue for human well-being. In previous studies, online detection has proven effective in Twitter, enabling proactive care for depressed users. Owing to cultural differences, replicating the method to other social media platforms, such as Chinese Weibo, however, might lead to poor performance because of insufficient available labeled (self-reported depression) data for model training. In this paper, we study an interesting but challenging problem of enhancing detection in a certain target domain (e.g. Weibo) with ample Twitter data as the source domain. We first systematically analyze the depressionrelated feature patterns across domains and summarize two major detection challenges, namely isomerism and divergency. We further propose a crossdomain Deep Neural Network model with Feature Adaptive Transformation &amp; Combination strategy (DNN-FATC) that transfers the relevant information across heterogeneous domains. Experiments demonstrate improved performance compared to existing heterogeneous transfer methods or training directly in the target domain (over 3.4% improvement in F1), indicating the potential of our model to enable depression detection via social media for more countries with different cultural settings.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Depression has been one of the leading factors to global burden of disease, with more than 300 million people affected <ref type="bibr">[WHO, 2017]</ref>. Preventing depression can conduce to human well-being, of which early detection is an essential task. Powerful depression criteria like <ref type="bibr">ICD-10 [WHO, 1992]</ref> have been widely employed in clinical diagnosis. However, people are somehow antipathetic towards consulting psychological doctors, especially at the early stage of depression, leading to the deterioration of condition.</p><p>Nowadays, people are increasingly relying on social media like Twitter 1 and Weibo 2 to share their daily activities and thoughts. The user-generated content may further reflect their personal states, hence enabling the analysis of users' mental wellness via harvesting social media. Psychological studies over depressed users online have been conducted in recent years, considering users' social networks, linguistic patterns, attitudes, etc. <ref type="bibr" target="#b8">[Park et al., 2013;</ref><ref type="bibr">Xu and Zhang, 2016]</ref>. Research efforts on depression detection were also made. <ref type="bibr" target="#b8">Park et al. [2013]</ref> for the first time managed to detect depressive disorders via Twitter, while Shen et al. <ref type="bibr">[2017]</ref> further proposed a multimodal depressive dictionary learning model. With such online detection systems, proactive care could be provided for depressed users.</p><p>The greatest challenge of online depression detection lies in the labeling of depressed users for model training. Traditional methods like questionnaires employed in <ref type="bibr" target="#b8">[Park et al., 2013]</ref> are credible, but expensive and inefficient. It is worth mentioning that Shen et al. <ref type="bibr">[2017]</ref> constructed a large well-labeled Twitter dataset by self-reported sentence pattern matching (i.e., matching depression-related expressions like "I'm diagnosed with depression" in user-generated content). Sufficient labeled training data enables effective depression detection in Twitter. However, replicating the method to other social media platforms might face challenges due to cultural differences, e.g. distinctive attitudes towards depression and disparate online depression discussion environment [Wang and <ref type="bibr" target="#b9">Liu, 2004;</ref><ref type="bibr" target="#b3">Kleinman, 2004]</ref>. Taking for example Twitter and Weibo, the prevalent platform respectively in the West and in China, by using the patterns utilized in <ref type="bibr" target="#b8">[Shen et al., 2017]</ref>, we found 481 depressed users out of 100 million randomly crawled tweets in Twitter while only 142 matches were obtained when we repeated the trial in Weibo. This leads us to an interesting but challenging problem: can we utilize the multi-source datasets to improve depression detection performance for a specific platform?</p><p>In this work, we systematically study the problem by employing Twitter and Weibo as the source and target domain respectively. Considering cultural diversities, this is nontrivial owing to the following challenges: 1) How to bridge the gap between the heterogeneous feature spaces of different domains? 2) How to design a model that exploits the source domain data to enhance detection for the target domain? We first construct benchmark datasets from Twitter and Weibo. For Weibo, we crawl 400 million tweets from which 580 depressed and 580 non-depressed users are obtained via selfreported sentence pattern matching. For Twitter, we employ the dataset constructed by <ref type="bibr" target="#b8">Shen et al. [2017]</ref>, with 1,394 depressed and 1,394 non-depressed users. We then conduct indepth investigations over feature patterns across domains and find that in different domains, the same feature may follow distinctive distributions (isomerism), or contribute to detection disparately (divergency). Leveraging the discoveries, we propose a cross-domain Deep Neural Network model with Feature Adaptive Transformation &amp; Combination strategy (DNN-FATC) to effectively transfer the relevant information across heterogeneous domains. We conduct extensive experiments and our model significantly outperforms existing heterogeneous transfer approaches (+3.4% to +4.8% in F1), as well as directly training with the Weibo dataset (+5.2% to +14.3% in F1). Figure <ref type="figure" target="#fig_0">1</ref> presents our framework.</p><p>We summarize the main contributions as follows:</p><p>• We propose the problem of enhancing online depression detection with multi-source datasets, which is novel to our knowledge. We also construct benchmark datasets to facilitate the research community. • We reveal two major detection challenges regarding cross-domain feature patterns, defined as isomerism and divergency. This provides the theoretical guidance for cross-domain depression detection models. • We propose a model named DNN-FATC which achieves remarkable performance in the poorly labeled target domain by utilizing the rich data of source domain. This will hopefully facilitate depression detection via social media for more countries of different cultural settings.</p><p>2 Related Work</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Online Depression Analysis and Detection</head><p>Psychological studies over online depressed users have been conducted in recent years. <ref type="bibr" target="#b8">Park et al. [2012]</ref> analyzed language use in describing depressive moods in Twitter. <ref type="bibr" target="#b8">Park et al. [2013]</ref> explored Twitter users' depressive attitudes and behaviors via face-to-face interviews. Xu and Zhang <ref type="bibr">[2016]</ref> studied online discussion of depression-related issues in terms of social networks and linguistic patterns.</p><p>Combined with these researches, depression detection via social media has become possible. <ref type="bibr" target="#b0">[Choudhury et al., 2013]</ref> first explored the potential of employing social media to detect major depressive disorders. <ref type="bibr">Wang's two works [2013a;</ref><ref type="bibr" target="#b9">2013b]</ref> presented a model to calculate the probability of a user being depressed, based on both node and linkage features. <ref type="bibr" target="#b8">Resnik et al. [2015]</ref> studied the supervised topic models in analysis of linguistic signals for detecting depression. <ref type="bibr" target="#b8">Shen et al. [2017]</ref> proposed a multimodal depressive dictionary learning model that combined multi-modal features. These depression detection efforts demonstrated the feasibility of analysis over massive depressed users in social media.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Heterogeneous Transfer Learning</head><p>Transfer learning aims to create a high-performance learner for the target domain trained from related source domains <ref type="bibr" target="#b9">[Weiss et al., 2016]</ref>. Existing transfer methods were proposed mainly to deal with textual or visual tasks by leveraging numerous unimodal low-level features. ARC-t <ref type="bibr" target="#b5">[Kulis et al., 2011]</ref> learns an asymmetric transformation to transfer feature knowledge. <ref type="bibr">MMDT [Hoffman et al., 2013]</ref> jointly learns affine separating hyperplanes in the source and a transformation from target points into the source. HFA <ref type="bibr" target="#b6">[Li et al., 2014]</ref> projects the feature spaces to a common latent space.</p><p>However, such methods may be unsuitable for depression detection where correspondences of features across domains are usually quite clear, e.g., follower count in Twitter simply corresponds to follower count in Weibo. Thus, the sophisticated feature mapping methods make little sense. In fact, the difficulty here lies mainly in the very different patterns and the possibly opposite influences on classification of the same feature across domains. Therefore, a new transfer method specific to cross-domain depression detection is in need.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Formulation</head><p>Suppose V is a set of users on a certain social media platform, and N denotes the total number of users. Each user v i ∈ V is represented by an M -dimensional feature vector which may involve multiple categories and vary in different platforms. Let X ∈ R N ×M be the feature matrix. The depression state of user v i is denoted by two-valued variable y i , and y ∈ R M is the depression states of all users. The dataset of the social media can be denoted by D = {X, y}.</p><p>The study involves two datasets D S and D T , corresponding to two different social media platforms. Following the common formulation in transfer learning, D S and D T refer to datasets from the source and target domain, respectively. We intend to detect depressed users in D T based on both datasets. In particular, we only have few labeled samples in D T for model training, in accordance with the common setting in supervised transfer learning problems <ref type="bibr" target="#b1">[Daumé III, 2007;</ref><ref type="bibr" target="#b0">Chattopadhyay et al., 2012]</ref>. That is to say, D T can be represented as</p><formula xml:id="formula_0">D T = D TL ∪ D T U , where D TL = {X TL , y TL }, D T U = {X T U }, X TL ∈ R N TL ×M T , X T U ∈ R N TU ×M T , N T = N TL + N T U , N TL N T U and N TL N S .</formula><p>On the other hand, the two platforms may have partially different features. Since the aim is to detect depression in D T , we leave out the features that are available only in D S . Thus, D S and D T share M S common features while D T has another M E exclusive features.</p><p>With notations above, we formally define our problem as: given the source and target domain datasets D S and D T , where D T = D TL ∪D T U has limited labels and partially exclusive features, we aim to learn function f : {D S , D TL , D T U } → y T U to detect the depression states of users in D T U . The number of followers, friends and favorites and proportion of bi-followers.</p><p>4 Data and Features</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Collection</head><p>We take Twitter and Weibo as the source and target domain respectively. Depression typically results from cumulative events or disorder and users may show chronic depressive tendency in a series of tweets rather than one. As is illustrated in <ref type="bibr">ICD-10 [WHO, 1992]</ref>, It takes at least two weeks to make a definite diagnosis of depression. Therefore, in accordance with clinical experiences, each sample includes a period of four weeks of tweet data, together with the user profile.</p><p>Weibo Dataset D T . We construct D T based on 400 million crawled tweets from 2009.10 to 2012.10. Inspired by Shen et al. <ref type="bibr">[2017]</ref>, users are identified as depressed when self-reported sentence pattern " I'm diagnosed with depression" is matched. A sophisticated Chinese regular expression 3 is designed that both excludes noisy content and takes into account the flexible ways of Chinese expressions. The matched tweets are further manually checked whether containing a genuine depression diagnosis statement. Eventually, 580 depressed users are identified out of the original dataset. Besides, users are labeled as non-depressed if no tweets containing "depress" were published in the sampling period. We randomly select 580 non-depressed users to keep a balance with the depressed samples in terms of scale. Manual check is also made that no depression-related content is involved.</p><p>Twitter  <ref type="table" target="#tab_0">1</ref>.</p><p>Textual Features (20 dimensions). Textual features are extracted in statistical forms to eliminate linguistic differences. We take the most commonly used linguistic features in sentiment analysis via <ref type="bibr">TextMind [Gao et al., 2013]</ref>, a Chinese language psychological analysis system, in consistence with the corresponding features in D S extracted by LIWC <ref type="bibr" target="#b8">[Pennebaker et al., 2001]</ref>. Emoticons of different sentiment polarities are also studied to evaluate users' emotional states.</p><p>Visual Features (21 dimensions). Based on previous work on affective image classification and color psychology theories <ref type="bibr" target="#b4">[Kobayashi, 1981</ref>; ?], we perform image processing and color-related attributes computation.</p><p>User Profile &amp; Posting Behavior Features (30 dimensions). We focus on posting behaviors to assess users' activeness. Tweeting time is studied as a reflection of daily schedules. For user profile, inspired by <ref type="bibr" target="#b8">[Piccinelli and Wilkinson, 2000;</ref><ref type="bibr" target="#b7">Li et al., 2015]</ref>, we extract gender and screen name length of Weibo users. Note the user profile is quite trustable, since real-name authentication is compulsory in Weibo.</p><p>Social Interaction Features (7 dimensions). It was found that depressed users were more sensitive in social media, longing more for social awareness and self-consoling <ref type="bibr" target="#b8">[Park et al., 2013]</ref>. Therefore, we consider the typical social interaction behaviors, e.g. following, retweeting and mentioning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Data analysis</head><p>We further investigate the distributions of features and summarize two major detection challenges regarding crossdomain feature patterns. For each challenge, we present detailed explanations with a specific example.</p><p>Isomerism. One feature may follow distinctive integral distributions in different domains. We call this isomerism. The definition is unrelated to specific user groups (i.e., depressed / non-depressed users). Taking follower count for instance, the feature distribution varies greatly in the two plat- Divergency. Due to cultural differences, the same feature may have distinctive, or even opposite implications on depression detection in different domains. We call this divergency and such features are referred to as divergent features. Figure <ref type="figure">2</ref>(e) and 2(f) show the distributions of recent tweet count of different user groups. Surprisingly, the feature seems to contribute oppositely to detection in the two platforms. In Twitter, depressed users post relatively less tweets than the non-depressed, while the contrary is true in Weibo. Besides, divergent features also include positive word count, image saturation, etc and may tremendously impact the validity of transfer methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Methodology</head><p>The isomerism and divergency of features pose great challenges in effectively utilizing the knowledge learned from the source domain data. Therefore, we propose a cross-domain Deep Neural Network model with Feature Adaptive Transformation &amp; Combination strategy (DNN-FATC) to handle these problems. Since D T is sparsely labeled, we construct the model based mainly on D S . The shared features, which are elucidated in Section 5.1 and 5.2, are processed against isomerism and divergency respectively, so that the model trained in the source domain can also perform well in the target domain. The extra features are integrated into the deep frame-work in the end, as stated in Section 5.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Feature Normalization &amp; Alignment (FNA)</head><p>As elaborated in Section 4.3, integral distributions of a feature might differ greatly across domains. Normalization aims to obtain a standard position of objects <ref type="bibr" target="#b8">[Rothe et al., 1996]</ref> while the frequently used min-max and zero-mean method do not perform well in our problem. This is because they rely on the mean, minimum or maximum of data, which may be gravely impacted by extreme values.</p><p>We perform transformations of feature normalization &amp; alignment to fill the distributional gap of features, or in other words, to reduce the isomerism. Let vector x S ∈ R N S , x T ∈ R N T denote a same feature in D S and D T , we learn two linear transformations with parameters a S , a T , b S , b T that transform x S , x T into x * S , x * T and minimize their Bhattacharyya distance, an effective divergence measure of probability distributions <ref type="bibr" target="#b2">[Kailath, 1967]</ref>. Let u * 0 , u * K be the minimum and the maximum of the joint vector (2) Eqn. 2 focuses on feature alignment and has infinitely many solutions. We further add two constraints. 1) We assume that the median of x * T is exactly zero so that the transformed distribution is generally symmetric around the origin, which may be beneficial in the subsequent processing (Section 5.2). 2) For x * S , we focus on the q 1 % and q 2 % (q 1 &lt; q 2 ) quantile in terms of scaling. We uniformly map the data between the two quantiles into an interval with a fixed length of l. To understand this, a simple situation is when q 1 = 0, q 2 = 100 and l = 2, the transformation is equivalent to min-max normalization. With q 1 and q 2 changeable, we can get rid of the q 1 % or q 2 % extreme data on both sides and robustly fit to features of various distributions. Suppose Q(x, q) denotes the q% quantile of x, we then have</p><formula xml:id="formula_1">a T Q(x T , 50) + b T = 0, (3) a S [Q(x S , q 2 ) − Q(x S , q 1 )] = l,</formula><p>(4) and the four parameters a S ,a T ,b S ,b T can be determined to get normalized x * S and x * T with similar distributions. Figure <ref type="figure">2(d)</ref> shows the transformed follower count with K = 100, q 1 = 25, q 2 = 25 and l = 0.5, which is quite desirable.</p><p>After performing the above method on all the M S shared features, distinction between the feature spaces of two domains can be reduced to the minimum, enabling us to take full advantage of the abundant labeled samples in D S during model training. Thus, we train a classifier H S based on dataset D S . In this work, a DNN is employed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Divergent Feature Conversion (DFC)</head><p>We illustrate the existence of divergent features in Section 4.3. With such features, even if they share similar integral distributions in the two domains and classfier H S possesses good differentiation ability, direct application in the target domain will lead to totally wrong results. The key here is to find out the divergent features, and thereby conduct a targeted transformation. Considering the high complexity of H S , the transformation is performed on each target domain feature vector x * Ti with two conversion factors α i and β i . We have x * * Ti = α i x * Ti + β i , for i = 1, 2, . . . , M S , or in terms of matrix, X * * T = αX * T + βI.</p><p>(5) To recognize the divergent features, dataset D TL is employed for validation. We analyze the detection results of H S with different values of α i and β i , and preserve the parameter values which optimize the performance. A divergent feature is found when better performance is achieved with α i &lt; 0. In reality, the identification result of one feature may change when other divergent features are converted. That is to say, the optimization problem relies on the combination of all features. Let F (H, D) be the performance indicator of model H over dataset D. Then we formulate the problem as</p><formula xml:id="formula_2">α * , β * = arg max α,β F (H S , {αX * TL +βI, y TL }) .<label>(6)</label></formula><p>To solve Eqn. 6, the complexity of enumeration is O(</p><formula xml:id="formula_3">(|α i | • |β i |) M S )</formula><p>, where |α i |, |β i | denote the number of respective possible values. This is unsolvable in practice. Therefore, we set W as an upper bound for the times of enumeration. In each iteration, we traverse all the features in a random sequence, determine α i and β i for each feature orderly, and record α * , β * which lead to the best performance in the W trials, as the solution to Eqn. 6. In this way, we reduce the complexity without ignoring the interrelation among features.</p><p>After FNA, each pair of feature vectors x * Ti and x * Si have similar distributions which are roughly symmetric around the origin (note the median of x * Ti is exactly 0). For divergent features, we intend to maintain the property to guarantee the validity of H S in D T and at the same time, reverse the mistaken impact on depression detection. As a result, we assume that α i ∈ {−1, 1} and β i = 0 so as to simultaneously realize the two targets. Specifically, when α i = −1 and β i = 0, a centrosymmetric transformation is performed and the impact is inverted in D T . Thus the conversion factor is a binary choice for each feature. We give up the original value of x * Ti on condition that an improvement of performance indicator over a threshold σ is observed after conversion. σ is proposed to avoid overfitting. With α * , β * solved, we conduct the conversion for samples in D T by X * * T = αX * T + βI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Feature Combination (FC)</head><p>With shared features well dealt with, we now combine the exclusive features in D T into the deep framework. Suppose H S is a d-layer network, with n i neurons in the i th layer, for i = 1, 2, . . . , d, where n 1 = M S and n d = 2. We feed the M E exclusive features into the δ th layer (δ &lt; d), and thus build another (d−δ+1)-layer DNN denoted by H T , with (n δ +M E ) neurons in the 1 st layer, and n j+δ neurons in the (j + 1) th layer, for j = 1, 2, . . . , d − δ. Similarly, as for detection of samples in D T U , the feature matrix of which has been transformed into X * * T U (Section 5.2), we input the M S shared features into H S for the intermediate n δ results, and then obtain the final predicted label with H T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Setup</head><p>We conduct experiments on datasets constructed in Section 4, where D S has 2,788 samples and D T has 1,160. Each dataset has an equal split of depressed and non-depressed users. We take 280 samples (approximately 10% the size of D S ) in D T as D TL and the remaining as D T U for testing.</p><p>Since the proposed DNN-FATC model has multiple steps, we comprehensively compare all the combinations of different processing approaches in each step. We consider the following feature normalization methods:</p><p>• Min-Max Normalization (MN). Mapping all the data into [0, 1] according to the maximum and the minimum. Section 5.3. We also compare DNN-FATC with the following heterogeneous transfer learning approaches:</p><p>• ARC-t <ref type="bibr" target="#b5">[Kulis et al., 2011]</ref>. It learns an asymmetric transformation metric between different feature spaces.</p><p>• <ref type="bibr">MMDT [Hoffman et al., 2013]</ref>. It transforms all target features to a new domain-invariant representation.</p><p>• HFA <ref type="bibr" target="#b6">[Li et al., 2014]</ref>. It learns a latent common space between the source and target domain. In experiments, we combine the three normalization approaches with different dataset utilization methods and DNN-FATC can be represented as FNA+DFC+FC. For the three transfer approaches, we employ the released codes of their papers. In each trial, D T is randomly split into two unequalsized sets D TL and D T U . The detection performance on D T U of each method is reported after over 10 randomized experimental runs, respectively in terms of precision, recall and F1measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Experimental Results</head><p>Performance. We report the performance of all methods in Table <ref type="table" target="#tab_4">3 and 4</ref>  ity and the full results can be accessed online 4 . DNN-FATC achieves the best performance, with 78.5% in F1-measure.</p><p>From Table <ref type="table" target="#tab_3">3</ref>, we have the following observations: 1) In terms of normalization, methods with FNA consistently outperform those using MN and ZN, demonstrating the effectiveness of FNA in reducing isomerism. In fact, FNA even works for direct learning, indicating the universality of normalization approaches with the idea of mapping two quantiles into a fixed-length. 2) DFC notably outperforms BP, indicating that in domain adaptation, divergence is a critical issue and DFC is a remarkable processing method. 3) DL and DFC+FC respectively outperform DL S and DFC, manifesting that the D Texclusive features extracted in Section 4.2, e.g. topic-related words and user profile, are helpful to detection, and moreover, FC is an effective way to utilize them.</p><p>Table <ref type="table" target="#tab_4">4</ref> shows the performance of transfer approaches, together with FNA+DL, the optimal direct learning method. It can be summarized that D S is useful to enhance depression detection in D T and DNN-FATC best fits the assignment.</p><p>Parameter Analysis. For results reported in Table <ref type="table" target="#tab_3">3</ref> and 4, we use a sigmoid activation function for DNN-FATC and the hyper-parameters are set as K = 100, W = 50, q 1 = q 2 = 25, l = 0.5, σ = 0.01, d = 4, δ = 2 for optimization after careful tuning. Actually, according to our extensive experiments, parameters have just limited impact on performance and four influential parameters are presented here. 1) Structural parameters of DNN d, δ. As illustrated in Figure <ref type="figure">3</ref>(a), the best performance is obtained when d = 4, δ = 2 and inserting exclusive features into the intermediate layer is a better 4 http://cross_domain_depression_detection.droppages.com/.</p><p>choice in feature combination. 2) FNA parameters q 1 , q 2 . We assume q 1 = q 2 = q for simplicity and Figure <ref type="figure">3</ref>(b) presents the performance with variation of q. DNN-FATC is optimal when q = 0.25, a moderate proportion of extreme data is excluded.</p><p>Data scalability Analysis. We train the model with different scales of labeled data in D T . Figure <ref type="figure">3</ref>(c) illustrates the results, which shows that our model consistently outperforms direct learning. It is clear that DNN-FATC is of high applicability when target domain data has limited labels.</p><p>Feature Group Analysis. To understand the effectiveness of different feature groups, we test our model with one feature group unselected each time. Four situations are denoted as DNN-FATC-T, DNN-FATC-V, DNN-FATC-U and DNN-FATC-S, respectively. As is shown in Figure <ref type="figure">3</ref>(d), the performance severely hurts when textual features are removed while visual features contribute to detection slightly.</p><p>Case Study: Depressive Behaviors Discovery. Shen et al. <ref type="bibr">[2017]</ref> discussed depressive behaviors in Twitter, while we also investigate some distinguishing features in Weibo, which is illustrated in Figure <ref type="figure">3</ref>(e) and 3(f). We discover that in Weibo: 1) The depressed users are more likely to post tweets between 22:00 and 6:00, indicating that they are susceptible to insomnia. 2) Female users are more likely to suffer from depression. 3) Depressed users tend to use more biologyrelated words and first person singulars, manifesting more concern about health issues and personal affairs. 4) Depressed users are retweeted less, which may reflect their lack in social engagement and attention from others.</p><p>On the other hand, we also look into the divergent features which have dissimilar indication on detection across domains. We count for each feature the frequency of being converted in DFC and show the top-6 divergent features in Figure <ref type="figure">3</ref>(g). Besides tweets count, positive word count also contributes disparately to depression detection in Twitter and Weibo.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we raised the problem of enhancing depression detection via social media with multi-source datasets. We proposed a cross-domain Deep Neural Network model with Feature Adaptive Transformation &amp; Combination strategy (DNN-FATC) to transfer the relevant information across heterogeneous domains. Experimental results verified the effectiveness of our method. In the future, we expect to further improve online detection by combining offline researches, and contribute to the well-being of more people.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An illustration of our framework.</figDesc><graphic url="image-1.png" coords="1,322.74,216.00,227.52,134.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 2: Feature distributions. (a)-(d) illustrate follower count processed in different ways (as marked in brackets).forms and a cap of 2,000 is imposed in Weibo, as can be seen from Figure2(a). Thus, the same number of followers might have different implications across domains. For example, owning 128 followers has reached the middle level in Twitter, while this barely exceeds 14% of users in Weibo, indicating relatively low social engagement. Isomerism is quite common in the dataset and we attempt to reduce such differences by normalization methods like min-max normalization and zero-mean normalization, with results presented in Figure 2(b) and 2(c), where distinctions are still obvious. Consequently, an effective method is required to reduce the isomerism of features across domains.Divergency. Due to cultural differences, the same feature may have distinctive, or even opposite implications on depression detection in different domains. We call this divergency and such features are referred to as divergent features. Figure2(e) and 2(f) show the distributions of recent tweet count of different user groups. Surprisingly, the feature seems to contribute oppositely to detection in the two platforms. In Twitter, depressed users post relatively less tweets than the non-depressed, while the contrary is true in Weibo. Besides, divergent features also include positive word count, image saturation, etc and may tremendously impact the validity of transfer methods.</figDesc><graphic url="image-7.png" coords="4,171.90,186.44,135.35,53.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>[x * T S , x * T T ], and divide the interval [u * 0 , u * K ] into K isometric intervals. Let p * Si and p * T ibe the proportions of elements in x * S and x * T that take value in the i th interval , we then havex * S = a S x S + b S , x * T = a T x T + b T ,(1)s.t. a S , a T , b S , b T = arg min a S ,a T ,b S ,b T − ln K i=1 p * Si p * T i .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure1provides a schematic illustration where d = 4, δ = 2, M E = 3, M S = n 1 = 6, n 2 = 4, n 3 = 3 and n 4 = 2. We set up H T with weights initialized to those of H S , except for weights in relation to the newly added M E neurons. In the subsequent processing, the last (d − δ) layers of H S are no longer used while the first δ layers of H S provide the n δ values for the input layer of H T . Based on above settings, we train H T on D TL via back propagation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Figure 3: Experimental results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Summary of features, where # S and # T denote the feature dimensionality of Twitter and Weibo, respectively. The number of words related to biology, body, health, death, society, money, work and leisure.</figDesc><table><row><cell>Group</cell><cell>Feature</cell><cell cols="2">#S #T</cell><cell>Description</cell></row><row><cell></cell><cell>Emotional Word Count</cell><cell>2</cell><cell>2</cell><cell>The number of positive and negative emotional words.</cell></row><row><cell></cell><cell>Emoticon Count</cell><cell>3</cell><cell>3</cell><cell>The number of positive, neutral and negative emoticons.</cell></row><row><cell></cell><cell>Pronoun Count</cell><cell>2</cell><cell>3</cell><cell>The number of first-person singular / plural pronouns, and other personal pronouns.</cell></row><row><cell>Textual</cell><cell>Punctuation Count</cell><cell></cell><cell>3</cell><cell>The number of 3 typical punctuations('!' , '?' , '...').</cell></row><row><cell></cell><cell>Topic-Related Word Count</cell><cell></cell><cell>8</cell><cell></cell></row><row><cell></cell><cell>Text Length</cell><cell>1</cell><cell>1</cell><cell>The mean length of the tweet texts.</cell></row><row><cell></cell><cell cols="2">Saturation &amp; Brightness 4</cell><cell>4</cell><cell>The mean value of saturation and brightness, and their contrasts.</cell></row><row><cell>Visual</cell><cell>Warm/Clear Color</cell><cell>2</cell><cell>2</cell><cell>Ratio of colors with hue in [30, 110] and colors with saturation &lt; 0.7.</cell></row><row><cell></cell><cell>Five-Color Theme</cell><cell cols="3">15 15 A combination of five dominant colors in HSV color space.</cell></row><row><cell>User Profile &amp; Posting Behaviour</cell><cell>User Profile Tweet Count Tweeting Type Tweeting Time</cell><cell cols="3">2 2 2 24 24 The proportion of tweets posted in each hour of the day. Gender and length of screen name. 2 The number of tweets published in the certain 4 weeks and ever since. 1 The proportion of original tweets and tweets with pictures.</cell></row><row><cell>Social</cell><cell>Social Engagement</cell><cell>1</cell><cell>3</cell><cell>The number of retweets, comments and mentions per tweet.</cell></row><row><cell>Interaction</cell><cell>Follow &amp; Favorites</cell><cell>3</cell><cell>4</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Dataset D S . A Twitter dataset constructed by Shen et al. [2017] is employed. It contains 2,788 users and the post time of tweets ranges from 2009 to 2016.The statistics of dataset D T , D S are summarized in Table2.</figDesc><table><row><cell cols="5">Table 2: Datasets. +(−) denotes (non-) depressed samples.</cell></row><row><cell>Dataset</cell><cell>D T (+)</cell><cell>D T (−)</cell><cell>D S (+)</cell><cell>D S (−)</cell></row><row><cell>Users</cell><cell>580</cell><cell>580</cell><cell>1,394</cell><cell>1,394</cell></row><row><cell>Tweets</cell><cell>45,461</cell><cell>30,920</cell><cell cols="2">290,886 1,119,466</cell></row><row><cell cols="3">4.2 Feature Extraction</cell><cell></cell><cell></cell></row></table><note>We extract 78 features in D T , involving 4 groups, with details illustrated in Table1. On the other hand, 115 features were 3 http://cross_domain_depression_detection.droppages.com/.studied in D S by Shen et al.[2017], including 60 features shared in both domains. Since the aim is to detect depression in D T , we: 1) disregard the D S -exclusive features; 2) include the 18 D T -exclusive features, which we believe to be useful according to previous researches, as shown in bold in Table</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>• Zero-Mean Normalization (ZN). Linearly transforming data to obey standard normal distribution. • Feature Normalization &amp; Alignment (FNA). The proposed method in Section 5.1. As for the utilization of D T and D S , we study: • Direct Learning (DL). Learning a DNN merely on D T . • Direct Learning on Shared Features (DL S ). Learning a DNN merely on D T with the M S shared features. • Direct Transfer (DT). Learning a DNN on D S and directly applying it on D T without any further adaptation. DL, DL S and DT are three naive approaches that only consider the information from one domain. • Back Propagation (BP). After H S is learned on D S , retraining it on D TL by back propagation.</figDesc><table><row><cell>• Divergent Feature Conversion (DFC). The proposed</cell></row><row><cell>method in Section 5.2.</cell></row><row><cell>• Feature Combination (FC). The proposed method in</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>F1-measure of method combinations in DNN-FATC. 5±7.9 64.2±5.2 34.3±12.1 61.2±6.9 66.6±1.6 67.4±4.5 ZN 68.2±4.8 70.1±2.2 58.6±2.2 73.0±2.3 72.3±2.2 73.9±2.1 FNA 72.0±3.2 73.3±2.7 68.0±1.3 75.9±1.8 77.6±1.1 78.5±1.2</figDesc><table><row><cell>DLs</cell><cell>DL</cell><cell>DT</cell><cell>BP</cell><cell>DFC DFC+FC</cell></row><row><cell>MN 60.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>F1-measure of heterogeneous transfer methods.</figDesc><table><row><cell>FNA+DL</cell><cell>ARC-t</cell><cell>MMDT</cell><cell>HFA</cell><cell>DNN-FATC</cell></row><row><cell>73.3±2.7</cell><cell cols="3">73.7±1.1 73.9±1.8 75.1±0.8</cell><cell>78.5±1.2</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Acknowledgments</head><p>This work is supported by National Key Research and Development Plan (2016YFB1001200), the Innovation Method Fund of China (2016IM010200), Tiangong Institute for Intelligent Computing, Tsinghua University, the National Natural Science Foundation of China (61772302) and the Royal Society-Newton Advanced Fellowship Award. This research is also part of the NExT research, supported by the National Research Foundation, Prime Minister's Office, Singapore under its IRC@SG Funding Initiative.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multisource domain adaptation and its application to early detection of fatigue</title>
		<author>
			<persName><surname>Chattopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Weblogs and Social Media</title>
				<editor>
			<persName><forename type="first">Munmun</forename><surname>De Choudhury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Gamon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Scott</forename><surname>Counts</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Eric</forename><surname>Horvitz</surname></persName>
		</editor>
		<meeting>the International Conference on Weblogs and Social Media</meeting>
		<imprint>
			<date type="published" when="2012">2012. 2012. 2013. 2013</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="128" to="137" />
		</imprint>
	</monogr>
	<note>Predicting depression via social media</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Developing simplified chinese psychological linguistic analysis dictionary for microblog</title>
		<author>
			<persName><forename type="first">Iii</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association Computational Linguistics</title>
				<meeting>the 45th Annual Meeting of the Association Computational Linguistics</meeting>
		<imprint>
			<publisher>Hal Daumé III</publisher>
			<date type="published" when="2007">2007. 2007. 2013. 2013. 2013. 2013</date>
			<biblScope unit="page" from="359" to="368" />
		</imprint>
	</monogr>
	<note>International Conference on Learning Representations</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The divergence and bhattacharyya distance measures in signal selection</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Kailath</surname></persName>
		</author>
		<author>
			<persName><surname>Kailath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on communication technology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="52" to="60" />
			<date type="published" when="1967">1967. 1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Culture and depression</title>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Kleinman</surname></persName>
		</author>
		<author>
			<persName><surname>Kleinman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New England Journal of Medicine</title>
		<imprint>
			<biblScope unit="volume">351</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="951" to="953" />
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Shigenobu Kobayashi. The aim and method of the color image scale. Color research &amp; application</title>
		<author>
			<persName><surname>Kobayashi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981. 1981</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="93" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">What you saw is not what you get: Domain adaptation using asymmetric kernel transforms</title>
		<author>
			<persName><surname>Kulis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
				<imprint>
			<date type="published" when="2011">2011. 2011</date>
			<biblScope unit="page" from="1785" to="1792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning with augmented features for supervised and semisupervised heterogeneous domain adaptation</title>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1134" to="1148" />
			<date type="published" when="2014-06">2014. June 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Predicting psychological features based on web behavioral data: Mental health status and subjective well-being</title>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chinese Science Bulletin</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="994" to="1001" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Depression detection via harvesting social media: A multimodal dictionary learning solution</title>
		<author>
			<persName><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality</title>
				<meeting>the 2nd Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality</meeting>
		<imprint>
			<publisher>Guangyao Shen</publisher>
			<date type="published" when="1996">2012. 2012. 2013. 2013. 2001. 2001. 2001. 2000. 2015. 2015. 1996. 2017. 2017</date>
			<biblScope unit="volume">177</biblScope>
			<biblScope unit="page" from="3838" to="3844" />
		</imprint>
	</monogr>
	<note>Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">WHO. The ICD-10 classification of mental and behavioural disorders: clinical descriptions and diagnostic guidelines</title>
		<author>
			<persName><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Liu</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Danfen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linlan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ronghua Xu and Qingpeng Zhang. Understanding online health groups for depression: Social network and linguistic perspectives</title>
				<imprint>
			<publisher>Xu and Zhang</publisher>
			<date type="published" when="1992">2004. 2004. 2013a. 2013. 2013b. 2013. 2016. 2016. 1992. 1992. 2017. 2016. 2016</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">e63</biblScope>
		</imprint>
	</monogr>
	<note>World Health Organization</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
