<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Performance and Stability of Communication Networks via Robust Exponential Bounds</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Student Member, IEEE</roleName><forename type="first">Yaron</forename><surname>Opher</surname></persName>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Moshe</forename><surname>Sidi</surname></persName>
						</author>
						<title level="a" type="main">Performance and Stability of Communication Networks via Robust Exponential Bounds</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">55EAFF5DFC40CBEF89B84CD118B379CD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a new way for evaluating the performance of packet switching communication networks under a fixed (session-based) routing strategy. Our approach is based on properly bounding the probability distribution functions of the system input processes. The bounds we suggest, which are decaying exponentials, possess three convenient properties. When the inputs to an isolated network element are all bounded, they result in bounded outputs, and assure that the delays and queues in this element have exponentially decaying distributions. In some network settings, bounded inputs result in bounded outputs. Natural traffic processes can be shown to satisfy such bounds. Consequently, our method enables the analysis of various previously intractable setups. We provide sufficient conditions for the stability of such networks, and derive upper bounds for the interesting parameters of network performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>N this paper, we consider data communication networks and I the problem of evaluating their performance. This problem, in its most general formulation, is to characterize the service a given network supplies when it is loaded with given user traffic. In this context, the network is known by a full description of the behavior of all its components (nodes and links), the user traffic is given as known stochastic processes, and the service is to be characterized by the distribution of its parameters (such as the traffic in its links, the delays it causes, etc.). The particular importance of this problem stems from the variety of settings in which it is encountered. For instance, when a new communication network is designed, which is supposed to guarantee some predetermined parameters of service, one wishes to calculate the amount and size of resources which are needed to fulfill the requirements. Another example is when a new user wishes to join an already operational network. Since modem real-time applications require some minimal performance guarantees (such as very rare packet losses or very short delays), the question here is whether the new user can be admitted and accept its needed service while the performance degradation other existing users sense will not violate their needs.</p><p>A certain special case of this problem, which has been addressed and studied very intensively, is the case of singlenode networks. Queueing theory (see, for example, [ 131) deals, basically, with the case of one node and one user. The input process in this case is some known stochastic point process, and the server is described by the distribution of the time it processes each "job." Many other cases of single-node networks have also been studied (see <ref type="bibr">[8]</ref>, <ref type="bibr">[23]</ref>, <ref type="bibr">[lo]</ref>, <ref type="bibr">[l]</ref>, <ref type="bibr">[15]</ref>,</p><p>[ 181 and many others). These works consider a variety of input and service processes, and address cases where the system has more than one input link. The other case, in which the network consists of more than one single node, has proved to be very complex even in the simplest settings. This complexity is essentially due to the complicated way in which different traffic streams interact with each other within the network, and to the dependencies which are imposed by these interactions. A closed-form solution in this case is known only for a limited class of networks, known as Product Form Networks. A good example for this class is the Jackson Network (see <ref type="bibr">[13]</ref>, <ref type="bibr">[ll]</ref>), where the queue lengths of all nodes behave as if they were independent.</p><p>The subject of this paper are general communication networks operating in a packet switched mode, where routing is performed on a session basis. Two original models for analyzing such networks have been recently proposed ( <ref type="bibr">[5]-[7]</ref>, <ref type="bibr">[16]</ref>). The first one, by R. L. Cruz, introduced the concept of U burstiness constraint. A traffic stream with rate R ( t ) is said to satisfy such a constraint if there exist some constants p and (T such that ss* R(u)du 5 p ( ts) + o holds for all 0 5 s &lt; t . This concept ignores the stochastic nature of the traffic, and must hold for any sample path of it. The analysis Cruz presents achieves three major results: <ref type="bibr">I )</ref> If all input traffics to an isolated network element (server) satisfy burstiness constraints, then so do the output traffics from that element (not necessarily with the same parameters, though). This claim is proved for a variety of elements, with various service disciplines. 2) In this case, the delay suffered by each bit is upper bounded by a constant D , which depends, of course, on the parameters of the entering traffics and the nature of the examined element.</p><p>3) If all input traffics to a network satisfy burstiness constraints, and if their parameters are small enough, then all the traffic streams within the network also satisfy some burstiness constraints. These results enable the conclusion of upper bounds for the size of the buffers needed within the network and the delays each bit suffers in a single node, and during its life in the system. Further progress within this model has been presented by  for a special service disciplinethe Packet-Based Generalized Processing Sharing (PGPS) .</p><p>The second model, by J. Kurose, deals with the discretetime case. It does not ignore the stochastic nature of traffic, but rather introduces the characterization of a traffic stream by stochastically bounding the amount of data it might carry in any fixed-length interval of time. In other words, a traffic stream with rate R ( t ) is characterized by a series</p><formula xml:id="formula_0">{ ( R k , k ) ; k E IN} of random variables if Pr{Sst R(u)du &gt; x} 5</formula><p>Pr{Rt-s 2 z} holds for all 0 5 s &lt; t and all s &gt; 0.</p><p>Similar to the previous model, Kurose proves that if all input traffics to a network element (a switch, in this case) have such characterizations, then the same series (possibly shifted) of random variables also characterizes the corresponding output traffics. Moreover, the delays suffered by each packet in the switch are upper bounded by some constant D. These results are easily extended to any feedforward network, and an adhoc iterative analysis is presented for a special case of the nonfeedforward setting.</p><p>Motivated by the studies of Cruz and Kurose, we aim to find upper bounds on the probability distribution functions which describe the network operation and its quality of service. Our target is to overcome the two limitations of their modelr. The first is the deterministic nature of the input processes they consider. Both of these studies assume that the bursts of the input processes are of bounded length. Their methodologies require the intervals over which the sum of the input peak rates to a component exceeds its output capacity to be bounded. This is not the case for most commonly used input processes, even for the simple Bemoulli process or the well-known Poisson process (which might have bursts of any length). The other limitation of these studies is the partiality of the solutions they present for the nonfeedfonvard case.</p><p>The issue of bounding traffic parameters has also been addressed in some different settings. C. S. Chang, in his recent studies [3], <ref type="bibr" target="#b19">[4]</ref>, proposed a multiclass model where customers of distinct classes are routed differently and studied the single (isolated) server thoroughly. He handled the deterministic case similarly to the aforementioned works, and used the momentgenerating functions of the input processes in the stochastic case to produce exponential bounds for the distributions of queue lengths and delays. However, nonfeedfonvard networks are only analyzed in the single-class case, which is rather limited; in the stochastic model, it describes a Jackson-type network. This model, of generalized Jackson networks (where the routing is random and performed according to a routing probability matrix), is studied in [ 171 where the input processes are only assumed to have affinely bounded expectations.</p><p>In this paper, we propose a new way for bounding a traffic process. Rather than assuming that it has a bounded burstiness, we impose exponential decay on the distribution of its burst length. We then say that the traffic process at hand possesses an exponentially bounded burstiness (E. <ref type="bibr">B. B.)</ref>. The basic advantage of this bound over the ones mentioned earlier is that it holds, as we show, for some natural processes that have been studied earlier. There is no doubt it holds for most of the processes one might encounter in modeling communication networks. Two additional advantages make it applicable in many settings where the aforementioned models cannot be used. First, it imposes no deterministic requirements on the bounded processes and, hence, allows the analysis of systems where the peak rates of the component streams might exceed the system capacity over arbitrarily long intervals of time. Moreover, it allows the analysis of compound systems with correlated input processes -no independence assumption is needed when applying the analysis we present.</p><p>The first step we take is to examine the behavior of an isolated network element that is fed with E.B.B. processes. It turns out that its output traffic streams are also bounded similarly and that the delays this element causes, and the length of the queues which are built up within it, all have exponentially decaying distributions.</p><p>In order to analyze general communication networks, our target is to show that if all input processes to a communication network are E.B.B., then so are all traffic streams within that network. Once we have accomplished this, we will be able to employ the previous statements concerning isolated elements for bounding the distributions as well as all moments of node performance measures in the network. Notice that we require no assumptions regarding the input process' statistical dependencies, as opposed to the independence assumption made in each of the aforementioned works <ref type="bibr" target="#b19">[4]</ref>, <ref type="bibr">[ 161, [ 171.</ref> We provide some numerical examples to illustrate our method.</p><p>In the case of feedforward networks, this target is rather modest and fully achieved (see also <ref type="bibr" target="#b2">[3]</ref>- <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr">[7]</ref>, [16]). The case of nonfeedforward networks is much more complex, and a full answer is not yet known in any of the models introduced so far. Motivated by the specific example of a cyclic network analyzed by Cruz <ref type="bibr" target="#b4">[ 5 ]</ref> , <ref type="bibr">[7]</ref>, we define and analyze a general cyclic network. The results we get improve his findings, and extend the scope of their applicability. The general case of nonfeedfonvard networks is currently under study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">THE NETWORK MODEL</head><p>Our model for a communication network is a network of queues, connected by error-free point-to-point communication links. This model consists of a directed graph G = (V, E ) and a set { C ( P ) :</p><p>P E E } of nonnegative real numbers, each of which might be finite or infinite. The collection E C V x V of directed edges represents the set of (directed) communication links and the capacity of each link r E E is C ( e ) . The set of vertices represents the various elements of the network, and it is due to these elements and their behavior that the problem of analyzing the system as a whole is an interesting and complicated problem.</p><p>A traffic stream flowing on a communication link of such a network is characterized by its traffic rate R(t). This rate is a stochastic process, expressing the instantaneous intensity of data flow on the link -the amount of data flowing in this stream from any time instant tl to any (later) time instant t z , to be denoted by R f 1 . t 2 , is exactly J 2: R(t)dt. If the stream is flowing in a link with finite capacity C , then for any t its rate must satisfy the obvious inequality R ( t ) 5 C .</p><p>Each node (queue) v in the network possesses a service rule describing the way in which it handles the traffic entering it via its incoming links. This rule is a set {Rx; e E E;ut} of functions, one for each outgoing link e E E&amp;t from U. Each of these functions determines the traffic rate exiting w via e-in the most general case, as a function of the whole history {Rer(s); e' E Ezn, 0 5 s &lt; t } of traffic that entered ' U through the set E&amp; of its incoming links during the time it has been working. The amount of data stored in w (also called backlog, or unfinished work) at any time t , subject to its service policy, is and we will naturally assume that Wv(t) 2 0 for all U E V and all t 2 0. If no work is created or destroyed in w and its server never idles in front of a nonempty queue, then this quantity actually expresses the amount of data that entered ' U and is still to be processed there. These conditions merely say that the flow in each link is legal at all times, and that the flows which exit any node in the network are determined according to this node service policy.</p><p>Throughout this work we consider the continuous-time case (of stochastic processes) as well as the discrete-time case. In the latter case, the concept of traffic stream R(t), t E R reduces to a sequence {R(t)},,m of random variables, and all other concepts should be understood accordingly. We always assume that the system is started at t = 0 and is then empty (meaning that all network queues are empty). All the results we present can be achieved in both (continuous and discrete) settings. For simplicity of exposition, we stick to the discrete model and assume all quantities (such as rates, buffer occupancies, and capacities) to be integral. However, the following section is exceptional and serves as an example for the application of the continuous-time technique. Notice that we enclose events in curly brackets and use the standard abbreviations i i d . (for independent and identically distributed) and r.v. (for random variable(s)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>e E E&amp;</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="111.">EXPONENTIALLY BOUNDED BURSTINESS</head><p>The target of the analysis which will be herein presented is to bound the probability distributions of the interesting parameters of a communication network. The bounds we are looking for will further enable the estimation of the various moments (such as expectations) of these distributions. We begin the presentation with definitions for a bounded distribution and a bounded traffic rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Definitions</head><p>Definition I : Let W ( t ) be any stochastic process. W ( t ) is exponentially bounded (E.B.) with parameters (A. a ) -E.B.</p><p>if it satisfies for all n 2 0 and all t 2 0. Definition 2: Let R(t) be a traffic rate. R(t) has an exponentially bounded burstiness (E.B.B.) with parameters <ref type="table" target="#tab_6">du 2 p ( t -s ) + o 5 d e -a u   1   for all n 2 0</ref> and<ref type="table" target="#tab_6">0 5 s &lt; t</ref> In both definitions, we call a the decay parameter of the bound.</p><formula xml:id="formula_1">( p , A, a) -E.B.B. if it satisfies P r { R(u)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Basic Properties</head><p>Consider a traffic rate R(t), and assume it is (p,A,cy) -E.B.B.</p><p>Let p be the upper limit of its long-term average rate, namely</p><formula xml:id="formula_2">t E 5 R(u)du p = lirnsup ' t -s -x t -s Then, x &lt; p ( t -s) + / A e -a u d ~ = p ( t -s) + -A - a 0 Therefore, Esst R(u)du p = limsup 5 P , t-s" t -s</formula><p>It is for this reason that we call p an upper rare of R(t). with upper rate v &gt; p will be larger (and, hence, better) than a. We discuss this tradeoff and illustrate it by a numerical example in Section V-C.</p><p>An interesting characterization of an E.B .B. process emerges when we look at the backlog it creates in some classes of systems. This characterization can serve as an alternative definition for E.B.B., and be employed when studying specific traffic rates.</p><p>Theorem I: Consider a system that transmits at rate p, and assume it is work conserving (which, in this context, means it transmits information whenever possible). Suppose that it is fed with a single stream of traffic rate R(t), and let W ( t ) be the amount of data stored in the system at time t. This concludes the proof, since (4) also holds for U 5 (TO by <ref type="bibr" target="#b2">(3)</ref>.</p><p>Remark: Using a somewhat different technique, which will be introduced later (in the proof to Proposition 5), we can show that in the discrete-time case</p><formula xml:id="formula_3">A Pr{W(t) L .&gt; I e</formula><p>for all U 2 0 and all t 2 0. Let 0 5 s &lt; t. Then,</p><formula xml:id="formula_4">C. Sums of E.B. and E.B.B. Stochastic Processes { W ( t ) L (T} 3 { I ' R ( U ) d U L p(t -s ) + 0</formula><p>since the system can transmit no more than p ( ts) during the time from s to t. Hence,</p><formula xml:id="formula_5">P r { R(u)du 2 p(t -s) + o 5 Pr{W(t) 2 U } 5 Ae-=" 1 which concludes the proof of Part 2).</formula><p>have some positive A, a, and t for which To prove Part ii), we note that by the assumptions here we <ref type="bibr" target="#b1">( 2 )</ref> holds for all (T 2 0 and all 0 I s &lt; t. Fix some positive (TO and choose a small enough 6 such that 0 &lt; 6 &lt; 1 and</p><formula xml:id="formula_6">P r { 6' R(u)du 2 ( p -t ) ( t -s) + U 5 Ae-ao</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>( 3 )</head><p>Suppose first that U &gt; (TO; notice that, in the setting we consider, the backlog W ( t ) <ref type="bibr">[defined by (l)</ref>] has an alternative expression, namely</p><formula xml:id="formula_7">W ( t ) = max { Lt R(u)du -p ( t -s)}</formula><p>(see <ref type="bibr" target="#b5">[6]</ref> for details and further references). Hence, there exists some s I t such that</p><formula xml:id="formula_8">s &lt; t W ( t ) = R(u)du -p ( t -s )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6'</head><p>An interesting, and very useful, feature of E.B.B. processes is that the sum of a finite number of E.B.B. processes is itself an E.B.B. process. This statement holds regardless of the statistical dependencies between the added processes.</p><p>However, better decay factors can be achieved when they are independent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition I :</head><p>Let Rl(t) be (p,A,a)-E.B.B., and Rz(t) be (q,B,P</p><formula xml:id="formula_9">)-E.B.B. Then, R l ( t ) + Rz(t) is ( p + 77, A + B,y)- E.B.B.</formula><p>, where y = s.</p><p>Proof: Set 0 5 s &lt; t and U 2 0, and let 0 &lt; p &lt; 1 be some constant. Then, we have</p><formula xml:id="formula_10">{ I ' ( R 1 ( u ) + RZ('21))dU L ( P + V ) ( t -+ f . 7 1 c { [ Rl(u)du 2 P ( t -s ) +pa</formula><p>and so and, if we assume W ( t ) 2 (T, then we have</p><formula xml:id="formula_11">Choose p such that cyp = p(1 -p ) . Then, p = 5. Setting Y = h+9, we get a3 lt R(u)du 2 p(t -s) + U 1 Setting i such that t -i6 &lt; s 5 t -i6 + 6, we get P r { Lt ( ~l ( u ) + ~z ( u ) ) d u 2 ( p + v ) ( t -8) + I ( A + B)e-Y" I:,, R(u)du 2 lt R(u)du Notice that the coefficient y satisfies 2. p ( t -s) + U 2 i6p -6p + U 1 . 1 -mln(Q, P ) 5 Y 5 5 max(a, P ) 2 It follows that</formula><p>A similar proof will show that the sum of two E.B. stochastic processes is again an E.B. process, and its parameters are as Splitting the integral into three parts, and using integration by parts, we get Substituting the expressions ( <ref type="formula">6</ref>)-( <ref type="formula">8</ref>) into (5), we get</p><p>The result follows if we choose A' and 9 such that A + 2B + aAB0 5 Alequ for all cr 2 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remark: A somewhat better result, namely</head><p>Pr{Rs3* + Rq't L ( p + v ) k + o} 5 Aepa" + Bep3" + crABe-P" could be achieved in the discrete-time case by a simpler analysis of (7). Note that the choice of A' and Q presents an interesting tradeoff. The smaller 9 one wishes to choose, the larger the A' that should be allowed. Note further that if we only need the bound to hold for o 1 00 for some 00 &gt; 0, then we can choose smaller A' and @.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. INPUT PROCESSES</head><p>In the course of the following study, we would like to analyze isolated network elements as well as interconnected elements subject to the hypothesis that the data streams entering the system under consideration by any of its users are all E.B.B. The most obvious advantage of this bound over the ones employed in <ref type="bibr" target="#b4">[5]</ref>- <ref type="bibr">[7]</ref> and <ref type="bibr">[16]</ref> is that it applies to standard stochastic processes.</p><p>In order to prove that a specific given input stochastic process is E.B.B., one can use a variety of approaches. The direct one, which involves merely checking the conditions of the appropriate definition, will be illustrated by the following proof to the fact that a discrete Bernoulli process with parameter p has exponentially bounded burstiness with upper rate p + t for any t &gt; 0. This claim is formalized in Proposition 3.</p><p>Proposition 3: Let {R(t)},,p~ be a Bernoulli random process with parameter p , and set t &gt; 0. Then, there exists (Y &gt; 0 such that</p><formula xml:id="formula_12">I t -I u=s+l for all t &gt; s 2 0.</formula><p>The proof of Proposition 3 is based on the following lemma, which is rather general, and can be applied to a variety of stochastic processes. In order to prove that this source is E.B.B., we make use of the characterization of E.B.B. given in Theorem 1. First, we show that when such a stochastic process is fed into a work-conserving server which transmits at a rate C which is high enough, then the distribution of the amount of data stored in this server at any time is E.B. We then use Theorem 1 to conclude the result. The first part is based on the following proposition, which is proved in <ref type="bibr">[l]</ref>.</p><p>Proposition 4: If an aggregate ordoff source (as described) is fed into a work-conserving server with service rate C and the utilization factor p = &amp; is less than 1, then there exist some 00 &gt; 0 and some A &gt; 0 such that Pr{ W ( t ) &gt; CT} 5 Ae+' for all CT 2 00, where</p><p>(1</p><formula xml:id="formula_13">+ -P ) 1 -y c r =</formula><p>To be precise, note that this statement is proved in <ref type="bibr">[ l ]</ref> only for the steady-state situation (when t + x). Applying a coupling argument, it is clear that the result extends to any t if the system is started empty with all input processes in the "off' state. Choosing where T;lr is the backlog in steady state, we see that Pr{W &gt; 0, Employing Theorem 1, we conclude that Proof (of Proposition 3): Let IC = ts, and recall the notation Rs,t = C',=,+, R(u). {R(u)}t=,+, are k i.i.d. r.v., distributed according to a Bernoulli(p) distribution. Hence,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Be-rc for any</head><formula xml:id="formula_14">(T p r { [ R(u)du 2 C ( t -s ) + 0 M"*(8) = (ped + 1 -p ) h</formula><p>Let f(8) = p e @ + 1 -p , g ( 0 ) = p ( ~+ f ) @ , w e have f ( 0 ) = and the source we are dealing with is E.B.B. with upper rate C for any C &gt; s. Notice that this is the best (smallest) g(0) = 1 and Therefore, by the continuity of both f and y, f ( H ) &lt; y(8) for some positive 8, which is small enough. Setting (r = sup{O; f(8) &lt; g ( 8 ) } , we have M"$*(cr) = ( f ( ~) ) ~ 5</p><p>( g ( a ) ) k for all f &gt; s 2 0. The result follows by Lemma 1.</p><p>A somewhat less straightforward way for proving the boundedness of a given stochastic process will be illustrated by the following proof to the fact that the combined information source analyzed in (11 is E.B.B. An on/off process is a continuous-time stochastic process, which alternates between two states: the "on" and "off' states. The alternations occur after exponentially distributed periods, which are all independent of each other. The average "on" period is of one unit length, and the average "off' period is of length i. While in the "on" state, the traffic rate of this process stays constant at a level of 1 and transmits no data ( R = 0) during the "off' periods. The aggregate source we want to characterize herein is the sum of N independent such ordoff processes. The instantaneous traffic rate of this process is T (for any integer 0 5 T 5 N ) , when exactly T of its N components are "on." upper rate possible, since the average rate of the aggregate source at hand is s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. ISOLATED NETWORK ELEMENTS</head><p>We will now switch to the discrete-time context. The amount of information transmitted on a link with capacity C = 1 during one time slot can be regarded as a (virtual) packet, and we will regard it as such throughout the following exposition, although each real packet of the system under consideration might consist of several such packets.</p><p>The analysis we present herein considers network elements that employ the Virtual Cut-Through Switching Technique, introduced in [12]. However, only some very minor modifications are needed to cany it out for the case of Store and Forward elements as well. If a packet arrives at a virtual cutthrough element and the element is free to handle it, then it will be handled and transmitted immediately without waiting for the whole packet to be received. In the slotted model we are dealing with, this can be interpreted as if the data which will be received during a time slot is available at the beginning of that slot and then virtually added to the element queue. Work conservation for a virtual cut-through node means that it will transmit, in each slot, as much data as possible from its available data.</p><p>The order in which a network element transmits the packets that wait in its queue is dictated by its service discipline. The analysis we present here assumes nothing about this discipline. A finer analysis, which takes a specific element preferences into account, may result in better bounds for that special element.</p><p>The goal of the following sections is to show that when the inputs to a network element are all E.B.B., then so are its outputs. We will also show that, in such a case, all the interesting parameters of the element behavior (such as queue length and delays) are E.B. Such results will prove to be very useful when we deal with communication networks. Just recall that any network is built up of separate components, and the outputs of one such component are the inputs to others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. A Multiplexer</head><p>A multiplexer is a work-conserving network element with some number of inputs and a single output. Its function is to merge multiple data streams into a single one. The information packets that enter the multiplexer through any of its inputs are stored in a common queue and are transmitted, one by one, on its output. For the sake of simplicity, we will restrict ourselves in this section to two input multiplexers. The results that follow hold, however, for multiplexers with more than two inputs as well. Generalization of the proofs to this more general case is simple. See, for example, the proof of Theorem 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I)</head><p>Output rate and queue length: If R1 ( t ) and R2 ( t ) are the input traffic rates to the multiplexer, R(t) its output traffic rate, and W ( t ) the amount of data stored in it, then the multblexer behavior is described by</p><formula xml:id="formula_15">W ( t ) = max(W(t -1) + R l ( t ) + Rz(t) -C.0) R(t) = min(W(t -1) + R l ( t ) + Rz(t)&gt; C )</formula><p>where C is the service rate of the multiplexer. A schematic diagram of the multiplexer is given in Fig. <ref type="figure">1</ref>. Proofi By the assumptions, there exist some positive A , hold for all integer 0 5 s &lt; t and o 2 0. Let d ( s ) be the r.v. defined by</p><formula xml:id="formula_16">d ( s ) = niin { U : W(s -U ) = 0)</formula><p>The quantity d ( s ) equals the time (number of slots) that has passed since the last time the queue was empty prior to s. As we assume the whole system is empty at t = 0, we know that 0 5 d ( s ) 5 s. Letting k = ts, we have</p><formula xml:id="formula_17">Pr { R ~, ~ 2 ( p + 7 i ) k + a} = C p r ( { ~~&gt; ' 2 ( p + q ) k + a } n { d ( s ) = i } ) (9)</formula><p>Notice that { d ( s ) = i } implies that, in each one of the i time slots, si + I, .ci + 2 . . . . . s , C packets have been transmitted, and {Rs,t 2 ( p + q ) k + o} implies that at least additional ( p + 7 ) k + o packets have been transmitted from s to t. Moreover, { d ( s ) = i } also implies that the queue of the multiplexer was empty at s -i, and all these packets have entered it from s -i to t. Therefore,</p><formula xml:id="formula_18">Y i=n {W 2 ( p + q)k + a} n { d ( s ) = i} c {Ry-7.t + Ri-z't 2 ( p + q ) k + o + Cz} (10) Substituting (IO) into (9), we get Pr { R s , t 2 ( p + q ) k + o} r=n S = Pr { R y -1 t + ~i -1 t 1=0 2 ( p + 7 / ) ( k + I ) + a + L(C -p -77))</formula><p>We already know, however, that the sum of two E.B.B. traffic rates is itself E.B.B. and so, using Proposition 1, we get</p><formula xml:id="formula_19">Pr { RS,t 2 ( p + 71)k + a} i=n - A + B ?--!U -1 -e-?(C--P-ll)</formula><p>where y is again 3.  <ref type="formula">12</ref>), we can write</p><p>2 ) The stability condition: A direct consequence of the previous section is that the multiplexer queue is stable when p + 71 &lt; C. We now show that this condition is necessary.</p><p>Pr { W ( t ) 2 .j 5 2 Pr (R;-a&gt;t + Rt-i,t 2 f f + ci} (13) Consider two independent sources for which there exist some i=O t with</p><formula xml:id="formula_20">2 ( p + q ) i + 0 + i(C -p -7 ) )</formula><p>and assume that p + q &gt; C . Then, and again, by Proposition 1, we conclude that</p><formula xml:id="formula_21">A + B e -Y u</formula><p>Pr { W ( t ) 2 01 5 1 -e-y(c--p-v)</p><p>In the practical case, when the input links to the multiplexer have bounded capacities as well, better results can be achieved.</p><p>Proposition 7: If the capacities of the two ingoing links of a multiplexer are C1 and C2 and if its input processes satisfy the conditions of Proposition 6, then the decay parameter of the backlog W ( t ) in the multiplexer is y 1 + c ~; &amp; ~c ) .</p><p>Notice that this value is greater than the decay parameter y achieved by Proposition 6, and might even be greater than the smaller of the two input parameters (Y and p (when the ratio between these two parameters is less than c,;12-Jc). Notice further that we implicitly assume C1 &gt; p, C2 &gt; 7, and that in the case C1 + C2 5 C we have W = 0 at all times; hence, we also assume Cl + C2 &gt; C. Prooj In the course of the proof to Proposition 6, we arrived at the following relation ( <ref type="formula">13</ref>):</p><formula xml:id="formula_22">( â‚¬ 2 5 Pr ({R;.' 2 pt&gt; n { R ~J 2 q t ) ) 5 Pr{ Ry,t + R:'t 2 ( p + q ) t ) I Pr{W(t) 2 ( P + 7 -C)t&gt;</formula><p>where the last inequality is due to the fact that from 0 to t no more than Ct packets can leave the multiplexer through its outgoing link. This equation, however, simply says that EW(t) 2 t2(p + 7 -C ) t which means that EW(t) diverges when t tends to infinity.</p><p>3) Busy periods: The stochastic process d( t) we have introduced in the previous proofs specifies the time when the busy period t resides in has started. More precisely, it specifies the time that has passed in this busy period up to t. The rest of this busy period, which is the time that is still to pass from t on, until the first subsequent exhaustion of the multiplexer queue, is defined by</p><formula xml:id="formula_23">t D ( t ) = min{u : W ( t + U ) = O j Pr { ~( t ) 2 0 j 5 Pr { ~i -2 ~ + ~t -1 ~ i=O</formula><p>The length of the busy period in which t resides is, then,</p><p>The input links we are now dealing with have bounded</p><formula xml:id="formula_24">D ( t ) = d ( t ) + D ( t )</formula><p>capacities and, hence,</p><p>In both the Cruz and Kurose models, these quantities were</p><formula xml:id="formula_25">&lt; (Cl + C2)i.</formula><p>bounded. In ours, they are not-rather, they are E.B.</p><p>Rt-z't f Ri-a?t - ' laries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof:</head><p>00</p><formula xml:id="formula_26">IEW(~) = 1 Pr { ~( t ) 1 0) u = l</formula><p>Corollary 2: In the previous multiplexer, the virtual delay sensed by a (virtual) packet, if it came at t, is E.B. with decay parameter y(Cp -71). Furthermore, if the multiplexer employs a FIFO discipline, then this parameter can be improved Proof: Let V d e l a y ( t ) be the virtual delay at t. Then, the first part of the corollary follows since VdeZay(t) = D(t).</p><p>The second part follows since, in the FIFO case, Vdelay( t ) = 5 ) Independent input processes: Throughout the analysis of the multiplexer presented so far, we made no assumption on the joint distribution of the two input processes, and applied Proposition 1 whenever the sum of them have been encountered. We can repeat this analysis, assuming the input processes are independent and applying Proposition 2 instead. Doing this with Propositions 5-7 will yield the following bounds.  If we assume further that the input links to the multiplexer have finite capacities C1 and Cp, respectively, then where, as before, R(t) is the output rate from the multiplexer, W ( t ) is the queue length in it, and 6, 9, and A' are as in Proposition 2.</p><p>The proof of these facts is essentially the same as the original proofs to Propositions 5-7. The only modifications needed are to replace the application of Proposition 1 at the end of each proof with an application of Proposition 2, which is suitable when the input rates are assumed to be independent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. A Switch</head><p>A switch is a single-sewer work-conserving element with some number (not necessarily two) of incoming and outgoing links. Its function is to switch the traffic of each session passing through it to the correct (predetermined) outgoing link. The information packets that enter the switch through any of its inputs are stored in a single common queue, and are transmitted, one by one, on the appropriate outputs. Notice that this model can also be used to describe switch fabrics with more than one server or queue. For instance, the output queueing model analyzed in <ref type="bibr">[9]</ref> can be described by a set of switches, one for each output link of the switch fabric. The analysis we present assumes nothing as to the switching technique (also called service disciplines) used or its being work-conserving, in the sense that the switch does not rest if it has work to do. Let R l ( t ) , R2(t). . .. , R N ( ~) be the traffic rates of the streams entering the switch, and Rl,,,t(t), Rz,out(t)r . . . , <ref type="bibr">R ~, , ~t ( t )</ref> the corresponding traffic rates of the exiting streams. Note that more than one input stream may enter the switch through a single incoming link, the same way that more than one output stream may exit through a single outgoing link. A schematic diagram of the switch is given in Fig. <ref type="figure" target="#fig_5">2</ref> (where the horizontal arrows indicate traffic rates, not physical links). and if E,"=, p3 &lt; C where C is the service rate of the switch, then the output rates R1,Out(t)l R2,0ut(t)l.. . . <ref type="bibr">R,v,out(t)</ref> are also E.B.B. with the same respective upper rates.</p><p>Proo$ By the assumptions, there exist Al. A P , . . . . AN and ~1 , a 2 , . . . , (YN such that 1</p><formula xml:id="formula_27">Pr { 2 R3(u) 2 p3(t -s) + IT 5 Ale-o)n</formula><p>holds for all IT 2 0, 0 5 s &lt; t and all 1 5 1 5 N . Let IC = ts, and d ( s ) is again the time that has passed since the last time the switch was empty prior to s. Then,</p><formula xml:id="formula_28">u=s+l Pr { R$,t 2 P l IC + I T } S i=O</formula><p>Using the same reasoning as in the proof of Proposition 5, we get Now, along the same lines of the proof of Proposition 1, let p l , p z l . . . , p~ be positive constants that sum to 1. Then, where the maximum is achieved when a l p 1 = a2p2 = . . . = a , y p ~ = CY. Hence, is E.B.B. with upper rate p1 and decay factor a = l+L: +1, which satisfies e l a.?</p><formula xml:id="formula_29">3=1 &lt; -A e -a ( u f z ( C -C ~~ A, where Q = min1&lt;,&lt;x a3p, &gt; 0, A = E,=, A,.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q V</head><p>Applying similar arguments, it is not surprising to discover that the total amount of data stored in the switch queue, as well as the amount of session j data (for all 1 5 j 5 N ) stored in it. are all E.B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Numerical Results</head><p>In order to illustrate the proposed technique, we consider a two-input multiplexer with output capacity C = 1 and bounded input capacities C1 = C2 = 1 and feed it with two Bernoulli input processes, each with parameter P = i. An appropriate E.B.B. characterization of the input processes can be derived by Proposition 3, which allows a tradeoff between the upper rate p and decay factor a. The results of applying Proposition 3 for three different values of p are summarized in Table <ref type="table">I</ref>. Notice that the larger the gap one allows between the true mean rate P and upper rate p of the characterization, the better the decay factor one gets.</p><p>Using these bounds for the input processes, we can compute E.B. characterizations for the queue length in the multiplexer. Fig. <ref type="figure" target="#fig_6">3</ref> presents the results of applying Proposition 8 for the case of independent input processes, with some actual simulation results distributions.</p><p>The dashed lines show the computed bounds for two different characterizations of the input processes (with p = 0.2 and p = 0.3). The solid lines show the actual distributions at five different time stops ( t = 10.50.100,500,1000) found by simulating the behavior of a multiplexer which has an empty queue at t = 0 for 100000 times. Considering these actual distributions, it is apparent that the proposed analysis captures the transient, as well as steady state, behavior of the multiplexer queue. One further interesting observation is that, in this special case, the convergence of the queue-length distribution to its steady state is rather quick. Thus, distributions at different time stops are almost indistinguishable.</p><p>A similar analysis for the case of totally dependent sources (namely, sources that transmit in exactly the same time slots), where the bounds are calculated by Proposition 7 as for the general case, yields the results presented in Fig. <ref type="figure" target="#fig_2">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. NETWORK ANALYSIS</head><p>We know by now that when the input streams to an isolated network element are all E.B.B., then so are all its output streams. Furthermore, we know that in this case the interesting parameters of that element behavior are E.B. If, in a network setting, all the streams in the network are E.B.B., then the previous results will imply that the parameters of the network behavior (such as queue lengths and virtual delays in each node) are E.B. As a direct consequence, we will get upper bounds for the distributions of these parameters and their moments, and will be able to conclude that the network is stable.</p><p>Our goal then is to learn when this is indeed the situation, once we make sure that all the (outside world) inputs to the network are E.B.B. A preliminary condition one must check is that the total average load on each link in the network (which is the sum of the upper rates of each of the streams that pass through that link) is less than that link capacity. To see why this condition, which we call the throughput condition, must hold, consult Section V-A-2. Observe that the problem at hand belongs to one of two fundamental classes. If there are no cycles in the graph generated by the routes of the various sessions, then the problem is feedforward; It is nonfeedforward otherwise. Notice that the concept we have just introduced depends on both the topology of the network and the specific assignment of session routing within it. If, however, we ignore the links that carry no traffic, then the resulting topology has no cycles if and only if the original problem is feedforward.</p><p>From here on, we will assume that all the links in the network do carry some traffic and will call the network feedforward if it has no cycles and nonfeedforward otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Theoretical Analysis</head><p>The case of feedforward networks is very simple since we know that E.B.B. input processes to an isolated network element result in E.B.B. output processes from it. Following the same lines of argument that were employed in <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr">[7]</ref>, [ 161, we can choose a peripheral node (which accepts only outside world inputs), deduce that all its outputs are E.B.B., and drop it. Continuing inductively, we prove that all the traffic streams in the network are E.B.B. and bound their parameters. Notice that, in this case, the previous argument works whenever the throughput condition holds.</p><p>The case of nonfeedforward networks is much more complicated, and none of the models we mentioned have solved it completely. Motivated by the example analyzed in <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr">[7]</ref>  One incoming link, called its internal link, which connects it to its predecessor node in the network. Packets which are received on this link are called intemal packets. and they accumulate and wait for service in the internal queue of the node. Some external links. through which the node accepts outside world input. Packets which are received on any of these links are called external packets, and they accumulate and wait for service in one common queue called the external queue of the node.</p><p>One server, which is capable of transmitting one packet per slot (its service rate equals 1) to the internal link of its successor node in the network. Thus, each internal link in the network is either busy at t (and then R,(t) = 1) or idle at ! (and then R , ( f ) = 0). The service discipline each node employs is cut through, in the sense that it can transmit a packet in the same time slot in which it arrives: it is work conserving, in the sense that it will never idle if there is a candidate packet for transmission (whether waiting in one of its queues or being received); it serves the packets in its internal queue on a FCFS basis. Note that priority is not necessarily granted to packets in the internal queue over those in the external queue, and that when the server chooses to serve a packet from the external queue, it may serve any of the packets which wait there. One final remark is that when a packet arrives at its destination node (through its internal link, naturally), it is considered delivered and does not join the internal queue of that node nor does it need any further service. Let S ( i ) be the number of sessions that enter the network at U;, R2,j(t), the rate of the jth session input traffic at I', (1 5 j 5 S ( i ) ) . Notice that the network might experience time slots when there are packets transmitted on its internal links but, nevertheless, no packet departs it during that slot.</p><p>Theorem 3: Let Wl(t) be the length of the external queue of ' U, and W ( t ) be the total number of packets that wait in the internal queues of the network. If &amp; ( t ) is <ref type="bibr">(~l,</ref><ref type="bibr">3rAl,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr">al,</ref><ref type="bibr" target="#b2">3)</ref> 2. There exist some positive A' and a' such that Pr { ~( t )</p><formula xml:id="formula_30">2 01 5 A ' ~-~' O Thus, W ( t ) is E.B.</formula><p>In what follows, we will use the term network to refer only to the set of all internal links and queues, and the term system will refer to the whole structure, including the network and all the external queues. Assume that the network (internal and external queues) has last been empty at to. Let mt be the number of packets that have entered the network from t o to t (meaning that they have passed at least one internal link of the network) and set A, = mt -(t -to). Define the evacuation time of the network at t to be the time that will pass from t until the network becomes empty, when we ignore all the external queues from t on, and denote this time by et. In other words, t t is the time it takes until the network evacuates, if no new packets enter it. The proof of Theorem 3 is based on the following lemma.</p><p>Lemma 2: Assume that, at t o = 0, the whole system (and its queues) is empty and it is never empty from t o on. Then, A, 2 et for all t 2 0.</p><p>Proof: By induction. For t = 0, we know that the system is empty; so, A0 = eo = 0. Assume that the lemma holds for t, and prove it for t + 1. Define a station at time t to be an internal queue cell which is occupied by a packet at the end of slot t. A station is created at time t if its queue cell is vacant at t -1 and is occupied at t . A station is deleted at t if its queue cell empties at t. Notice that a new station cannot be created at t in a node that does not transmit a packet from its external queue in this slot. Moreover, since internal packets receive FCFS service, each such packet proceeds to the next station in each time slot. Hence, if no packets enter the network from t on, then each (internal) packet in it will stop in some (et -1 at the most) of the stations at t , during the following time slots, and will get to its destination and leave the network (and the system) at the next slot. Let 1 2 0 be the number of new packets that enter the network during the t + 1 time slot (these are the external packets that are transmitted on an internal link at this time slot and become internal packets). As mentioned earlier, we may regard these packets as available at the beginning of this slot, and we will describe their transmission in two stages. First, each new packet creates a new station at the head of the internal queue of its node. Then, it is transmitted to the successor node in the network. According to our definitions, we have mt+l = mt +1 and then A,+, = A, + 1 -1. It now remains to check the value of t t + l .</p><p>Consider first a packet that was in the network at t. If no new packets were to enter the network after t, then this packet would have been evacuated from it in tt slots at the most. This means, as we have just seen, that this packet had to stop in f t -1 stations at the most, and in the following slot to get to its destination and leave the network. The new 1 packets add 1 new stations in which a packet can stop, and therefore the subject packet has tt+l-1 stations, at the most, in which it has to stop if no new packets arrive. During the t+ 1 slot, however, our packet proceeds one station (because of the FCFS nature of the service internal packets get) and so its evacuation time is E, + 1 -1 at the most ( 6 , + 1 -1 for the stations, one more for the slot in which it leaves the system, and one less for its progress during slot t + 1). Notice that this quantity is not negative, since our assumptions assure that 1 &gt; 0 if tt = 0.</p><p>Next, consider a packet that entered the network at t + 1 (a new packet) and check where this packet might stop, if no packets enter the network from t + 1 on. There are et such stations, at the most, where "old' packets reside and I -1 stations of the other "new" packets that entered at t + 1. Note that the network might contain much more than et stations at t but, nevertheless, a new packet will only have to stop in et of them at the most, the same way that each of the old packets that reside in these stations will only have to stop in tt -1 of them at the most. Since one more time slot will be needed for our packet to get from its last station to its destination, and during the current slot this packet proceeds one station, we get that it will be evacuated in t t + (1 -1) + 1 -1 at the most.</p><p>These cases together imply that f t + l 5 e, + 1 -1 and, therefore, At+, = A, + 1 -1 2 t t + 1 -1 2  Theorem 3 shows that all the queues in the system we are studying (both internal and external) are E.B. when p z , , &lt; 1. Therefore, this condition is sufficient for the stability of this network. Let us now refer back to the example that motivated this analysis [ 5 ] , <ref type="bibr">[7]</ref>. In this example, only one session enters the network at each node, is destined to the predecessor node, and whose traffic is assumed to be a ( 0 . p ) process (see <ref type="bibr" target="#b5">[6]</ref> for the notations). The analysis there proves the stability of the previous example only when p &lt; &amp;, while our analysis holds for any p &lt; 1 (notice that the throughput condition in this case is p &lt; n). Y</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Numerical Results</head><p>As an example of the application of the proposed method in the network setting, consider the three-node arrangement illustrated in Fig. <ref type="figure" target="#fig_10">5</ref>.</p><p>In this system, and &amp; ( t ) are both Bernoulli with P = &amp;, &amp;(t) is Bernoulli with P = i, and all are mutually IEEWACM TRANSACTIONS ON NETWORKING. VOL. I , NO. 3, JUNE 1993    -1 2 L Fig. <ref type="figure" target="#fig_1">6</ref>. Queue-length distributions in a three-node example network.</p><p>independent. Each packet introduced to the system by &amp;(t) is duplicated, and the two copies are routed to the two leftmost nodes (one copy to each node). Notice that exact analysis of this system is impossible, while our method produces reasonable bounds. Applying Proposition 3, we characterize both R l ( t ) and &amp; ( t ) as ( <ref type="formula">0</ref> Apparently, the nature of the simulated distributions is quite similar to the one discussed in Section V-C.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Manuscript received May 1992; revised May 1993; approved by IEEEIACM TRANSACTIONS ON NETWORKING Editor Don Towsley. This paper was presented in part at IEEE INFOCOM '93. The authors are with the Department of Electrical Engineering, Technion -Israel Institute of Technology, Haifa 32 OOO Israel. (email: opher@techunix.technion.ac.IL) (email: moshe@yael.technion.ac..IL) IEEE Log Number 92 1 1 139.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Proposition 6 :</head><label>6</label><figDesc>If both inputs to a multiplexer are E.B.B. and the sum of their upper rates is less than its service rate, then the backlog W ( t ) in the multiplexer is E.B.Proof: Using the notations of the previous proof, we can writePr{W(t) 2 0 ) L = PI ( { W ( t ) 2 0 ) n { d ( t ) = i})</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>4 )</head><label>4</label><figDesc>use the same trick as in Proposition 2 to conclude that D ( t ) is E.B. with decay factor y(Cpq ) -9 for any positive 9. Further pe~ormance measures: Calculating bounds for some other parameters of the multiplexer behavior is now immediate. Such bounds are illustrated in the following corol-Corollary I : The expected backlog in a multiplexer whose two inputs are (p,A,a)-E.B.B. and (q,B,P) E.B.B., respectively, is upper bounded for all t by e, where M = -* and y is as before.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>If the inputs Rl(t) and Rp(t) to a multiplexer are independent and if they are both E.B.B. with the same respective parameters as in the previously mentioned propositions, then</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Theorem 2 :</head><label>2</label><figDesc>If the inputs R1 ( t ) , R2 ( t ) . . . . . RN ( t ) to a switch are all E.B.B. with some upper rates p1, p 2 ] . . . , p ~,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Queue-length distributions and their E.B. bounds: Independent sources.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Queue-length distributions and their E.B. bounds: Correlated sources.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>of a four-node cyclic network and by the one analyzed in [ 161 of a two-node cyclic network, we deal with the following special case. Consider a cyclic network, defined by L7 = { L ' 1 . 7 ' 2 . . . . . ( ' \ -} E = ((2.1. 0 2 ) . ( ~1 2 . ~3 ) . . . . . (71.y-i.~.y). (vN.v~)} Each node in the network is composed of the following components:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>t -k . Using the same technique used in proving Theorem 2, we choose a set of positive numbers p i , j that sum to one and get where CY = mini,j c u ; , j p i , j , which concludes the proof of Part To prove Part ii), we write i) .t k=ORecall that an external packet can enter the network (and become internal) only by being transmitted on an internal link and, thus, no more than N new packets can enter the network in each time slot (one at each node) regardless of the amount of packets that join the external queues of the system in this slot (which is theoretically unbounded). Thus, W ( t ) 5 mt5 N d ( t )  , and we get Using Corollary 3, we have { d ( t ) = k } c {mt 2 k } and, therefore, Applying our well-known technique, we get</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5 . An example network</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>.15.1.1.77)-E.B.B., and R2(t) is (0.3.1.2.06)-E.B.B. Applying Proposition 8 to bound the output traffic of the leftmost nodes, and then Proposition 6, we get an E.B. characterization for the queue length W ( t )in the rightmost node. This bound, together with some actual simulation results distributions, are presented in Fig.6.In the application of Proposition 8, we used 00 = 3 and, hence, could choose A' = $, 9 = 0.4. Proposition 6 is now valid only for (T 6, and we calculate the bound only for such values of 0. The resulting bound for W ( t ) is plotted on the dashed line. ?e solid lines show the actual queue-length distributions at five different time stops (t = 10,50,100.500.1000) found by simulating the behavior of a network which has empty queues at t = 0 for 1000000 times.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>In this case, v is called work conserving (for a discussion of this concept, see [ 14, p. 1131).</figDesc><table><row><cell>A flow in a communication network is a collection {R,(t):</cell></row><row><cell>e E E } of traffic rates, defined for all t E [O, x) and satisfying</cell></row><row><cell>1) 0 5 R,(t) 5 C ( e ) for all t E [O,w).</cell></row><row><cell>2) Re(t) = RE(Re,(s); e' E E&amp;, O 5 s &lt; t ) for all</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>. In this case, we say that R(t)</figDesc><table /><note><p>is E.B.B., and refer to it as an E.B.B. process.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>We have:</figDesc><table /><note><p>If W ( t ) is E.B., then R(t) is E.B.B. with upper rate p. If R(t) is E.B.B. with upper rate pt for some E &gt; 0, then W ( t ) is E.B. Proof: By the assumptions of Part i ) , there exist some positive A and cy with Pr{W(t) 2 U } 5 Ae-ao and thus, by (2) and a union bound, we get i=l (4)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>case. It is worth mentioning that the joint distribution of any two E.B. or E.B.B. processes has a product form bound. For instance, if W1 is (A,a)-E.B. and Wz is (B,P)-E.B., then where y is defined as in Proposition 1. This is due to the fact that In the case when the added processes are independent, we can use a different technique and achieve larger decay factors. The following proposition states this claim for the case of E.B.B. processes. Only very slight modifications are needed for the case of E.B. processes. Prooj Set 0 5 s &lt; t, U &gt;_ 0, and let k = ts, 6 = min(cw,p). Assume cr 2 / 3 and, thus, 6 = p.</figDesc><table><row><cell>Proposition 2: Let R1 ( t ) be (p,A,a)-E.B.B. and &amp; ( t )</cell></row><row><cell>be (q,B,P)-E.B.B., and assume they are independent. Then,</cell></row><row><cell>Rl(t)+Rz(t) is (p+q,A1,6-9)-E.B.B. where 6 = min(cr, p),</cell></row><row><cell>Assume</cell></row><row><cell>further that R;'t has a distribution density, to be denoted by</cell></row><row><cell>rf't, such that</cell></row><row><cell>Then,</cell></row><row><cell>2 = 1</cell></row></table><note><p>I mentioned above, for the E.B.B. A' and 9 depend on A and B.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Lemma 1: Let R(t) be a stochastic process, Msxt(B) the Moment Generating Function of RS't. If there exist some positive p and 0 for which h6s,t(B) 5 e p ( t -s ) d for all t &gt; s 2 0, then R ( t ) is (p,l,O)-E.B.B.</figDesc><table><row><cell>Proofi Using the Markoff inequality (see [19, p. 114]),</cell></row><row><cell>we get</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Proposition 5 :</head><label>5</label><figDesc>If the inputs Rl(t) and Rz(t) to a multiplexer are both E.B.B. with some upper rates p and 71, respectively, and if p + 7 &lt; C, then the output R(t) from the multiplexer is also E.B.B. with upper rate p + 71.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>-E.B.B. for all 1 5 z 5 N , 1 5 j 5 S(z)</figDesc><table><row><cell>and if</cell><cell>pl,3 &lt; 1, then:</cell></row><row><cell cols="2">1. There exist some positive A and cy such that</cell></row><row><cell></cell><cell>Pr { W I ( ~) 2 01; Wz(t) 2 0 2 ; . . . ; W&gt;v(t) 2 ON}</cell></row><row><cell></cell><cell>&lt; Ae-a(Ol+02+ + U N ) -</cell></row><row><cell cols="2">Thus, the joint distribution of W1 (t) ~ WZ ( t ) . . . . . W,v ( t )</cell></row><row><cell cols="2">is E.B.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Since rnt = At + t 2 f t + t 2 t , we have Corollary 3: If the conditions of Lemma 2 hold, then Look at the system at some time slot t , and let d ( t ) be defined similarly as beforeit is the time that has passed since the system was last empty prior to t. We have {Wl(t) 2 01; W*(t) 2 0 2 : . . CAT; d ( t ) = IC} Using Corollary 3, we get {Wl(t) 2 u1: W*(t) 2 O2:. . . : W,y(t) 2 a" d ( t ) = IC} since the system was last empty at t -IC and all the packets that are queued at t have not been submitted to the system prior to</figDesc><table /><note><p>mt 2 t. Proof (of Theorem 3): . : WjV(t) 2 O N } t = U {Wl(t) 2 0 1 : Wz(t) 2 f f 2 : k=O . . . : Wn.(t) 2</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors wish to thank the anonymous referees for their careful reviews and helpful suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Stochastic theory of a datahandling system with multiple sources</title>
		<author>
			<persName><forename type="first">D</forename><surname>Anick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Sondhl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell Sysr. Tech. J</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1871" to="1894" />
			<date type="published" when="1982-10">Oct. 1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Principles and Practice of Information Theory</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Blahut</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Stability, queue length and delay, Part I: Deterministic queueing networks</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Res. Rep. RC</title>
		<imprint>
			<biblScope unit="volume">17708</biblScope>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Stability, queue length and delay, Part 11: Stochastic queueing networks</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Res. Rep. RC</title>
		<imprint>
			<biblScope unit="volume">17709</biblScope>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A calculus for network delay and a note on topologies of interconnection networks</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Cruz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<pubPlace>Urbana-Champaign</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Univ. of Illinois</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A calculus for network delay, Part I: Network elements in isolation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Cruz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">I</biblScope>
			<biblScope unit="page" from="114" to="131" />
			<date type="published" when="1991-01">Jan. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A generalized processor sharing approach to Row control -The multiple node case</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Parekh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Gallager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE INFOCOM&apos;93</title>
		<meeting>IEEE INFOCOM&apos;93</meeting>
		<imprint>
			<date type="published" when="1991">2076. 1991</date>
			<biblScope unit="page" from="521" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A calculus for network delay, Part 11: Network analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rubinovitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Cruz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stochast. Proces. and their Appl</title>
		<imprint>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="issue">171</biblScope>
			<biblScope unit="page" from="132" to="141" />
			<date type="published" when="1973-01">1973. Jan. 1991</date>
		</imprint>
	</monogr>
	<note>IEEE Trans. Inform. Theory</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Limiting distributions for some storage problems</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Gaver</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Miller</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studies in Applied Probability and Management Science</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Arrow</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Karlin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Scarf</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page" from="110" to="126" />
			<date type="published" when="1962">1962</date>
			<publisher>Stanford Univ. Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Input versus output queueing on a space-division packet switch</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Karol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Hluchyj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Morgan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1347" to="1356" />
			<date type="published" when="1987-12">Dec. 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The stochastic behavior of a buffer with non-identical input lines</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kaspi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rubinovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Srochasr. Proces. and rheir Applic</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Virtual cut-through: A new computer communication switching technique</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reversibility</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Stochastic</forename><surname>Networks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">P</forename><surname>Kermani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kleinrock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Netw</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="267" to="286" />
			<date type="published" when="1979">1979. 1979</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">L</forename><surname>Kleinrock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">L. Kleinrock, Queueing Systems</title>
		<imprint>
			<biblScope unit="volume">I</biblScope>
			<date type="published" when="1975">1975. 1976</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computer Applications New York</orgName>
		</respStmt>
	</monogr>
	<note>Queueing Systems</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">On computing per-session performance bounds in highspeed multi-hop computer networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kosten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kurose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Down</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Delft h o g . Rep</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="71" to="86" />
			<date type="published" when="1986-06">1986. June 1992. 1991</date>
			<pubPlace>Newport, CA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">preprint</note>
	<note>Stability of generalized Jackson networks</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Stochastic theory of a fluid model of producers and consumers coupled by a buffer</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advanc. in Appl. frob</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="64" to="676" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Papoulis</surname></persName>
		</author>
		<title level="m">Probability, Random Variables, and Stochastic Processes</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
	<note>rd Ed</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A generalized processor sharing approach to Row control in integrated services networks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Parekh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dept. of Electr. Eng. and Comput. Sci., M.I.T</title>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A generalized processor sharing approach to flow control -The single node case</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Parekh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Gallager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE INFOCOM&apos;92</title>
		<meeting>IEEE INFOCOM&apos;92</meeting>
		<imprint>
			<date type="published" when="1991">2040. 1991</date>
			<biblScope unit="page" from="915" to="924" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">research interest is cun service guarantees in c re C Opher Yaron (S&apos;93) was born in Israel in 1962. He received the B.Sc. degre in mathematics and physics, and the M.Sc. degree in mathematics from the Hebrew University, Jerusalem, Israel, in 1983 and 1987, respectively. From 1983 to 1988, he was with the Research Laboratories of the Israel Defense Force Signal Corps. Since</title>
		<imprint>
			<date type="published" when="1975">1975. 1990</date>
			<biblScope unit="page" from="73" to="88" />
			<pubPlace>Haifa, Israel</pubPlace>
		</imprint>
		<respStmt>
			<orgName>at the Electrical Engineering Department of the Technion -Israel Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note>he has been a D.Sc. candidate, as well as Teaching Assistant and Instructor. His mtly in the area of performance analysis and grade of nputer communication networks</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">and 1982, respectively. In 1982, he joined the faculty of the Electrical Engineering Department at the Technion. During the academic year 1983.1984, he was a Post-Doctoral Associate at the Electrical Engineering and Computer Science Department at the Massachusetts Institute of Technology, Cambridge, MA. During 1986-1987. he was a Visiting Scientist at the IBM -T</title>
		<author>
			<persName><forename type="first">Moshe</forename><surname>Sidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">M</forename><surname>Sc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">He received the New England Academic Award in 1989. He coauthored the book Multiple Access Protocols: Performance and Analysis</title>
		<meeting><address><addrLine>J. Watson Research Center, Yorktown Heights, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1975">1975. 1979. 1990</date>
		</imprint>
		<respStmt>
			<orgName>Israel Institute of Technology, Haifa, Israel</orgName>
		</respStmt>
	</monogr>
	<note>Currently, he serves as the Editor for Communication Networks for the IEEE TRANSACTIONS ON COMMLWCATIONS and as the Associate Editor for Communication Networks and Computer Networks for the IEEE. His current research interests are in queueing systems and computer communication networks</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
