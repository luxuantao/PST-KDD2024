<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">IEEE Transactions on Multimedia</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">F</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">are with Center for Future Media and School of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
								<address>
									<postCode>611731</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">are with Center for Future Media and School of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
								<address>
									<postCode>611731</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">are with Center for Future Media and School of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
								<address>
									<postCode>611731</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Heng</forename><surname>Tao</surname></persName>
							<email>dacheng.tao@uts.edu.au</email>
							<affiliation key="aff1">
								<orgName type="department">Tencent AI Lab</orgName>
								<address>
									<postCode>518057</postCode>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shen</forename><forename type="middle">L</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Tencent AI Lab</orgName>
								<address>
									<postCode>518057</postCode>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">D</forename><surname>Tao</surname></persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Centre for Quantum Computation and Intelligent Systems</orgName>
								<orgName type="department" key="dep2">Faculty of Engineering and Information Technology</orgName>
								<orgName type="institution">University of Technology</orgName>
								<address>
									<addrLine>81 Broadway Street</addrLine>
									<postCode>2007</postCode>
									<settlement>Sydney, Ultimo</settlement>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">IEEE Transactions on Multimedia</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3AD52327E9448F6987F79AF39F03A106</idno>
					<idno type="DOI">10.1109/TMM.2017.2699863</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Asymmetric Binary Coding for Image Search Fumin Shen, Yang Yang, Li Liu, Wei Liu, Dacheng Tao and Heng Tao Shen Abstract-Learning to hash has attracted broad research interests in recent computer vision and machine learning studies, due to its ability to accomplish efficient approximate nearest neighbor (ANN) search. However, the closely related task, Maximum Inner Product Search (MIPS), has rarely been studied in this literature.</p><p>To facilitate the MIPS study, in this work, we introduce a general binary coding framework based on asymmetric hash functions, named Asymmetric Inner-product Binary Coding (AIBC). In particular, AIBC learns two different hash functions which can reveal the inner products between original data vectors by the generated binary vectors. Although conceptually simple, the associated optimization is very challenging due to the highly nonsmooth nature of the objective that involves sign functions. We tackle the nonsmooth optimization in an alternating manner, by which each single coding function is optimized in an efficient discrete manner. We also simplify the objective by discarding the quadratic regularization term which significantly boosts the learning efficiency. Both problems are optimized in an effective discrete way without continuous relaxations, which produces high-quality hash codes. In addition, we extend the AIBC approach to the supervised hashing scenario, where the inner products of learned binary codes are forced to fit the supervised similarities. Extensive experiments on several benchmark image retrieval databases validate the superiority of the AIBC approaches over many recently proposed hashing algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>In recent years, binary coding (also known as hashing) has become a very popular research subject in computer vision <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b47">[48]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b51">[52]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b56">[57]</ref> and multimedia processing <ref type="bibr" target="#b49">[50]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b39">[40]</ref>. After encoding high-dimensional feature vectors of documents, images, or videos to compact binary codes, an effective binary coding or hashing method is expected to accomplish efficient similarity search while preserving the similarities among original data to some extent. As a result, using binary codes to represent and search in massive data is a promising solution to handle large-scale vision tasks, because of not only the storage efficiency (typically several hundred binary bits per data item) but also the high time efficiency of pairwise distance computations in the Hamming space.</p><p>Almost all the previous binary coding and hashing algorithms were designed to deal with Approximate Nearest Neighbor (ANN) search. Studies have rarely been dedicated to Maximum Inner Product Search (MIPS), which actually plays a critical role in various vision and learning applications <ref type="bibr" target="#b37">[38]</ref>. The efficacy of aforementioned methods have not been validated on the MIPS problem yet. Shrivastava and Li <ref type="bibr" target="#b37">[38]</ref> proposed an Asymmetric Locality-Sensitive Hashing (ALSH) algorithm for searching with (un-normalized) inner product being the underlying similarity measure. ALSH converts the MIPS problem to a standard LSH ANN problem by performing a simple asymmetric transformations on data pairs. While ALSH inherits all the theoretical guarantees of LSH <ref type="bibr" target="#b37">[38]</ref>, it can hardly achieve promising search performance using short binary codes due to its independence of data.</p><p>In this work, we focus on learning data-dependent binary codes for tackling the MIPS problem. Inspired by the latest advance in asymmetric hashing <ref type="bibr" target="#b37">[38]</ref>, we propose an asymmetric binary code learning method for MIPS, thus named Asymmetric Inner-product Binary Coding (AIBC). Specifically, two sets of coding functions are learned such that the inner products between their generated binary codes can reveal the inner products between original data vectors. Despite conceptually simple, the associated optimization is very challenging due to the highly nonsmooth nature of the objective that involves sign functions. To this end, we tackle the nonsmooth optimization in an alternating manner, by which a single coding function is solved with the others fixed. Through introducing auxiliary discrete variables to replace the sign functions, the optimization procedure is made efficient. As a simplified version of the proposed binary code learning framework, we propose another objective which maximizes the correlations between the inner products of the produced binary codes and raw data vectors. In both objectives, the binary codes and coding functions are simultaneously learned without continuous relaxations, which is the key to achieve high-quality binary codes.</p><p>The main contributions of our work are summarized as follows:</p><p>1) We propose a binary code learning framework for addressing the MIPS problem, which has the clear aim of preserving the inner-product similarities among raw data vectors. To this end, we design a tractable discrete optimization method, by which high-quality binary codes are iteratively generated with a closed-form solution for each bit. 2) To further speed up binary code learning for MIPS, we propose an alternative simpler objective which maximizes the correlations between the inner products of the yielded binary codes and raw data vectors. By this objective, the binary codes can be learned in a much more efficient way and, usually, with higher quality. This is mainly because the problem can be easily solved with closed-form solutions for the two associated subproblems. 3) Based on the AIBC framework, we propose an asymmetric supervised hashing algorithm (ASH), which learns two sets of binary codes to fit the supervised similarities instead of the inner products of original data. The effectiveness of asymmetric hashing is further validated by the supervised hashing method. 4) Our AIBC methods (with two unsupervised objectives) together with the supervised ASH are extensively evaluated on several large-scale image datasets. The experimental results demonstrate the superiority of our methods over the state-of-the-arts. The rest of this paper is organized as follows. Section II briefly reviews the related works. Section IV-B elaborates the details of the proposed AIBC methods. In Section V, we evaluate our approaches on three real-world large-scale datasets, followed by the conclusion of this work in Section VI.</p><p>This paper is an extended version of the work previously published in <ref type="bibr" target="#b32">[33]</ref>. The major improvements in this work over <ref type="bibr" target="#b32">[33]</ref> include the refinement of Abstract, Introduction (Section I) and Related work (Section II); We extend the original work to a general binary coding framework for maximum inner product search, which is studied by both the unsupervised AIBC approach and the newly introduced asymmetric supervised hashing algorithm (Section IV-D); More experimental results with comparison to additional methods are provided (Section V).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>In this section, we briefly review related works in the hashing literature. The binary coding or hashing techniques can be roughly divided into two major categories: unsupervised and supervised methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Unsupervised hashing</head><p>Locality-Sensitive Hashing (LSH) <ref type="bibr" target="#b6">[7]</ref> is one of the most popular data-independent unsupervised hashing methods, which generates randomized hash functions via random projections. The LSH family has been continuously developed to accommodate a variety of distance and similarity measures, such as Euclidean distance, p-norm distance <ref type="bibr" target="#b2">[3]</ref>, Mahalanobis distance <ref type="bibr" target="#b14">[15]</ref>, kernel similarity <ref type="bibr" target="#b13">[14]</ref> <ref type="bibr" target="#b31">[32]</ref>. Although LSH is ensured to have high collision probability for similar data items, in practice LSH usually needs long hash bits and multiple hash tables to achieve both high precision and recall. The huge storage overhead may restrict its applications.</p><p>Recent years has witnessed a rapid development of the data-dependent methods (or learning-based methods). The literature was comprehensive reviewed in <ref type="bibr" target="#b45">[46]</ref> recently. Its emergence is due to the benefit that learned compact binary codes can effectively and efficiently index and organize massive data. Different from LSH, data-dependent binary coding methods aim to generate short binary codes using available training data. Among the learning based hashing algorithms, linear coding functions formed by a set of learned hyperplanes are mostly adopted, since they are computationally simple and easy to connect to traditional dimensionality reduction techniques. A number of algorithms in this category have been proposed, including unsupervised PCA Hashing <ref type="bibr" target="#b43">[44]</ref>, Iterative Quantization (ITQ) <ref type="bibr" target="#b8">[9]</ref>, Isotropic Hashing (IsoHash) <ref type="bibr" target="#b11">[12]</ref> and so on. Specially, the works <ref type="bibr" target="#b23">[24]</ref>[8] introduced a bilinear form of hash functions, which could well handle high-dimensional data. Along this lines, a few other types of hash functions had been proposed, such as Circulant Binary Embedding (CBE) <ref type="bibr" target="#b54">[55]</ref> and Binary Projection Bank (BPB) <ref type="bibr" target="#b19">[20]</ref>.</p><p>It has also been shown that harnessing nonlinear manifold structures will help produce neighborhood-preserving compact binary codes. Spectral Hashing (SH) <ref type="bibr" target="#b47">[48]</ref>[47] is a well-known algorithm in this style. More recently, Anchor Graph Hashing (AGH) <ref type="bibr" target="#b22">[23]</ref>[21] leverages anchor graphs for making hash code training and out-of-sample extension to novel data both tractable and efficient. Shen et al. <ref type="bibr" target="#b35">[36]</ref> proposed a general Inductive Manifold Hashing (IMH) scheme which generates nonlinear coding functions by exploiting the flexibility of available manifold learning approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Supervised hashing</head><p>By taking advantages of the manually-labeled data, the hashing performance has been significantly improved by the supervised methods. Some representative supervised hashing algorithms are supervised Minimal Loss Hashing (MLH) <ref type="bibr" target="#b30">[31]</ref>, Semi-Supervised Hashing (SSH) <ref type="bibr" target="#b43">[44]</ref>, Ranking-Based Supervised Hashing <ref type="bibr" target="#b44">[45]</ref>, FastH <ref type="bibr" target="#b17">[18]</ref> etc. It has also been studied to construct coding functions in a kernel space, for example, Binary Reconstructive Embedding (BRE) <ref type="bibr" target="#b12">[13]</ref>, Random Maximum Margin Hashing (RMMH) <ref type="bibr" target="#b10">[11]</ref>, Kernel-Based Supervised Hashing (KSH) <ref type="bibr" target="#b21">[22]</ref>, the kernel variant of ITQ <ref type="bibr" target="#b8">[9]</ref> and Supervised Discrete Hashing (SDH) <ref type="bibr" target="#b33">[34]</ref>. The kernel based hashing algorithms are shown to perform better than the linear based hashing ones in some applications.</p><p>Recently, a few deep learning based hashing algorithms had been proposed, where the features learned from deep neural networks were shown to achieve better performance than the hand-crafted ones <ref type="bibr" target="#b5">[6]</ref> <ref type="bibr" target="#b15">[16]</ref>. For these deep hashing approaches, there might be concern about the binary coding time, since predicting a novel test sample needs to go through the timeconsuming deep neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. BACKGROUND: MAXIMUM INNER PRODUCT SEARCH</head><p>We give a brief introduction of Maximum Inner Product Search (MIPS). MIPS has been playing a significant role in various applications, such as recommender systems, deformable part model, multi-class classification <ref type="bibr" target="#b37">[38]</ref>. Given a new query q, MIPS targets at retrieving the datum having the largest inner product with q from the database A. Formally, the MIPS problem is formulated as below: p = arg max a∈A a q.</p><p>(1)</p><p>For large-scale similarity search problems, it is practical to implement MIPS by employing binary coding techniques to achieve both storage and computational efficiencies. A binary coding function h(x) maps an original feature vector x to a binary code of r bits b ∈ {1, -1} r in the Hamming space <ref type="foot" target="#foot_0">1</ref> . Then problem (1) is reformulated as follows</p><formula xml:id="formula_0">p = arg max a∈A h(a) h(q).<label>(2)</label></formula><p>It is natural to apply the popular locality sensitive hashing (LSH) for this problem. The LSH algorithm is simply constructed by the random projections generated from the standard normal distribution. Despite the popularity, the direct use of LSH on MIPS does not inherit the high collision probability guarantee of that on near neighbor search problems. To solve this problem, Shrivastava and Li <ref type="bibr" target="#b37">[38]</ref> proposed the Asymmetric Locality Sensitive Hashing (ALSH) method, which converted the MIPS problem to the standard 2 nearest neighbor search problem. ALSH adopts two sets of different hash functions h(•) and z(•) to compute the inner product of the query and database point. The MIPS problem is performed as</p><formula xml:id="formula_1">p = arg max a∈A h(a) z(q),<label>(3)</label></formula><p>where h(•) and z(•) are both constructed directly from LSH, by simply appending a few entries to a and q with different values. ALSH was proved to share the similar collision guarantee of similar points on MIPS as LSH on nearest neighbor search problem, which is mainly benefited from the flexibility of asymmetric hash functions. An asymmetric LSH algorithm with sketches <ref type="bibr" target="#b4">[5]</ref> was previously proposed at a early stage. Recently, <ref type="bibr" target="#b29">[30]</ref>[29] <ref type="bibr" target="#b27">[28]</ref> discussed the effectiveness of asymmetric hashes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. A GENERAL BINARY CODING FRAMEWORK FOR MAXIMUM INNER PRODUCT SEARCH</head><p>In this section, we present our binary code learning framework for maximum inner product search (MIPS). and then propose an inner-product fitting model to learn two asymmetric coding functions. To speed up the optimization, we practically simplify the original objective by maximizing inner-product correlation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. The binary coding framework</head><p>While the LSH and ALSH methods guarantee search accuracy to some extent, promising performance can hardly be achieved with compact binary codes due to the independence of data. To overcome the above limitation, we propose to learn hash functions rather than random projection for coping with the MIPS task.</p><p>Suppose that we have two sets of points: A = [a 1 , a 2 , . . . , a n ] and X = [x 1 , x 2 , . . . , x m ], where a i ∈ R d×1 and x i ∈ R d×1 . Denote the similarity matrix of A and X as S ∈ R n×m , of which the element S ij defines the similarity of a i and x j . We aim to learn two sets of binary codes for A and X respectively, the inner product of which can well approximate S. Inspired by <ref type="bibr" target="#b37">[38]</ref>, we adopt the asymmetric form of hash functions in our binary code learning formulation. That is, we consider the following problem:</p><formula xml:id="formula_2">min h,z n i=1 m j=1 (h(a i ) z(x j ), S ij ).<label>(4)</label></formula><p>Here (•, •) can be any proper loss function that forces the two terms to be close, which we will discuss later.</p><p>Hash function The hash functions h(•) and z(•) can be a linear, non-linear (i.e., kernel-based) or even a deep neural networks based model. In this work, we focus on the simple linear hash function, i.e., the hash functions write h(a) = sgn(W a)</p><p>(5)</p><formula xml:id="formula_3">z(x) = sgn(R x)<label>(6)</label></formula><p>where W ∈ R d×r , R ∈ R d×r is the projection matrix.</p><p>We name the proposed asymmetric binary coding methods for maximum inner-product search as Asymmetric Innerproduct Binary Coding (AIBC).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Unsupervised: Inner product fitting</head><p>A natural approach to model the similarity of two points is through their inner product, i.e., S ij = a i x j . In practice, to better fit with binary codes, we normalize S ij to be r (or 0) by a threshold.</p><p>We consider the following problem with hash functions h(•) and z(•), min</p><formula xml:id="formula_4">h,z ||h(A) z(X) -S|| 2 . (<label>7</label></formula><formula xml:id="formula_5">)</formula><p>Here || • || is the Frobenius norm. Problem <ref type="bibr" target="#b6">(7)</ref> turns out to be a problem of inner product fitting with binary codes. We will show next that the utilization of asymmetric hash functions can significantly facilitate the optimization of the above discrete optimization problem.</p><p>We then have</p><formula xml:id="formula_6">min W,R ||sgn(W A) sgn(R X) -S|| 2 . (<label>8</label></formula><formula xml:id="formula_7">)</formula><p>It is easy to see that the above problem is highly non-convex and difficult (usually NP hard) to solve due to the discrete sign functions. A feasible solution is to relax the discrete constraint by omitting the sign function. The continuous relaxation methodology is widely applied for hash code learning. However, this approximation method may accumulate considerable quantization errors, which makes the final binary codes less effective.</p><p>In order to obtain high-quality hash functions, we keep the sign function in our formulation. By taking the advantage of the flexibility of asymmetric hash functions, for this discrete optimization problem, we can naturally choose to solve W and R in an alternating fashion, that is, solve for one variable each time while keeping the other one fixed. We thus first consider the following sub-problem with variable W by fixing z(X) = Z in <ref type="bibr" target="#b6">(7)</ref>,</p><formula xml:id="formula_8">min W ||sgn(W A) Z -S|| 2 . (<label>9</label></formula><formula xml:id="formula_9">)</formula><p>In practice, we initialize R by PCA projections. Similarly, by fixing h(A) = H, we obtain the following sub-problem with variable R, min</p><formula xml:id="formula_10">R ||H sgn(R X) -S|| 2 ,<label>(10)</label></formula><p>Problem ( <ref type="formula" target="#formula_8">9</ref>) or ( <ref type="formula" target="#formula_10">10</ref>) is still with the sign function and cannot be solved trivially by an off-the-shelf solver. We now present a scalable and tractable method to <ref type="bibr" target="#b8">(9)</ref>, and ( <ref type="formula" target="#formula_10">10</ref>) can be accordingly solved in the same way. To conquer the optimization involving discrete function, we introduce an auxiliary variable B ∈ {-1, 1} r×n to separate the optimizing variable W and the sign function. We will show next the introduction of the auxiliary variable B (binary codes for A) is the key to simplify the optimization. We rewrite problem <ref type="bibr" target="#b8">(9)</ref> as</p><formula xml:id="formula_11">min B,W ||B Z -S|| 2 + λ||B -W A|| 2<label>(11)</label></formula><formula xml:id="formula_12">s.t. B ∈ {-1, 1} r×n .</formula><p>The objective of ( <ref type="formula" target="#formula_11">11</ref>) has a clear explanation: the first term minimizes the inner products fitting error by the learned binary codes; while the second term ensures the hash function h(x) can well predict the target binary codes B with minimum quantization loss. The parameter λ serve a trade-off between these two loss terms.</p><p>In problem <ref type="bibr" target="#b10">(11)</ref>, given B, it is easy to compute</p><formula xml:id="formula_13">W W = (AA ) -1 AB .<label>(12)</label></formula><p>We then have the following problem w.r.t. B,</p><formula xml:id="formula_14">min B ||B Z|| 2 -2trace(B D)<label>(13)</label></formula><formula xml:id="formula_15">s.t. B ∈ {-1, 1} r×n ,</formula><p>where D = ZS + λW A. Note that ||B|| 2 = nr.</p><p>For this key sub-problem, inspired by the recent progress of binary codes optimization <ref type="bibr" target="#b33">[34]</ref>, we choose to solve one row of B each time while fixing all other rows, i.e., we compute one-bit for all n samples each time. Let b be the l th row of </p><formula xml:id="formula_16">B, l = 1, • • • ,</formula><formula xml:id="formula_17">s.t. b ∈ {-1, 1} n .<label>(14)</label></formula><p>Thus, we obtain the optimal solution for the</p><formula xml:id="formula_18">l th row of B, b = sgn(z Z B -d).<label>(15)</label></formula><p>By this method, each bit is iteratively updated with the prelearned r -1 bits till the procedure converges with a set of better codes. In our experiments, the procedure usually converges with less than 10 iterations. With the analytical solution for each bit, the whole optimization is very efficient and thus can easily scale to massive data. Till now, we are ready to solve problem <ref type="bibr" target="#b10">(11)</ref> (therefor also ( <ref type="formula" target="#formula_8">9</ref>)) iteratively with the solution of W and B provided above. By iteratively solve ( <ref type="formula" target="#formula_8">9</ref>) and ( <ref type="formula" target="#formula_10">10</ref>), we finally obtain a pair of hash function of h(•) and z(•). Although this method can hardly achieve the globally optimal solution for the discrete optimization problem, at each step, the local optimal solution for each variable (e.g., W, b) is obtained in a closed form. We will show in the experiments that this optimization strategy works very well. Since the objective <ref type="bibr" target="#b6">(7)</ref> of this method involves a quadratic term with the hash functions, we denote this method as AIBC-Q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Unsupervised: Inner product correlation maximization</head><p>In this part, we propose an alternative model to further speed up the learning procedure of AIBC. We optimize the following problem:</p><formula xml:id="formula_19">max h,z trace(h(A)Sz(X) ).<label>(16)</label></formula><p>Problem ( <ref type="formula" target="#formula_19">16</ref>) has a clear intuition: it maximizes the correlation between the similarity matrix S and the inner products between learned binary codes. Note that the objective of ( <ref type="formula" target="#formula_19">16</ref>) can be easily obtained by discarding the quadratic term ||h(A) z(X)|| 2 in (4). However, the quadratic term does not leverage the groundtruth similarity and can be seen as a regularization with the magnitude of the learned inner product. We show next it provides a much more efficient mean of solving the asymmetric hash function learning problem. Using the same strategy described in the previous section, for <ref type="bibr" target="#b15">(16)</ref> we obtain the following two sub-problems ( <ref type="formula" target="#formula_20">17</ref>) and (18) w.r.t. W and R, respectively.</p><formula xml:id="formula_20">max W trace(sgn(W A)SZ ), (<label>17</label></formula><formula xml:id="formula_21">) max R trace(HSsgn(R X) ).<label>(18)</label></formula><p>By introducing the auxiliary variable B, problem ( <ref type="formula" target="#formula_20">17</ref>) is formulated as</p><formula xml:id="formula_22">max B,W trace(BSZ ) -λ||B -W A|| 2<label>(19)</label></formula><formula xml:id="formula_23">s.t. B ∈ {-1, 1} r×n .</formula><p>Same as problem <ref type="bibr" target="#b10">(11)</ref>, we solve problem <ref type="bibr" target="#b18">(19)</ref> iteratively with B and W. The difference is, problem <ref type="bibr" target="#b18">(19)</ref> benefits from the advantage that it has a optimal analytical solution for B with a given W,</p><formula xml:id="formula_24">B = sgn ZS + 2λW A . (<label>20</label></formula><formula xml:id="formula_25">)</formula><p>Compared to problem (4), optimizing (16) does not only make <ref type="bibr" target="#b18">(19)</ref> much more efficient to solve but also provide more accurate solution for the whole optimization. This explains why this method performs slightly better than AIBC-Q in our experiments. The optimization of ( <ref type="formula" target="#formula_22">19</ref>) can be easily solved by iteratively updating B and W (by <ref type="bibr" target="#b11">(12)</ref>). With the above closed-form solutions, the training of the proposed method can be easily performed on large-scale data with very high efficiency. Since the objective <ref type="bibr" target="#b15">(16)</ref> of this method only involves a linear term with each hash function, we denote this method as AIBC-L.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1</head><p>Asymmetric Inner-product Binary Coding (AIBC) Input: Data A and X; code length r; maximum iteration number t; parameters λ. Output: Hash function h(x) and z(x).</p><p>1) Compute similarity matrix S by A X for unsupervised hashing or by Eq. ( <ref type="formula" target="#formula_27">21</ref>) for supervised hashing. 2) Initialize R by PCA projections.</p><p>3) Loop until converge or reach maximum t iterations:</p><p>• h-step: Compute W by solving problem <ref type="bibr" target="#b8">(9)</ref> or <ref type="bibr" target="#b16">(17)</ref>. • z-step: Compute R by solving problem <ref type="bibr" target="#b9">(10)</ref> or <ref type="bibr" target="#b17">(18)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Supervised: Supervised asymmetric hashing</head><p>In this section, we extend our asymmetric inner-product binary coding (AIBC) approach to cope with the supervised hashing problem. In the supervised scenario, a simple modification of AIBC is to compute the similarity matrix (denoted as S l ) by the provided semantic labels. That is, we compute S l by</p><formula xml:id="formula_26">S l ij =</formula><p>r, if a i and x j share the same label(s), 0, otherwise.</p><p>Particularly, for multiple labelled data, S ij = r if a i and x j share at least one labels. Similar settings has been used in many supervised hashing methods <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b43">[44]</ref>. With the 2 loss as in <ref type="bibr" target="#b6">(7)</ref>, we write our supervised hashing as</p><formula xml:id="formula_28">min h,z ||h(A) z(X) -S l || 2 . (<label>22</label></formula><formula xml:id="formula_29">)</formula><p>Similarly, with the linear loss as in ( <ref type="formula" target="#formula_19">16</ref>), we have</p><formula xml:id="formula_30">max h,z trace(h(A)S l z(X) ).<label>(23)</label></formula><p>Both the above two problems can be solved exactly the same as the unsupervised algorithm as discussed before. For efficiency, in practice we adopt the supervised hashing method in <ref type="bibr" target="#b22">(23)</ref>.</p><p>The optimization follows the same procedure in Section IV-C with PCA as initialization. For the supervised hashing method, other supervised dimensionality reduction algorithms (e.g., LDA) can potentially improve the performance, which is however not the focus of this work. We denote this method as asymmetric supervised hashing (ASH) in the following text.</p><p>Connection to KSH The kernel-based supervised hashing (KSH) <ref type="bibr" target="#b21">[22]</ref> uses a similar objective as in <ref type="bibr" target="#b21">(22)</ref>:</p><formula xml:id="formula_31">min h ||h(A)h(A) -S l || 2 . (<label>24</label></formula><formula xml:id="formula_32">)</formula><p>However, our proposed AIBC mainly differs from KSH in the following aspects: 1) KSH learns a single coding function while AIBC learns two coding functions in an asymmetric fashion. 2) KSH applies a greedy optimization procedure to solve a relaxed problem by using a sigmoid function to replace the sign function. In contrast, AIBC directly optimizes the binary codes without resorting to any continuous relaxations.</p><p>In the experiments, we compare our methods with KSH and its unsupervised version (implemented by ourselves) and the comparative results clearly show the advantage of our AIBC techniques. We summarize the proposed Asymmetric Innerproduct Binary Coding (AIBC) algorithm in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS</head><p>In this section, we first compare the proposed AIBC to the state-of-the-arts in both supervised and unsupervised scenarios to validate its effectiveness. The AIBC model is then evaluated in terms of time efficiency, training convergence and parameter sensitiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Evaluation on unsupervised hashing</head><p>In this section, we evaluate the proposed two unsupervised hashing algorihtms (i.e., AIBC-Q and AIBC-L) by comparing them to several representative unuspervised hashing methods in the literature. Three large-scale datasets: YouTube Faces <ref type="bibr" target="#b48">[49]</ref>, SUN397 <ref type="bibr" target="#b50">[51]</ref> and ImageNet <ref type="bibr" target="#b3">[4]</ref> are used. The compared unsupervised hashing methods including LSH (implemented by signed random projections), ALSH <ref type="bibr" target="#b37">[38]</ref>, SH <ref type="bibr" target="#b47">[48]</ref>, ITQ <ref type="bibr" target="#b8">[9]</ref>, IsoHash <ref type="bibr" target="#b11">[12]</ref>, AGH <ref type="bibr" target="#b22">[23]</ref> and IMH <ref type="bibr" target="#b34">[35]</ref>. We also compare the unsupervised version of KSH <ref type="bibr" target="#b21">[22]</ref> implemented by ourselves with the similarity computed by inner product (thus named InnerKSH). We use the public codes and suggested parameters of these methods from the authors. For InnerKSH, we use 4,000 training samples to form the pairwise similarity matrix and randomly choose 1,000 samples as anchor points. Since our methods are unsupervised, we do not compare them with the supervised methods. For our AIBC, we empirically set the parameter λ to 100 and the maximum iteration number t = 2; the data matrix A is set as the whole training data; X is formed by the 10,000 randomly selected points from training data. We binarize each column of S with a threshold computed by the k th largest one among the n inner products, where k is set to 500 for SUN397, 1000 for ImageNet and 2000 for YouTube Faces. For evaluation, database data and queries are compressed by h(x) and z(x), respectively.</p><p>We report the compared results in terms of both hash lookup: precision of Hamming distance 2 (HD2 Precision) and Hamming ranking: mean of average precision (mAP) and mean precision of the top 500 retrieved neighbors (Precision@500). We also present the detailed results by precisionrecall and the precision of top 2000 curves. Note that we treat a query as a false case if no point is returned when calculating precisions. Ground truths are defined by the category information from the datasets.</p><p>1) SUN397: retrieval with scene images: SUN397 [51] contains about 108K images from 397 scene categories, where each image is represented by a 1,600-dimensional feature vector extracted by PCA from 12,288-dimensional Deep Convolutional Activation Features <ref type="bibr" target="#b9">[10]</ref>. We use a subset of this dataset including 42 categories with each containing more than 500 images (with total 33K images); 100 images are sampled uniformly randomly from each category to form a test set of 4,200 images.</p><p>The comparative results are shown in Table <ref type="table" target="#tab_0">I</ref>. First we can see that the proposed AIBC-L significantly outperforms all other algorithms in mAP with all code lengths. In terms of  precision500, AGH achieves the best result at 32-bit. However, we observe that it suffers from a severe performance drop with long code length for both MAP and precision. For example, AGH obtains much lower results than ITQ, IMH and AIBC at 128-bit. Our AIBC-Q performs slight worse than AIBC-L on this dataset, although it still outperforms all other methods in situations. It is not surprising that the data-independent algorithm LSH and ALSH do not perform as well as other learning based methods. Interestingly we also observe that the asymmetric ALSH algorithm achieves close results with the original signed random projection based LSH method on this dataset. The detailed precision curves of up to top 2000 retrieved samples and the precision-recall curves using 64 bits are shown in Figure <ref type="figure" target="#fig_1">1</ref>. We can easily see that the performance rank of the precision curves of the compared methods is consistent with the above analysis. The proposed AIBC still performs the best among the compared algorithms.</p><p>2) YouTube Faces: retrieval with face images: YouTube Faces dataset contains 1,595 different people, from which we choose 340 people such that each one has at least 500 images to form a subset of 370,319 face images, and represent each face image as a 1,770-dimensional LBP feature vector <ref type="bibr" target="#b0">[1]</ref>. We use a subset of YouTube Faces with 38 people each containing more than 2,000 faces (about 100K images in total). The test set includes 3,800 face images which are evenly sampled from each of the 38 classes.  We report the results on YouTube Faces in Table <ref type="table" target="#tab_1">II</ref>. Again, the proposed AIBC-L and AIBC-Q achieve the best results on this dataset in all situations. For instance, with 64 bits the proposed AIBC-L obtains 82.33% MAP which is higher than the second best 79.16% (by IMH) by 3.17%. SH and IsoHash do not perform as well as other data-dependent methods on this dataset. The proposed AIBC is further compared to these methods in precision of top 2000 samples and precision-recall. As can be clearly observed in Figure <ref type="figure" target="#fig_2">2</ref>, AIBC ranks the first on both of the two evaluation curves.</p><p>3) ImageNet: retrieval with large dataset : As a subset of ImageNet <ref type="bibr" target="#b3">[4]</ref>, the large dataset ILSVRC 2012 contains over 1.2 million images of totally 1,000 categories. We form the retrieval database by the 100 largest classes with total 128K images from the provided training set, and 50,000 images from the validation set as the query set. As in <ref type="bibr" target="#b17">[18]</ref>, we use the 4096-dimensional features extracted by the convolution neural networks (CNN) model.</p><p>The results are shown in Table <ref type="table" target="#tab_2">III</ref>. The superiority of the AIBC is further demonstrated on this large-scale database. For example, with 64-bit AIBC-L achieves 54.02% mAP while the best results of other methods is 50.95% obtained by AGH. Between the proposed methods, AIBC-L tends to achieve better MAP and precision than AIBC-Q with short binary codes (i.e., 32-bit and 64-bit), while these two methods obtain close results at 128-bit. Figure <ref type="figure" target="#fig_3">3</ref> illustrates the precision and  precision-recall curves, which clearly show AIBC performs better than other methods on this large dataset. At last, we evaluate the proposed AIBC by hash lookup in the metric of Hamming distance 2 precision. The compared results of various methods with 32 bits are shown in Table <ref type="table" target="#tab_3">IV</ref>. AGH obtains the best results (51.95%) on the SUN 397 dataset. However, AGH is surpassed by AIBC by large gaps, i.e., 13.7% and 6.92% on Youtube faces and ImageNet, respectively. The proposed AIBC methods (AIBC-Q and AIBC-L) also obtain similar results under this metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Evaluation on supervised hashing</head><p>We next validate the effectiveness of the proposed asymmetric hashing algorithm ASH by comparing with several recently proposed supervised hashing algorithm. These methods include Minimal Loss (MLH) <ref type="bibr" target="#b30">[31]</ref>, Kernel-Based Supervised Hashing (KSH) <ref type="bibr" target="#b21">[22]</ref>, CCA-ITQ <ref type="bibr" target="#b8">[9]</ref>, FastH <ref type="bibr" target="#b17">[18]</ref> and Supervised Discrete Hashing (SDH) <ref type="bibr" target="#b33">[34]</ref>. Due to the large memory overhead and computational costs, we sample 5K and 20K training samples for MLH, KSH and FastH, respectively.</p><p>the efficient CCA-ITQ, all available training data is used. As in Section V-A, we use all training data for A and 10,000 samples for X for our method.</p><p>1) Retrieval with single-labled images: In this part, we use the single-labeled datasets SUN397 and ImageNet for evaluation. The comparative results in MAP and Precision@500 are   <ref type="figure">4</ref> and 5 on the two datasets. Our method shows consistent improvements over other state-of-the-art approaches. These results clearly demonstrate the effectiveness of asymmetric hashing for image search in the supervised setting.</p><p>2) Retrieval with multi-labled images: In this part, we compare these supervised hashing methods on the NUS-WIDE dataset containing images annoted by multiple lables. The NUS-WIDE database <ref type="bibr" target="#b1">[2]</ref> contains about 270,000 images collected from Flickr. The images in NUS-WIDE are associated with 81 concepts, with each image containing multiple semantic labels. We define the true neighbors of a query as the images sharing at least one labels with the query image. The 1520-9210 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. provided 500-dimensional Bag-of-Words features are used. As suggested in <ref type="bibr" target="#b33">[34]</ref>, we collect the 21 most frequent label for test. For each label, 100 images are uniformly sampled for the query set and the remaining images are for the training set. The results in terms of retrieval performance (mAP and Precision@500) are reported in Table <ref type="table" target="#tab_5">VI</ref>. We observe that ASH achieves promising results on this multi-labeled dataset. The precision and precision-recall curves in Figure <ref type="figure" target="#fig_5">6</ref> validate the advantage of the proposed ASH on this dataset. Through the above experiments, we conclude that the proposed AIBC can achieve promising retrieval results compared to both supervised and unsupervised state-of-the-art hashing methods. We next analyze the AIBC model by the computational efficiency, parameter sensitiveness and convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Algorithm analysis</head><p>Efficiency We take the SUN397 dataset as an example to evaluate the computational efficiency of these compared algorithms. The model training time and the testing time (of compressing one query into binary codes with the trained model) are shown in Table <ref type="table" target="#tab_6">VII</ref>. First, we are not surprised to see that the proposed AIBC-L has a significant computational advantage over AIBC-Q, due to the simplified objective. Compared to SH, IsoHash and AGH, AIBC-L consumes more time to train the hash functions, which is mainly occupied by the inner product matrix calculation. However, the training of AIBC-L is still sufficiently efficient to scale to large-scale data: it runs only about 15 seconds on a standard PC for training with the whole 33K images of the SUN397 database. As can  be seen, InnerKSH suffers from a huge computational overwith the greedy optimization procedure, while AIBC-L can be trained much more efficiently with the closed-form solution of each sub-problem.</p><p>Parameter sensitive study In this part, we empirically evaluate the proposed algorithm (AIBC-L) on ImageNet and SUN397 with parameter λ varied from 0.1 to 10,000. We observe from Figure <ref type="figure" target="#fig_6">7</ref> that the performance reaches the peak at λ = 100, and drops dramatically with larger λs. In Eq. 11, the value of W A will be exactly equal to B with arbitrary large λ. This result demonstrate that allowing a certain discrepancy between B and the magnitude W A of the sign function is preferred for better performance.</p><p>Convergence study We also show in Figure <ref type="figure" target="#fig_7">8</ref> the objective values of our algorithm with increasing number of iterations. As can be seen, the algorithm converges within about 10 iterations. We conclude the fast convergence is due to the optimal analytical solution obtained in each sub-problem. The analytical solution not only provides fast training but also achieves high-quality codes as in the previous experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION AND FUTURE WORK</head><p>This paper focused on binary code learning for the maixmum Inner product search (MIPS) problem through proposing an inner-product fitting framework. In the framework, two asymmetric coding functions are learned such that the inner products between original data pairs are approximated by the produced binary code vectors. Benefiting from the flexibility of the asymmetric coding mechanism, we solved the optimization in an alternating fashion involving two sub-problems. We also  proposed an alternative objective that maximizes the correlations between the inner products of the pursed binary codes and raw data vectors, which enjoys a closed-form solution for each sub-problem, thus making the whole optimization more efficient. The effectiveness of the proposed Asymmetric Innerproduct Binary Coding (AIBC) technique with both quadratic (AIBC-Q) and linear objectives (AIBC-L) were validated on several large-scale image datasets. As an extension of AIBC, we proposed an asymmetric supervised hashing (ASH) algorithm, which maximized the correlations between the supervised similarity matrix and code inner products. Despite visual retrieval, the proposed AIBC can be potentially used in recommendation systems <ref type="bibr" target="#b55">[56]</ref>, visual recognition <ref type="bibr" target="#b52">[53]</ref>[54] <ref type="bibr" target="#b38">[39]</ref> and related tasks. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>r, and B the remaining rows of B. Then b contains one bit for each of n samples. Similarly, let d be the l th row of D, D the matrix of D excluding d, z the l th row of Z and Z the matrix of Z excluding z. With these notations and a few simple matrix manipulations, problem (13) can be written as w.r.t. b min b b( B Zzd )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 :</head><label>1</label><figDesc>Fig.1: Precision curves of up to top 2000 retrieved samples and precision-recall curves on SUN397. We only report AIBC-L for AIBC for clarity. 64 bits are used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Precision curves of up to top 2000 retrieved samples and precision-recall curves on Youtube Faces. We only report AIBC-L for AIBC for clarity. 64 bits are used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Precision curves up to top 2000 retrieved samples and precision-recall curves on ImageNet. We only report AIBC-L for AIBC for clarity. 64 bits are used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>8 NumberFig. 4 :Fig. 5 :</head><label>845</label><figDesc>Fig. 4: Precision top 2000 curves and Precision-recall curves on SUN397 with 64 bits.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 :</head><label>6</label><figDesc>Fig. 6: Precision top 2000 curves and Precision-recall curves on NUS-WIDE with 64 bits.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 :</head><label>7</label><figDesc>Fig. 7: MAPs with varying λs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 :</head><label>8</label><figDesc>Fig. 8: Objective value with iterations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I :</head><label>I</label><figDesc>Results in terms of mAP and Precision of top 500 samples of the compared methods on SUN397 with 32, 64 and 128 bits, respectively.</figDesc><table><row><cell>Method</cell><cell>32-bit</cell><cell>mAP 64-bit</cell><cell>128-bit</cell><cell>32-bit</cell><cell cols="3">Precision@500 64-bit 128-bit</cell></row><row><cell>LSH</cell><cell>0.0605</cell><cell>0.0920</cell><cell>0.1428</cell><cell cols="2">0.0921</cell><cell>0.1397</cell><cell>0.2036</cell></row><row><cell>ALSH</cell><cell>0.0592</cell><cell>0.0913</cell><cell>0.1425</cell><cell cols="2">0.0918</cell><cell>0.1406</cell><cell>0.2033</cell></row><row><cell>SH</cell><cell>0.2103</cell><cell>0.2191</cell><cell>0.1991</cell><cell cols="2">0.2737</cell><cell>0.2877</cell><cell>0.2735</cell></row><row><cell>IsoHash</cell><cell>0.2414</cell><cell>0.2668</cell><cell>0.2850</cell><cell cols="3">0.2912 0.3198</cell><cell>0.3391</cell></row><row><cell>ITQ</cell><cell>0.3014</cell><cell>0.3336</cell><cell>0.3456</cell><cell cols="2">0.3448</cell><cell>0.3774</cell><cell>0.3887</cell></row><row><cell>AGH</cell><cell>0.3629</cell><cell>0.3026</cell><cell>0.2383</cell><cell cols="2">0.4238</cell><cell>0.3806</cell><cell>0.3353</cell></row><row><cell>IMH</cell><cell>0.3043</cell><cell>0.3374</cell><cell>0.3631</cell><cell cols="2">0.3363</cell><cell>0.3690</cell><cell>0.3925</cell></row><row><cell>InnerKSH</cell><cell>0.2900</cell><cell>0.3312</cell><cell>0.3558</cell><cell cols="2">0.3367</cell><cell>0.3734</cell><cell>0.3923</cell></row><row><cell>AIBC-Q</cell><cell>0.3549</cell><cell>0.3925</cell><cell>0.4299</cell><cell cols="2">0.3996</cell><cell>0.4263</cell><cell>0.4409</cell></row><row><cell>AIBC-L</cell><cell>0.3639</cell><cell>0.4042</cell><cell>0.4348</cell><cell cols="2">0.4078</cell><cell>0.4428</cell><cell>0.4642</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II :</head><label>II</label><figDesc>Results in terms of mAP, Precision of top 500 samples of the compared methods on the YouTube Faces database with 32, 64 and 128 bits, respectively.</figDesc><table><row><cell cols="4">Method</cell><cell>32-bit</cell><cell></cell><cell>mAP 64-bit</cell><cell>128-bit</cell><cell>32-bit</cell><cell>Precision@500 64-bit 128-bit</cell></row><row><cell></cell><cell cols="2">LSH</cell><cell></cell><cell>0.1341</cell><cell></cell><cell>0.2513</cell><cell>0.4092</cell><cell>0.2710</cell><cell>0.4811</cell><cell>0.7004</cell></row><row><cell></cell><cell cols="2">ALSH</cell><cell></cell><cell>0.1124</cell><cell></cell><cell>0.2104</cell><cell>0.3565</cell><cell>0.2210</cell><cell>0.4106</cell><cell>0.6355</cell></row><row><cell></cell><cell></cell><cell>SH</cell><cell></cell><cell>0.6543</cell><cell></cell><cell>0.6395</cell><cell>0.5677</cell><cell>0.8556</cell><cell>0.9001</cell><cell>0.9047</cell></row><row><cell cols="4">IsoHash</cell><cell>0.6756</cell><cell></cell><cell>0.7204</cell><cell>0.7274</cell><cell>0.8698</cell><cell>0.9150</cell><cell>0.9274</cell></row><row><cell></cell><cell cols="2">ITQ</cell><cell></cell><cell>0.7443</cell><cell></cell><cell>0.7775</cell><cell>0.7767</cell><cell>0.8979</cell><cell>0.9321</cell><cell>0.9416</cell></row><row><cell></cell><cell cols="2">AGH</cell><cell></cell><cell>0.7054</cell><cell></cell><cell>0.6236</cell><cell>0.4610</cell><cell>0.8843</cell><cell>0.9233</cell><cell>0.9171</cell></row><row><cell></cell><cell cols="2">IMH</cell><cell></cell><cell>0.7467</cell><cell></cell><cell>0.7916</cell><cell>0.7916</cell><cell>0.8600</cell><cell>0.9228</cell><cell>0.9343</cell></row><row><cell cols="4">InnerKSH</cell><cell>0.7512</cell><cell></cell><cell>0.7634</cell><cell>0.7757</cell><cell>0.8989</cell><cell>0.9138</cell><cell>0.9239</cell></row><row><cell cols="4">AIBC-Q</cell><cell>0.7913</cell><cell></cell><cell>0.8175</cell><cell>0.8293</cell><cell>0.9393</cell><cell>0.9502</cell><cell>0.9625</cell></row><row><cell cols="4">AIBC-L</cell><cell>0.8152</cell><cell></cell><cell>0.8233</cell><cell>0.8400</cell><cell>0.9477</cell><cell>0.9551</cell><cell>0.9590</cell></row><row><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Precision</cell><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.2</cell><cell>0</cell><cell>500</cell><cell>1000</cell><cell>1500</cell><cell>2000</cell></row><row><cell></cell><cell></cell><cell cols="4">Number of retrieved samples</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">(a) Precision</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III :</head><label>III</label><figDesc>Results in terms of mAP and Precision of top 500 samples of the compared methods on the ImageNet database with 32, 64 and 128 bits, respectively.</figDesc><table><row><cell>Method</cell><cell>32-bit</cell><cell>mAP 64-bit</cell><cell>128-bit</cell><cell>32-bit</cell><cell cols="3">Precision@500 64-bit 128-bit</cell></row><row><cell>LSH</cell><cell>0.0496</cell><cell>0.0974</cell><cell>0.1743</cell><cell cols="3">0.1036 0.1963</cell><cell>0.3133</cell></row><row><cell>ALSH</cell><cell>0.0495</cell><cell>0.0907</cell><cell>0.1694</cell><cell cols="2">0.1043</cell><cell>0.1847</cell><cell>0.3074</cell></row><row><cell>SH</cell><cell>0.2418</cell><cell>0.3066</cell><cell>0.3309</cell><cell cols="3">0.3647 0.4531</cell><cell>0.4956</cell></row><row><cell>IsoHash</cell><cell>0.2521</cell><cell>0.3326</cell><cell>0.3847</cell><cell cols="2">0.3673</cell><cell>0.4649</cell><cell>0.5231</cell></row><row><cell>ITQ</cell><cell>0.3231</cell><cell>0.4127</cell><cell>0.4621</cell><cell cols="3">0.4304 0.5313</cell><cell>0.5882</cell></row><row><cell>AGH</cell><cell>0.4545</cell><cell>0.5095</cell><cell>0.4541</cell><cell cols="2">0.5346</cell><cell>0.6086</cell><cell>0.6036</cell></row><row><cell>IMH</cell><cell>0.2805</cell><cell>0.3554</cell><cell>0.3985</cell><cell cols="3">0.3197 0.4453</cell><cell>0.4998</cell></row><row><cell>InnerKSH</cell><cell>0.4073</cell><cell>0.4651</cell><cell>0.4850</cell><cell cols="2">0.5080</cell><cell>0.5693</cell><cell>0.5893</cell></row><row><cell>AIBC-Q</cell><cell>0.4421</cell><cell>0.5280</cell><cell>0.5756</cell><cell cols="2">0.5702</cell><cell>0.6180</cell><cell>0.6658</cell></row><row><cell>AIBC-L</cell><cell>0.4771</cell><cell>0.5402</cell><cell>0.5753</cell><cell cols="2">0.5796</cell><cell>0.6375</cell><cell>0.6643</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV :</head><label>IV</label><figDesc>Comparison in HD2 precision with code length 32.</figDesc><table><row><cell>Method</cell><cell>SUN 397</cell><cell>Youtube Faces</cell><cell>ImageNet</cell></row><row><cell>LSH</cell><cell>0.0304</cell><cell>0.4444</cell><cell>0.0708</cell></row><row><cell>ALSH</cell><cell>0.0352</cell><cell>0.3262</cell><cell>0.0644</cell></row><row><cell>SH</cell><cell>0.2479</cell><cell>0.9596</cell><cell>0.4029</cell></row><row><cell>IsoHash</cell><cell>0.3101</cell><cell>0.9561</cell><cell>0.4194</cell></row><row><cell>ITQ</cell><cell>0.3815</cell><cell>0.9646</cell><cell>0.4619</cell></row><row><cell>AGH</cell><cell>0.5195</cell><cell>0.8561</cell><cell>0.4903</cell></row><row><cell>IMH</cell><cell>0.3107</cell><cell>0.7467</cell><cell>0.2493</cell></row><row><cell>InnerKSH</cell><cell>0.3735</cell><cell>0.9697</cell><cell>0.4942</cell></row><row><cell>AIBC-Q</cell><cell>0.4684</cell><cell>0.9859</cell><cell>0.5280</cell></row><row><cell>AIBC-L</cell><cell>0.4704</cell><cell>0.9931</cell><cell>0.5595</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE V :</head><label>V</label><figDesc>MAP and Precision500 of the compared supervised hashing methods on SUN 397 and ImageNet.</figDesc><table><row><cell>Method</cell><cell>32-bit</cell><cell>mAP 64-bit</cell><cell>128-bit</cell><cell>32-bit</cell><cell cols="3">Precision@500 64-bit 128-bit</cell></row><row><cell></cell><cell></cell><cell></cell><cell>SUN 397</cell><cell></cell><cell></cell><cell></cell></row><row><cell>MLH</cell><cell>0.1558</cell><cell>0.2040</cell><cell>0.2170</cell><cell cols="2">0.2200</cell><cell>0.2824</cell><cell>0.3091</cell></row><row><cell>CCA-ITQ</cell><cell>0.6291</cell><cell>0.7241</cell><cell>0.7390</cell><cell cols="2">0.6291</cell><cell>0.7099</cell><cell>0.7170</cell></row><row><cell>KSH</cell><cell>0.6291</cell><cell>0.7099</cell><cell>0.7170</cell><cell cols="2">0.4815</cell><cell>0.5376</cell><cell>0.5833</cell></row><row><cell>FastH</cell><cell>0.6204</cell><cell>0.7043</cell><cell>0.7526</cell><cell cols="3">0.6219 0.6925</cell><cell>0.7295</cell></row><row><cell>SDH</cell><cell>0.6317</cell><cell>0.7007</cell><cell>0.7310</cell><cell cols="2">0.6526</cell><cell>0.6992</cell><cell>0.7181</cell></row><row><cell>ASH</cell><cell>0.8087</cell><cell>0.8237</cell><cell>0.8271</cell><cell cols="2">0.7480</cell><cell>0.7617</cell><cell>0.7650</cell></row><row><cell></cell><cell></cell><cell></cell><cell>ImageNet</cell><cell></cell><cell></cell><cell></cell></row><row><cell>MLH</cell><cell>0.4106</cell><cell>0.4889</cell><cell>0.5509</cell><cell cols="2">0.5136</cell><cell>0.5939</cell><cell>0.6533</cell></row><row><cell>CCA-ITQ</cell><cell>0.4286</cell><cell>0.5959</cell><cell>0.7199</cell><cell cols="2">0.4730</cell><cell>0.6401</cell><cell>0.7601</cell></row><row><cell>KSH</cell><cell>0.4624</cell><cell>0.5553</cell><cell>0.6228</cell><cell cols="2">0.5488</cell><cell>0.6431</cell><cell>0.6963</cell></row><row><cell>FastH</cell><cell>0.4721</cell><cell>0.5791</cell><cell>0.6495</cell><cell cols="3">0.5942 0.6846</cell><cell>0.7339</cell></row><row><cell>SDH</cell><cell>0.5919</cell><cell>0.6771</cell><cell>0.7208</cell><cell cols="2">0.6867</cell><cell>0.7432</cell><cell>0.7667</cell></row><row><cell>ASH</cell><cell>0.7501</cell><cell>0.7854</cell><cell>0.7961</cell><cell cols="3">0.7128 0.7480</cell><cell>0.7688</cell></row><row><cell cols="8">reported in Table V. It can be clearly seen that on these two</cell></row><row><cell cols="8">datasets our ASH significantly outperforms other methods in</cell></row><row><cell cols="8">most cases. On the SUN 397 dataset, CCA-ITQ, KSH, FastH</cell></row><row><cell cols="8">and SDH achieve on par MAPs with short bit length, while</cell></row><row><cell cols="8">FastH perform best at 128-bit (75.26%), which is however still</cell></row><row><cell cols="8">much lower than ASH (82.71%). In terms of precision500,</cell></row><row><cell cols="8">ASH also outperform all other methods by over 4% accuracy.</cell></row><row><cell cols="8">On the ImageNet dataset, SDH performs the second best and</cell></row><row><cell cols="8">achieve close precision at 128-bit with ASH. The detailed</cell></row><row><cell cols="8">comparison of these methods are furthered shown in Precision</cell></row><row><cell cols="7">of top 2000 curves Precision-recall curves in Figure</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE VI :</head><label>VI</label><figDesc>MAP (%) and Precision500 (%) of the compared supervised hashing methods on the multi-labled dataset NUS-WIDE.</figDesc><table><row><cell></cell><cell cols="2">Method</cell><cell>32-bit</cell><cell>mAP 64-bit</cell><cell cols="2">128-bit</cell><cell></cell><cell>32-bit</cell><cell cols="4">Precision@500 64-bit 128-bit</cell></row><row><cell></cell><cell cols="2">MLH</cell><cell>0.4633</cell><cell>0.4670</cell><cell cols="2">0.4733</cell><cell></cell><cell cols="4">0.5413 0.5587</cell><cell>0.5676</cell></row><row><cell></cell><cell cols="2">CCA-ITQ</cell><cell>0.4544</cell><cell>0.4627</cell><cell cols="2">0.4690</cell><cell></cell><cell cols="2">0.5354</cell><cell cols="2">0.5440</cell><cell>0.5533</cell></row><row><cell></cell><cell></cell><cell>KSH</cell><cell>0.4899</cell><cell>0.5085</cell><cell cols="2">0.5095</cell><cell></cell><cell cols="4">0.4066 0.5292</cell><cell>0.5752</cell></row><row><cell></cell><cell cols="2">FastH</cell><cell>0.5146</cell><cell>0.5239</cell><cell cols="2">0.5327</cell><cell></cell><cell cols="2">0.5584</cell><cell cols="2">0.5885</cell><cell>0.6140</cell></row><row><cell></cell><cell></cell><cell>SDH</cell><cell>0.5141</cell><cell>0.5214</cell><cell cols="2">0.5283</cell><cell></cell><cell cols="4">0.5399 0.5739</cell><cell>0.5883</cell></row><row><cell></cell><cell></cell><cell>ASH</cell><cell>0.6307</cell><cell>0.6363</cell><cell cols="2">0.6371</cell><cell></cell><cell cols="4">0.6387 0.6452</cell><cell>0.6651</cell></row><row><cell></cell><cell>0.68</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.66</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.65</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.64</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Precision</cell><cell>0.6 0.62 0.58</cell><cell cols="2">ASH SDH CCA-ITQ KSH</cell><cell></cell><cell>Precision</cell><cell>0.55 0.5 0.45</cell><cell></cell><cell cols="2">ASH SDH CCA-ITQ KSH</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.56</cell><cell>FastH</cell><cell></cell><cell></cell><cell></cell><cell>0.4</cell><cell></cell><cell>FastH</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>MLH</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>MLH</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.54</cell><cell>500</cell><cell>1000</cell><cell>1500</cell><cell>2000</cell><cell>0.35</cell><cell>0</cell><cell>0.2</cell><cell></cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell cols="3">Number of retrieved samples</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Recall</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">(a) Precision</cell><cell></cell><cell></cell><cell></cell><cell cols="5">(b) Precision-recall</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VII :</head><label>VII</label><figDesc>Comparison of the the computational efficiency (in consumed seconds) on SUN397. Both the training and testing time are compared with two different code lengths.</figDesc><table><row><cell>Method</cell><cell cols="2">Training time 64-bit 128-bit</cell><cell cols="2">Testing time 64-bit 128-bit</cell></row><row><cell>LSH</cell><cell>0.0846</cell><cell>0.1459</cell><cell>3.136e-6</cell><cell>3.629e-6</cell></row><row><cell>ALSH</cell><cell>0.5460</cell><cell>0.5976</cell><cell>1.296e-5</cell><cell>1.486e-5</cell></row><row><cell>SH</cell><cell>2.377</cell><cell>5.223</cell><cell>2.750e-5</cell><cell>1.060e-4</cell></row><row><cell>IsoHash</cell><cell>1.825</cell><cell>2.311</cell><cell>3.664e-6</cell><cell>6.335e-6</cell></row><row><cell>ITQ</cell><cell>3.326</cell><cell>5.296</cell><cell>3.527e-6</cell><cell>6.409e-6</cell></row><row><cell>AGH</cell><cell>0.623</cell><cell>0.656</cell><cell>1.905e-05</cell><cell>1.925e-05</cell></row><row><cell>IMH</cell><cell>2.427</cell><cell>2.964</cell><cell>2.402e-05</cell><cell>2.468e-05</cell></row><row><cell>InnerKSH</cell><cell>1933.1</cell><cell>4259.1</cell><cell>5.533e-5</cell><cell>6.1706e-5</cell></row><row><cell>AIBC-Q</cell><cell>53.29</cell><cell>173.9</cell><cell>3.179e-6</cell><cell>4.240e-6</cell></row><row><cell>AIBC-L</cell><cell>15.19</cell><cell>15.61</cell><cell>3.272e-6</cell><cell>3.853e-6</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Note that we use (1,-1) bits for mathematical derivations, and use (1,0) bits for implementations of all referred binary coding and hashing algorithms.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Face description with local binary patterns: Application to face recognition</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ahonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hadid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2037" to="2041" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Nus-wide: A real-world web image database from national university of singapore</title>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-T</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM Conf. on Image and Video Retrieval</title>
		<meeting>of ACM Conf. on Image and Video Retrieval</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Locality-sensitive hashing scheme based on p-stable distributions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Datar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Immorlica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Indyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Mirrokni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ISCG</title>
		<meeting>ISCG</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Asymmetric distance estimation with sketches for similarity search in high-dimensional spaces</title>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Charikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Conf. Inf. Ret</title>
		<meeting>ACM Conf. Inf. Ret</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="123" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep hashing for compact binary codes learning</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">Erin</forename><surname>Liong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Moulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2475" to="2483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Similarity search in high dimensions via hashing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gionis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Indyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB</title>
		<meeting>VLDB</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning binary codes for high-dimensional data using bilinear projections</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Rowley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Iterative quantization: A procrustean approach to learning binary codes for large-scale image retrieval</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gordo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2916" to="2929" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multi-scale orderless pooling of deep convolutional activation features</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comp. Vis</title>
		<meeting>Eur. Conf. Comp. Vis</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="392" to="407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Random maximum margin hashing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Buisson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Isotropic hashing</title>
		<author>
			<persName><forename type="first">W</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning to hash with binary reconstructive embeddings</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Kernelized locality-sensitive hashing for scalable image search</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fast similarity search for learned metrics</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2143" to="2157" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Simultaneous feature learning and hash coding with deep neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3270" to="3278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Adaptive binary quantization for fast nearest neighbor search</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECAI</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="64" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fast supervised hashing with decision trees for high-dimensional data</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hengel</surname></persName>
		</author>
		<author>
			<persName><surname>Suter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multiview alignment hashing for efficient image search</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Proc</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="956" to="966" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Projection bank: From high-dimensional data to medium-length binary codes</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2821" to="2829" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Discrete graph hashing</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Supervised hashing with kernels</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-G</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Hashing with graphs</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Mach. Learn</title>
		<meeting>Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Compact hyperplane hashing with bilinear functions</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Mach. Learn</title>
		<meeting>Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Query-adaptive reciprocal hash tables for nearest neighbor search</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Proc</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="907" to="919" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Structure sensitive hashing with adaptive product quantization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE trans. Cybernetics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2252" to="2264" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multiple feature kernel hashing for largescale visual search</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="748" to="757" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Asymmetric cyclical hashing for large scale image retrieval</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P K</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1225" to="1235" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On symmetric and asymmetric lshs for inner product search</title>
		<author>
			<persName><forename type="first">B</forename><surname>Neyshabur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Mach. Learn</title>
		<meeting>Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1926" to="1934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The power of asymmetry in binary hashing</title>
		<author>
			<persName><forename type="first">B</forename><surname>Neyshabur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Makarychev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yadollahpour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2823" to="2831" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Minimal loss hashing for compact binary codes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Mach. Learn</title>
		<meeting>Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Locality-sensitive binary codes from shift-invariant kernels</title>
		<author>
			<persName><forename type="first">M</forename><surname>Raginsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning binary codes for maximum inner product search</title>
		<author>
			<persName><forename type="first">F</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Tao</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2015-12">December 2015</date>
			<biblScope unit="page" from="4148" to="4156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Supervised discrete hashing</title>
		<author>
			<persName><forename type="first">F</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="37" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Inductive hashing on manifolds</title>
		<author>
			<persName><forename type="first">F</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hengel</surname></persName>
		</author>
		<author>
			<persName><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Hashing on nonlinear manifolds</title>
		<author>
			<persName><forename type="first">F</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den Hengel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Proc</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1839" to="1851" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A fast optimization method for general binary code learning</title>
		<author>
			<persName><forename type="first">F</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5610" to="5621" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Asymmetric lsh (ALSH) for sublinear time maximum inner product search (MIPS)</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2321" to="2329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Optimized graph learning using partial tags and multiple features for image and video annotation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4999" to="5011" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Supervised hashing with pseudo labels for scalable multimedia retrieval</title>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="827" to="830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A distance-computation-free search scheme for binary code databases</title>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="484" to="495" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Effective multiple feature hashing for large-scale near-duplicate video retrieval</title>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<date type="published" when="1997">1997 -2008, 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Inter-media hashing for large-scale retrieval from heterogeneous data sources</title>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Semi-supervised hashing for large scale search</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2393" to="2406" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning hash codes with listwise supervision</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-G</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ji</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.2927</idno>
		<title level="m">Hashing for similarity search: A survey</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Multidimensional spectral hashing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comp. Vis</title>
		<meeting>Eur. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Spectral hashing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Face recognition in unconstrained videos with matched background similarity</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hassner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Maoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="529" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Sparse multi-modal hashing</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="427" to="439" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Sun database: Large-scale scene recognition from abbey to zoo</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Ehinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="3485" to="3492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Zero-shot hashing via transferring supervised knowledge</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1286" to="1295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Exploiting web images for semantic video indexing via robust sample-specific loss</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-J</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1677" to="1689" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Visual coding in a semantic hierarchy</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="59" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Circulant binary embedding</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Mach. Learn</title>
		<meeting>Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="946" to="954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Discrete collaborative filtering</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="325" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Play and rewind: Optimizing binary representations of videos by self-supervised temporal hashing</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="781" to="790" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
