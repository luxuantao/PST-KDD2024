<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Logistics Institute</orgName>
								<orgName type="laboratory">Liaoning Key Laboratory of Manufacturing Systems and Logistics</orgName>
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<postCode>110819</postCode>
									<settlement>Shenyang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B7B1BDA106CAFEA6D758C4B7917107DE</idno>
					<idno type="DOI">10.1109/TEVC.2012.2185702</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Hybrid Multiobjective Evolutionary Algorithm for Multiobjective Optimization Problems</head><p>Lixin Tang, Member, IEEE, and Xianpeng Wang Abstract-Recently, the hybridization between evolutionary algorithms and other metaheuristics has shown very good performances in many kinds of multiobjective optimization problems (MOPs), and thus has attracted considerable attentions from both academic and industrial communities. In this paper, we propose a novel hybrid multiobjective evolutionary algorithm (HMOEA) for real-valued MOPs by incorporating the concepts of personal best and global best in particle swarm optimization and multiple crossover operators to update the population. One major feature of the HMOEA is that each solution in the population maintains a nondominated archive of personal best and the update of each solution is in fact the exploration of the region between a selected personal best and a selected global best from the external archive. Before the exploration, a selfadaptive selection mechanism is developed to determine an appropriate crossover operator from several candidates so as to improve the robustness of the HMOEA for different instances of MOPs. Besides the selection of global best from the external archive, the quality of the external archive is also considered in the HMOEA through a propagating mechanism. Computational study on the biobjective and three-objective benchmark problems shows that the HMOEA is competitive or superior to previous multiobjective algorithms in the literature. Index Terms-Evolutionary algorithm, multiobjective optimization, multiple crossover operators with selfadaptive selection strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>I N MANY OPTIMIZATION problems in science and engineering, it is often necessary to optimize multiple objectives that are generally conflicting with each other. Since the pioneering attempt of Schaffer <ref type="bibr" target="#b0">[1]</ref> to solve multiobjective optimization problems, many kinds of multiobjective evolutionary algorithms (MOEAs), ranging from traditional evolutionary algorithms to newly developed techniques, have been proposed and widely used in different applications <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>. Based on the adopted type of selection mechanism, these MOEAs can be classified into the following three categories: aggregating function approaches, population-based approaches, and Pareto-based approaches <ref type="bibr" target="#b3">[4]</ref>. The aggregating function approach combines multiple objectives into a scalar objective via an aggregating function <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>. By repeating the evolution process for a given number of runs with different settings of the aggregating function, the whole tradeoff surface can be obtained. However, the main difficulty of this approach is how to determine appropriate weight for each objective. The population-based approaches treat multiple objectives separately during the evolution by dividing the population into several subpopulations and letting each subpopulation treat only one objective. The main disadvantage of this approach is that it can only manage to find certain extreme solutions along the Pareto tradeoffs <ref type="bibr" target="#b0">[1]</ref>. Most MOEAs belong to the Pareto-based approaches, which incorporate the Pareto optimality into the selection process. The representative methods of this category are the niched Pareto genetic algorithm <ref type="bibr" target="#b6">[7]</ref>, the nondominated sorting genetic algorithm (NSGA) <ref type="bibr" target="#b7">[8]</ref> and its improved version NSGA-II <ref type="bibr" target="#b8">[9]</ref>, the Pareto archive evolutionary strategy <ref type="bibr" target="#b9">[10]</ref>, the microGA <ref type="bibr" target="#b10">[11]</ref>, the strength Pareto evolutionary algorithm (SPEA) <ref type="bibr" target="#b11">[12]</ref> and its improved version SPEA2 <ref type="bibr" target="#b12">[13]</ref>, the incrementing multiobjective evolutionary algorithm (MOEA) <ref type="bibr" target="#b13">[14]</ref>, and the MOEA based on decomposition <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>.</p><p>Besides the traditional MOEAs, some other evolutionary metaheuristics have also been widely used for MOPs, such as scatter search (SS) <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, particle swarm optimization <ref type="bibr" target="#b18">[19 ]</ref>- <ref type="bibr" target="#b28">[29]</ref>, and differential evolution (DE) <ref type="bibr" target="#b29">[30 ]</ref>- <ref type="bibr" target="#b31">[32]</ref>. In recent years, a new trend of developing hybrid MOEAs by combining different concepts or components of more than one MOEA or multiobjective metaheuristic or other simple heuristics has appeared. Proper combination of different MOEAs or metaheuristics may further enhance the effectiveness of the solution space search by adopting the advantages of each MOEA or metaheuristic, and consequently may overcome the inherent limitations of single MOEA or metaheuristic. Molina et al. <ref type="bibr" target="#b32">[33]</ref> proposed a scatter tabu search procedure for non-linear multiobjective optimization by incorporating the tabu search into scatter search to generate the initial population and improve the new trial solutions generated from the reference set. Nebro et al. <ref type="bibr" target="#b33">[34]</ref> presented an archive-based hybrid scatter search (AbYSS) for MOPs, which follows the scatter search but uses mutation and crossover operators from evolutionary algorithms (EAs). In fact, the AbYSS is no longer a multiobjective SS, but a hybridization of SS with randomized operators typically used in EAs. Computational results on benchmark instances of MOPs showed that the AbYSS is very competitive with or superior to the state-of-the-art MOEAs, such as NSGA-II and SPEA2. Soliman et al. <ref type="bibr" target="#b34">[35]</ref> combined ideas from coevolution and local search into multiobjective DE to guide the search process toward the Pareto optimal set, and thus developed a memetic coevolutionary multiobjective DE algorithm for MOPs.</p><p>Due to the high convergence speed and ease of implementation, PSO has often been used to construct hybrid MOEAs by many researchers. Li <ref type="bibr" target="#b35">[36]</ref> incorporated the main mechanisms of NSGA-II into PSO, and developed a hybrid PSO named the nondominated sorting PSO (NSPSO). Like NSGA-II, the NSPSO uses the "combine-then-compare" method in each iteration to first combine the offspring of all particles in the swarm and their corresponding personal bests into a temporary population of ( is the population size) particles and then sort them into different nondomination levels. The particles selected from the front nondomination levels will be taken for the next iteration. The computational results reported by the author showed that the NSPSO is very competitive or even superior to NSGA-II for the ZDT series of test problems <ref type="bibr" target="#b36">[37 ]</ref>. Srinivasan and Seow <ref type="bibr" target="#b37">[38]</ref> presented the particle swarm inspired evolutionary algorithm (PS-EA) that is a hybrid MOEA between PSO and EA. In the PS-EA, the particle update mechanism in standard PSO is replaced by a selfupdating mechanism that uses a probability inheritance tree to update the position values of particles. Santana-Quintero et al. <ref type="bibr" target="#b38">[39]</ref> proposed a hybrid PSO with SS for MOPs. This algorithm is in fact a two-phase MOEA that first uses multiobjective PSO (MOPSO) to obtain the nondominated solutions and then uses SS to act as local search aiming to improve the spread of the nondominated solutions. Tsou et al. <ref type="bibr" target="#b39">[40]</ref> incorporated the local search and clustering mechanism into MOPSO so as to prevent premature convergence, speed up the search, and maintain good diversity of nondominated solutions. Liu et al. <ref type="bibr" target="#b40">[41]</ref> also incorporated the local search into MOPSO and proposed a multiobjective memetic algorithm, in which a new particle updating strategy is adopted based on the concept of fuzzy global-best to avoid premature convergence and maintain diversity. Wickramasinghe and Li <ref type="bibr" target="#b41">[42]</ref> constructed a hybrid MOPSO that makes use of DE to select global best solution (i.e.,</p><p>). In the selection process, this algorithm first randomly selects three different particles and then creates for each particle by using the DE operator on the three selected particles. Goh et al. <ref type="bibr" target="#b42">[43]</ref> extended the competitive-coevolutionary paradigm into PSO and proposed a competitive and cooperative coevolutionary MOPSO, in which the MOP is decomposed in search space and the decision variables are evolved by different subswarms. Since the th variable is assigned to the th subswarm, before evaluating a particle in a subswarm, the particle under evaluation must be combined with the representative of every other subswarm to form a complete solution. The computational results reported by the authors showed that this MOPSO is very competitive with existing state-of-the-art MOEAs. Elhossini et al. <ref type="bibr" target="#b43">[44]</ref> developed a modified MOPSO based on the strength Pareto approach originally used in EA, and then proposed three hybrid EA-PSO algorithms.</p><p>In the last decade, many kinds of crossover operators have been proposed for GA to solve continuous optimization problems, such as the blend crossover - <ref type="bibr" target="#b44">[45]</ref>, the simulated binary crossover (SBX) <ref type="bibr" target="#b45">[46]</ref>, the simplex crossover (SPX) <ref type="bibr" target="#b46">[47]</ref>, and the parent centric crossover (PCX) <ref type="bibr" target="#b48">[48]</ref>. In these four crossover operators, the -and SBX are performed on two solutions, while the other two are performed on multiple solutions. Since different crossover operators may have advantage on different kinds of optimization problems (e.g., the operator works well for separable functions but does not work well for non-separable functions <ref type="bibr" target="#b49">[49]</ref>), there is no report in the literature that one operator is always superior to others for all optimization problems, which conforms to the no-free-launch theorem <ref type="bibr" target="#b50">[50]</ref>. Therefore, it is reasonable to adopt multiple crossover operators so as to improve the robustness of EAs for different kinds of optimization problems. Saravanan and Fogel <ref type="bibr" target="#b51">[51]</ref> developed a multioperator evolutionary programming based on two operators for continuous function optimization. Yoon and Moon <ref type="bibr" target="#b52">[52]</ref> studied the synergy of multiple crossover operators, and the computational results reported by the authors showed that some crossover operators have strong synergy effects and the adoption of multiple operators gives the best performance.</p><p>Motivated by the successful hybrid strategies and multioperator application in previous research, in this paper we propose a hybrid MOEA (HMOEA) for real-valued MOPs based on the particle update mechanism of PSO and the multiple crossover operators used in EAs. However, different from previous hybrid strategies between PSO and EAs, the proposed HMOEA has the following features.</p><p>1) The update of solutions in the population makes use of the concepts of personal best and global best of PSO. Each solution in the HMOEA maintains a nondominated archive of personal best solutions it has found, and the algorithm uses crossover operators to explore the region between the personal best and the global best. That is, the offspring of a solution is generated from parents selected from the personal best of this solution and the nondominated solution in the external archive. 2) Since there is no crossover operator that is always superior to others for all MOPs, the HMOEA adopts multiple crossover operators and uses a selfadaptive selection mechanism to select an appropriate crossover operator to be used in the update of a solution. Such a strategy can help to improve the robustness of the HMOEA for different kinds of MOPs.</p><p>3) The HMOEA considers the quality of the external archive by adopting a propagating mechanism to improve the nondominated solutions in the external archive found so far. This strategy can accelerate the convergence to the Pareto front and at the same time maintain the search diversity. The rest of this paper is organized as follows. Section II introduces the multiobjective optimization. The details of the proposed HMOEA are presented in Section III. Section IV reports and analyzes the computational results on benchmark problems, and compares the HMOEA with other state-of-the-art MOEAs. Finally, some conclusions of this paper are presented in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. BACKGROUND OF MULTIOBJECTIVE OPTIMIZATION</head><p>A multiobjective optimization problem (MOP) can be stated as follows:</p><p>(1)</p><formula xml:id="formula_0">(2) (3) (4)</formula><p>where is the vector consisting of real-valued objective functions to be minimized, are inequality constraints, are equality constraints, and is the vector of decision variables.</p><p>Let and be two decision variable vectors, is said to dominate (denoted as ) if and only if for and where . A decision variable vector is said to be Pareto optimal if and only if there exists no in the decision space such that . The set of all Pareto optimal vectors is called the Pareto set (denoted as ), and correspondingly the set of all the Pareto optimal objective vectors is called the Pareto front (denoted as ),</p><p>which is defined as .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED HMOEA</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm Overview</head><p>As described in Section I, the main objective of this paper is to develop a hybrid MOEA that has a good and robust performance for different kinds of MOPs. To reach this objective, we have carried out considerable experiments on the hybridization strategies of different MOEAs. In the computational experiment, two important observations are obtained. The first observation is that traditional MOEAs generally use a single crossover operator (mostly the SBX operator in <ref type="bibr" target="#b45">[46]</ref>), which makes the MOEAs more suitable for a certain kind of MOPs but less competitive for other kinds of MOPs. The other observation is that most MOEAs focus on the selection of the (or guiding solution) from the external archive (denoted as EXA) but pay little attention to the quality of solutions in the EXA, which makes the MOEAs have poor search performance during the initial evolution process. For example, Goh et al. <ref type="bibr" target="#b42">[43]</ref> reported that the MOPSO in <ref type="bibr" target="#b20">[21]</ref> shows a poor performance for the ZDT4 problem of <ref type="bibr" target="#b36">[37]</ref>. During the experiments of the MOPSO, we found that in the initial iterations the EXA contains very few nondominated solutions and these solutions are very close to each other. That is, the poor quality of the EXA may cause the MOPSO to converge quickly to local optimal regions and cannot get out of it, even if a good selection strategy of is used. Therefore, based on the preliminary experiments we develop three key strategies to improve the proposed HMOEA: 1) the multiple crossover operator with a selfadaptive selection mechanism to make the proposed HMOEA more suitable for different kinds of MOPs; 2) the EXA propagating mechanism to improve the quality of the so as to avoid premature convergence; and 3) the maintenance of the best archive of an individual (denoted as ) in the population to further improve the diversity of new solutions in the next iteration. In the proposed HMOEA, the first strategy is used in both the EXA propagating mechanism and the update of solutions in the population to generate new solutions. In addition, the maximum size of each is set to be the same one, i.e., . The procedure of the proposed HMOEA is presented in Algorithm 1, and the details of all the bolded and italic mechanisms in this algorithm are elaborated in Sections IV and V. 1. Set the termination criterion, and initialize the values of parameters such as the size of the population , the maximum size of , the mutation probability, and the parameter values of crossover operators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Set</head><p>and to be the empty set.</p><p>3. Generate the initial population using the Population-generation-method () in Section III-B. <ref type="bibr" target="#b3">4</ref>. Evaluate each solution in the population, and store each particle in .</p><p>5. Store the nondominated solutions in the population in .</p><p>while (the termination criterion is not reached) do 1. Improve the using the EXA-propagating-mechanism () described in Section III-D.</p><p>2. Update the population using the Solution-update-mechanism () in Section III-E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Mutate the population using the Solution-mutation () in</head><p>Section III-F. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>End for</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>End while</head><p>Report the obtained nondominated solutions in the .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>End</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Population Generation Method</head><p>To obtain an initial population with good diversity, we developed a diversification method, which follows the main ideas of <ref type="bibr" target="#b33">[34]</ref> and <ref type="bibr" target="#b53">[53]</ref>. Let denote the th solution in the population ( is the index of solution in the population while is the index of the decision variable in each solution), then the procedure of this method can be given as follows.</p><p>Step 1: Step 1) According to Nebro et al. <ref type="bibr" target="#b33">[34]</ref>, divide the range of each variable into subranges with equal size (e.g.,</p><p>). Set . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Multiple Crossover Operators and the Selfadaptive Selection Mechanism</head><p>As mentioned before, we use multiple crossover operators in our HMOEA, which is inspired by the ideas of <ref type="bibr" target="#b51">[51]</ref> and <ref type="bibr" target="#b52">[52]</ref>. In addition to the four crossover operators mentioned above, the DE operator used in <ref type="bibr" target="#b15">[16]</ref> is also incorporated in our algorithm. These operators are described in Appendix A. To select the operators whose performances are more suitable for a given MOP, a selfadaptive selection mechanism is developed. To simplify the calculation of the selection probability of each operator, we memorize the type of operator that is adopted by each solution in the population. After the initial population is generated, we assign each operator type to /5 solutions in the population so that each operator has an equal selection probability. During the evolution process, when an operator is selected to generate a new solution, the type (or index) of this operator will be assigned to the new solution. Let pi denote the selection probability of each operator (in the following of this paper we use the index for -, for , for , for , and for DE), and the selfadaptive selection mechanism can be described as follows.</p><p>Step 1: Step 1) If the EXA is updated, then calculate the selection probability of each operator as , where is the number of solutions in the EXA whose assigned operator index is and denotes the current size of the EXA.</p><p>Step 2:</p><p>Step 2) Use the roulette-wheel method to select an operator. This strategy is very simple and follows the idea that the suitability of an operator for the current MOP is proportional to the number of nondominated solutions whose assigned operator index are in the EXA. To avoid the situation that all solutions in the EXA have the same assigned operator, each operator has a minimum selection probability . That is, after the calculation of the selection probability of each operator, if , then we set and , where is the selection probability of the operator with the overwhelming superiority. Note that in our algorithm, if the EXA is not updated, then the calculation of in Step 1 will be ignored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. EXA Propagating Mechanism</head><p>As mentioned in Section III-A, the EXA propagating mechanism is developed to improve the quality of the EXA and the multiple crossover operators are also adopted in this mechanism. To ensure the diversity of the EXA, the crowding distance used in the NSGA-II algorithm <ref type="bibr" target="#b8">[9]</ref> is adopted to calculate the selection probability of each crossover operator. According to <ref type="bibr" target="#b8">[9]</ref>, the crowding distance of a solution is the average side length of the cuboid defined by its adjacent solutions before and after it in the objective space. Let denote the maximum size of the EXA, and then the propagating mechanism can be described as follows.</p><p>Step </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Population Update Mechanism</head><p>The generation of the offspring solution consists of three steps: select an operator based on the selfadaptive selection mechanism, select parents according to the selected operator, and generate the new offspring solution. The new population in the next iteration is made up of these new offspring solutions.</p><p>On the basis of the computational results, we prefer to take the following strategy in the selection of parents.</p><p>1) For the -and SBX operators, the parents consist of a randomly selected personal best and a randomly selected solution from the EXA.</p><p>2) For the other three operators, the parents consist of a randomly selected personal best and two randomly selected solutions from the EXA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Solution Mutation</head><p>To improve the search diversity, the mutation operator is used in our HMOEA. For each dimension of each solution in the population, we first generate a random number rnd in . If (the mutation probability), then the polynomial mutation operator in <ref type="bibr" target="#b44">[45 ]</ref> is used to mutate this dimension. As suggested in <ref type="bibr" target="#b8">[9]</ref> and <ref type="bibr" target="#b44">[45]</ref>, is set to be ( is the number of decision variables for a specific MOP).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. EXA Update Strategy</head><p>One major task of the MOEA requires that the solutions in the obtained EXA should be uniformly distributed along the Pareto front in the objective space. Therefore, as in <ref type="bibr" target="#b35">[36]</ref>, the crowding distance of NSGA-II in <ref type="bibr" target="#b8">[9]</ref> is adopted to maintain the diversity of the EXA.</p><p>Since the EXA has been initialized by the nondominated solutions in the population at the first iteration, for a given nondominated solution in the current population at iteration , the update procedure of the EXA can be described as follows.</p><p>Step </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Update Strategy</head><p>The of each solution is updated using the same update strategy of the EXA, except that in Step 3 we just randomly remove a solution from the if the size of the exceeds its limit, i.e.,</p><p>. We adopt such a strategy because the total crowding distance calculation of solutions in the best archive for each individual in the population will be very time consuming with comparison to the crowding distance calculation of solutions in the EXA. So this strategy can help to save computational efforts for the HMOEA to focus on the evolution search process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. Constraint Handling</head><p>Since MOPs may have constraints, the constraint-handling approach used in <ref type="bibr" target="#b8">[9]</ref> and <ref type="bibr" target="#b20">[21]</ref> is adopted to compare solutions for such MOPs. A solution is said to constrained-dominate solution , if any of the following conditions is satisfied.</p><p>1) Solution is feasible and solution is infeasible.</p><p>2) Solutions and are both feasible, and solution dominates solution . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL RESULT</head><p>This section starts with a description of the MO benchmark test problems in Section IV-A and the performance metrics in Section IV-B. Section IV-C describes the parameter setting in the proposed HMOEA. Finally, Section IV-D analyzes the performance of the proposed improvement strategies and then carries out the comparative studies between our HMOEA and the other state-of-the-art MOEAs. All the experiments are carried out on a personal computer with an Intel 2.83GHz CPU, 4GB memory and the Windows 7 operating system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Test Problems</head><p>We adopted 23 biobjective and three-objective benchmark problems chosen from the literature as the test problems, whose definitions are given in Appendix A and Appendix B of this paper.</p><p>1) The nine biobjective problems are as follows: ZDT1, ZDT2, ZDT3, ZDT4, and ZDT6 in <ref type="bibr" target="#b36">[37]</ref>, Kursawe in <ref type="bibr" target="#b54">[54]</ref>,</p><p>Deb2 in <ref type="bibr" target="#b55">[55]</ref>, Kita in <ref type="bibr" target="#b56">[56 ]</ref>, and Constr in <ref type="bibr" target="#b8">[9]</ref>. 2) The 14 three-objective problems are as follows: LZ09_F6 in <ref type="bibr" target="#b15">[16]</ref>, DTLZ family of scalable test problems in <ref type="bibr" target="#b58">[57]</ref>, Viennet, Viennet2, Viennet3, Viennet4 in <ref type="bibr" target="#b59">[58]</ref>, Binh4 in <ref type="bibr" target="#b60">[59]</ref>, and Tamaki in <ref type="bibr" target="#b61">[60]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Performance Metrics</head><p>Based on the assumption that the true Pareto front of a test problem is known, many kinds of performance metrics have been proposed and used by many researchers such as <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b42">[43]</ref>, and <ref type="bibr" target="#b62">[61]</ref>. In this paper, we use three metrics among them: the general distance (GD), the spread (SP), and the maximum spread (MS). The definitions of the three metrics are presented in Appendix B. Please note that all three metrics should be considered when evaluating an algorithm in the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Parameters Setting</head><p>The parameters to be determined in the proposed HMOEA can be classified into two categories: 1) the parameters of the five operators, such as the of -, the distribution index of SBX, the expansion rate of SPX, the , of PCX, and the control parameters CR and of DE; and 2) the parameters of the HMOEA, such as the population size , the maximum size of the Pareto set , the maximum size of the personal best archive , and the minimum selection probability of each operator . Since there are many parameters contained in the five operators, it is very hard to analyze the impacts of all parameters, as well as their interactions, on the performance of the HMOEA within the framework of the selfadaptive selection scheme. In the experiment carried out in Section IV-D-I, we tested five kinds of HMOEA, each of which adopts only one of the five operators, and found that the suggested parameter settings in the literature can produce satisfactory results. Therefore, we adopt the suggested settings for the first kind of parameters. That is, for the -operator according to <ref type="bibr" target="#b38">[39]</ref> and <ref type="bibr" target="#b44">[45]</ref>, for the SBX operator according to <ref type="bibr" target="#b8">[9]</ref> and <ref type="bibr" target="#b45">[46]</ref>, for the SPX operator according to <ref type="bibr" target="#b46">[47]</ref>,</p><p>for the PCX operator according to <ref type="bibr" target="#b48">[48]</ref>, and for the DE operator according to <ref type="bibr" target="#b15">[16]</ref>.</p><p>For the second kind of parameters, we adopt the following parameter setting: , , , and , according to the computational results and the fact that most of the state-of-the-art MOEAs in the literature usually set to be 100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Efficiency of Each Crossover Operator and the Selfadaptive Selection Mechanism:</head><p>In this section, we derived five variations of the HMOEA by using only one crossover operator and compared their performances for the nine biobjective problems. In addition, the proposed HMOEA using all five crossover operators is also tested to analyze the efficiency of the selfadaptive selection mechanism. In this experiment, all algorithms stop after 25000 function evaluations have been computed. We made 100 independent runs for each problem, and as did in <ref type="bibr" target="#b33">[34]</ref> we collected the median and interquartile range (IRQ) of each problem as measures of location (or central tendency) and statistical dispersion. The test results are given in Table <ref type="table" target="#tab_1">I</ref>, in which the best result for each test problem has a gray colored background. If two algorithms have the same best , then the one with the smaller IRQ is better. In addition, we use the symbol " " in the last column to represent that the performance difference between the best and second best algorithms is significant with a confidence level of 95%; conversely, the symbol " " means that the difference is not significant. In the experiments of Section V of this paper, we also adopt these measures and symbols.</p><p>From Table <ref type="table" target="#tab_1">I</ref>, it is shown that the SPX operator has a better performance for the ZDT series of problems with comparison to the other four operators because it obtains better GD metric values and competitive SP and MS metric values. However, it loses the advantage over the others for the other problems. The -operator outperforms the other four operators for problems Kita and Constr, especially on the GD metric. The SBX operator is more suitable for problem Kursawe. It appears that the performances of the -and the SBX operator are relatively more stable than the other three. The PCX operator fails to obtain the best GD metric result for each test problem, and its performance is even worse on ZDT series of problems. Although it appears that the PCX operator produces better results for the SP metric, it can be seen that the obtained Pareto fronts in fact converge to a local area when considering the MS metric (Fig. <ref type="figure" target="#fig_0">1</ref> illustrates this for problem ZDT4). Though the DE operator only obtains the best GD metric for problem Deb2, its performance is better than the PCX operator. Therefore, it can be concluded that none of the five operators has a dominant performance for all test problems.</p><p>When these operators are combined by the selfadaptive selection mechanism, the results show that the proposed HMOEA obtains the best GD metric value for seven out of the nine test problems and with statistical confidence in six problems. This means that the selfadaptive selection mechanism can help to drive the obtained nondominated solutions closer to the optimal Pareto set than only one single operator. When considering the SP and MS metrics, the proposed HMOEA with the selfadaptive selection mechanism also shows a superior or competitive performance with comparison to the best one among the five operators. In addition, the results obtained by the proposed HMOEA with the selfadaptive selection mechanism are more stable, which means that the selfadaptive selection mechanism can help to improve the robustness of the HMOEA and make it applicable in different MOPs.</p><p>2) Performance Analysis of Each Improvement Strategy: As mentioned in Section I, the proposed HMOEA has three main improvement strategies: 1) the adoption of multiple crossover operators based on a selfadaptive selection scheme; 2) the propagating mechanism to improve the EXA; and 3) the new solution update strategy to use personal best and global best for improving search efficiency. In this section, the relative importance of each strategy is tested. If these three strategies are removed, the HMOEA can be reduced to a traditional MOEA, in which a new solution is generated through the SBX operator based on two parents randomly selected from the current population. When a new population is obtained, the EXA is then updated. In the experiment, we use to denote the obtained algorithm by incorporating improvement strategy into the MOEA. Similarly, the symbol is used to denote the resulting algorithm by adopting both strategies and so as to test their interactions on improving the MOEA. It should be noted that in the proposed HMOEA all the three strategies are combined with each other, e.g., the first strategy is combined in the other two. Therefore, we have to separate their combination during the test. When the first strategy is not used, only the SBX operator is used in the update of population and the propagation of the EXA. When the third strategy is not used, the parents used in each operator are just selected from the current population to generate new solutions in the next population. In the experiment of this section, the sizes of the population and the EXA are set to be 100, and the stopping criterion of 15000 function evaluations is adopted for all algorithms. The computational results of the GD, SP, and MS metrics for all test algorithms are given in Tables II -IV.  When comparing the contribution of each strategy, we can find that the single use of the multioperator strategy (i.e.,</p><p>) can only obtain better results of GD metric than the MOEA for nine test problems, but for the other 14 problems the MOEA is better. For the SP and MS metrics, the can obtain a better performance than the MOEA. The performance of the shows that the adoption of the multioperator strategy can help to improve the search diversity because different crossover operators have different search directions and thus the next population can have a good diversity. However, this strategy cannot guarantee a good convergence to the Pareto front because the search directions of operators are too disperse and many of them may be opposite to the Pareto front in the objective space. So the guidance on the search direction of operators should be incorporated so as to improve the search convergence to the Pareto front. For the single use of the EXA propagation mechanism (i.e.,</p><p>), it appears that this strategy can obtain better results of GD and MS metrics than the MOEA for most problems. This shows that this strategy can help to improve the quality of the EXA. However, the cannot obtain an overwhelming advantage over the other algorithms such as the because this strategy only focuses on the improvement of non-dominated solutions but these high-quality solutions are not used in the update of solutions in the population. The adoption of the new solution update strategy (i.e.,</p><p>) can help to improve the performance of the MOEA, especially on the GD metric and the MS metric. This strategy helps to improve the search efficiency because it uses the information of the nondominated solutions in the EXA and the search history of each solution, which can guarantee the quality of selected parents used in the SBX operator (please note that only the SBX operator is used in the because the multioperator strategy is not adopted).</p><p>Though the single use of each improvement strategy can help to improve the performance of the original MOEA, their contributions are not the same. It appears that for the GD metric the EXA propagation strategy is better than the other two and the new solution update strategy is better than the multioperator strategy. For the SP metric, the multioperator strategy obtains better results. For the MS metric, the three strategies are competitive. Therefore, it can be concluded that the advantage of the multioperator strategy is the improvement in the search di- versity, and that the advantage of the EXA propagation strategy is the improved convergence of the obtained Pareto front. In addition, the new solution update strategy can obtain a balance between the diversity and the convergence of the obtained Pareto front.</p><p>When combining the improvement strategies, we can find that the performance of the MOEA and the algorithms can be further improved. The adoption of both the multioperator strategy and the EXA propagation strategy (i.e.,</p><p>) clearly obtains the best results, especially on the GD and MS metrics. The algorithm improves the GD and MS metrics for most test problems with comparison to and , and for the SP metric the algorithm is better than the while competitive with the . The major reason for the good performance of the algorithm is that the incorporation of the multioperator strategy helps to select appropriate crossover operators and thus strengthens the search efficiency and diversity of the EXA propagating mechanism. The combination of multioperator strategy and the new solution update strategy (i.e.,</p><p>) also shows a superior performance to the and , especially on the GD and MS metrics. The reason behind is that the uses the traditional solution update strategy, which only select random solutions from the population as the parents used in the crossover operators, while the makes full use of the high-quality solutions in the EXA and the search history of each solution in the population to update solutions. And with comparison to the , the multioperator strategy can help to further improve the search diversity. For the combination of the EXA propagation strategy and the new solution update strategy (i.e.,</p><p>), it appears that this combination does not obtain much improvement with comparison to the and the . Though the improved the GD metric for more than half of the test problems, the SP and MS metrics it obtained are inferior for many problems. The major reason for such a performance of the can be analyzed as follows. The quality of the EXA improved the propagating mechanism and subsequently the high-quality nondominated solutions are used in the new solution update strategy to guide the search direction. This can help to improve the search convergence and thus the obtained a relatively better performance on the GD metric (especially for the three-objective MOPs). However, the improved search convergence, to some extent, causes the to lose a good search diversity, which results in the inferior performance of the for the SP and MS metrics. Therefore, we can reach a conclusion that each improvement strategy has a positive effect and that the combination of these strategies can help to obtain much better results. The multioperator strategy can help to improve the search diversity and at the same time the selection of appropriate operators can also strengthen the search efficiency. The EXA propagating mechanism and the new solution update strategy have the advantage in improving the search convergence. In our HMOEA, the multioperator strategy is combined in the EXA propagating mechanism and the new solution update strategy, respectively. So such a combination can guarantee the good search diversity and convergence. Please note that the adoption of all the three strategies (i.e., the proposed HMOEA) can further improve the performance of the (see the results of the HMOEA in Tables VI -VIII.</p><p>3) Comparison Results Against Other Algorithms for Benchmark MOPs: In this section, the proposed HMOPSO algorithm is compared with other state-of-the-art algorithms such as NSGA-II in Deb et al. <ref type="bibr" target="#b8">[9]</ref>, SPEA2 in Zitzler et al. <ref type="bibr" target="#b12">[13]</ref>, AbYSS in Nebro et al. <ref type="bibr" target="#b33">[34]</ref>, and SMPSO in Nebro et al. <ref type="bibr" target="#b63">[62]</ref>. The source codes of the four rival algorithms are implemented in Java using jMetal, a framework that can be downloaded from http://jmetal.sourceforge.net/. In all experiments, we made use of the suggested parameter setting of the original authors for each algorithm, and for each problem we executed 100 independent runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE II MEDIAN AND INTERQUARTILE RANGE OF THE GD METRIC FOR DIFFERENT STRATEGIES</head><p>To make a fair comparison, we adopt two kinds of stopping criteria: the function evaluations and the running time. In the experiment with the same function evaluations, we first executed all algorithms with the stopping criterion of 15000 function evaluations, and then repeated them with the stopping criterion of 25000 function evaluations so as to test whether their performance can be improved when more computational efforts are available. In the experiment with the same running time, all algorithms are executed with the stopping criterion of 0.5 s of running time. In addition, we tested the performance of the initial population generation method described in Section III-B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Results After Performing 15000 Function Evaluations:</head><p>The computational results of the GD, SP, and MS metrics for all test algorithms with the execution of 15000 function evaluations are given in Tables VI -VIII. Table <ref type="table" target="#tab_10">IX</ref> provides the sum of problems for which each algorithm obtains a significantly better performance.</p><p>Table VI reveals that the proposed HMOEA obtains the best values for the GD metric in 12 out of the 23 test MOPs, and with statistical confidence in nine cases. The AbYSS algorithm has a significantly better performance for 3 problems, the SMPSO for 2, and the SPEA2 for 1. The NSGA-II cannot obtain significantly better result for any one problem. More specifically, for the biobjective MOPs, it appears that SMPSO algorithm is more suitable for the ZDT series of MOPs; however, the performance differences between SMPSO and our HMOEA for the ZDT1 and ZDT2 are not statistically significant. But for the other biobjective MOPs such as Deb2, Kita, and Constr, HMOEA becomes superior to other competitive algorithms. For the three-objective MOPs, HMOEA shows a better performance in 8 out of the 14 test MOPs. It can also be observed that HMOEA is the only algorithm reporting values in the order of e-03 in problem Viennet, e-02 in problem LZ09_F6, and e-03 in problem Binh4. For problems such as ZDT1, ZDT2, ZDT4, Kursawe, DTLZ4, Viennet4, and Tamaki, HMOEA does not obtain the best values; however, its performances are relatively competitive with the algorithms reporting the best values.</p><p>On the basis of Table <ref type="table" target="#tab_5">VI</ref>, we can also observe that HMOEA outperforms AbYSS in 7 out of the 9 biobjective problems, and in 9 out of the 14 three-objective problems. For the biobjective problems, HMOEA is competitive with SMPSO, but for three-objective problems, HMOEA is superior. For most cases, HMOEA gives better results than NSGA-II and SPEA2. In addition, we wish to point out that none of the other algorithms AbYSS, SMPSO, NSGA-II, and SPEA2 shows a consistent and good performance for all MOPs. For example, though SMPSO results in better performance in ZDT series of MOPs, it fails in some problems such as Kita, Constr, Viennet4, LZ09_F6, Binh4, and Tamaki. AbYSS obtains good results in biobjective MOPs, but it fails to give good results in problems of DTLZ6, Viennet, and LZ09_F6. However, the performance of HMOEA is consistent and good for almost all MOPs except problem ZDT6. Therefore, with the help of multiple crossover operators and the selfadaptive selection mechanism, HMOEA shows a very robust performance for different MOPs.</p><p>From Tables VII and IX, it seems that SPEA2 outperforms the other algorithms in the SP metric, e.g., it obtains significantly better results for 11 problems. However, we can see from Tables VI and VIII that the Pareto fronts obtained by SPEA2 for these problems are far from the true Pareto fronts and the obtained nondominated solutions tend to converge to a local area. The converged Pareto front will surely help to reduce the average distance between adjacent solutions and consequently result in smaller SP values. For example, Fig. <ref type="figure" target="#fig_2">2</ref> shows the nondominated solutions with the best SP metric obtained by HMOEA and SPEA2 on problem Constr, whose true Pareto front of this problem consists of two parts. It can be observed that though SPEA2 produces the SP value of 0.515, most of the nondominated solutions obtained by it are on the left part; conversely, though HMOEA obtains the SP metric of 0.798, the nondominated solutions obtained by it are uniformly spread along the two parts. Since the distances measured in the right part are negligible with comparison to the left part, SPEA2 of course produces smaller SP metric. So, the SP metric sometimes may be misleading and we should also take into account the GD and MS metrics when evaluating the performance of an algorithm. Such a phenomenon also occurs for AbYSS in problem Viennet, and for SMPSO in problems Kita, DTLZ7, LZ09_F6, Binh4, and Tamaki. We note that for problems Binh4 and Tamaki, the Pareto fronts obtained by SMPSO are outside the limits of the true Pareto fronts and they in fact converge to one single solution. Based on the results shown in Table VIII, it can be observed that HMOEA succeeds in covering the true Pareto fronts for all MOPs.</p><p>To give a graphical overview of the behavior of these algorithms, we show the Pareto fronts obtained by each algorithm with the lowest GD values for problems ZDT3, Kita, DTLZ1, DTLZ6, Binh4 and DTLZ7 in Figs. <ref type="figure" target="#fig_5">3</ref><ref type="figure" target="#fig_10">4</ref><ref type="figure">5</ref><ref type="figure">6</ref><ref type="figure" target="#fig_12">7</ref><ref type="figure" target="#fig_13">8</ref>(note that in Fig. <ref type="figure" target="#fig_13">8</ref> the shown Pareto fronts consist of the best five Pareto fronts obtained by each algorithm). From these figures, we can observe that in ZDT3 and DTLZ1, HMOEA, SMPSO, and NSGA-II are competitive while SPEA2 cannot reach the true Pareto fronts. In problems Kita and Binh4, SMPSO fails to reach the true Pareto fronts (it is trapped in a local optimal point in Binh4) and HMOEA outperforms the others in the spread of the obtained Pareto fronts. In problems DTLZ6 and DTLZ7, HMOEA and SMPSO are the only two algorithms that can reach the true Pareto fronts and the quality of the Pareto fronts obtained by HMOEA is a little better than that obtained by SMPSO. In addition, the two algorithms clearly outperform the other three algorithms. Based on these figures, it can also be seen that though AbYSS is competitive with our HMOEA, the Pareto fronts obtained by it tend to converge to local areas (e.g., Figs. <ref type="figure" target="#fig_9">3</ref> and<ref type="figure">5</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) Results After Performing 25000 Function Evaluations:</head><p>In this section, we further run all the algorithms with the execution of 25000 function evaluations as the stopping criterion so as to analyze the performance of each algorithm when given more computational efforts. The experimental results are given in Tables X -XII, and the statistical results of the sum of problems for which each algorithm obtains significantly better results are presented in Table <ref type="table" target="#tab_12">XIII</ref>.</p><p>For the GD metric shown in Table <ref type="table" target="#tab_10">X</ref>, it appears that all of the algorithms get noticeable improvements in the biobjective MOPs when given another 10000 function evaluations. It can be observed that HMOEA further obtains the best values in ZDT4, Kursawe, DTLZ1, and DTLZ4. AbYSS loses its supe- riority in DTLZ4 and DTLZ5, but obtains significant improvement in DTLZ7. SMPSO obtains better performances in DTLZ3 and DTLZ5, but is not the best one in ZDT4 and DTLZ1. In addition, HMOEA gets improvements for the GD metric in all cases except DTLZ6, DTLZ7, Viennet2, Viennet4, LZ09_F6, and Tamaki. In these six problems, the GD metric obtained by HMOEA becomes worse. Such a phenomenon also occurs for the other algorithms, e.g., DTLZ4, DTLZ5, Viennet3, LZ09_F6, Binh4, and Tamaki for AbYSS. In general, it can be observed that the proposed HMOEA is also competitive or even outperform the other four algorithms for most MOPs.</p><p>Concerning the SP and MS metrics shown in Tables XI and XII, it appears that all algorithms obtain similar results to those reached when executing 15000 function evaluations. However, it should be noted that some algorithms obtain significant improvements for the MS metric, e.g., AbYSS in Viennet, and SPEA2 in ZDT series of problems.</p><p>On the basis of the results of experiments with 15000 and 25000 function evaluations, we can reach a general conclusion that the proposed HMOEA can obtain Pareto fronts that have similar diversity but are closer to the true Pareto fronts for most of the test MOPs than those obtained by the other algorithms. In addition, the major advantage of HMOEA over its rivals is that its performance is very robust for different MOPs.</p><p>6) Results of Performing 0.5 S of Running Time: Since different algorithms may have quite different levels of time complexity, in this section we perform all the algorithms with the stopping criterion of 0.5 s of running time using the 14 benchmark MOPs with three objectives. Due to the fact that our HMOEA is implemented in C++ and that an algorithm implemented in Java has a slower running speed than that implemented in C++, we download the C++ source codes of the NSGA-II and AbYSS from http://neo.lcc.uma.es/software/deme/so as to make a fair comparison.</p><p>The comparison results are presented in Tables XIV and XV, and the statistical results of the sum of problems for which each algorithm obtains significantly better results are presented in Table <ref type="table" target="#tab_13">XVI</ref>. From these results, it can be found that the proposed HMOEA still shows a superior or competitive performance with comparison to the NSGA-II and AbYSS. This is because during the evolution process the HMOEA can selfadaptively select appropriate crossover operators to generate high quality solutions and the EXA propagating mechanism will also continuously improve the quality of selected guiding solutions, which helps to accelerate the convergence to the true Pareto fronts.</p><p>7) Performance Analysis of Initial Population Generation Method: Since our HMOEA uses a diversification generation method to generate the initial population while its rivals such as the NSGA-II, SPEA-II, and SMPSO use a randomly generated initial population (note that the AbYSS also uses a similar diversification generation method), in this section we further test the proposed HMOEA with a random initial population (denoted as ) to check whether the diversification generation method has a significant impact on the performance of the HMOEA.</p><p>The results are given in Table <ref type="table" target="#tab_13">XVII</ref>, from which we can find that the diversification method can really improve the performance of the HMOEA. However, the performance difference between the HMOEA and the is not very significant and for the GD metric the can even obtain slightly better results for problems such as ZDT1, ZDT3, Constr, DTLZ4, and Binh4. The statistical analysis of this table is presented in Table <ref type="table" target="#tab_13">XVIII</ref>, which shows that the incorporation of the diversification generation method can obtain significantly better results for the GD metric, and for the other metrics the two algorithms are competitive.</p><p>The comparison results for the GD, SP, and MS metrics between the and the other state-of-the-art algorithms are presented in Tables XIX -XXI, and the statistical results of the sum of problems for which each algorithm obtains significantly better results are presented in Table <ref type="table" target="#tab_17">XXII</ref>. From these results, it appears that is still competitive with the other algorithms. Although the SPEA2 obtains significantly better results on 11 problems for the SP metric, on the basis of the results of the MS metric we can see that for many of these 11 problems (especially the ZDT series) the Pareto fronts obtained by the SPEA2 tend to converge to local optimum areas. The Pareto fronts obtained by the AbYSS on problems DTLZ7 and Viennet also converged to local optimum areas, and the same phenomenon occurs for the SMPSO on problem Kita.</p><p>8) More Discussion: Based on the computational results shown in the above sections, it can be found that the proposed HMOEA shows a superior or competitive performance with comparison to the other state-of-the-art MOEAs. The major reasons behind this can be analyzed as follows.</p><p>1) The HMOEA integrates the advantages of different crossover operators through the selfadaptive selection mechanism that dynamically selects appropriate operators for a MOP under consideration while its rivals (i.e., NSGA-II, AbYSS, and SPEA2) only use the SBX operator to generate new offspring solutions during the evolution process. This could be one of the major reasons why the HMOEA shows a robust performance. For the SBX operator, although it has shown excellent performance for many kinds of MOPs, it may cause the population to lose diversity, particularly at the early stage of the search, and often generate inferior solutions when applied to MOPs with complicated Pareto optimal points <ref type="bibr" target="#b15">[16 ]</ref>. In contrast, though the other operators cannot provide competitive performance for most MOPs compared to the SBX operator, they have particular advantages on special problems, e.g., -operator works very well for separable functions <ref type="bibr" target="#b50">[50]</ref> while SPX operator is more suitable for functions having multimodality <ref type="bibr" target="#b46">[47]</ref>. This is our major motivation of developing the mechanism of adopting multiple crossover operators, whose advantage is illustrated by the results of problem LZ09_F6 with complicated Pareto optimal points. Moreover, the adoption of more suitable crossover operator also helps to accelerate the convergence speed of the HMOEA.</p><p>2) The EXA propagating mechanism can guarantee a good balance between exploration and exploitation, which is very critical for MOPs with particular requirements on the convergence speed and diversity. First, this mechanism is similar to a kind of local search that is often used in single objective optimization, which helps to improve the quality of nondominated solutions in the EXA and consequently accelerate the convergence speed. This is illustrated by the results of problem ZDTL6 shown in Fig. <ref type="figure">6</ref>. Within the same function evaluations, the HMOEA can obtain an approximation set that is very close to the Pareto front of problem ZDTL6, while the lack of convergence to the Pareto front causes the other MOEAs (AbYSS, NSGA-II, and SPEA2) to find a dominated surface as the obtained front, though the Pareto front is a curve. Second, this mechanism can help to avoid the premature convergence, particularly at the early stage of the search process, which in turn helps the HMOEA to keep good diversity. This is illustrated by the results of several problems. More specifically, for problem Binh4 (Fig. <ref type="figure" target="#fig_13">8</ref>) the HMOEA succeeds in closely covering the Pareto fronts and maintaining good diversity, whereas the SMPSO algorithm is trapped in local optimal areas or point; for problems ZDT3 (Fig. <ref type="figure" target="#fig_5">3</ref>), DTLZ1 (Fig. <ref type="figure">5</ref>), and DTLZ7 (Fig. <ref type="figure" target="#fig_13">8</ref>), the HMOEA also shows a better performance in keeping the diversity of the EXA than the AbYSS. Besides the above two mechanisms that help to improve the HMOEA's performance, the solution update mechanism could be another important reason. This mechanism explores the region between a selected personal best and a selected global best from the EXA, which can increase the probability of finding better solutions and consequently help to accelerate the convergence speed.</p><p>In addition, we want to point out that the three mechanisms are connected with each other in our HMOEA, e.g., the adoption of multiple crossover operators is incorporated in the EXA propagating process and the solution update process. The three mechanisms as a whole can help the HMOEA to have a high convergence speed and at the same time keep good diversity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this paper, we presented a HMOEA by incorporating the concepts of personal best and global best of PSO to solve realvalued MOPs. The evolution process is carried out by generating new population of solutions through crossover operators that explore the region between the personal best selected from the personal best archive of each solution and the global best selected from the external archive. To make the proposed HMOEA more robust for different MOPs, five kinds of crossover operators are adopted based on the fact that one crossover operator may be efficient for a certain kind of MOPs but not for other kinds of MOPs. To determine the appropriate crossover operator to be used, we developed a selfadaptive selection mecha- nism based on the performance of each operator for the current MOP. In addition, we proposed a propagating mechanism to improve the quality and diversity of the external archive, taking into account that the external archive has a significant effect on guiding the search direction. The proposed HMOEA was evaluated on 23 benchmark MOPs with two and three objectives, and compared with four state-of-the-art MOEAs, i.e., AbYSS, SMPSO, NSGA-II, and SPEA2. The computational results reveal that under different stopping criteria the HMOEA outperforms the other algorithms for most of the testing MOPs according to the GD metric, and is competitive in the diversity according to the SP and MS metrics. Moreover, the computational results also show that the incorporation of the three main improvement strategies proposed in this paper can significantly improve the robustness of the basic MOEA for different MOPs while the other state-of-the-art MOEAs cannot guarantee a consistently good performance. Our future research will be devoted to the application of HMOEA in the complex multiobjective operation optimization of production process in process industries such as the iron and steel industry and the petrochemical industry.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A DESCRIPTION OF CROSSOVER OPERATORS</head><p>The five crossover operators used in this paper are described as follows.</p><p>-: From two parents and , the -operator <ref type="bibr" target="#b44">[45]</ref> generates a new solution , where , , , , and is a constant.</p><p>SBX: SBX is a widely used crossover operator in practice. From two parents and , the SBX operator generates two offspring and in the following manner <ref type="bibr" target="#b45">[46]</ref>. SPX: SPX is a multiparent recombination operator for realcoded genetic algorithms <ref type="bibr" target="#b46">[47]</ref>. Suppose that the search space is and the solutions are -dimensional continuous vectors, and then the procedure of the SPX operator can be described as follows.</p><p>Step 1: Step 1) Choose parents, namely .</p><p>Step 2: Step 2) Determine the center of mass of these parents, i.e., .  where is the expansion rate, and</p><p>Step 5:</p><p>Step 5) Generate the offspring solution . PCX: PCX operator is also implemented on multiple parents. The procedure of this operator is given as follows <ref type="bibr" target="#b48">[48]</ref>.</p><p>Step 1: Step 1) Choose parents through an appropriate fitness selection procedure, namely , and then calculate the mean vector of these parents.</p><p>Step 2: Step 2) Randomly select a parent, namely , from these parents with equal probability, and then calculate the direction vector . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX B PERFORMANCE MEASURES</head><p>The three performance measures used in this paper are described as follows.</p><p>General Distance (GD): The GD metric is defined as where is the number of the nondominated solutions found so far, and is the Euclidean distance (measured in objective space) between each solution in the obtained Pareto front and the nearest member of the true Pareto optimal front. This metric indicates how far the obtained Pareto front is from the true Pareto optimal front. Spread: The spread (SP) metric is used to measure how evenly the obtained nondominated solutions are distributed along the true Pareto optimal front. According to Nebro et al. <ref type="bibr" target="#b32">[33]</ref>, the SP metric is defined as where is the Pareto solution set obtained by an algorithm, is the Pareto optimal solution set, are extreme solutions in (note that is the number of all  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Maximum Spread (MS):</head><p>The MS metric is proposed in <ref type="bibr" target="#b39">[40]</ref> and <ref type="bibr" target="#b41">[42]</ref> and it can show how well the true Pareto front is covered by the obtained Pareto front. MS is defined as where and are, respectively, the maximum and minimum of the th objective in the obtained Pareto front, and and are, respectively, the maximum and minimum of the th objective in the true Pareto optimal front. Note that if , then . Algorithms with larger MS values are desirable and MS=1 means that the true Pareto front is totally covered by the obtained Pareto front.             </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Algorithm 1</head><label>1</label><figDesc>Main procedure of HMOEA Begin: Initialization:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>4 . 6 .</head><label>46</label><figDesc>Evaluate each solution in the population. 5. for each solution i in the for each nondominated solution in the population Update the using the in Section III-G.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Step 2 :</head><label>2</label><figDesc>Step 2) If , stop; otherwise, set and initialize the selection probability of each subrange of the th variable to be . Step 3: Step 3) Select a subrange using the roulette-wheel method based on the selection probability of each subrange, and then randomly generate the value of within the selected subrange. Step 4: Step 4) Update the selection probability of each subrange by Step 5: Step 5) Set . If , set and go to Step 2; otherwise, go to Step 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>1 :</head><label>1</label><figDesc>Step 1) If the size of the external archive , go to Step 2; otherwise, go to Step 3. Step 2: Step 2) Randomly select a solution from the EXA and perturb this solution to generate a new solution. The perturbation procedure first randomly selects a dimension (e.g., ) of the single solution, and then sets the value of this dimension to be a number randomly generated within , where and are, respectively, the lowerbound and upperbound for the dimension . Repeat this step for times to generate new solutions. Then use the EXAupdate-strategy described in Section III-G to update the EXA with the new solutions, and stop. Step 3: Step 3) Calculate the crowding distance of each solution (denoted as ) in the EXA, and then determine the selection probability of each solution by . That is, the more crowded a solution is, the lower the probability it has to be selected to generate new solutions. Step 4: Step 4) Use the selfadaptive selection mechanism to select an operator . If (i.e., the selected operator is -or SBX), then randomly select two solutions from the EXA; otherwise randomly select three solutions from the EXA. The selection of solutions uses the roulette-wheel method based on the selection probability of each solution determined in Step 3. Step 5: Step 5) Perform the selected operator on the selected solutions to generate a new offspring solution. If the selected operator is SBX that can generate two offspring solutions, then we select the nondominated one (if they are nondominated to each other, then randomly select one). Step 6: Step 6) Repeat Step 4 and Step 5 for times to generate new solutions. Then use the EXAupdate-strategy described in Section III-G to update the EXA with the new solutions, and stop.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>1 :</head><label>1</label><figDesc>Step 1) If solution is dominated by one solution in the EXA, then discard this solution.Step 2: Step 2) If solution is not dominated by any solution in the EXA, store it in the EXA and then remove all solutions that are dominated by it from the EXA.Step 3: Step 3) If (the maximum size of the EXA), calculate the crowding distance of all solutions in the EXA, and then remove the most crowded solution. Repeat this step until .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>3 )</head><label>3</label><figDesc>Solutions and are both infeasible, but solution has a smaller overall constraint violation. The overall constraint violation of a solution is calculated as , where if and if .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Pareto fronts obtained by different HMOEAs on problem ZDT4.</figDesc><graphic coords="8,58.02,66.70,474.00,221.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Step 1 :</head><label>1</label><figDesc>Step 1) Randomly generate a uniform number . Step 2: Step 2) Generate a random number by where is the distribution index. Step 3: Step 3) Generate the two offspring by , .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Step 3 :</head><label>3</label><figDesc>Step 3) For the remaining parents, calculate their perpendicular distances to the line , and subsequently the average of all .Step 4: Step 4) The offspring solution is then generated according to the following equation:where and are zero-mean normally distributed variables with variances and , respectively; and ei are the orthogonal bases that span the subspace perpendicular to . DE: DE operator has shown very good performance in testing problems with complicated Pareto fronts<ref type="bibr" target="#b15">[16]</ref>. In implementation, this operator first chooses three parents through an appropriate fitness selection procedure, namely , , and , and then generates the offspring solution according to where CR and are control parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Pareto fronts obtained by different algorithms on problem ZDT3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Pareto fronts obtained by different algorithms on problem Kita.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 5 .Fig. 6 .</head><label>56</label><figDesc>Fig. 5. Pareto fronts obtained by different algorithms on problem DTLZ1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Pareto fronts obtained by different algorithms on problem Binh4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Pareto fronts obtained by different algorithms on problem DTLZ7 (union of the best five Pareto fronts).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="7,77.52,93.10,438.00,389.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="9,70.80,96.00,451.00,300.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="10,72.06,96.12,446.00,300.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="11,73.56,94.92,446.00,267.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I COMPARISON</head><label>I</label><figDesc>RESULTS FOR DIFFERENT CROSSOVER OPERATORS AND THE SELF-ADAPTIVE MECHANISMsum of problems for which each algorithm obtains significantly better results.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III MEDIAN</head><label>III</label><figDesc>AND INTERQUARTILE RANGE OF THE SP METRIC FOR DIFFERENT STRATEGIES</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV MEDIAN</head><label>IV</label><figDesc>AND INTERQUARTILE RANGE OF THE MS METRIC FOR DIFFERENT STRATEGIES</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE V STATISTICAL</head><label>V</label><figDesc>SUM OF PROBLEMS FOR WHICH EACH STRATEGY OBTAINS SIGNIFICANTLY BETTER RESULTS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE VI MEDIAN</head><label>VI</label><figDesc>AND INTERQUARTILE RANGE OF THE GD METRIC (15000 FUNCTION EVALUATIONS)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VII MEDIAN</head><label>VII</label><figDesc>AND INTERQUARTILE RANGE OF THE SP METRIC (15000 FUNCTION EVALUATIONS)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE VIII MEDIAN</head><label>VIII</label><figDesc>AND INTERQUARTILE RANGE OF THE MS METRIC (15000 FUNCTION EVALUATIONS) Fig. 2. Pareto fronts obtained by HMOEA and SPEA2 on problem Constr.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE X MEDIAN</head><label>X</label><figDesc>AND INTERQUARTILE RANGE OF THE GD METRIC (25000 FUNCTION EVALUATIONS)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>TABLE XII MEDIAN</head><label>XII</label><figDesc>AND INTERQUARTILE RANGE OF THE MS METRIC (25000 FUNCTION EVALUATIONS)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>TABLE XIII STATISTICAL</head><label>XIII</label><figDesc>SUM OF PROBLEMS FOR WHICH EACH STRATEGY OBTAINS SIGNIFICANTLY BETTER RESULTSTABLE XIV MEDIAN AND INTERQUARTILE RANGE OF THE GD METRIC (0.5 SECOND OF RUNNING TIME)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>TABLE XV MEDIAN</head><label>XV</label><figDesc>AND INTERQUARTILE RANGE OF THE SP AND MS METRICS (0.5 SECOND OF RUNNING TIME)TABLE XVI STATISTICAL SUM OF PROBLEMS FOR WHICH EACH STRATEGY OBTAINS SIGNIFICANTLY BETTER RESULTSTABLE XVII PERFORMANCE RESULTS OF THE DIVERSIFICATION GENERATION METHOD (15000 FUNCTION EVALUATION)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>TABLE XIX MEDIAN</head><label>XIX</label><figDesc>AND INTERQUARTILE RANGE OF THE GD METRIC FOR EACH ALGORITHM (15000 FUNCTION EVALUATIONS)TABLE XVIII STATISTICAL SUM OF PROBLEMS FOR WHICH EACH STRATEGY OBTAINS SIGNIFICANTLY BETTER RESULTS Xianpeng Wang received the B.S. degree in materials and control engineering from Shenyang University, Shenyang, China, and the Ph.D. degree in systems engineering from Northeastern University, Shenyang, in 2002 and 2007, respectively. He is currently an Associate Professor with the Liaoning Key Laboratory of Manufacturing System and Logistics, Logistics Institute, Northeastern University. His current research interests include multiobjective optimization, production scheduling, modeling and optimization in process industries, decision support systems, and intelligent optimization algorithms. He has published 15 papers in international journals.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>TABLE XX MEDIAN</head><label>XX</label><figDesc>AND INTERQUARTILE RANGE OF THE SP METRIC FOR EACH ALGORITHM (15000 FUNCTION EVALUATIONS)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>TABLE XXI MEDIAN</head><label>XXI</label><figDesc>AND INTERQUARTILE RANGE OF THE MS METRIC FOR EACH ALGORITHM (15000 FUNCTION EVALUATIONS)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>TABLE XXII STATISTICAL</head><label>XXII</label><figDesc>SUM OF PROBLEMS FOR WHICH EACH STRATEGY OBTAINS SIGNIFICANTLY BETTER RESULTSTABLE XXIII DEFINITION OF TEST PROBLEMS</figDesc><table /></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported by the Key Program of the National Natural Science Foundation of China, under Grant 71032004, and by the National Natural Science Foundation of China, under Grant 70902065.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multiple objective optimization with vector evaluated genetic algorithms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Schaffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st Int. Conf. Genet. Algorithms</title>
		<meeting>1st Int. Conf. Genet. Algorithms</meeting>
		<imprint>
			<date type="published" when="1985">1985</date>
			<biblScope unit="page" from="93" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Multiobjective Optimization Using Evolutionary Algorithms</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Wiley</publisher>
			<pubPlace>Chichester, U.K.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Evolutionary Algorithms for Solving Multiobjective Problems</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A V</forename><surname>Veldhuizen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Lamont</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Kluwer</publisher>
			<pubPlace>Norwell, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Applications of Multiobjective Evolutionary Algorithms</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Lamont</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>World Scientific Publishing</publisher>
			<pubPlace>Singapore</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Using genetic algorithms to solve a multiobjective underwater pollution containment problem</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Ritzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Eheart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ranjithan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Water Resources Res</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1589" to="1603" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Nonlinear Multiobjective Optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Miettinen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<pubPlace>Boston, MA, Kluwer</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A niched Pareto genetic algorithm for multiobjective optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nafpliotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st IEEE Conf</title>
		<meeting>1st IEEE Conf</meeting>
		<imprint>
			<date type="published" when="1994-06">Jun. 1994</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="82" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multiobjective optimization using nondominated sorting in genetic algorithms</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="221" to="248" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A fast and elitist multiobjective genetic algorithm: NSGA-II</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pratap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Meyarivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="182" to="197" />
			<date type="published" when="2002-04">Apr. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Approximating the nondominated front using the Pareto archived evolution strategy</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Corne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="149" to="172" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multiobjective optimization using a micro-genetic algorithm</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Pulido</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GECCO</title>
		<meeting>GECCO</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="274" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multiobjective evolutionary algorithms: A comparative case study and the strength Pareto approach</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="257" to="271" />
			<date type="published" when="1999-11">Nov. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">SPEA2: Improving the strength Pareto evolutionary algorithm</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laumanns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Eng. Networks Lab., Swiss Fed. Inst. Technol</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<pubPlace>Zurich, Switzerland</pubPlace>
		</imprint>
	</monogr>
	<note>Tech. Rep. 103</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Evolutionary algorithms with dynamic population size and local exploration for multiobjective optimization</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Khor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="565" to="588" />
			<date type="published" when="2001-12">Dec. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">MOEA/D: A multiobjective evolutionary algorithm based on decomposition</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="712" to="731" />
			<date type="published" when="2007-12">Dec. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multiobjective optimization problems with complicated Pareto set, MOEA/D and NSGA-II</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="284" to="302" />
			<date type="published" when="2009-04">Apr. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">MOSS multiobjective scatter search applied to nonlinear multiple criteria optimization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Beausoleil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Opl. Res</title>
		<imprint>
			<biblScope unit="volume">169</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="426" to="449" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multiobjective optimization of surface grinding operations using scatter search approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Adv. Manuf. Technol</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="475" to="480" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">MOPSO: A proposal for multiple objective particle swarm optimization</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Lechuga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Congr</title>
		<meeting>Congr</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="1051" to="1056" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Using clustering techniques to improve the performance of a multiobjective particle swarm optimizer</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Pulido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Genet</title>
		<meeting>Genet</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="1051" to="1056" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Handling multiple objectives with particle swarm optimization</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Pulido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Lechuga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="256" to="279" />
			<date type="published" when="2004-06">Jun. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multiobjective particle swarm optimizers: A survey of the state-of-the-art</title>
		<author>
			<persName><forename type="first">M</forename><surname>Reyes-Sierra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Intell. Res</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="287" to="308" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Particle swarm with extended memory for multiobjective optimization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Swarm Intell. Symp</title>
		<meeting>IEEE Swarm Intell. Symp</meeting>
		<imprint>
			<date type="published" when="2003-04">Apr. 2003</date>
			<biblScope unit="page" from="193" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Covering Pareto-optimal fronts by subswarms in multiobjective particle swarm optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mostaghim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Teich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Congr</title>
		<meeting>Congr</meeting>
		<imprint>
			<date type="published" when="2004-06">Jun. 2004</date>
			<biblScope unit="page" from="1404" to="1411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Autonomous agent response learning by a multi-species particle swarm optimization</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Tsui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Congr</title>
		<meeting>Congr</meeting>
		<imprint>
			<date type="published" when="2004-06">Jun. 2004</date>
			<biblScope unit="page" from="778" to="785" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">PSO-based multiobjective optimization with dynamic population size and adaptive local archives</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybern. B: Cybern</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1270" to="1293" />
			<date type="published" when="2008-10">Oct. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Dynamic multiple swarms in multiobjective particle swarm optimization</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Leong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybern. A: Syst. Man</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="890" to="911" />
			<date type="published" when="2009-07">Jul. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multiobjective particle swarm optimization with time variant inertia and acceleration coefficients</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Tripathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">177</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="5033" to="5049" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Adaptive multiobjective particle swarm optimization algorithm</title>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint>
			<date type="published" when="2007-09">Sep. 2007</date>
			<biblScope unit="page" from="2281" to="2288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Differential evolution with adaptive parameter setting for multiobjective optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zielinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Laur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint>
			<date type="published" when="2007-09">Sep. 2007</date>
			<biblScope unit="page" from="3585" to="3592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Differential evolution for multiobjective optimization with selfadaptation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cichon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Szlachcic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Kotowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 14th Int</title>
		<meeting>14th Int</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="165" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Constrained multiobjective optimization algorithm with diversity enhanced differential evolution</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint>
			<date type="published" when="2010-07">Jul. 2010</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">SSPMO: A scatter tabu search procedure for non-linear multiobjective optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laguna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Caballero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IN-FORMS J. Comput</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="100" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">AbYSS: Adapting scatter search to multiobjective optimization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Nebro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Luna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Alba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dorronsoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Durillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="439" to="457" />
			<date type="published" when="2008-08">Aug. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A memetic coevolutionary multiobjective differential evolution algorithm</title>
		<author>
			<persName><forename type="first">O</forename><surname>Soliman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Abbass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multiobjective Memetic Alg</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="369" to="388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A non-dominated sorting particle swarm optimizer for multiobjective optimization</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">D</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Genet</title>
		<meeting>Genet</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2723</biblScope>
			<biblScope unit="page" from="37" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Comparison of multiobjective evolutionary algorithms: Empirical results</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="173" to="195" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Particle swarm inspired evolutionary algorithm (PS-EA) for multiobjective optimization problem</title>
		<author>
			<persName><forename type="first">D</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Seow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Congr</title>
		<meeting>Congr</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="2292" to="2297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A multiobjective particle swarm optimizer hybridized with scatter search</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V</forename><surname>Santana-Quintero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ramirez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th Mexican Int. Conf. Artif. Intel.: MICAI Adv</title>
		<meeting>5th Mexican Int. Conf. Artif. Intel.: MICAI Adv</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">4293</biblScope>
			<biblScope unit="page" from="294" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">An improved particle swarm Pareto optimizer with local search and clustering</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Tsou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Kao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SEAL: 6th Int. Conf. Simul. Evol. Learning</title>
		<meeting>SEAL: 6th Int. Conf. Simul. Evol. Learning</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">4247</biblScope>
			<biblScope unit="page" from="400" to="407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A multiobjective memetic algorithm based on particle swarm optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybern. B: Cybern</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="42" to="50" />
			<date type="published" when="2007-02">Feb. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Choosing leaders for multiobjective PSO algorithms using differential evolution</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R M U K</forename><surname>Wickramasinghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SEAL 7th Int. Conf. Simul. Evol. Learning</title>
		<meeting>SEAL 7th Int. Conf. Simul. Evol. Learning</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">5361</biblScope>
			<biblScope unit="page" from="249" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A competitive and cooperative co-evolutionary approach to multiobjective particle swarm optimization algorithm design</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Chiam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Opl. Res</title>
		<imprint>
			<biblScope unit="volume">202</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="42" to="54" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Strength Pareto particle swarm optimization and hybrid EA-PSO for multiobjective optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Elhossini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Areibi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dony</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="127" to="156" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Real-coded genetic algorithms and interval-schemata</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Eshelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Schaffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Whitley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations of Genetic Algorithms 2</title>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="187" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Simulated binary crossover for continuous search space</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex Syst</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="148" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Multiparent recombination with simplex crossover in real coded genetic algorithms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tsutsui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yamamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Higuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GECCO</title>
		<meeting>GECCO</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="657" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m">TABLE XI MEDIAN AND INTERQUARTILE RANGE OF THE SP METRIC (25000 FUNCTION EVALUATIONS</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A computationally efficient evolutionary algorithm for real-parameter evolution</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="371" to="395" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">No free lunch theorems for optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Wolpert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Macready</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="67" to="82" />
			<date type="published" when="1997-04">Apr. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A crossover operator using independent component analysis for real-coded genetic algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint>
			<date type="published" when="2001-05">May 2001</date>
			<biblScope unit="page" from="643" to="649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Multi-operator evolutionary programming: A preliminary study on function optimization</title>
		<author>
			<persName><forename type="first">N</forename><surname>Saravanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Fogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Evol. Programming</title>
		<meeting>Int. Conf. Evol. Programming</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">1213</biblScope>
			<biblScope unit="page" from="213" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">An empirical study on the synergy of multiple crossover operators</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Moon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="212" to="223" />
			<date type="published" when="2002-04">Apr. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Scatter search</title>
		<author>
			<persName><forename type="first">F</forename><surname>Glover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laguna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Evolutionary Computing: Theory and Applications</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Tsutsui</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="519" to="537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A variant of evolution strategies for vector optimization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Kursawe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st Workshop PPSN</title>
		<meeting>1st Workshop PPSN</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">496</biblScope>
			<biblScope unit="page" from="193" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Multiobjective genetic algorithms: Problem difficulties and construction of test problem</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="205" to="230" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Multiobjective optimization by means of the thermodynamical genetic algorithm</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yabunoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nishikawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th</title>
		<meeting>4th</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Ppsn</forename><surname>Workshop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">1141</biblScope>
			<biblScope unit="page" from="504" to="512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Scalable test problems for evolutionary multiobjective optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laumanns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary Multiobjective Optimization. Theoretical Advances and Applications</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Abraham</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Jain</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Goldberg</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="105" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Multicriteria optimization using a genetic algorithm for determining a Pareto set</title>
		<author>
			<persName><forename type="first">R</forename><surname>Viennet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fontiex</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Marc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Syst. Sci</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="255" to="260" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Multiobjective evolution strategy with linear and nonlinear constraints</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Binh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ulrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 15th IMACS World Congr</title>
		<meeting>15th IMACS World Congr</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="357" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Multiobjective optimization by genetic algorithms: A review</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kobayashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd IEEE Conf</title>
		<meeting>3rd IEEE Conf</meeting>
		<imprint>
			<date type="published" when="1996-05">May 1996</date>
			<biblScope unit="page" from="517" to="522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Performance assessment of multiobjective optimizers: An analysis and review</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laumanns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">G</forename><surname>Fonseca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="117" to="132" />
			<date type="published" when="2003-04">Apr. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">SMPSO: A new PSO-based metaheuristic for multiobjective optimization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Nebro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Durillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Garca-Nieto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Luna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Alba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Symp</title>
		<meeting>IEEE Symp</meeting>
		<imprint>
			<date type="published" when="2009-04">Mar.-Apr. 2009</date>
			<biblScope unit="page" from="66" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">He has published a monograph and more than 70 papers in international journals. His current research interests include operations planning, production scheduling, logistics and supply chain management, and mathematical programming, combinational optimization, optimal control theory, and dynamic optimization. Dr. Tang has received the National Natural Science Foundation Award for Distinguished Young Scholars of China, the State Youth Science and Technology Award of China</title>
		<author>
			<persName><forename type="first">M</forename><surname>Eng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">degree in systems engineering, and the Ph.D. degree in control theory and application from Northeastern University</title>
		<meeting><address><addrLine>Shenyang, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988">1988. 1991. 1996</date>
		</imprint>
		<respStmt>
			<orgName>Northeastern University</orgName>
		</respStmt>
	</monogr>
	<note>respectively. Currently, he is a Chair Professor of the Cheung Kong Scholars Program of China, and the Director of both the Liaoning Key Laboratory of Manufacturing Systems and Logistics and the Logistics Institute. the Outstanding Young Faculty Award Program of the Ministry of Education, and the Fok Ying Tung Education-Foundation Reward</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
