<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FinRL-Meta: A Universe of Near-Real Market Environments for Data-Driven Deep Reinforcement Learning in Quantitative Finance</title>
				<funder ref="#_kWSun7T">
					<orgName type="full">National Natural Science Foundation of China</orgName>
					<orgName type="abbreviated">NNSFC</orgName>
				</funder>
				<funder ref="#_xpRHEgd">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-03-02">2 Mar 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xiao-Yang</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Columbia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jingyang</forename><surname>Rui</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">The University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiechao</forename><surname>Gao</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Virginia</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Liuqing</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Columbia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hongyang</forename><surname>Yang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhaoran</forename><surname>Wang</surname></persName>
							<email>zhaoranwang@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Columbia University</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Northwestern University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Christina</forename><forename type="middle">Dan</forename><surname>Wang</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jian</forename><surname>Guo</surname></persName>
							<email>guojian@idea.edu.cn</email>
						</author>
						<title level="a" type="main">FinRL-Meta: A Universe of Near-Real Market Environments for Data-Driven Deep Reinforcement Learning in Quantitative Finance</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-03-02">2 Mar 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2112.06753v2[q-fin.TR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep reinforcement learning (DRL) has shown huge potentials in building financial market simulators recently. However, due to the highly complex and dynamic nature of real-world markets, raw historical financial data often involve large noise and may not reflect the future of markets, degrading the fidelity of DRL-based market simulators. Moreover, the accuracy of DRL-based market simulators heavily relies on numerous and diverse DRL agents, which increases demand for a universe of market environments and imposes a challenge on simulation speed. In this paper, we present a FinRL-Meta framework that builds a universe of market environments for data-driven financial reinforcement learning. First, FinRL-Meta separates financial data processing from the design pipeline of DRL-based strategy and provides open-source data engineering tools for financial big data. Second, FinRL-Meta provides hundreds of market environments for various trading tasks. Third, FinRL-Meta enables multiprocessing simulation and training by exploiting thousands of GPU cores. Our codes are available online at https://github.com/AI4Finance-Foundation/FinRL-Meta.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In quantitative finance, market simulators play important roles in studying the complex market phenomena and investigating financial regulations <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b11">12]</ref>. Compared to traditional simulation models, deep reinforcement learning (DRL) has shown huge potentials in building financial market simulators through multi-agent systems <ref type="bibr" target="#b9">[10]</ref>. However, due to the high complexity of real-world markets, raw historical financial data involve significant noise and may not reflect the future of markets. This issue usually degrades the fidelity of DRL-based simulation. Moreover, in reality, there are innumerable participators that impact together on the market. To better simulate the market, numerous and diverse DRL agents are needed to represent those participators with different aims and strategies.</p><p>Recently, researchers have explored various applications of DRL in quantitative finance <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b12">13]</ref>. Lussange et al. <ref type="bibr" target="#b9">[10]</ref> have proposed a market simulation model using multi-agent reinforcement learning. Although it has shown the feasibility of DRL-based market simulation, only a few DRL agents are used. The potentials of DRL-based market simulators are not fully explored yet. The FinRL framework <ref type="bibr" target="#b8">[9]</ref> has proposed a DRL framework as a full pipeline of developing trading strategies and  is growing an open-source community AIFinannce that can contribute diverse DRL agents. However, it <ref type="bibr" target="#b8">[9]</ref> focuses on developing trading strategies instead of building market simulations.</p><p>In this paper, we develop a FinRL-Meta framework that is a universe of near real-market environments for data-driven financial reinforcement learning. First, we apply the DataOps paradigm <ref type="bibr" target="#b20">[21]</ref> to the data engineering pipeline, providing agility to agent deployment. We offer a unified and automated data processor for data accessing, data cleaning and feature engineering. Second, we build hundreds of near real-market DRL environments for various trading tasks such as high-frequency trading, cryptocurrencies trading, stock portfolio allocation, etc.. The environments are directly connected to our data processor. High-quality large datasets can be generated efficiently and encapsulated into our environments. Third, to accelerate the training process of DRL agents in large datasets, we utilize thousands of GPU cores to perform multiprocessing training.</p><p>2 Proposed FinRL-Meta Framework MDP Model for Trading Tasks: We model a trading task as a Markov Decision Process (MDP) (S, A, P, r, ?) <ref type="bibr" target="#b18">[19]</ref>, where S and A denote the state space and action space, respectively, P (s |s, a) denotes the transition probability, r(s, a) is a reward function, and ? ? (0, 1) is a discount factor. Specifically, the state denotes an observation that a DRL agent receives from a market environment; the action space consists of actions that an agent is allowed to take at a state; the reward function r(s, a, s ) is the incentive for agents to learn a better policy. A trading agent aims to learn a policy ?(s t |a t ) that maximizes the expected return R = ? t=0 ? t r(s t , a t ). Overview of FinRL-Meta: We utilize a layered structure, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. FinRL-Meta consists of three layers: data layer, environment layer, and agent layer. Each layer executes its functions and is relatively independent. Meanwhile, layers interact through end-to-end interfaces to implement the complete workflow of algorithm trading.</p><p>DataOps for Data-Driven DRL in Finance: We follow the DataOps paradigm <ref type="bibr" target="#b20">[21]</ref> in the data layer. First, we establish a standard pipeline for financial data engineering, ensuring data of different formats from different sources can be incorporated in a unified RL framework. Second, we automate this pipeline with a data processor, which can access data, clean data and extract features from various data sources with high quality and efficiency. Our data layer provides agility to model deployment. The data sources are shown in Table <ref type="table" target="#tab_0">1</ref>.</p><p>Multiprocessing Training: We utilize thousands of GPU cores to perform multiprocessing training, which significantly accelerates the training process. In each CUDA core, a trading agent interacts ElegantRL <ref type="bibr" target="#b6">[7]</ref> Stable-baselines3  with a market environment to produce transitions in the form of (state, action, reward, next state). Then all the transitions are stored in a replay buffer and used to update a learner and evaluator. By adopting this technique, we successfully achieve multiprocessing simulation of hundreds of market environments to improve the performance of DRL trading agents on large datasets.</p><p>Plug-and-Play: In the development pipeline, we separate market environments from the data layer and the agent layer. Any DRL agent can be directly plugged into our environments, then trained and tested. Different agents can run on the same benchmark environment for fair comparison.</p><p>Training-Testing-Trading Pipeline: We employ a training-testing-trading pipeline. The DRL agent first learns from the training environment and is then validated in the validation environment for further adjustment. Then the validated agent is tested on historical datasets. Finally, the tested agent will be deployed in paper trading or live trading markets. First, this pipeline solves the information leakage problem because the trading data are generated yet when adjusting agents. Second, a unified pipeline allows fair comparisons among different trading strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supported Trading Tasks:</head><p>We have supported and achieved satisfactory trading performance for trading tasks such as stock trading, cryptocurrency trading, and portfolio allocation. Derivatives such as futures and forex are also supported. Besides, we have supported multi-agent simulation and execution optimizing tasks by reproducing the experiment in <ref type="bibr" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Performance Evaluation</head><p>To provide benchmarks for researchers, we will continuously add typical trading tasks with corresponding environments. Here, we show results of stock trading and cryptocurrency trading.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experiment Settings</head><p>Stock trading task: We select the 30 constituent stocks in Dow Jones Industrial Average (DJIA), accessed at the beginning our testing period. We use the Proximal Policy Optimization (PPO) algorithm <ref type="bibr" target="#b17">[18]</ref> of ElegantRL <ref type="bibr" target="#b6">[7]</ref>, Stable-baselines3 <ref type="bibr" target="#b14">[15]</ref> and RLlib <ref type="bibr" target="#b5">[6]</ref>, respectively, to train agents and use the DJIA index as the baseline. We use  Cryptocurrency trading task: We select top 10 market cap cryptocurrencies<ref type="foot" target="#foot_0">2</ref> . We use the PPO algorithm <ref type="bibr" target="#b17">[18]</ref> of ElegantRL <ref type="bibr" target="#b6">[7]</ref> to train an agent and use the Bitcoin (BTC) price as the baseline.</p><p>We Cryptocurrency trading: In the backtesting stage, the ElegantRL agent outperforms the benchmark (BTC price) in most performance metrics, as shown in Fig. <ref type="figure">3</ref> and Table <ref type="table" target="#tab_4">3</ref>. It achieves an annual return of 360.823% and a Sharpe ratio of 2.992. The ElegantRL agent also outperforms the benchmark (BTC price) in the paper trading stage, which is consistent with the backtesting results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>In this paper, we followed the DataOps paradigm and developed a FinRL-Meta framework. FinRL-Meta provides open-source data engineering tools and hundreds of market environments with multiprocessing simulation.</p><p>For future work, we are building a multi-agent based market simulator that consists of over ten thousands of agents, namely, a FinRL-Metaverse. First, FinRL-Metaverse aims to build a universe of market environments, like the Xland environment <ref type="bibr" target="#b1">[2]</ref> and planet-scale climate forecast <ref type="bibr" target="#b15">[16]</ref> by DeepMind. To improve the performance for large-scale markets, we will employ GPU-based massive parallel simulation as Isaac Gym <ref type="bibr" target="#b10">[11]</ref>. Moreover, it will be interesting to explore the evolutionary perspective <ref type="bibr">[3][17]</ref>[5] <ref type="bibr" target="#b7">[8]</ref> to simulate the markets. We believe that FinRL-Metaverse will provide insights into complex market phenomena and offer guidance for financial regulations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview of FinRL-Meta.</figDesc><graphic url="image-1.png" coords="2,108.00,72.00,400.00,144.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Cumulative returns (5-minute) of stock trading in backtesting and paper trading.</figDesc><graphic url="image-3.png" coords="3,306.00,72.00,178.17,120.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Data platforms. OHLCV means open, high, low, close, volume data.</figDesc><table><row><cell>Data Source</cell><cell>Type</cell><cell>Range and Frequency</cell><cell>Request Limits</cell><cell>Raw Data</cell><cell>Preprocessed Data</cell></row><row><cell>Yahoo! Finance</cell><cell>US Securities</cell><cell>Frequency-specific, 1min</cell><cell>2,000/hour</cell><cell>OHLCV</cell><cell>Prices &amp; Indicators</cell></row><row><cell>CCXT</cell><cell>Cryptocurrency</cell><cell>API-specific, 1min</cell><cell>API-specific</cell><cell>OHLCV</cell><cell>Prices &amp; Indicators</cell></row><row><cell>WRDS.TAQ</cell><cell>US Securities</cell><cell>2003-now, 1ms</cell><cell cols="3">5 requests each time Intraday Trades Prices &amp; Indicators</cell></row><row><cell>Alpaca</cell><cell>US Stocks, ETFs</cell><cell>2015-now, 1min</cell><cell>Account-specific</cell><cell>OHLCV</cell><cell>Prices &amp; Indicators</cell></row><row><cell>RiceQuant</cell><cell>CN Securities</cell><cell>2005-now, 1ms</cell><cell>Account-specific</cell><cell>OHLCV</cell><cell>Prices &amp; Indicators</cell></row><row><cell>JoinQuant</cell><cell>CN Securities</cell><cell>2005-now, 1min</cell><cell>3 requests each time</cell><cell>OHLCV</cell><cell>Prices &amp; Indicators</cell></row><row><cell>QuantConnect</cell><cell>US Securities</cell><cell>1998-now, 1s</cell><cell>NA</cell><cell>OHLCV</cell><cell>Prices &amp; Indicators</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Performance of backtesting (red) and paper trading (blue) for stock trading.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>1-minute data from 06/01/2021 to 08/14/2021 for training and data from 08/15/2021 to 08/31/2021 for validation (backtesting). Then we retrain the agent using data from 06/01/2021 to 08/31/2021 and conduct paper trading from 09/03/2021 to 09/16/2021. The historical data and real-time data are accessed from the Alpaca's database and paper trading APIs.Figure 3: Cumulative returns (5-minute) of cryptocurrency trading in backtesting and paper trading.</figDesc><table><row><cell></cell><cell>ElegantRL [7]</cell><cell>BTC buy and hold</cell></row><row><cell>Cumul. return</cell><cell>10.857% / 4.844%</cell><cell>1.332% / -1.255%</cell></row><row><cell>Annual return</cell><cell>360.823% / 121.380%</cell><cell>21.666% / 5.492%</cell></row><row><cell>Annual volatility</cell><cell>59.976% / 65.857%</cell><cell>47.410% / 57.611%</cell></row><row><cell>Sharpe ratio</cell><cell>2.992 / 1.608</cell><cell>0.657 / -0.113</cell></row><row><cell>Max drawdown</cell><cell>-6.396% / -10.474%</cell><cell>-7.079% / -14.849%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Performance of backtesting (red) and paper trading (blue) for cryptocurrency trading.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>use 5-minute data from 06/01/2021 to 08/14/2021 for training and data from 08/15/2021 to 08/31/2021 for validation (backtesting). Then we retrain the agent using data from 06/01/2021 to 08/31/2021 and conduct paper trading from 09/01/2021 to 09/15/2021. The historical data and real-time data are accessed from Binance.3.2 Trading PerformanceStock trading: In the backtesting stage, both ElegantRL<ref type="bibr" target="#b6">[7]</ref> agent and Stable-baselines3<ref type="bibr" target="#b14">[15]</ref> agent outperform DJIA in annual return and Sharpe ratio, as shown in Fig.2and Table2. The ElegantRL agent achieves an annual return of 22.425% and a Sharpe ratio of 1.457. The Stable-baselines3 agent achieves an annual return of 32.106% and a Sharpe ratio of 1.621. In the paper trading stage, the results are consistent with the backtesting results. Both the ElegantRL agent and the Stable-baselines3 agent outperform the baseline.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>The top 10 market cap cryptocurrencies as of Oct 2021 are: Bitcoin (BTC), Ethereum (ETH), Cardano (ADA), Binance Coin (BNB), Ripple (XRP), Solana (SOL), Polkadot (DOT), Dogecoin (DOGE), Avalanche (AVAX), Uniswap (UNI). Tether (USDT) and USD Coin (USDC) are excluded.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>This research used computational resources of the GPU cloud platform [20] provided by the <rs type="institution">IDEA Research institute</rs>.</p></div>
			</div>
			<div type="funding">
<div><p>is supported in part by <rs type="funder">National Natural Science Foundation of China (NNSFC)</rs> grant <rs type="grantNumber">11901395</rs> and <rs type="person">Shanghai Pujiang Program</rs>, China <rs type="grantNumber">19PJ1408200</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_kWSun7T">
					<idno type="grant-number">11901395</idno>
				</org>
				<org type="funding" xml:id="_xpRHEgd">
					<idno type="grant-number">19PJ1408200</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Multi-agent deep reinforcement learning for liquidation strategy analysis</title>
		<author>
			<persName><forename type="first">Wenhang</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liu</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Open-ended learning leads to generally capable agents</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Stooke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deepmind-Oel</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Anuj</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catarina</forename><surname>Barros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charlie</forename><surname>Deck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakub</forename><surname>Sygnowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maja</forename><surname>Trebacz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nat</forename><surname>Mcaleese</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.12808</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Embodied intelligence via learning and evolution</title>
		<author>
			<persName><forename type="first">Agrim</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Surya</forename><surname>Ganguli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multi-agent reinforcement learning in a realistic limit order book market simulation</title>
		<author>
			<persName><forename type="first">Micha?l</forename><surname>Karpe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongyao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on AI in Finance</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">FinRL-Podracer: High performance and scalable deep reinforcement learning for quantitative finance</title>
		<author>
			<persName><forename type="first">Zechu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao-Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaoran</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anwar</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Walid</surname></persName>
		</author>
		<author>
			<persName><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on AI in Finance (ICAIF)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">RLlib: Abstractions for distributed reinforcement learning</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Nishihara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ken</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018-07">Jul 2018</date>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="10" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">ElegantRL: A lightweight and stable deep reinforcement learning library</title>
		<author>
			<persName><forename type="first">Xiao-Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zechu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaoran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiahao</forename><surname>Zheng</surname></persName>
		</author>
		<ptr target="https://github.com/AI4Finance-Foundation/ElegantRL" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Xiao-Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zechu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuoran</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiahao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaoran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anwar</forename><surname>Walid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
		<title level="m">ElegantRL-Podracer: Scalable and elastic library for cloud-native deep reinforcement learning. Deep RL Workshop</title>
		<imprint>
			<date type="published" when="2021">NeurIPS 2021, 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">FinRL: Deep reinforcement learning framework to automate trading in quantitative finance</title>
		<author>
			<persName><forename type="first">Xiao-Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiechao</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christina</forename><forename type="middle">Dan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on AI in Finance (ICAIF)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Modelling stock markets by multi-agent reinforcement learning</title>
		<author>
			<persName><forename type="first">Johann</forename><surname>Lussange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Lazarevich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sacha</forename><surname>Bourgeois-Gironde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Palminteri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Gutkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Economics</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="113" to="147" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Viktor</forename><surname>Makoviychuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Wawrzyniak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunrong</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michelle</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kier</forename><surname>Storey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miles</forename><surname>Macklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Hoeller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikita</forename><surname>Rudin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Allshire</surname></persName>
		</author>
		<title level="m">Ankur Handa, and Gavriel State. Isaac Gym: High performance GPU-based physics simulation for robot learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A brief review of recent artificial market simulation (agent-based model) studies for financial market regulations and/or rules</title>
		<author>
			<persName><forename type="first">Takanobu</forename><surname>Mizuta</surname></persName>
		</author>
		<idno>SSRN 2710495</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Tidor-Vlad</forename><surname>Pricope</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.00123</idno>
		<title level="m">Deep reinforcement learning in quantitative algorithmic trading: A review</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Agent-based simulation of a financial market</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Raberto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvano</forename><surname>Cincotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergio</forename><forename type="middle">M</forename><surname>Focardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Marchesi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica A: Statistical Mechanics and its Applications</title>
		<imprint>
			<biblScope unit="volume">299</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="319" to="327" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Antonin</forename><surname>Raffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashley</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maximilian</forename><surname>Ernestus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Gleave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anssi</forename><surname>Kanervisto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Dormann</surname></persName>
		</author>
		<ptr target="https://github.com/DLR-RM/stable-baselines3" />
	</analytic>
	<monogr>
		<title level="j">Stable baselines</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Skilful precipitation nowcasting using deep generative models of radar</title>
		<author>
			<persName><forename type="first">Suman</forename><surname>Ravuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karel</forename><surname>Lenc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Willson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Kangin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Remi</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Mirowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Megan</forename><surname>Fitzsimons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Athanassiadou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheleem</forename><surname>Kashem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Madge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Prudden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amol</forename><surname>Mandhane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niall</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Clancy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Arribas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">597</biblScope>
			<biblScope unit="issue">7878</biblScope>
			<biblScope unit="page" from="672" to="677" />
			<date type="published" when="2021-09">Sep 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">How market ecology explains market malfunction</title>
		<author>
			<persName><forename type="first">P</forename><surname>Maarten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anisoara</forename><surname>Scholl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J Doyne</forename><surname>Calinescu</surname></persName>
		</author>
		<author>
			<persName><surname>Farmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">26</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filip</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleg</forename><surname>Klimov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.06347</idno>
		<title level="m">Proximal policy optimization algorithms</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">NVIDIA DGX SuperPOD: Scalable infrastructure for ai leadership</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>NVIDIA DGX A100 system reference architecture</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">DataOps: An agile methodology for data-driven organizations</title>
		<author>
			<persName><forename type="first">Crystal</forename><surname>Valentine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Merchan</surname></persName>
		</author>
		<ptr target="https://www.oracle.com/a/ocom/docs/oracle-ds-data-ops-map-r.pdf" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
