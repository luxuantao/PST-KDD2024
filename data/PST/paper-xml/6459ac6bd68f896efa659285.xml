<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Enhancing Knowledge Graph Construction Using Large Language Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-05-08">8 May 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Milena</forename><surname>Trajanoska</surname></persName>
							<email>milena.trajanoska@finki.ukim.mk</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Comp. Sci. and Eng. Ss. Cyril and Methodius University Skopje</orgName>
								<address>
									<country key="MK">Macedonia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">nd Riste Stojanov Faculty of Comp. Sci. and Eng. Ss. Cyril and Methodius University Skopje</orgName>
								<address>
									<country key="MK">Macedonia</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">rd Dimitar Trajanov Faculty of Comp. Sci. and Eng. Ss. Cyril and Methodius University Skopje</orgName>
								<address>
									<country key="MK">Macedonia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Enhancing Knowledge Graph Construction Using Large Language Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-05-08">8 May 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2305.04676v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ChatGPT</term>
					<term>REBEL</term>
					<term>LLMs</term>
					<term>Relation-extraction</term>
					<term>NLP</term>
					<term>Sustainability</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The growing trend of Large Language Models (LLM) development has attracted significant attention, with models for various applications emerging consistently. However, the combined application of Large Language Models with semantic technologies for reasoning and inference is still a challenging task. This paper analyzes how the current advances in foundational LLM, like ChatGPT, can be compared with the specialized pretrained models, like REBEL, for joint entity and relation extraction. To evaluate this approach, we conducted several experiments using sustainability-related text as our use case. We created pipelines for the automatic creation of Knowledge Graphs from raw texts, and our findings indicate that using advanced LLM models can improve the accuracy of the process of creating these graphs from unstructured text. Furthermore, we explored the potential of automatic ontology creation using foundation LLM models, which resulted in even more relevant and accurate knowledge graphs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The technological advancements, together with the availability of Big Data, have led to a surge in the development of Large Language Models (LLMs) <ref type="bibr" target="#b0">[1]</ref>. This trend has paved the way for a cascade of new models being released on a regular basis, each outperforming its predecessors. These models have started a revolution in the field with their capability to process massive amounts of unstructured text data and by achieving state-of-the-art results on multiple Natural Language Processing (NLP) tasks.</p><p>However, one of the aspects which have not yet taken over the spotlight is the combined application of these models with semantic technologies to enable reasoning and inference. This paper attempts to fill this gap by making a connection between the Deep Learning (DL) space and the semantic space, through the use of NLP for creating Knowledge Graphs <ref type="bibr" target="#b1">[2]</ref>.</p><p>Knowledge Graphs are structured representations of information that capture the relationships between entities in a particular domain. They are used extensively in various applications, such as search engines, recommendation systems, and question-answering systems.</p><p>On a related note, there is a significant amount of raw texts available on the Web which contain valuable information. Nevertheless, this information is unusable if it cannot be extracted from the texts and applied for intelligent reasoning. This fact has motivated us to use some of the state-of-the-art models in an attempt to extract information from text data on the Web.</p><p>Yet, creating Knowledge Graphs from raw text data is a complex task that requires advanced NLP techniques such as Named Entity Recognition <ref type="bibr" target="#b2">[3]</ref>, Relation Extraction <ref type="bibr" target="#b3">[4]</ref>, and Semantic Parsing <ref type="bibr" target="#b4">[5]</ref>. Large language models such as GPT-3 <ref type="bibr" target="#b5">[6]</ref>, T5 <ref type="bibr" target="#b6">[7]</ref>, and BERT <ref type="bibr" target="#b7">[8]</ref> have shown remarkable performance in these tasks, and their use has resulted in significant improvements in the quality and accuracy of knowledge graphs.</p><p>To evaluate our approach in connecting both fields, we chose to analyze the specific use case of sustainability. Sustainability is a topic of great importance for our future, and a lot of emphasis has been placed on identifying ways to create more sustainable practices in organizations. Sustainability has become the norm for organizations in developed countries, mainly due to the rising awareness of their consumers and employees. However, this situation is not reflected in developing and underdeveloped countries to this extent. Although the perception of sustainability has improved, progress toward sustainable development has been slower, indicating the need for more concrete guidance <ref type="bibr" target="#b8">[9]</ref>. Moreover, theoretical research has attempted to link strategic management and sustainable development in corporations in order to encourage the integration of sustainability issues into corporate activities and strategies <ref type="bibr" target="#b9">[10]</ref>. Even though research has set a basis for developing standards and policies in favor of sustainability, a more empirical approach is needed for policy definitions and analyzing an organization's sustainability level with respect to the defined policies.</p><p>In this study, the goal is to make a connection between LLMs and semantic reasoning to automatically generate a Knowledge Graph on the topic of sustainability and populate it with concrete instances using news articles available on the Web. For this purpose, we create multiple experiments where we utilize popular NLP models, namely Relation Extraction By End-to-end Language generation (REBEL) <ref type="bibr" target="#b10">[11]</ref> and Chat-GPT <ref type="bibr" target="#b11">[12]</ref>. We show that although REBEL is specifically trained for relation extraction, ChatGPT, a conversational agent using a generative model, can streamline the process of automatically creating accurate Knowledge Graphs from an unstructured text when provided with detailed instructions.</p><p>The rest of the paper is structured as follows: Section II presents a brief literature overview, Section III describes the methods and experimental setup, Section IV outlines the results of the information extraction process, Section V states the propositions for future work, and finally section VI gives the conclusion of the work done in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. LITERATURE REVIEW A. Algorithms</head><p>Our study focuses on the task of information extraction from news and reports available on the Web. For this purpose, we compare the capabilities of NLP models to generate a useful Knowledge Base on the topic.</p><p>A Knowledge Base represents information stored in a structured format, ready to be used for analysis or inference. Often, Knowledge Bases are stored in the form of a graph and are then called Knowledge Graphs.</p><p>In order to create such a Knowledge Base, we need to extract information from the raw texts in a triplet format. An example of a triplet would be &lt;Person, Location, City&gt;. In the triplet, we have a structure consisting of the following links Entity -&gt; Relation -&gt; Entity, where the first entity is referred to as the subject, the relation is a predicate, and the second entity represents the object. In order to achieve this structured information extraction, we need to identify entities in the raw texts, as well as the relations connecting these entities.</p><p>In the past, this process was implemented by leveraging multi-step pipelines, where one step included Named-entity Recognition (NER) <ref type="bibr" target="#b2">[3]</ref>, and another step was Relation classification (RC) <ref type="bibr" target="#b12">[13]</ref>. However, these multi-step pipelines often prove to have unsatisfactory performance due to the propagation of errors from the steps. In order to tackle this problem, end-to-end approaches have been implemented, referred to as Relation-Extraction (RE) <ref type="bibr" target="#b3">[4]</ref> methods.</p><p>One of the models utilized in this study is REBEL (Relation Extraction By End-to-end Language generation) <ref type="bibr" target="#b10">[11]</ref>, which is an auto-regressive seq2seq model based on BART <ref type="bibr" target="#b13">[14]</ref> that performs end-to-end relation extraction for more than 200 different relation types. The model achieves 74 micro-F1 and 51 macro-F1 scores. It was created for the purpose of joint entity-relation extraction.</p><p>REBEL is a generative seq2seq model which attempts to "translate" the raw text into a triple format. The REBEL model outputs additional tokens, which are used during its training to identify a triplet. These tokens include &lt;triplet&gt;, which represents the beginning of a triplet, &lt;subj&gt;, which represents the end of the subject and the start of the predicate, and &lt;obj&gt;, which represents the end of the predicate and start of the object. The authors of the paper for REBEL provide a parsing function for extracting the triplet from the output of REBEL.</p><p>The second approach we took was to use ChatGPT <ref type="bibr" target="#b11">[12]</ref>, as a conversational agent and compare the performance in the task of entity-relation extraction and creation of a common Knowledge Base. The agent consists of three steps, including separate models: a supervised fine-tuning (SFT) model based on GPT-3 <ref type="bibr" target="#b5">[6]</ref>, a reward model, and a reinforcement learning model.</p><p>ChatGPT was trained using Reinforcement Learning from Human Feedback (RLHF) <ref type="bibr" target="#b14">[15]</ref>, employing methods similar to InstructGPT with minor variations in data collection. An initial model is trained through supervised fine-tuning, with human AI trainers engaging in conversations, assuming both user and AI assistant roles. To aid in formulating responses, trainers were given access to model-generated suggestions. The newly created dialogue dataset was then combined with the InstructGPT dataset, which was transformed into a dialogue format. In order to establish a reward model for reinforcement learning, comparison data needed to be gathered, consisting of two or more model responses ranked by quality. This data was collected by taking conversations between AI trainers and the chatbot, randomly selecting a model-generated message, sampling multiple alternative completions, and having AI trainers rank them. The reward models enabled fine-tuning of ChatGPT using Proximal Policy Optimization <ref type="bibr" target="#b15">[16]</ref>, and several iterations of this procedure were executed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Use case: Sustainability</head><p>The Global sustainability study of 2022 has reported that 71% out of 11,500 surveyed consumers around the world are making changes to the way they live and the products they buy in an effort to live more sustainably <ref type="bibr" target="#b16">[17]</ref>. This shows that corporations not only need to change their operations to be more sustainable for the sake of the environment but also to be able to stay competitive.</p><p>With the vast amount of unstructured data available on the Web, it is crucial to develop methods that can automatically identify sustainability-related information from news, reports, papers, and other forms of documents. One such study identifies this opportunity and attempts to create a method for directly extracting non-financial information generated by various media to provide objective ESG information <ref type="bibr" target="#b17">[18]</ref>. The authors have trained an ESG classifier and recorded a classification accuracy of 86.66% on 4-class on texts which they manually labeled. On a related note, researchers have taken a step further to extract useful ESG information from texts. In this article <ref type="bibr" target="#b18">[19]</ref>, the authors have trained a joint entity and relation extraction model on a private dataset consisting of ESG and CSR reports annotated internally at Cr?dit Agricole. They were able to identify entities such as coal activities and environmental or social issues. In <ref type="bibr" target="#b19">[20]</ref>, the authors presented an approach for knowledge graph generation based on ESGrelated news and company official documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METHODS</head><p>This section describes the methods used in this research, including the data collection process and the entity-relation extraction algorithms used to analyze the gathered data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Data Collecting Process</head><p>In order to conduct the experimental comparison of the two approaches for entity-relation extraction, news data was gathered from the Web on the topic of sustainability. For this purpose, the News API <ref type="bibr" target="#b20">[21]</ref> system was used. News API is an HTTP REST API for searching and retrieving live articles from all over the Web. It provides the ability to search through the articles posted on the Web by specifying the following options: keyword or phrase, date of publication, source domain name, and language.</p><p>Using News API, 94 news articles from 2023-02-15 to 2023-03-19 on the topic of sustainability have been collected. The collected texts contained various numbers of words ranging from 50 to over 4200. With the limitation of the number of tokens that can be passed as input to a language model, additional pre-processing steps needed to be taken to account for the texts consisting of a large number of words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Relation-Extraction Methods</head><p>Relation-extraction is a fundamental task in NLP that aims to identify the semantic relationships between entities in a sentence or document. The task is challenging because it requires understanding the context in which the entities appear and the types of relationships that exist between them.</p><p>In this subsection, we describe how we utilize REBEL and ChatGPT for the task of relation extraction.</p><p>1) REBEL: Our first approach was to use REBEL in an attempt to extract relations from unstructured news articles. In order for REBEL to be able to use the provided texts, they need to be tokenized with the corresponding tokenizer function. Tokenization is the process of separating the raw text into smaller units called tokens. Tokens can refer to words, characters, or sub-words. The model has a token limitation of 512 tokens, which means that the collected articles which are longer need to be pre-processed before sending them to the model for triplets extraction.</p><p>To address this limitation, we tokenize the raw text and divide the tokens into 256-token batches. These batches are processed separately by the REBEL model, and the results are subsequently merged to extract relations for longer texts. Metadata is also added to the extracted relations, referencing the token batch from which the relation was derived. With this approach, some relations may not be extracted accurately because the batch of tokens might begin or end in the middle of the sentence. However, the number of cases where this happens is insignificant. Thus, we leave their handling for future work.</p><p>Once the entity-relation extraction process is finished, the extracted information is stored in a triplet structure. To further normalize the extracted entities, we perform Entity Linking <ref type="bibr" target="#b21">[22]</ref>. Entity Linking refers to the identification and association of entity mentions in raw text with their corresponding entities in a Knowledge Base. The process of Entity Linking is not part of the REBEL model, and it is an additional post-processing step that is used to refine the extracted relations. In this study, we utilize DBpedia as our Knowledge Base and consider two entities identical if they share the same DBpedia URL. This approach will not work for entities that are not present on DBpedia.</p><p>2) ChatGPT: The second approach taken in this paper uses OpenAI's ChatGPT <ref type="bibr" target="#b11">[12]</ref>. We have created two experiments using ChatGPT.</p><p>The first experiment prompts ChatGPT to extract relations from the collected news articles. After extracting the relations, we follow the same steps as with the REBEL model in order to create a comprehensive Knowledge Base.</p><p>The second experiment focuses on creating a prompt that would directly generate the entire Knowledge Base and write an ontology describing the concepts identified in the texts. This approach has the goal of reducing the number of manual steps which need to be performed in order to obtain the final Knowledge Graph.</p><p>For both experiments, we set the value of the parameter 'temperature' to 0 in order to get more deterministic outputs since OpenAI models are non-deterministic by nature.</p><p>Experiment 1. For the first experiment, we prompt Chat-GPT to extract relations connected to sustainability. ChatGPT was able to successfully extract entities and connect them with relations, and return the results in a triple format. After the relations had been extracted, the same post-processing step of Entity Linking was implemented on the results from ChatGPT.</p><p>Although ChatGPT was able to extract entities from the articles and link them with relations, it was not successful at abstracting concepts. The entities and relations identified often represented whole phrases instead of concepts.</p><p>To overcome the obstacle, we prompted ChatGPT to map identified entities and relations to a suitable OWL ontology <ref type="bibr" target="#b22">[23]</ref>. However, ChatGPT failed to identify relevant sustainability concepts or define their instances. The identified classes, such as Company, Customer, MarketingEcosystem, Resource, CustomerExperience, Convenience, and DigitalMarketing, had some potential relevance to sustainability, but ChatGPT did not identify any instances for these classes.</p><p>Experiment 2. In the second experiment, we refined the prompt to ask ChatGPT to explicitly generate an OWL ontology on sustainability, which includes concepts like organizations, actions, practices, policies, and related terms. We also allowed ChatGPT to create additional classes and properties if necessary. We explicitly requested the results to be returned in RDF Turtle format.</p><p>Providing additional information to ChatGPT resulted in the creation of an improved Knowledge Base. ChatGPT was able to define concepts such as organizations, actions, practices, and policies, as well as identify suitable relations to connect them together. Moreover, it was able to create instances of the defined classes and properties and link them together. This shows that adding more specific instructions to the prompts for ChatGPT can produce drastically different results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. RESULTS</head><p>This section presents the results from the experiments described in Section III. A comparison of the created Knowledge Base from both methods is given, and the characteristics of the generated Knowledge Bases are outlined. Table <ref type="table">I</ref> represents the Knowledge Bases from the REBEL model and the first experiment with ChatGPT, respectively. The table shows the number of entities, relations, and triplets extracted from the raw texts on sustainability. As it is evident from the table, the number of triplets extracted by both algorithms is similar. However, the number of entities that ChatGPT extracts are larger than those from REBEL. Although this is true, a lot of the extracted entities are not connected to each other via any relation, thus defeating the purpose of creating a Knowledge Base. Moreover, the number of unique relations is far too large for ChatGPT to be able to produce an ontology that can be used for further experimentation.</p><p>The most frequent relation for the REBEL model is the 'subclass of' relation, being part of 120 triplets. For ChatGPT, it's the 'has' relation, being identified in 29 triplets. In addition, ChatGPT often fails to generate standard relations and entities which represent abstract concepts and instead outputs an entire phrase, such as in the example 'has already surpassed a goal set in 2019 to install 100,000 heat pumps in homes and businesses', where it identifies this phrase as a relation.</p><p>The following subsections represent a visual display of a subset of the generated Knowledge Bases from both algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. REBEL</head><p>In order to be able to analyze the Knowledge Base generated using the REBEL model more accurately, we have created a visualization in a graph format, where each entity represents a node in the graph, and each relation represents an edge. Fig.</p><p>IV-A displays a subset of the extracted Knowledge Base.</p><p>It is visible from the figure that the model successfully identifies entities related to sustainability, such as 'sustainability', 'recycling', 'clean technology', 'business model', 'repurposing', and even links corporations such as 'Samsung' to these entities. We can notice that multiple entities are interlinked in a meaningful way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. ChatGPT</head><p>The same visualization for the Knowledge Base generated by the first experiment with ChatGPT is represented in this subsection. We can see from the figure that ChatGPT is able to identify entities related to sustainability, but they are represented as phrases instead of concepts. For example, ChatGPT extracts 'small high-value items in jumbo packaging', 'steps and waste from its supply chain', and 'suppliers to use recycled and recyclable materials', as entities.  Although these phrases are related to sustainability, they do not represent specific entities. This happens as a result of the fact that ChatGPT is a conversational model trained on a task to generate responses to a provided prompt and not specifically trained to be able to recognize entities and relations. On the other hand, ChatGPT is able to identify some concepts that REBEL does not, and additionally, it is able to link corporations to specific sustainability-related phrases.</p><p>Prompt engineering <ref type="bibr" target="#b23">[24]</ref> is of great importance when it comes to the results generated from ChatGPT <ref type="bibr" target="#b11">[12]</ref>. Since it is a generative model, small variations in the input sequence can create large differences in the produced output.</p><p>Observing the full Knowledge Base generated using Chat-GPT, most of the time, the extracted entities represent phrases or whole sentences, which is not beneficial for creating a Knowledge Base because it's hard to normalize the entities and relations and create a more general ontology consisting of the concepts represented in the graph.</p><p>For this reason, we conducted the second experiment with ChatGPT, where we defined a more detailed prompt and instructed ChatGPT to generate an ontology based on each article it sees and additionally define instances of the generated ontology based on the information present in each article.  Not only does ChatGPT create an ontology using the concepts it was instructed to use, but it also defines classes on its own and is able to create instances of most of the classes accurately.</p><p>As an example, it identifies the entity "Soluna" as an "instanceOf" the class "Organizations". Furthermore, it is able to identify the triplet &lt;Soluna, utilizes, Excess Energy&gt;, and &lt;Excess Energy, instanceOf, Practices&gt;.</p><p>These types of triplets already start representing an initial knowledge base, which can answer queries on companies that implement practices that use excess energy. Although the hierarchy of concepts can be better defined so that more complex queries can be answered, this method represents a solid start in building a shared Knowledge Base, using only unstructured texts.</p><p>Using another article, the ontology and instances given in Fig. <ref type="figure">IV-B</ref> have been generated. Looking at this second example, we can see that ChatGPT links practices, actions, and policies to the organizations, which was not the case in the previous example.</p><p>Additionally, it identifies the triplets &lt;Starbucks, in-stanceOf, Organization&gt;, and &lt;Starbucks, hasPractice, ResourceSharing&gt;. This also allows for answering complex queries in the sustainability domain.</p><p>While the consistency of the generated ontologies may be limited, our analysis reveals that there are significant similarities between them. Therefore, future research can explore methods for unifying these ontologies across all articles, which has the potential to enhance the overall definition of concepts and their interrelationships in the sustainability domain.</p><p>It is important to mention that due to the limitations of the length of the input prompt passed to ChatGPT, it was not possible to prompt the model first to define an ontology based on all articles on sustainability and then create instances from all the other articles using the same ontology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Quality Evaluation</head><p>Since the evaluation of a Knowledge Base cannot be created in an automated way based on some metric, when ground truth data is not available, we need to utilize qualitative principles in order to evaluate the results. Based on the practical framework defined in the study <ref type="bibr" target="#b24">[25]</ref>, the following 18 principles identified:</p><p>1) Triples should be concise 2) Contextual information of entities should be captured 3) Knowledge graph does not contain redundant triples 4) Knowledge graph can be updated dynamically 5) Entities should be densely connected 6) Relations among different types of entities should be included 7) Data source should be multi-field 8) Data for constructing a knowledge graph should in different types and from different resources 9) Synonyms should be mapped, and ambiguities should be eliminated to ensure reconcilable expressions 10) Knowledge graph should be organized in structured triples for easily processed by machine 11) The scalability with respect to the KG size 12) The attributes of the entities should not be missed 13) Knowledge graph should be publicly available and proprietary 14) Knowledge graph should be an authority 15) Knowledge graph should be concentrated 16) The triples should not contradict each other 17) For domain-specific tasks, the knowledge graph should be related to that field 18) Knowledge graph should contain the latest resources to guarantee freshness According to these principles, in our use case, we manually inspected the Knowledge Graphs generated with the proposed methods, and we can conclude that the second ChatGPT approach creates a Knowledge Graph of greater quality compared to the other two Knowledge Bases.</p><p>However, it should be noted that to create these Knowledge Bases, a few steps of refining the answers from ChatGPT are needed. Sometimes the produced output is erroneous and needs to be corrected before proceeding. Thus, this calls for methods for automatically identifying incorrect OWL syntax and requesting to fix the previous output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this paper, we presented a Natural Language Processingbased method for constructing a Knowledge Graph on the topic of sustainability using raw documents available on the Web. The study demonstrated that meaningful information could be extracted from unstructured data through an automated process, which can subsequently be utilized for decision-making and process modeling. The focus on sustainability served as a concrete use case, illustrating the effectiveness and potential of the presented approach.</p><p>Although the experiments were conducted on the use case of sustainability, the primary emphasis is on the methodology itself, which lays the foundation for empirical analysis of qualitative data derived from various sources. The construction of a Knowledge Base using the presented approach can serve as a first step for analyzing diverse aspects of any subject matter and answering complex queries based on the gathered information.</p><p>In future research, first, we plan to adopt a more formal framework for assessing the quality of generated knowledge graphs. Such a framework will enable us to effectively evaluate the quality of KGs and provide a standardized means of assessing their overall quality. We also want to extend the presented methodology to other domains, unifying generated knowledge bases and employing graph-based modeling to predict missing links between concepts and relationships for a given domain.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Fig. IV-B displays a subset of the extracted Knowledge Base.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Subset of the Knowledge Base generated using the REBEL model. The Knowledge Base is displayed in a graph format where entities are represented as nodes and relations are represented as edges.</figDesc><graphic url="image-1.png" coords="4,334.69,50.54,205.63,205.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Subset of the Knowledge Base generated using the first experiment with ChatGPT. The Knowledge Base is displayed in a graph format where entities are represented as nodes and relations are represented as edges.</figDesc><graphic url="image-2.png" coords="4,334.69,308.80,205.63,205.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure IV-B presents the results of the refined prompt, with the ontology and instances generated from a single article out of the 94 collected articles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Knowledge Base generated with ChatGPT for the first article. The identified concepts are represented as yellow rectangles, and the instances are represented with green rectangles.</figDesc><graphic url="image-3.png" coords="5,-56.84,232.44,462.66,167.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Knowledge Base generated with ChatGPT for the second article. The identified concepts are represented as yellow rectangles, and the instances are represented with green rectangles.</figDesc><graphic url="image-4.png" coords="5,308.99,50.54,257.01,93.07" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Large language models in machine translation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brants</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Popat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007-06">June 2007</date>
			<biblScope unit="page" from="858" to="867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A review: Knowledge reasoning over knowledge graph</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="page">112948</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Named entity recognition without gazetteers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mikheev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Grover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ninth Conference of the European Chapter</title>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Exploring various knowledge in relation extraction</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd annual meeting of the association for computational linguistics (acl&apos;05)</title>
		<meeting>the 43rd annual meeting of the association for computational linguistics (acl&apos;05)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="427" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A survey on semantic parsing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Das</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.00978</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5485" to="5551" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">World&apos;s poorest nations left behind in reaching sustainable development goals, delegates stress as second committee begins general debate</title>
		<author>
			<persName><forename type="first">U</forename><surname>Nations</surname></persName>
		</author>
		<ptr target="https://press.un.org/en/2018/gaef3495.doc.htm" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Strategic perspectives of corporate sustainability management to develop a sustainable organization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Baumgartner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rauter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="page" from="81" to="92" />
		</imprint>
	</monogr>
	<note>Journal of Cleaner Production</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Rebel: Relation extraction by end-to-end language generation</title>
		<author>
			<persName><forename type="first">P.-L</forename><forename type="middle">H</forename><surname>Cabot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2370" to="2381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.08774</idno>
		<title level="m">Gpt-4 technical report</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Relation classification via convolutional deep neural network</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th international conference on computational linguistics: technical papers</title>
		<meeting>COLING 2014, the 25th international conference on computational linguistics: technical papers</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2335" to="2344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">BART: Denoising sequence-tosequence pre-training for natural language generation, translation, and comprehension</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="page" from="7871" to="7880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Training language models to follow instructions with human feedback</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="27730" to="27744" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Klimov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.06347</idno>
		<title level="m">Proximal policy optimization algorithms</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">2022 global sustainability study: The growth potential of environmental change</title>
		<author>
			<persName><surname>Simon-Kucher</surname></persName>
		</author>
		<ptr target="https://www.simon-kucher.com/en/insights/2022-global-sustainability-study-growth-potential-environmental-change" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Esg information extraction with cross-sectoral and multi-source adaptation based on domain-tuned language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="page">119726</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automated esg report analysis by joint entity and relation extraction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ehrhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Principles and Practice of Knowledge Discovery in Databases: International Workshops of ECML PKDD 2021, Virtual Event</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">September 13-17, 2021. 2022</date>
			<biblScope unit="page" from="325" to="340" />
		</imprint>
	</monogr>
	<note>Proceedings, Part II</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Challenges and opportunities in esg investments</title>
		<author>
			<persName><forename type="first">I</forename><surname>Vodenska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Trajanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chitkushev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Trajanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Science and Education in Computer Science: 18th EAI International Conference, CSECS 2022, On-Site and Virtual Event</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">June 24-27, 2022. 2022</date>
			<biblScope unit="page" from="168" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName><surname>Newsapi</surname></persName>
		</author>
		<author>
			<persName><surname>Newsapi</surname></persName>
		</author>
		<ptr target="https://newsapi.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Entity linking with a knowledge base: Issues, techniques, and solutions</title>
		<author>
			<persName><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="443" to="460" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Owl web ontology language overview</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Mcguinness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Van Harmelen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">W3C recommendation</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">2004</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Prompt Engineering Guide</title>
		<author>
			<persName><forename type="first">E</forename><surname>Saravia</surname></persName>
		</author>
		<ptr target="https://github.com/dair-ai/Prompt-Engineering-Guide" />
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A practical framework for evaluating the quality of knowledge graph</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Knowledge Graph and Semantic Computing: Knowledge Computing and Language Understanding: 4th China Conference</title>
		<meeting><address><addrLine>Hangzhou, China</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-08-24">2019. August 24-27, 2019. 2019</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="111" to="122" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
