<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CHiRP: Control-Flow History Reuse Prediction</title>
				<funder ref="#_qxkhqAb #_edhUgBg #_EgRETVv">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder>
					<orgName type="full">Intel Labs</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Samira</forename><surname>Mirbagher-Ajorpaz</surname></persName>
							<email>samiramir@tamu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">Texas A&amp;M University College Station</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Elba</forename><surname>Garza</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">Texas A&amp;M University College Station</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gilles</forename><surname>Pokam</surname></persName>
							<email>gilles.a.pokam@intel.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Intel Labs Santa Clara</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Jim?nez</surname></persName>
							<email>djimenez@acm.org</email>
							<affiliation key="aff3">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">Texas A&amp;M University College Station</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CHiRP: Control-Flow History Reuse Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/MICRO50266.2020.00023</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Translation Lookaside Buffers</term>
					<term>Replacement Policies</term>
					<term>Paging</term>
					<term>Microarchitectures</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Translation Lookaside Buffers (TLBs) play a critical role in hardware-supported memory virtualization. To speed up address translation and reduce costly page table walks, TLBs cache a small number of recently-used virtual-to-physical address translations. TLBs must make the best use of their limited capacities. Thus, TLB entries with low potential for reuse should be replaced by more useful entries. This paper contributes to an aspect of TLB management that has received little attention in the literature: replacement policy. We show how predictive replacement policies can be tailored toward TLBs to reduce miss rates and improve overall performance.</p><p>We begin by applying recently proposed predictive cache replacement policies to the TLB. We show these policies do not work well without considering specific TLB behavior. Next, we introduce a novel TLB-focused predictive policy, Control-flow History Reuse Prediction (CHIRP). This policy uses a history signature and replacement algorithm that correlates to known TLB behavior, outperforming other policies.</p><p>For a 1024-entry 8-way set-associative L2 TLB with a 4KB page size, we show that CHIRP reduces misses per 1000 instructions (MPKI) by an average 28.21% over the least-recentlyused (LRU) policy, outperforming Static Re-reference Interval Prediction (SRRIP) [1], Global History Reuse Policy (GHRP) <ref type="bibr" target="#b1">[2]</ref> and SHiP [3], which reduce MPKI by an average of 10.36%, 9.03% and 0.88%, respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Virtual-to-physical address translation is expensive <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b15">[15]</ref>. Translation lookaside buffers (TLBs) help minimize the need for costly page table walks by caching recently retrieved virtual-tophysical address mappings <ref type="bibr" target="#b16">[16]</ref>, <ref type="bibr" target="#b17">[17]</ref>.</p><p>Recent studies by Google <ref type="bibr" target="#b18">[18]</ref>, asmDB <ref type="bibr" target="#b19">[19]</ref>, and Facebook <ref type="bibr" target="#b20">[20]</ref> confirm that modern deeply pipelined speculative OoO CPUs face increasing challenges associated with TLB performance. For example, server workloads show growing code footprints and working set sizes <ref type="bibr" target="#b18">[18]</ref>, <ref type="bibr" target="#b21">[21]</ref>, <ref type="bibr" target="#b22">[22]</ref>, <ref type="bibr" target="#b23">[23]</ref>, placing tremendous pressure on caches and TLBs <ref type="bibr" target="#b24">[24]</ref>. The caches and TLBs of future systems will need to improve at a similar rate to maintain performance.</p><p>Unfortunately, TLBs are limited in size, and thus reach, due to power, timing, and area constraints <ref type="bibr" target="#b26">[25]</ref>. The TLB lies on SHiP Fig. <ref type="figure">1</ref>. Comparing predictive policy efficiency with a heat map shows CHIRP maintains more live TLB entries compared to other policies when analyzed on 870 different benchmarks. A lighter color block indicates higher TLB efficiency, while darker denotes lower efficiency.</p><p>the critical path to accessing memory. Thus, increasing L2 TLB sizes to reduce TLB misses is difficult because larger TLBs incur higher access latencies <ref type="bibr" target="#b27">[26]</ref>.</p><p>Meanwhile, TLB misses are a first-order concern in terms of their negative impact on performance. Recently studies <ref type="bibr" target="#b28">[27]</ref>, <ref type="bibr" target="#b29">[28]</ref>, <ref type="bibr" target="#b30">[29]</ref> indicate that many programs can spend hundreds of extra cycles conducting address translations that did not hit in the TLBs. This is despite the fact that the Skylake architecture includes special MMU/paging structure caches (or PSCs) to lessen the page walk penalty <ref type="bibr" target="#b31">[30]</ref>. The study <ref type="bibr" target="#b28">[27]</ref> finds L2 TLB miss costs range from 16.3 cycles for Sandy Bridge in 2011, increasing up to 212 for Skylake in 2015, 272 cycles for Broadwell Xeon in 2016, and 230 cycles for Coffee Lake in 2017. Such overhead is likely to be exacerbated in the future <ref type="foot" target="#foot_0">1</ref> given that modern computing platforms can now be supplied with terabytes, and even petabytes, of main memory <ref type="bibr" target="#b33">[32]</ref>, <ref type="bibr" target="#b34">[33]</ref> , all on various memory-intensive workloads that are rapidly emerging <ref type="bibr" target="#b18">[18]</ref>, <ref type="bibr" target="#b19">[19]</ref>, <ref type="bibr" target="#b20">[20]</ref>, <ref type="bibr" target="#b29">[28]</ref>.</p><p>Translation overheads running into 100+ cycles have also been reported in prior work <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>. Address translation latencies due to TLB misses represent between 20% and 50% of system run-times today <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b35">[34]</ref>, <ref type="bibr" target="#b36">[35]</ref>, <ref type="bibr" target="#b37">[36]</ref>, <ref type="bibr" target="#b38">[37]</ref>, <ref type="bibr" target="#b39">[38]</ref>, <ref type="bibr" target="#b40">[39]</ref>, <ref type="bibr" target="#b41">[40]</ref>, <ref type="bibr" target="#b42">[41]</ref> and consume a substantial share of processor energy <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b15">[15]</ref>, <ref type="bibr" target="#b43">[42]</ref>.</p><p>Peng et al. conduct a thorough study of TLB behavior of Java applications <ref type="bibr" target="#b44">[43]</ref>, reporting 230+ cycle TLB miss latencies and indicate TLB miss overhead accounts for 5.5% to 19% of the total execution time. Their study finds that five out of seven benchmarks exhibit similar TLB overhead.</p><p>These concerns motivate us to investigate mechanisms to improve TLB performance that do not require increasing TLB sizes. Similar efforts to improve TLB performance have included using varied page sizes and superpages <ref type="bibr" target="#b24">[24]</ref>, <ref type="bibr" target="#b45">[44]</ref>, <ref type="bibr" target="#b46">[45]</ref>, <ref type="bibr" target="#b47">[46]</ref>, <ref type="bibr" target="#b48">[47]</ref>, <ref type="bibr" target="#b49">[48]</ref> as well as prefetching <ref type="bibr" target="#b37">[36]</ref>, <ref type="bibr" target="#b50">[49]</ref>, <ref type="bibr" target="#b51">[50]</ref>, <ref type="bibr" target="#b52">[51]</ref>.</p><p>Fortunately, TLBs' organization makes them amenable to predictive replacement policies. TLBs are organized with tagged set-associative SRAM arrays much like cache memories. Predictive replacement policies have been well-explored and have been shown to perform well in data caches <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b53">[52]</ref>, <ref type="bibr" target="#b54">[53]</ref>, <ref type="bibr" target="#b55">[54]</ref> that depend on spatial and temporal locality of data accesses to maintain useful entries. Access patterns to TLBs are similar to cache accesses at a larger granularity. Thus, it is reasonable to apply previous work on cache replacement/management to TLBs.</p><p>TLB replacement policy has received little attention in the literature. Recent work <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b35">[34]</ref>, <ref type="bibr" target="#b37">[36]</ref>, <ref type="bibr" target="#b38">[37]</ref>, <ref type="bibr" target="#b39">[38]</ref>, <ref type="bibr" target="#b56">[55]</ref>, <ref type="bibr" target="#b57">[56]</ref>, <ref type="bibr" target="#b58">[57]</ref>, <ref type="bibr" target="#b59">[58]</ref> advocates using an LRU replacement policy for all levels of TLBs. Other prior work focuses either on reducing the cost of a page table walk upon a TLB miss <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b35">[34]</ref>, <ref type="bibr" target="#b50">[49]</ref>, <ref type="bibr" target="#b51">[50]</ref>, <ref type="bibr" target="#b52">[51]</ref> or reducing the TLB miss rate by extending the size of the TLB <ref type="bibr" target="#b27">[26]</ref>. In this paper, we suggest tackling the fundamental problem of the TLB's insufficient capacity by improving its replacement policy.</p><p>Our work builds on prior predictive replacement policies geared toward the last-level cache (LLC), such as static rereference interval prediction (SRRIP) <ref type="bibr" target="#b0">[1]</ref>, signature-based hit prediction (SHiP) <ref type="bibr" target="#b54">[53]</ref>, and Global History Reuse Prediction (GHRP) <ref type="bibr" target="#b1">[2]</ref>, to extract key insights for the TLB. We propose a novel mechanism, Control-flow History Reuse Prediction (CHIRP), that provides superior prediction accuracy and performance by better correlating to TLB reuse behavior.</p><p>We begin with predictive policies adapted from the cache replacement literature, in particular the last-level cache (LLC), and show that they are not a good fit for TLBs. We show that features used by these schemes do not correlate well to TLB reuse, resulting in negligible performance gains. Moreover, LLC-focused prediction policies are designed with less stringent cycle time requirements and can tolerate several accesses to their prediction tables. TLBs, on the other hand, have tighter timing requirements for TLB access. Based on this and other insights, we introduce a policy that efficiently indexes prediction tables using a novel signature specifically designed to correlate to TLB behavior. We focus on the L2 TLB as L2 TLB misses account for most of the cycles spent in the TLB miss handler <ref type="bibr" target="#b42">[41]</ref>.</p><p>This paper makes the following contributions:</p><p>1) A first study and exploration of TLB replacement policies by implementing and adapting policies from previous work on data caches and branch target buffers to the TLB. 2) An intuition on why previous predictive replacement policies may or may not be as effective on TLBs. We evaluate the impact of various optimizations on adapted predictive replacement policies over a large suite of industry-sourced traces. 3) A new predictive replacement policy, Control-flow History Reuse Prediction (CHIRP). This policy indexes prediction tables using a signature specially designed to correlate with TLB behavior. It reduces L2 TLB misses by 28.21% on average over LRU, resulting in significant speedup. For example, for a page walk latency of 150 cycles, CHIRP yields a geometric mean speedup of 4.8%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. BACKGROUND</head><p>Processor performance is affected by the TLB in two ways: the number of TLB misses and the TLB miss penalty in cycles. While other solutions have mainly focused on reducing the TLB miss penalty, very little work has focused on reducing the number of misses in the TLB directly. There have been a handful of papers on prefetching into the TLB <ref type="bibr" target="#b37">[36]</ref>, <ref type="bibr" target="#b50">[49]</ref>, <ref type="bibr" target="#b51">[50]</ref>. However, to the best of our knowledge, no previous work has proposed a predictive replacement policy specifically for TLB. Rather, recent work employs LRU or Random replacement policies <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b35">[34]</ref>, <ref type="bibr" target="#b37">[36]</ref>, <ref type="bibr" target="#b38">[37]</ref>, <ref type="bibr" target="#b39">[38]</ref>, <ref type="bibr" target="#b56">[55]</ref>, <ref type="bibr" target="#b57">[56]</ref>, <ref type="bibr" target="#b58">[57]</ref>, <ref type="bibr" target="#b59">[58]</ref>, <ref type="bibr" target="#b60">[59]</ref>. We advocate using a predictive replacement policy that relies on a variety of program features to guide TLB entry replacement to improve performance without needing to increase the TLB's size.</p><p>Recent work in cache and BTB replacement shows that reuse prediction can significantly reduce misses and improve performance <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b54">[53]</ref>, <ref type="bibr" target="#b55">[54]</ref>, <ref type="bibr" target="#b61">[60]</ref>, <ref type="bibr" target="#b62">[61]</ref>, <ref type="bibr" target="#b63">[62]</ref>, <ref type="bibr" target="#b64">[63]</ref>. Predictive replacement policies attempt to predict whether a cached item will be used again before it is evicted. If not, then it is a prime candidate for eviction. This idea is superior to LRU replacement, in which a block with no near-term reuse must migrate all the way down the recency stack before being replaced. However, a highly accurate predictive replacement policy for one cachelike structure may not work for another cache-like structure. For example Mirbagheret al. <ref type="bibr" target="#b1">[2]</ref> show that while PC-based policies such as SDBP <ref type="bibr" target="#b2">[3]</ref> and SHiP <ref type="bibr" target="#b54">[53]</ref> reduce the number of dead blocks in the LLC, it is detrimental to instruction caches and BTBs. We find the same applies to TLBs.</p><p>There are three main challenges in designing a predictive replacement policy. The first is finding the microarchitectural features that correlate with reuse for a particular cache-like structure. These features vary for different structures such as the TLB and data caches, and even different applications <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b54">[53]</ref>, <ref type="bibr" target="#b55">[54]</ref>, <ref type="bibr" target="#b61">[60]</ref>, <ref type="bibr" target="#b62">[61]</ref>, <ref type="bibr" target="#b64">[63]</ref>. The second is building an efficient signature by combining the identified correlating features. The features are combined to reduce their hardware storage budget and prediction time. The third is designing a fast/low-cost prediction algorithm to use this signature. The latter is particularly important for the TLB as it lies on the critical path to a memory access.</p><p>Once we identified highly correlating features of TLB entry reuse, we adapted previous algorithms to propose a novel, low-cost algorithm specifically tailored for reuse prediction in L2 TLBs. Previous work on LLC reuse prediction that uses prediction tables has used multiple features hashed to multiple indices <ref type="bibr" target="#b2">[3]</ref> or signature <ref type="bibr" target="#b55">[54]</ref>, <ref type="bibr" target="#b64">[63]</ref> to combine several predictions into one. Because the TLB is on the critical path to accessing memory, we reduce accesses to a single table with a signature combining several features as the most latencysensitive approach.</p><p>We explore using predictive cache replacement policies such as static re-reference interval prediction (SRRIP) <ref type="bibr" target="#b0">[1]</ref>, signature-based hit prediction (SHiP) <ref type="bibr" target="#b54">[53]</ref>, and Global History Reuse Prediction (GHRP) <ref type="bibr" target="#b1">[2]</ref> for the TLB, and propose a new mechanism, Control-flow History Reuse Prediction (CHIRP), to better guide TLB entry replacement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Static Re-Reference Interval Prediction</head><p>SRRIP <ref type="bibr" target="#b0">[1]</ref> predicts which blocks will be referenced again (i.e. re-referenced) in the cache. Each block has a 2-bit rereference prediction value (RRPV) placing the block into one of four categories ranging from near-immediate re-reference to distant re-reference. A first prediction is made on block placement and revised when a block is reused or replaced. Blocks with distant re-reference prediction are evicted. If there are none, the RRPV for each block in the set is incremented until there is at least one eviction candidate. We adapt SRRIP to work with TLB entries instead of cache blocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. PC-Based Dead Block Predictors</head><p>In sampling-based Dead Block Prediction (SDBP) <ref type="bibr" target="#b2">[3]</ref>, a predictor learns the pattern of accesses and evictions from a small number of sets kept in a structure called the sampler. When a load or store accesses the LLC, the address (PC) of that instruction is hashed to index prediction tables. Counters read from the tables are summed and thresholded to predict whether the block is dead. In the original SDBP paper, blocks are predicted on each access <ref type="bibr" target="#b2">[3]</ref>. Signature-based Hit Prediction (SHiP) improves on this idea by using the prediction only for placement in a RRIP-replaced cache, reducing the number of predictions and significantly improving performance.</p><p>However, sampling is not suitable for structures indexed by instruction addresses such as the BTB and instruction cache <ref type="bibr" target="#b1">[2]</ref>. Sampling works for data caches because the behavior of a memory access instruction, represented by its PC, generalizes over the entire cache. Instruction streams do not allow set sampling to generalize the behavior of accesses to such structures since the PC itself forms the index into the structure.</p><p>We find that sampling also does not work well for secondlevel TLBs. The reason is the coarser granularity of TLB entries versus cache blocks. A PC accesses different data addresses that are in the L2 TLB, which might lead one to believe sampling should generalize across the TLB. However, in the LLC, one sampled set may map to many cache sets all accessed by the same PC, which allows behavior to be generalized across sets. On the other hand, in the L2 TLB, one PC accesses data that are mapped to much fewer TLB entries than cache blocks. Spatial locality for data accessed by a single PC does not expand beyond a few TLB entries, so generalization fails.</p><p>Because of this failure, in this work we evaluate SHiP with the same general algorithm, but with bits of PC kept as metadata in each TLB entry, which is equivalent to keeping a sampler the same size as the structure. We consider SHiP to be the best cache replacement policy from previous work that would be implementable under the tight timing requirements of the TLB access critical path.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Global History Reuse Prediction</head><p>Global History Reuse Prediction (GHRP) <ref type="bibr" target="#b1">[2]</ref> is the stateof-the-art predictive replacement policy for BTB and i-cache replacement. We adapt GHRP for TLB replacement. GHRP has a structure similar to SHiP, but the signature used to index the prediction tables is specifically designed for instruction streams. Like a branch predictor, it uses the global history of conditional branch outcomes <ref type="bibr" target="#b65">[64]</ref> as well as lower-order bits from branch addresses to form an index into a table of counters that keep track of reuse behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Offline Learning</head><p>We use insights from neural networks to design a new handcrafted feature that represents a program's control-flow history compactly and that can be used with a much simpler linear learning model. Offline training has been used for designing replacement policies in the past through using genetic algorithm by Jim?nez et al. <ref type="bibr" target="#b66">[65]</ref> and LSTM by Shi et al. <ref type="bibr" target="#b67">[66]</ref>. Their work shows how insights from offline training can improve learning model for online prediction in the LLC. We use ADALINE (ADAptive LINear Element) <ref type="bibr" target="#b68">[67]</ref>, <ref type="bibr" target="#b69">[68]</ref> to find insights for TLB replacement policy.</p><p>ADALINE uses a vector of weights that records correlations between an input vector and a target value. It can be used to classify inputs into one of two classes.</p><p>ADALINE computes the weighted sum of the input patterns</p><formula xml:id="formula_0">x(n). y(n) = w T (n)x(n) + ?</formula><p>ADALINE weights are updated after the desired outcome d(n) of the predicted event is known. If the prediction was correct then the weights remain unchanged. Otherwise, the inputs are used to update the corresponding weights.</p><formula xml:id="formula_1">w(n + 1) = w(n) + ?[d(n) -y(n)]x(n)</formula><p>where ? is the learning-rate parameter and the difference d(n)y(n) is the error signal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. CHIRP</head><p>We explored adapting predictive cache replacement policies to the TLB and observed that features that correlate well to cache reuse behavior may not necessarily correlate well to TLB reuse behavior. In contrast to a cache access, a TLB access is of coarser granularity with many PCs that map to the same TLB entry. Furthermore, depending on the context, each such PC may result in an eviction or a reuse of the same TLB entry. We find that predicting a TLB entry's reuse requires multiple features that we compose into a single signature for better prediction accuracy and overhead reduction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. THE REUSE PREDICTION PROBLEM IN TLB &amp; OUR SOLUTION</head><p>We find that predictive policies for the LLC, instruction cache, and BTB do not apply well to L2 TLBs, and describe the main reasons why in this section.</p><p>We simulated 870 workloads from a variety of categories provided publicly by Qualcomm <ref type="bibr" target="#b70">[69]</ref> to prevent overfitting to one type of workload. More information about the full details of our simulation methodology can be found in Section V.</p><p>We first applied signature-based hit prediction (SHiP) <ref type="bibr" target="#b54">[53]</ref>, which was shown to be useful in the LLC. SHiP uses only the address (PC) of the most recent instruction. However, our results show that a solely PC-based reuse entry prediction does not perform much better than LRU, giving a reduction in MPKI of only 0.88%.</p><p>We investigated whether aliasing was the cause of the observed mispredictions, but found that even with an unlimited prediction table size (i.e. no aliasing), SHiP is not able to detect dead entries in the TLB, giving a reduction in MPKI of only 0.63%. Since prediction table size was not the source of the mispredictions, we further investigated by limiting the prediction to only a subset of the TLB sets and used LRU for the rest. This technique also just slightly improves accuracy, reducing MPKI by 1.28%, leading to the following observation:</p><p>Observation 1: The inaccuracy in previous predictive policies for the TLB is not due to conflicts among multiple sets but rather within the sets themselves.</p><p>We find that a TLB entry may experience many hits from one or more PCs that map to the same entry before it is eventually evicted. This is because a larger range of unique addresses map to the same entry in the TLB compared to accesses to a block in a cache. Indeed, there is a nearly two order-of-magnitude difference between a 4KB page and a 64B block.</p><p>Therefore, we obtain our second observation: Observation 2: The coarse-grained nature of TLB accesses results in increased aliasing in previous predictive policies, which cause the prediction counters to saturate too quickly, rendering the predictor ineffective.</p><p>From Observation 2 we posit that in order to dissipate this noise, we need to slow down the rate at which the prediction counters are updated. We do this by limiting updates only to hits of a TLB set different from the one last accessed. We call this method Selective Hit Update. Selective Hit Update improves accuracy by reducing average MPKI by 5.85%.</p><p>Previous work <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b67">[66]</ref> has shown that a longer history of past PCs would benefit predictive replacement policies in the LLC and i-cache. Figure <ref type="figure" target="#fig_0">2</ref> shows our results conducting a similar study for the TLB. Here, we analyze varying PC history lengths from 4 to 40 and their resulting speedups. We find that the benefits of using longer global PC history for TLB reuse prediction diminishes beyond a length of 15. This contrasts with prior work on predictive policies for the LLC, which show benefits of using global PC history length of 60 or more. This is likely due to the coarse-grain nature of TLB accesses that may limit the global history window from capturing enough information pertaining to TLB reuse. To improve on this, we augment the global PC history with branch path history information, resulting in a history length greater than 30 (Figure <ref type="figure" target="#fig_0">2</ref>). Hence, our third observation is as follows:</p><p>Observation 3: TLB reuse prediction does not benefit from a global PC history of length 15 or more. However, by combining branch path history into a prediction signature, CHIRP can take advantage of a PC history length of 30 or more. Branch history is effective because L2 TLB accesses come from both data and instructions in the first-level TLBs. Conditional branch histories can reflect the data accesses when global path history does not. Branch path history can also reveal high-level program semantics that also contribute to TLB misses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. PC Bits Carry Uneven Weights</head><p>Previous work <ref type="bibr" target="#b66">[65]</ref>, <ref type="bibr" target="#b67">[66]</ref> shows that certain features from program behavior are important to predicting reuse of a block in the LLC. We come to the same conclusion with regard to TLBs, recognizing that some bits of the PC carry more weight than others in reuse prediction. To show this for the case of TLBs, we use the weights of a trained ADALINE neural network to score the bits of PCs that we incorporate into the global history. The idea is based on the principle that the weights of the input nodes corresponding to less important features are expected to be smaller in trained ADALINE networks. The incorporation of appropriate regularization terms in the ADALINE update function encourages such weights to converge to zero and ultimately be eliminated.</p><p>Figure <ref type="figure" target="#fig_1">3</ref> shows that the two lower-order bits of a PC address (bits 2 and 3) contain important information, as indicated by their higher-weight color values. Thus, passing on these bits to the signature function yields a high chance of preserving information to reduce aliasing. In our proposed CHIRP policy described in Section IV, we keep these two correlated bits in the global path history.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Modeling Efficient Signatures</head><p>Aliasing in the prediction table is harder to solve in the TLB than caches. With TLB reuse prediction, far too many PCs map to the same TLB entry, i.e., 64 times more than to a cache block. The problem of aliasing is exacerbated further with large footprint applications.</p><p>If a counter in the prediction table changes direction frequently due to aliasing, the same problem will only be exacerbated with a smaller table size. To achieve high reuse prediction accuracy with a smaller table size, we have to solve aliasing first.</p><p>This problem can be addressed by coordinating how the input bits are transformed by designing a succinct signature. We found that employing shifting and scaling techniques as described by Lecun and Hinton <ref type="bibr" target="#b71">[70]</ref>, <ref type="bibr" target="#b72">[71]</ref> improves prediction accuracy.</p><p>We accomplished this by injecting and shifting leading zeros into specific bit positions of different components of the signature including the global path history, conditional branch history, indirect branch history, and the shifted PC of the access (section IV).</p><p>Doing this both shifts the individual PCs and scales the less salient history bits down to make them less visible to the learning process, allowing the prediction table to converge to an accurate counter value with 3 times fewer entries than GHRP.</p><p>The above techniques of shifting and scaling the signature bits are simple to implement in hardware and provide significant reduction in TLB MPKI. Figure <ref type="figure">6</ref> shows that while adding conditional branch path history to the signature would reduce MPKI by 23.88%, adding two leading zeros in the path history would allow the effect of conditional branch history to reduce MPKI by 26.98%.</p><p>In the next section we discuss our signature function and the individual effect of above optimizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONTROL-FLOW HISTORY REUSE PREDICTION ALGORITHM</head><p>A. Overview CHIRP correlates TLB replacement with reuse history. CHIRP uses features that best correlate to reuse behavior and combines them into a signature that is used to uniquely tag each TLB entry (IV-B).</p><p>This signature is subsequently used to track the reuse behavior of the associated TLB entry by means of a prediction table indexed by the signature (IV-C). The prediction table is updated on an eviction or a reuse, and the resulting prediction status is written back into the corresponding TLB entry to inform the next TLB replacement operation (IV-D). Figure <ref type="figure" target="#fig_2">4</ref> describes the main components of CHIRP and Algorithm 5 provides the CHIRP algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. CHIRP Signature</head><p>CHIRP contributes four features that correlate with reuse behavior. The first is the global path history of PCs. The global path history in CHIRP is 64 bits wide and is updated on each access by shifting the two lower-order bits of the PC into the path history, followed by two zero bits (Figure <ref type="figure" target="#fig_3">5</ref>, line 28), as previously discussed in subsections III-A and III-B, respectively. The global path history in CHIRP allows recording the last 16 accesses.</p><p>The second and third features are the conditional and unconditional indirect branch address history, respectively. Each of these histories is 64 bits and is updated by shifting the eight bits of the PC <ref type="bibr">[11:4]</ref> into the branch history on every conditional (resp. unconditional indirect) branch instruction (Algorithm 5, line 31.), recording the last 8 branch accesses for each type.</p><p>The fourth feature is the current PC, shifted right by two bits. The signature is constructed by XOR-ing the global path history with the conditional branch history, the unconditional indirect branch history, and the shifted PC of the access (Figure <ref type="figure" target="#fig_3">5</ref>, line 5).</p><p>To compute indices into the prediction table, CHIRP computes a 16-bit hash of the constructed signature. For hashing, we first use Robert Jenkins' 64-bit mix function <ref type="bibr" target="#b73">[72]</ref>. The mix function enables a single-bit change in the key to influence widely disparate bits in the hash result. We then </p><formula xml:id="formula_2">sign ? VA?2 ? pathHist ? condBrHist ? unCondBrHist 6:</formula><p>index ? Hash(sign) mod 2 16   7:</p><formula xml:id="formula_3">cntrNew ? predTable[index] 8: if isMissed = true then miss 9:</formula><p>entry ? victimEntry(set)  take the modulo of the table size to generate the hash table index(Figure <ref type="figure" target="#fig_3">5</ref>, line 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>predTable[index]--</head><p>Note that the signature relies on bits from the branch PC, not conditional branch outcomes or bits from branch targets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. CHIRP Prediction Table</head><p>CHIRP stores metadata for each L2 TLB entry, consisting of 3 LRU stack position bits, a valid bit, a 16-bit signature and a prediction bit (See Figure <ref type="figure" target="#fig_2">4</ref>, Updating TLB Metadata). CHIRP uses a table of saturating counters to provide a prediction. The table is indexed by a hash function of the signature. The corresponding counter is thresholded, and if the counter exceeds the threshold, the entry is predicted as dead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. CHIRP Operations</head><p>In contrast to SHiP and GHRP that require updating the prediction table on each TLB access, the bulk of CHIRP operations occurs off the TLB critical path, with minimal impact to TLB latency. In particular, CHIRP updates its prediction table on a TLB miss only if the selected victim is LRU (i.e. no dead entry is found).</p><p>The operations pertaining to a TLB miss involve (1) selecting a victim, (2) updating the victim's reuse history in the prediction table if the victim is LRU, and (3) updating the prediction metadata for the new TLB entry.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>a) Victim selection</head><p>On a TLB miss, CHIRP first attempts to select a victim among the entries predicted as dead. If no such entry is found, CHIRP evicts the LRU entry (Figure <ref type="figure" target="#fig_3">5</ref>, line 37).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>b) Prediction table update</head><p>Because CHIRP updates its prediction table only if the victim is LRU (Figure <ref type="figure" target="#fig_3">5</ref>, line 10 -12), evicting the LRU entry effectively makes it a dead candidate the next time around. This justifies why the prediction table needs be updated. The signature of the victim entry is used to index the prediction table and the corresponding counter is incremented, since the entry was just shown to be dead (Figure <ref type="figure" target="#fig_3">5</ref>, line 41).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>c) Prediction metadata update</head><p>After the new entry is inserted into the TLB, its CHIRP metadata is updated to inform CHIRP of the next replacement decision. First, the signature of the new entry is used to index the prediction table and then the corresponding counter is read out (Figure <ref type="figure" target="#fig_3">5</ref>, line 6). The counter value is thresholded and used to decide if the incoming entry should be predicted dead or live in the future. The resulting prediction status is then used to update the prediction bit in the CHIRP metadata.</p><p>On a TLB hit CHIRP updates its prediction table only if the current access is the first hit to the TLB entry line 16). These optimizations improve both performance and energy as they reduce the frequency of access to the CHIRP prediction table to only 10.14% of all TLB accesses (Figure <ref type="figure" target="#fig_8">11</ref>). In addition, for smaller prediction tables, they prove very effective at improving MPKI by reducing aliasing (Figure <ref type="figure">9</ref>). These optimizations and results are discussed in detail in Section VI).</p><p>A TLB hit (Figure <ref type="figure" target="#fig_3">5</ref>, line 14) involves the following operations:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>d) Prediction table update</head><p>On a hit the prediction table is accessed only on the first access or reuse (Figure <ref type="figure" target="#fig_3">5</ref>, line 16). The old signature in the entry (Figure <ref type="figure" target="#fig_3">5</ref>, line 17) is used to index the prediction table and the corresponding counter is then decremented to assure this entry will be predicted as live under the same conditions in the future (Figure <ref type="figure" target="#fig_3">5</ref>, lines 18 and 41). Then the old signature is replaced with the new one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>e) Prediction metadata update</head><p>The new signature of the hitting entry is used to index the prediction table and then the corresponding counter is read out. The counter value is thresholded and used to decide if that entry should be predicted dead or live in the future. The resulting prediction status is then used to update the prediction bit in the CHIRP metadata. Figure <ref type="figure" target="#fig_3">5</ref> summarizes the steps taken during a TLB hit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Adapting Training Algorithm for TLB</head><p>Access to a TLB reuse predictor must be fast and energy efficient, as the TLB is on the critical path to accessing memory. Thus, we are motivated to minimize the number of updates made to prediction structures. We find that two specific events are sufficient for an accurate training update:</p><p>? The first hit of an entry.</p><p>? A miss in a set with no dead entry (this leads the algorithm to choose an entry to evict based on LRU.) With this technique, CHIRP reduces the access ratio to the prediction tables by 90% compared to SHiP and GHRP (see Figure <ref type="figure" target="#fig_8">11</ref>), which must access tables on every access to the TLB.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Component Size</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. METHODOLOGY</head><p>To implement and test CHIRP, we use the simulator and traces released for the recent Championship Value Prediction Competition (CVP1) <ref type="bibr" target="#b70">[69]</ref>. There are hundreds of traces available (of which we use 870), coming from a variety of workload categories of interest to Qualcomm who provided them. In particular, the workloads come from the team working on their (now defunct) server project. The traces contain SPEC, database, crypto, scientific, web, "big data" and other applications, many of which exhibit interesting address translation behavior. The traces contain very detailed information such as instruction type, register values, effective addresses of loads and stores, and data values, making them suitable to drive a performance simulator. Short traces are simulated completely, while long traces are allowed to run for 100 million instructions. To measure the performance numbers we built a timing-approximate performance model similar to previous work <ref type="bibr" target="#b38">[37]</ref>.</p><p>Our model simulates first-order sources of processor latency such as the memory hierarchy composed of L1 i-TLB and L1 d-TLB, L1 i-cache, L1 d-cache, L2 and L3 unified caches, DRAM, a branch prediction unit that includes an indirect branch predictor, a conditional branch predictor with branch target buffer, and an in-order pipeline model. We use a hashed perceptron predictor as the branch direction predictor <ref type="bibr" target="#b74">[73]</ref>.</p><p>We measure misses per 1000 instructions (MPKI) as well as instructions per cycle (IPC) based on the simulated microarchitecture across a variety of page table walk latencies derived from previous work. A recent reverse engineering study on TLB <ref type="bibr" target="#b28">[27]</ref> reported a range of L2 TLB miss penalties for Intel microarchitecture: 230 cycles for Coffeelake, 272 cycles for BroadwellXeon, 212 cycles for Skylake and 18 cycles for Haswell. A related study on TLBs, Li et al. <ref type="bibr" target="#b11">[12]</ref>, uses 150 cycles for L2 TLB miss penalties. We measure speedup for a range of 20 to 340 cycles page walk latencies, shown in Figure <ref type="figure" target="#fig_7">10</ref>.</p><p>We model static re-reference interval prediction (SRRIP), signature-based hit prediction (SHiP), global history reuse prediction (GHRP) and control-flow history reuse prediction (CHIRP). CHiRP keeps metadata for each L2 TLB entry. CHiRP also uses one prediction table. Each of the entries in the table contains a two bit counter. The additional metadata for each entry consists of 1 prediction bit, 3 bits to maintain LRU positions, and 16 bits of signature. Table-I summarizes the storage requirements for CHiRP for a 1024-entry 4KB page size L2 TLB with 8-way associativity.</p><p>We assume a 4KB page size similar to previous work <ref type="bibr" target="#b11">[12]</ref>. Large pages are supported in current microarchitectures, e.g. Intel's Skylake supports page sizes of 4KB, 2MB, 4MB, and 1GB. Large pages can reduce capacity misses in TLBs when program behavior exhibits high locality. However, 4KB pages are still the norm for most mobile and desktop operating systems, providing a good balance between impact of page faults for workloads with good locality and impact of fragmentation for workloads with poor locality. It would be easy to say, "just use large pages" but the performance of legacy systems, mobile apps, cloud computing workloads, etc. that continue to use 4KB pages matters to users of those systems.</p><p>The complexity of variable-sized TLB entries (as compared to fixed-sized lines in cache replacement) further complicates efforts to improve TLB replacement. Entries for different sized pages share the L2 TLB; as the L2 TLB is built for capacity, it is not partitioned among page sizes.</p><p>Reasoning about how to do replacement with a mix of page sizes is an interesting problem we plan to tackle in future work; imagine, when one entry covers 4KB and another covers 2MB, which one is is more important to keep? It is no longer a matter of pure replacement in the sense of trying to achieve B?l?dy's optimal result <ref type="bibr" target="#b75">[74]</ref>, but now requires taking into account the different costs of replacing different sized entries <ref type="bibr" target="#b76">[75]</ref>, <ref type="bibr" target="#b77">[76]</ref>, <ref type="bibr" target="#b78">[77]</ref>, <ref type="bibr" target="#b79">[78]</ref>. This question is beyond the scope of this initial study. In addition, large pages' susceptibility to memory fragmentation requires simulating traces with varying levels of known fragmentation behavior, complicating an already complex issue. We hope this initial work invites the community to consider and tackle the problem of TLB replacement further from the surface work seen so far. Thus, in this initial study of predictive replacement policies for TLBs, we focus on the standard 4KB page size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. RESULTS</head><p>In this section, we describe the results of experiments simulating the CHIRP policy and demonstrate its superior over policies used in previous work. Results with a range of hardware budgets are presented. In the absence of public data about L2 TLB size, our calculation accounts only for tag, physical page number, replacement metadata, protection bits, valid bit, and ASID, estimating 118 bits for a TLB entry, giving 14.75KB for a 1024-entry TLB. A 6% TLB overhead places CHiRP overhead of 1KB, which still offers a 28% MPKI improvement (see Figure <ref type="figure">9</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. MPKI Results</head><p>Figure <ref type="figure">7</ref> shows an S-curve of MPKIs for 870 benchmarks. The x-axis shows the benchmarks in order of sorted MPKI for LRU and is compared with other policies. Insets highlight key areas of the graph.</p><p>LRU and Random yield an average 1.51 and 1.47 MPKI, respectively. SRRIP, which uses a simple static prediction on each TLB entry placement and has a lower cost than LRU, yields 1.35 MPKI, a 10.36% improvement over LRU. SHiP, a PC-based reuse predictor, gives an average 1.50 MPKI, performing almost the same as LRU with 0.88% improvement. GHRP, which uses a more detailed prediction signature, yields an average 1.37 MPKI, or a 9.03% reduction in misses over LRU. CHIRP, with a signature specially designed for TLB replacement, gives an average MPKI of 1.08% an improvement of 28.21% over LRU. Nearly all of the tested benchmarks exhibit considerable MPKI reduction under CHIRP, achieving an improvement of 58.93% in some cases.</p><p>These results demonstrate that the case for LRU as a TLB replacement policy is weak, as even Random replacement slightly outperforms it. SRRIP, which is a simpler and lowoverhead policy, could more conveniently be deployed in current processors, yielding better performance. CHIRP is somewhat more complex but yields the best improvement, more than double the improvement provided by SRRIP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Accesses to Prediction Table</head><p>Predictive replacement policies often access tables of counters to make a prediction. Previous work on cache and BTB replacement policies read out from the tables on every access to the cache/BTB to make a prediction for the next access. The tables are also modified frequently as counters are updated.</p><p>CHIRP only accesses the prediction table on a TLB miss or on a hit to a TLB set different than the one accessed last, following our selective hit update policy. It follows from this that consecutive hits to the same set do not result in writing or reading from the prediction table but only updates to the signature in the TLB entry. Updating the signature bits in the TLB entry has the same overhead as an LRU stack update. Thus, the energy and timing properties of CHIRP are considerably more favorable to implementation than techniques based on previous predictive replacement policies.</p><p>Figure <ref type="figure" target="#fig_8">11</ref> shows a density plot of the rate of the number of accesses to prediction table over accesses to the TLB for SHiP, GHRP and CHIRP. The plot shows the distribution of access rates over all the benchmarks. For SHiP and GHRP, the access rate has a very high variance, reaching over 100% in many cases. The rate can exceed 100% because, for every TLB access, there could be two accesses to the prediction table: one to read out the prediction, and another to update the table for training. For CHIRP the access rate is quite low, and has low variance, making for a far more practical policy for implementation. On average CHIRP accesses the prediction table for 10.14% of the accesses to L2 TLB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Speedup</head><p>Figure <ref type="figure" target="#fig_5">8</ref> shows speedup for various policies with TLB miss penalty of 150 cycles. Page walk latency depends on several microarchitectural and software parameters. Thus, we explore a range of L2 TLB miss penalties to provide an estimate of performance under different assumptions. With TLB miss penalty of 150 cycles, CHIRP improves performance by 4.80% compared to 0.42% for Random, 1.65% for SRRIP, 0.13% for SHiP, and 0.94% for GHRP. At higher latencies, the advantage of predictive policies grows. With a penalty of 320 cycles, representing more memory intensive behaviors, CHIRP provides a speedup of over 10%. Other predictive replacement policies do not provide significant speedup. Clearly, CHIRP provides significant improvement to performance over all other replacement policies. </p><formula xml:id="formula_4">G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G -</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. TLB Efficiency</head><p>Cache efficiency is the average amount of time in which a block was live in the cache. We calculate cache efficiency <ref type="bibr" target="#b80">[79]</ref> for TLB entries instead of cache blocks. Figure <ref type="figure">1</ref> depicts cache efficiency for the L2 TLB for 870 benchmarks. Each row is the cache efficiency of one benchmark for various policies scaled by LRU. Benchmarks are sorted from low to high cache efficiency from down to up respectively. Figure <ref type="figure">1</ref> shows Random helps improve the cache efficiency of some benchmarks (most which had high efficiency already) but CHIRP removes most of the dead entries in TLB for all 870 benchmarks. CHIRP improves average cache efficiency over 870 traces by 8.07% compared to LRU. This number is 2.92% for GHRP, 1.85% for SHiP, 2.84% for SRRIP, and 3.10% for Random. Thus, the MPKI improvement in CHIRP comes from reducing dead entries and increasing live entries in the TLB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Complexity and Efficiency</head><p>Note that CHIRP is more complex than simple replacement policies such as LRU and RRIP. However, it is far less complex than, for example, branch prediction techniques such as TAGE <ref type="bibr" target="#b81">[80]</ref> and perceptron <ref type="bibr" target="#b82">[81]</ref> that have been implemented in recent processors. These predictors require far more logic, dynamic energy, and state than CHIRP and have tighter timing constraints. Thus, we believe the complexity of CHIRP is very manageable given its benefits to front-end performance.</p><p>Consistent with branch predictor implementation, CHIRP only updates the tables of counters at commit with right-path branches to prevent pollution of the tables. For misprediction recovery, CHIRP maintains two path histories: the speculative history updated using the outcome of the branch predictor, and a non-speculative history updated when a branch commits.</p><p>The energy overhead of predictive policies results from accesses to the prediction table and updating respective metadata in the TLB entry. Because CHIRP reduces the number of accesses to the prediction table by 90% compared to previous predictive policies (e.g. SHiP and GHRP), energy consumption related to accessing the tables should be less of a concern (Figure <ref type="figure">7</ref>).</p><p>CHIRP requires more accesses to the prediction metadata in the TLB compared to SHiP. While SHiP only updates metadata at insertion time, CHiRP updates the signature in the TLB during both hit and insertion. CHIRPupdates the metadata in the same manner as updating LRU bits. While SHiP cannot perform better than LRU for the L2 TLB, updating the metadata on every access is the cost for an accurate predictor.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Impact of Predictor Size</head><p>Figure <ref type="figure">9</ref> shows MPKI improvement over LRU for CHIRP with a range of prediction table sizes. The size of the prediction table has an impact on area, energy, and timing, so we would like to choose a size that yields a good improvement while maintaining a reasonable cost. At a very small hardware budget of 128B, we note that even though we may experience higher conflicts rate in the prediction table, CHIRP still yields up to 7% MPKI improvement over LRU. As we double the prediction table size to 256B and 512B, the MPKI improvement increases to up to 20% and 22%, respectively. What this shows is that even with a small hardware budget size of 256B, CHIRP doubles the MPKI improvement realized by an 8K GHRP (9%). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Performance Gain</head><p>This first study focuses on single core. IPC gains in each generation are usually within 10-15%, of which 20-40% might come from the front-end (2-4% overall), which is considered aggressive. A 4.8% improvement over LRU is a significant milestone in this case. Figure <ref type="figure" target="#fig_8">11</ref> shows the speedup for CHIRP is statistically significant over 870 workloads assuming a TLB miss penalty of 150 cycles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. Area Overhead vs. Performance</head><p>CHIRP reduces hardware overhead by two-thirds compared to GHRP because the signature formula enables CHIRP to use one prediction table rather than the three needed by GHRP. The predictor cost was evaluated for a range of extra overhead. Figure <ref type="figure">9</ref> shows even a small 256B predictor leads to a 20% MPKI reduction. As a matter of comparison, a recent study from Intel <ref type="bibr" target="#b83">[82]</ref> demonstrates a branch prediction technique that costs 64KB hardware overhead improves IPC by 2.7%. CHIRP for a TLB with 1KB overhead and 4.80% speedup is 13? more efficient in terms of speedup-per-KB overhead. This is due to the high TLB page walk latency compared to other miss penalties in the pipeline. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Reuse Prediction</head><p>This paper proposes reuse prediction for TLB replacement. However, reuse prediction has a long history in the literature. Caches often retain dead blocks, i.e. blocks in the cache that will not be used again until they are evicted <ref type="bibr" target="#b61">[60]</ref>. Dead blocks waste space and energy in the cache. Lai et al. initially proposed dead block prediction <ref type="bibr" target="#b61">[60]</ref> to prefetch data into predicted dead blocks. Kharbutli et al. propose a counter-based dead block prediction approach <ref type="bibr" target="#b84">[83]</ref> for replacement and bypass. Liu et al. <ref type="bibr" target="#b85">[84]</ref> propose a predictor leveraging the burst-like nature of accesses to the L1 cache. Teran et al. propose using perceptron learning for reuse prediction <ref type="bibr" target="#b55">[54]</ref>, <ref type="bibr" target="#b64">[63]</ref>.</p><p>Dead block prediction has been evaluated in the context of making replacement decisions in the L1 data cache <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b54">[53]</ref>, <ref type="bibr" target="#b55">[54]</ref>, <ref type="bibr" target="#b61">[60]</ref>, <ref type="bibr" target="#b64">[63]</ref>, <ref type="bibr" target="#b85">[84]</ref>, last-level cache <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b85">[84]</ref>, <ref type="bibr" target="#b86">[85]</ref>, prefetching <ref type="bibr" target="#b61">[60]</ref>, <ref type="bibr" target="#b87">[86]</ref>, bypassing <ref type="bibr" target="#b88">[87]</ref>, <ref type="bibr" target="#b89">[88]</ref>, <ref type="bibr" target="#b90">[89]</ref>, <ref type="bibr" target="#b91">[90]</ref>, <ref type="bibr" target="#b92">[91]</ref>, <ref type="bibr" target="#b93">[92]</ref>, <ref type="bibr" target="#b94">[93]</ref>, <ref type="bibr" target="#b95">[94]</ref>, <ref type="bibr" target="#b96">[95]</ref>, <ref type="bibr" target="#b97">[96]</ref>, <ref type="bibr" target="#b98">[97]</ref>, <ref type="bibr" target="#b99">[98]</ref>, <ref type="bibr" target="#b100">[99]</ref>, power reduction <ref type="bibr" target="#b101">[100]</ref>, <ref type="bibr" target="#b102">[101]</ref>, and cache coherence protocol optimization <ref type="bibr" target="#b103">[102]</ref>, <ref type="bibr" target="#b104">[103]</ref>, <ref type="bibr" target="#b105">[104]</ref>. However, no replacement policy has been proposed for the TLB based on dead block prediction. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Translation Lookaside Buffers</head><p>Previous work shows that superpages, i.e. any page size larger than the default, can increase TLB reach and reduce TLB misses. Large pages are especially beneficial for applications with a hard upper bound of memory usage in terms of maximal heap size <ref type="bibr" target="#b44">[43]</ref>, <ref type="bibr" target="#b45">[44]</ref>, <ref type="bibr" target="#b46">[45]</ref>, <ref type="bibr" target="#b48">[47]</ref>, <ref type="bibr" target="#b49">[48]</ref>, <ref type="bibr" target="#b106">[105]</ref>, <ref type="bibr" target="#b107">[106]</ref>. Still, Peng et al. <ref type="bibr" target="#b44">[43]</ref> show that while superpages can remove nearly all the TLB miss overhead of some benchmarks, an increased page size of 1MB cannot cover the working set of some benchmarks due to unpredictable memory access patterns. If memory access patterns are predictable, TLB misses can be reduced through prefetching and speculation <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b35">[34]</ref>, <ref type="bibr" target="#b50">[49]</ref>, <ref type="bibr" target="#b51">[50]</ref>, <ref type="bibr" target="#b52">[51]</ref>.</p><p>Conversely, using superpages may unnecessarily increase the memory footprint of an application, resulting in elevated, but useless, paging traffic and memory allocation. Additionally, handling multiple page sizes increases complexity in the operating system <ref type="bibr" target="#b45">[44]</ref>, <ref type="bibr" target="#b46">[45]</ref>, <ref type="bibr" target="#b47">[46]</ref>, <ref type="bibr" target="#b48">[47]</ref>, <ref type="bibr" target="#b108">[107]</ref>, <ref type="bibr" target="#b109">[108]</ref>. Algorithms to evaluate the need for larger pages based on applications' behavior are essential for choosing the appropriate page size. Techniques for mapping multiple smaller pages into a single superpage TLB entry <ref type="bibr" target="#b38">[37]</ref>, <ref type="bibr" target="#b46">[45]</ref>, <ref type="bibr" target="#b57">[56]</ref>, <ref type="bibr" target="#b58">[57]</ref>, <ref type="bibr" target="#b110">[109]</ref> reduce splintering and make superpage usage more efficient, but require deep OS-hardware co-design.</p><p>With the prevalence of chip multiprocessors (CMPs) and parallel workloads, recent TLB work has focused on distributed TLBs in architectures. Cooperative TLB <ref type="bibr" target="#b37">[36]</ref>, <ref type="bibr" target="#b111">[110]</ref> and shared last-level TLB <ref type="bibr" target="#b40">[39]</ref>, <ref type="bibr" target="#b52">[51]</ref>, <ref type="bibr" target="#b56">[55]</ref> schemes have been proposed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSIONS AND FUTURE WORK</head><p>This paper extensively investigated the replacement policy of TLBs, which has been rarely studied in previous work. In the past, the only way to provide a predictive policy for larger cache structures was to use a sampling method. We show that sampling does not work in the L2 TLB. The idea of sampling is to generalize learning over sets; we used the granularity of L2 TLB entries to generalize learning instead of sampling. Prior work does not recognize the effect of the granularity of a structure on sampling and dead block prediction. The signatures of previous policies do not detect dead blocks in the L2 TLB. Because they do not follow control flow, it was impossible for them to learn the reuse patterns in the L2 TLB properly. They end up averaging over traces, whereas we present a specific signature that tracks the trace of dead blocks in a large granularity environment while minimizing the prediction counters' fluctuations. That allows CHiRP to use a small table with fast convergence, providing a predictive replacement policy that fits into constraints of the L2 TLB for the first time. In future work we plan to extend CHIRP to TLBs with mixed page sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IX. ACKNOWLEDGEMENT</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Speedup does not increase for global PC history length more than 15. However, combining branch history into signature, CHIRP can benefit from history lengths longer than 30.</figDesc><graphic url="image-2.png" coords="4,302.61,332.63,260.03,162.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Each row represents an offline-trained ADALINE weight vector for one benchmark. The x-axis shows the PC bit used as input. The white boxes show reuse prediction in TLB entries is strongly correlated with bits 2 and bit 3 of the PC.</figDesc><graphic url="image-3.png" coords="5,53.77,68.61,275.20,183.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig.4. CHIRP TLB metadata and prediction table update flow using a signature.</figDesc><graphic url="image-7.png" coords="6,109.39,156.49,196.95,58.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. CHIRP algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .Fig. 7 .</head><label>67</label><figDesc>Fig.6. Effect of correlating features, transforming input, shifting PC bits and scaling, signature formula and prediction table update policies on reducing misses in the L2 TLB. The x-axis is the reduction rate of average MPKI over 870 traces over a baseline LRU. Previous predictive replacement policies need specific optimizations to work for L2 TLB. Results show the advantage of CHIRP. p p g</figDesc><graphic url="image-9.png" coords="9,53.86,95.90,134.65,100.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Speedup for 870 traces.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Average Speedup for a range of L2 TLB miss penalties over 870 traces.</figDesc><graphic url="image-19.png" coords="11,77.70,233.40,198.39,198.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Density plot for rate of accesses to prediction table over accesses to TLB for SHiP, GHRP and CHIRP with mean values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I STORAGE</head><label>I</label><figDesc>OVERHEAD OF CHIRP FOR A 1024 ENTRY, 8-WAY L2 TLB WITH 4KB PAGES.</figDesc><table><row><cell>Processor</cell><cell>Parameter</cell></row><row><cell>L1 i-Cache</cell><cell>64KB, 8 way, 4 cycles</cell></row><row><cell>L1 d-Cache</cell><cell>64KB, 8 way, 4 cycles</cell></row><row><cell cols="2">L2 Unified Cache 256KB, 16 way, 12 cycles</cell></row><row><cell>L3 Unified Cache</cell><cell>8MB, 16 way, 42 cycles</cell></row><row><cell>DRAM</cell><cell>240 cycles</cell></row><row><cell>Branch Predictor</cell><cell>Hashed perceptron, 4K</cell></row><row><cell></cell><cell>entry BTB, 20 cycle</cell></row><row><cell></cell><cell>miss penalty</cell></row><row><cell>L1 i-TLB</cell><cell>64 entry, 8 way, 1 cycle</cell></row><row><cell>L1 d-TLB</cell><cell>64 entry, 8 way, 1 cycle</cell></row><row><cell>L2 Unified TLB</cell><cell>1024 entries, 8 way,</cell></row><row><cell></cell><cell>8 cycle hit latency, 20 to</cell></row><row><cell></cell><cell>360 cycle miss penalty</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Table Size MPKI Improvement (%) CHiRP with a range of prediction table size Fig. 9. MPKI improvement over LRU for CHIRP with a range of prediction table sizes.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Table sizes of 1K and 2K yield similar improvement: about 28% MPKI reduction; our main results are presented with a 1K budget. Gains realized by larger table sizes are higher, but come with larger area overhead.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The new generation of Intel processors, Sunny Cove<ref type="bibr" target="#b32">[31]</ref>, introduced 5-levels radix page tabling.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>Authorized licensed use limited to: Carleton University. Downloaded on May 30,2021 at 06:53:41 UTC from IEEE Xplore. Restrictions apply.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>We thank <rs type="person">Jeffrey N. Collins</rs> and <rs type="person">Andrew Worthen</rs> for their help and comments during the drafting of this paper. This research was supported by <rs type="funder">NSF</rs> grants <rs type="grantNumber">CCF-1912617</rs>, <rs type="grantNumber">CNS-1938064</rs>, and <rs type="grantNumber">CCF-1332598</rs> as well as generous gifts from <rs type="funder">Intel Labs</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_qxkhqAb">
					<idno type="grant-number">CCF-1912617</idno>
				</org>
				<org type="funding" xml:id="_edhUgBg">
					<idno type="grant-number">CNS-1938064</idno>
				</org>
				<org type="funding" xml:id="_EgRETVv">
					<idno type="grant-number">CCF-1332598</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">High performance cache replacement using re-reference interval prediction (rrip)</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jaleel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Theobald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Steely</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Emer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="60" to="71" />
			<date type="published" when="2010">2010</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Exploring predictive replacement policies for instruction cache and branch target buffer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirbagher-Ajorpaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Garza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jindal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jim?nez</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISCA.2018.00050</idno>
		<ptr target="https://doi.org/10.1109/ISCA.2018.00050" />
	</analytic>
	<monogr>
		<title level="m">45th ACM/IEEE Annual International Symposium on Computer Architecture, ISCA 2018</title>
		<meeting><address><addrLine>Los Angeles, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">June 1-6, 2018, 2018</date>
			<biblScope unit="page" from="519" to="532" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Sampling dead block prediction for last-level caches</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jim?nez</surname></persName>
		</author>
		<editor>MICRO</editor>
		<imprint>
			<date type="published" when="2010-12">December 2010</date>
			<biblScope unit="page" from="175" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Reducing tlb power requirements</title>
		<author>
			<persName><forename type="first">T</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Navarro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 1997 International Symposium on Low Power Electronics and Design</title>
		<meeting>1997 International Symposium on Low Power Electronics and Design</meeting>
		<imprint>
			<date type="published" when="1997-08">Aug 1997</date>
			<biblScope unit="page" from="196" to="201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generating physical addresses directly for saving instruction tlb energy</title>
		<author>
			<persName><forename type="first">I</forename><surname>Kadayif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sivasubramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kandiraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">35th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2002-11">2002. Nov 2002</date>
			<biblScope unit="page" from="185" to="196" />
		</imprint>
	</monogr>
	<note>Proceedings.</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Compilerdirected physical address generation for reducing dtlb power</title>
		<author>
			<persName><forename type="first">I</forename><surname>Kadayif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sivasubramaniam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on -ISPASS Performance Analysis of Systems and Software</title>
		<imprint>
			<date type="published" when="2004-03">2004. March 2004</date>
			<biblScope unit="page" from="161" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An energy efficient tlb design methodology</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Gao</surname></persName>
		</author>
		<idno type="DOI">10.1145/1077603.1077688</idno>
		<ptr target="http://doi.acm.org/10.1145/1077603.1077688" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 International Symposium on Low Power Electronics and Design, ser. ISLPED &apos;05</title>
		<meeting>the 2005 International Symposium on Low Power Electronics and Design, ser. ISLPED &apos;05<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="351" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Accelerating two-dimensional page walks for virtualized systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Serebrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Spadini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Manne</surname></persName>
		</author>
		<idno type="DOI">10.1145/1346281.1346286</idno>
		<ptr target="http://doi.acm.org/10.1145/1346281.1346286" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS XIII</title>
		<meeting>the 13th International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS XIII<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="26" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Translation caching: Skip, don&apos;t walk (the page table)</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rixner</surname></persName>
		</author>
		<idno type="DOI">10.1145/1816038.1815970</idno>
		<ptr target="http://doi.acm.org/10.1145/1816038.1815970" />
	</analytic>
	<monogr>
		<title level="j">SIGARCH Comput. Archit. News</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="48" to="59" />
			<date type="published" when="2010-06">June 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Spectlb: A mechanism for speculative address translation</title>
		<idno type="DOI">10.1145/2024723.2000101</idno>
		<ptr target="http://doi.acm.org/10.1145/2024723.2000101" />
	</analytic>
	<monogr>
		<title level="s">SIGARCH Comput. Archit. News</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="307" to="318" />
			<date type="published" when="2011-06">June 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Race to exascale: Opportunities and challenges</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sodani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Keynote at the 44th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Ps-tlb: Leveraging page classification information for fast, scalable and efficient translation for future cmps</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Melhem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACO</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">21</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Efficient memory virtualization: Reducing dimensionality of nested page walks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
		</author>
		<idno type="DOI">10.1109/MICRO.2014.37</idno>
		<ptr target="http://dx.doi.org/10.1109/MICRO.2014.37" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO-47</title>
		<meeting>the 47th Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO-47<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="178" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Large pages and lightweight memory management in virtualized environments: Can you have it both ways</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vesel?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Loh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<idno>ser. MICRO-48</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 48th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<idno type="DOI">10.1145/2830772.2830773</idno>
		<ptr target="http://doi.acm.org/10.1145/2830772.2830773" />
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="1" to="12" />
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Energy-efficient address translation</title>
		<author>
			<persName><forename type="first">V</forename><surname>Karakostas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cristal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Mckinley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nemirovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
		<imprint>
			<date type="published" when="2016-03">March 2016</date>
			<biblScope unit="page" from="631" to="643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Shared-access data processing system</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Couleur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Glaser</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1968-11-19">November 19 1968</date>
			<biblScope unit="page">382</biblScope>
		</imprint>
	</monogr>
	<note>uS Patent 3,412</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Performance of the vax-11/780 translation buffer: Simulation and measurement</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Emer</surname></persName>
		</author>
		<idno type="DOI">10.1145/214451.214455</idno>
		<ptr target="http://doi.acm.org/10.1145/214451.214455" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="62" />
			<date type="published" when="1985-02">February 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Profiling a warehouse-scale computer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kanev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Darago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hazelwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ranganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA &apos;15 Proceedings of the 42nd Annual International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="158" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Asmdb: Understanding and mitigating front-end stalls in warehouse-scale computers</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Nagendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>August</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kanev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ranganathan</surname></persName>
		</author>
		<idno type="DOI">10.1145/3307650.3322234</idno>
		<ptr target="http://doi.acm.org/10.1145/3307650.3322234" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th International Symposium on Computer Architecture, ser. ISCA &apos;19</title>
		<meeting>the 46th International Symposium on Computer Architecture, ser. ISCA &apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="462" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Softsku: Optimizing server architectures for microservice diversity @scale</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sriraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dhanotia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<idno type="DOI">10.1145/3307650.3322227</idno>
		<ptr target="http://doi.acm.org/10.1145/3307650.3322227" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th International Symposium on Computer Architecture, ser. ISCA &apos;19</title>
		<meeting>the 46th International Symposium on Computer Architecture, ser. ISCA &apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="513" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Clearing the clouds: A study of emerging scale-out workloads on modern hardware</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Adileh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kocberber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Volos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alisafaee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jevdjic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kaynak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<idno type="DOI">10.1145/2150976.2150982</idno>
		<ptr target="http://doi.acm.org/10.1145/2150976.2150982" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS XVII</title>
		<meeting>the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS XVII<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="37" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Blasting through the front-end bottleneck with shotgun</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Grot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Nagarajan</surname></persName>
		</author>
		<idno type="DOI">10.1145/3173162.3173178</idno>
		<ptr target="http://doi.acm.org/10.1145/3173162.3173178" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS &apos;18</title>
		<meeting>the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="30" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Memory hierarchy for web search</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ranganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
		<imprint>
			<date type="published" when="2018-02">Feb 2018</date>
			<biblScope unit="page" from="643" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Runtime performance optimization blueprint: Intel architecture optimization with large code pages</title>
		<author>
			<persName><forename type="first">S</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Pawar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Aribuki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Manciu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Schulhof</surname></persName>
		</author>
		<ptr target="https://software.intel.com/sites/default/files/managed/a0/" />
	</analytic>
	<monogr>
		<title level="j">Intel, Tech. Rep. Intel White Paper</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName><surname>Runtimeperformanceoptimizationblueprint_Largecodepages</surname></persName>
		</author>
		<author>
			<persName><surname>Pdf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Memory Systems: Cache, DRAM, Disk</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<pubPlace>San Francisco, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Rethinking tlb designs in virtualized environments: A very large part-of-memory tlb</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Ryoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gulur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>John</surname></persName>
		</author>
		<idno type="DOI">10.1145/3079856.3080210</idno>
		<ptr target="http://doi.acm.org/10.1145/3079856.3080210" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th Annual International Symposium on Computer Architecture, ser. ISCA &apos;17</title>
		<meeting>the 44th Annual International Symposium on Computer Architecture, ser. ISCA &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="469" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Translation Leak-aside Buffer: Defeating Cache Side-channel Protections with TLB Attacks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Gras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Giuffrida</surname></persName>
		</author>
		<ptr target="https://www.vusec.net/download/?t=papers/tlbleed_sec18.pdf" />
	</analytic>
	<monogr>
		<title level="m">USENIX Security</title>
		<imprint>
			<date type="published" when="2018-08">August 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Elastic cuckoo page tables: Rethinking virtual memory translation for parallelism</title>
		<author>
			<persName><forename type="first">D</forename><surname>Skarlatos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kokolis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Torrellas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<meeting>the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1093" to="1108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Babelfish: Fusing address translations for containers</title>
		<author>
			<persName><forename type="first">D</forename><surname>Skarlatos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Darbaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gopireddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Torrellas</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Intel 64 and ia-32 architectures optimization reference manual</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="248966" to="248999" />
		</imprint>
		<respStmt>
			<orgName>Intel Corporation ; Intel Corporation</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep. Order Number</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">5-level paging and 5-level ept white paper</title>
		<ptr target="http://software.intel.com/content/www/us/en/develop/download/5-level-paging-and-5-level-ept-white-paper.html" />
		<imprint>
			<date type="published" when="2018-05">May 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Platform storage performance with 3d xpoint technology</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>Hady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Foong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Veal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1822" to="1833" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Phase change memory: From devices to systems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Qureshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gurumurthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rajendran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Computer Architecture</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="134" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Translation-triggered prefetching</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<idno type="DOI">10.1145/3037697.3037705</idno>
		<ptr target="http://doi.acm.org/10.1145/3037697.3037705" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS &apos;17</title>
		<meeting>the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="63" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Hardware translation coherence for virtualized systems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vesel?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA)</title>
		<imprint>
			<date type="published" when="2017-06">June 2017</date>
			<biblScope unit="page" from="430" to="443" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Inter-core cooperative tlb for chip multiprocessors</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
		<idno type="DOI">10.1145/1736020.1736060</idno>
		<ptr target="http://doi.acm.org/10.1145/1736020.1736060" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth Edition of ASPLOS on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS XV</title>
		<meeting>the Fifteenth Edition of ASPLOS on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS XV<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="359" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Efficient address translation for architectures with multiple page sizes</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<idno type="DOI">10.1145/3037697.3037704</idno>
		<ptr target="http://doi.acm.org/10.1145/3037697.3037704" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS &apos;17</title>
		<meeting>the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="435" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Large-reach memory management unit caches</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<idno type="DOI">10.1145/2540708.2540741</idno>
		<ptr target="http://doi.acm.org/10.1145/2540708.2540741" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO-46</title>
		<meeting>the 46th Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO-46<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="383" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Shared lastlevel tlbs for chip multiprocessors</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lustig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=2014698.2014896" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 IEEE 17th International Symposium on High Performance Computer Architecture, ser. HPCA &apos;11</title>
		<meeting>the 2011 IEEE 17th International Symposium on High Performance Computer Architecture, ser. HPCA &apos;11<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="62" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Redundant memory mappings for fast access to large memories</title>
		<author>
			<persName><forename type="first">V</forename><surname>Karakostas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ayar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cristal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Mckinley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nemirovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>?nsal</surname></persName>
		</author>
		<idno type="DOI">10.1145/2872887.2749471</idno>
		<ptr target="http://doi.acm.org/10.1145/2872887.2749471" />
	</analytic>
	<monogr>
		<title level="j">SIGARCH Comput. Archit. News</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="66" to="78" />
			<date type="published" when="2015-06">June 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Efficient virtual memory for big memory servers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
		</author>
		<idno type="DOI">10.1145/2508148.2485943</idno>
		<ptr target="http://doi.acm.org/10.1145/2508148.2485943" />
	</analytic>
	<monogr>
		<title level="j">SIGARCH Comput. Archit. News</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="237" to="248" />
			<date type="published" when="2013-06">June 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Predictionbased superpage-friendly tlb designs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Papadopoulou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA)</title>
		<imprint>
			<date type="published" when="2015-02">Feb 2015</date>
			<biblScope unit="page" from="210" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A comprehensive study of hardware/software approaches to improve tlb performance for java applications on embedded systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-Y</forename><surname>Lueh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rakvic</surname></persName>
		</author>
		<idno type="DOI">10.1145/1178597.1178614</idno>
		<ptr target="http://doi.acm.org/10.1145/1178597.1178614" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 Workshop on Memory System Performance and Correctness, ser. MSPC &apos;06</title>
		<meeting>the 2006 Workshop on Memory System Performance and Correctness, ser. MSPC &apos;06<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="102" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Tradeoffs in supporting two page sizes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Talluri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Patterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings the 19th Annual International Symposium on Computer Architecture</title>
		<meeting>the 19th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1992-05">May 1992</date>
			<biblScope unit="page" from="415" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Surpassing the tlb performance of superpages with less operating system support</title>
		<author>
			<persName><forename type="first">M</forename><surname>Talluri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<idno type="DOI">10.1145/195473.195531</idno>
		<ptr target="http://doi.acm.org/10.1145/195473.195531" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS VI</title>
		<meeting>the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS VI<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="171" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Practical, transparent operating system support for superpages</title>
		<author>
			<persName><forename type="first">J</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Druschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cox</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=1060289.1060299" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Symposium on Operating Systems Design and implementationCopyright Restrictions Prevent ACM from Being Able to Make the PDFs for This Conference Available for Downloading, ser. OSDI &apos;02</title>
		<meeting>the 5th Symposium on Operating Systems Design and implementationCopyright Restrictions Prevent ACM from Being Able to Make the PDFs for This Conference Available for Downloading, ser. OSDI &apos;02<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="89" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">General purpose operating system support for multiple page sizes</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ganapathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schimmel</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=1268256.1268264" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Conference on USENIX Annual Technical Conference, ser. ATEC &apos;98</title>
		<meeting>the Annual Conference on USENIX Annual Technical Conference, ser. ATEC &apos;98<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="8" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Increasing tlb reach using superpages backed by shadow memory</title>
		<author>
			<persName><forename type="first">M</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Stoller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 25th Annual International Symposium on Computer Architecture (Cat. No.98CB36235)</title>
		<meeting>25th Annual International Symposium on Computer Architecture (Cat. No.98CB36235)</meeting>
		<imprint>
			<date type="published" when="1998-07">July 1998</date>
			<biblScope unit="page" from="204" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Recency-based tlb preloading</title>
		<author>
			<persName><forename type="first">A</forename><surname>Saulsbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dahlgren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stenstr?m</surname></persName>
		</author>
		<idno type="DOI">10.1145/339647.339666</idno>
		<ptr target="http://doi.acm.org/10.1145/339647.339666" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th Annual International Symposium on Computer Architecture, ser. ISCA &apos;00</title>
		<meeting>the 27th Annual International Symposium on Computer Architecture, ser. ISCA &apos;00<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="117" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Going the distance for tlb prefetching: an application-driven study</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Kandiraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sivasubramaniam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 29th Annual International Symposium on Computer Architecture</title>
		<meeting>29th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2002-05">May 2002</date>
			<biblScope unit="page" from="195" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Characterizing the tlb behavior of emerging parallel workloads on chip multiprocessors</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 18th International Conference on Parallel Architectures and Compilation Techniques</title>
		<imprint>
			<date type="published" when="2009-09">Sept 2009</date>
			<biblScope unit="page" from="29" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Cache replacement based on reuse-distance prediction</title>
		<author>
			<persName><forename type="first">G</forename><surname>Keramidas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Petoumenos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaxiras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Computer Design (ICCD-2007)</title>
		<meeting>the 25th International Conference on Computer Design (ICCD-2007)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="245" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">SHiP: Signature-based hit predictor for high performance caching</title>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jaleel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hasenplaugh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Steely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Emer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO-44</title>
		<meeting>the 44th Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO-44<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="430" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Perceptron learning for reuse prediction</title>
		<author>
			<persName><forename type="first">E</forename><surname>Teran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jim?nez</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=3195638.3195641" />
	</analytic>
	<monogr>
		<title level="m">The 49th Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO-49</title>
		<meeting><address><addrLine>Piscataway, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Scalable distributed last-level tlbs using low-latency interconnects</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bharadwaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st International Symposium on Microarchitecture, ser. MICRO-51</title>
		<meeting>the 51st International Symposium on Microarchitecture, ser. MICRO-51<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Increasing tlb reach by exploiting clustering in page translations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Eckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Loh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE 20th International Symposium on High Performance Computer Architecture (HPCA)</title>
		<imprint>
			<date type="published" when="2014-02">Feb 2014</date>
			<biblScope unit="page" from="558" to="567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Colt: Coalesced large-reach tlbs</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vaidyanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jaleel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 45th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2012-12">Dec 2012</date>
			<biblScope unit="page" from="258" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Seesaw: Using superpages to improve vipt caches</title>
		<author>
			<persName><forename type="first">M</forename><surname>Parasar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Krishna</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISCA.2018.00026</idno>
	</analytic>
	<monogr>
		<title level="m">2018 ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA)</title>
		<imprint>
			<date type="published" when="2018-06">Jun 2018</date>
			<biblScope unit="volume">00</biblScope>
			<biblScope unit="page" from="193" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Architectural and Operating System Support for Virtual Memory, ser. Synthesis Lectures on Computer Architecture</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lustig</surname></persName>
		</author>
		<idno type="DOI">10.2200/S00795ED1V01Y201708CAC042</idno>
		<ptr target="https://doi.org/10.2200/S00795ED1V01Y201708CAC042" />
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Dead-block prediction and dead-block correlating prefetchers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Symposium on Computer Architecture</title>
		<meeting>the 28th International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="144" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Cache bursts: A new approach for eliminating dead blocks and increasing cache efficiency</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 41st Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="222" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Back to the future: Leveraging belady&apos;s algorithm for improved cache replacement</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd ACM/IEEE International Symposium on Computer Architecture, ser. ISCA &apos;16</title>
		<meeting>the 43rd ACM/IEEE International Symposium on Computer Architecture, ser. ISCA &apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="78" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Multiperspective reuse prediction</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jim?nez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Teran</surname></persName>
		</author>
		<idno type="DOI">10.1145/3123939.3123942</idno>
		<idno>ser. MICRO-50 &apos;17</idno>
		<ptr target="http://doi.acm.org/10.1145/3123939.3123942" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 50th Annual IEEE/ACM International Symposium on Microarchitecture<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="436" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Combining branch predictors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mcfarling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993-06">June 1993</date>
		</imprint>
		<respStmt>
			<orgName>Digital Western Research Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep. TN-36m</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Multiperspective reuse prediction</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jim?nez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Teran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 50th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="436" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Applying deep learning to the cache replacement problem</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1145/3352460.3358319</idno>
		<ptr target="http://doi.acm.org/10.1145/3352460.3358319" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52Nd Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO &apos;52</title>
		<meeting>the 52Nd Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO &apos;52<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="413" to="425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Adaptive switching circuits</title>
		<author>
			<persName><forename type="first">B</forename><surname>Widrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hoff</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IRE WESCON Convention Record</title>
		<imprint>
			<date type="published" when="1960">1960</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="96" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">30 years of adaptive neural networks: Perceptron, MADALINE, and backpropagation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Widrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lehr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of IEEE</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1415" to="1442" />
			<date type="published" when="1990-09">September 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<ptr target="http://www.microarch.org/cvp1" />
		<title level="m">The 1st Championship Value Prediction Competition (CVP-1)</title>
		<imprint>
			<date type="published" when="2018-06">June 2018</date>
		</imprint>
	</monogr>
	<note>International Symposium on Computer Architecture</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Efficient backprop</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">A</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Orr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural networks: Tricks of the trade</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="9" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Neural networks for machine learning lecture 6a overview of mini-batch gradient descent</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Integer hash function</title>
		<ptr target="https://gist.github.com/badboy/6267743" />
		<imprint>
			<date type="published" when="2007-03">Mar 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Merging path and gshare indexing in perceptron branch prediction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tarjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Skadron</surname></persName>
		</author>
		<idno type="DOI">10.1145/1089008.1089011</idno>
		<ptr target="http://doi.acm.org/10.1145/1089008.1089011" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Archit. Code Optim</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="280" to="300" />
			<date type="published" when="2005-09">September 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">A Study of Replacement Algorithms for a Virtual-storage Computer</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>B?l?dy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Systems Journal</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="78" to="101" />
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Page replacement for general caching problems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Albers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<imprint>
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">On-line file caching</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">E</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="371" to="383" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Caching is hard-even in the fault model</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chrobak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Woeginger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Makino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="781" to="794" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Practical bounds on optimal caching with variable object sizes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harchol-Balter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Measurement and Analysis of Computing Systems</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">The declining effectiveness of dynamic caching for general-purpose microprocessors</title>
		<author>
			<persName><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kagi</surname></persName>
		</author>
		<idno>1261</idno>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Storage free confidence estimation for the tage branch predictor</title>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">High Performance Computer Architecture (HPCA), 2011 IEEE 17th International Symposium on</title>
		<imprint>
			<date type="published" when="2011-02">feb. 2011</date>
			<biblScope unit="page" from="443" to="454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Dynamic branch prediction with perceptrons</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jim?nez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Symposium on High Performance Computer Architecture (HPCA-7)</title>
		<meeting>the 7th International Symposium on High Performance Computer Architecture (HPCA-7)</meeting>
		<imprint>
			<date type="published" when="2001-01">January 2001</date>
			<biblScope unit="page" from="197" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Towards the adoption of local branch predictors in modern out-of-order superscalar processors</title>
		<author>
			<persName><forename type="first">N</forename><surname>Soundararajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rappoport</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yoaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Subramoney</surname></persName>
		</author>
		<idno type="DOI">10.1145/3352460.3358315</idno>
		<ptr target="http://doi.acm.org/10.1145/3352460.3358315" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52Nd Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO &apos;52</title>
		<meeting>the 52Nd Annual IEEE/ACM International Symposium on Microarchitecture, ser. MICRO &apos;52<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="519" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Counter-based cache replacement and bypassing algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kharbutli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Solihin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="433" to="447" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Cache bursts: A new approach for eliminating dead blocks and increasing cache efficiency</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the IEEE/ACM International Symposium on Microarchitecture<address><addrLine>Los Alamitos, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="222" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Using dead blocks as a virtual victim cache</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jim?nez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Chip Multiprocessor Memory Systems and Interconnects (CMP-MSI)</title>
		<meeting>the 4th Workshop on Chip Multiprocessor Memory Systems and Interconnects (CMP-MSI)</meeting>
		<imprint>
			<date type="published" when="2010-01">January 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Timekeeping in the memory system: predicting and optimizing memory behavior</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaxiras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGARCH Comput. Archit. News</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="209" to="220" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Improving cache performance by selective cache bypass</title>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dietz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Architecture Track, Proceedings of the Twenty-Second Annual Hawaii International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1989">1989. 1989</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="277" to="285" />
		</imprint>
	</monogr>
	<note>System Sciences</note>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Compiler managed micro-cache bypassing for high performance epic processors</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rakvic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chrysos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 35th Annual IEEE/ACM International Symposium on</title>
		<meeting>35th Annual IEEE/ACM International Symposium on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="134" to="145" />
		</imprint>
	</monogr>
	<note>in Microarchitecture, 2002.(MICRO-35</note>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Runtime cache bypassing</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Connors</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Merten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-M</forename><surname>Hwu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1338" to="1354" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Active management of data caches by exploiting reuse information</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Rivers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Tyson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Davidson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1244" to="1259" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Run-time adaptive cache hierarchy management via reference analysis</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-M</forename><forename type="middle">W</forename><surname>Hwu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="315" to="326" />
			<date type="published" when="1997">1997</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Utilizing reuse information in data cache management</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Rivers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Tyson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Farrens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th international conference on Supercomputing</title>
		<meeting>the 12th international conference on Supercomputing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="449" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Reducing conflicts in direct-mapped caches with a temporality-based design</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Rivers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Davidson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1996 International Conference on</title>
		<meeting>the 1996 International Conference on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1996">1996. 1996</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="154" to="163" />
		</imprint>
	</monogr>
	<note>Parallel Processing</note>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">The split temporal/spatial cache: initial performance analysis</title>
		<author>
			<persName><forename type="first">V</forename><surname>Milutinovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Markovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tomasevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tremblay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the SCIzzL-5</title>
		<meeting>of the SCIzzL-5<address><addrLine>Santa Clara, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="72" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">A data cache with multiple caching strategies tuned to different types of locality</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gonz?lez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Aliagas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Valero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Supercomputing 25th Anniversary Volume</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="217" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">A modified approach to data cache management</title>
		<author>
			<persName><forename type="first">G</forename><surname>Tyson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Farrens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Pleszkun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th annual international symposium on Microarchitecture</title>
		<meeting>the 28th annual international symposium on Microarchitecture</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="93" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Leakage energy management in cache hierarchies</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kadayif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-F</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vijaykrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Irwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sivasubramaniam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Architectures and Compilation Techniques</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002">2002. 2002</date>
			<biblScope unit="page" from="131" to="140" />
		</imprint>
	</monogr>
	<note>Proceedings. 2002 International Conference on</note>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Enhancing last-level cache performance by block bypassing and early miss determination</title>
		<author>
			<persName><forename type="first">H</forename><surname>Dybdahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stenstr?m</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asia-Pacific Conference on Advances in Computer Systems Architecture</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="52" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">A novel approach to cache block reuse predictions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jalminger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stenstrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Processing, 2003. Proceedings. 2003 International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="294" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Iatac: a smart predictor to turn-off l2 cache lines</title>
		<author>
			<persName><forename type="first">J</forename><surname>Abella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gonz?lez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Vera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>O'boyle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Architecture and Code Optimization (TACO)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="77" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Cache decay: Exploiting generational behavior to reduce cache leakage power</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kaxiras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture</title>
		<meeting>the International Symposium on Computer Architecture<address><addrLine>Los Alamitos, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page">240</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Selective, accurate, and timely selfinvalidation using last-touch prediction</title>
		<author>
			<persName><forename type="first">A.-C</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="139" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Dynamic self-invalidation: Reducing coherence overhead in shared-memory multiprocessors</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Lebeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="48" to="59" />
			<date type="published" when="1995">1995</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Memory coherence activity prediction in commercial workloads</title>
		<author>
			<persName><forename type="first">S</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hardavellas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WMPI &apos;04: Proceedings of the 3rd workshop on Memory performance issues</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="37" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Reevaluating online superpage promotion with hardware support</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Mckee</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=580550.876428" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Symposium on High-Performance Computer Architecture, ser. HPCA &apos;01</title>
		<meeting>the 7th International Symposium on High-Performance Computer Architecture, ser. HPCA &apos;01<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page">63</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<idno type="DOI">10.1145/511334.511351</idno>
		<ptr target="http://doi.acm.org/10.1145/511334.511351" />
		<title level="m">Characterizing the d-TLB Behavior of SPEC CPU2000 Benchmarks, ser. SIGMETRICS &apos;02</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Reducing tlb and memory overhead using online superpage promotion</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Romer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Ohlrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Karlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">N</forename><surname>Bershad</surname></persName>
		</author>
		<idno type="DOI">10.1145/223982.224419</idno>
		<ptr target="http://doi.acm.org/10.1145/223982.224419" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22Nd Annual International Symposium on Computer Architecture, ser. ISCA &apos;95</title>
		<meeting>the 22Nd Annual International Symposium on Computer Architecture, ser. ISCA &apos;95<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="176" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<title level="m" type="main">Transparent huge pages in 2.6.38</title>
		<ptr target="http://lwn.net/Articles/423584/" />
		<imprint>
			<date type="published" when="2011-01">January 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Hybrid tlb coalescing: Improving tlb translation coverage under diverse fragmented memory allocations</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA)</title>
		<imprint>
			<date type="published" when="2017-06">June 2017</date>
			<biblScope unit="page" from="444" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Synergistic tlbs for high performance address translation in chip multiprocessors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Srikantaiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kandemir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2010-12">Dec 2010</date>
			<biblScope unit="page" from="313" to="324" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
