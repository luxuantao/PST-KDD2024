<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Who did what? Who said that? Collaid: an environment for capturing traces of collaborative learning at the tabletop</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Roberto</forename><surname>Mart√≠nez</surname></persName>
							<email>roberto@it.usyd.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Technologies</orgName>
								<orgName type="institution">The University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anthony</forename><surname>Collins</surname></persName>
							<email>anthony@it.usyd.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Technologies</orgName>
								<orgName type="institution">The University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Judy</forename><surname>Kay</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Technologies</orgName>
								<orgName type="institution">The University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kalina</forename><surname>Yacef</surname></persName>
							<email>kalina@it.usyd.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Technologies</orgName>
								<orgName type="institution">The University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Who did what? Who said that? Collaid: an environment for capturing traces of collaborative learning at the tabletop</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EA1D6F1C990985EA31FC8B6996EF4277</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H5.2 [Information interfaces and presentation]: User Interfaces. -Graphical user interfaces</term>
					<term>Input devices and strategies</term>
					<term>Interaction styles Design</term>
					<term>Human Factors User-centred design</term>
					<term>Collaborative learning</term>
					<term>Tabletop</term>
					<term>Visualisation</term>
					<term>Data mining INTRODUCTION!</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Tabletops have the potential to provide new ways to support collaborative learning generally and, more specifically, to aid people in learning to collaborate more effectively. To achieve this potential, we need to gain understanding of how to design tabletop environments so that they capture relevant information about collaboration processes so that we can make it available in a form that is useful for learners, their teachers and facilitators. This paper draws upon research in computer supported collaborative learning to establish a set of principles for the design of a tabletop learning system. We then show how these have been used to design our Collaid (Collaborative Learning Aid) environment. Key features of this system are: capture of multimodal data about collaboration in a tabletop activity using a microphone array and a depth sensor; integration of these data with other parts of the learning system; transforming the data into visualisations depicting the processes that occurred during the collaboration at the table; and sequence mining of the interaction logs. The main contributions of this paper are: our design guidelines to build the Collaid environment and the demonstration of its use in a collaborative concept mapping learning tool applying data mining and visualisations of collaboration.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Collaboration has been proven to activate special learning mechanisms that cannot be triggered by working individually <ref type="bibr" target="#b3">[4]</ref>. This is partly because working in groups creates the need to externalise internal thoughts to explain a point of view, or to defend a position, and it also helps individuals to learn about others' perspectives. Emerging tangible and interactive surfaces provide the possibility for new ways to support collaborative learning. Notably, it is feasible to collect rich data about the collaboration at a tabletop. If we can then present it in a suitable form, learners and their teachers can gain understanding of the learning and collaboration processes. This can be valuable for two aspects of the learning. First, it can show the learning process that led to the final artefacts created at the table. Second, it can provide insights into the collaboration processes, in terms of the nature of the participation of each individual and the sequences of interactions between them. This generic skill in group work is valuable in many contexts, beyond the classroom into the workplace.</p><p>If we are aiming to create these potential aids to collaboration, one of the first challenges is in forming a basis for the design of the tabletop environment and its associated collaborative interfaces, so that they can capture the required collaboration data. This must be done in a manner that makes it possible to do downstream analysis of the data, to present it in a suitable form to support understanding of the learning and collaboration processes.</p><p>There is a growing body of research indicating the importance of gathering contextual information when people collaborate at the tabletop in order to offer enhanced or personalised user interface capabilities, such as adapted content delivery <ref type="bibr" target="#b2">[3]</ref>, automatic orientation <ref type="bibr" target="#b8">[9]</ref>, visualisations of collaboration at the tabletop for teachers and researchers <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b20">21]</ref>, application of data mining techniques to find patterns of interaction <ref type="bibr" target="#b11">[12]</ref> or building a user model to adapt the support that the tabletop system can offer <ref type="bibr" target="#b10">[11]</ref>. Currently, there are no guidelines to inform the design process for tabletop software designers, so as to capture the right information to create such user models or for further data mining to enhance these models. In addition, the hardware currently available often fails to distinguish which activities were associated with each person at the table.</p><p>At present, there are many tabletop interfaces but it is timely to establish principled guidelines to design the key features that should define these systems. Our work aims to Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. ITS 2011, November 13-16, Kobe, Japan. Copyright 2011 ACM 978-1-4503-0871-7/11/11....$10.00. outline a theoretical foundation for this new area so that it will serve as a basis for designing interfaces for a range of collaborative tasks in a manner that will make it feasible to provide support for collaboration in the form of, for example, visualisations, personalised capabilities or content delivery, group modelling and machine learning techniques (see Figure <ref type="figure" target="#fig_0">1</ref>). The contributions of this paper include the proposal of a set of learner-centred guidelines that we used in designing a tabletop setting that captures rich contextual information about learning processes. These guidelines range from the design of the physical setting to specific software interface features. Then, we describe the implementation of the Collaid (Collaborative Learning Aid) environment. This comprises a set of multimodal devices, namely a tabletop, a microphone array and a depth sensor, that are integrated in order to capture audio, physical and positioning traces of activity. We map each of Collaid's features to the guidelines. Finally, we validate the usefulness of Collaid in a case study application that makes use of its elements to capture information that can be exploited for different purposes, such as visualising collaboration or feeding educational data mining techniques (green squares, Figure <ref type="figure" target="#fig_0">1</ref>). The remainder of the paper is organised as follows. Next section describes related work on collocated collaboration and the use of the data collected from tabletop settings. Then, we present our design guidelines, followed by the implementation of the Collaid environment. We present an exploratory concept mapping system to demonstrate how the Collaid environment can be effectively applied. Finally, we discuss the results and conclude with future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RELATED WORK</head><p>Several researchers have explored how to achieve the potential of digital tabletops in educational contexts for giving support to collaborative learning. This section presents key work of two main research paths: collocated and tabletopbased settings designed with the purpose of giving better support for collaboration; and research that has specifically tackled collaborative learning issues by exploiting the information gathered by the tabletop setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Designing to support collocated collaboration</head><p>Collocated collaboration has been explored in a variety of applications; most research has investigated the ways to !"!#$%&amp;' !"(' %)**!+,%&amp;' !' *&amp;&amp;-,".' %/' !%' -/' *!0&amp;' -1&amp;' 2/##!3/+!-,4&amp;' 5+/2&amp;%%' */+&amp;' &amp;66&amp;2-,4&amp; <ref type="bibr" target="#b24">[25]</ref>. However, the active role that a tabletop can play in a collocated group meeting is a research direction with high potential. Scott et. al. <ref type="bibr" target="#b18">[19]</ref> established a set of high level guidelines for tabletop systems oriented to support collaboration. They highlighted the importance of the setting, the arrangement of the subjects and how the tabletop can communicate with other devices and services to support the collaborative process.</p><p>More recently, Nacenta et. al. <ref type="bibr" target="#b16">[17]</ref> specifically explored the impact of the interaction techniques and location of feedback at the tabletop on the way in which users collaborate. They found that small changes in the design of the interface input and output may greatly affect the usage of the tabletop application, and thus the collaborative process. Kharrufa et. al. <ref type="bibr" target="#b7">[8]</ref> also investigated the design of tabletop applications focused on learning contexts. They describe the importance of grounding the design of educational tabletop applications on learning theories to increase the likelihood the group will engage in collaborative discussions. AlAgha et. al. <ref type="bibr" target="#b0">[1]</ref> presented a visionary teacher-centred approach to enhance the effectiveness of tabletops in classroom activities by offering a real-time interface to the facilitator for monitoring multiple groups at the same time. Ballendat et. al. <ref type="bibr" target="#b2">[3]</ref> explored ways to capture and use contextual information about users, such as position, proximity, focus of attention and activity, to offer personalised format and content delivery according to the users' needs at a given moment.</p><p>Investigations on the use of interactive tabletops for collaboration have mostly focused on the way in which learners and their facilitators interact with the computer (and between themselves) rather than just the user interface modes of interaction <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. An example of how the tabletop, embedded in an integral system, can become a useful walk-up-and-use tool to support collocated collaboration is WeSpace <ref type="bibr" target="#b23">[24]</ref>. This system allows users to collaborate and share information on the tabletop, by integrating personal devices, applications and other shared services. The work of Marshall et. al. <ref type="bibr" target="#b9">[10]</ref> also sheds light on the way people naturally approach, interact, work in groups and behave around the tabletops and the implications of this observations on the design of collaborative applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysing, visualising and mining tabletop data</head><p>Even though past research has explored the potential of tabletops for supporting learning, little attention has been paid to the analysis of the digital footprints generated by the face-to-face interactions and the role that the tabletop can play as a mediator of the collaborative activity; and additionally, how to provide the tabletop with better tools to become an active participant providing information to   <ref type="bibr" target="#b19">[20]</ref>, in the context of learning systems, remarked on the importance of capturing a user model to observe and record the collaborative interaction, diagnose the state of the collaborative process, and then, offer some kind of feedback: from mirroring information back to users to actively advising them towards a goal. Therefore, special attention should be placed on the data collection to provide the tabletop system with the knowledge to give such feedback.</p><p>A number of researchers have also highlighted the importance of the collected data to help understand the collaborative process and interactions at the tabletop. For example, Bachour et. al. <ref type="bibr" target="#b1">[2]</ref> developed a system to visualise in real time the amount of conversation each person produces around a non-interactive tabletop; they observed the effect of the quantity of speech on the final result of the group activity. Also Tse et. al. <ref type="bibr" target="#b21">[22]</ref> performed a multi-modal observation on how pairs collaborate at the tabletop with speech and gesture commands. VisTaco <ref type="bibr" target="#b20">[21]</ref> provided a generic tabletop analytic tool to support the exploration of the data generated by the low level touch interactions with the surface in a non-collocated environment. However, even though the low level interactions may be useful for studying the user interface, they do not actually say much about the meaning of the actions. The authors also highlight the importance of linking the logged touch interactions with higher level collaborative activities.</p><p>Jermann et. al. <ref type="bibr" target="#b6">[7]</ref> performed low level observations on the ways people collaborate around a tangible table to investigate the impact of the arrangement of people and objects around the tabletop on the division of labour. They made use of collaborative learning techniques and collabograms to visualise and summarise the interactions given between learners. Harris et. al. <ref type="bibr" target="#b5">[6]</ref> also used a wide range of sources of information gathered in their tabletop user trials to study the social processes. These included the use of the application logs, measures of symmetry of activity and coding schemas to observe the equity of participation and the content of what was said by the learners while collaborating. A particular usage of tabletop-based collected data is shown in <ref type="bibr" target="#b11">[12]</ref>. Here, the authors applied data mining techniques to their dataset collected from a learning application to find sequential patterns of activity that differentiate high from low achieving groups.</p><p>Our work goes beyond these examples by taking principles that have been used for analysing collocated meetings, and applying them in a tabletop setting. This approach is grounded on designing and implementing the tabletop system to gather the readily available contextual information within and beyond the tabletop hardware, and to make it accessible in real time to services that can mirror or give active support for the collaborative process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DESIGN GUIDELINES FOR CAPTURING TABLETOP COLLABORATION DATA IN COLLAID</head><p>There have been proposals for general tabletop design guidelines to support collaboration <ref type="bibr" target="#b18">[19]</ref> and to capture user models <ref type="bibr" target="#b12">[13]</ref>. There are also guidelines for designing learning systems to ensure the collection of the data needed for data mining <ref type="bibr" target="#b15">[16]</ref>. We build upon these to establish a set of design guidelines to create a system that captures a rich set of collaboration data that can be used for analysis, visualisation, and data mining. We propose a top-down approach in which the design of the tabletop environment is defined by the nature and format of the data that needs to be captured for mining and user modelling. Next, we outline these key design guidelines, taking into account both the learning theories and current technology affordances.</p><p>(i) Distinguish users. One of the most important requirements for capturing rich contextual information and providing certain types of adaptation at the tabletop, is to distinguish between each user's touches <ref type="bibr" target="#b10">[11]</ref>. It is essential to know who-touched-what in order to perform a full data analysis of actions or to offer support in the form of personalisation and customisation of the interface!" Current solutions for distinguishing who is touching the tabletop include specialised hardware such as the DiamondTouch <ref type="foot" target="#foot_0">1</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>21</head><p>, attaching gadgets to users' hands (gloves or pens), or using distributed tabletops in which the users are not collocated (e.g. [ ]). Another option is to restrict users' reach by assigning roles or territories, and asking them to respect others' personal space <ref type="bibr" target="#b14">[15]</ref>. However, this implies that the task and users' behaviour are constrained to meet the user identification requirement.</p><p>(ii) Capture verbal communication. The presence and content of the utterances made during collaboration are crucial for analysing collaboration <ref type="bibr" target="#b3">[4]</ref>, and tabletop settings should be instrumented to capture them. Previous work on tabletops has made use of the manual transcription of the utterances spoken by the group members <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b21">22]</ref> or the automatic collection of the presence of speech to measure levels of participation <ref type="bibr" target="#b1">[2]</ref>. The captured speech can range from detecting when people are talking, to more detailed aspects such as the tone, volume or the speech content. The speech features of collocated learners can be captured using individual wearable audio recorders or less intrusive multi-directional microphone arrays.</p><p>(iii) Integrate user and contextual data. The model of the collaborators (that the tabletop can use to reason about the group's status) can be enriched by incorporating information that is beyond the boundaries of the physical tabletop system. This information includes, for example, the degree of familiarity of group members, their individual learner models, outcomes reached in other academic activities <ref type="bibr" target="#b15">[16]</ref> and ubiquitous information like position or proximity to the table <ref type="bibr" target="#b2">[3]</ref>. If the tabletop is used as a part of a sequenced activity which involves other technologies such as webbased portals or desktop multimedia, then a possible solution is to adhere to a common user modelling framework to integrate multiple services or to share data through a central repository.</p><p>(iv) Integrate with services. Using tabletops as an added interface to existing collaborative e-learning tools, such as wikis, chat or forums can expand the collaboration facilities provided by these input services and improve the collaborative experience by supporting face-to-face group work sessions. In this way, tabletop applications can be integrated within a larger scale system that can give continued support to the students' learning process over long periods. On the other hand, the information captured during the collocated tabletop sessions should be available for output services that can exploit this information to improve the group members' awareness of collaboration.</p><p>(v) Interconnect with external devices. Scott et. al. <ref type="bibr" target="#b18">[19]</ref> noted the importance of easing the transition between the collaborative work at the tabletop and external work performed through other devices. In collaborative situations, learners usually can make use of multiple sources of information, from books and paper articles, to modern devices like desktop computers, whiteboards and smart phones. Personal devices and interactive surfaces other than tabletops provide added specialised functions and the flexibility needed for specific tasks. These are individual spaces in which learners can work first, and then they can share their individual work with the group. It is also important to record the user activity using these different devices to gather a comprehensive set of data about the group actions. To illustrate this point, consider a scenario in which a digital whiteboard is used to brainstorm ideas, with the results stored on a personal device, and shared at the tabletop for group discussion.</p><p>(vi) Define the degree of structure of the activity. The interface may afford and constrain specific activities to be performed at specific times according to a script. In this way, the logged data is naturally connected with the different steps of the collaborative process, hence aiding data interpretation. Furthermore, the design may help learners to collaborate -as a starting pointwhile they do not have their own coordination strategies <ref type="bibr" target="#b22">[23]</ref>. An example of this design approach was used by Kharrufa et. al <ref type="bibr" target="#b7">[8]</ref> in which the tabletop activity was divided into three stages, providing users with different goals and tools in each of them.</p><p>(vii) Capture the data in multiple formats. Another design aspect to consider is that data needs to be captured and recorded in multiple formats according to the potential analysis techniques that can be used to exploit it. This is important because different algorithms might require specific contextual information. For example, sequential pattern mining algorithms need data formatted as a detailed sequence of events. Other techniques might need the historical status of the objects at the tabletop to measure the progress of the task over time, or for supporting monitoring services that could be used to detect important moments in the activity or visualise the logged interactions.</p><p>(viii) Define the logging semantics. The lowest granularity at which the raw physical actions on the tabletop can be logged is the coordinates of each touch point. These data can be used to study low level dimensions of the group activity like territoriality or user interactions <ref type="bibr" target="#b20">[21]</ref>. However, this kind of logging does not indicate much about collaboration. Semantically meaningful data logs should be created to gain insight into the strategies followed by groups (e.g. create an object; press a button; group ele- ments). In addition, it might be valuable to establish even higher-levels of abstraction by giving meaning to sets of basic actions based on heuristics. For example, basic actions such as rotating elements towards others can indicate communication <ref type="bibr" target="#b8">[9]</ref>, or sequences of actions such as dragging, inserting text or resizing, can be associated with higher level strategies like collecting information, brainstorming or negotiation <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COLLAID: A MULTIMODAL ENVIRONMENT TO AID COLLABORATIVE LEARNING PROCESSES</head><p>Using the guidelines described above, we designed and implemented a tabletop-based learning environment that can capture, in a non-intrusive way, the collaborative interactions of people as they solve a problem or build joint understanding. First, we describe the generic physical setting that can be used on a range of different tabletop hardware. Then, we detail the specific learning applications and techniques we used to evaluate the system. The first column of Figure <ref type="figure">2</ref> lists the set of design guidelines described in the previous section. The second column contains our system features that map to each of the guidelines. These features are detailed in the next subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Physical generic setting.</head><p>The tabletop used in this study had a 46-inch LCD touch screen with a display resolution of 1920x1080 pixels, offering enough space for up to four participants. The tabletop hardware can detect multiple touches at a time, butlike most current touch hardware -it cannot recognise which user is providing an input. To give support to the model for capturing group members' interactions (i-Distinguish users) we designed a system based on a depth sensor 2</p><p>However, as mentioned earlier, most of the collaborative interactions among collocated users do not occur between the computer and people, but between the users themselves.</p><p>In order to capture this important dimension of the collaborative process, we capture the speech and verbal participation through an array of microphones located above the tabletop to track the position of each user's body and arms (Figure <ref type="figure">3</ref>). We match the depth images generated by the sensor with each touch performed on the interactive tabletop identifying the finger that is touching the table in that exact position, at that precise moment. Then, using a greedy search algorithm (weighted to make it follow the shape of hands and arms), we detect the arm span of that learner, therefore recognising the owner of that touch according to their position around the table. In this way, any direct-manipulation tabletop hardware can be extended to track who is touching what in a non-intrusive manner.</p><p>3 2 Kinect sensor device: http://www.xbox.com/kinect situated above the tabletop (ii-Capture verbal communication). We use a radial 7-channel USB microphone array that can distinguish sounds based on the spatial location of the source, in our 3 Microcone recorder: http://www.dev-audio.com case, the learners who are collocated around the tabletop. The array recognises when a learner is speaking, then, the application links the source of the sound with the learner's position to finally record the audio information to audio files and the shared database.</p><p>Through this set of hardware, we obtained multidimensional sources of information: verbal interactions between learners (without attaching microphones to people) and tabletop data logs with the authorship of each touch at the tabletop (without attaching any gadget to people's hands or having additional furniture restrictions) by mapping the position of the users around the tabletop with the information captured by the microphone array and depth the sensor. Figure <ref type="figure">3</ref> shows the generic hardware disposition of the sensors of the system. This setting can potentially be used in a number of environments like classrooms, public spaces or controlled research settings. However, an additional function may be useful in some cases where users need to be able to identify themselves (login). This would make it suitable for walk-up-and-work settings in which the tabletop is deployed in a shared space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Software architecture.</head><p>The software architecture of this system is distributed across a number of servers in which the different applications get information from the corresponding sensors and record it into a central data server. The advantages of using a common repository of information rather than log files is that sensing applications can save information at the same time that a number of services (such as real time monitoring systems or machine learning techniques) can make use of these data <ref type="bibr" target="#b15">[16]</ref>.</p><p>The software architecture consists of 4 key parts, as illustrated in Figure <ref type="figure" target="#fig_2">4</ref>. The first block corresponds to the set of </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generic environment Domain dependant</head><p>Verbal capture</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Verbal participation Speech content</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>From the tabletop</head><p>Raw touch data Touch authorship</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Beyond the tabletop</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hands movements Body positioning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Domain specific logs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tabletop application Collaborative task App logs UI snapshots</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Clients</head><p>Data Mining / AI Visualisations Queries/ feedback features</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data repository</head><p>Database Files External data</p><p>applications that is connected to the sensors with the purpose of capturing information about the activity of the collaborators. These include the applications for capturing and mapping the position of users with the tabletop, the application for recording the verbal utterances and process the speech content, and the regular system for capturing the touches at the tabletop. This part of the system is generic and can be used with any tabletop application that offers services to multiple users at the same time.</p><p>The second block corresponds to the tabletop application that gives support for learning, training or any other collaborative activity. This second part of the system is closely dependant on the domain of the activity and the learning goals of the group of learners. The application logs should contain the contextual information about what the learners intended to do at the tabletop, rather than just the raw touch-down and up events. Therefore, the meaning of the logs depends on the range of the possible actions permitted by the design of the tabletop application. This information can be formatted as a long ordered sequence of user actions or as a set of snapshots of the state of the tabletop at a regular interval.</p><p>The third part is the data repository that can reside in a central file system or a database server in which all the sensing applications can record data and the client services get information out (iii, Integrate user and contextual data). Finally, the managed data can be easily accessed by different services to feed data mining engines, visualise the collaborative data, perform queries or provide adapted support to the collaborative activity (iv, Integrate with services). In this paper, we explore the feasibility of the first two of these examples, as described in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset description</head><p>Every touch action on the tabletop is logged on two levels: the raw data that include each touch and motion of a finger across the tabletop; and application logs, that include meaningful actions like moving, creating, deleting or pressing objects at the tabletop. The latter is the level of logging our approach is focused on (viii, Define the logging semantic). Each of these application-level logged actions includes the information about the time in which the action started and finished, the initial and final position/rotation/size if the action involves the manipulation of an object, the status of the content of the object, and in our case study, the added concepts, links and the author of such actions.</p><p>We also record the information of the status of each element on the tabletop every second (as a snapshot of the system at a given moment), the position of learners around the tabletop, each verbal utterance and the individual audio that can be fed into a speech recogniser for automatically generating transcripts of the sessions. These data might be used for further analysis (vii, Capture the data in multiple formats) however an exhaustive analysis is beyond the scope of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CASE STUDY AND VALIDATION OF THE MODEL</head><p>We conducted a qualitative case study evaluation to demonstrate how the Collaid environment can enable the collection of collaboration data, used for visualisation (to provide real-time feedback during the group's task) and for running data mining algorithms to extract frequent patterns. We ran the system analysis with 12 participants organised in groups of 3. They were students predominantly enrolled in computer science courses and were aged between 25 and 30. Group members were familiar with one another. They were asked to build an artefact collaboratively at the tabletop. The collaborative task chosen for this case study is the concept mapping technique for externalising knowledge <ref type="bibr" target="#b17">[18]</ref>. However, any other tabletop application can be used along with the Collaid environment to capture collaborative interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tabletop application.</head><p>We integrated a concept mapping tabletop application to the environment for capturing the collaborative interactions among learners while they build a common artefact. A concept map is a diagram through which learners can represent their understanding about a topic. It is formed by concepts (short words that represent objects, processes or ideas) that can be linked through a linking phrase.</p><p>The tabletop application is linked with a well-known desktop-based learning tool called CMapTools<ref type="foot" target="#foot_1">4</ref> </p><p>Additionally, this information is used by the application to offer hints on which parts of the personal concept maps are interesting to discuss when there are clear differences between the same conceptual definitions, or to identify which parts of the individual maps can be automatically loaded by the tabletop because all learners already agreed on them. In this way, learners reduce the initial workload of starting a new map from scratch; instead they can focus on discussing the disagreements.</p><p>server. First, before learners come to the tabletop, they use this tool to build their individual concept maps in private (v-Interconnect with external devices). Then, learners come together to the tabletop to discuss the commonalities and differences between their perspectives, and create a collaborative concept map. These individual concept maps are used by the tabletop application to extract the personal vocabulary of concepts and links, and make them available to the learners during the collaborative part of the activity (iv, Integrate with services). Thus, learners can use the concepts and links they previously included in their individual work, or create new ones and relate them with other participants' ideas to build a new mutually accepted artefact.</p><p>Overall, the concept mapping activity for the application is semi-structured in four stages: i) individual concept mapping (external to the tabletop); ii) brainstorming concepts at the tabletop; iii) adding propositions that the individual learners have in common, and iv) the linking phase in which users build relationships between concepts (vi, Define the degree of structure of the activity).</p><p>Regarding the user interactions with the tabletop, learners are initially provided with 3 tools: a list of concepts that includes the ones they used in the individual stage (or a list of suggested concepts if there was not an individual stage); an onscreen keyboard for editing phrases; and a resizable representation of their individual concept map. All these elements are initially minimised to avoid clutter (see Figure <ref type="figure" target="#fig_3">5-A</ref>). Learners can add concepts by simply selecting them from the list of concepts (Figure <ref type="figure" target="#fig_3">5-B</ref>) that is linked with the individual map that was built externally. They can add links by dragging a concept and dropping it on another target concept; and delete elements by dropping them on one of the pair of black holes situated on the corners of the tabletop.</p><p>The user interface interaction is simple; in order to select any element at the tabletop for maximising it, editing a node (Figure <ref type="figure" target="#fig_3">5-C</ref>) or pressing 'buttons', the generalised interaction technique consists of a touch and hold gesture. This also gives some additional time to the system to resolve the authorship of the touch in case that all participants are touching the interface with all their fingers at the same time, and thus, providing real-time feedback on each touch by representing each contact point with a different colour per user (see Figure <ref type="figure" target="#fig_3">5-A</ref>). All elements at the tabletop are coloured according to the user who created such an object (Figure <ref type="figure" target="#fig_3">5-D</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Visualisation of the group's collaboration</head><p>In order to effectively analyse and evaluate collaborative work through the use of new technologies, including the tabletop, it is required to design metrics and techniques for evaluating the behaviour and interaction space of the users of such technologies. One of the most powerful and, at the same time, simpler techniques to improve the awareness on the learning processes is the visualisation of the contextual data. Visualising data generated by tabletop systems has not been the exception <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b20">21]</ref>.</p><p>To demonstrate the quality and utility of the data captured by our system we designed a dashboard which contains a set of visualisations of the collaborative activity of the learners at the tabletop that is generated in real time while the users build a concept map, and it is displayed into a small, handheld multitouch device (v-Interconnect with external devices). This tool aims to help the facilitator to gain an overview to assess how evenly each group member is contributing; the facilitator could then give special attention to that group or leave them work to continue on their own. Inspired by the visualisations presented by Martinez et.al <ref type="bibr" target="#b13">[14]</ref>, we designed a 3-layered visual interactive dashboard. These visualisations are: the radar of physical activity, the radar of verbal participation and the contributions chart. The data used for generating these visualisations included the application logs, the audio participation logs and the snapshots of the elements at the tabletop taking into account the authorship of each action. These visualisations were created for each of the experiment groups in real time. We now detail the data captured and resulting visualisations of two extreme cases of the experiment groups. The radars of verbal participation (top row of visualisations of Figure <ref type="figure" target="#fig_4">6</ref>, blue radars) measure the amount of speech that each participant has produced during a certain period of time. Each coloured circular marker corresponds to a learner interacting at the tabletop as they are represented by the colour of the elements they create (yellow, green, blue and red). The further the marker is from the centre of the radar, the more speech they have produced during the period of time the visualisation covers. The coloured figure of the radars (in this case, blue), formed by joining the individual markers, depicts how egalitarian the verbal participation of the group is during a given period of time <ref type="bibr" target="#b3">[4]</ref>. If there are 3 learners, a perfectly symmetrical triangle would indicate that the three group members participated to a similar extent.</p><p>The second set of visualisations corresponds to the radars of touch participation (second row of Figure <ref type="figure" target="#fig_4">6</ref>, red radars). Similarly, these visualisations measure the quantity and symmetry of physical actions, in other words, touches on the interactive surface. The third set, contributions charts (bottom of Figure <ref type="figure" target="#fig_4">6</ref>), consists of simple pie charts that show the proportion of elements present at the tabletop that We established these maximum limits of the talk and touch dimensions based on preliminary user trials.</p><p>For our user study, the group members had up to 25 minutes to create the collaborative concept map. We created a dashboard containing 6 sets of the three visualisations that appeared sequentially, in real time, whilst the users were working at the tabletop. In Figure <ref type="figure" target="#fig_4">6</ref> we present the first 12 minutes of activity of two extreme groups (therefore 3 sets of visualisations per group). The first group of learners (Figure <ref type="figure" target="#fig_4">6</ref>, left) was very communicative and learners tried to collaborate and be aware of others' actions. In the second group (Figure <ref type="figure" target="#fig_4">6</ref>, right) learners worked on their own for longer periods of time creating a more complete artefact compared with the first group. In this example, the generated visualisations clearly showed a marked difference between these groups: higher amounts of egalitarian talk in the first group against large amounts of touches on the tabletop and a bigger concept map in the second group. What we learnt from this exercise is that the data generated by the environment can be used to feed these visualisations to show how members of the groups explore the tabletop, and manage the balance between the quantity of discussed ideas and their physical interaction with the surface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mining data captured about the collaboration</head><p>The second technique that we explored to validate the significance of the captured traces was a data mining procedure to discover patterns of interaction that are hard to find by simple inspection of the logs.</p><p>A dataset collected from a multi-user setting, such as the tabletop, poses challenges for data mining because the user actions occur in parallel and are performed by multiple users in distinct order. Additionally, our data might contain more non-relevant human-computer interaction since the user interface is accessible for intuitive exploration and can be touched by learners at any time (sometimes even accidentally). We took into account the nature of the data to design a data mining strategy to extract frequent patterns of activity and confirm that the data produced by our environment is mineable. Two key attributes of this tabletop dataset are: the authorship and the sequential order of each action.</p><p>The data mining task we set out to solve was to discover the frequent sequences of interactions with the user interface performed per learner at the tabletop. One technique that has proven to be successful in analysing the timing and order of the events is sequential pattern mining. A sequential pattern is a highly frequent consecutive or nonconsecutive ordered sub-set of a sequence of events. However, the sequences extracted in this exercise are exclusively focused on the consecutive ordered sub-set of events that can potentially form a pattern. We do not consider the non-consecutive actions because frequent patterns of a pair of actions might not be meaningful if many other events or large gaps of inactivity occur between such actions.</p><p>As mentioned in the previous sections, the raw logged touches do not indicate the intention of the users and therefore about user strategies. In this way, the input data for the algorithm consists of a list of sequential raw sequences of events. The table at Figure <ref type="figure">7</ref> shows the simplified description of the set of actions that learners can perform on the tabletop (viii-Define the logging semantics) The dataset collected during the user trials of the case of study was preprocessed and a long sequence of actions per learner was generated to obtain a total of 12 long sequences (one for each participant). Then, we split these long sequences when a considerable gap of inactivity was found (an arbitrary threshold of 15 seconds of inactivity was chosen). For example, we got a sequence of actions {M-AC-AC-MC-MC-AL-m} from the activity of the learner "Alfred". He started the trial by opening the list of concepts he included in his personal artefact (M), then added a couple of concepts (AC), rearranged these elements (MC) and created a link between them (AL). In this case, if "Alfred" did not do any other action for more than 15 seconds then his first generated sequence of events would be similar to the sequence presented above. The goal is to find how many times "Alfred", or other learners, repeated this same sequence of events or at least part of it. In other words, the aim is to look for frequent ordered patterns within the action sequences.</p><p>With the purpose of detecting both the frequency and redundancy of the patterns of interaction, we implemented an extraction algorithm of n-grams. An n-gram is a subsequence of n elements from a given sequence. Only sequences of at least 3 actions were considered (n=3). For this exercise we fixed the minimum support threshold in 10 times to consider a pattern as frequent. The output of the algorithm is a list of frequent sequential patterns that meet the minimum given support. Based on the full sequences generated in this way, our algorithm seeks consecutive and also repeated patterns within the dataset of sequences. For example, following from the initial example, if we identify from our dataset that "Alfred", along with other learners, performed the sequential sub-set of actions {AC-AC-MC-MC-AL} more than 10 times, then our algorithm will list this sequential pattern as frequent. The resulting output was a list of frequent patterns. The final result included 69 frequent patterns found of length varying from 3 to 17 actions.</p><p>The dataset obtained from our formative case study is not extensive enough to make educational assumptions about the concept mapping activity, but we obtained interesting results about the way learners interacted with the user interface. For example, Figure <ref type="figure">8</ref> shows some discovered sequences that were highly frequent in the dataset for three example trials. These results show that high amounts of touches are dedicated to reorganise the content of the concept map (move links and concepts) and its distribution across the groups. Indeed, in Figure <ref type="figure">8</ref>, columns G1 and G2 correspond to the visualisations of the groups depicted in Figure <ref type="figure" target="#fig_4">6</ref>. A deeper data mining analysis goes beyond the scope of this paper; however, these two simple examples (visualisations of collaboration and data mining of tabletop activity data) illustrate the potential of the contextual data capture and the application of machine learning analysis to identify key traces of the collaborative process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSIONS</head><p>In this paper we described a set of guidelines we used for designing tabletop-based collaborative learning applications taking into account the special needs that are required to collect rich contextual information. This information can then be used to analyse and visualise the different facets of collaboration at the tabletop. We detailed the construction of an environment to capture and record, in a non-intrusive way, the user interactions of the collaborators. Our environment is focused on permitting learners to naturally interact between themselves, rather than ask them to adapt their behaviour to the hardware or software features. We mapped each of the system characteristics with the guidelines posed by our model as it was shown in the table of Figure <ref type="figure">2</ref>. The system can also be adapted to pre-existing tabletop devices, therefore permitting its use in the classroom in the short-term.</p><p>Thereafter, we ran a case study in which we illustrated the feasibility and utility of the environment and the design model, to provide data that can be applied to feed visualisation in a dashboard that offers a real-time overview of the collaborative work for the facilitator. We additionally describe a sequence pattern mining technique applicable to this tabletop dataset. We demonstrated that the data is mineable and that it can be integrated with different sources of information. This analysis can provide a useful platform for looking at aspects of the interface design and also the group collaboration.</p><p>The long-term goal of this research is to make tabletop systems into adaptive, supportive tools and intelligent mediators between peers' activity. Future work will explore  how the tabletop setting is used in the wild (e.g. in a school classroom) to collect larger amounts of interaction and collaboration data, enabling us to perform a deeper analysis of the logs using artificial intelligence techniques. Thus, this enables us to move towards the provision of adapted support to the collaborative learning processes at the tabletop.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Capturing traces of collaborative learning at the tabletop and potential uses.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :Figure 2 :</head><label>32</label><figDesc>Figure 3: The Collaid data capture and output services.</figDesc><graphic coords="4,309.00,489.54,249.65,210.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Software architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The concept mapping application. A) User identification B) Accessing external sources C) Editing node words D) Building the artefact collaboratively.</figDesc><graphic coords="7,55.50,165.00,148.62,99.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Collaborative visualisations dashboard corresponding to 12 minutes of activity of a communicative group (left) and a less collaborative group (right). Generated through the GoogleDocs API. 0 -4 min 4 -8 min 8 -12 min 0 -4 min 4 -8 min 8 -12 min</figDesc><graphic coords="8,159.84,65.94,192.00,212.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :Figure 8 :</head><label>78</label><figDesc>Figure 7: Basic actions considered for the data mining sequential mining.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>DiamondTouch Table.: http://www.circletwelve.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>Institute for Humans and Machine Cognition. CmapTools: http://cmap.ihmc.us/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This research was carried out as part of the activities of, and funded by, the Smart Services Cooperative Research Centre (CRC) through the Australian Government's CRC Programme (Department of Innovation, Industry, Science and Research).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards a teacher-centric approach for multi-touch surfaces in classrooms</title>
		<author>
			<persName><forename type="first">I</forename><surname>Alagha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hatch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Burd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ITS&apos;10</title>
		<meeting>of ITS&apos;10</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="187" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An Interactive Table for Supporting Participation Balance in Face-to-Face Collaborative Learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bachour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dillenbourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Learning Technologies</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="203" to="213" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Proxemic interaction: designing for a proximity and orientation-aware environment</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ballendat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Marquardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ITS&apos;10</title>
		<meeting>of ITS&apos;10</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="121" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">What do you mean by &apos;collaborative learning&apos;? Collaborative Learning: Cognitive and Computational Approaches</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dillenbourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Learning and Instruction Series</title>
		<imprint>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Actions Speak Loudly with Words: Unpacking Collaboration Around the Table</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fleck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yuill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bonnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ITS&apos;09</title>
		<meeting>of ITS&apos;09</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="189" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Around the table: are multiple-touch surfaces better than single-touch for children&apos;s collaborative interactions?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bonnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yuill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fleck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rogers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CSCL&apos;09</title>
		<meeting>of CSCL&apos;09</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="335" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Physical space and division of labor around a tabletop tangible simulation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Jermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zufferey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lepine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dillenbourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CSCL&apos;09</title>
		<meeting>of CSCL&apos;09</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="345" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Digital mysteries: designing for learning at the tabletop</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kharrufa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Leat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Olivier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ITS&apos;10</title>
		<meeting>of ITS&apos;10</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="197" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Roles of Orientation in Tabletop Collaboration: Comprehension, Coordination and Communication</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kruger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Supported Cooperative Work</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="501" to="537" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Rethinking&apos;multi-user&apos;: an in-the-wild study of how groups approach a walk-up-and-use tabletop interface</title>
		<author>
			<persName><forename type="first">P</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kreitmayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Davies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CHI&apos;11</title>
		<meeting>of CHI&apos;11</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Towards Adapting Group Activities in Multitouch Tabletops</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mart√≠n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Haya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adj. Proc. of UMAP</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="28" to="30" />
			<date type="published" when="2010">2010</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Analysing frequent sequential patterns of collaborative learning activity around an interactive tabletop</title>
		<author>
			<persName><forename type="first">R</forename><surname>Martinez Maldonado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yacef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kharrufa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Al-Qaraghuli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. of EDM</title>
		<imprint>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Designing tabletop-based systems for user modelling of collaboration</title>
		<author>
			<persName><forename type="first">R</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ackad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yacef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ASTC&apos;11</title>
		<meeting>of ASTC&apos;11</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Visualisations for longitudinal participation, contribution and progress of a collaborative task at the tabletop</title>
		<author>
			<persName><forename type="first">R</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yacef</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CSCL&apos;11. ISLS</title>
		<meeting>of CSCL&apos;11. ISLS</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Considering multi-touch display technology for collaboration in the classroom</title>
		<author>
			<persName><forename type="first">M</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Butler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EDMEDIA&apos;09</title>
		<meeting>of EDMEDIA&apos;09</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="674" to="683" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Some Useful Design Tactics for Mining ITS Data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mostow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc of ITS&apos;04, Workshop on Analyzing Student-Tutor Interaction Logs to Improve Educational Outcomes</title>
		<meeting>of ITS&apos;04, Workshop on Analyzing Student-Tutor Interaction Logs to Improve Educational Outcomes</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Individual and Group Support in Tabletop Interaction Techniques</title>
		<author>
			<persName><forename type="first">C</forename><surname>M√ºller-Tomfelde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Nacenta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pinelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gutwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mandryk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Springer</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Concept maps and Vee diagrams: two metacognitive tools to facilitate meaningful learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Novak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Instructional Science</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="29" to="52" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">System guidelines for co-located, collaborative work on a tabletop display</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Mandryk</surname></persName>
		</author>
		<idno>ECSCW &apos;03</idno>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="159" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">From Mirroring to Guiding: A Review of State of the Art Technology for Supporting Collaborative Learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Soller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Muehlenbrock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJAIED</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="261" to="290" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pahud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Buxton</surname></persName>
		</author>
		<title level="m">VisTACO: visualizing tabletop collaboration Proc. of ITS&apos;10</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="29" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">How pairs interact over a multimodal digital table</title>
		<author>
			<persName><forename type="first">E</forename><surname>Tse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Forlines</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI&apos;2007</title>
		<meeting>CHI&apos;2007</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="215" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Computer-supported collaborative learning in higher education: scripts for argumentative knowledge construction in distributed groups</title>
		<author>
			<persName><forename type="first">A</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Stegmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CSCL&apos;05</title>
		<meeting>of CSCL&apos;05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="717" to="726" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">WeSpace: the design development and deployment of a walk-up and share multi-surface visual collaboration system</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wigdor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Forlines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Borkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human factors in computing systems ACM</title>
		<imprint>
			<biblScope unit="page" from="1237" to="1246" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Smart meeting systems: A survey of state-of-the-art and open issues</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
