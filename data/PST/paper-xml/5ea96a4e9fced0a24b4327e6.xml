<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Learning and Time Series-to-Image Encoding for Financial Forecasting</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Silvio</forename><surname>Barra</surname></persName>
							<email>silvio.barra@uni-ca.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics and Computer Sci-ence</orgName>
								<orgName type="institution">University of Cagliari</orgName>
								<address>
									<postCode>09121</postCode>
									<settlement>Cagliari</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics and Computer Sci-ence</orgName>
								<orgName type="institution">University of Cagliari</orgName>
								<address>
									<postCode>09121</postCode>
									<settlement>Cagliari</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Salvatore</forename><forename type="middle">Mario</forename><surname>Carta</surname></persName>
							<email>salvatore@unica.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics and Computer Sci-ence</orgName>
								<orgName type="institution">University of Cagliari</orgName>
								<address>
									<postCode>09121</postCode>
									<settlement>Cagliari</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andrea</forename><surname>Corriga</surname></persName>
							<email>andrea.corriga@unica.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics and Computer Sci-ence</orgName>
								<orgName type="institution">University of Cagliari</orgName>
								<address>
									<postCode>09121</postCode>
									<settlement>Cagliari</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alessandro</forename><forename type="middle">Sebastian</forename><surname>Podda</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics and Computer Sci-ence</orgName>
								<orgName type="institution">University of Cagliari</orgName>
								<address>
									<postCode>09121</postCode>
									<settlement>Cagliari</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Diego</forename><forename type="middle">Reforgiato</forename><surname>Recupero</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics and Computer Sci-ence</orgName>
								<orgName type="institution">University of Cagliari</orgName>
								<address>
									<postCode>09121</postCode>
									<settlement>Cagliari</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Learning and Time Series-to-Image Encoding for Financial Forecasting</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">57841D1FE68B00986102A38F2EF36F7D</idno>
					<idno type="DOI">10.1109/JAS.2020.1003132</idno>
					<note type="submission">received October 19, 2019; revised December 22, 2019, February 6, 2020; accepted March 9, 2020.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T04:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Convolutional neural networks (CNNs)</term>
					<term>ensemble of CNNs</term>
					<term>financial forecasting</term>
					<term>Gramian angular fields (GAF) imaging</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the last decade, market financial forecasting has attracted high interests amongst the researchers in pattern recognition. Usually, the data used for analysing the market, and then gamble on its future trend, are provided as time series; this aspect, along with the high fluctuation of this kind of data, cuts out the use of very efficient classification tools, very popular in the state of the art, like the well known convolutional neural networks (CNNs) models such as Inception, ResNet, AlexNet, and so on. This forces the researchers to train new tools from scratch. Such operations could be very time consuming. This paper exploits an ensemble of CNNs, trained over Gramian angular fields (GAF) images, generated from time series related to the Standard &amp; Poor's 500 index future; the aim is the prediction of the future trend of the U.S. market. A multi-resolution imaging approach is used to feed each CNN, enabling the analysis of different time intervals for a single observation. A simple trading system based on the ensemble forecaster is used to evaluate the quality of the proposed approach. Our method outperforms the buyand-hold (B&amp;H) strategy in a time frame where the latter provides excellent returns. Both quantitative and qualitative results are provided.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Introduction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S</head><p>INCE the dawn of the financial market, people have been trying to build tools able to provide insights and information about the stock price variations in the near future, so to increase the possibilities to invest on the right company <ref type="bibr" target="#b1">[1]</ref>, future, etc. Since then, the market has become much bigger, and the available instruments for financial forecasting have reached an unprecedented efficiency. Nowadays, the research in this area is one of the most active amongst the pattern recognition related topics, and at the same time it is one of the most challenging. This is mainly due to the fact that stock prices are often influenced by factors which are quite hard predictable like political events, the behaviour of the other stock markets and, last but not least, the psychology of the in-vestors <ref type="bibr" target="#b2">[2]</ref>; these aspects tend to model the market as an entity which is dynamic, non-linear, non-parametric, and chaotic <ref type="bibr" target="#b3">[3]</ref>.</p><p>Notwithstanding the above components, the research performed in recent years in this field is growing both in terms of literature production and in tools generation <ref type="bibr" target="#b4">[4]</ref>, <ref type="bibr" target="#b5">[5]</ref>; also, an increasing number of studies involves the use of learning approaches like machine learning classifiers and neural network models. Essentially, these techniques cover most of the research achieved in the field. The neural networks approaches applied to financial forecasting started approximately across the end of 80's and the beginning of 90's.</p><p>In those years, one of the first artificial neural network has been proposed <ref type="bibr" target="#b1">[1]</ref>, with the aim of predicting the Tokyo stock exchange price indexes (TOPIX Index), by taking six metric vectors as input. In the same year, the authors in <ref type="bibr" target="#b6">[6]</ref> built a recurrent neural network for stock price patterns' recognition, exploiting the triangle pattern as a clue to the trend of the future stock prices. In <ref type="bibr" target="#b7">[7]</ref>, a similar approach has exploited eleven market indicators for building and training a recurrent neural network for monthly transition of the stock price index <ref type="bibr" target="#b8">[8]</ref>. Several approaches have also been proposed in the field, facing the financial series prediction topic by using the dendritic neuron model (DNM) technique <ref type="bibr" target="#b9">[9]</ref>, whose performances have been shown both on Asiatic <ref type="bibr" target="#b10">[10]</ref> and U.S. market <ref type="bibr" target="#b11">[11]</ref>. These techniques have evolved a lot in the recent 10 years, as well as the finance itself <ref type="bibr" target="#b12">[12]</ref>. As a consequence, dozens of scientific papers have been published, proposing approaches which aim at predicting the stock prices by exploiting news data extracted from the most popular social networks for modelling the uncertainty which lies behind the fluctuation of the market <ref type="bibr" target="#b13">[13]</ref>. Financial forecasting is indeed one of the research branches in which sentiment analysis found a quite breeding ground <ref type="bibr" target="#b14">[14]</ref>, <ref type="bibr" target="#b15">[15]</ref>.</p><p>Alongside the artificial neural networks (ANN), also the machine learning approaches had the possibility to show their efficiency through the years. In <ref type="bibr" target="#b16">[16]</ref>, the authors have compared the capabilities of the support vector machines <ref type="bibr" target="#b17">[17]</ref> in market prediction related issues against those obtained by using the radial basis function (RBF) networks and back propagation (BP). In <ref type="bibr" target="#b18">[18]</ref>, a recent literature review is performed, which compares the modern machine learning approaches in financial forecasting field.</p><p>Interesting results have also been obtained when fusing together the above described techniques: as an example, in <ref type="bibr" target="#b19">[19]</ref> the authors have fused ANN with decision trees (DT). The rationale behind this hybrid approach is that where ANNs are able to provide quite good performances in forecasting the market trend, a DT model is stronger in generating potential rules which describe the forecasting decisions. Similarly, in <ref type="bibr" target="#b20">[20]</ref>, a two-stage fusion approach is proposed for predicting CNX Nifty and S&amp;P Bombay Stock Exchange (BSE) Sensex from Indian stock markets. Specifically, the first stage uses a support vector regressor (SVR), whereas the second one exploits, in turn, ANN, random forest, and SVR. Ten indicators have been selected as input to the prediction models. In general, however, predicting the daily direction (positive or negative) of the market requires to solve a classification problem, whereas directly predicting the profit needs to address a regression problem. A comparison of different market price prediction approaches is shown in <ref type="bibr" target="#b21">[21]</ref>, where classification-based approaches usually provide better results, such as <ref type="bibr" target="#b22">[22]</ref>- <ref type="bibr" target="#b24">[24]</ref>, rather than some regression-based competitors. As reported in <ref type="bibr" target="#b25">[25]</ref>, moreover, "there is no general consensus on best forecasting technique for price prediction", particularly since "price series is inherently a non-stationary series having non-constant mean and variance", making it not always advantageous to represent the problem through linear models such as regression.</p><p>Furthermore, the actual trend of the research seems to be oriented towards the analysis of the data in their raw forms, therefore as time series, without doing any dimensionality changing. Inspired by recent successes of supervised and unsupervised learning techniques in computer vision, and with the aim to change this trend, in this paper we propose a trading system based on the forecast of the daily direction of a market index by exploiting the discriminatory capabilities of the convolutional neural networks (CNN) when dealing with GAF images. Indeed, CNNs has shown very good accuracy results when applied to pattern recognition on image and video data <ref type="bibr" target="#b26">[26]</ref>, <ref type="bibr" target="#b27">[27]</ref>. We encoded time series as images to allow machines to visually recognise, classify and learn structures and patterns. Reformulating features of time series as visual clues has raised much attention in computer science and physics <ref type="bibr" target="#b28">[28]</ref>.</p><p>Model training, evaluation and testing are executed on Standard &amp; Poor's 500 (S&amp;P500) index future. Time series of the future prices are processed in a twofold way: firstly, different intervals of time are considered, in order to analyse the same trend under different points of view; then, GAF images are built for each of the defined time intervals. Therefore, the main contributions of the proposed approach are as follows.</p><p>• The proposed system exploits the GAF imaging approach for encoding time series data as images;</p><p>• The composition of GAF images in a multi-resolution structure helps improving the market prediction results;</p><p>• The classification phase is carried out by organising in an ensemble a set of CNNs which have the same architecture, but each of them is initialized with a different kernel function for initialization. A majority voting-based policy is adopted;</p><p>• Comparisons both with state of the art baseline approaches (e.g., buy-and-hold (B&amp;H) strategy) and with the results of an existing competitor method (Calvi et al. <ref type="bibr" target="#b29">[29]</ref>) have been performed, showing that the proposed system is capable of obtaining a higher profit in the same investment period.</p><p>The remainder of this paper is organised as follows: Section II outlines the developed method, from the generation of the GAF images to the description of the ensemble of CNNs. Sections III and IV describe, respectively, the experiments' settings, along with the data preparation and the dataset description, and show and discuss the qualitative and quantitative results. Section V ends the paper with conclusions and future work where we are headed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. The Proposed Approach</head><p>As pointed in Section I, most of the research in market prediction and financial forecasting is based on ANN or machine learning approaches. These models are commonly trained on time series data describing a market index in the past, with the goal of predicting its future trend. The aim of this work is to achieve market prediction over the S&amp;P500 index, by using an ensemble of CNNs, with the training phase executed over GAF images (particularly, the GADF). This particular kind of imaging technique is detailed in Section II-B. The rightmost part of Fig. <ref type="figure" target="#fig_0">1</ref> shows how the proposed trading system works; firstly, the data of the original time series are aggregated according to 4 intervals of time; then, consecutive time frames of 20 observations are extracted from each time series, in order to generate the related set of GADF images. Twenty similar CNNs (whose architecture is shown in the leftmost part of Fig. <ref type="figure" target="#fig_0">1</ref>) are trained over these images, and the threshold-driven ensemble approach takes place for deciding which action to perform the day after the observations, as described in what follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Trading Strategy</head><p>We design our system to simulate a classic intraday trading strategy. This strategy generally consists of buying or selling a specific financial instrument (in our case, the S&amp;P500 index future), by making sure that any open position is closed before the market closes in the same trading day. Specifically, we model our strategy such that, for each single trading day, the final output of our system is one of the following actions:</p><p>• A long action, which consists of buying the stock, and then selling it before the market closes;</p><p>• A short action, which consists of selling the stock (using the mechanism of the uncovered sale), and then buying it before the market closes;</p><p>• A hold action, which consists of deciding not to invest in that day.</p><p>The ideal target of this strategy requires the system to choose the action that maximizes the economic return (i.e., the profit) of the day, given a prediction about the stock price trend in that day (i.e., whether the price will rise or fall). Thus, a long action is performed whenever our system predicts that the price will rise in that day; conversely, a short action is chosen whenever our system predicts that the price will fall in that day; last case, a hold action is performed whenever the system is not enough confident about the market behaviour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Gramian Angular Fields Imaging</head><p>The GAF imaging is an elegant way to encode time series as images. This has been proposed by Wang and Oates in <ref type="bibr" target="#b30">[30]</ref>.</p><p>The main reasons which led to the definition of this approach regards the possibility to use existing pre-trained models, rather than training recurrent neural networks from scratch or using 1D-CNN models. The last two models may result inconvenient.</p><formula xml:id="formula_0">X = {x 1 , x 2 , . . . , x n } n</formula><p>In order to build the GAF images, first a rescaling of the real observations of the time series is needed; therefore, let be the considered time series with components, the rescaling to the interval [-1, 1] is achieved by applying the mean normalization xi</p><formula xml:id="formula_1">= (x i -max(X)) + (x i -min(X)) max(X) -min(X)</formula><p>.</p><p>(1)</p><formula xml:id="formula_2">X = { x1 , x2 , . . . , xn }</formula><p>Hence, the scaled series is represented by . This is transformed to a polar coordinates system by computing the angular cosine of the single components of the scaled time series</p><formula xml:id="formula_3">           θ i = arccos( xi ), xi ∈ X r i = i N , with t i ≤ N            . (<label>2</label></formula><formula xml:id="formula_4">)</formula><p>Finally, Gramian summation angular field (GASF) and Gramian difference angular field can be easily obtained by computing the sum/difference between the points of the time series</p><formula xml:id="formula_5">GASF = [cos(θ i + θ j )] = X • X - √ I -X2 ′ • √ I -X2 GADF = [sin(θ i + θ j )] = √ I -X2 ′ • X -X • √ I -X2 .<label>(3</label></formula><p>) Fig. <ref type="figure" target="#fig_2">2</ref> shows the process for transforming a time series to the GADF and GASF images. It is worth to notice that the equations in (3) produce a 1D matrix as an output of the encoding process. This matrix actually represents a heatmap, whose values range from 0 (blue) to 1 (red). In a successive step, we applied the RGB color map to the image, thus resulting in a three channel matrix (further details on this process can be found in <ref type="bibr" target="#b28">[28]</ref> and <ref type="bibr" target="#b30">[30]</ref>). Note that the application of the color map is not strictly required by our approach; however, preliminary experiments showed us that applying the color map to the images led us to obtain better results and, additionally, to achieve a faster network convergence and stability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Multi-Resolution Time Series Imaging</head><formula xml:id="formula_6">D = {T, F 1 , F 2 , . . . , F N } F i i = 1, 2, . . . , N D j D j+1 I D D 1 , D 2 , . . . , D K I D k &gt; I D k = 1, . . . , K</formula><p>The time-series data show a quite important factor, that is the variation of a feature across the time and, therefore, how quickly data change. The speed which regulates the change of the features provides many insights about the evolution of the event: unfortunately, this peculiarity is hidden or even impossible to identify when data granularity is too coarse. As a trivial example, let us think to how important is the granularity of information in weather forecasting: an actual changing from sunny to rainy which occurs in few minutes gives different information with respect to the same change in 24 hours period. Moreover, often the observations contained in a time series are not done at the same interval of time, i.e., the distance between two consecutive observations is not always the same, thus forcing the researcher to aggregate the data for uniforming this distance through the entire time series. Given the two factors described above, our approach proposes a multi-resolution imaging, which aggregates the data under K different intervals of time, thus creating K different, but analogous, time series. Let be the original time series in which T defines the moment in which the observations of a given event are done, and with are the features describing the event. Given two consecutive observations in D, let us say and , let be the distance between them in terms of time. The new K aggregated time series are , and the interval between two consecutive observations is for each .  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Ensemble of CNNs</head><p>Once the time series are converted to GADF images, the training phase can take place. Fig. <ref type="figure" target="#fig_0">1</ref> shows the architecture of the convolutional neural network involved (on the left). It consists of a simplified version of the VGG-16 network <ref type="bibr" target="#b31">[31]</ref>, composed by 5 convolutional layers and a fully-connected one. Although our approach is independent of the network adopted, our choice was motivated by the fact that very deep networks were not suitable for the task, given the low number of samples at our disposal (S&amp;P500 only has a few thousands of daily samples). Indeed, our early tests showed that the simplified VGG led us to significantly improve the results, learning stability and execution times, both when compared to the standard VGG-16 and ResNet <ref type="bibr" target="#b32">[32]</ref> architectures.</p><p>Additionally, note that no padding is added, therefore the    nets are trained, the test samples are given as input to all the networks. The final decision of the ensemble is taken by applying a majority voting based approach, which returns a specific output , according to the percentage of networks which agree with the same classification. In the experimental results section, six different thresholds (related to the agreement percentage of the networks) are tested, from to 1, according to the percentage of networks which agree to the same classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. Experimental Settings</head><p>This section describes the settings of the experimental phase. In particular, first, in Section III-A the dataset S&amp;P500 is presented and described along with the B&amp;H investment strategy applied on it. This represents the baseline comparison method for the majority of the trading systems. Then, in Section III-B, the validation approach is defined. Finally, in Section III-C the ensemble policy is shown.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Evaluation and S&amp;P500</head><p>The S&amp;P500 is maybe the most important U.S. index. Born in 1789, at the beginning it only consisted of 90 titles. 1957, the year corresponding to when computers started to be actively applied to the financial market, the number of quoted companies has grown up to 500. It followed that S&amp;P500 became one of the most influencing market in the U.S., even overcoming the Dow-Jones index. For the trading operations the S&amp;P500 futures have been used. They consist of futures contracts on a stock or a financial index. These derivative securities are used by investors and portfolio managers to hedge their equity positions against a loss in stocks; in other words, S&amp;P500 index is used by those who want to hedge risk over a certain period of time.</p><p>Currently, S&amp;P500 index is one of the most widely traded index future contracts in the U.S. and it is computed by multiplying the S&amp;P500 value by $50. As an example, if the S&amp;P500 is at a level of 2500, then the market value of a future contract is 2500 × $50 or $125 000.</p><p>The S&amp;P500 data are publicly available on many platforms over Internet; also, these can be downloaded at different levels of granularity, according to the scope of the research that is being carried out. Historically the data are tracked and gathered once every 15 s, but some of the platforms only provide data daily. More in detail, for each of the acquired records, the following data are available.</p><p>• Date of the observation: mm/dd/yyyy; • Interval of the observation: hh:mm:ss;</p><p>• Open: the value the index has opened in the specified date;</p><p>• Close: the value the index has closed in the specified date;</p><p>• High: the highest value reached by the index in the specified date;</p><p>• Low: the lowest value reached by the index in the specified date.</p><p>We decided to use S&amp;P500 as a benchmark for several reasons. First of all, because it is one of the most relevant stock markets in the world. The second reason is that it is extremely challenging to forecast its behaviour. Indeed, it shows a high level of volatility, where this measure indicates the mean fluctuation of the market over a certain time interval. The practical importance of this factor relies on the assumption that there is a tight correlation between the mean fluctuation and the quantification of the risks related to the asset <ref type="bibr" target="#b33">[33]</ref>. In the recent years, many studies have been conducted in this area to the point that a specific branch of the market-related research focuses on the prediction of this fluctuation <ref type="bibr">[34]</ref>. On top of this, we can use the performances of the B&amp;H applied on S&amp;P500 as a direct benchmark. B&amp;H is both a strategy easy to replicate, and also an extremely significant competitor when considering a time frame where the market performs a large and quite constant growth. Indeed, B&amp;H is a passive investment strategy where an investor buys stocks and holds them for a long time, with the hope that stocks will gradually increase in value over a long period of time. This strategy works as follows: given an investment period, B&amp;H "buys" a stock at the beginning, "holds" it for the entire investment period, and sells it at the end. The net profit is the difference between the price at the end period and the price at the beginning. In Fig. <ref type="figure" target="#fig_5">4</ref>, the selected time frame for comparing our approach against the B&amp;H strategy is shown (from 2009-02-01 to 2014-07-31); it is easy to notice that this investment period is extremely favourable for B&amp;H and extremely challenging for our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Walks' Definition</head><formula xml:id="formula_7">t t + 1</formula><p>With respect to the common cross-validation approaches, which are typically applied when dealing with image classification, like the leave-one-out cross validation (LOOCV) or the k-fold cross validation, time series data need a more specific purpose approach, since they need to consider the semantic linking between the observation at time and the one at time . The walk-forward validation strategy properly fits in this scenario since the folds which are considered for the validation are temporally split, and internally processed as one sample. As a consequence, the use of GADF helps maintaining the correlation between two consecutive observations, thus keeping unaltered the semantic of the succession.</p><p>For our own research we considered an investment period which goes from 2000-02-01 to 2015-01-30, for a total of 16 years and 4569 observations which are related to the actual days in which the financial market has been opened. Each observation has been labelled according to the difference close-open of the day after which is • 1, if the close-open value of the day after is positive;</p><p>• 0, otherwise. The data are divided in training, validation and testing sets; in Table <ref type="table" target="#tab_1">II</ref>, the walks are shown: in particular, each model has been trained over a period of ten years, validated over the following six months and finally tested over the last six months.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. CNN Training and Ensemble Policy</head><p>According to the considerations exposed in Section II-C, we used K = 4 for the evaluation of our approach. Starting from the original time series of S&amp;P500, in which the observations are sampled at intervals of 5 minutes, the data have been aggregated according to 4 new intervals:</p><p>• 1 hour; • 4 hours; • 8 hours; • 1 day. This means that starting from the original time series, we aggregated the data in four different ways and from each we selected 20 samples for predicting the market-day after (20 1hour blocks make one GADF for the first time series, 20 4hours blocks make one more GADF image, etc.).</p><p>The close-open value has been computed for each sample, and a 20 × 20 × 3 GADF image has been built and composed according to the process shown in Fig. <ref type="figure" target="#fig_1">3</ref>. By following this procedure, the aggregated GADF image will have dimension 40 × 40 × 3. For each of the walks defined in the previous section, the ensemble of CNNs is executed over the test samples; the majority voting approach works as follows: each of the</p><formula xml:id="formula_8">t ∈ [0.5, 1] A A n &gt; tN A</formula><p>CNN gives as output a single-value which is 0 or 1 whether the CNN suggests to perform a short or a long action, respectively. When working in ensemble, the final prediction is taken according to the answer of all the CNNs, according to the trading strategy defined in Section II-A. Note that in cases where not all the CNNs agree with the same result, a coveragebase approach is used: let N be the number of networks involved in the ensemble, be a threshold which indicates the required percentage of agreement, and be the most predicted action (between long or short) by the nets for the considered day. Then, the system performs in that day if and only if at least networks have voted ; conversely, if the agreement threshold is not reached, the system does not perform any operation and just holds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. Results and Discussion</head><p>In this section, the quantitative and qualitative results are shown and discussed. In the following we report the metrics we have used.  • The Accuracy is a well-known metric; it is defined as the ratio between the number of correct predictions against the total number of test samples;</p><p>• The Coverage is a metric (expressed as a percentage) which indicates how many times the networks in the ensemble agree on an action, according to the threshold set;</p><p>• The annualized Sharpe Ratio is a financial risk index used to help investors to understand the return of an investment compared to its risk; the greater the value of the Sharpe Ratio, the more attractive the risk-adjusted return;</p><p>• As the term suggests, the Net Profit is the actual profit we earned in the testing period;</p><p>• The Sortino Ratio is a variation of the Sharpe Ratio that differentiates harmful volatility from total overall volatility by using the asset's standard deviation of negative portfolio returns; it is defined as follows:</p><formula xml:id="formula_9">S ortino Ratio = R p -r f σ d (4) R p r f σ d</formula><p>where is the actual portfolio return, is the risk-free rate, and is the standard deviation of the downside; • The return over maximum drawdown (RoMaD) is the average return in a given period for a portfolio; it is computed as follows:</p><formula xml:id="formula_10">RoMaD = NetPro f it MDD (5)</formula><p>where the Portfolio Return is the effective gain or loss realized by an investment, and the MDD indicates the maximum draw down (MDD), which is defined as the maximum loss from a peak to a trough of a portfolio, before a new peak is attained. Currently the MDD is the preferred way to evaluate the riskiness of an investment.</p><p>The results of the proposed approach have been compared against the following baselines:</p><p>• B&amp;H strategy: as explained in Section III, this represents the baseline comparison method for the majority of the trading system approaches;</p><p>• Random guessing: this easy technique exploits 10 random classifiers, included in an ensemble that using a majority voting approach tries to perform long or short operations. The comparison against this random predictor serves as proof that our approach does not act randomly, that the performed actions (longs or shorts) have a strong basis, and that the criteria are correctly learnt from the past trend of the market;</p><p>• 1D-CNN: this approach does not apply the GADF transformation to the time series; therefore, the time series are directly applied and processed by 1D-CNN. This test aims at showing the benefits of the GADF transformations in the proposed approach. 0.5 0.7 Fig. <ref type="figure" target="#fig_7">5</ref> shows the performances of the simple trading system based on our forecasting approach (in blue) against those described before: the B&amp;H strategy (in red), the 1D-CNN (in and the random guessing (in orange). The performances are computed over all the walks that have been taken into account; on the x-axis of each plot the considered threshold for the ensemble is indicated. Overall, the thresholds from to let us obtain the best achievements. As shown in the plot, the proposed approach is the only one capable of sensitively overcome the baseline performance of the B&amp;H. However, a peak in the performance is appreciable with the threshold set to , in which the highest net profit is obtained. The quantitative results are shown in Table <ref type="table" target="#tab_2">III</ref> and further confirm the good qualitative scores. Moreover, the table shows the big difference between the net profit obtained by our approach and the B&amp;H strategy. Using ensemble thresholds higher than , the results tend to degrade, mainly due to the fact that it becomes harder to obtain a total agreement among the nets in the ensemble. Anyway, even with a threshold set to 1 (meaning that all the nets must agree to trigger a long or short action), we managed to earn $ ; thus, we still do not lose money, even though the risk is quite high, as shown in the Sharpe Ratio and Sortino Ratio plots. In general, the good performances for all the threshold values are a clear indicator of the robustness of our proposed approach.</p><p>In addition to comparing our results to the baselines, we have also considered the approach proposed by Calvi et al. <ref type="bibr" target="#b29">[29]</ref>, which consists of the daily prediction of the S&amp;P500 index, as in our case, but by using a support tensor machine (STM) as a predictor (defined as a tensor extension of the better known support vector machine). Fig. <ref type="figure">6</ref> shows the gap between the net profit given by our method, and those returned by the B&amp;H and the work in <ref type="bibr" target="#b29">[29]</ref>. The comparison does not take into account the market period related to the 2008's Financial Crisis (whose effects impacted the years between 2007 and early 2009), when it results unfair to overcome the B&amp;H strategy, due to the dramatic performances of the index in this period.</p><p>Conversely, the considered period (from late 2009 until 2016) highlights a strong increase of the S&amp;P500 index, thus improving the B&amp;H performances. Nevertheless, our method is able to outperform such performances, which is not the case of the approach in <ref type="bibr" target="#b29">[29]</ref>.</p><p>Finally, note that, in the financial forecasting domain, the prediction accuracy is very close to 50%, mainly due to the high variability of the indexes which complicates a lot the decision between long and short actions. In this scenario, using a single CNN (both in terms of prediction and, where appropriate, in terms of probability of the prediction) usually introduces a major drawback: the initialization seed may significantly affect the final result. Moreover, focusing on improving the accuracy does not usually imply the net profit to grow accordingly. It follows that, by slightly changing the initialization, the same network could give worse results for the same period, or in any case could behave too differently when tested on different markets. This reveals the need of stabilizing the results; the ensemble architecture, together with different weight initialization policies, has shown to have a much more robust behaviour, allowing us to obtain more stable results and thus alleviate the randomness. As a result, according to the set thresholds, we perform a long operation only when the ensemble suggests to buy when a certain ensemble voting policy is satisfied; otherwise we perform a short operation. The mitigation of the randomness yields two simple but significant consequences.</p><p>• When we lose, we tend to lose very little;</p><p>• When we win, we tend to win considerably.  This result is to be considered particularly significant, thanks to the capability of our approach of beating the B&amp;H strategy in the years in which the latter performs well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. Conclusions</head><p>In this paper we have proposed an innovative approach for the forecasting of market behaviour by using deep learning technologies and by encoding time series to GAF images. The developed CNNs have been applied to the GAF images for a classification task. Moreover, an ensemble was fed with the CNNs above ans a majority voting strategy has been used to select the final classification. High results have been obtained using the S&amp;P500 future, the market where we have trained, validated and tested our networks and the overall ensemble. The GAF imaging technique has thus been applied within the financial technology domain bringing the benefits of CNN. Moreover, our approach, combination of deep learning and GAF images technologies, outperformed the baseline strategies consisting of B&amp;H operations for a classification task where long and short actions can be performed. The analysis of the tuning of several hyperparameters is being carried out by our team and is subject of future works. Currently we are studying the stacking policy of the GAF images (as shown in Fig. <ref type="figure" target="#fig_1">3</ref>), and how accuracy and net profit vary according to the value of K (currently set to 4). Note that our approach outperforms the B&amp; H strategy, although the latter was still very competitive and profitable within the considered period. As our approach is highly promising, there are several directions we would like to explore.</p><p>• First of all, we would like to apply our method to other markets and understand the benefits it brings with respect to the baselines;</p><p>• Then, something we are already exploring consists of applying the results of our ensemble to real trading platforms. The goal is to simulate the real earnings we would obtain on the past data and on a certain market. The platform we are already playing with is MultiCharts<ref type="foot" target="#foot_1">1</ref> ;</p><p>• We would also like to test our approach on different classification tasks within several domains such as sentiment analysis, emotion detection, credit scoring. The reason is to understand how the GAF imaging performs in presence of text or different kind of feature vectors. Fig. <ref type="figure">6</ref>. The comparison, in terms of cumulative profit, between the proposed approach (in blue) and the approach in <ref type="bibr" target="#b29">[29]</ref> (in black). Finally, in orange, we show the B&amp;H baseline as a benchmark.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. On the leftmost side of the figure the architecture of the convolutional neural network is shown. On the rightmost side, the overall process of the proposed trading system is depicted.</figDesc><graphic coords="3,97.18,56.61,418.56,234.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3</head><label>3</label><figDesc>Fig. 3 shows the composition approach in which (a)-(d) are four GADF images built from four time-series which differ for their aggregation intervals. The composition aims at building a unique image, which considers the evolution of the time series in a fixed period of time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The policy of composition of the multi-resolution GADF images; in particular, (a)-(d) refer to the same label, but the observations considered in each are aggregated in four different ways.</figDesc><graphic coords="4,359.49,52.11,124.56,156.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. The process leading to the generation of the GAF images: from left to right, the data are first plotted and then the coordinate system is transformed to a polar plane; finally, the GADF and GASF images are generated according to the function defined in (3).</figDesc><graphic coords="4,90.98,344.49,167.04,133.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>mode = "fan_in," distr. = "normal" -RandomNormal mean = 0.0, stddev = 0.05 -RandomUniform minval = -0.05,maxval = 0minval = -0.05, maxval = 0.05 42 TruncatedNormal mean = 0.0, stddev = 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. The net profit obtained by the application of the buy-and-hold strategy is shown over the period which has been taken into account for the experiments (https://www.investing.com/indices/us-spx-500-futures).</figDesc><graphic coords="6,80.62,52.37,435.84,211.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5 .</head><label>5</label><figDesc>Fig.5. The comparison among the tested approaches. In particular, the blue, orange and green lines represent, respectively, the results obtained by applying our approach, a random guessing approach and a 1D-CNN. The red line evidences the results which are obtained by the buy-and-hold strategy. In each plot, the -axis indicates the ensemble threshold considered, while in the -axis it is shown the obtained Net Profit, the RoMaD value, the annualized Sharpe Ratio and the Sortino Ratio, respectively, from the upper-leftmost image to the bottom-rightmost one.</figDesc><graphic coords="8,145.13,212.70,162.00,120.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I</head><label>I</label><figDesc>For Each Trained CNN, a Different Weight Initialization Method is Applied. In the Table, the Set of Configuration Paramenters is Reported</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II 11</head><label>II</label><figDesc>The Walks Used for Training, Validation, and Testing the Models and how They are Composed</figDesc><table><row><cell></cell><cell>Training</cell><cell>Validation</cell><cell>Test</cell></row><row><cell>#</cell><cell>since → to</cell><cell>since → to</cell><cell>since → to</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III The</head><label>III</label><figDesc>Quantitative Results of the Proposed Approach. for Each Metric, the Best Result is Highlighted in Bold</figDesc><table><row><cell></cell><cell>Threshold</cell><cell>Coverage (%)</cell><cell>Accuracy (%)</cell><cell>Net Profit ($)</cell><cell>RoMaD</cell><cell>Annualized Sharpe Ratio</cell><cell>Sortino Ratio</cell></row><row><cell></cell><cell>0.500</cell><cell>95.433</cell><cell>52.638</cell><cell>66.625</cell><cell>8.289</cell><cell>1.196</cell><cell>0.452</cell></row><row><cell></cell><cell>0.600</cell><cell>72.423</cell><cell>54.810</cell><cell>82.312</cell><cell>11.95</cell><cell>1.808</cell><cell>0.828</cell></row><row><cell></cell><cell>0.700</cell><cell>47.716</cell><cell>56.564</cell><cell>62.600</cell><cell>8.517</cell><cell>1.518</cell><cell>1.009</cell></row><row><cell>Proposed approach</cell><cell>0.800</cell><cell>22.950</cell><cell>56.632</cell><cell>46.2125</cell><cell>9.105</cell><cell>1.596</cell><cell>1.504</cell></row><row><cell></cell><cell>0.900</cell><cell>7.494</cell><cell>53.125</cell><cell>17.4875</cell><cell>3.970</cell><cell>0.452</cell><cell>0.370</cell></row><row><cell></cell><cell>1.000</cell><cell>1.990</cell><cell>55.882</cell><cell>1.375</cell><cell>0.365</cell><cell>-1.445</cell><cell>-0.524</cell></row><row><cell></cell><cell>0.500</cell><cell>94.906</cell><cell>47.254</cell><cell>-69.525</cell><cell>-0.904</cell><cell>-0.936</cell><cell>-0.425</cell></row><row><cell></cell><cell>0.600</cell><cell>74.824</cell><cell>46.791</cell><cell>-52.250</cell><cell>-0.832</cell><cell>-0.921</cell><cell>-0.420</cell></row><row><cell></cell><cell>0.700</cell><cell>53.688</cell><cell>46.564</cell><cell>-40.725</cell><cell>-0.927</cell><cell>-1.172</cell><cell>-0.451</cell></row><row><cell>1D-CNN</cell><cell>0.800</cell><cell>33.723</cell><cell>46.875</cell><cell>-13.2875</cell><cell>-0.749</cell><cell>-0.743</cell><cell>-0.281</cell></row><row><cell></cell><cell>0.900</cell><cell>15.456</cell><cell>48.106</cell><cell>-6.650</cell><cell>-0.463</cell><cell>-0.836</cell><cell>-0.387</cell></row><row><cell></cell><cell>1.000</cell><cell>7.494</cell><cell>49.218</cell><cell>1.3375</cell><cell>0.200</cell><cell>-0.582</cell><cell>-0.293</cell></row><row><cell></cell><cell>0.500</cell><cell>82.552</cell><cell>48.297</cell><cell>-41.912</cell><cell>-0.991</cell><cell>-0.930</cell><cell>-0.395</cell></row><row><cell></cell><cell>0.600</cell><cell>26.639</cell><cell>50.109</cell><cell>-9.575</cell><cell>-0.596</cell><cell>-0.661</cell><cell>-0.265</cell></row><row><cell></cell><cell>0.700</cell><cell>4.449</cell><cell>42.105</cell><cell>-5.775</cell><cell>-0.604</cell><cell>-1.665</cell><cell>-0.586</cell></row><row><cell>Random guessing</cell><cell>0.800</cell><cell>0.292</cell><cell>20.000</cell><cell>-1.275</cell><cell>-0.610</cell><cell>-4.067</cell><cell>-1.331</cell></row><row><cell></cell><cell>0.900</cell><cell>0.000</cell><cell>0.000</cell><cell>n.a.</cell><cell>n.a.</cell><cell>n.a</cell><cell>n.a</cell></row><row><cell></cell><cell>1.000</cell><cell>0.000</cell><cell>0.000</cell><cell>n.a.</cell><cell>n.a.</cell><cell>n.a.</cell><cell>n.a.</cell></row><row><cell>B&amp;H</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>56.600</cell><cell>3.847</cell><cell>0.258</cell><cell>0.394</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Authorized licensed use limited to: University of Canberra. Downloaded on May 02,2020 at 14:20:53 UTC from IEEE Xplore. Restrictions apply.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>https://www.multicharts.com/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan X GPU used for this research.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported by the "Bando Aiuti per progetti di Ricerca e Sviluppo-POR FESR 2014-2020-Asse 1, Azione 1.1.3. Project AlmostAnOracle-AI and Big Data Algorithms for Financial Time Series Forecasting". Recommended by Associate Editor MengChu Zhou.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>He co-founded 6 companies within the ICT sector and is actively involved in European projects and research (with one of his companies he won more than 30 FP7 and H2020 projects). His current research interests include sentiment analysis, semantic web, natural language processing, human robot interaction, financial technology, and smart grid. In all of them, machine learning, deep learning, big data are key technologies employed to effectively solve several tasks. He is author of more than 100 conference and journal papers in these research fields, with more than 1000 citations.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Stock market prediction system with modular neural networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Asakawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yoda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Takeoka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Joint Conf. Neural Networks</title>
		<meeting>Int. Joint Conf. Neural Networks<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Stock market prediction of S&amp;P500 via combination of improved BCO approach and BP neural network</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="8849" to="8854" />
			<date type="published" when="2009-07">Jul. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Brain-inspired genetic complementary learning for stock market prediction</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Z</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Quek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr<address><addrLine>Edinburgh, Scotland, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="2653" to="2660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Applications of ANNs in stock market prediction: a survey</title>
		<author>
			<persName><forename type="first">S</forename><surname>Soni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Sci. Eng. Technol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="71" to="83" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Self-learning of multivariate time series using perceptually important points</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lintonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Raty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/CAA J. Autom. Sinica</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1318" to="1331" />
			<date type="published" when="2019-11">Nov. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Stock price pattern recognition-a recurrent neural network approach</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kamijo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tanigawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Joint Conf. Neural Networks</title>
		<meeting>Int. Joint Conf. Neural Networks<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="215" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Prediction of monthly transition of the composition stock price index using recurrent back-propagation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Park</surname></persName>
		</author>
		<editor>Artificial Neural Networks, I. Aleksander and J. Taylor</editor>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Elsevier</publisher>
			<biblScope unit="page" from="1629" to="1632" />
			<pubPlace>Amsterdam, Netherlands</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Using artificial neural network models in stock market index prediction</title>
		<author>
			<persName><forename type="first">E</forename><surname>Guresen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kayakutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">U</forename><surname>Daim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="10389" to="10397" />
			<date type="published" when="2011-08">Aug. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dendritic neuron model with effective learning algorithms for classification, approximation, and prediction</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yachi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="601" to="614" />
			<date type="published" when="2019-02">Feb. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A dendritic neuron model with nonlinearity validation on Istanbul stock and Taiwan futures exchange indexes prediction</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Todo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th IEEE Int. Conf. Cloud Computing and Intelligence Systems</title>
		<meeting>5th IEEE Int. Conf. Cloud Computing and Intelligence Systems<address><addrLine>Nanjing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="242" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Financial time series prediction using a dendritic neuron model</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Todo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl-Based Syst</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="214" to="224" />
			<date type="published" when="2016-08">Aug. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Frontiers of finance: evolution and efficient markets</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Farmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Lo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl. Acad. Sci. USA</title>
		<meeting>Natl. Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="1999-08">Aug. 1999</date>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="9991" to="9992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sentiment analysis of twitter data for predicting stock market movements</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Pagolu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Panda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Majhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Signal Processing, Communication, Power and Embedded System</title>
		<meeting>Int. Conf. Signal essing, Communication, Power and Embedded System<address><addrLine>Paralakhemundi, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1345" to="1350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Stock prediction using twitter sentiment analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goel</surname></persName>
		</author>
		<ptr target="http://cs229.stanford.edu/proj2011/GoelMittal-StockMarketPredictionUsingTwitterSentimentAnalysis.pdf" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The impact of microblogging data for stock market prediction: using twitter to predict returns, volatility, trading volume and survey sentiment indices</title>
		<author>
			<persName><forename type="first">N</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cortez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="125" to="144" />
			<date type="published" when="2017-05">May 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Support vector machine for regression and applications to financial forecasting</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Trafalis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ince</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Computing: New Challenges and Perspectives for the New Millennium</title>
		<meeting><address><addrLine>Como, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000. 2000</date>
			<biblScope unit="page" from="348" to="353" />
		</imprint>
	</monogr>
	<note>Proc. IEEE-INNS-ENNS Int. Joint Conf. Neural Networks</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Support-vector networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995-09">Sept. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Literature review: machine learning techniques applied to financial market prediction</title>
		<author>
			<persName><surname>Calvi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Dates Cumulative profit</title>
		<imprint>
			<date type="published" when="2010">2000 1500 1000 500 2010 2011 2012 2013. 2014. Jun. 2019</date>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page" from="226" to="251" />
		</imprint>
	</monogr>
	<note>3000 Our approach B&amp;H baseline 2500</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Stock price forecasting by hybrid machine learning techniques</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. MultiConf. Engineers and Computer Scientists</title>
		<meeting>Int. MultiConf. Engineers and Computer Scientists<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">60</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Predicting stock market index using fusion of machine learning techniques</title>
		<author>
			<persName><forename type="first">J</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Thakkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kotecha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2162" to="2172" />
			<date type="published" when="2015-03">Mar. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Stock market analysis: a review and taxonomy of prediction techniques</title>
		<author>
			<persName><forename type="first">D</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Isah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zulkernine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Financ. Stud</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">26</biblScope>
			<date type="published" when="2019-06">Jun. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Evaluating multiple classifiers for stock price direction prediction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ballings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Van Den Poel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hespeels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gryp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="7046" to="7056" />
			<date type="published" when="2015-11">Nov. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Predicting the direction of stock market prices using tree-based classifiers</title>
		<author>
			<persName><forename type="first">S</forename><surname>Basak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Khaidem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Dey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Finance</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="552" to="567" />
			<date type="published" when="2019-01">Jan. 2019</date>
		</imprint>
	</monogr>
	<note>North Am</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Forecasting to classification: predicting the direction of stock market price using Xtreme gradient boosting</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Basak</surname></persName>
		</author>
		<idno type="DOI">10.13140/RG.2.2.15294</idno>
		<ptr target="https://doi.org/10.13140/RG.2.2.15294" />
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page">48968</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Price forecasting using wavelet transform and LSE based mixed model in Australian electricity market</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Saini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Energy Sector Manage</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="521" to="546" />
			<date type="published" when="2008-11">Nov. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep imitation learning for autonomous vehicles based on convolutional neural networks</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Kebria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khosravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Salaken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nahavandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/CAA J. Autom. Sinica</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="82" to="95" />
			<date type="published" when="2020-01">Jan. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep learning for source camera identification on mobile devices</title>
		<author>
			<persName><forename type="first">D</forename><surname>Freire-Obregón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Narducci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Barra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Castrillón-Santana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit. Lett</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="page" from="86" to="91" />
			<date type="published" when="2019-09">Sept. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Imaging time-series to improve classification and imputation</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Oates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 24th Int. Joint Conf. Artificial Intelligence</title>
		<meeting>24th Int. Joint Conf. Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Support tensor machine for financial forecasting</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Calvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lucic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Mandic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Acoustics, Speech and Signal Processing</title>
		<meeting>IEEE Int. Conf. Acoustics, Speech and Signal essing<address><addrLine>Brighton, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="8152" to="8156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Encoding time series as images for visual inspection and classification using tiled convolutional neural networks</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Oates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshops at the 29th AAAI Conf</title>
		<meeting>Workshops at the 29th AAAI Conf</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Q</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition<address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Volatility distribution in the S&amp;P500 stock index</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cizeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. A Stat. Mech. Appl</title>
		<imprint>
			<biblScope unit="volume">245</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="441" to="445" />
			<date type="published" when="1997-11">Nov. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Measuring and forecasting S&amp;P500 index-futures volatility using high-frequency data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Martens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Futur. Mark</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="497" to="518" />
			<date type="published" when="2002-06">Jun. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
