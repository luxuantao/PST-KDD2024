<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Taskonomy: Disentangling Task Transfer Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Amir</forename><forename type="middle">R</forename><surname>Zamir</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexander</forename><surname>Sax</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">William</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Leonidas</forename><surname>Guibas</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Taskonomy: Disentangling Task Transfer Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Do visual tasks have a relationship, or are they unrelated? For instance, could having surface normals simplify estimating the depth of an image? Intuition answers these questions positively, implying existence of a structure among visual tasks. Knowing this structure has notable values; it is the concept underlying transfer learning and provides a principled way for identifying redundancies across tasks, e.g., to seamlessly reuse supervision among related tasks or solve many tasks in one system without piling up the complexity.</p><p>We proposes a fully computational approach for modeling the structure of space of visual tasks. This is done via finding (first and higher-order) transfer learning dependencies across a dictionary of twenty six 2D, 2.5D, 3D, and semantic tasks in a latent space. The product is a computational taxonomic map for task transfer learning. We study the consequences of this structure, e.g. nontrivial emerged relationships, and exploit them to reduce the demand for labeled data. We provide a set of tools for computing and probing this taxonomical structure including a solver users can employ to find supervision policies for their use cases.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Object recognition, depth estimation, edge detection, pose estimation, etc are examples of common vision tasks deemed useful and tackled by the research community. Some of them have rather clear relationships: we understand that surface normals and depth are related (one is a derivate of the other), or vanishing points in a room are useful for orientation. Other relationships are less clear: how keypoint detection and the shading in a room can, together, perform pose estimation.</p><p>The field of computer vision has indeed gone far without explicitly using these relationships. We have made remarkable progress by developing advanced learning machinery (e.g. ConvNets) capable of finding complex mappings from Figure <ref type="figure">1</ref>: A sample task structure discovered by the computational task taxonomy (taskonomy). It found that, for instance, by combining the learned features of a surface normal estimator and occlusion edge detector, good networks for reshading and point matching can be rapidly trained with little labeled data.</p><p>X to Y when many pairs of (x, y) s.t. x ∈ X, y ∈ Y are given as training data. This is usually referred to as fully supervised learning and often leads to problems being solved in isolation. Siloing tasks makes training a new task or a comprehensive perception system a Sisyphean challenge, whereby each task needs to be learned individually from scratch. Doing so ignores their quantifiably useful relationships leading to a massive labeled data requirement.</p><p>Alternatively, a model aware of the relationships among tasks demands less supervision, uses less computation, and behaves in more predictable ways. Incorporating such a structure is the first stepping stone towards developing provably efficient comprehensive/universal perception models <ref type="bibr" target="#b30">[32,</ref><ref type="bibr" target="#b3">4]</ref>, i.e. ones that can solve a large set of tasks before becoming intractable in supervision or computation demands. However, this task space structure and its effects are still largely unknown. The relationships are non-trivial, and finding them is complicated by the fact that we have imperfect learning models and optimizers. In this paper, we attempt to shed light on this underlying structure and present a framework for mapping the space of visual tasks. Here what we mean by "structure" is a collection of computationally found relations specifying which tasks supply useful information to another, and by how much (see Fig. <ref type="figure">1</ref>).</p><p>We employ a fully computational approach for this purpose, with neural networks as the adopted computational function class. In a feedforward network, each layer successively forms more abstract representations of the input containing the information needed for mapping the input to the output. These representations, however, can transmit statistics useful for solving other outputs (tasks), presumably if the tasks are related in some form <ref type="bibr" target="#b77">[80,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b53">56,</ref><ref type="bibr" target="#b42">44]</ref>. This is the basis of our approach: we computes an affinity matrix among tasks based on whether the solution for one task can be sufficiently easily read out of the representation trained for another task. Such transfers are exhaustively sampled, and a Binary Integer Programming formulation extracts a globally efficient transfer policy from them. We show this model leads to solving tasks with far less data than learning them independently and the resulting structure holds on common datasets (ImageNet <ref type="bibr" target="#b72">[75]</ref> and Places <ref type="bibr" target="#b98">[101]</ref>).</p><p>Being fully computational and representation-based, the proposed approach avoids imposing prior (possibly incorrect) assumptions on the task space. This is crucial because the priors about task relations are often derived from either human intuition or analytical knowledge, while neural networks need not operate on the same principles <ref type="bibr" target="#b57">[60,</ref><ref type="bibr" target="#b29">31,</ref><ref type="bibr" target="#b36">38,</ref><ref type="bibr" target="#b41">43,</ref><ref type="bibr" target="#b96">99,</ref><ref type="bibr" target="#b82">85]</ref>. For instance, although we might expect depth to transfer to surface normals better (derivatives are easy), the opposite is found to be the better direction in a computational framework (i.e. suited neural networks better).</p><p>An interactive taxonomy solver which uses our model to suggest data-efficient curricula, a live demo, dataset, and code are available at http://taskonomy.vision/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Assertions of existence of a structure among tasks date back to the early years of modern computer science, e.g. with Turing arguing for using learning elements <ref type="bibr" target="#b89">[92,</ref><ref type="bibr" target="#b92">95]</ref> rather than the final outcome or Jean Piaget's works on developmental stages using previously learned stages as sources <ref type="bibr" target="#b68">[71,</ref><ref type="bibr" target="#b35">37,</ref><ref type="bibr" target="#b34">36]</ref>, and have extended to recent works <ref type="bibr" target="#b70">[73,</ref><ref type="bibr" target="#b67">70,</ref><ref type="bibr" target="#b46">48,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b91">94,</ref><ref type="bibr" target="#b55">58,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b60">63]</ref>. Here we make an attempt to actually find this structure. We acknowledge that this is related to a breadth of topics, e.g. compositional modeling <ref type="bibr" target="#b31">[33,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b19">21,</ref><ref type="bibr" target="#b51">53,</ref><ref type="bibr" target="#b86">89,</ref><ref type="bibr" target="#b84">87]</ref>, homomorphic cryptography <ref type="bibr" target="#b38">[40]</ref>, lifelong learning <ref type="bibr" target="#b87">[90,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b79">82,</ref><ref type="bibr" target="#b78">81]</ref>, functional maps <ref type="bibr" target="#b65">[68]</ref>, certain aspects of Bayesian inference and Dirichlet processes <ref type="bibr" target="#b50">[52,</ref><ref type="bibr" target="#b85">88,</ref><ref type="bibr" target="#b84">87,</ref><ref type="bibr" target="#b83">86,</ref><ref type="bibr" target="#b33">35,</ref><ref type="bibr" target="#b35">37]</ref>, few-shot learning <ref type="bibr" target="#b75">[78,</ref><ref type="bibr" target="#b21">23,</ref><ref type="bibr" target="#b20">22,</ref><ref type="bibr" target="#b64">67,</ref><ref type="bibr" target="#b80">83]</ref>, transfer learning <ref type="bibr" target="#b69">[72,</ref><ref type="bibr" target="#b78">81,</ref><ref type="bibr" target="#b25">27,</ref><ref type="bibr" target="#b58">61,</ref><ref type="bibr" target="#b61">64,</ref><ref type="bibr" target="#b54">57]</ref>, un/semi/self-supervised learning <ref type="bibr" target="#b18">[20,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b97">100,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b77">80]</ref>, which are studied across various fields <ref type="bibr" target="#b67">[70,</ref><ref type="bibr" target="#b88">91,</ref><ref type="bibr" target="#b9">10]</ref>. We review the topics most pertinent to vision within the constraints of space:</p><p>Self-supervised learning methods leverage the inherent relationships between tasks to learn a desired expensive one (e.g. object detection) via a cheap surrogate (e.g. colorization) <ref type="bibr" target="#b62">[65,</ref><ref type="bibr" target="#b66">69,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b97">100,</ref><ref type="bibr" target="#b94">97,</ref><ref type="bibr" target="#b63">66]</ref>. Specifically, they use a manually-entered local part of the structure in the task space (as the surrogate task is manually defined). In contrast, our approach models this large space of tasks in a computational manner and can discover obscure relationships.</p><p>Unsupervised learning is concerned with the redundancies in the input domain and leveraging them for forming compact representations, which are usually agnostic to the downstream task <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b45">47,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b28">30,</ref><ref type="bibr" target="#b71">74]</ref>. Our approach is not unsupervised by definition as it is not agnostic to the tasks. Instead, it models the space tasks belong to and in a way utilizes the functional redundancies among tasks.</p><p>Meta-learning generally seeks performing the learning at a level higher than where conventional learning occurs, e.g. as employed in reinforcement learning <ref type="bibr">[19,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b24">26]</ref>, optimization <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b76">79,</ref><ref type="bibr" target="#b44">46]</ref>, or certain architectural mechanisms <ref type="bibr" target="#b23">[25,</ref><ref type="bibr" target="#b26">28,</ref><ref type="bibr" target="#b81">84,</ref><ref type="bibr" target="#b59">62]</ref>. The motivation behind meta learning has similarities to ours and our outcome can be seen as a computational meta-structure of the space of tasks.</p><p>Multi-task learning targets developing systems that can provide multiple outputs for an input in one run <ref type="bibr" target="#b46">[48,</ref><ref type="bibr" target="#b15">16]</ref>. Multi-task learning has experienced recent progress and the reported advantages are another support for existence of a useful structure among tasks <ref type="bibr" target="#b87">[90,</ref><ref type="bibr" target="#b94">97,</ref><ref type="bibr" target="#b46">48,</ref><ref type="bibr" target="#b70">73,</ref><ref type="bibr" target="#b67">70,</ref><ref type="bibr" target="#b46">48,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b91">94,</ref><ref type="bibr" target="#b55">58,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b60">63]</ref>. Unlike multi-task learning, we explicitly model the relations among tasks and extract a meta-structure. The large number of tasks we consider also makes developing one multi-task network for all infeasible.</p><p>Domain adaption seeks to render a function that is developed on a certain domain applicable to another <ref type="bibr" target="#b40">[42,</ref><ref type="bibr" target="#b93">96,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b74">77,</ref><ref type="bibr" target="#b48">50,</ref><ref type="bibr" target="#b22">24,</ref><ref type="bibr" target="#b32">34]</ref>. It often addresses a shift in the input domain, e.g. webcam images to D-SLR <ref type="bibr" target="#b43">[45]</ref>, while the task is kept the same. In contrast, our framework is concerned with output (task) space, hence can be viewed as task/output adaptation. We also perform the adaptation in a larger space among many elements, rather than two or a few.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>We define the problem as follows: we want to maximize the collective performance on a set of tasks T = {t 1 , ..., t n }, subject to the constraint that we have a limited supervision budget γ (due to financial, computational, or time constraints). We define our supervision budget γ to be the maximum allowable number of tasks that we are willing to train from scratch (i.e. source tasks). The task dictionary is defined as V=T ∪ S where T is the set of tasks which we want solved (target), and S is the set of tasks that can be trained (source). Therefore, T − T ∩ S are the tasks that  we want solved but cannot train ("target-only"), T ∩ S are the tasks that we want solved but could play as source too, and S − T ∩ S are the "source-only" tasks which we may not directly care about to solve (e.g. jigsaw puzzle) but can be optionally used if they increase the performance on T . The task taxonomy (taskonomy) is a computationally found directed hypergraph that captures the notion of task transferability over any given task dictionary. An edge between a group of source tasks and a target task represents a feasible transfer case and its weight is the prediction of its performance. We use these edges to estimate the globally optimal transfer policy to solve T . Taxonomy produces a family of such graphs, parameterized by the available supervision budget, chosen tasks, transfer orders, and transfer functions' expressiveness.</p><p>Taxonomy is built using a four step process depicted in Fig. <ref type="figure" target="#fig_1">2</ref>. In stage I, a task-specific network for each task in S is trained. In stage II, all feasible transfers between sources and targets are trained. We include higher-order transfers which use multiple inputs task to transfer to one target. In stage III, the task affinities acquired from transfer function performances are normalized, and in stage IV, we synthesize a hypergraph which can predict the performance of any transfer policy and optimize for the optimal one.</p><p>A vision task is an abstraction read from a raw image. We denote a task t more formally as a function f t which maps image I to f t (I). Our dataset, D, contains for each task t a set of training pairs (I, f t (I)), e.g. (image, depth).</p><p>Task Dictionary: Our mapping of task space is done via <ref type="bibr" target="#b24">(26)</ref> tasks included in the dictionary, so we ensure they cover common themes in computer vision (2D, 3D, semantics, etc) to the elucidate fine-grained structures of task space. See Fig. <ref type="figure" target="#fig_2">3</ref> for some of the tasks with detailed definition of each task provided in the supplementary material.</p><p>It is critical to note the task dictionary is meant to be a sampled set, not an exhaustive list, from a denser space of all conceivable visual tasks. This gives us a tractable way to sparsely model a dense space, and the hypothesis is that (subject to a proper sampling) the derived model should  generalize to out-of-dictionary tasks. The more regular / better sampled the space, the better the generalization. We evaluate this in Sec. 4.2 with supportive results. For evaluation of the robustness of results w.r.t the choice of dictionary, see the supplementary material.</p><p>Dataset: We need a dataset that has annotations for every task on every image. Training all of our tasks on exactly the same pixels eliminates the possibility that the observed transferabilities are affected by different input data peculiarities rather than only task intrinsics. We created a dataset of 4 million images of indoor scenes from about 600 buildings; every image has an annotation for every task. The images are registered on and aligned with building-wide Source Task Encoder Target Task Output meshes similar to <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b95">98,</ref><ref type="bibr" target="#b11">12]</ref> enabling us to programmatically compute the ground truth for many tasks without human labeling. For the tasks that still require labels (e.g. scene classes), we generate them using Knowledge Distillation <ref type="bibr" target="#b39">[41]</ref> from known methods <ref type="bibr" target="#b98">[101,</ref><ref type="bibr">55,</ref><ref type="bibr" target="#b52">54,</ref><ref type="bibr" target="#b72">75]</ref>. See the supplementary material for full details of the process and a user study on the final quality of labels generated using Knowledge Distillation (showing &lt; 7% error).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Step I: Task-Specific Modeling</head><p>We train a fully supervised task-specific network for each task in S. Task-specific networks have an encoderdecoder architecture homogeneous across all tasks, where the encoder is large enough to extract powerful representations, and the decoder is large enough to achieve a good performance but is much smaller than the encoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Step II: Transfer Modeling</head><p>Given a source task s and a target task t, where s ∈ S and t ∈ T , a transfer network learns a small readout function for t given a statistic computed for s (see <ref type="bibr">Fig 4)</ref>. The statistic is the representation for image I from the encoder of s: E s (I). The readout function (D s→t ) is parameterized by θ s→t minimizing the loss L t :</p><formula xml:id="formula_0">D s→t := arg min θ E I∈D L t D θ E s (I) , f t (I) ,<label>(1)</label></formula><p>where f t (I) is ground truth of t for image I. E s (I) may or may not be sufficient for solving t depending on the relation between t and s (examples in Fig. <ref type="figure" target="#fig_5">5</ref>). Thus, the performance of D s→t is a useful metric as task affinity. We train transfer functions for all feasible source-target combinations.</p><p>Accessibility: For a transfer to be successful, the latent representation of the source should both be inclusive of sufficient information for solving the target and have the information accessible, i.e. easily extractable (otherwise, the raw image or its compression based representations would be optimal). Thus, it is crucial for us to adopt a low-capacity (small) architecture as transfer function trained with a small amount of data, in order to measure transferability conditioned on being highly accessible. We use a shallow fully convolutional network and train it with little data (8x to 120x less than task-specific networks).  Higher-Order Transfers: Multiple source tasks can contain complementary information for solving a target task (see examples in <ref type="bibr">Fig 6)</ref>. We include higher-order transfers which are the same as first order but receive multiple representations in the input. Thus, our transfers are functions D : ℘(S) → T , where ℘ is the powerset operator.</p><p>As there is a combinatorial explosion in the number of feasible higher-order transfers (|T | × |S| k for k th order), we employ a sampling procedure with the goal of filtering out higher-order transfers that are less likely to yield good results, without training them. We use a beam search: for transfers of order k ≤ 5 to a target, we select its 5 best sources (according to 1 st order performances) and include all of their order-k combination. For k ≥ 5, we use a beam of size 1 and compute the transfer from the top k sources.</p><p>We also tested transitive transfers (s → t 1 → t 2 ) which showed they do not improve the results, and thus, were not include in our model (results in supplementary material).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Step III: Ordinal Normalization using Analytic</head><p>Hierarchy Process (AHP)</p><p>We want to have an affinity matrix of transferabilities across tasks. Aggregating the raw losses/evaluations L s→t from transfer functions into a matrix is obviously problematic as they have vastly different scales and live in different spaces (see Fig. <ref type="figure" target="#fig_8">7</ref>-left). Hence, a proper normalization is needed. A naive solution would be to linearly rescale each row of the matrix to the range [0, 1]. This approach fails when the actual output quality increases at different speeds w.r.t. the loss. As the loss-quality curve is generally unknown, such approaches to normalization are ineffective.</p><p>Instead, we use an ordinal approach in which the output quality and loss are only assumed to change monotonically. For each t, we construct W t a pairwise tournament matrix between all feasible sources for transferring to t. The element at (i, j) is the percentage of images in a held-out test set, D test , on which s i transfered to t better than s j did (i.e. D si→t (I) &gt; D sj →t (I)).</p><p>We clip this intermediate pairwise matrix W t to be in [0.001, 0.999] as a form of Laplace smoothing. Then we divide W ′ t = W t /W T t so that the matrix shows how many times better s i is compared to s j . The final tournament ratio matrix is positive reciprocal with each element w ′ i,j of W ′ t : </p><p>We quantify the final transferability of s i to t as the corresponding (i th ) component of the principal eigenvector of W ′ t (normalized to sum to 1). The elements of the principal eigenvector are a measure of centrality, and are proportional to the amount of time that an infinite-length random walk on W ′ t will spend at any given source <ref type="bibr" target="#b56">[59]</ref>. We stack the principal eigenvectors of W ′ t for all t ∈ T , to get an affinity matrix P ('p' for performance)-see Fig. <ref type="figure" target="#fig_8">7</ref>, right.</p><p>This approach is derived from Analytic Hierarchy Process <ref type="bibr" target="#b73">[76]</ref>, a method widely used in operations research to create a total order based on multiple pairwise comparisons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Step IV: Computing the Global Taxonomy</head><p>Given the normalized task affinity matrix, we need to devise a global transfer policy which maximizes collective performance across all tasks, while minimizing the used supervision. This problem can be formulated as subgraph selection where tasks are nodes and transfers are edges. The optimal subgraph picks the ideal source nodes and the best edges from these sources to targets while satisfying that the number of source nodes does not exceed the supervision budget. We solve this subgraph selection problem using Boolean Integer Programming (BIP), described below, which can be solved optimally and efficiently <ref type="bibr" target="#b37">[39,</ref><ref type="bibr" target="#b13">14]</ref>.</p><p>Our transfers (edges), E, are indexed by i with the form ({s i 1 , . . . , s i mi }, t i ) where {s i 1 , . . . , s i mi } ⊂ S and t i ∈ T . We define operators returning target and sources of an edge:</p><formula xml:id="formula_2">{s i 1 , . . . , s i mi }, t i sources − −−−− → {s i 1 , . . . , s i mi } {s i 1 , . . . , s i mi }, t i target − −−− → t i .</formula><p>Solving a task t by fully supervising it is denoted as {t}, t . We also index the targets T with j so that in this section, i is an edge and j is a target. The parameters of the problem are: the supervision budget (γ) and a measure of performance on a target from each of its transfers (p i ), i.e. the affinities from P . We can also optionally include additional parameters of: r j specifying  See supplementary material for the full matrix with higher-order transfers.</p><p>the relative importance of each target task and ℓ i specifying the relative cost of acquiring labels for each task.</p><p>The BIP is parameterized by a vector x where each transfer and each task is represented by a binary variable; x indicates which nodes are picked to be source and which transfers are selected. The canonical form for a BIP is: maximize c T x , subject to Ax b and x ∈ {0, 1} |E|+|V| .</p><p>Each element c i for a transfer is the product of the importance of its target task and its transfer performance:</p><formula xml:id="formula_3">c i := r target(i) • p i .<label>(3)</label></formula><p>Hence, the collective performance on all targets is the summation of their individual AHP performance, p i , weighted by the user specified importance, r i . Now we add three types of constraints via matrix A to enforce each feasible solution of the BIP instance corresponds to a valid subgraph for our transfer learning problem: Constraint I: if a transfer is included in the subgraph, all of its source nodes/tasks must be included too, Constraint II: each target task has exactly one transfer in, Constraint III: supervision budget is not exceeded.</p><p>Constraint I: For each row a i in A we require a i • x ≤ b i , where</p><formula xml:id="formula_4">a i,k =      |sources(i)| if k = i −1 if (k − |E|) ∈ sources(i) 0 otherwise (4) b i = 0. (<label>5</label></formula><formula xml:id="formula_5">)</formula><p>Constraint II: Via the row a |E|+j , we enforce that each target has exactly one transfer:</p><formula xml:id="formula_6">a |E|+j,i := 2 • ✶ {target(i)=j} , b |E|+j := −1. (6)</formula><p>Constraint III: the solution is enforced to not exceed the budget. Each transfer i is assigned a label cost ℓ i , so</p><formula xml:id="formula_7">a |E|+|V|+1,i := ℓ i , b |E|+|V|+1 := γ.<label>(7)</label></formula><p>The elements of A not defined above are set to 0. The problem is now a valid BIP and can be optimally solved in a fraction of a second <ref type="bibr" target="#b37">[39]</ref>. The BIP solution x corresponds to the optimal subgraph, which is our taxonomy. Ji i i ig g g gsaw w w w Figure <ref type="figure">8</ref>: Computed taxonomies for solving 22 tasks given various supervision budgets (x-axes), and maximum allowed transfer orders (y-axes). One is magnified for better visibility. Nodes with incoming edges are target tasks, and the number of their incoming edges is the order of their chosen transfer function. Still transferring to some targets when tge budget is 26 (full budget) means certain transfers started performing better than their fully supervised task-specific counterpart. See the interactive solver website for color coding of the nodes by Gain and Quality metrics. Dimmed nodes are the source-only tasks, and thus, only participate in the taxonomy if found worthwhile by the BIP optimization to be one of the sources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>With 26 tasks in the dictionary (4 source-only tasks), our approach leads to training 26 fully supervised task-specific networks, 22 × 25 transfer networks in 1 st order, and 22 × 25 k for k th order, from which we sample according to the procedure in Sec. 3. The total number of transfer functions trained for the taxonomy was ∼3,000 which took 47,886 GPU hours on the cloud.</p><p>Out of 26 tasks, we usually use the following 4 as sourceonly tasks (described in Sec. 3) in the experiments: colorization, jigsaw puzzle, in-painting, random projection. However, the method is applicable to an arbitrary partitioning of the dictionary into T and S. The interactive solver website allows the user to specify any desired partition.</p><p>Network Architectures: We preserved the architectural and training details across tasks as homogeneously as possible to avoid injecting any bias. The encoder architecture is identical across all task-specific networks and is a fully convolutional ResNet-50 without pooling. All transfer functions include identical shallow networks with 2 conv layers (concatenated channel-wise if higher-order). The loss (L t ) and decoder's architecture, though, have to depend on the task as the output structures of different tasks vary; for all pixel-to-pixel tasks, e.g. normal estimation, the decoder is a 15-layer fully convolutional network; for low dimensional tasks, e.g. vanishing points, it consists of 2-3 FC layers. All networks are trained using the same hyperparameters regardless of task and on exactly the same input images. Tasks with more than one input, e.g. relative camera pose, share weights between the encoder towers. Transfer net-works are all trained using the same hyperparameters as the task-specific networks, except that we anneal the learning rate earlier since they train much faster. Detailed definitions of architectures, training process, and experiments with different encoders can be found in the supplementary material.</p><p>Data Splits: Our dataset includes 4 million images. We made publicly available the models trained on full dataset, but for the experiments reported in the main paper, we used a subset of the dataset as the extracted structure stabilized and did not change when using more data (explained in Sec. 5.2). The used subset is partitioned into training (120k), validation (16k), and test (17k) images, each from non-overlapping sets of buildings. Our task-specific networks are trained on the training set and the transfer networks are trained on a subset of validation set, ranging from 1k images to 16k, in order to model the transfer patterns under different data regimes. In the main paper, we report all results under the 16k transfer supervision regime (∼10% of the split) and defer the additional sizes to the supplementary material and website (see Sec. 5.2). Transfer functions are evaluated on the test set.</p><p>How good are the trained task-specific networks? Win rate (%) is the proportion of test set images for which a baseline is beaten. Table <ref type="table" target="#tab_2">1</ref> provides win rates of the taskspecifc networks vs. two baselines. Visual outputs for a random test sample are in Fig. <ref type="figure" target="#fig_2">3</ref>. The high win rates in Table <ref type="table" target="#tab_2">1</ref> and qualitative results show the networks are well trained and stable and can be relied upon for modeling the task space. See results of applying the networks on a YouTube video frame-by-frame here. A live demo for user uploaded queries is available here. To get a sense of the quality of our networks vs. state-ofthe-art task-specific methods, we compared our depth estimator vs. released models of <ref type="bibr" target="#b49">[51]</ref> which led to outperforming <ref type="bibr" target="#b49">[51]</ref> with a win rate of 88% and losses of 0.35 vs. 0.47 (further details in the supplementary material). In general, we found the task-specific networks to perform on par or better than state-of-the-art for many of the tasks, though we do not formally benchmark or claim this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Evaluation of Computed Taxonomies</head><p>Fig. <ref type="figure">8</ref> shows the computed taxonomies optimized to solve the full dictionary, i.e. all tasks are placed in T and S (except for 4 source-only tasks that are in S only). This was done for various supervision budgets (columns) and maximum allowed order (rows) constraints. Still seeing transfers to some targets when the budget is 26 (full dictionary) means certain transfers became better than their fully supervised task-specific counterpart.</p><p>While Fig. <ref type="figure">8</ref> shows the structure and connectivity, Fig. <ref type="figure" target="#fig_9">9</ref> quantifies the results of taxonomy recommended transfer policies by two metrics of Gain and Quality, defined as: Gain: win rate (%) against a network trained from scratch using the same training data as transfer networks'. That is, the best that could be done if transfer learning was not utilized. This quantifies the gained value by transferring. Quality: win rate (%) against a fully supervised network trained with 120k images (gold standard).</p><p>Each column in Fig. <ref type="figure" target="#fig_9">9</ref> shows a supervision budget. As apparent, good results can be achieved even when the supervision budget is notably smaller than the number of solved tasks, and as the budget increases, results improve (expected). Results are shown for 2 maximum allowed orders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Generalization to Novel Tasks</head><p>The taxonomies in Sec. 4.1 were optimized for solving all tasks in the dictionary. In many situations, a practitioner is interested in a single task which even may not be in the dictionary. Here we evaluate how taxonomy transfers to a novel out-of-dictionary task with little data. This is done in an all-for-one scenario where we put one task in T and all others in S. The task in T is target-only and has no task-specific network. Its limited data (16k) is used to train small transfer networks to sources. This basically localizes where the target would be in the taxonomy.   Fig. <ref type="figure" target="#fig_10">10</ref> (left) shows the Gain and Quality of the transfer policy found by the BIP for each task. Fig. <ref type="figure" target="#fig_10">10</ref> (right) compares the taxonomy suggested policy against some of the best existing self-supervised methods <ref type="bibr" target="#b90">[93,</ref><ref type="bibr" target="#b97">100,</ref><ref type="bibr" target="#b62">65,</ref><ref type="bibr" target="#b94">97,</ref><ref type="bibr" target="#b0">1]</ref>, ImageNet FC7 features <ref type="bibr" target="#b47">[49]</ref>, training from scratch, and a fully supervised network (gold standard).</p><p>The results in Fig. <ref type="figure" target="#fig_10">10</ref> (right) are noteworthy. The large win margin for taxonomy shows that carefully selecting transfer policies depending on the target is superior to fixed transfers, such as the ones employed by self-supervised methods. ImageNet features which are the most popular off-the-shelf features in vision are also outperformed by those policies. Additionally, though the taxonomy transfer policies lose to fully supervised networks (gold standard) in most cases, the results often get close with win rates in 40% range. These observations suggests the space has a rather predicable and strong structure. For graph visualization of the all-for-one taxonomy policies please see the supplementary material. The solver website allows generating the taxonomy for arbitrary sets of target-only tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Significance Test of the Structure</head><p>The previous evaluations showed good transfer results in terms of Quality and Gain, but how crucial is it to use our taxonomy to choose smart transfers over just choosing any transfer? In other words, how significant/strong is the discovered structure of task space? Fig. <ref type="figure">11</ref> quantifies this by showing the performance of our taxonomy versus a large set of taxonomies with random connectivities. Taxonomy outperformed all other connectivities by a large margin signifying both existence of a strong structure in the space as well as a good modeling of it by our approach. See the supplementary material for full experimental details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Evaluation on MIT Places &amp; ImageNet</head><p>To what extent are our findings dataset dependent, and would the taxonomy change if done on another dataset? We examined this by finding the ranking of all tasks for transferring to two target tasks of object classification and scene classification on our dataset. We then fine tuned our taskspecific networks on other datasets (MIT Places <ref type="bibr" target="#b98">[101]</ref> for scene classification, ImageNet <ref type="bibr" target="#b72">[75]</ref> for object classification) and evaluated them on their respective test sets and metrics. Fig. <ref type="figure" target="#fig_11">12</ref> shows how the results correlate with taxonomy's ranking from our dataset. The Spearman's rho between the taxonomy ranking and the Top-1 ranking is 0.857 on Places and 0.823 on ImageNet showing a notable correlation. See the supplementary material for full experimental details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Universality of the Structure</head><p>We employed a computational approach with various design choices. It is important to investigate how specific to those the discovered structure is. We did stability tests by computing the variance in our output when making changes in one of the following system choices: I. architecture of task-specific networks, II. architecture of transfer function networks, III. amount of data available for training transfer networks, IV. datasets, V. data splits, VI. choice of dictionary. Overall, despite injecting large changes (e.g. varying the size of training data of transfer functions by 16x, ImageNet <ref type="bibr" target="#b72">[75]</ref> and MIT Places <ref type="bibr" target="#b98">[101]</ref>. Y-axis shows accuracy on the external benchmark while bars on x-axis are ordered by taxonomy's predicted performance based on our dataset. A monotonically decreasing plot corresponds to preserving identical orders and perfect generalization.</p><p>size and architecture of task-specific networks and transfer networks by 4x), we found the outputs to be remarkably stable leading to almost no change in the output taxonomy computed on top. Detailed results and experimental setup of each tests are reported in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Limitations and Discussion</head><p>We presented a method for modeling the space of visual tasks by way of transfer learning and showed its utility in reducing the need for supervision. The space of tasks is an interesting object of study in its own right and we have only scratched the surface in this regard. We also made a number of assumptions in the framework which should be noted.</p><p>Model Dependence: We used a computational approach and adopted neural networks as our function class. Though we validated the stability of the findings w.r.t various architectures and datasets, it should be noted that the findings are in principle model and data specific.</p><p>Compositionality: We performed the modeling via a set of common human-defined visual tasks. It is natural to consider a further compositional approach in which such common tasks are viewed as observed samples which are composed of computationally found latent subtasks.</p><p>Space Regularity: We performed modeling of a dense space via a sampled dictionary. Though we showed a good tolerance w.r.t. to the choice of dictionary and transferring to out-of-dictionary tasks, this outcome holds upon a proper sampling of the space as a function of its regularity. More formal studies on properties of the computed space is required for this to be provably guaranteed for a general case.</p><p>Lifelong Learning: We performed the modeling in one go. In many cases, e.g. lifelong learning, the system is evolving and the number of mastered tasks constantly increase. Such scenarios require augmentation of the structure with expansion mechanisms based on new beliefs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Computational modeling of task relations and creating the taxonomy. From left to right: I. Train task-specific networks. II. Train (first order and higher) transfer functions among tasks in a latent space. III. Get normalized transfer affinities using AHP (Analytic Hierarchy Process). IV. Find global transfer taxonomy using BIP (Binary Integer Program).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Task Dictionary. Outputs of 24 (of 26) task-specific networks for a query (top left). See results of applying frame-wise on a video here.</figDesc><graphic url="image-52.png" coords="3,302.79,422.61,52.94,50.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Transfer Function. A small readout function is trained to map representations of source task's frozen encoder to target task's labels. If order&gt; 1, transfer function receives representations from multiple sources.</figDesc><graphic url="image-69.png" coords="4,299.88,120.24,74.32,61.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Transfer results to normals and 2.5D Segmentation from 5 different source tasks. The spread in transferability among sources is apparent. "Scratch" was trained from scratch without transfer learning.</figDesc><graphic url="image-66.png" coords="4,322.73,69.62,135.09,110.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Higher-Order Transfers. Representations can contain complementary information. E.g. by transferring simultaneously from 3D Edges and Curvature individual stairs were brought out. See our publicly available interactive transfer visualization page for more examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>A</head><label></label><figDesc>ut oe nc od in g Sc en e C la ss C ur va tu re D en oi si ng In -P ai nt in g C ol or iz at io n R an do m Pr oj . Ta sk -S pe ci fic O bj ec t C la ss (1 00 ) A ut oe nc od in g Sc en e C la ss O bj ec t C la ss (1 00 ) C ol or iz at io n C ur va tu re D en oi si ng O t C la ss . (1 00 0) O bj ec t C la ss . (1 00 0)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: First-order task affinity matrix before (left) and after (right) Analytic Hierarchy Process (AHP) normalization. Lower means better transfered. For visualization, we use standard affinity-distance method dist = e −β•P (where β = 20 and e is element-wise matrix exponential).See supplementary material for the full matrix with higher-order transfers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Evaluation of taxonomy computed for solving the full task dictionary. Gain (left) and Quality (right) values for each task using the policy suggested by the computed taxonomy, as the supervision budget increases(→). Shown for transfer orders 1 and 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Generalization to Novel Tasks. Each row shows a novel test task. Left: Gain and Quality values using the devised "all-for-one" transfer policies for novel tasks for orders 1-4. Right: Win rates (%) of the transfer policy over various self-supervised methods, ImageNet features, and scratch are shown in the colored rows. Note the large margin of win by taxonomy. The uncolored rows show corresponding loss values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Evaluating the discovered structure on other datasets:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Denoising 100 99.9 Layout 99.6 89.1 Scene Class. 97.0 93.4 Autoenc. 100 99.8 2D Edges 100 99.9 Occ. Edges 100 95.4 Reshading 94.9 95.2 Pose (fix) 76.3 79.5 Pose (nonfix) 60.2 61.9 Inpainting 99.9 -2D Segm. 97.7 95.7 2.5D Segm. 94.2 89.4 Curvature 78.7 93.4 Matching 86.8 84.6 Egomotion 67.5 72.3 Normals 99.4 99.5 Vanishing 99.5 96.4 2D Keypnt. 99.8 99.4 Z-Depth 92.3 91.1 Distance 92.4 92.1 3D Keypnt. 96.0 96.9 Mean 92.4 90.9 Task-Specific Networks' Sanity: Win rates vs. random (Gaussian) network representation readout and statistically informed guess avg.</figDesc><table><row><cell>Task</cell><cell>avg rand Task</cell><cell>avg rand Task</cell><cell>avg rand</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Structure Significance. Our taxonomy compared with random transfer policies (random feasible taxonomies that use the maximum allowable supervision budget). Y-axis shows Quality or Gain, and X-axis is the supervision budget. Green and gray represent our taxonomy and random connectivities, respectively. Error bars denote 5 th -95 th percentiles.</figDesc><table><row><cell>Taxonomy Signi cance Test</cell><cell></cell></row><row><cell>9</cell><cell></cell></row><row><cell>7</cell><cell></cell></row><row><cell>5</cell><cell></cell></row><row><cell>3</cell><cell></cell></row><row><cell>1</cell><cell></cell></row><row><cell>Supervision Budget</cell><cell>Supervision Budget</cell></row><row><cell>Figure 11:</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgement: We acknowledge the support of NSF (DMS-1521608), MURI (1186514-1-TBCJE), ONR MURI (N00014-14-1-0671), Toyota(1191689-1-UDAWF), ONR MURI (N00014-13-1-0341), Nvidia, Tencent, a gift by Amazon Web Services, a Google Focused Research Award.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning to see by moving</title>
		<author>
			<persName><forename type="first">P</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
				<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="37" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning to learn by gradient descent by gradient descent</title>
		<author>
			<persName><forename type="first">M</forename><surname>Andrychowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3981" to="3989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Joint 2d-3d-semantic data for indoor scene understanding</title>
		<author>
			<persName><forename type="first">I</forename><surname>Armeni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sax</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.01105</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Provable bounds for learning some deep representations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhaskara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="584" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Tabula rasa: Model transfer for object category detection</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Aytar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision (ICCV), 2011 IEEE International Conference on</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2252" to="2259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Representation learning: A review and new perspectives</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A survey of clustering data mining techniques. Grouping multidimensional data</title>
		<author>
			<persName><forename type="first">P</forename><surname>Berkhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Compositionality, mdl priors, and object recognition</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bienenstock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Potter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="838" to="844" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Integrated perception with recurrent multi-task neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bilen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="235" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Bingel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Søgaard</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.08303</idno>
		<title level="m">Identifying beneficial task relations for multi-task learning in deep neural networks</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Similarity by composition</title>
		<author>
			<persName><forename type="first">O</forename><surname>Boiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="177" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Halber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nießner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.06158</idno>
		<title level="m">Matterport3d: Learning from rgb-d data in indoor environments</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<title level="m">Lifelong Machine Learning</title>
				<imprint>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">V12. 1: Users manual for cplex</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">I</forename><surname>Cplex</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>International Business Machines Corporation</publisher>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page">157</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Unsupervised visual representation learning by context prediction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
				<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1422" to="1430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Multi-task self-supervised visual learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.07860</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Decaf: A deep convolutional activation feature for generic visual recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="647" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Krähenbühl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.09782</idno>
		<idno>arXiv:1611.02779</idno>
		<title level="m">Rl2: Fast reinforcement learning via slow reinforcement learning</title>
				<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Adversarial feature learning</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Why does unsupervised pre-training help deep learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="625" to="660" />
			<date type="published" when="2010-02">Feb. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">clustering by compositionunsupervised discovery of image categories</title>
		<author>
			<persName><forename type="first">A</forename><surname>Faktor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="474" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A bayesian approach to unsupervised oneshot learning of object categories</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fe-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision, 2003. Proceedings. Ninth IEEE International Conference on</title>
				<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="1134" to="1141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">One-shot learning of object categories</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
				<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="594" to="611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unsupervised visual domain adaptation using subspace alignment</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Habrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sebban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
				<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2960" to="2967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Model-agnostic metalearning for fast adaptation of deep networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.03400</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Guided cost learning: Deep inverse optimal control via policy optimization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<idno>CoRR, abs/1603.00448</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep spatial autoencoders for visuomotor learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics and Automation (ICRA), 2016 IEEE International Conference on</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="512" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Generalizing skills with semi-supervised reinforcement learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<idno>CoRR, abs/1612.00429</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Oneshot visual imitation learning via meta-learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<idno>CoRR, abs/1709.04905</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">A survey of dimension reduction techniques</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">K</forename><surname>Fodor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
		<respStmt>
			<orgName>Lawrence Livermore National Lab., CA (US)</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Catastrophic forgetting in connectionist networks: Causes, consequences and solutions</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>French</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Trends in Cognitive Sciences</title>
				<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="128" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Provable algorithms for machine learning problems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ge</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
		<respStmt>
			<orgName>Princeton University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Composition systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Potter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quarterly of Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="707" to="736" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Domain adaptation for object recognition: An unsupervised approach</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gopalan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision (ICCV), 2011 IEEE International Conference on</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="999" to="1006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">A theory of causal learning in children: Causal maps and bayes nets</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gopnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sobel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kushnir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Danks</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page" from="2" to="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">A theory of causal learning in children: causal maps and bayes nets. Psychological review</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gopnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Sobel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kushnir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Danks</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">111</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">The scientist in the crib: Minds, brains, and how children learn</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gopnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Meltzoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Kuhl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>William Morrow &amp; Co</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Neural turing machines</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<idno>CoRR, abs/1410.5401</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Optimization. Gurobi optimizer reference manual</title>
		<author>
			<persName><forename type="first">I</forename><surname>Gurobi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">The theory and applications of homomorphic cryptography</title>
		<author>
			<persName><forename type="first">K</forename><surname>Henry</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
		<respStmt>
			<orgName>University of Waterloo</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Continuous manifold based adaptation for evolving visual domains</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="867" to="874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Visual learning of arithmetic operations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hoshen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Peleg</surname></persName>
		</author>
		<idno>CoRR, abs/1506.02264</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Transferring deep convolutional neural networks for the scene classification of high-resolution remote sensing imagery</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-S</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="14680" to="14707" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Robust visual domain adaptation with low-rank reconstruction</title>
		<author>
			<persName><forename type="first">I.-H</forename><surname>Jhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2168" to="2175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno>CoRR, abs/1412.6980</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<title level="m">Auto-encoding variational bayes</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Ubernet: Training auniversal&apos;convolutional neural network for low-, mid-, and high-level vision using diverse datasets and limited memory</title>
		<author>
			<persName><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02132</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">What you saw is not what you get: Domain adaptation using asymmetric kernel transforms</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1785" to="1792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Deeper depth prediction with fully convolutional residual networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Laina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rupprecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Belagiannis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3D Vision (3DV), 2016 Fourth International Conference on</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="239" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">350</biblScope>
			<biblScope unit="issue">6266</biblScope>
			<biblScope unit="page" from="1332" to="1338" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Building machines that learn and think like people</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="101" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Fully convolutional instance-aware semantic segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">; T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.07709</idno>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2016. 2014</date>
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Microsoft coco: Common objects in context</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">CRF learning with CNN features for image segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<idno>CoRR, abs/1503.08263</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<title level="m">Label efficient learning of transferable representations across domains and tasks</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">The three rs of computer vision: Recognition, reconstruction and reorganization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Arbeláez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fragkiadaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tulsiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="4" to="14" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Random walks and diffusion on networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Masuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lambiotte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics Reports</title>
		<imprint>
			<biblScope unit="page" from="716" to="717" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Catastrophic interference in connectionist networks: The sequential learning problem. The Psychology of Learning and Motivation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="104" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Mapping and revising markov logic networks for transfer learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mihalkova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="608" to="614" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Exploiting similarities among languages for machine translation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<idno>CoRR, abs/1309.4168</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Crossstitch networks for multi-task learning</title>
		<author>
			<persName><forename type="first">I</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3994" to="4003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Inductive transfer for bayesian network structure learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
				<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="339" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName><forename type="first">M</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Representation learning by learning to count</title>
		<author>
			<persName><forename type="first">M</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pirsiavash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.06734</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Zero-shot learning by convex combination of semantic embeddings</title>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Frome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.5650</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Functional maps: a flexible representation of maps between shapes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ovsjanikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ben-Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Solomon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Butscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">30</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Context encoders: Feature learning by inpainting</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Krahenbuhl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2536" to="2544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Multi-task learning with labeled and unlabeled tasks. stat</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pentina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1050</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">The origins of intelligence in children</title>
		<author>
			<persName><forename type="first">J</forename><surname>Piaget</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cook</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1952">1952</date>
			<publisher>International Universities Press</publisher>
			<biblScope unit="volume">8</biblScope>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Discriminability-based transfer between neural networks</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Y</forename><surname>Pratt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="204" to="211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Playing for benchmarks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hayder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Nonlinear dimensionality reduction by locally linear embedding. science</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="page" from="2323" to="2326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2008">2015. 2, 4, 8</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">The analytic hierarchy process -what it is and how it is used</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Saaty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mat/d Modelling</title>
				<imprint>
			<date type="published" when="1987">1987. 1987</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="161" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Adapting visual category models to new domains</title>
		<author>
			<persName><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2010</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="213" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">One-shot learning with a hierarchical nonparametric bayesian model</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML Workshop on Unsupervised and Transfer Learning</title>
				<meeting>ICML Workshop on Unsupervised and Transfer Learning</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="195" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Trust region policy optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<idno>CoRR, abs/1502.05477</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Cnn features off-the-shelf: an astounding baseline for recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sharif Razavian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Azizpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carlsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition workshops</title>
				<meeting>the IEEE conference on computer vision and pattern recognition workshops</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="806" to="813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Guest editors introduction: special issue on inductive transfer learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Bennett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="215" to="220" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Lifelong machine learning systems: Beyond learning algorithms</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Spring Symposium Series</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Zeroshot learning through cross-modal transfer</title>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ganjoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="935" to="943" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Intriguing properties of neural networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<idno>CoRR, abs/1312.6199</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Generalization, similarity, and bayesian inference</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">629640</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kemp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<title level="m">How to grow a mind: Statistics, structure, and abstraction. science</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">331</biblScope>
			<biblScope unit="page" from="1279" to="1285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Theory-based bayesian models of inductive learning and reasoning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kemp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shafto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Trends in Cognitive Sciences</title>
				<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="309" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">Toward the neural implementation of structure learning. Current opinion in neurobiology</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G R</forename><surname>Tervo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="99" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">A deep hierarchical approach to lifelong learning in minecraft</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Givony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zahavy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Mankowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mannor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1553" to="1561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">Learning to learn</title>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pratt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Computing machinery and intelligence</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Turing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mind</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">236</biblScope>
			<biblScope unit="page" from="433" to="460" />
			<date type="published" when="1950">1950</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations using videos</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
				<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2794" to="2802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Transitive invariance for self-supervised visual representation learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02901</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">Thinking machines: Can there be? Are we</title>
		<author>
			<persName><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>University of California Press</publisher>
			<biblScope unit="volume">200</biblScope>
			<pubPlace>Berkeley</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Adapting svm classifiers to data with shifted distributions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Mining Workshops, 2007. ICDM Workshops</title>
				<imprint>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="page" from="69" to="76" />
		</imprint>
	</monogr>
	<note>Seventh IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Generic 3d representation via pose estimation and matching</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wekel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Gibson Env: Real-world perception for embodied agents</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sax</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title level="m" type="main">Understanding deep learning requires rethinking generalization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno>CoRR, abs/1611.03530</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Colorful image colorization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Learning deep features for scene recognition using places database</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2008">2014. 2, 4, 8</date>
			<biblScope unit="page" from="487" to="495" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
