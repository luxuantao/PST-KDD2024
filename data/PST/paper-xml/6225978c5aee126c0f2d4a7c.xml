<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ReuseTracker: Fast Yet Accurate Multicore Reuse Distance Analyzer</title>
				<funder ref="#_aKYU7bY">
					<orgName type="full">Scientific and Technological Research Council of Turkey (TUBITAK)</orgName>
				</funder>
				<funder>
					<orgName type="full">Royal Society-Newton Advanced Fellowship</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Muhammad</forename><forename type="middle">Aditya</forename><surname>Sasongko</surname></persName>
							<email>msasongko17@ku.edu</email>
						</author>
						<author>
							<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Marzijarani</surname></persName>
							<email>mmarzijarani20@ku.edu</email>
						</author>
						<author>
							<persName><forename type="first">D</forename><surname>Unat</surname></persName>
							<email>dunat@ku.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Ko? University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">MANDANA BAGHERI MARZIJARANI and DIDEM UNAT</orgName>
								<orgName type="institution" key="instit1">MILIND CHABBI</orgName>
								<orgName type="institution" key="instit2">Scalable Machines Research</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Ko? University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Ko? University</orgName>
								<address>
									<postCode>34450</postCode>
									<settlement>Sariyer, Istanbul</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ReuseTracker: Fast Yet Accurate Multicore Reuse Distance Analyzer</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3484199</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS Concepts:</term>
					<term>General and reference ? Measurement</term>
					<term>Performance</term>
					<term>? Computer systems organization ? Multicore architectures</term>
					<term>Reuse distance, hardware performance counters, debug registers, address sampling</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>One widely used metric that measures data locality is reuse distance-the number of unique memory locations that are accessed between two consecutive accesses to a particular memory location. State-of-the-art techniques that measure reuse distance in parallel applications rely on simulators or binary instrumentation tools that incur large performance and memory overheads. Moreover, the existing sampling-based tools are limited to measuring reuse distances of a single thread and discard interactions among threads in multi-threaded programs. In this work, we propose ReuseTracker-a fast and accurate reuse distance analyzer that leverages existing hardware features in commodity CPUs. ReuseTracker is designed for multi-threaded programs and takes cache-coherence effects into account. By utilizing hardware features like performance monitoring units and debug registers, ReuseTracker can accurately profile reuse distance in parallel applications with much lower overheads than existing tools. It introduces only 2.9? runtime and 2.8? memory overheads. Our tool achieves 92% accuracy when verified against a newly developed configurable benchmark that can generate a variety of different reuse distance patterns. We demonstrate the tool's functionality with two use-case scenarios using PARSEC, Rodinia, and Synchrobench benchmark suites where ReuseTracker guides code refactoring in these benchmarks by detecting spatial reuses in shared caches that are also false sharing and successfully predicts whether some benchmarks in these suites can benefit from adjacent cache line prefetch optimization.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Data locality remains an important concern in shared-memory multicore architectures and it is often a more important concern than computation in terms of both energy consumption and performance <ref type="bibr" target="#b54">[54]</ref>. Because of its importance, data locality optimizations have become a central focus of application tuning and tool development <ref type="bibr" target="#b55">[55]</ref>. One metric widely used to measure data locality is reuse distance. Reuse distance is an architecture-independent metric that is defined as the number of unique memory locations that are accessed between two consecutive accesses to a particular memory location (use and reuse). For example, consider a sequence of accessed memory locations: a 1 , b 1 , c 1 , b 2 , d 1 , a 2 . In this example, the reuse distance of a is three, because there are three unique locations accessed between the two consecutive accesses to a, namely, b, c, and d. Reuse distance shows the likelihood of a cache hit for a memory access in a typical least-recently used (LRU) cache. If the reuse distance of a memory access is larger than the cache size, then the latter access (reuse) is likely to cause a cache miss.</p><p>Reuse distance is well-studied for single-threaded programs <ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b8">8,</ref><ref type="bibr" target="#b10">10,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b21">21,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b37">37,</ref><ref type="bibr" target="#b49">49,</ref><ref type="bibr" target="#b64">64,</ref><ref type="bibr" target="#b65">65</ref>] and a handful of tools are available <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b60">60,</ref><ref type="bibr" target="#b64">64]</ref>. The techniques introduced in References <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b36">36]</ref> employ analytical models that digest and analyze execution traces to predict shared cache behavior. The execution traces needed by these models are generated through hardware simulation or binary instrumentation. Hardware simulators typically incur significant performance and memory overheads and hence are limited to studying only a small part of a full application. Similarly high overhead exists in binary instrumentation methods. Loca, a reuse distance analysis tool <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b64">64]</ref> implemented using PIN binary-instrumentation tool <ref type="bibr" target="#b42">[42]</ref> incurs 49? runtime and 40? memory overheads, which makes the tool impractical to use in real-life applications. In addition to the overhead problem, authors in Reference <ref type="bibr" target="#b41">[41]</ref> show that binary instrumentation can potentially distort the parallel schedule among threads of the profiled program.</p><p>Significant overheads and distortion of parallel schedule can also occur in the methods proposed in References <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b33">33,</ref><ref type="bibr" target="#b46">[46]</ref><ref type="bibr" target="#b47">[47]</ref><ref type="bibr" target="#b48">[48]</ref><ref type="bibr" target="#b59">59]</ref> as they rely on either hardware simulators or binary instrumentation. A technique that avoids these flaws was proposed in Reference <ref type="bibr" target="#b41">[41]</ref>. This technique reduces trace size by generating traces at coarser granularity instead of at every load/store access. However, as it operates at coarser granularity, it might miss reuses that are very near in distance while can still capture distant reuses. Another shortcoming of existing reuse distance profilers is that a limited number of them are publicly available. To the best of our knowledge, only Loca <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b64">64]</ref> and RDX <ref type="bibr" target="#b60">[60]</ref> are open source. Yet, both of these tools are limited to measuring reuse distances of a single thread and discard interactions among threads in multi-threaded programs. Considering the wide-spread use of multicore architectures, having a fast yet accurate reuse distance analysis tool for multi-threaded applications is the need of the hour.</p><p>This work proposes ReuseTracker-an open-source, low-overhead reuse distance analysis tool for multi-threaded applications. To make ReuseTracker fast and memory efficient, we leverage hardware counters of performance monitoring units (PMUs) and debug registers, which are commonly available in current commodity CPUs. In ReuseTracker's design, PMUs are utilized to periodically sample memory accesses (uses) in each profiled thread, while debug registers are used to trap the next accesses (reuses) to the sampled memory regions. While the prior PMUbased tools <ref type="bibr" target="#b7">[7,</ref><ref type="bibr" target="#b60">60]</ref> that profile reuse distance have focused only on reuses in a private cache of a core and single-threaded applications, our tool can analyze multi-threaded codes by considering cache line invalidations in detecting reuses in individual threads. Moreover, our tool detects reuses across different threads in profiling reuse distance in shared caches. This capability has several applications, one of which is deciding the cache sizes in multicore CPUs.</p><p>To account for cache-coherence effects when profiling reuse distance in threads, ReuseTracker employs a novel algorithm that monitors loads and stores in each thread. A thread that samples ReuseTracker: Fast Yet Accurate Multicore Reuse Distance Analyzer 3:3  <ref type="bibr" target="#b48">[48]</ref> Schuff et al. <ref type="bibr" target="#b47">[47]</ref> StatCache <ref type="bibr" target="#b7">[7]</ref> loca <ref type="bibr" target="#b64">[64]</ref> RDX <ref type="bibr" target="#b60">[60]</ref>  Overheads of RDX are measured using a sampling interval of 100K. *StatCache's accuracy is high in predicting miss ratio but it is not quantified in Reference <ref type="bibr" target="#b7">[7]</ref>.</p><p>a particular memory access arms one of its debug registers and the debug registers of other cores to trap any future accesses to the sampled accessed address. When a trap happens, if it pertains to the same core that had sampled the initial access, then reuse is detected. If the trap pertains to a store access in another core, then cache line invalidation is detected, reporting no reuse. When detecting reuse in a shared cache, when a trap happens in another core that shares the same cache with the sampling core, a reuse is detected. A cache line invalidation is detected when the trap is due to a store access in another core located on a different socket.</p><p>Evaluating multithreaded reuse distance, whether for threads or shared caches, turns out to be surprisingly complicated, because one may not know the ground truth reuse distance; the act of measuring the ground truth via instrumentation can perturb the parallel schedule and produce incorrect results unless an additional tool such as Intel's PinPlay <ref type="bibr" target="#b40">[40]</ref> that can record and replay application execution deterministically is used. Hence, we developed a benchmark that can generate a variety of reuse distance histograms to aid in validating ReuseTracker. Our set of benchmarks are useful not only for evaluating this work but can also serve to evaluate future tools in this area of research.</p><p>Table <ref type="table" target="#tab_0">1</ref> compares ReuseTracker against five similar tools that perform online reuse detection. ReuseTracker-to the best of our knowledge-is the first tool that accurately profiles reuse distances in threads and shared caches for multi-threaded applications while introducing significantly lower overhead compared to instrumentation-based or simulation-based tools. More specifically, it introduces 2.9? performance and 2.8? memory overheads. ReuseTracker relies on existing hardware features in commodity CPUs and works on fully optimized binaries, which makes it appropriate for monitoring full applications in production. Furthermore, ReuseTracker is more accurate compared to other available tools as it profiles multi-threaded code based on real hardware events without dilating the original execution. It achieves 92% accuracy when verified against a configurable-synthetic benchmark that we developed.</p><p>In our experimental study, we also demonstrate several use cases of ReuseTracker. We show that the reuse distance profiles produced by ReuseTracker can help guide code refactoring to reduce false sharing. Through this code refactoring, we could improve the performance of the benchmarks by up to 87%. Furthermore, we also show that our tool can help predict whether profiled applications can gain or lose performance when adjacent cache line prefetch (ACP) is enabled.</p><p>In summary, our contributions are listed as follows:</p><p>? Formal definitions of reuse in threads and shared caches as microarchitecture-independent events in multi-core systems. ? Low-overhead reuse distance analysis algorithms that profile reuse distance in threads and shared caches for multi-threaded programs. ? A synthetic benchmark that can be configured to produce a variety of reuse distance histograms. ? Open source implementation of aforementioned techniques in a tool called ReuseTracker, as well as extensive evaluation of this tool using a number of benchmarks and applications. ? Demonstration of use-case scenarios using PARSEC <ref type="bibr" target="#b9">[9]</ref>, Rodinia <ref type="bibr" target="#b12">[12]</ref>, and Synchrobench <ref type="bibr" target="#b22">[22]</ref> benchmark suites where ReuseTracker guides code refactoring in these benchmarks by detecting spatial reuses in shared cache that are also false sharing and predicts whether some benchmarks in these suites can benefit from ACP.</p><p>The repository of ReuseTracker is publicly available at https://github.com/ParCoreLab/ ReuseTracker.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND AND TERMINOLOGY</head><p>In this section, we first provide the background on reuse in single-threaded applications; we then expand the definition to multi-threaded applications; we finally provide a background of a few basic building-block hardware and software facilities needed to develop our tool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Single-threaded Reuse Distance</head><p>Time Reuse Distance and Reuse Distance: Time reuse distance is defined as the number of memory accesses between the current access (reuse) and the previous access to the same element (use). If the accessed element is in a unit of cache line, then reuse can be classified into two, temporal reuse and spatial reuse. A temporal reuse happens when both use and reuse access exactly the same address, while a spatial reuse occurs when its use and reuse access different addresses that are located in the same cache line.</p><p>The term reuse distance used in this work refers to LRU stack distance as defined in Reference <ref type="bibr" target="#b37">[37]</ref>. The difference between time reuse distance and reuse distance is described in the following example. Consider the sequence of memory accesses:</p><formula xml:id="formula_0">a 1 , b 1 , c 1 , b 2 , d 1 , d 2 a 2 .</formula><p>In this example, the time reuse distance of a is five, because there are five total memory accesses between the first access to a (a 1 ) and the second access to a (a 2 ). However, the reuse distance of a is three, since there are only three unique accesses between a 1 and a 2 , i.e., b, c, and d.</p><p>Time reuse histograms can be accurately translated into stack reuse histograms <ref type="bibr" target="#b50">[50,</ref><ref type="bibr" target="#b60">60]</ref>. ReuseTracker captures time-reuse during its online profiling and exploits the same conversion techniques during a post-processing step to finally present the stack reuse histograms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Multi-threaded Reuse Distance</head><p>We now define reuse as a microarchitecture-independent event in the context of cache-coherent multi-core systems. For the ease of prose, in the rest of this article, we treat OS threads being pinned to CPU cores and cores are not oversubscribed, hence we use the terms "threads" and "cores" interchangeably.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 2.1 (Intra-thread Reuse).</head><p>If two consecutive accesses (loads or stores) happen to the same memory location in the same thread without an intervening store to the same location in another thread, then the access pair represents an instance of reuse.  The time reuse distance is the number of memory accesses elapsed on the same thread between the use and reuse events. As we define intra-thread reuse as a microarchitecture-independent event, we disregard microarchitectural configurations such as private cache size, shared cache size, and cache inclusion policy. Therefore a reuse in a thread, no matter how long it is from its use, is always counted as a reuse even if it hits in a shared cache or DRAM memory in a real machine provided that it still happens in the same thread as the use. Definition 2.2 (Invalidation for Intra-thread Reuse). If two consecutive memory accesses happen to the same memory location by two different threads where the second access is a store operation, then the second access represents an instance of invalidation with respect to the first access.</p><p>An invalidation makes the previous access ineligible for reuse with the immediately next access to the same location. Reuse and invalidation are mutually exclusive events. A pair of consecutive memory accesses to the same location can also neither be a reuse nor be an invalidation; for example, a read by one core followed by a read of the same address by another core is neither a reuse nor an invalidation.</p><p>Table <ref type="table" target="#tab_2">2</ref> summarizes reuse, no-reuse, and invalidation in all possible read/write access and same/different core scenarios. R ? W indicates that a write access happens following the read access to the same location. The Read or Write may be accessing data at any level in the memory hierarchy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 2.3 (Reuse in Shared Cache</head><p>). If two consecutive memory accesses happen to the same memory location from two different cores that share the same cache on a multi-core machine, then the access pair represents an instance of reuse in the shared cache. Definition 2.3 covers a situation where one thread fetched data into the shared cache of a multicore system and a subsequent access by another core can reuse the same data without having to refetch it from the main memory. We are aware of the possibility that an intra-thread reuse might also hit in a shared cache or DRAM. However, we omit that situation from this definition as it has been covered by our definition of intra-thread reuse, and thus, will be detected by the intrathread profiling. On multi-socket systems, cores span beyond a single socket. In such cases, writes happening on another socket to the same address can create an invalidation at shared cache level. This is analogous to write accesses on another thread in the intra-thread reuse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 2.4 (Invalidation in Shared Cache</head><p>). If two consecutive memory accesses happen to the same memory location by cores on different sockets, where the second access is a store operation, then the second access represents an instance of shared cache invalidation with respect to the first access.</p><p>Table <ref type="table" target="#tab_3">3</ref> summarizes reuse, no-reuse, and invalidation in all possible read/write access and same/different core scenarios. We describe a few cells in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R?R:</head><p>The first access is a read that may access data at any level in the memory hierarchy. (a) If the subsequent read happens on the same core, then it is already captured as a reuse in the intra-thread profiling and thus not a case of shared-cache reuse. (b) If the subsequent read happens on another core of the same socket, then it offers an opportunity to exploit the data fetched by one core into the shared cache to be reused by another core (c) Finally, if the subsequent read happens on another socket, there is no reuse opportunity but it does not invalidate the data on the first socket.<ref type="foot" target="#foot_1">1</ref> R?W : This is similar to R?R except that the second access is a write and the write on a different socket causes an invalidation. W ?W : The first access is a write. (a) If the subsequent write happens on the same core, then it is already captured as a reuse in the intra-thread profiling and hence it is not counted as a case of shared-cache reuse. (b) If a subsequent write happens on another core of the same socket, then it is guaranteed to miss in its private cache; as before, it offers an opportunity for data reuse at the shared-cache level. (c) Finally, if the subsequent write happens on another socket, it will invalidate the data on the first socket. W ?R: This is similar toW ?W except that the subsequent read on another socket does not cause an invalidation on the first socket. A following R/W on the same socket can create a reuse pair.</p><p>Since we treat reuses and invalidations as microarchitecture-independent events, we do not consider microarchitectural configurations such as cache inclusion policy, private cache size, or shared cache size in our definition. Therefore, any memory access that we count as a reuse in shared cache does not necessarily hit in a shared cache in an actual machine. Nevertheless, we can still derive metrics such as L2 or L3 cache miss rates from the reuse distance profiles that follow this definition if the microarchitectural configurations of the machines are known. The reuse distance profiles based on this definition can also recommend suitable L3 cache sizes that optimize the applications' runtime.</p><p>Duality property: Shared and intra-thread reuses are the dual of one another. A pair of accesses can either be a reuse in a single thread or in the shared cache, but not both. If an access pair in the same core is counted toward intra-thread reuse, then it is not counted toward shared-cache reuse. If an access pair in the same socket is not counted toward intra-thread reuse, then it is counted toward shared-cache reuse on the same socket. A subsequent remote write operation always invalidates both intra-thread and shared cache reuses. A subsequent remote read operation never causes an invalidation but does not contribute toward reuses neither in a thread nor in a shared cache.</p><p>From the hardware perspective, reuse happens at the cache line granularity or sometimes larger than cache line granularities (e.g., Adjacent Cache-Line Prefetch <ref type="bibr" target="#b23">[23]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Background on Building Blocks</head><p>Hardware Performance Monitoring Unit (PMU): CPU's PMU has the ability to count hardware events such as retired instructions, loads, and stores to name a few. PMUs can be programmed to cause a counter overflow interrupt once a number of events elapse. This number of events is a configurable parameter called sampling period. A signal handler, which is a part of ReuseTracker, handles the OS signal triggered by the interrupt and collects the data, such as accessed effective address, related to the event that causes the interrupt. We refer to a PMU counter overflow interrupt as a "sample. " PMUs exist in each CPU core and virtualized by the OS for each OS thread.</p><p>ReuseTracker: Fast Yet Accurate Multicore Reuse Distance Analyzer 3:7</p><p>Intel's Precise Event-based Sampling (PEBS) <ref type="bibr" target="#b25">[25]</ref> allows the programmer to obtain the effective address accessed by the sampled instruction for memory access events such as loads, stores, and cache misses. This address sampling ability is provided in AMD processors by Instructionbased Sampling (IBS) feature <ref type="bibr" target="#b17">[17]</ref> since AMD Family 10h Processors, in POWER processors by Marked Events feature <ref type="bibr" target="#b52">[52]</ref> since POWER 5, and in Intel processors by PEBS since Intel Nehalem and their successors.</p><p>Hardware debug registers: Hardware debug registers <ref type="bibr" target="#b30">[30,</ref><ref type="bibr" target="#b38">38]</ref> trap CPU execution when a program counter reaches an instruction address (breakpoint) or when an instruction accesses a monitored address (watchpoint). When a thread sets up a debug register to trap a future memory access to certain address, we consider this thread to be arming a watchpoint on that address. One can configure debug registers with different addresses, widths, and types of memory accesses to be trapped (i.e., WP_WRITE for stores and WP_RW for both loads and stores). Current processors from x86 architectures typically have four debug registers.</p><p>Linux perf_events: Linux provides an interface to configure PMUs and debug registers using the perf_event_open <ref type="bibr" target="#b35">[35]</ref> system call and ioctl calls. The capability to configure debug registers has been available since Linux 2.6.33, and the capability to program multiple PMUs since Linux 2.6.39 <ref type="bibr" target="#b35">[35]</ref>. The Linux kernel can deliver a signal to the specific thread that encounters a PMU interrupt or a debug register trap. The user code can (1) create a circular buffer into which the kernel appends the sampled data on each sample using mmap function and (2) collect the signal context on each watchpoint trap.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODOLOGY</head><p>In this section, we provide a high-level sketch of our approach to measuring reuse distance in multi-threaded applications.</p><p>Our tool-ReuseTracker-adopts a sampling philosophy. One need not observe every instance of reuse or invalidation but only a few events in an unbiased manner to produce reuse histograms. <ref type="foot" target="#foot_3">2</ref>We rely on the statistical significance of reuse or invalidation events to guide us in detecting reuse and invalidation and eventually in computing multi-core reuse distance.</p><p>To accomplish the sampling-based monitoring, we need two building block components:</p><p>(1) The ability to sample memory addresses accessed by each thread in the monitored program.</p><p>(2) The ability to identify whether the immediate next memory access to a sampled address happens on the same thread (reuse) or on a different thread (invalidation if the access is a memory write).</p><p>In other words, we need the ability to sample pairs of consecutive accesses to the same memory location, irrespective of which thread performs those accesses.</p><p>We achieve (1) by using hardware performance monitoring units. As previously described, when programming in sampling mode, on reaching a threshold number of events, i.e., sampling period, the PMU can pause the CPU and deliver an interrupt, which can include a packet of information including the memory address being accessed by the thread at the time of counter overflow. This sample is treated as a use whose reuse or invalidation is to be detected later.</p><p>We achieve (2) by using hardware debug registers to trap execution when a thread accesses a designated memory address. A sampling thread can arm a watchpoint for itself and for other threads in the process so that any thread accessing a designated address will cause a trap; based on whether the same thread traps or a different thread traps (on a different core or a different socket), we can conclude reuse vs. invalidation. For example, if a watchpoint traps in the sampling thread, before it traps in any other thread, then an intra-thread reuse is detected and the time reuse distance between the use and reuse is the total loads and stores elapsed on the same thread; if a watchpoint traps in a different thread on the same socket, then a shared cache reuse is detected and the time reuse distance between the use and reuse is the total loads and stores elapsed between the two events on all threads on the same socket.</p><p>In practice, one may not be able to sample an address and instantaneously convey the sampled address to all other threads so that they can monitor their access to it. Hence, we mildly relax the definitions as follows.</p><p>Relaxed Definition of Reuse. Rather than holding up to the ground truth definition of reuse in Definition 2.1 (2.3), we relax it to mean that no intervening store happened on another core (another socket) between two consecutively observed accesses to the same memory location by the same thread. This relaxation accommodates the possibility of the profiler missing an invalidation event in a short window between when the tool samples an address accessed in one thread and informs all other threads to monitor their own accesses to the same address. Thus, if an instance of reuse is detected in this scheme, then there is a high probability that a reuse happened, but we could have missed an invalidation with a small probability.</p><p>We do not relax the definition of invalidation, because a thread that produces an address sample can be immediately paused before it can execute the next instruction, thanks to the precise performance events in modern PMUs. Hence, any invalidation detected by a sampling-based profiler is a true invalidation event.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DESIGN AND IMPLEMENTATION</head><p>ReuseTracker utilizes two slightly different algorithms to profile reuse distance in individual threads and in shared caches. Next, we present the intra-thread profiling algorithm followed by the one for shared caches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Intra-thread profiling</head><p>Figure <ref type="figure" target="#fig_0">1</ref> shows the main components of the Intra-thread profiling algorithm and one of the possible execution scenarios. In this algorithm, ReuseTracker samples memory store and load events. It handles PMU samples of these events and watchpoint traps with algorithms shown in Algorithms 1 and 2, respectively. In both algorithms, there is a common global data structure, GlobalWP, which is an array of a struct of length equal to the number of available debug registers per core (e.g., four on an x86 machine). The ith element in GlobalWP holds the information about the watchpoints currently set in the ith debug register of every thread in the monitored process.  On a PMU Sample: On reaching a threshold number of loads or stores an interrupt is delivered to the thread reaching the threshold. Assume M 1 is the address accessed at the time of interrupt by thread, say T 1 . This signal-handling function, PMUSampleHandler shown in Algorithm 1, takes the sampled address, sampling thread ID, and the total value of load and store PMU counters at the time of sample as inputs. We iterate over all watchpoint slots looking for an available slot (line 4); we look for the unused slots first; the search ends if we find one. If we do not find an unused (inactive) slot, then the search continues into in-use (active) slots. The check AllowReplacement on line 5 is the reservoir sampling logic, which we explain later. If the slot is in-use, then it returns true or false probabilistically. If the slot is inactive, then AllowReplacement will return true, because slot.samples is reset to 1.0 when a watchpoint traps in Line 11 of Algorithm 2. In case of a successful search, the address will be armed on all watchpoints on all cores. However, the search may end without arming any watchpoint, in which case the sampled address will be dropped.</p><p>Special attention needs to be placed on the mode in which the watchpoints are set up. A subsequent load or store access to the sampled address by the same thread, indicates reuse (see Table <ref type="table" target="#tab_2">2</ref>); hence, the sampling thread, T 1 , arms the watchpoints in its own debug registers in read-write WP_RW mode. A subsequent store to the sampled address by another thread, indicates invalidation; hence, the sampling thread arms the watchpoints in debug registers of other threads in write-only WP_WRITE mode.</p><p>On watchpoint trap: When a watchpoint traps in a thread, say T 2 , due to a memory access to an address, say M 1 , ReuseTracker handles the trap with an algorithm shown in Algorithm 2. In Line 3, T 2 checks if the watchpoint slot that corresponds to the trapping debug register is still active (meaning never trapped in any threads). If it is still active, then T 2 checks if the thread ID of the watchpoint slot matches its own thread ID. If it matches, then time reuse distance is computed as use and reuse occur on the same thread. In this case, the time reuse distance is the number of loads and stores elapsed from the use to the reuse point, which is read from PMU counters. If the two accesses are from two different threads (the latter one guaranteed to be a write access), then an invalidation is detected. After detecting either a reuse or an invalidation, in Line 10, T 2 marks the watchpoint slot as inactive; subsequent traps, if any, on the same slot will be ignored so that at most one reuse or invalidation is detected per sampled address.</p><p>After detecting reuse or invalidation, the watchpoint slot is immediately released for use by a subsequent sample. As a special case, if every armed watchpoint traps before the next PMU address sample, then the reservoir sampling ensures all sampled addresses to be monitored.</p><p>Reservoir Sampling Strategy: On a PMU sample, a previously armed watchpoint may have already trapped (either because of reuse or invalidation) or not yet trapped. ReuseTracker needs to balance between retaining a previously armed watchpoint to potentially detect a reuse separated by some other memory accesses and a new address that may trap sooner; neither of these is predictable without time traveling into the future of execution.</p><p>We employ reservoir sampling to give equal probability to retain an already monitored address for a longer time vs. beginning to monitor a new address, disregarding when the sample happens. This gives a fair opportunity to short vs. long distance reuses. The probability of an older, already armed watchpoint to be replaced with a new sampled address decays following the harmonic progression <ref type="bibr" target="#b1">[2]</ref> over time with each new PMU sample; meaning, the longer a watchpoint stays armed, the higher the probability for it to stay even longer. However, a newly sampled address always has a probability to replace an older sample in such a way that any sampled address has equal probability to be observed irrespective of when the address was sampled. AllowReplacement on Line 19 in Algorithm 1 probabilistically answers this question, whether the sampling thread is allowed to arm watchpoint in a slot in all threads including replacing any old existing untrapped watchpoints. We refer the reader to Reference <ref type="bibr" target="#b58">[58]</ref> for theoretical guarantees of reservoir sampling <ref type="bibr" target="#b60">[60,</ref><ref type="bibr" target="#b61">61]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Shared cache profiling</head><p>To detect reuses in the shared cache, ReuseTracker again samples load and store accesses, and employs debug registers to trap accesses to the sampled addresses that happen in the same shared cache.</p><p>In this algorithm, when a thread samples a load or a store access, this sampled event is considered as a use. After extracting the effective address of the event, the sampling thread arms watchpoints on the address in all threads. Watchpoints that trap load or store accesses are created in cores that share the same socket (and hence the same shared cache) with the sampling thread. In cores that do not share the same socket, watchpoints that trap only store accesses are set up. When the next trap happens in a watchpoint in a core on the same socket, a reuse in the shared cache is detected, otherwise an invalidation is detected if the trap happens in a core on another socket. Figure <ref type="figure" target="#fig_2">2</ref> shows the main components and one possible execution scenario of the Shared cache profiling algorithm. Next, we explain the steps how ReuseTracker handles a PMU sample when profiling reuse distance in shared cache.</p><p>On a PMU sample: When a thread, say T 1 , samples a load or a store access to an address, say M 1 , a signal is delivered by the Linux kernel to T 1 . This signal is handled by our signal-handling function, which is very similar to the intra-thread profiling algorithm except for few differences. If T 1 is allowed to arm watchpoints globally, then T 1 collects the sum of the PMU counter values of load and store events from all cores that share the same socket as the sampled core. T 1 sets the watchpoint types and arms watchpoints that trap load or store accesses in all of the other threads that share the same socket with itself. The aim of these watchpoints is to detect a reuse in the shared cache. To detect cache line invalidation from the shared cache, T 1 also arms watchpoints that trap only store accesses in cores of other sockets.</p><p>On watchpoint trap: When a watchpoint trap happens in a thread, say T 2 , due to an access to an address, say M 1 , the trap is handled by ReuseTracker. First, T 2 checks if the watchpoint slot is still active to see if no trap has occurred on this slot globally. On an active slot, T 2 checks whether it shares the same socket with the thread that arms its watchpoint. If so, then a shared cache reuse is detected and time reuse distance between the trap in T 2 and the sample owner is computed. However, if T 2 and the sample owner are on different sockets, then an invalidation is detected. After detecting a reuse or an invalidation, the reservoir sampling probability is reset, and the watchpoint slot is marked as inactive.</p><p>Measuring Time Reuse Distance in Shared Cache Profiling: To measure time reuse distance when a reuse in a shared cache is detected, we leverage the PMU counter for loads and stores. The time reuse distance is measured as follows.</p><p>(1) At the sampling point when the watchpoints are armed, the PMU sample handler function memorizes the total count C 1 = ncor es on skt i=1 Loads (i) + Stores (i) of load and store events from all cores that share the same socket where the sample occurs. C 1 becomes an attribute in each watchpoint that can be accessed by the watchpoint trap handler.</p><p>(2) When a reuse is detected, and the trap handler records the total count, say C 2 = ncor es on skt i=1 Loads (i) + Stores (i) of loads and stores again from all cores sharing the same socket again. C 2 -C 1 is recorded as time reuse distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Implementation</head><p>ReuseTracker is built on top of the open-source HPCToolkit tools suite <ref type="bibr" target="#b4">[4]</ref>. It intercepts thread creation and termination using LD_PRELOAD for dynamically linked executables <ref type="bibr" target="#b39">[39]</ref>. On each thread creation, we configure the Linux perf_events for the newly created thread to monitor relevant PMU events.</p><p>To profile reuse distance in individual threads and in shared caches, we sample MEM_UOPS_RETIRED:ALL_STORES and MEM_UOPS_RETIRED:ALL_LOADS events, respectively, for sampling stores and loads. All of these events allow the signal-handling function to record the accessed effective address and the program counter when an event is sampled. By recording effective address, ReuseTracker's signal-handling function is able to detect a memory access use and its reuse.</p><p>In addition to recording effective address and calculating time reuse distance, the signalhandling and the watchpoint trap-handling functions also record program counters at the moments of PMU samples and watchpoint traps. Using the program counters, the profiling functions can trace the sampled and trapped threads' call stacks through an online binary analysis. This online binary analysis is performed by HPCToolkit every time a PMU sample or a watchpoint trap is handled to retrieve the procedure frames that are parts of the call stack that becomes the execution context of the detected PMU sample or the watchpoint trap. After tracing the call stack of a sampled or a trapped memory access, the detected use or reuse can be attributed to the call stack, which makes it easier for programmers to spot the locations of each detected use-reuse pairs in the source code.</p><p>Concurrency Control: GlobalWP is a shared data structure and accessed concurrently by different PMU sample handlers and watchpoint traps. We use a two-counter-based transactional memory mechanism proposed by Lamport <ref type="bibr" target="#b31">[31]</ref> that allows multiple readers and a single writer to concurrently access the same slot of GlobalWP; accessing different slots of GlobalWP by different threads is obviously conflict free. We ensure mutual exclusion among multiple writers to the same slot via a test-and-test-and-set lock <ref type="bibr" target="#b44">[44]</ref>.</p><p>Workaround for Limited GlobalWP Slot Count: We acknowledge the possibility of having much higher thread count than there are GlobalWP slots. If profiled threads exhibit uniform behavior, then a low number of GlobalWP slots, which is four in x86 architecture, is sufficient. In case there are more than four different behaviors at the same time, ReuseTracker might still capture all of these behaviors in one run as multiple threads can context switch to be monitored by a GlobalWP slot. However, in an extreme condition where the thread count in an application is much higher than the number of GlobalWP slots and the behaviors of the threads are very diverse to the point that each thread might have its own distinct behavior, there is a possibility that ReuseTracker might not capture all of these behaviors as it can only monitor four behaviors at the same time. To work around this limitation, a user of our tool might have to profile the application a number of times to get a more complete insight into the reuse behavior of the application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EVALUATION</head><p>This section evaluates the accuracy of ReuseTracker and demonstrates its functionality in analyzing reuse distances in PARSEC, Rodinia, and Synchrobench benchmarks. Additionally, this section also evaluates the performance and memory overheads of ReuseTracker.</p><p>The experimental study is carried out in a two-socket Intel Xeon Gold 6148 Skylake CPU. Each socket has twenty cores, each core has its own L1d, L1i, and L2 caches, and each socket has one shared L3 cache. The machine runs Linux 5.5.2 kernel, and we use gcc 8.3.1 compiler. Unless   otherwise stated, the default sampling interval for both load and store events is 100K, and the used debug register count in each core is four. In each experiment, the threads are distributed evenly across the two sockets, and the threads in each socket are bound to CPU cores with compact mapping<ref type="foot" target="#foot_5">3</ref> strategy by default.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">RIBench Benchmark</head><p>To evaluate the accuracy of ReuseTracker, we develop a synthetic benchmark with controllable reuse and invalidation counts shown in Listing 1. We refer to this benchmark as RIBench. Using the RIBench, one can configure the amount of reuses for different reuse distances as well as the amount of invalidations that happen during execution. In the RIBench, there are several configurable parameters; outer , a, a 1 , b, b <ref type="figure" target="#fig_0">1 ,</ref><ref type="figure">c,</ref><ref type="figure" target="#fig_0">c 1 ,</ref><ref type="figure">d,</ref><ref type="figure">d</ref> 1 , e, e 1 , and inv. These parameters can be configured to generate expected reuse distances and number of reuses for each reuse distance. There are five different reuse distances that can be generated. These reuse distances are a 1 +inv, b 1 +inv, c 1 +inv, d 1 +inv, and e 1 +inv. When we want to configure each thread to have five different non-zero reuse distances without being interrupted by any invalidation, we set up the values of a 1 , b 1 , c 1 , d 1 , and e 1 to be five different non-zero values as these five variables determine the number of iterations to access five different 3. Reuse distance histograms of RIBench without cache line invalidation. X-axis shows the reuse distance ranges in logarithm-scale. Y-axis displays the fraction of reuse-pairs that belong to specific reuse distance ranges.</p><p>private arrays, while the value of inv variable is set to be zero. Then, in case we want to introduce cache line invalidations, we set the value of inv variable to be a non-zero value, since this variable determines the number of iterations that access a shared array. The other parameters, i.e., outer , a, b, c, d, and e, can be configured to determine the reuse count of each reuse distance.</p><p>The computation of expected reuse count for each reuse distance is displayed in Table <ref type="table" target="#tab_5">4</ref>. By changing the parameters, it is possible to produce a variety of reuse distance histogram patterns. For example, if In addition to controlling the shapes of patterns in generated reuse distance histograms, it is also possible to control the amount of cache line invalidations by setting up the value of inv parameter when there are more than one thread. This parameter determines the iteration count of a loop that performs store access to a shared array shared_array. The number of cache line invalidations can be increased by increasing the value of inv variable. Therefore, say, for reuse distance inv+a1, instead of having reuse count num_threads*outer *a*(a1+inv), its reuse count becomes num_threads*outer *a*a1, as each access to shared_array is expected to lead to a cache line invalidation instead of a reuse.</p><formula xml:id="formula_1">e 1 &gt; d 1 &gt; c 1 &gt; b 1 &gt; a 1 , inv = 0, and e * e 1 &lt; d * d 1 &lt; c * c 1 &lt; b * b 1 &lt; a * a 1 ,</formula><p>To evaluate the accuracy of ReuseTracker, we compute the expected reuse distance histogram of the RIBench with a given set of parameters, and this histogram is compared with the histogram produced by ReuseTracker. Given two histograms H and ? , the accuracy, S, is calculated as below <ref type="bibr" target="#b50">[50,</ref><ref type="bibr" target="#b60">60]</ref>:</p><formula xml:id="formula_2">S = 1 - n i=1 B i -Bi 2</formula><p>B i and Bi are fractions of reuse-pairs in H and ? , respectively, that fall into the ith bin, and n is the number of bins in each histogram. The value of S metric is in the range [0, 1.0] with 1.0 meaning H and ? are perfectly similar.  reason for this is that there are more loop iterations that perform store accesses to shared_array in Case 3 than in Case 2 and there are more store accesses to the shared array in Case 2 than in Case 1. These store accesses to the shared array is also the main difference between this experiment and the experiment without invalidation in Section 5.2. In the experiment without invalidation, the parameter inv, which defines number of store accesses to the shared array, is always zero.</p><p>Figures <ref type="figure" target="#fig_5">4</ref> and<ref type="figure" target="#fig_6">5</ref> show the reuse distance histograms generated by ReuseTracker running on 32 threads compared to the ground truth. As shown in both figures, our results are close to the ground truth with an average accuracy 89% over short reuse distance cases, and 93% over long reuse distance cases. The lower accuracy in short reuse distance cases is the result of our relaxed definition of reuse. Within a short interval between when a thread samples a memory access and when the thread arms watchpoints in all threads, a cache line invalidation to the sampled address might occur undetected. If the interval between the watchpoint arming and the reuse of the sampled address is very short, which is the case for the short reuse distance cases, then the undetected invalidation that happens between the sample and the watchpoint arming might be the only opportunity detect cache line invalidation, which is missed. As a result, a false detection of reuse will occur, which still satisfies our relaxed definition of reuse but violates the ground truth definition in Definition 2.1.</p><p>One pattern that can be observed from the ground truths in Figures <ref type="figure" target="#fig_5">4</ref> and<ref type="figure" target="#fig_6">5</ref> is that the offsets of the histograms shift to the right as we go from Case 1 to 3. The reason for the offset shift is the sum of inv+a1, which is the shortest reuse distance in all cases, that keeps increasing from Case 1 to 2 and from Case 2 to 3. Another pattern that can be observed from the ground truths and the results is that the histograms become narrower as we go from Case 1 to 3. This is the result of the logarithmic scaling of the bin sizes whose range increases along the X-axis. Therefore, as the histogram shifts to the right due to increases in reuse distances, the capacity of each bin becomes larger, and hence the number of filled bins becomes smaller. The increase in all reuse distances and the logarithmic scaling are also the reasons for the mode shift of the histograms in Figure <ref type="figure" target="#fig_5">4</ref> as the mode that is in the third bin in Case 1 becomes "pushed" to the fourth bin in Case 2 and grouped together with the reuses that are already in the fourth bin in Case 1. Such transformation also happens from Case 2 to 3 as some reuses that belong to the fourth bin in Case 2 are "pushed" to the fifth bin in Case 3 and makes the height of the fifth bin taller.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Accuracy under Different Thread Counts</head><p>To evaluate ReuseTracker's accuracy under different thread counts, we ran it on the RIBench with Long-RD Bell-shaped Case 2 and Long-RD Decreasing Case 2 configurations. We chose these configurations as they include invalidations and reservoir sampling in their executions and, among all Long RD cases that have invalidations, they have the most complex patterns, since they have more filled bins and more variation of tall and short bins in their patterns. We performed the experiment under six different thread counts; 1, 2, 4, 8, 16, and 32. The accuracy results are presented in Figure <ref type="figure" target="#fig_7">6</ref>. The accuracy of ReuseTracker is consistently high under different thread counts with an average of 95% for the Long-RD Bell-shaped Case 2 and an average of 96% for the Long-RD Decreasing Case 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Reuse Distances of PARSEC Benchmarks</head><p>In this section, we present and discuss the reuse distance histograms for the PARSEC benchmark suite <ref type="bibr" target="#b9">[9]</ref>. For the sake of brevity, we will only discuss four of the benchmarks in detail.  Figure <ref type="figure" target="#fig_8">7</ref> shows the histograms of blackscholes and bodytrack generated from intra-thread reuse distance profiling for 32 threads processing native input size. Figure <ref type="figure" target="#fig_8">7</ref> shows that most reuses in the selected benchmarks are short in distance. blackscholes, which computes prices of a portfolio of European options, has a huge portion of short-distanced reuses. These short-distanced reuses mostly occur on the prices array, a data structure that records options' prices. Reuses happen in the bs_thread, the BlkSchlsEqEuroNoDiv, and the CNDF functions. Longer-distanced reuses are detected in the main function on accesses to local variables, which become memory accesses due to register spilling.</p><p>In bodytrack, a lot of reuses of various distances happen within the TrackingModel::LogLikelihood function and in other functions called by it. TrackingModel::LogLikelihood is a function that computes the likelihood of each observed particle in tracking an object in an image. This computation is needed in resampling particles with the best fitness values from image data to help analyze interesting regions in the image in more detail.</p><p>Figure <ref type="figure" target="#fig_9">8</ref> displays the histograms of streamcluster and freqmine generated from shared cache reuse distance profiling. streamcluster is a benchmark that solves an online clustering problem by grouping streamed data points into their nearest centers. In streamcluster, some of the detected temporal and spatial reuses happen with distances less than or equal to 8M. Most of these usereuse pairs happen on Point-typed shared array elements in the pgain, dist, and shuffle functions. Aside from accesses to Point-typed data structures, there are also detected short-distanced reuses due to locking mechanism in the pthread_barrier_wait function. For reuses that are longer than 8M in distance, they also occur because of accesses to shared Point data structures in the dist function. These reuses can be long in distance, because dist is a function that measures distances between data points when making new cluster centers and consecutive accesses to the same data points can happen across different dist function calls separated by wide time gaps.</p><p>freqmine is a data mining benchmark that performs the Frequent Pattern-growth (FPgrowth) method for frequent itemset mining (FIMI) problem. In this benchmark, reuses of various distances are detected between the FP_tree::database_tiling and FP_tree::scan2_DB functions due to memory accesses to a shared tree data structure. Furthermore, long-distanced reuses are also detected in the FP_tree::database_tiling function on accesses to the item_order array. These long-distanced reuses occur due to accesses to the shared array in creating a prefix tree whose branches represent frequent itemsets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Use Case: False Sharing Removal</head><p>Spatial reuses in shared cache detected by ReuseTracker include false sharing as the use-reuse pair belong to different threads that access different memory regions located in the same cache line. Therefore shared cache spatial reuse distance profiles produced by ReuseTracker can assist in guiding code refactoring that reduces false sharing in the profiled code. To demonstrate this capability, we leverage ReuseTracker to profile some benchmarks from Synchrobench <ref type="bibr" target="#b22">[22]</ref>, namely, ESTM-rbtree, MUTEX-hashtable, MUTEX-lazy-list, SPIN-hashtable, and SPIN-lazy-list, and use the generated profiles to guide code modifications that improve their performances. To detect only false sharing, we generate a shared cache reuse distance profile that includes only read-afterwrite (RAW) and write-after-write (WAW) use-reuse pairs. The reason for this is these kinds of use-reuse pairs trigger inter-core cache line transfers caused by false sharing for certain.</p><p>In ESTM-rbtree, we identify false sharing in the TMlookup function that involves struct node and struct thread_data data types. To remove the false sharing, we inserted padding into struct node and struct thread_data. After this modification, ESTM-rbtree's performance is improved by 87%. In MUTEX-hashtable, MUTEX-lazy-list, SPIN-hashtable, and SPIN-lazy-list, false sharing is found in the parse_delete function or in other functions called from it. In all of these benchmarks, the detected false sharing involves struct node_l data type. Paddings in this data structure improves the performance of these benchmarks by 6%, 46%, 39%, and 58% for MUTEXhashtable, MUTEX-lazy-list, SPIN-hashtable, and SPIN-lazy-list, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Use Case: Adjacent Cache Line Prefetch</head><p>By analyzing the intra-thread and shared cache reuse distance histograms of a multi-threaded code, we demonstrate that it is possible to decide whether the code will benefit from ACP <ref type="bibr" target="#b23">[23]</ref> or not. ACP, a feature in Intel microarchitectures, allows prefetching a cache line that is adjacent to the currently accessed cache line. This feature can improve an application performance if the application threads have a good spatial locality where each thread actually accesses the prefetched cache lines before they are evicted. In addition to locality in individual threads, another factor that affects application performance when using ACP is inter-thread communication. Excessive communication, such as false sharing, may hinder the benefit of spatial locality that ACP offers. Due to communication, prefetched cache lines could be invalidated before they are accessed by the prefetching threads. To account for locality-affected access latencies and inter-thread communication, we build a model to predict whether an application can benefit from ACP or not.</p><p>We consider an application to have better performance with ACP if its performance overhead due to main memory access is higher than its overhead due to false sharing. Let G be a binary predictor metric, where G = T m -T f s , such that T m is the total latency of accesses to main memory, and T f s is the total false sharing latency. T m in this model is computed as follows:</p><formula xml:id="formula_3">T m = R dr am * L dr am ,</formula><p>where R dr am is the number of detected spatial reuses in the intra-thread reuse distance histogram that access DRAM, and L dr am is the latency of access to DRAM. In the model, T f s is calculated as follows:</p><formula xml:id="formula_4">T f s = R f s * L f s ,</formula><p>where R f s is the number of detected spatial reuses in the shared cache reuse distance histogram with reuse distances that are short enough to be in the range of false sharing communication, and L f s is the latency of inter-core cache line transfer. We obtained the values of L dr am and L f s by running Intel Memory Latency Checker (Intel MLC) <ref type="bibr" target="#b57">[57]</ref> on our machine. We expect an application to get a performance speedup when running with ACP if G ? 0. By using this metric, we predict whether an application will gain or lose performance when ACP is activated in the Intel Xeon Gold 6148 Skylake. The benchmarks that we use in this experiment are 10 benchmarks from PARSEC <ref type="bibr" target="#b9">[9]</ref> (bodytrack, streamcluster, swaptions, vips, blackscholes, dedup, facesim, ferret, fluidanimate, and freqmine), 7 benchmarks from Rodinia <ref type="bibr" target="#b12">[12]</ref> (backprop, bfs, hotspot, kmeans, leukocyte, needle, and srad), and all 14 benchmarks from Synchrobench <ref type="bibr" target="#b22">[22]</ref>. After running these benchmarks with ACP enabled, we noticed that only 12 of them display performance gains or losses that are higher than 5%. Our model accurately predicts the execution outcomes of these 12 benchmarks as shown in Table <ref type="table" target="#tab_7">8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.8">Overhead Analysis</head><p>To evaluate the runtime and memory overheads of ReuseTracker, we run it on ten PARSEC benchmarks to profile their intra-thread reuse distance with 100K sampling interval. For these benchmarks, the average runtime overhead is 2.9?, and the average memory overhead is 2.8?, which are much lower than the overheads of existing simulator and binary instrumentation-based tools as shown in Table <ref type="table" target="#tab_0">1</ref>. However, the overheads of ReuseTracker are slightly higher than the overheads of other PMU-based techniques like StatCache <ref type="bibr" target="#b7">[7]</ref> and RDX <ref type="bibr" target="#b60">[60]</ref>. This is because each sampling thread in ReuseTracker arms not only its own debug registers but also debug registers of other cores. The comparison between ReuseTracker and other similar techniques are shown in Table <ref type="table" target="#tab_0">1</ref>. The overheads of RDX and loca were obtained by running them with the same ten PARSEC benchmarks, and RDX with 100K sampling interval. The overheads of RDX reported here are higher than the ones reported in its paper, because in Reference <ref type="bibr" target="#b60">[60]</ref> authors used a sampling interval of 5M. In addition to measuring overheads while profiling reuse distance in individual threads, we also measure overheads for shared cache profiling. The average runtime overhead for reuse distance profiling in shared cache is 2.1?, and the average memory overhead is 2.4?, which are even lower than the overheads of intra-thread profiling. These lower overheads might be caused by lower number of watchpoint traps that are handled at shared cache level than at intra-thread level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RELATED WORK</head><p>Existing related works can be organized into two groups. The first group consists of the papers that proposed multi-core reuse distance analysis techniques that profile individual threads and shared caches. The second group introduced reuse distance analysis techniques that leverage PMUs and debug registers. Table <ref type="table" target="#tab_0">1</ref> presents the comparison between ReuseTracker and some of the techniques discussed in this section that also perform detection of reuses at runtime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Modeling Individual Threads and Shared Caches</head><p>Ding and Chilimbi proposed an analytical model that predicts shared cache behavior indirectly by combining per-thread reuse distance, interleaving, and data sharing information <ref type="bibr" target="#b14">[14]</ref>. This technique processes execution trace of a multithreaded code to generate a set of per-thread metrics. This set of metrics cover locality (i.e., reuse distance profile), data sharing, and interleaving information of each thread. By accounting for multiple sets of metrics from a subset of threads using the model, miss ratio of this subset of threads while running in a shared cache can be predicted. Another work by Jiang et al. <ref type="bibr" target="#b29">[29]</ref> proposed a probabilistic model that can approximate concurrent reuse distance from reuse distances of individual threads. The multithreaded applications targeted by this model are those that perform similar computations in all threads and have uniform amount of shared data across their thread groups. These techniques in References <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b29">29]</ref> require processing of execution traces that might incur large storage overhead in the host machines. Furthermore, the computation of reuse distance profiles from the traces can also require huge performance overhead depending on the size of the traces.</p><p>Schuff et al. introduced a different approach in Reference <ref type="bibr" target="#b48">[48]</ref>. Their technique performs on-thefly reuse distance computations by using a modified hardware simulator. This technique computes reuse distances in both private and shared caches by also ensuring the coherence in the private caches. Furthermore, it also models the interleaving of memory accesses by all threads in the shared cache. This technique was improved in Reference <ref type="bibr" target="#b47">[47]</ref> by having all threads run in parallel while being profiled. Moreover, sampling technique was also introduced to reduce overhead by computing reuse distances only on randomly selected memory references. A shortcoming in these approaches is that they require simulator or binary instrumentation to intercept every single memory access. The use of simulator introduces huge performance and memory consumption overhead. Furthermore, the use of binary instrumentation might distort the parallel schedules of task-parallel and dataflow applications as reported in Reference <ref type="bibr" target="#b41">[41]</ref>.</p><p>Chandra et al. <ref type="bibr" target="#b13">[13]</ref> introduced one of the first models that predict L2 cache misses when multiple threads run on a shared L2 cache. Eklov et al. <ref type="bibr" target="#b20">[20]</ref> also proposed another model that estimates miss ratio and CPI of co-scheduled applications that run on a shared cache. These models work by firstly approximating the reuse distance profile of the applications' interleaved accesses in the shared cache. After that, the models calculate the shared cache miss ratio based on the approximated profile. One key difference of these works from ours is that they target co-scheduled applications that do not share data among them.</p><p>Pericas et al. <ref type="bibr" target="#b41">[41]</ref> introduced a low-overhead method to generate execution traces of multithreaded code and compute reuse distances of shared caches from these traces. In generating shared cache reuse distance histograms, it also captures cache coherence-based invalidations across caches. To minimize overhead, this method reduces trace sizes by operating at the granularity of compute kernels. By operating at coarse-grained level, this method can accurately capture distant reuses while losing information on near reuses.</p><p>Maeda et al. <ref type="bibr" target="#b36">[36]</ref> introduced a technique to profile reuse distances in every level of a multi-level cache hierarchy. Since this technique still requires memory address trace as an input, it still needs other tools to generate the trace. As a result, this technique is still exposed to the drawbacks of these tools, such as huge overhead in simulators or distortion of parallel schedule due to binary instrumentation.</p><p>Another work that leverages memory traces to profile reuse distances in private and shared caches was proposed by Barai et al. <ref type="bibr" target="#b5">[5]</ref>. In this work, they utilized a compiler-assisted technique to generate a basic block-labeled memory trace from a single sequential execution of a profiled application. This trace is then used by a probabilistic analytical method to predict the reuse distance profiles of the application in private and shared caches when the application runs in parallel.</p><p>Hu et al. <ref type="bibr" target="#b24">[24]</ref> proposed a model that reduces time and space costs in constructing cache miss ratio curves (MRCs) by analyzing only reuse-time distribution. They used average eviction time (AET) as a parameter to detect reuses that lead to cache misses. Their model could be extended to predict cache misses in a shared cache when multiple threads run on it. However, in estimating cache misses in private and shared caches, their model does not assume data sharing among threads that might lead to coherence misses in private caches and shared caches.</p><p>Ji et al. <ref type="bibr" target="#b26">[26]</ref> developed a probability model that computes L2 reuse distance profile and predicts cache misses in L2 without requiring extra simulations or trace generations. Though able to give cache miss prediction, this model still needs inputs in the form of L1 reuse distance histograms. These inputs might have to be generated by simulator or binary instrumentation-based tools.</p><p>There are also recent works in References <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b34">34,</ref><ref type="bibr" target="#b46">46,</ref><ref type="bibr" target="#b59">59</ref>] that proposed analytical models to profile shared cache behaviors by processing L1 cache reuse distance profiles. Similar to previously discussed works, these works also depend on other tools to generate per-thread reuse distance histograms that they need.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Leveraging PMUs and Debug Registers</head><p>To the best of our knowledge, there have been only two techniques in literature that utilize hardware counters and watchpoint mechanism to compute reuse distances. The first technique was presented by Berg and Hagersten in Reference <ref type="bibr" target="#b7">[7]</ref>. In that paper, they proposed StatCache, a profiling tool that calculates time reuse distances by using hardware counters and watchpoints and deploys a statistical model to predict cache miss ratio based on the collected time reuse distance profile. This tool could predict the miss ratio of a fully associative cache with random replacement policy. The second technique that leverages hardware counters and watchpoints was introduced by Wang et al. <ref type="bibr" target="#b60">[60]</ref>. This technique, which is named RDX, utilizes PMUs and debug registers in Intel machines to compute time reuse distances, and then, convert them to stack reuse distances. Both techniques in References <ref type="bibr" target="#b7">[7,</ref><ref type="bibr" target="#b60">60]</ref> differ from our work in the way that they do not account for inter-thread interactions in multithreaded code and they do not model shared caches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>In this work, we developed ReuseTracker, a reuse distance analysis tool that profiles reuse distance in individual threads and in shared caches of multi-threaded applications with low overheads by leveraging PMUs and debug registers. We proposed two different algorithms to profile reuse distance in individual threads and shared caches, respectively. To verify the accuracy of the intrathread profiling algorithm, we developed a synthetic benchmark that can be configured to generate a variety of reuse distance histogram patterns. We also demonstrated how ReuseTracker can be used to guide performance optimization by removing false sharing via code refactoring and how it can predict whether multi-threaded applications gain or lose performance when ACP is enabled. By using ReuseTracker, programmers will be able to profile data locality in thread and shared caches with low overheads, and use the generated information to tune application performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. One possible execution scenario when profiling intra-thread reuse distance: (1) Every thread sets its PMUs to sample its stores and loads. (2) Thread T 1 's PMU counter overflows on a store to address m 1 . (3) T 1 arms its watchpoint with type WP_RW and watchpoints of other threads (e.g., the one in T 2 ) with type WP_WRITE and with address m 1 in debug registers. (4) T 1 accesses address m 1 again before any other thread, the watchpoint traps, time reuse distance is computed. (5) Cache line invalidation happens if T 2 stores to address m 1 before T 1 accesses m 1 .</figDesc><graphic url="image-2.png" coords="8,109.74,125.68,60.16,55.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>ALGORITHM 1 : 5 : 19 : 26 :</head><label>151926</label><figDesc>PMU Sample Handler 1: global GlobalWP[NUM_DEBUG_REGS] 2: 3: procedure PMUSampleHandler(Address M , ThreadID T , PMUCounterValue P ) 4: for each slot ? { GlobalWP } ordered-by inactive to active do if AllowReplacement(slot) then 6: slot.active = true 7: for each T i ? { all threads in the program } do 8: if T i == T then (M , T i , P , slot , mode) return 14: procedure AllowReplacement(WPInfo slot) 20: r = GenerateRandomNumber(0.0, 1.0) 21: ret = (r ? 1.0 / slot.samples) ? true : procedure ArmWatchpoint(Address M , ThreadID</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. One possible execution scenario in profiling reuse distance in L3 cache: (1) Every thread sets its PMUs to sample its load and store accesses. (2) Thread T 1 's PMU counter overflows on a store or a load on address m 1 . (3) T 1 arms the watchpoints on other cores that share the same L3 cache with itself with type WP_RW and with type WP_WRITE on cores that do not share the same L3 cache. (4) T 2 accesses address m 1 again before any other thread, the debug register traps, time reuse distance in L3 is computed. (5) Cache line invalidation in L3 level occurs if T 3 or T 4 stores to address m 1 before T 2 accesses m 1 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>outer = 10</head><label>10</label><figDesc>, a = 20, a1 = 1,000, b = 20, b1 = 2,000, c = 20, c1 = 4,000, d = 20, d1 = 8,000, e = 20, e1 = 16,000, inv = 0 Short-RD Decreasing outer = 10, a = 200, a1 = 1,000, b = 60, b1 = 2,000, c = 15, c1 = 4,000, d = 4, d1 = 8,000, e = 2, e1 = 16,000, inv = 0 Short-RD Bell-shaped outer = 10, a = 50, a1 = 1,000, b = 40, b1 = 2,000, c = 40, c1 = 4,000, d = 10, d1 = 8,000, e = 3, e1 = 16,000, inv = 0 Short-RD Multi-modal outer = 10, a = 100, a1 = 1,000, b = 30, b1 = 2,000, c = 24, c1 = 4,000, d = 8, d1 = 8,000, e = 7, e1 = 16,000, inv = 0 Long-RD Increasing outer = 10, a = 10, a1 = 100,000, b = 10, b1 = 200,000, c = 10, c1 = 400,000, d = 10, d1 = 800,000, e = 10, e1 = 1,600,000, inv = 0 Long-RD Decreasing outer = 10, a = 100, a1 = 100,000, b = 30, b1 = 200,000, c = 12, c1 = 400,000, d = 5, d1 = 800,000, e = 2, e1 = 1,600,000, inv = 0 Long-RD Bell-shaped outer = 10, a = 50, a1 = 100,000, b = 40, b1 = 200,000, c = 40, c1 = 400,000, d = 10, d1 = 800,000, e = 3, e1 = 1,600,000, inv = 0 Long-RD Multi-modal outer = 10, a = 100, a1 = 100,000, b = 30, b1 = 200,000, c = 24, c1 = 400,000, d = 8, d1 = 800,000, e = 7, e1 = 1,600,000, inv = 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>the reuse distance histogram will exhibit a decreasing pattern. Another example is when e 1 &gt; d 1 &gt; c 1 &gt; b 1 &gt; a 1 , inv = 0, and e * e 1 &gt; d * d 1 &gt; c * c 1 &gt; b * b 1 &gt; a * a 1 , then the reuse distance histogram will form an increasing pattern.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Reuse distance histograms of RIBench with cache line invalidations on bell-shaped pattern.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Reuse distance histograms of RIBench with cache line invalidations on decreasing pattern.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. Accuracy of ReuseTracker running the RIBench under different thread counts. X-axis displays the thread counts, and Y-axis shows the accuracy for each thread count.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Histograms of intra-thread reuse distance of blackscholes and bodytrack from PARSEC. X-axis shows the reuse distance ranges in logarithm-scale. Y-axis displays in logarithmscale the fraction of reuse-pairs that belong to specific reuse distance ranges.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Histograms of reuse distance in L3 cache of streamcluster and freqmine from PARSEC. X-axis shows the reuse distance ranges in logarithm-scale. Y-axis displays in linear scale the fraction of reuse-pairs that belong to specific reuse distance ranges.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparison of ReuseTracker against Other Techniques that Perform Online Detection of reuses Attributes Schuff et al.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Intra-thread Reuse</figDesc><table><row><cell cols="3">access order same core different cores</cell></row><row><cell></cell><cell></cell><cell>(any socket)</cell></row><row><cell>R?R</cell><cell>reuse</cell><cell>no reuse</cell></row><row><cell>R?W</cell><cell>reuse</cell><cell>invalidation</cell></row><row><cell>W ?W</cell><cell>reuse</cell><cell>invalidation</cell></row><row><cell>W ?R</cell><cell>reuse</cell><cell>no reuse</cell></row><row><cell cols="3">Read (R) or Write (W) may be accessing data at</cell></row><row><cell cols="3">any level in the memory hierarchy.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Reuse in Shared Cache</figDesc><table><row><cell cols="3">same core different cores different cores</cell></row><row><cell></cell><cell cols="2">(same socket) (different socket)</cell></row><row><cell>R?R no reuse</cell><cell>reuse</cell><cell>no reuse</cell></row><row><cell>R?W no reuse</cell><cell>reuse</cell><cell>invalidation</cell></row><row><cell>W ?W no reuse</cell><cell>reuse</cell><cell>invalidation</cell></row><row><cell>W ?R no reuse</cell><cell>reuse</cell><cell>no reuse</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>T , PMUCounterValue P , WPInfo slot , WPMode t )</figDesc><table><row><cell></cell><cell cols="3">ALGORITHM 2: Watchpoint Trap Handler</cell></row><row><cell></cell><cell cols="3">1: procedure WPTrapHandler(ThreadID T , PMUCounterValue P ,</cell></row><row><cell></cell><cell></cell><cell>WPInfo slot )</cell></row><row><cell></cell><cell>2:</cell><cell></cell></row><row><cell></cell><cell>3:</cell><cell>if GlobalWP[slot ].active then</cell><cell>Check if no thread has</cell></row><row><cell></cell><cell></cell><cell>trapped on this address</cell></row><row><cell></cell><cell>4:</cell><cell cols="2">if T == GlobalWP[slot ].ownerTID then</cell></row><row><cell></cell><cell>5:</cell><cell cols="2">P 0 = GlobalWP[slot ].GetPMUCounterValue()</cell></row><row><cell></cell><cell>6:</cell><cell cols="2">Record time reuse distance P -P 0</cell><cell>Reuse distance is</cell></row><row><cell></cell><cell></cell><cell>recorded</cell></row><row><cell></cell><cell>7:</cell><cell>else</cell></row><row><cell></cell><cell>8:</cell><cell>Record invalidation</cell><cell>WP type must be WP_WRITE</cell></row><row><cell></cell><cell>9:</cell><cell>end if</cell></row><row><cell></cell><cell>10:</cell><cell cols="2">GlobalWP[slot ].active = false</cell></row><row><cell></cell><cell>11:</cell><cell cols="2">GlobalWP[slot ].samples = 1.0</cell></row><row><cell></cell><cell>12:</cell><cell>end if</cell></row><row><cell></cell><cell cols="2">13: end procedure</cell></row><row><cell>27:</cell><cell>WP.address = M</cell><cell></cell></row><row><cell>28:</cell><cell>WP.PMUValue = P</cell><cell></cell></row><row><cell>29:</cell><cell>WP.mode = t</cell><cell></cell></row><row><cell>30:</cell><cell>Set a WP in the debug register watchpoint slot of thread</cell><cell></cell></row><row><cell>T</cell><cell></cell><cell></cell></row><row><cell cols="2">31: end procedure</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 .</head><label>4</label><figDesc>Reuse Distance and Reuse Count of RIBench</figDesc><table><row><cell cols="2">1 # pragma omp parallel shared ( shared_array ) \</cell><cell></cell><cell></cell></row><row><cell>2</cell><cell>private ( private_array1 , private_array2 ,</cell><cell></cell><cell></cell></row><row><cell cols="2">3 private_array3 , \ private_array4 , private_array5 )</cell><cell>Reuse Distance</cell><cell>Reuse Count</cell></row><row><cell>4 {</cell><cell></cell><cell>inv+a1</cell><cell>num_threads*outer*a*a1</cell></row><row><cell cols="2">5 for ( int i = 0; i &lt; outer ; i ++)</cell><cell>inv+b1</cell><cell>num_threads*outer*b*b1</cell></row><row><cell>6 7 8 9</cell><cell>for ( int j = 0; j &lt; a; j ++) for ( int k = 0; k &lt; inv ; k ++) Store to shared_array [k] for ( int k = 0; k &lt; a1; k = k+2)</cell><cell>inv+c1 inv+d1 inv+e1</cell><cell>num_threads*outer*c*c1 num_threads*outer*d*d1 num_threads*outer*e*e1</cell></row><row><cell>10</cell><cell>Load from private_array1 [k]</cell><cell></cell><cell></cell></row><row><cell>11</cell><cell>Store to private_array1 [k +1]</cell><cell></cell><cell></cell></row><row><cell>12</cell><cell>for ( int j = 0; j &lt; b; j ++)</cell><cell></cell><cell></cell></row><row><cell>13</cell><cell>for ( int k = 0; k &lt; inv ; k ++)</cell><cell></cell><cell></cell></row><row><cell>14</cell><cell>Store to shared_array [k ];</cell><cell></cell><cell></cell></row><row><cell>15</cell><cell>for ( int k = 0; k &lt; b1; k = k+2)</cell><cell></cell><cell></cell></row><row><cell>16</cell><cell>Load from private_array2 [k]</cell><cell></cell><cell></cell></row><row><cell>17</cell><cell>Store to private_array2 [k +1]</cell><cell></cell><cell></cell></row><row><cell>18</cell><cell>for ( int j = 0; j &lt; c; j ++)</cell><cell></cell><cell></cell></row><row><cell>19</cell><cell>for ( int k = 0; k &lt; inv ; k ++)</cell><cell></cell><cell></cell></row><row><cell>20</cell><cell>Store to shared_array [k]</cell><cell></cell><cell></cell></row><row><cell>21</cell><cell>for ( int k = 0; k &lt; c1; k = k+2)</cell><cell></cell><cell></cell></row><row><cell>22</cell><cell>Load from private_array3 [k]</cell><cell></cell><cell></cell></row><row><cell>23</cell><cell>Store to private_array3 [k +1]</cell><cell></cell><cell></cell></row><row><cell>24</cell><cell>for ( int j = 0; j &lt; d; j ++)</cell><cell></cell><cell></cell></row><row><cell>25</cell><cell>for ( int k = 0; k &lt; inv ; k ++)</cell><cell></cell><cell></cell></row><row><cell>26</cell><cell>Store to shared_array [k ];</cell><cell></cell><cell></cell></row><row><cell>27</cell><cell>for ( int k = 0; k &lt; d1; k = k+2)</cell><cell></cell><cell></cell></row><row><cell>28</cell><cell>Load from private_array4 [k]</cell><cell></cell><cell></cell></row><row><cell>29</cell><cell>Store to private_array4 [k +1]</cell><cell></cell><cell></cell></row><row><cell>30</cell><cell>for ( int j = 0; j &lt; e; j ++)</cell><cell></cell><cell></cell></row><row><cell>31</cell><cell>for ( int k = 0; k &lt; inv ; k ++)</cell><cell></cell><cell></cell></row><row><cell>32</cell><cell>Store to shared_array [k]</cell><cell></cell><cell></cell></row><row><cell>33</cell><cell>for ( int k = 0; k &lt; e1; k = k+2)</cell><cell></cell><cell></cell></row><row><cell>34</cell><cell>Load from private_array5 [k]</cell><cell></cell><cell></cell></row><row><cell>35</cell><cell>Store to private_array5 [k +1]</cell><cell></cell><cell></cell></row><row><cell>36 }</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Listing 1. Pseudo-code for Reuse-Invalidation Bench-</cell><cell></cell><cell></cell></row><row><cell cols="2">mark, RIBench.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 .</head><label>5</label><figDesc>Parameter Values of RIBench when Assessing Accuracy without Cache Line Invalidation</figDesc><table><row><cell>Test Case</cell><cell>Parameter Values</cell></row><row><cell>Short-RD Increasing</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 .</head><label>8</label><figDesc>Prediction of Execution Outcomes When ACP Is Activated</figDesc><table><row><cell>Benchmarks</cell><cell cols="2">Predictor Metric Actual Speedup</cell></row><row><cell>bodytrack</cell><cell>-1.1  *  10 9 (G &lt;0)</cell><cell>-5.41%</cell></row><row><cell>streamcluster</cell><cell>-1.2  *  10 8 (G &lt;0)</cell><cell>-8.84%</cell></row><row><cell>swaptions</cell><cell>0 ( G &gt;= 0)</cell><cell>9.74%</cell></row><row><cell>vips</cell><cell>0 (G &gt;= 0)</cell><cell>12.02%</cell></row><row><cell>backprop</cell><cell>6.9  *  10 10 (G &gt;= 0)</cell><cell>8.21%</cell></row><row><cell>bfs</cell><cell>7.6  *  10 10 (G &gt;= 0)</cell><cell>15.54%</cell></row><row><cell cols="2">ESTM-specfriendly-tree -1.6  *  10 10 (G &lt;0)</cell><cell>-25.00%</cell></row><row><cell cols="2">lockfree-fraser-skiplist -1.5  *  10 12 (G &lt;0)</cell><cell>-12.10%</cell></row><row><cell>MUTEX-hashtable</cell><cell>-3.1  *  10 11 (G &lt;0)</cell><cell>-7.25%</cell></row><row><cell>MUTEX-skiplist</cell><cell>-9.6  *  10 10 (G &lt;0)</cell><cell>-15.34%</cell></row><row><cell>SPIN-hashtable</cell><cell>-5.3  *  10 10 (G &lt;0)</cell><cell>-11.66%</cell></row><row><cell>SPIN-hoh-list</cell><cell>-1.8  *  10 10 (G &lt;0)</cell><cell>-11.24%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>ACM Transactions on Architecture and Code Optimization, Vol. 19, No. 1, Article 3. Publication date: December 2021.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>We note that a different thread pinning can expose the reuse opportunity, but we consider it orthogonal to our current work. ACM Transactions on Architecture and Code Optimization, Vol. 19, No. 1, Article 3. Publication date: December</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2021" xml:id="foot_2"><p></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_3"><p>The same philosophy has been at the core of RDX<ref type="bibr" target="#b60">[60]</ref>, but it is limited to single-threaded reuse distance measurement. ACM Transactions on Architecture and Code Optimization, Vol. 19, No. 1, Article</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_4"><p>Publication date: December 2021.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_5"><p>Compact mapping assigns the thread t + 1 to a free thread context as close as possible to the thread context where the thread t was placed. ACM Transactions on Architecture and Code Optimization, Vol. 19, No. 1, Article 3. Publication date: December 2021.</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>The work is supported by the <rs type="funder">Scientific and Technological Research Council of Turkey (TUBITAK)</rs>, Grant No. <rs type="grantNumber">120E492</rs>. <rs type="person">Dr. Didem Unat</rs> is supported by the <rs type="funder">Royal Society-Newton Advanced Fellowship</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_aKYU7bY">
					<idno type="grant-number">120E492</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ReuseTracker: Fast Yet Accurate Multicore Reuse Distance Analyzer 3:15  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Accuracy without Invalidation</head><p>The simplest case is that of intra-thread reuse distance when there is no invalidation (this is analogous to single-threaded reuse distance). For this base case, we configured the parameters of the RIBench to generate four different reuse distance patterns, increasing, decreasing, bell-shaped, and multi-modal. We also created two cases for each pattern, short reuse distance (short-RD) and long reuse distance (long-RD) cases. In the short-RD cases, the reuse distance is lower than the sampling period, while in the long-RD cases, the reuse distance is higher than or equal to the sampling period. Therefore, in total there are eight different test cases. Table <ref type="table">5</ref> shows the values of the parameters in each test case. As can be seen in the table, a1, b1, c1, d1, and e1 that determine the reuse distances in each thread are always less than the sampling interval, which is 100K, for the short-RD cases, while they are always equal to or higher than the sampling interval for the long-RD cases.</p><p>The results produced by ReuseTracker running these test cases with 32 threads are presented in Figure <ref type="figure">3</ref>. As can be seen in the figures, the reuse distance histograms generated by ReuseTracker are close to the ground truth. The average accuracy for short reuse distance cases is 94%, and the accuracy for long reuse distance cases is 90%. In short reuse distance cases, all reuses can be trapped without having to rely on reservoir sampling. Thus, ReuseTracker exhibits better accuracy in these cases than in the long reuse distance ones.</p><p>Among the long reuse distance cases, we can see that the Long-RD Decreasing (Figure <ref type="figure">3</ref>(f)) and the Long-RD Multi-modal (Figure <ref type="figure">3(h)</ref>) cases have the lowest accuracies. These results can be attributed to the probabilistic nature of reservoir sampling and the fact that the Long-RD Decreasing and the Long-RD Multi-modal cases have fewer sample counts taken from the loops in lines 18-35 of Listing 1, which access large arrays, than the other two Long-RD cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Accuracy with Invalidation</head><p>Next, we introduce invalidations in the setup and assess the intra-thread reuse profiling algorithm with cache line invalidations. This setup has 12 test cases that were derived from the Bell-shaped and Decreasing configurations given in Table <ref type="table">5</ref>. Each configuration was modified to generate three different reuse distance histogram patterns that have different amount of cache line invalidations. Table <ref type="table">6</ref> displays the modified configurations for the Bell-shaped cases, while Table <ref type="table">7</ref> shows the modified configurations for the Decreasing cases. Among these configurations, Case 3 leads to more cache line invalidations than Case 2, which leads to more cache line invalidations than Case 1. The</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><surname>Github</surname></persName>
		</author>
		<ptr target="https://github.com/dcompiler/loca" />
		<title level="m">dcompiler/loca: Program Locality Analysis Tools</title>
		<imprint/>
	</monogr>
	<note>Retrieved on 20 July, 2020 from</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Harmonic Progression</title>
		<author>
			<persName><surname>Wikipedia</surname></persName>
		</author>
		<ptr target="https://en.wikipedia.org/wiki/Harmonic_progression_(mathematics)" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName><surname>Intel</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Retrieved on 1 February</title>
		<author>
			<persName><forename type="first">*</forename><surname>Linux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">*)</forename><surname>Windows</surname></persName>
		</author>
		<ptr target="https://software.intel.com/content/www/us/en/develop/documentation/cpp-compiler-developer-guide-and-reference/top/optimization-and-programming-guide/openmp-support/openmp-library-support/thread-affinity-interface-linux-and-windows" />
	</analytic>
	<monogr>
		<title level="m">Thread Affinity Interface</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">HPCToolkit: Tools for performance analysis of optimized parallel programs</title>
		<author>
			<persName><forename type="first">L</forename><surname>Adhianto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Krentel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Marin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mellor-Crummey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Tallent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Concurr. Comput.: Pract. Exper</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="685" to="701" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">PPT-SASMM: Scalable analytical shared memory model: Predicting the performance of multicore caches from a single-threaded execution trace</title>
		<author>
			<persName><forename type="first">Atanu</forename><surname>Barai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gopinath</forename><surname>Chennupati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nandakishore</forename><surname>Santhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdel-Hameed</forename><surname>Badawy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yehia</forename><surname>Arafa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Eidenbenz</surname></persName>
		</author>
		<idno type="DOI">10.1145/3422575.3422806</idno>
		<ptr target="https://doi.org/10.1145/3422575.3422806" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Memory Systems (MEM-SYS&apos;20)</title>
		<meeting>the International Symposium on Memory Systems (MEM-SYS&apos;20)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="341" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">StatCache: A probabilistic approach to efficient and accurate data locality analysis</title>
		<author>
			<persName><forename type="first">E</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hagersten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Symposium on Performance Analysis of Systems and Software</title>
		<meeting>the IEEE International Symposium on Performance Analysis of Systems and Software</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="20" to="27" />
		</imprint>
	</monogr>
	<note>ISPASS&apos;04</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fast data-locality profiling of native execution</title>
		<author>
			<persName><forename type="first">Erik</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Hagersten</surname></persName>
		</author>
		<idno type="DOI">10.1145/1064212.1064232</idno>
		<ptr target="https://doi.org/10.1145/1064212.1064232" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIG-METRICS International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS&apos;05)</title>
		<meeting>the ACM SIG-METRICS International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS&apos;05)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="169" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Reuse distance as a metric for cache behavior</title>
		<author>
			<persName><forename type="first">Kristof</forename><surname>Beyls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik D'</forename><surname>Hollander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Parallel and Distributed Computing and Systems</title>
		<meeting>the International Conference on Parallel and Distributed Computing and Systems</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="617" to="622" />
		</imprint>
	</monogr>
	<note>IASTED&apos;01</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The PARSEC benchmark suite: Characterization and architectural implications</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bienia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Parallel Architectures and Compilation Techniques (PACT&apos;08)</title>
		<meeting>the International Conference on Parallel Architectures and Compilation Techniques (PACT&apos;08)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="72" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Estimating cache misses and locality using stack distances</title>
		<author>
			<persName><forename type="first">Calin</forename><surname>Cascaval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Padua</surname></persName>
		</author>
		<idno type="DOI">10.1145/782814.782836</idno>
		<ptr target="https://doi.org/10.1145/782814.782836" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Annual International Conference on Supercomputing (ICS&apos;03)</title>
		<meeting>the 17th Annual International Conference on Supercomputing (ICS&apos;03)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="150" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Formalizing data locality in task parallel applications</title>
		<author>
			<persName><forename type="first">Germ?n</forename><surname>Ceballos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Hagersten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Black-Schaffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Algorithms and Architectures for Parallel Processing</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="43" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rodinia: A benchmark suite for heterogeneous computing</title>
		<author>
			<persName><forename type="first">Che</forename><surname>Shuai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Boyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiayuan</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Tarjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><forename type="middle">W</forename><surname>Sheaffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sang-Ha</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Skadron</surname></persName>
		</author>
		<idno type="DOI">10.1109/IISWC.2009.5306797</idno>
		<ptr target="https://doi.org/10.1109/IISWC.2009.5306797" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Symposium on Workload Characterization (IISWC&apos;09)</title>
		<meeting>the IEEE International Symposium on Workload Characterization (IISWC&apos;09)</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="44" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Predicting inter-thread cache contention on a chip multi-processor architecture</title>
		<author>
			<persName><forename type="first">Dhruba</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seongbeom</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Solihin</surname></persName>
		</author>
		<idno type="DOI">10.1109/HPCA.2005.27</idno>
		<ptr target="https://doi.org/10.1109/HPCA.2005.27" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Symposium on High-Performance Computer Architecture</title>
		<meeting>the 11th International Symposium on High-Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="340" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A Composable Model for Analyzing Locality of Multi-threaded Programs</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trishul</forename><surname>Chilimbi</surname></persName>
		</author>
		<idno>MSR-TR-2009-107</idno>
		<ptr target="https://www.microsoft.com/en-us/research/publication/a-composable-model-for-analyzing-locality-of-multi-threaded-programs/" />
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Chen</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutao</forename><surname>Zhong</surname></persName>
		</author>
		<title level="m">Reuse Distance Analysis</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Predicting whole-program locality through reuse distance analysis</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutao</forename><surname>Zhong</surname></persName>
		</author>
		<idno type="DOI">10.1145/780822.781159</idno>
		<ptr target="https://doi.org/10.1145/780822.781159" />
	</analytic>
	<monogr>
		<title level="j">SIGPLAN Not</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="245" to="257" />
			<date type="published" when="2003-05">2003. May 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Instruction-based Sampling: A New Performance Analysis Technique for AMD Family 10h Processors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><surname>Drongowski</surname></persName>
		</author>
		<ptr target="https://pdfs.semanticscholar.org/5219/" />
		<imprint>
			<date type="published" when="2007">2007. 4b43b8385ce39b2b08ecd409c753e0efafe5.pdf</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Improving cache management policies using dynamic reuse distances</title>
		<author>
			<persName><forename type="first">Nam</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dali</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taesu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rosario</forename><surname>Cammarota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateo</forename><surname>Valero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">V</forename><surname>Veidenbaum</surname></persName>
		</author>
		<idno type="DOI">10.1109/MICRO.2012.43</idno>
		<ptr target="https://doi.org/10.1109/MICRO.2012.43" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO&apos;12)</title>
		<meeting>the 45th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO&apos;12)</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="389" to="400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">StatCC: A Statistical Cache Contention Model</title>
		<author>
			<persName><forename type="first">David</forename><surname>Eklov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Black-Schaffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Hagersten</surname></persName>
		</author>
		<idno type="DOI">10.1145/1854273.1854347</idno>
		<ptr target="https://doi.org/10.1145/1854273.1854347" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on Parallel Architectures and Compilation Techniques</title>
		<meeting>the 19th International Conference on Parallel Architectures and Compilation Techniques<address><addrLine>Vienna, Austria; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="551" to="552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Fast modeling of shared caches in multicore systems</title>
		<author>
			<persName><forename type="first">David</forename><surname>Eklov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Black-Schaffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Hagersten</surname></persName>
		</author>
		<idno type="DOI">10.1145/1944862.1944885</idno>
		<ptr target="https://doi.org/10.1145/1944862" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on High Performance and Embedded Architectures and Compilers (HiPEAC&apos;11)</title>
		<meeting>the 6th International Conference on High Performance and Embedded Architectures and Compilers (HiPEAC&apos;11)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2011">2011. 1944885</date>
			<biblScope unit="page" from="147" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">StatStack: Efficient modeling of LRU caches</title>
		<author>
			<persName><forename type="first">D</forename><surname>Eklov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hagersten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Symposium on Performance Analysis of Systems Software (ISPASS&apos;10</title>
		<meeting>the IEEE International Symposium on Performance Analysis of Systems Software (ISPASS&apos;10</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="55" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">More than you ever wanted to know about synchronization: Synchrobench, measuring the impact of the synchronization on concurrent algorithms</title>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Gramoli</surname></persName>
		</author>
		<idno type="DOI">10.1145/2688500.2688501</idno>
		<ptr target="https://doi.org/10.1145/2688500.2688501" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPoPP&apos;15)</title>
		<meeting>the 20th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPoPP&apos;15)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Optimizing Application Performance on Intel Core Microarchitecture Using Hardware-Implemented Prefetchers</title>
		<author>
			<persName><forename type="first">Ravi</forename><surname>Hegde</surname></persName>
		</author>
		<ptr target="https://software.intel.com/content/www/us/en/develop/articles/optimizing-application-performance-on-intel-coret-microarchitecture-using-hardware-implemented-prefetchers.html" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fast miss ratio curve modeling for storage cache</title>
		<author>
			<persName><forename type="first">Xiameng</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingwei</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenlin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chencheng</forename><surname>Ye</surname></persName>
		</author>
		<idno type="DOI">10.1145/3185751</idno>
		<ptr target="https://doi.org/10.1145/3185751" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Storage</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">34</biblScope>
			<date type="published" when="2018-04">2018. Apr. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Intel Microarchitecture Codename Nehalem Performance Monitoring Unit Programming Guide</title>
		<author>
			<persName><surname>Intel</surname></persName>
		</author>
		<ptr target="https://software.intel.com/sites/default/files/m/5/2/c/f/1/30320-Nehalem-PMU-Programming-Guide-Core.pdf" />
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A probability model of calculating L2 cache misses</title>
		<author>
			<persName><forename type="first">Kecheng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.2991/csece-18.2018.71</idno>
		<ptr target="https://doi.org/10.2991/csece-18.2018.71" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computer Science, Electronics and Communication Engineering (CSECE&apos;18)</title>
		<meeting>the International Conference on Computer Science, Electronics and Communication Engineering (CSECE&apos;18)</meeting>
		<imprint>
			<publisher>Atlantis Press</publisher>
			<date type="published" when="2018">2018/02</date>
			<biblScope unit="page" from="329" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Using the first-level cache stack distance histograms to predict multilevel LRU cache misses</title>
		<author>
			<persName><forename type="first">Kecheng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Longxing</forename><surname>Shi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.micpro.2017.10.001</idno>
		<ptr target="https://doi.org/10.1016/j.micpro.2017.10.001" />
	</analytic>
	<monogr>
		<title level="j">Microprocess. Microsyst</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="55" to="69" />
			<date type="published" when="2017-11">2017. Nov. 2017</date>
		</imprint>
	</monogr>
	<note>C</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An artificial neural network model of LRU-cache misses on out-of-order embedded processors</title>
		<author>
			<persName><forename type="first">Kecheng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Longxing</forename><surname>Shi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.micpro.2017.02.005</idno>
		<idno>02.005</idno>
		<ptr target="https://doi.org/10.1016/j.micpro.2017" />
	</analytic>
	<monogr>
		<title level="j">Microprocess. Microsyst</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="66" to="79" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Is reuse distance applicable to data locality analysis on chip multiprocessors?</title>
		<author>
			<persName><forename type="first">Yunlian</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eddy</forename><forename type="middle">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xipeng</forename><surname>Shen</surname></persName>
		</author>
		<editor>Compiler Construction, Rajiv Gupta</editor>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="264" to="282" />
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Some requirements for architectural support of software debugging</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johnson</forename></persName>
		</author>
		<idno type="DOI">10.1145/800050.801837</idno>
		<ptr target="https://doi.org/10.1145/800050.801837" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st International Symposium on Architectural Support for Programming Languages and Operating Systems (ASPLOS&apos;82)</title>
		<meeting>the 1st International Symposium on Architectural Support for Programming Languages and Operating Systems (ASPLOS&apos;82)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1982">1982</date>
			<biblScope unit="page" from="140" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Concurrent reading and writing</title>
		<author>
			<persName><forename type="first">Leslie</forename><surname>Lamport</surname></persName>
		</author>
		<idno type="DOI">10.1145/359863.359878</idno>
		<ptr target="https://doi.org/10.1145/359863.359878" />
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="806" to="811" />
			<date type="published" when="1977-11">1977. Nov. 1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">David</forename><surname>Levinthal</surname></persName>
		</author>
		<ptr target="https://www.amd.com/system/files/TechDocs/24594.pdf" />
		<title level="m">Performance Analysis Guide for Intel Core i7 Processor and Intel Xeon 5500 Processors. Retrieved from</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fast modeling L2 cache reuse distance histograms using combined locality information from software traces</title>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiancong</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangmin</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.sysarc.2020.101745</idno>
		<ptr target="https://doi.org/10.1016/j.sysarc.2020.101745" />
	</analytic>
	<monogr>
		<title level="j">J. Syst. Architect</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page">101745</biblScope>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Analytical modeling the multi-core shared cache behavior with considerations of data-sharing and coherence</title>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoqian</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiancong</forename><surname>Ge</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2021.3053350</idno>
		<ptr target="https://doi.org/10.1109/ACCESS.2021.3053350" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="17728" to="17743" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><surname>Linux</surname></persName>
		</author>
		<ptr target="https://linux.die.net/man/2/perf_event_open" />
		<title level="m">Linux Man Page</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Fast and accurate exploration of multi-level caches using hierarchical reuse distance</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K V</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Symposium on High Performance Computer Architecture (HPCA&apos;17</title>
		<meeting>the IEEE International Symposium on High Performance Computer Architecture (HPCA&apos;17</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="145" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Evaluation techniques for storage hierarchies</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Mattson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gecsei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Slutz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">L</forename><surname>Traiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Syst. J</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="78" to="117" />
			<date type="published" when="1970">1970. 1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Guidelines for creating a debuggable processor</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Mclear</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Scheibelhut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tammaru</surname></persName>
		</author>
		<idno type="DOI">10.1145/800050.801833</idno>
		<ptr target="https://doi.org/10.1145/800050.801833" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st International Symposium on Architectural Support for Programming Languages and Operating Systems (ASPLOS&apos;82)</title>
		<meeting>the 1st International Symposium on Architectural Support for Programming Languages and Operating Systems (ASPLOS&apos;82)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1982">1982</date>
			<biblScope unit="page" from="100" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Debugging and Performance Tuning with Library Interposers</title>
		<author>
			<persName><forename type="first">Greg</forename><surname>Nakhimovsky</surname></persName>
		</author>
		<ptr target="http://dsc.sun.com/solaris/articles/lib_interposers.html" />
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">PinPlay: A framework for deterministic replay and reproducible analysis of parallel programs</title>
		<author>
			<persName><forename type="first">Harish</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristiano</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mack</forename><surname>Stallcup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Lueck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Cownie</surname></persName>
		</author>
		<idno type="DOI">10.1145/1772954.1772958</idno>
		<ptr target="https://doi.org/10.1145/1772954.1772958" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Annual IEEE/ACM International Symposium on Code Generation and Optimization (CGO&apos;10)</title>
		<meeting>the 8th Annual IEEE/ACM International Symposium on Code Generation and Optimization (CGO&apos;10)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="2" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Scalable analysis of multicore data reuse and sharing</title>
		<author>
			<persName><forename type="first">Miquel</forename><surname>Pericas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenjiro</forename><surname>Taura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satoshi</forename><surname>Matsuoka</surname></persName>
		</author>
		<idno type="DOI">10.1145/2597652.2597674</idno>
		<ptr target="https://doi.org/10.1145/2597652.2597674" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Supercomputing (ICS&apos;14)</title>
		<meeting>the 28th ACM International Conference on Supercomputing (ICS&apos;14)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="353" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">PIN: A binary instrumentation tool for computer architecture research and education</title>
		<author>
			<persName><forename type="first">V</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Settle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Connors</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Computer Architecture Education (WCAE&apos;04)</title>
		<meeting>the Workshop on Computer Architecture Education (WCAE&apos;04)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">PIN: A binary instrumentation tool for computer architecture research and education</title>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Janapa Reddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Settle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Connors</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">S</forename><surname>Cohn</surname></persName>
		</author>
		<idno type="DOI">10.1145/1275571.1275600</idno>
		<ptr target="https://doi.org/10.1145/1275571.1275600" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Computer Architecture Education: Held in Conjunction with the 31st International Symposium on Computer Architecture (WCAE&apos;04)</title>
		<meeting>the Workshop on Computer Architecture Education: Held in Conjunction with the 31st International Symposium on Computer Architecture (WCAE&apos;04)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">22</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Dynamic decentralized cache schemes for mimd parallel processors</title>
		<author>
			<persName><forename type="first">Larry</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zary</forename><surname>Segall</surname></persName>
		</author>
		<idno type="DOI">10.1145/800015.808203</idno>
		<ptr target="https://doi.org/10.1145/800015.808203" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Annual International Symposium on Computer Architecture (ISCA&apos;84)</title>
		<meeting>the 11th Annual International Symposium on Computer Architecture (ISCA&apos;84)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1984">1984</date>
			<biblScope unit="page" from="340" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Analytical miss rate calculation of L2 cache from the RD profile of L1 cache</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Sabarimuthu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Venkatesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="9" to="15" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Analytical derivation of concurrent reuse distance profile for multithreaded application running on chip multi-processor</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Sabarimuthu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Venkatesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Parallel Distrib. Syst</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1704" to="1721" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Accelerating multicore reuse distance analysis with sampling and parallelization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Schuff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Pai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on Parallel Architectures and Compilation Techniques</title>
		<meeting>the 19th International Conference on Parallel Architectures and Compilation Techniques</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="53" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Multicore-aware reuse distance analysis</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Schuff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Parsons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Pai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Symposium on Parallel Distributed Processing, Workshops and Phd Forum</title>
		<meeting>the IEEE International Symposium on Parallel Distributed Processing, Workshops and Phd Forum</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Reuse-based online models for caches. SIGMETRICS Perform</title>
		<author>
			<persName><forename type="first">Rathijit</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
		<idno type="DOI">10.1145/2494232.2465756</idno>
		<ptr target="https://doi.org/10.1145/2494232.2465756" />
	</analytic>
	<monogr>
		<title level="j">Eval. Rev</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="279" to="292" />
			<date type="published" when="2013-06">2013. June 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Accurate Approximation of Locality from Time Distance Histograms</title>
		<author>
			<persName><forename type="first">Xipeng</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Meeker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Locality approximation using time</title>
		<author>
			<persName><forename type="first">Xipeng</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Meeker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Ding</surname></persName>
		</author>
		<idno type="DOI">10.1145/1190215.1190227</idno>
		<ptr target="https://doi.org/10.1145/1190215.1190227" />
	</analytic>
	<monogr>
		<title level="j">SIGPLAN Not</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="55" to="61" />
			<date type="published" when="2007-01">2007. Jan. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">IBM POWER7 performance modeling, verification, and evaluation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sinharoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Eickemeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kunkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Maron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Flemming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blanchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Seshadri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Kellington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mericas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Petruski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Indukuru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reyes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM JRD</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="1" to="4" />
			<date type="published" when="2011-05">2011. May-June 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Simultaneous multithreading: Maximizing on-chip parallelism</title>
		<author>
			<persName><forename type="first">Dean</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><forename type="middle">J</forename><surname>Eggers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henry</forename><forename type="middle">M</forename><surname>Levy</surname></persName>
		</author>
		<idno type="DOI">10.1145/223982.224449</idno>
		<ptr target="https://doi.org/10.1145/223982.224449" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Annual International Symposium on Computer Architecture (ISCA&apos;95)</title>
		<meeting>the 22nd Annual International Symposium on Computer Architecture (ISCA&apos;95)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="392" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Trends in data locality abstractions for HPC systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Unat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hoefler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shalf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bianco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cledat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fuerlinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hannig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Jeannot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kamil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Keasler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H J</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ltaief</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Maruyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Newburn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pericas</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPDS.2017.2703149</idno>
		<ptr target="https://doi.org/10.1109/TPDS.2017.2703149" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Parallel Distrib. Syst</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="3007" to="3020" />
			<date type="published" when="2017-10">2017. Oct. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">TiDA: High-level programming abstractions for data locality management</title>
		<author>
			<persName><forename type="first">Didem</forename><surname>Unat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tan</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiqun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhammed</forename><surname>Nufail Farooqi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Burak</forename><surname>Bastem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Michelogiannakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ann</forename><surname>Almgren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Shalf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">High Performance Computing</title>
		<editor>
			<persName><forename type="first">Julian</forename><forename type="middle">M</forename><surname>Kunkel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Pavan</forename><surname>Balaji</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jack</forename><surname>Dongarra</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="116" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Modeling superscalar processor memory-level parallelism</title>
		<author>
			<persName><forename type="first">S</forename><surname>Van Den Steen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Eeckhout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Architect. Lett</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="9" to="12" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">Krishnaswamy</forename><surname>Viswanathan</surname></persName>
		</author>
		<ptr target="https://software.intel.com/content/www/us/en/develop/articles/intelr-memory-latency-checker.html" />
		<title level="m">Intel Memory Latency Checker v3.9</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Random sampling with a reservoir</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Vitter</surname></persName>
		</author>
		<idno type="DOI">10.1145/3147.3165</idno>
		<ptr target="https://doi.org/10.1145/3147.3165" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Math. Softw</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="37" to="57" />
			<date type="published" when="1985-03">1985. Mar. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A data-sharing aware and scalable cache miss rates model for multi-core processors with multi-level cache hierarchies</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE 25th International Conference on Parallel and Distributed Systems (ICPADS)</title>
		<meeting>the IEEE 25th International Conference on Parallel and Distributed Systems (ICPADS)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="267" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Featherlight reuse-distance measurement</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chabbi</surname></persName>
		</author>
		<idno type="DOI">10.1109/HPCA.2019.00056</idno>
		<ptr target="https://doi.org/10.1109/HPCA.2019.00056" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Symposium on High Performance Computer Architecture (HPCA&apos;19)</title>
		<meeting>the IEEE International Symposium on High Performance Computer Architecture (HPCA&apos;19)<address><addrLine>Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="440" to="453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Watching for software inefficiencies with witch</title>
		<author>
			<persName><forename type="first">Shasha</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milind</forename><surname>Chabbi</surname></persName>
		</author>
		<idno type="DOI">10.1145/3296957.3177159</idno>
		<ptr target="https://doi.org/10.1145/3296957.3177159" />
	</analytic>
	<monogr>
		<title level="j">SIGPLAN Not</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="332" to="347" />
			<date type="published" when="2018-03">2018. Mar. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Watching for software inefficiencies with witch</title>
		<author>
			<persName><forename type="first">Shasha</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milind</forename><surname>Chabbi</surname></persName>
		</author>
		<idno type="DOI">10.1145/3173162.3177159</idno>
		<ptr target="https://doi.org/10.1145/3173162.3177159" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS&apos;18)</title>
		<meeting>the 23rd International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS&apos;18)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="332" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Coherent profiles: Enabling efficient reuse distance analysis of multicore scaling for loop-based parallel programs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Parallel Architectures and Compilation Techniques</title>
		<meeting>the International Conference on Parallel Architectures and Compilation Techniques</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="264" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">HOTL: A higher order theory of locality</title>
		<author>
			<persName><forename type="first">Xiaoya</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Bao</surname></persName>
		</author>
		<idno type="DOI">10.1145/2490301.2451153</idno>
		<ptr target="https://doi.org/10.1145/2490301.2451153" />
	</analytic>
	<monogr>
		<title level="j">SIGARCH Comput. Archit. News</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="343" to="356" />
			<date type="published" when="2013-03">2013. Mar. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Program locality analysis using reuse distance</title>
		<author>
			<persName><forename type="first">Yutao</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xipeng</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Ding</surname></persName>
		</author>
		<idno type="DOI">10.1145/1552309.1552310</idno>
		<ptr target="https://doi.org/10.1145/1552309.1552310" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Program. Lang. Syst</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="2009-08">2009. Aug. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
