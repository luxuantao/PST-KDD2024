<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data Management in Machine Learning: Challenges, Techniques, and Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Arun</forename><surname>Kumar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">UC</orgName>
								<address>
									<addrLine>San Diego La Jolla</addrLine>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Matthias</forename><surname>Boehm</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">IBM Research -Almaden</orgName>
								<address>
									<settlement>San Jose</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jun</forename><surname>Yang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Duke University Durham</orgName>
								<address>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data Management in Machine Learning: Challenges, Techniques, and Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1CE3AE952130899D573058D0E8F167AD</idno>
					<idno type="DOI">10.1145/3035918.3054775</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large-scale data analytics using statistical machine learning (ML), popularly called advanced analytics, underpins many modern data-driven applications. The data management community has been working for over a decade on tackling data management-related challenges that arise in ML workloads, and has built several systems for advanced analytics. This tutorial provides a comprehensive review of such systems and analyzes key data management challenges and techniques. We focus on three complementary lines of work: (1) integrating ML algorithms and languages with existing data systems such as RDBMSs, (2) adapting data management-inspired techniques such as query optimization, partitioning, and compression to new systems that target ML workloads, and (3) combining data management and ML ideas to build systems that improve ML lifecycle-related tasks. Finally, we identify key open data management challenges for future research in this important area.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Analysis of large datasets using statistical machine learning (ML) algorithms, popularly called advanced or deep analytics, is central to modern data-driven applications in business intelligence (BI), e-commerce, healthcare, science, and other domains <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b47">47]</ref>. Dating back to the in-RDBMS data mining boom of the late 1990s, the database industry and academia have been working for over a decade on data management-oriented challenges in ML. This has led to a proliferation of systems and frameworks for scalable and fast ML built by our community <ref type="bibr" target="#b2">[2,</ref><ref type="bibr" target="#b3">3,</ref><ref type="bibr" target="#b38">38,</ref><ref type="bibr" target="#b46">46,</ref><ref type="bibr" target="#b70">70,</ref><ref type="bibr" target="#b109">109]</ref>, as well as projects that apply database-inspired ideas to make ML faster and more user-friendly <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b36">36,</ref><ref type="bibr" target="#b105">105,</ref><ref type="bibr" target="#b107">107]</ref>. The diversity of this landscape of systems and projects could be overwhelming for data management researchers, data scientists, and system developers alike.</p><p>Goals: This tutorial aims to provide a timely and comprehensive review of systems and techniques that tackle data management challenges in the context of ML workloads. Our Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. focus is on analyzing the technical challenges and on explaining the key ideas, architecture, strengths, and limitations of major systems that address these challenges. This tutorial aims to provide data management researchers and systems developers with a survey of effective techniques and open issues, and to help identify systems they could build upon or compare with. It could also help data scientists understand the assumptions, pros, and cons of different systems and make more informed choices for their applications.</p><p>Tutorial Scope: Unlike previous tutorials on ML for "Big Data" <ref type="bibr" target="#b26">[26]</ref>, we do not focus on a general introduction to ML, usage of ML systems, or general dataflow or graph analytics systems, which have been covered before <ref type="bibr" target="#b10">[10,</ref><ref type="bibr" target="#b103">103]</ref>. Instead, our focus is on identifying general data management challenges and techniques in ML across a broader swathe of works. Given this focus, we also do not cover deep learning algorithms <ref type="bibr" target="#b66">[66]</ref> and systems <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b14">14,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b52">52]</ref>. Deep learning is popular specifically for image, speech, and text data, but is too broad to cover along with other techniques <ref type="bibr" target="#b101">[101]</ref>, and unlike many other ML workloads, deep learning is typically very compute-intensive and often requires GPUs, FPGAs, or even custom ASICs <ref type="bibr" target="#b4">[4]</ref>. We also exclude works that apply ML for text analytics, domain-specific applications, or for improving RDBMS internals such as speculative execution <ref type="bibr" target="#b79">[79]</ref>, learning cost models <ref type="bibr" target="#b89">[89]</ref>, predicting workload patterns <ref type="bibr" target="#b80">[80]</ref>, or resource allocation <ref type="bibr" target="#b68">[68]</ref>.</p><p>Tutorial Outline: This 1.5-hour tutorial covers the following technical content:</p><p>• Workload Characterization: We motivate a datacentric view of ML by providing some basic background on the common data characteristics, data management operations, data access patterns of popular ML algorithms, and pre-processing techniques. • ML in Data Systems: We review systems and frameworks that integrate ML algorithms, frameworks, and languages with existing data systems (Section 2). We will discuss techniques ranging from UDF-centric approaches to deeply integrated approaches. • DB-Inspired ML Systems: We review systems and frameworks designed for ML workloads that apply and adapt DB-inspired techniques (Section 3). Example techniques include optimization with rewrites and operator selection, incremental model maintenance, compression, and access methods. • ML Lifecycle Systems: We review systems that combine DB and ML ideas and target ML lifecycle tasks that go beyond improving the performance of individual algorithms (Section 4).</p><p>• Open Problems: Finally, we identify and discuss several open research problems as potential directions for new research in this emerging area (Section 5).</p><p>Target Audience: This tutorial targets all researchers and practitioners interested in data management challenges and techniques in the context of building scalable and userfriendly systems for ML. We assume that the audience is generally familiar with ML applications and common technical terms. We do not require prior knowledge of specific ML algorithms, workload characteristics, or system internals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">ML IN DATA SYSTEMS</head><p>We cover systems that integrate ML algorithms with an RDBMS or more recent dataflow systems to bring ML computations closer to where the data resides (e.g., in an RDBMS, or on HDFS). Thus, they avoid or reduce the cost of moving data to specialized ML toolkits. In the tutorial, we will introduce these systems, explain the architecture of representative examples, and highlight the data management challenges that arise, along with how they are tackled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">UDF-Oriented ML</head><p>An early approach to scalable ML exploited the userdefined function (UDF) and user-defined aggregate (UDA) abstractions in data systems. Examples include ATLAS <ref type="bibr" target="#b100">[100]</ref>, in-RDBMS ML libraries such as Oracle Data Mining, GLADE, which introduced generalized linear aggregates using UDAs <ref type="bibr" target="#b22">[22]</ref>, one-pass algorithms computing sufficient statistics using UDFs <ref type="bibr" target="#b76">[76]</ref>, as well as Mahout on Hadoop <ref type="bibr" target="#b1">[1]</ref> and MLlib on Spark <ref type="bibr" target="#b70">[70]</ref>. Some systems offer more templated approaches to reduce software development effort. Examples include Bismarck <ref type="bibr" target="#b38">[38]</ref>, which offers a unified architecture based on stochastic gradient descent, and MADlib <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b46">46]</ref>, which provides abstractions for in-RDBMS ML with type bridging from database types such as the SQL:99 array type. Similarly, UDFs are also commonly used for parallel prediction <ref type="bibr" target="#b81">[81]</ref>. Overall, such systems make it easier to use ML in conjunction with regular SQL for data processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Learning over Joins</head><p>Some recent efforts integrate ML with data systems more deeply by optimizing ML over datasets that are logically the output relational queries, especially, joins. This includes Orion <ref type="bibr" target="#b63">[63]</ref>, which introduced the "factorized learning" technique to push generalized linear models through joins to avoid redundancy in ML computations, Santoku <ref type="bibr" target="#b62">[62]</ref>, a library of factorized learning and scoring algorithms in R, F <ref type="bibr" target="#b87">[87]</ref>, a new algorithm and tool for linear regression over "factorized joins," and Morpheus, which generalizes this idea to any ML computations expressible in the formal language of linear algebra <ref type="bibr" target="#b21">[21]</ref>. Closely related are LibFM <ref type="bibr" target="#b84">[84]</ref>, which lets users specify repeating patterns in the data (possibly caused by joins), and TensorDB <ref type="bibr" target="#b58">[58]</ref>, which pushes tensor decompositions through joins and unions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">SRL Systems</head><p>Some systems exploit RDBMSs to support complex multirelational ML models known as statistical relational learning (SRL) models <ref type="bibr" target="#b42">[42]</ref>. The primary example is DeepDive <ref type="bibr" target="#b31">[31]</ref>, which supports Markov Logic Networks (MLN) and derived SRL models on top of an RDBMS. DeepDive exploits the advanced join processing capabilities of RDBMSs to scale MLN inference, making it possible to apply such models to large-scale datasets <ref type="bibr" target="#b75">[75]</ref>. Another example, ERACER <ref type="bibr" target="#b69">[69]</ref>, implemented relational dependency network models on top of an RDBMS for data cleaning tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Query Generators</head><p>A further class of systems provide higher level abstractions on top of a data system to simplify the development and customization of new and existing ML algorithms. Under the covers, these systems generate either SQL queries (potentially augmented with procedural extensions and UDFs) on top of an RDBMS, or jobs for data-parallel frameworks such as Hadoop or Spark. The primary examples in this class are the R-based analytics systems such as RIOT-DB <ref type="bibr" target="#b109">[109]</ref>, Oracle R Enterprise <ref type="bibr" target="#b3">[3]</ref>, IBM BigR <ref type="bibr" target="#b104">[104]</ref>, and SparkR <ref type="bibr" target="#b99">[99]</ref>, which provide R as a front-end, store matrices or data frames in the underlying system, and convert operations over these matrices into queries. Further examples include ScalOps <ref type="bibr" target="#b18">[18]</ref>, which generates Datalog programs and finally data-parallel jobs, as well as SimSQL <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b40">40]</ref>, which targets Bayesian ML model specifications that generate SQL queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Deep RDBMS Integration</head><p>A few projects extend core RDBMS technology to better support ML workloads, in contrast to the previously described classes of systems that leave the data system unaltered. There are two main categories. First, there are DBMS extensions with built-in support for specific model classes. For example, the Fa <ref type="bibr" target="#b34">[34]</ref> and F 2 DB <ref type="bibr" target="#b39">[39]</ref> systems allow declarative forecasting queries by automating model creation, maintenance, and usage. Second, systems like SAP HANA aim to integrate linear algebra for a wide range of ML algorithms. Existing prototypes integrate sparse matrices into SAP HANA's delta architecture <ref type="bibr" target="#b54">[54]</ref> and extend the database task scheduler to support multi-threaded OpenMP applications such as linear algebra kernels <ref type="bibr" target="#b102">[102]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">DB-INSPIRED ML SYSTEMS</head><p>We cover a variety of systems and domain-specific languages (DSLs) that go beyond just reusing existing data systems for ML workloads. Many techniques used here are inspired by databases, programming languages, and high performance computing. We will cover a variety of techniques, ranging from optimization and processing, over storage and access methods, to deployment in the cloud. The major differences with traditional RDBMSs are the focus on linear algebra and other ML operations, general DAG structures, and specific sparse and dense data representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Rewrites and Operator Selection</head><p>Similar to traditional query optimization, many state-ofthe-art optimizing compilers for ML algorithms like RIOT <ref type="bibr" target="#b109">[109]</ref>, OptiML <ref type="bibr" target="#b94">[94]</ref>, SystemML <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b17">17]</ref>, Cumulon <ref type="bibr" target="#b48">[48]</ref>, and Mahout Samsara <ref type="bibr" target="#b86">[86]</ref> rely on simplification rewrites <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b94">94,</ref><ref type="bibr" target="#b109">109]</ref> and operator selection <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b48">48,</ref><ref type="bibr" target="#b86">86]</ref>. Most of these systems use pattern-matching rewrites and a variety of physical operators, chosen with a cost model that incorporates data and cluster characteristics. One important techniquesimilar to join ordering-is matrix multiplication chain optimization, for which SpMacho incorporated sparsity estimates into a common dynamic programming algorithm <ref type="bibr" target="#b55">[55]</ref> and FAQ described a generalization to so-called functional aggregate queries <ref type="bibr" target="#b57">[57]</ref>. Furthermore, SystemML SPOOF made a case for automatic rewrite identification via sumproduct optimization on restricted relational algebra plans <ref type="bibr" target="#b35">[35]</ref>. Finally, note that initially unknown or changing characteristics require runtime plan adaptation similar to adaptive query processing. SystemML, for instance, adapts plans during runtime via dynamic recompilation <ref type="bibr" target="#b16">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Incremental Model Maintenance</head><p>Incremental maintenance of materialized views is a well studied topic in the database literature. In the spirit of MauveDB's model-based views <ref type="bibr" target="#b32">[32]</ref>, we can regard an ML model and its predictions as a materialized view of the input data. Several learning tasks then allow efficient incremental maintenance. For example, LINVIEW derives delta update rules from linear algebra programs <ref type="bibr" target="#b73">[73]</ref>, and incremental iterations aim to reduce the working set across iterations of fixpoint computations <ref type="bibr" target="#b37">[37]</ref>. Similarly, DeepDive performs incremental grounding and inference for SRL models <ref type="bibr" target="#b88">[88]</ref>, Hazy incrementally maintains classification views <ref type="bibr" target="#b59">[59]</ref>, and Velox applies offline and online learning <ref type="bibr" target="#b27">[27]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Operator Fusion and Code Generation</head><p>Modern in-memory database systems often apply query compilation. Several ML systems also use fused operators or automatic code generation to reduce the number of intermediates and input scans, or to exploit sparsity across operations. SystemML <ref type="bibr" target="#b11">[11,</ref><ref type="bibr" target="#b17">17]</ref> and Cumulon <ref type="bibr" target="#b48">[48]</ref> use handcoded fused operators, whereas <ref type="bibr" target="#b111">[111]</ref> applies static analysis and code generation techniques to optimize I/O for matrix computation. OptiML <ref type="bibr" target="#b94">[94]</ref> and Emma <ref type="bibr">[7]</ref> apply automatic fusion in the context of DSLs embedded in functional programming languages. Tupleware <ref type="bibr" target="#b29">[29]</ref> and Kasen <ref type="bibr" target="#b108">[108]</ref> generate distributed programs for UDF-centric programs but without exploiting sparsity across operations. SystemML SPOOF <ref type="bibr" target="#b35">[35]</ref> recently introduced a holistic framework for automatic rewrite identification and operator fusion, including the generation of sparsity-exploiting operators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Asynchronous Execution</head><p>A few recent systems go beyond the bulk synchronous processing model to enable asynchronous execution of iterative ML algorithms, especially those that use stochastic gradient descent (SGD). Since SGD is often robust to the order of updates, we can use asynchronous execution to avoid global barriers. Example systems are GraphLab <ref type="bibr" target="#b67">[67]</ref> and Tensor-Flow <ref type="bibr" target="#b4">[4]</ref>. In contrast, Hogwild! <ref type="bibr" target="#b74">[74]</ref> uses lock-free updates of a shared model for multi-threaded, single-node SGD. They showed, for sparse model updates, that SGD still achieves near-optimal convergence rates. Finally, Gonzalez et al. also extended the Hogwild! idea to dataflow systems <ref type="bibr" target="#b43">[43]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Compression and Scan Sharing</head><p>Many ML algorithms are iterative and perform repeated matrix-vector multiplications. Since matrix-vector multiplications are-similar to traditional table scans-even inmemory I/O-bound, existing work tries to reduce the data size via compression or reduce the number of scans. First, SciDB uses general-purpose compression techniques in the storage manager and decompresses arrays block-wise for each operation <ref type="bibr" target="#b93">[93]</ref>. In contrast, SystemML employs lightweight database compression techniques and executes linear algebra operations directly on the compressed matrix representation <ref type="bibr" target="#b36">[36]</ref>. Second, once again due to the promi-nence of I/O-bound operations, other scenarios such as cross validation, ensemble learning, feature selection, and hyperparameter tuning also typically benefit from scan sharing. For example, MLbase's TUPAQ <ref type="bibr" target="#b91">[91]</ref> and Columbus <ref type="bibr" target="#b105">[105]</ref> use batching to evaluate multiple model configurations in one pass. Similarly, SystemML uses a technique called runtime piggybacking to batch MR jobs submitted from concurrent threads of a task-parallel parfor loop <ref type="bibr" target="#b15">[15]</ref> for scan sharing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Index Structures and Partitioning</head><p>Inspired by traditional access methods in database systems, some ML systems employ dedicated index structures, operation-and topology-aware partitioning and replication, as well as buffer management. First, the LAB-tree (Linearized Array B-tree) <ref type="bibr" target="#b110">[110]</ref> indexes out-of-core matrices in a sparsity-aware manner. Similarly, the AT MATRIX (Adaptive Tile Matrix) <ref type="bibr" target="#b56">[56]</ref> also uses sparse and dense leaf blocks but is designed for in-memory, NUMA-aware parallelization. The TileDB storage manager uses fragments to handle dense and sparse arrays with random writes <ref type="bibr" target="#b78">[78]</ref>. Furthermore, there are domain-specific data structures such as a skip list for I/O-efficient processing of forecasting queries <ref type="bibr" target="#b41">[41]</ref>. Second, various systems apply partitioning and replication in an operation-or topology-aware manner. For example, the AT MATRIX <ref type="bibr" target="#b56">[56]</ref> uses horizontal range partitioning and socket-local task queues with task-stealing across queues. DimmWitted <ref type="bibr" target="#b107">[107]</ref> explores the tradeoff of statistical and hardware efficiency in NUMA architectures via different access methods and replication strategies. ArrayStore <ref type="bibr" target="#b90">[90]</ref> investigates effective partitioning schemes for typical array operations and accessing adjacent tiles. Complementary to these strategies, SystemML injects hash partitioning directives for out-of-core matrices that are used read-only in loops to avoid shuffling per iteration <ref type="bibr" target="#b17">[17]</ref>. Third, there is also work on buffer management. Elementary <ref type="bibr" target="#b106">[106]</ref> explores materialization and buffer management for out-of-core factor graphs, whereas SystemML employs a buffer pool <ref type="bibr" target="#b17">[17]</ref> to evict intermediate results of linear algebra programs, if required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Cloud ML Resource Elasticity</head><p>In public or private clouds, BI and ML workloads share similar challenges of cost-effective resource allocation and robustness against preemption. Cumulon <ref type="bibr" target="#b48">[48]</ref> simplifies the deployment in cloud environments by optimizing physical plans for monetary costs under time constraints. This includes allocation decisions such as the cluster size, node types, and configurations. In contrast, SystemML's resource optimizer <ref type="bibr" target="#b50">[50]</ref> optimizes for performance without unnecessary over-provisioning via an online what-if analysis, in a plan-aware manner. Similar to SystemML's resource adaptation, Dolphin <ref type="bibr" target="#b23">[23]</ref> performs runtime configuration optimization but for parameter servers. Cümülön <ref type="bibr" target="#b49">[49]</ref>-an extension of Cumulon that makes use of cheap, but unreliable "spot instances"-considers the risk of preemption to optimize bidding strategies. Narayanamurthy et al. handle preemption in an algorithm-specific manner by approximating the loss function for missing partitions <ref type="bibr" target="#b72">[72]</ref>. Similarly, Schelter et al. introduced an optimistic recovery mechanism for fixpoint computations based on compensation functions <ref type="bibr" target="#b85">[85]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">ML LIFECYCLE SYSTEMS</head><p>We cover systems that target-beyond training individual models-other important tasks in the ML lifecycle, in-cluding tasks that occur before training or as "outer loops" surrounding training and prediction. We discuss tasks such as feature engineering, model selection, and model management. Many of these systems apply DB-centric ideas such as declarativity, interactivity, and optimization, often combining such ideas with techniques from the ML literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Feature Engineering</head><p>Feature engineering is the process of constructing features, which includes tasks such as feature extraction from raw data and feature selection <ref type="bibr" target="#b44">[44]</ref>. It is often considered to be the most time-consuming part of an applied ML project <ref type="bibr" target="#b33">[33]</ref>. While the ML community has studied algorithmic feature selection, auxiliary pains in feature engineering have largely been ignored. Our community is building systems to support such tasks by taking a dataflow-oriented view. Brainwash <ref type="bibr" target="#b9">[9]</ref> and DeepDive <ref type="bibr" target="#b83">[83]</ref> abstracted such tasks using workflows of UDFs and proposed DB-style ideas to optimize them. Columbus proposed a DSL for exploratory feature selection and applied both DB-style and ML-style optimizations such as batching, QR decomposition, and warm starting to reduce runtimes under accuracy constraints. Zombie <ref type="bibr" target="#b8">[8]</ref> optimized feature extraction and refinement tasks by combining indexing and partitioning ideas with a multi-armed bandit technique to read only parts of the data. KeystoneML <ref type="bibr" target="#b92">[92]</ref> provides libraries for certain forms of featurization and optimizes pipelines of such ML operators over Spark. Complementary to these ideas, Hamlet <ref type="bibr" target="#b65">[65]</ref> applied statistical learning theory to exploit certain database dependencies to drop features before ML without affecting accuracy significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Model Selection and Management</head><p>Model selection is the overarching process of obtaining satisfactory ML models; it subsumes feature engineering and includes algorithm selection (AS) and hyper-parameter tuning (HT) <ref type="bibr" target="#b45">[45]</ref>. It is typically an iterative human-in-the-loop process but most existing ML systems provide little support for optimizing this process end-to-end. Longview <ref type="bibr" target="#b6">[6]</ref> proposed integrating "model management" functionality into a DBMS to automate certain aspects of model selection, along with managing learned ML models. AutoWeka <ref type="bibr" target="#b96">[96]</ref> and MLbase <ref type="bibr" target="#b60">[60]</ref> automate AS and HT, with MLbase's TUPAQ applying multi-armed bandit-style techniques <ref type="bibr" target="#b91">[91]</ref>. Hemingway <ref type="bibr" target="#b77">[77]</ref> automates AS and cluster size tuning jointly for distributed optimization algorithms, while <ref type="bibr" target="#b82">[82]</ref> applied online aggregation-style techniques for HT in optimization algorithms. More generally, <ref type="bibr" target="#b64">[64]</ref> outlined a vision of "model selection management systems" that build upon existing systems and combine ideas from the DB and ML to enable a wider spectrum of automation. Example systems include Sherlock <ref type="bibr" target="#b97">[97]</ref>, which proposed abstractions for iterative model building, ModelHub <ref type="bibr" target="#b71">[71]</ref>, which proposed a language and storage manager for managing deep neural networks that arise in computer vision, and ModelDB <ref type="bibr" target="#b98">[98]</ref>, which instruments ML libraries to capture and manage models.</p><p>Complementary to the above systems, cloud ML services, such as AzureML <ref type="bibr" target="#b2">[2]</ref>, aim at simple construction, scaling, and management of end-to-end ML workflows. A few recent systems target data cleaning and interactive specification as well. ActiveClean <ref type="bibr" target="#b61">[61]</ref> integrates iterative data cleaning with SGD-based learning of convex ML models and proposes new sampling mechanisms to preserve convergence guarantees. Ava <ref type="bibr" target="#b53">[53]</ref> provides a chat-bot front-end to make it easier to build models by maintaining a repository of "storyboards" for typical templates, while Vizdom <ref type="bibr" target="#b30">[30]</ref> enables users to visually specify ML tasks on a touchscreen with incremental refinement of partial results. Finally, some systems aim to improve the usability and performance of serving trained ML models and predictions. Examples include Velox <ref type="bibr" target="#b27">[27]</ref> and its successor Clipper <ref type="bibr" target="#b28">[28]</ref>, which enables model deployment across multiple frameworks, as well as MacroBase <ref type="bibr" target="#b12">[12]</ref>, which combines stream mining with streaming data explanation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">OPEN PROBLEMS</head><p>There are still various open research problems that need the attention of our community. We outline several problems although by no means is this an exhaustive list.</p><p>Size and Sparsity Estimation: Many optimization techniques require prior knowledge of the size and sparsity of matrices for cost comparisons and valid plan generation. But it is often non-trivial to infer such information for intermediates in complex linear algebra programs with conditional control flow, complex function call patterns, UDFs, and data-dependent operations. Hence, principled techniques for estimating the size and sparsity would be beneficial.</p><p>Convergence Estimation: Iterative ML algorithms often use convergence-based termination conditions. This leads to an unpredictable number of iterations, which makes it challenging to estimate the runtime, say, for resource allocation, or for decisions on expensive data re-organizations. Techniques to predict the number of iterations for convergence of ML algorithms would not only enable such optimizations but also enable progress estimators.</p><p>Adaptive Query Processing and Storage: Unknown or changing workloads are typically handled with adaptive query processing and storage techniques. But such concerns have received little attention in the context of large-scale ML. The state of the art is limited to inter-DAG dynamic recompilation <ref type="bibr" target="#b16">[16]</ref> and lazy expression optimization <ref type="bibr" target="#b86">[86]</ref>.</p><p>Automatic Rewrites and Operator Fusion: Existing systems mostly apply coarse-grained pattern transformations, which limits rewrite and fusion potential. Rewrite frameworks would further benefit from a better exploitation of data flow (e.g., partitioning) and structural properties (e.g., diagonal matrices). Also, the increasing use of compression and new access methods make operator fusion far more challenging than on regular dense matrices.</p><p>Special Value Handling: Most systems ignore the effects of special values such as NaN or INF, which render, for example, sparse linear algebra invalid because 0 • NaN = NaN. The challenge is to support these special values during optimization and runtime without sacrificing performance.</p><p>Integrating Relational and Linear Algebra: A grand challenge is a seamless integration of relational and linear algebra so that users can specify, optimize, and execute ML tasks in a holistic framework, including data transformations for feature engineering such as joins and aggregates, and training and prediction of different ML models, including tasks such as cross-validation and feature selection.</p><p>Seamless Feature Engineering and Model Selection: To simplify end-to-end ML applications, there is a push towards (semi-)automating feature engineering and model selection <ref type="bibr" target="#b64">[64]</ref>. Open questions include abstractions, meta-algorithms, and system architectures for different classes of ML models, including deep learning, which combines feature engineering and learning. An architecture that leverages the progress on individual ML systems could be a feasible and impactful option. Other open questions involve applying and adapting theoretical results from learning theory, optimization, and human-computer interaction.</p><p>ML System Benchmarks: Existing benchmarks for large-scale analytics such as HiBench <ref type="bibr" target="#b51">[51]</ref>, BigBench <ref type="bibr" target="#b13">[13]</ref>, and SparkBench <ref type="bibr" target="#b5">[5]</ref> contain a few ML tasks but only refer to reference implementations of large-scale ML libraries, which makes it hard to compare existing ML systems. There are also existing SQL-centric benchmarks for array databases <ref type="bibr" target="#b95">[95]</ref> and Bayesian ML <ref type="bibr" target="#b20">[20]</ref>, but a broader range of benchmarks would be invaluable for the community at large. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">BIOGRAPHIES</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>SIGMOD' 17 ,</head><label>17</label><figDesc>May 14-19, 2017, Chicago, IL, USA c 2017 ACM. ISBN 978-1-4503-4197-4/17/05. . . $15.00 DOI: http://dx.doi.org/10.1145/3035918.3054775</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Arun</head><label></label><figDesc>Kumar is an Assistant Professor at the University of California, San Diego. He received his Ph.D. from the University of Wisconsin-Madison in 2016. His research interests are in the intersection of data management and ML, with a focus on making ML-based data analytics easier, faster, and more scalable. Ideas from his work have been adopted by many companies, including EMC, Oracle, Cloudera, and Facebook. He is a recipient of the Best Paper Award at SIG-MOD 2014, the 2016 CS dissertation research award from UW-Madison, and a 2016 Google Faculty Research Award. Matthias Boehm is a Research Staff Member at IBM Research -Almaden, where he is working since 2012 on optimization and runtime techniques for declarative, large-scale machine learning in SystemML. He received his Ph.D. from Technische Universitaet Dresden in 2011 with a dissertation on cost-based optimization of integration flows under the supervision of Prof. Wolfgang Lehner. His previous research also includes systems support for time series forecasting as well as in-memory indexing and query processing. In 2016, he received the VLDB Best Paper Award. Jun Yang is a Professor of Computer Science at Duke University, where he has been teaching since receiving his Ph.D. from Stanford University in 2001. He is broadly interested in databases and data-intensive systems. He has been a recipient of the NSF CAREER Award, IBM Faculty Award, HP Labs Innovation Research Award, and Google Faculty Research Award. He also received the David and Janet Vaughan Brooks Teaching Award at Duke. His current research interests lie in making data analysis easier and more scalable for scientists, statisticians, and journalists.</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Apache Mahout. mahout.apache.org</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">Microsoft AzureML Studio. studio.azureml.net</orgName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName><surname>Oracle R Enterprise</surname></persName>
		</author>
		<ptr target="www.oracle.com/technetwork/database/database-technologies/r/r-enterprise" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">TensorFlow: A System for Large-Scale Machine Learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OSDI</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">SparkBench -A Spark Performance Testing Suite</title>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TPCTC</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The Case for Predictive Database Systems: Opportunities and Challenges</title>
		<author>
			<persName><forename type="first">M</forename><surname>Akdere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Implicit Parallelism through Deep Language Embedding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Alexandrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Input Selection for Fast Feature Engineering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cafarella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Brainwash: A Data System for Feature Engineering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Introduction to spark 2.0 for database researchers</title>
		<author>
			<persName><forename type="first">M</forename><surname>Armbrust</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On Optimizing Machine Learning Workloads via Kernel Fusion</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ashari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PPoPP</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">MacroBase: Prioritizing Attention in Fast Data</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bailis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Discussion of BigBench: A Proposed Industry Standard Performance Benchmark for Big Data</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Baru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TPCTC</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Theano: a CPU and GPU Math Expression Compiler</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SciPy</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Hybrid Parallelization Strategies for Large-Scale Machine Learning in SystemML</title>
		<author>
			<persName><forename type="first">M</forename><surname>Boehm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">SystemML&apos;s Optimizer: Plan Generation for Large-Scale Machine Learning Programs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Boehm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Eng. Bull</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Boehm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Declarative Machine Learning on Spark. PVLDB</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">13</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Declarative Systems for Large-Scale Machine Learning</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Borkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Eng. Bull</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Simulation of Database-valued Markov Chains Using SimSQL</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A Comparison of Platforms for Implementing and Running Very Large Scale Machine Learning Algorithms</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Towards Linear Algebra over Normalized Data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<idno>CoRR, abs/1612.07448</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">GLADE: Big Data Analytics Made Easy</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Dolphin: Runtime Optimization for Distributed Machine Learning</title>
		<author>
			<persName><forename type="first">B.-G</forename><surname>Chun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Workshop MLSystems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">MAD Skills: New Analysis Practices for Big Data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Torch7: A Matlab-like Environment for Machine Learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop BigLearn</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Machine Learning for Big Data</title>
		<author>
			<persName><forename type="first">T</forename><surname>Condie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The Missing Piece in Complex Analytics: Low Latency, Scalable Model Management and Serving with Velox</title>
		<author>
			<persName><forename type="first">D</forename><surname>Crankshaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Clipper: A Low-Latency Online Prediction Serving System</title>
		<author>
			<persName><forename type="first">D</forename><surname>Crankshaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSDI</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">An Architecture for Compiling UDF-centric Workflows</title>
		<author>
			<persName><forename type="first">A</forename><surname>Crotty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Vizdom: Interactive Analytics through Pen and Touch</title>
		<author>
			<persName><forename type="first">A</forename><surname>Crotty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">DeepDive: Declarative Knowledge Base Construction</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">De</forename><surname>Sa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">MauveDB: Supporting Model-based User Views in Database Systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Deshpande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A Few Useful Things to Know About Machine Learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM CACM</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Processing Forecasting Queries</title>
		<author>
			<persName><forename type="first">S</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">SPOOF: Sum-Product Optimization and Operator Fusion for Large-Scale Machine Learning</title>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>CIDR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Compressed Linear Algebra for Large-Scale Machine Learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Elgohary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Spinning Fast Iterative Data Flows</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ewen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Towards a Unified Architecture for in-RDBMS Analytics</title>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Forecasting in Database Systems</title>
		<author>
			<persName><forename type="first">U</forename><surname>Fischer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
		<respStmt>
			<orgName>Technische Universitaet Dresden</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The BUDS Language for Distributed Bayesian Machine Learning</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">J</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A Skip-list Approach for Efficiently Processing Forecasting Queries</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Zdonik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Introduction to Statistical Relational Learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Taskar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Asynchronous Complex Analytics in a Distributed Dataflow Architecture</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Feature Extraction: Foundations and Applications</title>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">The Elements of Statistical Learning: Data mining, Inference, and Prediction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The MADlib Analytics Library or MAD Skills, the SQL</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Starfish: A Self-tuning System for Big Data Analytics</title>
		<author>
			<persName><forename type="first">H</forename><surname>Herodotou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Cumulon: Optimizing Statistical Data Analysis in the Cloud</title>
		<author>
			<persName><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Cumulon: Matrix-Based Data Analytics in the Cloud with Spot Instances</title>
		<author>
			<persName><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Resource Elasticity for Large-Scale Machine Learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">The HiBench Benchmark Suite: Characterization of the MapReduce-Based Data Analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE Workshop WISS</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Caffe: Convolutional Architecture for Fast Feature Embedding</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Ava: From Data to Insights Through Conversation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J L</forename><surname>John</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">SLACID -Sparse Linear Algebra in a Column-Oriented In-Memory Database System</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kernert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SSDBM</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">SpMacho -Optimizing Sparse Linear Algebra Expressions with Probabilistic Density Estimation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kernert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EDBT</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Topology-Aware Optimization of Big Sparse Matrices and Matrix Multiplications on Main-Memory Systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kernert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">FAQ: Questions Asked Frequently</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Khamis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PODS</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">TensorDB and Tensor-Relational Model (TRM) for Efficient Tensor-Relational Operations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
		<respStmt>
			<orgName>Arizona State University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Incrementally maintaining classification using an RDBMS</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Koc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">MLbase: A Distributed Machine-learning System</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kraska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">ActiveClean: Interactive Data Cleaning For Statistical Modeling</title>
		<author>
			<persName><forename type="first">S</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Demonstration of Santoku: Optimizing Machine Learning over Normalized Data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Learning Generalized Linear Models Over Normalized Data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Model Selection Management Systems: The Next Frontier of Advanced Analytics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGMOD Record</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">To Join or Not to Join? Thinking Twice about Joins before Feature Selection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Deep Learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Distributed GraphLab: A Framework for Machine Learning in the Cloud</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Low</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">WiSeDB: A Learning-based Workload Management Advisor for Cloud Databases</title>
		<author>
			<persName><forename type="first">R</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Papaemmanouil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">ERACER: A Database Approach for Statistical Inference and Data Cleaning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mayfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">MLlib: Machine Learning in Apache Spark</title>
		<author>
			<persName><forename type="first">X</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">ModelHub: Towards Unified Data and Lifecycle Management for Deep Learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Miao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Towards Resource-Elastic Machine Learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Narayanamurthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop BigLearn</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">LINVIEW: Incremental View Maintenance for Complex Analytical Queries</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nikolic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Hogwild!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent</title>
		<author>
			<persName><forename type="first">F</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Tuffy: Scaling up Statistical Inference in Markov Logic Networks using an RDBMS</title>
		<author>
			<persName><forename type="first">F</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">One-pass Data Mining Algorithms in a DBMS with UDFs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ordonez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Hemingway: Modeling Distributed Optimization Algorithms</title>
		<author>
			<persName><forename type="first">X</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop MLSystems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">The TileDB Array Data Storage Manager</title>
		<author>
			<persName><forename type="first">S</forename><surname>Papadopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">On Predictive Modeling for Optimizing Transaction Execution in Parallel OLTP Systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pavlo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Self-Driving Database Management Systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pavlo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Large-scale Predictive Analytics in Vertica: Fast Data Transfer, Distributed Model Creation, and In-database Prediction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Prasad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Speculative Approximations for Terascale Distributed Gradient Descent Optimization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rusu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD DanaC</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Feature Engineering for Knowledge Base Construction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Eng. Bull</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Scaling Factorization Machines to Relational Data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">All Roads Lead to Rome</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schelter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Optimistic Recovery for Distributed Iterative Data Processing</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>CIKM</note>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Schelter</surname></persName>
		</author>
		<title level="m">Samsara: Declarative Machine Learning on Distributed Dataflow Systems. NIPS Workshop MLSystems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Learning Linear Regression Models over Factorized Joins</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schleich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Incremental Knowledge Base Construction Using DeepDive</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Active and Accelerated Learning of Cost Models for Optimizing Scientific Applications</title>
		<author>
			<persName><forename type="first">P</forename><surname>Shivam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">ArrayStore: A Storage Manager for Complex Parallel Array Processing</title>
		<author>
			<persName><forename type="first">E</forename><surname>Soroush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Automating Model Search for Large Scale Machine Learning</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Sparks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SoCC</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">KeystoneML: Optimizing Pipelines for Large-Scale Advanced Analytics</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Sparks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">The Architecture of SciDB</title>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SSDBM</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">OptiML: An Implicitly Parallel Domain-Specific Language for Machine Learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Sujeeth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">GenBase: A Complex Analytics Genomics Benchmark</title>
		<author>
			<persName><forename type="first">R</forename><surname>Taft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Auto-WEKA: Combined Selection and Hyperparameter Optimization of Classification Algorithms</title>
		<author>
			<persName><forename type="first">C</forename><surname>Thornton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Supporting Fast Iteration in Model Building</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vartak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop LearningSys</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">MODELDB: A System for Machine Learning Model Management</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vartak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD Workshop HILDA</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">SparkR: Scaling R Programs with Spark</title>
		<author>
			<persName><forename type="first">S</forename><surname>Venkataraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">ATLAS: A Small but Complete SQL Extension for Data Mining and Data Streams</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Database Meets Deep Learning: Challenges and Opportunities</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Extending Database Task Schedulers for Multi-threaded Application Code</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SSDBM</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Big Graph Analytics Systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Big R: Large-Scale Analytics on Hadoop Using R</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">D L</forename><surname>Yejas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Big Data</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Materialization Optimizations for Feature Selection Workloads</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Towards High-throughput Gibbs Sampling at Scale: A Study Across Storage Managers</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">DimmWitted: A Study of Main-Memory Statistical Analytics</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Measuring and Optimizing Distributed Array Programs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">RIOT: I/O-Efficient Numerical Computing without SQL</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Storing Matrices on Disk: Theory and Practice Revisited</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Optimizing I/O for Big Array Analytics</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
