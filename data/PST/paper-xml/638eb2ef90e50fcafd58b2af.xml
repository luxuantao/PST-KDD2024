<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Retrieval as Attention: End-to-end Learning of Retrieval and Reading within a Single Transformer</title>
				<funder>
					<orgName type="full">Bosch Research</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhengbao</forename><surname>Jiang</surname></persName>
							<email>zhengbaj@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University ? Bosch Research North America</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Luyu</forename><surname>Gao</surname></persName>
							<email>luyug@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University ? Bosch Research North America</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jun</forename><surname>Araki</surname></persName>
							<email>jun.araki@us.bosch.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University ? Bosch Research North America</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Haibo</forename><surname>Ding</surname></persName>
							<email>haibo.ding@us.bosch.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University ? Bosch Research North America</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhiruo</forename><surname>Wang</surname></persName>
							<email>zhiruow@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University ? Bosch Research North America</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jamie</forename><surname>Callan</surname></persName>
							<email>callan@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University ? Bosch Research North America</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
							<email>gneubig@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University ? Bosch Research North America</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Retrieval as Attention: End-to-end Learning of Retrieval and Reading within a Single Transformer</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Systems for knowledge-intensive tasks such as open-domain question answering (QA) usually consist of two stages: efficient retrieval of relevant documents from a large corpus and detailed reading of the selected documents to generate answers. Retrievers and readers are usually modeled separately, which necessitates a cumbersome implementation and is hard to train and adapt in an end-to-end fashion. In this paper, we revisit this design and eschew the separate architecture and training in favor of a single Transformer that performs Retrieval as Attention (ReAtt), and end-toend training solely based on supervision from the end QA task. We demonstrate for the first time that a single model trained end-toend can achieve both competitive retrieval and QA performance, matching or slightly outperforming state-of-the-art separately trained retrievers and readers. Moreover, end-to-end adaptation significantly boosts its performance on out-of-domain datasets in both supervised and unsupervised settings, making our model a simple and adaptable solution for knowledgeintensive tasks. Code and models are available at https://github.com/jzbjyb/ReAtt.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Knowledge-intensive tasks such as question answering (QA), fact checking, and dialogue generation require models to gather relevant information from potentially enormous knowledge corpora (e.g., Wikipedia) and generate answers based on gathered evidence. A widely used solution is to first retrieve a small number of relevant documents from the corpus with a bi-encoder architecture which encodes queries and documents independently for efficiency purposes, then read the retrieved documents in a more careful and expansive way with a cross-encoder architecture which encodes queries and documents jointly <ref type="bibr" target="#b22">(Lee et al., 2019;</ref><ref type="bibr" target="#b8">Guu et al., 2020;</ref><ref type="bibr">Lewis et al., 2020;</ref><ref type="bibr" target="#b13">Izacard et al., 2022)</ref>. The distinction between retrieval and reading leads to the widely adopted paradigm of treating retrievers and readers separately. Retrievers and readers are usually two separate models with heterogeneous architectures and different training recipes, which is cumbersome to train. Even though two models can be combined in an ad-hoc way for downstream tasks, it hinders effective end-to-end learning and adaptation to new domains.</p><p>There have been several attempts to connect up reader and retriever training <ref type="bibr" target="#b22">(Lee et al., 2019;</ref><ref type="bibr" target="#b8">Guu et al., 2020;</ref><ref type="bibr">Lewis et al., 2020;</ref><ref type="bibr" target="#b33">Sachan et al., 2021;</ref><ref type="bibr">Lee et al., 2021a;</ref><ref type="bibr" target="#b13">Izacard et al., 2022)</ref>. However, retrievers in these works are not learned in a fully end-to-end way. They require either initialization from existing supervisedly trained dense retrievers <ref type="bibr">(Lewis et al., 2020)</ref>, or expensive unsupervised retrieval pretraining as warm-up <ref type="bibr" target="#b22">(Lee et al., 2019;</ref><ref type="bibr" target="#b8">Guu et al., 2020;</ref><ref type="bibr" target="#b33">Sachan et al., 2021;</ref><ref type="bibr">Lee et al., 2021a;</ref><ref type="bibr" target="#b13">Izacard et al., 2022)</ref>. The reliance on retrieval-specific warm-up and the ad-hoc combination of retrievers and readers makes them less of a unified solution and potentially hinders their domain adaptation ability. With the ultimate goal of facilitating downstream tasks, retriever and reader should instead be fused more organically and learned in a fully end-to-end way.</p><p>In this paper, we focus on one of the most important knowledge-intensive tasks, open-domain QA. We ask the following question: is it possible to perform both retrieval and reading within a single Transformer model, and train the model in a fully end-to-end fashion to achieve competitive performance from both perspectives? Such a single-model end-to-end solution eliminates the need for retrieval-specific annotation and warm-up and simplifies retrieval-augmented training, making adaptation to new domains easier. Based on the analogy between self-attention which relates dif-ferent tokens in a single sequence <ref type="bibr" target="#b37">(Vaswani et al., 2017)</ref> and the goal of retrieval which is to relate queries with relevant documents, we hypothesize that self-attention could be a natural fit for retrieval, and it allows an organic fusion of retriever and reader within a single Transformer. Specifically, we start from a encode-decoder T5 <ref type="bibr" target="#b31">(Raffel et al., 2020)</ref> and use it as both retriever and reader. We use the first B encoder layers as bi-encoder to encode queries and documents independently, and the attention score at layer B + 1 (denoted as retrieval attention) to compute relevance scores, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. We found that directly using self-attention for retrieval underperforms strong retrievers, which we conjecture is because self-attention pretrained on local context is not sufficient to identify relevant information in the large representation space of the whole corpus. To solve this, we propose to compute retrieval attention between a query and a large number of documents and adjust the retrieval attention across documents. For each query, we compute retrieval attention over both close documents that potentially contain positive and hard negative documents, and documents of other queries in the same batch as random negatives. The retrieval attention is adjusted by minimizing its discrepancy from the cross-attention between the decoder and encoder (denoted as target attention), which is indicative of the usefulness of each document in generating answers <ref type="bibr">(Izacard and Grave, 2021a)</ref>. The resulting Retrieval as Attention model (ReAtt) is a single T5 trained based on only QA annotations and simultaneously learns to promote useful documents through cross-document adjustment.</p><p>We train ReAtt on Natural Questions dataset (NQ) <ref type="bibr" target="#b19">(Kwiatkowski et al., 2019)</ref> in a fully end-toend manner. It achieves both competitive retrieval and QA performance, matching or slightly outperforming state-of-the-art retriever ColBERT-NQ <ref type="bibr">(Khattab et al., 2020)</ref> trained with explicit retrieval annotations and strong QA model FiD <ref type="bibr">(Izacard and Grave, 2021b,a)</ref>, demonstrating for the first time end-to-end training can produce competitive retriever and reader within a single model. To further test ReAtt's generalization and end-to-end adaptation ability, we conduct zero-shot, supervised, and unsupervised adaptation experiments on 7 datasets from the BEIR benchmark <ref type="bibr">(Thakur et al., 2021)</ref>. In all settings, end-to-end adaptation improves the retrieval performance usually by a large margin, with the first B=2 encoder layers as bi-encoder (i.e., retriever) and the rest L-B=2 layers as cross-encoder.</p><p>During training, the retrieval attention between a query q 1 and documents d 11,12,13 is adjusted by minimizing its discrepancy from the target attention. For simplicity, we use a single arrow to represent attention of a single head between multiple tokens.</p><p>achieving comparable or superior performance to strong retrieval adaptation and pretraining methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Retrieval as Attention (ReAtt)</head><p>With the goal of developing a single Transformer that can perform both retrieval and reading, and the analogy between retrieval and self-attention, we first introduce architecture changes to allow retrieval as attention ( ? 2.2), then examine how well attention as-is can be directly used to perform retrieval ( ? 2.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Formal Definition</head><p>We first briefly define the task of retrieval and question answering. As mentioned in the introduction, queries and documents need to be represented independently for efficient retrieval which implies a bi-encoder architecture that has no interaction between queries and documents. Without loss of generality, we use E d = biencoder(d) to denote one or multiple representations generated by a bi-encoder based on a document from a corpus d ? D, and likewise E q = biencoder(q) to denote query representations. <ref type="foot" target="#foot_0">1</ref> The top-k documents most relevant to a query are retrieved by D ret q = arg topk d?D r(E q , E d ), where function r computes relevance based on query and document representations which can be as simple as a dot product if queries and documents are encoded into a single vector, and D ret q stands for the returned documents. We consider encoder-decoder-based generative question answering in this paper, which jointly represents queries and retrieved documents with the encoder E q,d = crossencoder(q, d), and generates the answer a autoregressively with the decoder P gen (a|q, d) = P gen (a|E q,d ). To handle multiple retrieved documents, we follow the fusion-in-decoder model (FiD) <ref type="bibr">(Izacard and Grave, 2021b)</ref> which encodes each query-document pair independently and fuse these representations in decoder through cross-attention P gen (a|q, D ret q ) = P gen (a|E q,d 1 , ..., E q,d |D ret q | ). Negative log likelihood (NLL) is used in optimization L QA = -log P gen (a|q, D ret q ). 2.2 Leveraging Attention for Retrieval Next, we introduce our method that directly uses self-attention between queries and documents as retrieval scores.</p><p>Putting the Retriever into Transformers As illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>, we choose T5 <ref type="bibr" target="#b31">(Raffel et al., 2020)</ref> as our base model, use the first B layers of the encoder as the bi-encoder "retriever" by disabling self-attention between queries and documents, and the remaining L -B layers as the crossencoder "reader". We use the self-attention paid from query tokens to document tokens at the B + 1th layer as the retrieval score, which is denoted as retrieval attention (green arrows in Fig. <ref type="figure" target="#fig_0">1</ref>). It is computed based on the independent query and document contextual representations from the last (Bth) layer of the bi-encoder (green blocks in Fig. <ref type="figure" target="#fig_0">1</ref>). Formally for an H-head Transformer, document and query representations are:</p><formula xml:id="formula_0">E d = {K B+1,h d ? R |d|?e } H h=1 , E q = {Q B+1,h q ? R |q|?e } H h=1 ,</formula><p>where K and Q are key and query vectors of the token sequence used in self-attention, |d| and |q| are document and query length, and e is the dimensionality of each head. The retrieval attention matrix from query tokens to document before softmax for one head is computed by:</p><formula xml:id="formula_1">A B+1,h q,d = Q B+1,h q ? K B+1,h d T ? R |q|?|d| .</formula><p>Directly using attention for retrieval can not only leverage its ability to identify relatedness, it is also a natural and simple way to achieve both retrieval and reading in a single Transformer with minimal architectural changes, which facilitates our final goal of end-to-end learning.</p><p>From Token Attention to Document Relevance Given the token-level attention scores A B+1,h q,d , the relevance between q and d is computed by avg-max aggregation: choosing the most relevant document token for each query token (i.e., max) then averaging across query tokens:</p><formula xml:id="formula_2">r h (q, d) = avg 0 max 1 (A B+1,h q,d ) ,<label>(1)</label></formula><p>where 1 and 0 refer to the dimension over which the operation is applied. This is similar to the MaxSim and sum operators used in ColBERT <ref type="bibr">(Khattab and Zaharia, 2020)</ref>, with the intuition that a relevant document should match as many query tokens as possible with the best-matching token. The final relevance is a weighted sum over all heads:</p><formula xml:id="formula_3">r(q, d) = H h=1 P head h ? r h (q, d),</formula><p>where P h is a learnable weight that sums to one.</p><p>As explained in the next section, we empirically find only a few attention heads with non-random retrieval performance, and among them one particular head is significantly better than the others. Given this observation, we introduce a low temperature ? to promote this sparsity P head h = exp(w h /? ) h exp(w h /? ) , which always ends with a single head with the great majority of the weight, which is denoted as retrieval head h * . As a result, the learned head weights are practically a head selector, a fact that can also be exploited to make test-time retrieval more efficient.</p><p>End-to-end Retrieval with Attention To perform retrieval over a corpus, we first generate key vectors K B+1,h * d of retrieval head for all document tokens offline and index them with FAISS library <ref type="bibr" target="#b14">(Johnson et al., 2021)</ref>. For each query token, we issue its vector (Q B+1,h * q ) to the index to retrieve top-K document tokens, which yields a filtered set of documents, each of which has at least one token retrieved by a query token. We then fetch all tokens of filtered documents, compute relevance scores following Eq. 1, and return top-K documents with the highest scores r h * (q, d). This is similar to the two-stage retrieval in ColBERT <ref type="bibr">(Khattab and Zaharia, 2020)</ref>, and we reuse their successful practice Figure 2: Illustration of approximate attention over the corpus with |Q|=4 queries in a batch and K=3 close documents per query. We use q 1 as an example to illustrate the required computation, where close documents require both retrieval and target attention while random documents only require retrieval attention.</p><p>in index compression and search approximation to make test-time retrieval efficient, which we refer to <ref type="bibr" target="#b35">Santhanam et al. (2021)</ref> for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">How Good is Attention As-is?</head><p>To examine this question, we use T5-large and test queries from the Natural Question dataset (NQ), retrieve 100 documents with BM25, compute relevance scores r h (q, d) with half layers (B = 12) as bi-encoder, and measure its correlation with the gold binary annotation. We found that among H = 24 heads, 4 heads have non-trivial correlations of 0.137, 0.097, 0.082, and 0.059. We further perform end-to-end retrieval over Wikipedia using the best head, achieving top-10 retrieval accuracy of 43.5%, inferior to 55.5% of BM25. This demonstrates that there are indeed heads that can relate queries with relevant documents, but they are not competitive. We hypothesize that because self-attention is usually trained by comparing and relating tokens in a local context (512/1024 tokens) it cannot effectively identify relevant tokens in the enormous representation space of a corpus with millions of documents. This discrepancy motivates us to compute retrieval attention between queries and potentially all documents (i.e., attention over the corpus), and adjust attention across documents to promote useful ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Learning Retrieval as Attention</head><p>We first approximate attention over the corpus at training time by sub-sampling a manageable number of documents for each query containing both potentially relevant and random documents ( ? 3.1). Next, we introduce our end-to-end training objective that optimizes a standard QA loss while also adding supervision to promote attention over documents that are useful for the end task ( ? 3.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Approximate Attention over the Corpus</head><p>Encoding the entire corpus and computing attention between the query and all documents is very expensive. To make it practical, we propose to subsample a small set of documents for each query to approximate the whole corpus. Inspired by negative sampling methods used in dense retriever training <ref type="bibr" target="#b15">(Karpukhin et al., 2020;</ref><ref type="bibr" target="#b43">Xiong et al., 2021;</ref><ref type="bibr">Khattab and Zaharia, 2020)</ref>, we sub-sample both (1) documents close to queries that can be either relevant or hard negatives, and (2) random documents that are most likely to be easy negatives. This allows the model to distinguish between relevant and hard negative documents, while simultaneously preventing it from losing its ability to distinguish easy negatives, which form the majority of the corpus.</p><p>Iterative Close Document Sub-sampling To sample documents close to a query D close q , we start from widely used lexical retriever BM25 <ref type="bibr" target="#b32">(Robertson and Zaragoza, 2009)</ref> to retrieve K = 100 documents, as shown by the orange blocks in Fig. <ref type="figure">2</ref>. We set K to a relatively large number to better approximate the local region, inspired by Izacard and Grave (2021b)'s findings that QA performance increases as more documents are used.</p><p>This fixed set of close documents can become outdated and no longer close to the query anymore as the retrieval attention gets better. To provide dynamic close sub-samples, we re-index the corpus and retrieve a new set of K documents using the current retrieval attention after each iteration. It is similar in spirit to the hard negative mining methods used in <ref type="bibr" target="#b15">Karpukhin et al. (2020)</ref>; <ref type="bibr">Khattab et al. (2020)</ref>, with a major difference that we do not manually or heuristically annotate documents but instead learn from the end loss with cross-document adjustment, which will be explained in ? 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>In-batch Random Document Sub-sampling</head><p>We use close documents of other queries in the same batch as the random documents of the current query D random q = ? q ?Q?q =q D close q where Q contains all queries in a batch, as shown by the green blocks in Fig. <ref type="figure">2</ref>, which has the advantage of reusing document representations across queries. This is similar to the in-batch negatives used in DPR <ref type="bibr" target="#b15">(Karpukhin et al., 2020)</ref> with a major difference that we reuse a token representations (K B+1,h d , 1 ? h ? H) across queries instead of a single-vector document representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Cross-document Adjustment with</head><p>Decoder-to-Encoder Attention Distillation Given the sub-sampled |Q| ? K documents D q = D close q ? D random q for each query q, we compute the retrieval attention-based relevance scores r(q, d) and adjust them across multiple documents d ? D q only relying on end task supervision. Since retrieval is simply a means to achieve the downstream task, documents useful for downstream tasks should be promoted by retrieval. Inspired by reader-to-retriever distillation <ref type="bibr">(Izacard and Grave, 2021a;</ref><ref type="bibr" target="#b44">Yang and Seo, 2020)</ref>, we measure document usefulness based on cross-attention between decoder and encoder, and minimize retrieval attention's discrepancy from it through distillation. In contrast to Izacard and Grave (2021a) that learns two models iteratively and alternatively, we optimize QA and distillation loss in a single model simultaneously.</p><p>Minimizing KL-divergence Between Retrieval and Target Attention Specifically, we denote cross-attention before softmax of the first position/token of the last decoder layer as target attention C a,q,Dq ? R H?|Dq|?(|d|+|q|) where a is the answer, |D q | is the number of sub-sampled documents to be fused by the decoder ( ? 2.1), and |d| is document length. <ref type="foot" target="#foot_1">2</ref> To aggregate tokenlevel target attention into document-level distribution P tgt (a, q, D q ) ? R |Dq| , we first perform softmax over all tokens in all query-document pairs (|D q | ? (|d| + |q|)), sum over tokens of each querydocument pair (|d| + |q|), then average across multiple heads (H):</p><p>P tgt (a, q, D q ) = avg 0 sum 2 softmax 1,2 (C a,q,Dq ) .</p><p>Given relevance scores obtained from retrieval attention, the final cross-document adjustment loss is the KL-divergence between relevance distribution P ret and target distribution P tgt : P ret (q, Dq) = softmax r(q, d1), ..., r(q, d |Dq | ) .</p><p>Lcross-doc = KL P tgt (a, q, Dq) P ret (q, Dq) ,</p><p>(2)</p><p>where the overline indicates stop gradient back propagation to target distributions. Our final loss combines QA loss and cross-document adjustment loss with ? as combination weight.</p><formula xml:id="formula_4">L = L QA + ? ? L cross-doc .</formula><p>(3)</p><p>Zero Target Attention for Random Documents For a batch with |Q| queries, we need to compute retrieval attention and target attention between |Q| ? |Q| ? K query-document pairs. This is both computation-and memory-intensive when batch size is large, especially for target attention because it requires L -B layers of joint encoding of querydocument pairs in the cross-encoder. To alleviate this, we make a simple and effective assumption that in-batch random documents are not relevant to the current query thus having zero target attention:</p><formula xml:id="formula_5">P tgt (a, q, D random q ) ? R |D random q | ? 0.</formula><p>As a result, we only need to run cross-encoder and decoder for K close documents of each query, as shown in Fig. <ref type="figure">2</ref>. In Appendix A we will introduce our efficient implementation to make it possible to run a large batch size over a limited number of GPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Domain Adaptation Methods</head><p>One of the major benefits of a single end-to-end trainable model is that given a new corpus from a new domain, possibly without retrieval annotations, we can easily adapt it by end-to-end training. This section describes how we adapt ReAtt under different setups.</p><p>We consider adapting ReAtt with (1) QA supervision, (2) information retrieval (IR) supervision, or (3) unsupervised adaptation where we only have access to the document corpus. Although our goal is to learn retrieval through downstream tasks instead of retrieval supervision, being able to consume retrieval annotations is helpful when retrieval supervision is indeed available. To do so, we convert retrieval task with annotations in the form of query-document-relevance triples q, d, l into a generative task: given a query, the target is to generate its relevant document and the corresponding relevance with the following format "relevance: l. d". If a query has multiple relevant documents, we follow <ref type="bibr">Izacard and Grave (2021b)</ref> to randomly sample one of them. For unsupervised adaptation, with simplicity as our primary goal, we randomly choose one sentence from a document and mask one entity, which is considered as the "query", and have our model generate the masked entity as the "answer", similar to salient span masking (SSM) used in <ref type="bibr" target="#b8">Guu et al. (2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">In-domain Experiments</head><p>In this section, we examine if supervisedly training ReAtt end-to-end with only QA supervision yields both competitive retrieval and QA performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets, Baselines, and Metrics</head><p>We train our model using the Natural Questions dataset (NQ). We compare retrieval performance with lexical models BM25 <ref type="bibr" target="#b32">(Robertson and Zaragoza, 2009)</ref>, passage-level dense retrievers DPR, ANCE, coCondenser, FiD-KD, YONO (with and without retrieval pretraining) <ref type="bibr" target="#b15">(Karpukhin et al., 2020;</ref><ref type="bibr" target="#b28">Oguz et al., 2021;</ref><ref type="bibr" target="#b43">Xiong et al., 2021;</ref><ref type="bibr" target="#b5">Gao and Callan, 2022;</ref><ref type="bibr">Izacard and Grave, 2021a;</ref><ref type="bibr">Lee et al., 2021a)</ref>, and token/phrase-level dense retrievers DensePhrase, ColBERT, ColBERT-NQ <ref type="bibr">(Lee et al., 2021b;</ref><ref type="bibr">Khattab and Zaharia, 2020;</ref><ref type="bibr">Khattab et al., 2020)</ref>. 3 Among them ColBERT-NQ, FiD-KD and YONO are the most fair-to-compare baselines because of either similar token-level retrieval granularity (ColBERT-NQ) or similar end-to-end training settings (FiD-KD and YONO). We report top-k retrieval accuracy (R@k), the fraction of queries with at least one retrieved document containing answers. We compare QA performance with ORQA, REALM, RAG, FiD, EMDR 2 , YONO, UnitedQA, and R2-D2 <ref type="bibr" target="#b22">(Lee et al., 2019;</ref><ref type="bibr" target="#b8">Guu et al., 2020;</ref><ref type="bibr">Lewis et al., 2020;</ref><ref type="bibr">Izacard and Grave, 2021b,a;</ref><ref type="bibr" target="#b33">Sachan et al., 2021;</ref><ref type="bibr">Lee et al., 2021a;</ref><ref type="bibr" target="#b1">Cheng et al., 2021;</ref><ref type="bibr" target="#b3">Fajcik et al., 2021)</ref> using exact match (EM), among which FiD, EMDR 2 , and YONO are the most fair-to-compare baselines because they have similar model sizes and training settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Implementation Details of ReAtt</head><p>ReAtt is based on T5-large with B = 12 encoder layers as bi-encoder and temperatures ? = 0.001 to select the best retrieval head. We retrieve K = 100 close documents for each query, and use a batch size of |Q| = 64 queries to obtain in-batch random documents. We use ? = 8 to combine crossdocument adjustment loss with QA loss. We use AdamW with a learning rate of 5e-5, 10% steps of warmup, and linear decay. We first warmup crossattention's ability to distinguish documents by only using the QA loss for 3K steps, then train with the combined losses (Eq. 3) for 4 iterations, where the first iteration uses close documents returned by BM25, and the following 3 iterations use close documents returned by the previous ReAtt model (denoted as ReAtt BM25 ). Each iteration has 8K update steps and takes ? 1.5 days on a single node with 8 ? A100 GPUs with 80GB memory. Since DPR <ref type="bibr" target="#b15">(Karpukhin et al., 2020)</ref> achieves stronger performance than BM25, training with close doc-3 ColBERT is trained on MS MARCO, ColBERT-NQ is on NQ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><p>R@1 R@5 R@20 R@100 #Params.</p><p>supervised retrievers BM25 23.9 45.9 At test-time, we save key vectors of all tokens in the corpus and use exact index from FAISS (i.e., faiss.IndexFlatIP) to perform inner-product search. We retrieve K = 2048 document tokens for each query token and return top-100 documents with the highest aggregated scores (Eq. 1) to generate answers. We found compressing index with clustering and quantization proposed by <ref type="bibr" target="#b35">Santhanam et al. (2021)</ref> can greatly reduce search latency and index size with a minor retrieval accuracy loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Overall Results</head><p>We compare ReAtt with various retrievers and readers in Tab. 1 and Tab. 2. ReAtt achieves both slightly better retrieval performance than the strongest retriever baseline ColBERT-NQ <ref type="bibr">(Khattab et al., 2020)</ref> and comparable QA performance than the strong reader baseline FiD-KD <ref type="bibr">(Izacard and Grave, 2021a)</ref> on NQ, demonstrating for the first time that fully end-to-end training using QA supervision can produce both competitive retrieval and QA performance. Compared to another singlemodel architecture YONO <ref type="bibr">(Lee et al., 2021a)</ref>, ReAtt offers better performance without cumbersome pretraining to warm-up retrieval. ORQA <ref type="bibr" target="#b22">(Lee et al., 2019)</ref> 33.3 330M REALM <ref type="bibr" target="#b8">(Guu et al., 2020)</ref> 40.4 330M RAG <ref type="bibr">(Lewis et al., 2020)</ref> 44.5 220M FiD <ref type="bibr">(Izacard and Grave, 2021b)</ref> 51.4 990M FiD-KD <ref type="bibr">(Izacard and Grave, 2021a)</ref>   <ref type="bibr">(Lee et al., 2021a)</ref> 42.4 440M YONOw/ PT <ref type="bibr">(Lee et al., 2021a)</ref> 53.2 440M UnitedQA <ref type="bibr" target="#b1">(Cheng et al., 2021)</ref> 54.7 1.870B R2-D2 <ref type="bibr" target="#b3">(Fajcik et al., 2021)</ref> 55.9 1.290B ReAtt DPR 54.0 770M ReAtt BM25 54.7 770M</p><p>Table <ref type="table">2</ref>: QA performance on NQ. PT is retrieval pretraining. Fair-to-compare baselines are highlighted. Best performance is in bold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Ablations</head><p>We perform ablation experiments to understand the contribution of each component. Due to resource limitations, all ablations are trained with 2K steps per iteration. We use ReAtt trained with B=12 bi-encoder layers, |Q|=16 batch size, and ?=8 cross-document loss weight as the baseline, remove one component or modify one hyperparameter at a time to investigate its effect. As shown in Tab. 3, we found: 1. Only using QA loss without cross-document adjustment (#2) improves retrieval performance over the original T5 (#3), but cross-document adjustment is necessary to achieve further improvement (#1). 2. Iteratively retrieving close documents with the current model is helpful (#5 vs #1). 3. In-batch random documents are beneficial (#4 vs #1), and a larger batch size leads to larger improvements (#8-11). 4. A larger weight on cross-document adjustment loss improves retrieval performance but hurts QA performance, with 4?8 achieving a good trade-off (#12-15). 5. A small number of bi-encoder layers (#6) significantly hurts retrieval while a large number of layers (#7) significantly hurts QA, suggesting choosing equal numbers of layers in bi-encoder and cross-encoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Out-of-domain Generalization and Adaptation</head><p>In this section, we examine both zero-shot retrieval performance on out-of-domain datasets and ReAtt's end-to-end adaptability in supervised (QA, IR) and unsupervised settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Datasets, Baselines, and Metrics</head><p>We choose 7 datasets from BEIR <ref type="bibr">(Thakur et al., 2021)</ref>, a benchmark covering diverse domains and tasks. On each dataset we compare ReAtt with different types of retrievers including BM25, DPR, and ColBERT. We consider 2 QA datasets (BioASQ and FiQA <ref type="bibr" target="#b36">(Tsatsaronis et al., 2015;</ref><ref type="bibr" target="#b25">Maia et al., 2018)</ref>) and one IR dataset (MS MARCO <ref type="bibr" target="#b26">(Nguyen et al., 2016)</ref>) to evaluate supervised adaptation capability, and 4 other datasets (CQADupStack, TREC-COVID, SCIDOCS, Sci-Fact <ref type="bibr" target="#b9">(Hoogeveen et al., 2015;</ref><ref type="bibr" target="#b38">Voorhees et al., 2020;</ref><ref type="bibr" target="#b2">Cohan et al., 2020;</ref><ref type="bibr" target="#b39">Wadden et al., 2020)</ref>) to evaluate unsupervised adaptation capability. Detailed statistics are listed in Tab. 8. We report nDCG@10 to measure retrieval performance and EM to measure QA performance. We group all baselines into three categories and denote them with different colors in the following tables:</p><formula xml:id="formula_6"># Methods R@1 R@5 R@20 R@</formula><p>? Supervised adaptation models are trained with downstream task supervision, including RAG trained on BioASQ, Contriever fine-tuned on FiQA, and docT5query, ANCE, ColBERT, and Contriever fine-tuned on MS MARCO <ref type="bibr" target="#b27">(Nogueira and Lin, 2019;</ref><ref type="bibr" target="#b43">Xiong et al., 2021;</ref><ref type="bibr">Khattab and Zaharia, 2020;</ref><ref type="bibr">Izacard et al., 2021)</ref>. ? Unsupervised adaptation models are trained on domain corpus in an unsupervised way such as contrastive learning or pseudo query generation, including SimCSE and TSDAE+GPL <ref type="bibr">(Gao et al., 2021c;</ref><ref type="bibr">Wang et al., 2021a,b)</ref> out direct exposure to the target domain, such as Contriever <ref type="bibr">(Izacard et al., 2021)</ref> trained with contrastive learning on Wikipedia and CCNet. We highlight baselines in the same category as ReAtt in the following tables since comparison between them is relatively fair. Details of adaptation of ReAtt can be found in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Experimental Results</head><p>Results of supervised and unsupervised adaptation are listed in Tab. 4, Tab. 5, and Tab. 6 respectively.</p><p>Zero-shot Generalization Ability As shown in Tab. 4 and Tab. 6, the zero-shot performance of ReAtt is significantly better than other zero-shot baselines on two QA datasets and one fact checking dataset (+3.0/+6.5/+4.5 on BioASQ/FiQA/SciFact than the second best), and overall comparable on the rest of datasets (-0.5/-0.6/-3.0/-1.0 on MS MARCO/CQA./TRECC./SCIDOCS than the best which is usually BM25), demonstrating that our end-to-end training with QA loss on NQ produces a robust retriever. We conjecture that the superior performance on QA datasets can be attributed to our end-to-end training using QA loss which learns retrieval that better aligns with the end task than training with retrieval annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retrieval Adaptation with QA Supervision</head><p>As shown in the left-hand side of Tab. 4, end-toend adaptation with QA supervision significantly improves ReAtt's retrieval performance by 5.8/8.5 on BioASQ/FiQA, achieving similar performance as Contriever fine-tuned on FiQA, and better performance than other unsupervised methods, confirming the end-to-end adaptability of our methods.</p><p>End-to-end QA Adaptation We perform endto-end adaptation on BioASQ and compare with RAG as a baseline, which combines DPR as retriever and BART as reader, and DPR has a query and document encoder. Since updating document encoder requires corpus re-indexing, it is fixed during fine-tuning. We found end-to-end fine-tuning fails on RAG. To understand why, we conduct a rigorous experiment that breaks down each component of RAG to find the failure point in Tab. 5.</p><p>Starting from the initial model trained on NQ (#1), we first fine-tune the reader while fixing the query encoder (#2), and as expected QA performance improves. However fine-tuning both query encoder and reader (end-to-end #3) makes the retriever collapse with zero relevant documents returned, indicating end-to-end fine-tuning does not work for RAG on new domains. In order to improve both retrieval and QA, we need to fine-tune RAG in a pipeline manner: first fine-tune the re-triever (both query and doc encoder) similarly to DPR using retrieval annotations (#4), then finetune the reader (#5). With the DPR-like fine-tuned retriever, end-to-end fine-tuning of query encoder and reader still fails (#6), although the retriever does not completely collapse.</p><p>End-to-end fine-tuning of ReAtt improves retrieval and QA simultaneously. Fine-tuning starting from ReAtt trained on NQ is better than starting from T5, indicating the capability learned in NQ could be transferred to BioASQ. Comparing RAG and ReAtt, we identify several keys that enable endto-end adaptation. (1) ReAtt relying on token-level attention has a strong initial performance, (2) crossdocument adjustment over both close and random documents in ReAtt provides a better gradient estimation than only using retrieved documents in RAG, (3) distillation-based loss in ReAtt might be more effective than multiplying the retrieval probability into the final generation probability.</p><p>Leveraging Retrieval Annotations As shown on the right-hand side of Tab. 4, ReAtt is able to consume retrieval supervision in a generative format and achieve competitive performance as other supervised dense retrievers.</p><p>Unsupervised Adaptation with SSM As shown in Tab. 6, adaptation by simply masking salient entities from sentences as input and generating masked entities using ReAtt improves the retrieval performance on 4 datasets, some by a large margin, achieving comparable or superior performance than strong retrieval adaptation methods such as TSDAE+GPL that relies on query generation. This indicates that our end-to-end trainable model also works well in unsupervised settings without involving too many engineering heuristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related Work</head><p>Retrieval-augmented question answering utilizes evidence retrieved from an external knowledge source to facilitate question answering. There have been several attempts to learn retrievers and readers jointly. ORQA, REALM, RAG, EMDR 2 , YONO, and Atlas <ref type="bibr" target="#b22">(Lee et al., 2019;</ref><ref type="bibr" target="#b8">Guu et al., 2020;</ref><ref type="bibr" target="#b33">Sachan et al., 2021;</ref><ref type="bibr">Lee et al., 2021a;</ref><ref type="bibr" target="#b13">Izacard et al., 2022)</ref> first warm-up retrievers using unsupervised pretraining methods such as inverse cloze task (ICT), salient span masking (SSM), and large-scale contrastive learning, or initialize from supervised retrievers, then fine-tune both retriever and reader on downstream tasks. They either use fixed index <ref type="bibr" target="#b22">(Lee et al., 2019;</ref><ref type="bibr">Lewis et al., 2020)</ref> or asynchronously update the index during training <ref type="bibr" target="#b8">(Guu et al., 2020;</ref><ref type="bibr" target="#b33">Sachan et al., 2021;</ref><ref type="bibr">Lee et al., 2021a;</ref><ref type="bibr" target="#b13">Izacard et al., 2022)</ref>. Recently, retrieval-augmented models are scaled up to very large corpora such as the web <ref type="bibr" target="#b29">(Piktus et al., 2021;</ref><ref type="bibr" target="#b0">Borgeaud et al., 2021)</ref>, making them capable of handling information out of the scope of Wikipedia. Atlas <ref type="bibr" target="#b13">(Izacard et al., 2022)</ref> scales up retrieval-augmented models with T5-11B as the reader and Contriever <ref type="bibr">(Izacard et al., 2021)</ref> as the retriever and achieves strong few-shot performance on multiple benchmarks. Detailed comparisons of these models can be found in Tab. 7. More related works on dense retrieval, unsupervised retrieval learning, and retrieval augmentation for language modeling can be found in Appendix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We propose retrieval as attention (ReAtt), a single Transformer model that can be learned in an endto-end fashion only using end task loss. We demonstrated on NQ dataset that ReAtt can achieve both competitive retrieval and QA performance. We further show that ReAtt is easy to adapt to other domains in both supervised and unsupervised settings, achieving both boosted retrieval and end task performance. Future directions include better endto-end training objectives and efficient training and inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>ReAtt is based on token-level representations, and belongs to the same category as token-level dense retrievers such as ColBERT <ref type="bibr">(Khattab and Zaharia, 2020)</ref>. Comparing to passage-level dense retrievers such as DPR <ref type="bibr" target="#b15">(Karpukhin et al., 2020)</ref>, token-level retrievers usually offer better performance (shown in Tab. 1, Tab. 4, and Tab. 6) but require more space to store the index and longer query time. Our methods have the same limitation. We found ColBERT's practice in index compression and approximate search <ref type="bibr">(Khattab and Zaharia, 2020;</ref><ref type="bibr" target="#b35">Santhanam et al., 2021</ref><ref type="bibr" target="#b34">Santhanam et al., , 2022) )</ref> also works for our model, making this issue less of a concern.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of Retrieval as Attention (ReAtt)with the first B=2 encoder layers as bi-encoder (i.e., retriever) and the rest L-B=2 layers as cross-encoder. During training, the retrieval attention between a query q 1 and documents d 11,12,13 is adjusted by minimizing its discrepancy from the target attention. For simplicity, we use a single arrow to represent attention of a single head between multiple tokens.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Retrieval performance on NQ. PT is retrieval pretraining. Fair-to-compare baselines are highlighted with background color. Best performance is in bold.</figDesc><table><row><cell>63.8</cell><cell>78.9</cell><cell>-</cell></row></table><note><p>uments returned by DPR can potentially reduce training time. We experimented with training on close documents from DPR for a single iteration with 16K steps (denoted as ReAtt DPR ). Since both approaches achieve similar performance (Tab. 1 and Tab. 2) and ReAtt DPR is cheaper to train, we use it in other experimental settings.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Ablations by removing one component or changing one hyperparameter from the ReAtt baseline.</figDesc><table><row><cell>100 EM</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>.? Pretraining models are trained on corpora with-nDCG@10 of zero-shot and supervised adaptation experiments on two QA and one IR datasets. We use colors to denote categories: pretraining, unsupervised adaptation, and supervised adaptation. Baselines comparable to ReAtt are highlighted with blue background color. We also show the improvement of ReAtt over zero-shot performance in subscript.</figDesc><table><row><cell>Tasks</cell><cell></cell><cell cols="2">QA</cell><cell>Retrieval</cell></row><row><cell cols="2">Datasets</cell><cell cols="2">BioASQ FiQA</cell><cell>MS MARCO</cell></row><row><cell></cell><cell></cell><cell cols="3">zero-shot performance</cell></row><row><cell>BM25</cell><cell></cell><cell>68.1</cell><cell>23.6</cell><cell>22.8</cell></row><row><cell>DPR</cell><cell></cell><cell>14.1</cell><cell>11.2</cell><cell>17.7</cell></row><row><cell cols="2">ColBERT-NQ</cell><cell>65.5</cell><cell>23.8</cell><cell>32.8</cell></row><row><cell>ReAtt</cell><cell></cell><cell>71.1</cell><cell>30.1</cell><cell>32.3</cell></row><row><cell></cell><cell></cell><cell cols="3">additional training</cell></row><row><cell cols="2">Contriever</cell><cell>-</cell><cell cols="2">32.9 docT5query</cell><cell>33.8</cell></row><row><cell>SimCSE</cell><cell></cell><cell>58.1</cell><cell cols="2">31.4 ANCE</cell><cell>38.8</cell></row><row><cell cols="2">TSDAE+GPL</cell><cell>61.6</cell><cell cols="2">34.4 ColBERT</cell><cell>40.1</cell></row><row><cell cols="2">Contrieverw/ FT</cell><cell>-</cell><cell cols="2">38.1 Contriever</cell><cell>40.7</cell></row><row><cell>ReAtt</cell><cell></cell><cell cols="2">+5.876.9 +8.538.6</cell><cell>ReAtt</cell><cell>+7.639.9</cell></row><row><cell cols="3"># Ablations</cell><cell cols="2">nDCG@1 @5</cell><cell>EM</cell></row><row><cell cols="2">1 RAG</cell><cell></cell><cell>14.6 13.0</cell><cell>1.3</cell></row><row><cell cols="2">2 + reader</cell><cell></cell><cell>14.6 13.0</cell><cell>-27.5 26.2</cell></row><row><cell>3</cell><cell cols="4">+ qry (e2e) 0.0 0.0 -13.0 25.7 -1.9</cell></row><row><cell cols="5">4 + doc/qry enc  *  29.4 27.1 14.1</cell><cell>5.0 3.7</cell></row><row><cell>5</cell><cell cols="3">+ reader (pipe) 29.4 27.1</cell><cell>-27.8 22.8</cell></row><row><cell>6</cell><cell cols="2">+ qry enc</cell><cell cols="2">23.3 23.2 -4.0 26.2 -1.6</cell></row><row><cell cols="2">7 T5</cell><cell></cell><cell>49.2 47.7</cell><cell>0.0</cell></row><row><cell cols="2">8 + e2e</cell><cell></cell><cell cols="2">75.2 73.5 25.7 44.4 44.4</cell></row><row><cell cols="2">9 ReAtt</cell><cell></cell><cell>72.8 70.1</cell><cell>17.2</cell></row><row><cell cols="2">10 + e2e</cell><cell></cell><cell cols="2">77.4 75.4 5.3 47.2 30.0</cell></row><row><cell cols="5">Table 5: RAG and ReAtt on BioASQ. Each indent in-</cell></row><row><cell cols="5">dicates fine-tuning one more component than its parent</cell></row><row><cell cols="5">with performance difference colored with green/red.  *</cell></row><row><cell cols="5">denotes fine-tuning conducted sequentially instead of</cell></row><row><cell cols="5">jointly with the current component.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Queries and documents can use different bi-encoders but we use one notation for simplicity.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>We also attempted other variations of target attention and found performances are similar, consistent with observations inIzacard and Grave (2021a).</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported by a gift from <rs type="funder">Bosch Research</rs>. We would like to thank <rs type="person">Chunting Zhou</rs>, <rs type="person">Uri Alon</rs>, <rs type="person">Omar Khattab</rs>, <rs type="person">Patrick Lewis</rs>, and <rs type="person">Jane Dwivedi-Yu</rs> for their insightful feedback and help with experiments.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Efficient Implementation</head><p>Under typical optimization setups where the loss is point-wise with respect to each training data, like training classifiers or readers, scaling batch size can be easily achieved with gradient accumulation. However, due to the use of in-batch negatives, our systems, like others <ref type="bibr" target="#b15">(Karpukhin et al., 2020;</ref><ref type="bibr" target="#b30">Qu et al., 2021)</ref>, require having all examples in a batch to reside in GPUs simultaneously when trained directly. Larger batches therefore need proportionally more GPU memory.</p><p>In order to accommodate large batches with our limited memory hardware, we adopt the gradient cache approach <ref type="bibr">(Gao et al., 2021b)</ref> decouple instances in the same batch. In particular, we run an extra forward pass over the large batch in inference mode and record (1) representations for all query and document tokens (Q B+1,h q and K B+1,h d ) and (2) decoder-encoder target attention values (C a,q,Dq ). Note that we do not store model internal activation nor perform gradient computation with respect to model parameters in this step. With (1) we can compute the retrieval attention, and with (2) we can compute cross-document adjustment loss (Eq. 2). We then compute and cache gradient vec-tors of all query and document vectors with respect to Eq. 2. We finally optimize the model with a sufficiently small batch size to fit in GPU memory and use cached gradient in the backward pass of the Eq. 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Details of Adaptation Experiments</head><p>For supervised adaptation, we train on BioASQ, FiQA, and MS MARCO separately using all training queries. For CQADupStack, we merge the document corpora of 12 sub-domains into a single corpus to sample masked sentences for salient span masking training. For each of the 4 unsupervised domain adaptation datasets (CQADupStack, TREC-COVID, SCIDOCS, SciFact), we sample 20?100K sentences and mask one entity, which is approximately proportional to the size of the corpus with a larger sampling rate for small corpora. We reuse the same hyperparameters as NQ ( ? 5), except that we train each model for a single iteration using close documents from BM25 with 4K update steps and a batch size of 16. Since MS MARCO has a large number of annotations, we train for 12K update steps.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Improving language models by retrieving from trillions of tokens</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eliza</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katie</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Baptiste</forename><surname>Lespiau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bogdan</forename><surname>Damoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>De Las</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelia</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Guy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Menick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Ring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saffron</forename><surname>Hennigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loren</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Maggiore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albin</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Cassirer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michela</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Paganini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><forename type="middle">W</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erich</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName><surname>Sifre</surname></persName>
		</author>
		<idno>CoRR, abs/2112.04426</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unitedqa: A hybrid approach for open domain question answering</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.240</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08-01">2021. August 1-6, 2021</date>
			<biblScope unit="page" from="3080" to="3090" />
		</imprint>
	</monogr>
	<note>Virtual Event</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">SPECTER: document-level representation learning using citation-informed transformers</title>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.207</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07-05">2020. July 5-10, 2020</date>
			<biblScope unit="page" from="2270" to="2282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">R2-D2: A modular baseline for open-domain question answering</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Fajcik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Docekal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karel</forename><surname>Ondrej</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pavel</forename><surname>Smrz</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-emnlp.73</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11">2021. 16-20 November, 2021</date>
			<biblScope unit="page" from="854" to="870" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Condenser: a pretraining architecture for dense retrieval</title>
		<author>
			<persName><forename type="first">Luyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.75</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-07-11">2021. 7-11 November, 2021</date>
			<biblScope unit="page" from="981" to="993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unsupervised corpus aware language model pre-training for dense passage retrieval</title>
		<author>
			<persName><forename type="first">Luyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022-05-22">2022. May 22-27, 2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2843" to="2853" />
		</imprint>
	</monogr>
	<note>Long Papers), ACL 2022</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">COIL: revisit exact lexical match in information retrieval with contextualized inverted list</title>
		<author>
			<persName><forename type="first">Luyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie Callan ; Luyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.repl4nlp-1.31</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-06-06">2021. June 6-11, 2021</date>
			<biblScope unit="page" from="316" to="321" />
		</imprint>
	</monogr>
	<note>Proceedings of the 6th Workshop on Representation Learning for NLP. RepL4NLP-2021. Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">2021c. Simcse: Simple contrastive learning of sentence embeddings</title>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingcheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.552</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11-11">7-11 November, 2021</date>
			<biblScope unit="page" from="6894" to="6910" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">REALM: retrievalaugmented language model pre-training</title>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zora</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<idno>abs/2002.08909</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Cqadupstack: A benchmark data set for community question-answering research</title>
		<author>
			<persName><forename type="first">Doris</forename><surname>Hoogeveen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karin</forename><forename type="middle">M</forename><surname>Verspoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
		<idno type="DOI">10.1145/2838931.2838934</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Australasian Document Computing Symposium</title>
		<meeting>the 20th Australasian Document Computing Symposium<address><addrLine>Parramatta, NSW, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015-09">2015. 2015. December 8-9, 2015</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="3" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Towards unsupervised dense information retrieval with contrastive learning</title>
		<author>
			<persName><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<idno>CoRR, abs/2112.09118</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Distilling knowledge from reader to retriever for question answering</title>
		<author>
			<persName><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria</title>
		<imprint>
			<publisher>OpenReview</publisher>
			<date type="published" when="2021">May 3-7, 2021</date>
		</imprint>
	</monogr>
	<note>net</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Leveraging passage retrieval with generative models for open domain question answering</title>
		<author>
			<persName><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.eacl-main.74</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, EACL 2021</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, EACL 2021<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-04-19">2021. April 19 -23, 2021</date>
			<biblScope unit="page" from="874" to="880" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Few-shot learning with retrieval augmented language models</title>
		<author>
			<persName><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Lomeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timo</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jane</forename><surname>Dwivedi-Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2208.03299</idno>
		<idno>CoRR, abs/2208.03299</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Billion-scale similarity search with gpus</title>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<idno type="DOI">10.1109/TBDATA.2019.2921572</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Big Data</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="535" to="547" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dense passage retrieval for open-domain question answering</title>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ledell</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Yih</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.550</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11-16">2020. 2020. November 16-20, 2020</date>
			<biblScope unit="page" from="6769" to="6781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Generalization through memorization: Nearest neighbor language models</title>
		<author>
			<persName><forename type="first">Urvashi</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations, ICLR 2020</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-26">2020. April 26-30, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Relevance-guided supervision for openqa with colbert</title>
		<author>
			<persName><forename type="first">Omar</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<idno>CoRR, abs/2007.00814</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Colbert: Efficient and effective passage search via contextualized late interaction over BERT</title>
		<author>
			<persName><forename type="first">Omar</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<idno type="DOI">10.1145/3397271.3401075</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SI-GIR 2020, Virtual Event</title>
		<meeting>the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SI-GIR 2020, Virtual Event<address><addrLine>China</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020-07-25">2020. July 25-30, 2020</date>
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Natural questions: a benchmark for question answering research</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivia</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><forename type="middle">P</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danielle</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Kelcey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00276</idno>
	</analytic>
	<monogr>
		<title level="j">Trans. Assoc. Comput. Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="452" to="466" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">You only need one model for open-domain question answering</title>
		<author>
			<persName><forename type="first">Haejun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akhil</forename><surname>Kedia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jongwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashwin</forename><surname>Paranjape</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyoung-Gu</forename><surname>Woo</surname></persName>
		</author>
		<idno>CoRR, abs/2112.07381</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">2021b. Phrase retrieval learns passage retrieval, too</title>
		<author>
			<persName><forename type="first">Jinhyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Wettig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.297</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11-11">7-11 November, 2021</date>
			<biblScope unit="page" from="3661" to="3672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Latent retrieval for weakly supervised open domain question answering</title>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p19-1612</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2019-07-28">2019. July 28-August 2, 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6086" to="6096" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Retrieval-augmented generation for knowledge-intensive NLP tasks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heinrich</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>K?ttler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Rockt?schel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020</title>
		<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-12-06">2020. 2020. December 6-12, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Zero-shot neural passage retrieval via domain-targeted synthetic question generation</title>
		<author>
			<persName><forename type="first">Ji</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Korotkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><forename type="middle">B</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">T</forename><surname>Mcdonald</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.eacl-main.92</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, EACL 2021</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, EACL 2021<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-04-19">2021. April 19 -23, 2021</date>
			<biblScope unit="page" from="1075" to="1088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Www&apos;18 open challenge: Financial opinion mining and question answering</title>
		<author>
			<persName><forename type="first">Macedo</forename><surname>Maia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siegfried</forename><surname>Handschuh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andr?</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Mcdermott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manel</forename><surname>Zarrouk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Balahur</surname></persName>
		</author>
		<idno type="DOI">10.1145/3184558.3192301</idno>
	</analytic>
	<monogr>
		<title level="m">Companion of the The Web Conference 2018 on The Web Conference 2018</title>
		<meeting><address><addrLine>Lyon , France</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018-04-23">2018. April 23-27, 2018</date>
			<biblScope unit="volume">2018</biblScope>
			<biblScope unit="page" from="1941" to="1942" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">MS MARCO: A human generated machine reading comprehension dataset</title>
		<author>
			<persName><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Cognitive Computation: Integrating neural and symbolic approaches 2016 colocated with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016)</title>
		<meeting>the Workshop on Cognitive Computation: Integrating neural and symbolic approaches 2016 colocated with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016)<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-12-09">2016. December 9. 2016</date>
			<biblScope unit="volume">1773</biblScope>
		</imprint>
	</monogr>
	<note>CEUR Workshop Proceedings</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">From doc2query to doctttttquery</title>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Domain-matched pre-training tasks for dense retrieval</title>
		<author>
			<persName><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kushal</forename><surname>Lakhotia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anchit</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xilun</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sonal</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yashar</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><surname>Mehdad</surname></persName>
		</author>
		<idno>CoRR, abs/2107.13602</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">The web is your oyster -knowledge-intensive NLP against a very large web corpus</title>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmytro</forename><surname>Okhonko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Broscheit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<idno>CoRR, abs/2112.09924</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Rocketqa: An optimized training approach to dense passage retrieval for opendomain question answering</title>
		<author>
			<persName><forename type="first">Yingqi</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuchen</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiyang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daxiang</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.466</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-06-06">2021. June 6-11, 2021</date>
			<biblScope unit="page" from="5835" to="5847" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page">67</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The probabilistic relevance framework: BM25 and beyond</title>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
		<idno type="DOI">10.1561/1500000019</idno>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="333" to="389" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">End-to-end training of multi-document reader and retriever for open-domain question answering</title>
		<author>
			<persName><forename type="first">Devendra</forename><surname>Singh Sachan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021</title>
		<imprint>
			<date type="published" when="2021-12-06">2021. December 6-14, 2021</date>
			<biblScope unit="page" from="25968" to="25981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">PLAID: an efficient engine for late interaction retrieval</title>
		<author>
			<persName><forename type="first">Keshav</forename><surname>Santhanam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omar</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2205.09707</idno>
		<idno>CoRR, abs/2205.09707</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Nandan Thakur, Nils Reimers, Andreas R?ckl?, Abhishek Srivastava, and Iryna Gurevych</title>
		<author>
			<persName><forename type="first">Keshav</forename><surname>Santhanam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omar</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Saad-Falcon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<idno>CoRR, abs/2112.01488</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021</title>
		<meeting>the Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021</meeting>
		<imprint>
			<date type="published" when="2021-12">2021. 2021. December 2021</date>
		</imprint>
	</monogr>
	<note>BEIR: A heterogeneous benchmark for zero-shot evaluation of information retrieval. virtual</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">An overview of the BIOASQ large-scale biomedical semantic indexing and question answering competition</title>
		<author>
			<persName><forename type="first">George</forename><surname>Tsatsaronis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Balikas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prodromos</forename><surname>Malakasiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Partalas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Zschunke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">R</forename><surname>Alvers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergios</forename><surname>Petridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Polychronopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yannis</forename><surname>Almirantis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Pavlopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Baskiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Gallinari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thierry</forename><surname>Arti?res</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Axel-Cyrille Ngonga</forename><surname>Ngomo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norman</forename><surname>Heino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?ric</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liliana</forename><surname>Barrio-Alvers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Schroeder</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12859-015-0564-6</idno>
	</analytic>
	<monogr>
		<title level="m">Ion Androutsopoulos, and Georgios Paliouras</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09">2017. 2017. December 4-9, 2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">TREC-COVID: constructing a pandemic information retrieval test collection</title>
		<author>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tasmeer</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kirk</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucy</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename></persName>
		</author>
		<idno type="DOI">10.1145/3451964.3451965</idno>
	</analytic>
	<monogr>
		<title level="j">SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Fact or fiction: Verifying scientific claims</title>
		<author>
			<persName><forename type="first">David</forename><surname>Wadden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanchuan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucy</forename><forename type="middle">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madeleine</forename><surname>Van Zuylen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.609</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="7534" to="7550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">2021a. TSDAE: using transformer-based sequential denoising auto-encoderfor unsupervised sentence embedding learning</title>
		<author>
			<persName><forename type="first">Kexin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-emnlp.59</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021, Virtual Event / Punta Cana</title>
		<meeting><address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11-20">16-20 November, 2021</date>
			<biblScope unit="page" from="671" to="688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Nils Reimers, and Iryna Gurevych. 2021b. GPL: generative pseudo labeling for unsupervised domain adaptation of dense retrieval</title>
		<author>
			<persName><forename type="first">Kexin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nandan</forename><surname>Thakur</surname></persName>
		</author>
		<idno>CoRR, abs/2112.07577</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Memorizing transformers</title>
		<author>
			<persName><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Norman Rabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Delesley</forename><surname>Hutchins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event</title>
		<imprint>
			<publisher>OpenReview</publisher>
			<date type="published" when="2022-04-25">2022. April 25-29, 2022</date>
		</imprint>
	</monogr>
	<note>net</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Approximate nearest neighbor negative contrastive learning for dense text retrieval</title>
		<author>
			<persName><forename type="first">Lee</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kwok-Fung</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junaid</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnold</forename><surname>Overwijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations, ICLR 2021, Virtual Event</title>
		<meeting><address><addrLine>Austria</addrLine></address></meeting>
		<imprint>
			<publisher>OpenReview</publisher>
			<date type="published" when="2021-05-03">2021. May 3-7, 2021</date>
		</imprint>
	</monogr>
	<note>net</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Is retriever merely an approximator of reader?</title>
		<author>
			<persName><forename type="first">Sohee</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<idno>CoRR, abs/2010.10999</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Training language models with memory augmentation</title>
		<author>
			<persName><forename type="first">Zexuan</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2205.12674</idno>
		<idno>CoRR, abs/2205.12674</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Work Dense Retrieval Models Dense retrieval models can be categorized into two groups, passagelevel retrievers</title>
		<author>
			<persName><forename type="first">;</forename><surname>Related</surname></persName>
		</author>
		<author>
			<persName><surname>Karpukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Passage-level retrievers encode queries and documents into a single vector, while token/phrase-level retrievers directly use token/phrase representations, resulting in multivector representations</title>
		<imprint>
			<date type="published" when="2020">2020. 2021. 2021. 2020</date>
		</imprint>
	</monogr>
	<note>Gao and Callan, 2022) and token/phrase-level retrievers (Khattab and Zaharia. Khattab et 2020; Gao et al., 2021a; Lee et al., 2021b. Passage-level retrievers are usually more efficient but less expressive than token-level retrievers</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">SimCSE (Gao et al., 2021c) obtains representations of the same input by passing through the model twice with different dropout masks and minimizes their distance. Contriever (Izacard et al., 2021) is trained by large-scale contrastive learning with random cropping of text spans sampled from Wikipedia and CCNet. GPL (Wang et al., 2021b) leverages query generators to obtain pseudo queries, and collect positive and negative documents by pseudo labeling using a cross-encoder. Retrieval Augmentation for Language Modeling Retrieval from external datastore to improve language modeling perplexity has been explored by many works, where additional tokens are retrieved during generation based on contextual representations</title>
		<author>
			<persName><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019. 2021. 2021. 2021. 2020. 2021. 2022. 2022</date>
			<publisher>Wu et al</publisher>
		</imprint>
	</monogr>
	<note>Izacard et al., 2021) and question generation-based. They differ in whether retrieval is fixed or learnable, retrieval frequency, and contextual representations used to perform nearest neighbors search</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
