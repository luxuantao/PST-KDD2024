<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jiaqi</forename><surname>Ma</surname></persName>
							<email>jiaqima@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<settlement>Ann Arbor</settlement>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<settlement>Ann Arbor</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
							<email>zhezhao@google.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Google Inc</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Google Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xinyang</forename><surname>Yi</surname></persName>
							<email>xinyang@google.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Google Inc</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Google Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jilin</forename><surname>Chen</surname></persName>
							<email>jilinc@google.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Google Inc</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Google Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hong</forename><surname>Lichan</surname></persName>
							<email>lichan@google.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Google Inc</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Google Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
							<email>edchi@google.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Google Inc</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Google Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName><surname>Modeling</surname></persName>
						</author>
						<title level="a" type="main">Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3219819.3220007</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS CONCEPTS</term>
					<term>Computing methodologies → Multi-task learning</term>
					<term>Neural networks</term>
					<term>• Information systems → Recommender systems</term>
					<term>multi-task learning</term>
					<term>mixture of experts</term>
					<term>neural network</term>
					<term>recommendation system</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Neural-based multi-task learning has been successfully used in many real-world large-scale applications such as recommendation systems. For example, in movie recommendations, beyond providing users movies which they tend to purchase and watch, the system might also optimize for users liking the movies afterwards. With multi-task learning, we aim to build a single model that learns these multiple goals and tasks simultaneously. However, the prediction quality of commonly used multi-task models is often sensitive to the relationships between tasks. It is therefore important to study the modeling tradeo s between task-speci c objectives and inter-task relationships.</p><p>In this work, we propose a novel multi-task learning approach, Multi-gate Mixture-of-Experts (MMoE), which explicitly learns to model task relationships from data. We adapt the Mixture-of-Experts (MoE) structure to multi-task learning by sharing the expert submodels across all tasks, while also having a gating network trained to optimize each task. To validate our approach on data with di erent levels of task relatedness, we rst apply it to a synthetic dataset where we control the task relatedness. We show that the proposed approach performs better than baseline methods when the tasks are less related. We also show that the MMoE structure results in an additional trainability bene t, depending on di erent levels of randomness in the training data and model initialization. Furthermore, we demonstrate the performance improvements by MMoE on real tasks including a binary classi cation benchmark, and a large-scale content recommendation system at Google.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In recent years, deep neural network models have been successfully applied in many real world large-scale applications, such as recommendation systems <ref type="bibr" target="#b10">[11]</ref>. Such recommendation systems often need to optimize multiple objectives at the same time. For example, when recommending movies for users to watch, we may want the users to not only purchase and watch the movies, but also to like the movies afterwards so that they'll come back for more movies. That is, we can create models to predict both users' purchases and their ratings simultaneously. Indeed, many large-scale recommendation systems have adopted multi-task learning using Deep Neural Network (DNN) models <ref type="bibr" target="#b2">[3]</ref>.</p><p>Researchers have reported multi-task learning models can improve model predictions on all tasks by utilizing regularization and transfer learning <ref type="bibr" target="#b7">[8]</ref>. However, in practice, multi-task learning models do not always outperform the corresponding single-task models on all tasks <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b25">26]</ref>. In fact, many DNN-based multi-task learning models are sensitive to factors such as the data distribution di erences and relationships among tasks <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b33">34]</ref>. The inherent con icts from task di erences can actually harm the predictions of at least some of the tasks, particularly when model parameters are extensively shared among all tasks.</p><p>Prior works <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8]</ref> investigated task di erences in multi-task learning by assuming particular data generation processes for each task, measuring task di erences according to the assumption, and then making suggestions based on how di erent the tasks are. However, as real applications often have much more complicated data patterns, it is often di cult to measure task di erences and to make use of the suggested approaches of these prior works.</p><p>Several recent works proposed novel modeling techniques to handle task di erences in multi-task learning without relying on an explicit task di erence measurement <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b33">34]</ref>. However, these techniques often involve adding many more model parameters per task to accommodate task di erences. As large-scale recommendation systems can contain millions or billions of parameters, those additional parameters are often under-constrained, which may hurt model quality. The additional computational cost of these parameters are also often prohibitive in real production settings due to limited serving resource.</p><p>In this paper, we propose a multi-task learning approach based on a novel Multi-gate Mixture-of-Experts (MMoE) structure, which is inspired by the Mixture-of-Experts (MoE) model <ref type="bibr" target="#b20">[21]</ref> and the recent MoE layer <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b30">31]</ref>. MMoE explicitly models the task relationships and learns task-speci c functionalities to leverage shared representations. It allows parameters to be automatically allocated to capture either shared task information or task-speci c information, avoiding the need of adding many new parameters per task.</p><p>The backbone of MMoE is built upon the most commonly used Shared-Bottom multi-task DNN structure <ref type="bibr" target="#b7">[8]</ref>. The Shared-Bottom model structure is shown in Figure <ref type="figure" target="#fig_0">1</ref> (a), where several bottom layers following the input layer are shared across all the tasks and then each task has an individual "tower" of network on top of the bottom representations. Instead of having one bottom network shared by all tasks, our model, shown in Figure <ref type="figure" target="#fig_0">1</ref> (c), has a group of bottom networks, each of which is called an expert. In our paper, each expert is a feed-forward network. We then introduce a gating network for each task. The gating networks take the input features and output softmax gates assembling the experts with di erent weights, allowing di erent tasks to utilize experts di erently. The results of the assembled experts are then passed into the task-speci c tower networks. In this way, the gating networks for di erent tasks can learn di erent mixture patterns of experts assembling, and thus capture the task relationships.</p><p>To understand how MMoE learns its experts and task gating networks for di erent levels of task relatedness, we conduct a synthetic experiment where we can measure and control task relatedness by their Pearson correlation. Similar to <ref type="bibr" target="#b23">[24]</ref>, we use two synthetic regression tasks and use sinusoidal functions as the data generation mechanism to introduce non-linearity. Our approach outperforms baseline methods under this setup, especially when task correlation is low. In this set of experiments, we also discover that MMoE is easier to train and converges to a better loss during multiple runs. This relates to recent discoveries that modulation and gating mechanisms can improve the trainability in training non-convex deep neural networks <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b18">19]</ref>.</p><p>We further evaluate the performance of MMoE on a benchmark dataset, UCI Census-income dataset, with a multi-task problem setup. We compare with several state-of-the-art multi-task models which model task relations with soft parameter sharing, and observe improvement in our method.</p><p>Finally, we test MMoE on a real large-scale content recommendation system, where two classi cation tasks are learned at the same time when recommending items to users. We train MMoE model with hundreds of billions of training examples and compare it with a shared-bottom production model. We observe signi cant improvements in o ine metrics such as AUC. In addition, our MMoE model consistently improves online metrics in live experiments.</p><p>The contribution of this paper is threefold: First, we propose a novel Multi-gate Mixture-of-Experts model which explicitly models task relationships. Through modulation and gating networks, our model automatically adjusts parameterization between modeling shared information and modeling task-speci c information. Second, we conduct control experiments on synthetic data. We report how task relatedness a ects training dynamics in multi-task learning and how MMoE improves both model expressiveness and trainability. Finally, we conduct experiments on real benchmark data and a large-scale production recommendation system with hundreds of millions of users and items. Our experiments verify the e ciency and e ectiveness of our proposed method in real-world settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK 2.1 Multi-task Learning in DNNs</head><p>Multi-task models can learn commonalities and di erences across di erent tasks. Doing so can result in both improved e ciency and model quality for each task <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b29">30]</ref>. One of the widely used multi-task learning models is proposed by Caruana <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref>, which has a shared-bottom model structure, where the bottom hidden layers are shared across tasks. This structure substantially reduces the risk of over tting, but can su er from optimization con icts caused by task di erences, because all tasks need to use the same set of parameters on shared-bottom layers.</p><p>To understand how task relatedness a ects model quality, prior works used synthetic data generation and manipulated di erent types of task relatedness so as to evaluate the e ectiveness of multitask models <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b7">8]</ref>.</p><p>Instead of sharing hidden layers and same model parameters across tasks, some recent approaches add di erent types of constraints on task-speci c parameters <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b33">34]</ref>. For example, for two tasks, Duong et al. <ref type="bibr" target="#b14">[15]</ref> adds L-2 constraints between the two sets of parameters. The cross-stitch network <ref type="bibr" target="#b26">[27]</ref> learns a unique combination of task-speci c hidden-layer embeddings for each task. Yang et al. <ref type="bibr" target="#b33">[34]</ref> uses a tensor factorization model to generate hidden-layer parameters for each task. Compared to shared-bottom models, these approaches have more task-speci c parameters and can achieve better performance when task di erences lead to conicts in updating shared parameters. However, the larger number of task-speci c parameters require more training data to t and may not be e cient in large-scale models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Ensemble of Subnets &amp; Mixture of Experts</head><p>In this paper, we apply some recent ndings in deep learning such as parameter modulation and ensemble method to model task relationships for multi-task learning. In DNNs, ensemble models and ensemble of subnetworks have been proven to be able to improve model performance <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b19">20]</ref>.</p><p>Eigen et al <ref type="bibr" target="#b15">[16]</ref> and Shazeer et al <ref type="bibr" target="#b30">[31]</ref> turn the mixture-of-experts model into basic building blocks (MoE layer) and stack them in a DNN. The MoE layer selects subnets (experts) based on the input of the layer at both training time and serving time. Therefore, this model is not only more powerful in modeling but also lowers computation cost by introducing sparsity into the gating networks. Similarly, PathNet <ref type="bibr" target="#b16">[17]</ref>, which is designed for arti cial general intelligence to handle di erent tasks, is a huge neural network with multiple layers and multiple submodules within each layer. While training for one task, multiple pathways are randomly selected and trained by di erent workers in parallel. The parameters of the best pathway is xed and new pathways are selected for training new tasks. We took inspiration from these works by using an ensemble of subnets (experts) to achieve transfer learning while saving computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Multi-task Learning Applications</head><p>Thanks to the development of distributed machine learning systems <ref type="bibr" target="#b12">[13]</ref>, many large-scale real-world applications have adopted DNN-based multi-task learning algorithms and observed substantial quality improvements. On multi-lingual machine translation tasks, with shared model parameters, translation tasks having limited training data can be improved by jointly learning with tasks having large amount of training data <ref type="bibr" target="#b21">[22]</ref>. For building recommendation systems, multi-task learning is found helpful for providing context-aware recommendations <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b34">35]</ref>. In <ref type="bibr" target="#b2">[3]</ref>, a text recommendation task is improved by sharing feature representations and lower level hidden layers. In <ref type="bibr" target="#b10">[11]</ref>, a shared-bottom model is used to learn a ranking algorithm for video recommendation. Similar to these prior works, we evaluate our modeling approach on a realworld large-scale recommendation system. We demonstrate that our approach is indeed scalable, and has favorable performance compared with other state-of-the-art modeling approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARY 3.1 Shared-bottom Multi-task Model</head><p>We rst introduce the shared-bottom multi-task model in Figure <ref type="figure" target="#fig_0">1</ref> (a), which is a framework proposed by Rich Caruana <ref type="bibr" target="#b7">[8]</ref> and widely adopted in many multi-task learning applications <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b28">29]</ref>. Therefore, we treat it as a representative baseline approach in multitask modeling.</p><p>Given K tasks, the model consists of a shared-bottom network, represented as function f , and K tower networks h k , where k = 1, 2, ..., K for each task respectively. The shared-bottom network follows the input layer, and the tower networks are built upon the output of the shared-bottom. Then individual output k for each task follows the corresponding task-speci c tower. For task k, the model can be formulated as,</p><formula xml:id="formula_0">k = h k ( f (x )).</formula><p>(1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Synthetic Data Generation</head><p>Prior works <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b26">27]</ref> indicate that the performance of multi-task learning models highly depends on the inherent task relatedness in the data. It is however di cult to study directly how task relatedness a ects multi-task models in real applications, since in real applications we cannot easily change the relatedness between tasks and observe the e ect. Therefore to establish an empirical study for this relationship, we rst use synthetic data where we can easily measure and control the task relatedness.</p><p>Inspired by Kang et al. <ref type="bibr" target="#b23">[24]</ref>, we generate two regression tasks and use the Pearson correlation of the labels of these two tasks as the quantitative indicator of task relationships. Since we focus on DNN models, instead of the linear functions used in <ref type="bibr" target="#b23">[24]</ref>, we set the regression model as a combination of sinusoidal functions as used in <ref type="bibr" target="#b32">[33]</ref>. Speci cally, we generate the synthetic data as follows.</p><p>(1) Given the input feature dimension d, we generate two orthogonal unit vectors</p><formula xml:id="formula_1">u 1 , u 2 ∈ R d , i.e., u T 1 u 2 = 0, u 1 2 = 1, u 2 2 = 1. (2) Given a scale constant c and a correlation score −1 ≤ p ≤ 1,</formula><p>generate two weight vectors w 1 , w 2 such that</p><formula xml:id="formula_2">w 1 = cu 1 , w 2 = c pu 1 + (1 − p 2 )u 2 .<label>(2)</label></formula><p>(3) Randomly sample an input data point x ∈ R d with each of its element from N (0, 1). ( <ref type="formula" target="#formula_3">4</ref>) Generate two labels 1 , 2 for two regression tasks as follows,</p><formula xml:id="formula_3">1 = w T 1 x + m i=1 sin α i w T 1 x + β i + ϵ 1 (3) 2 = w T 2 x + m i=1 sin α i w T 2 x + β i + ϵ 2<label>(4)</label></formula><p>where α i , β i , i = 1, 2, ..., m are given parameters that control the shape of the sinusoidal functions and ϵ 1 , ϵ 2 i.i.d</p><p>∼ N (0, 0.01), ( <ref type="formula" target="#formula_5">5</ref>) Repeat ( <ref type="formula">3</ref>) and ( <ref type="formula" target="#formula_3">4</ref>) until enough data are generated.</p><p>Due to the non-linear data generation procedure, it's not straightforward to generate tasks with a given label Pearson correlation. Instead, we manipulate the cosine similarity of the weight vectors in Eq 2, which is cos(w 1 , w 2 ) = p, and measuring the resulting label Pearson correlation afterwards. Note that in the linear case where</p><formula xml:id="formula_4">1 = w T 1 x + ϵ 1 2 = w T 2 x + ϵ 2 , the label Pearson correlation of 1 , 2 is exactly p.</formula><p>In the nonlinear case, 1 and 2 in Eq 3 and Eq 4 are also positively correlated, as shown in Figure <ref type="figure">2</ref>.</p><p>In the rest of this paper, for simplicity, we refer to cosine similarity of the weight vectors as "task correlation".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>label correlation</head><p>Figure <ref type="figure">2</ref>: Label Pearson correlation v.s. weight cosine similarity (task correlation). X-axis shows the cosine similarities of weight vectors. Y-axis is the resulting Pearson correlation between the labels. For each weight cosine similarity, we generate 10k data points with two labels and calculate the Pearson correlation between these two labels. We repeat this process and plot the average with the error bar indicating 2 standard deviations among the 100 trials.</p><p>Figure <ref type="figure">3</ref>: Performance of the Shared-Bottom model on synthetic data with di erent task correlation. Tasks with task correlation 1 means the two tasks have the same weight vectors but independent noises. X-axis is the number of training steps. Y-axis is the average loss of 200 independent runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Impact of Task Relatedness</head><p>To verify that low task relatedness hurts model quality in a baseline multi-task model setup, we conduct control experiments on the synthetic data as follows.</p><p>(1) Given a list of task correlation scores, generate a synthetic dataset for each score;</p><p>(2) Train one Shared-Bottom multi-task model on each of these datasets respectively while controlling all the model and training hyper-parameters to remain the same; (3) Repeat step (1) and ( <ref type="formula" target="#formula_2">2</ref>) hundreds of times with datasets generated independently but control the list of task correlation scores and the hyper-parameters the same; (4) Calculate the average performance of the models for each task correlation score.</p><p>Figure <ref type="figure">3</ref> shows the loss curves for di erent task correlations. As expected, the performance of the model trends down as the task correlation decreases. This trend is general for many di erent hyper-parameter settings. Here we only show an example of the control experiment results in Figure <ref type="figure">3</ref>. In this example, each tower network is a single-layer neural network with 8 hidden units, and the shared bottom network is a single-layer network with size=16. The model is implemented using TensorFlow <ref type="bibr" target="#b0">[1]</ref> and trained using Adam optimizer <ref type="bibr" target="#b24">[25]</ref> with the default setting. Note that the two regression tasks are symmetric so it's su cient to report the results on one task. This phenomenon validates our hypothesis that the traditional multi-task model is sensitive to the task relationships.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">MODELING APPROACHES 4.1 Mixture-of-Experts</head><p>The Original Mixture-of-Experts (MoE) Model <ref type="bibr" target="#b20">[21]</ref> can be formulated as:</p><formula xml:id="formula_5">= n i=1 (x ) i f i (x ),<label>(5)</label></formula><p>where n i=1 (x ) i = 1 and (x ) i , the ith logit of the output of (x ), indicates the probability for expert f i .</p><p>Here, f i , i = 1, ..., n are n expert networks and represents a gating network that ensembles the results from all experts. More speci cally, the gating network produces a distribution over the n experts based on the input, and the nal output is a weighted sum of the outputs of all experts.</p><p>MoE Layer : While MoE was rst developed as an ensemble method of multiple individual models, Eigen et al <ref type="bibr" target="#b15">[16]</ref> and Shazeer et al <ref type="bibr" target="#b30">[31]</ref> turn it into basic building blocks (MoE layer) and stack them in a DNN. The MoE layer has the same structure as the MoE model but accepts the output of the previous layer as input and outputs to a successive layer. The whole model is then trained in an end-to-end way.</p><p>The main goal of the MoE layer structure proposed by Eigen et al <ref type="bibr" target="#b15">[16]</ref> and Shazeer et al <ref type="bibr" target="#b30">[31]</ref> is to achieve conditional computation <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b11">12]</ref>, where only parts of a network are active on a per-example basis. For each input example, the model is able to select only a subset of experts by the gating network conditioned on the input.  </p><formula xml:id="formula_6">= h k ( f k (x )),<label>(6)</label></formula><p>where</p><formula xml:id="formula_7">f k (x ) = n i=1 k (x ) i f i (x ).<label>(7)</label></formula><p>See Figure <ref type="figure" target="#fig_0">1</ref> (c) for an illustration of the model structure.</p><p>Our implementation consists of identical multilayer perceptrons with ReLU activations. The gating networks are simply linear transformations of the input with a softmax layer:</p><formula xml:id="formula_8">k (x ) = softmax(W k x ),<label>(8)</label></formula><p>where W k ∈ R n×d is a trainable matrix. n is the number of experts and d is the feature dimension. Each gating network can learn to "select" a subset of experts to use conditioned on the input example. This is desirable for a exible parameter sharing in the multi-task learning situation. As a special case, if only one expert with the highest gate score is selected, each gating network actually linearly separates the input space into n regions with each region corresponding to an expert. The MMoE is able to model the task relationships in a sophisticated way by deciding how the separations resulted by di erent gates overlap with each other. If the tasks are less related, then sharing experts will be penalized and the gating networks of these tasks will learn to utilize di erent experts instead. Compared to the Shared-Bottom model, the MMoE only has several additional gating networks, and the number of model parameters in the gating network is negligible. Therefore the whole model still enjoys the bene t of knowledge transfer in multi-task learning as much as possible.</p><p>To understand how introducing separate gating network for each task can help the model learn task-speci c information, we compare with a model structure with all tasks sharing one gate. We call it One-gate Mixture-of-Experts (OMoE) model. This is a direct adaption of the MoE layer to the Shared-Bottom multi-task model. See Figure <ref type="figure" target="#fig_0">1</ref> (b) for an illustration of the model structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">MMOE ON SYNTHETIC DATA</head><p>In this section, we want to understand if the MMoE model can indeed better handle the situation where tasks are less related. Similar to Section 3.3, we conduct control experiments on the synthetic data to investigate this problem. We vary the task correlation of the synthetic data and observe how the behavior changes for different models. We also conduct a trainability analysis and show that MoE based models can be more easily trained compared to Shared-Bottom models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Performance on Data with Di erent Task Correlations</head><p>We repeat the experiments in section 3. (1) For all models, the performance on the data with higher correlation is better than that on the data with lower correlation. <ref type="bibr" target="#b1">(2)</ref> The gap between performances on data with di erent correlations of the MMoE model is much smaller than that of the OMoE model and the Shared-Bottom model. This trend is especially obvious when we compare the MMoE model with the OMoE model: in the extreme case where the two tasks are identical, there is almost no di erence in performance between the MMoE model and the OMoE model; when the correlation between tasks decreases, however, there is an obvious degeneration of performance for the OMoE model while there is little in uence on the MMoE model. Therefore, it's critical to have task-speci c gates to model the task di erences in the low relatedness case. (3) Both MoE models are better than the Shared-Bottom model in all scenarios in terms of average performance. This indicates that the MoE structure itself brings additional bene ts. Following this observation, we show in the next subsection that the MoE models have better trainability than the Shared-Bottom model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Trainability</head><p>For large neural network models, we care much about their trainability, i.e., how robust the model is within a range of hyper-parameter settings and model initializations.</p><p>Recently, Collins et al <ref type="bibr" target="#b9">[10]</ref> nd that some gated RNN models (like LSTM and GRU) we thought to perform better than the vanilla RNN are simply easier to train rather than having better model capacities. While we have demonstrated that MMoE can better handle the situation where tasks are less related, we also want to have a deeper understanding how it behaves in terms of trainability.</p><p>With our synthetic data, we can naturally investigate the robustness of our model against the randomness in the data and model initialization. We repeat the experiments under each setting multiple times. Each time the data are generated from the same distribution but di erent random seeds and the models are also initialized di erently. We plot the histogram of the nal loss values from repeated runs in Figure <ref type="figure" target="#fig_2">5</ref>.</p><p>There are three interesting observations from the histogram. First, in all task correlation settings, the performance variances of Shared-Bottom model are much larger than those of the MoE based model. This means that Shared-Bottom models in general have much more poor quality local minima than the MoE based models do. Second, while the performance variance of OMoE models is similarly robust as that of MMoE models when task correlation is 1, the robustness of the OMoE has an obvious drop when the task correlation decreases to 0.5. Note that the only di erence between MMoE and OMoE is whether there is a multi-gate structure. This validates the usefulness of the multi-gate structure in resolving bad local minima caused by the con ict from task di erence. Finally, it's worth to observe that the lowest losses of all the three models are comparable. This is not surprising as neural networks are theoretically universal approximator. With enough model capacity, there should exist a "right" Shared-Bottom model that learns both tasks well. However, note that this is the distribution of 200 independent runs of experiments. And we suspect that for larger and more complicated model (e.g. when the shared bottom network is a recurrent neural network), the chance of getting the "right" model of the task relationship will be even lower. Therefore, explicitly modeling the task relationship is still desirable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">REAL DATA EXPERIMENTS</head><p>In this section, we conduct experiments on real datasets to validate the e ectiveness of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Baseline Methods</head><p>Besides the Shared-Bottom multi-task model, we compare our approach with several state-of-the-art multi-task deep neural network models that attempt to learn the task relationship from the data. <ref type="bibr" target="#b14">[15]</ref>: This method is designed for a cross-lingual problem with two tasks. In this method, parameters used for di erent tasks are shared softly by an L2 constraint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L2-Constrained</head><p>Given k as the ground truth label for task k, k ∈ 1, 2, the prediction of task k is represented as</p><formula xml:id="formula_9">ˆ k = f (x; θ k ),</formula><p>where θ k are model parameters.</p><p>The objective function of this method is</p><formula xml:id="formula_10">EL( 1 , f (x; θ 1 )) + EL( 2 , f (x; θ 2 )) + α θ 1 − θ 2 2 2</formula><p>where 1 , 2 are the ground truth label for task 1 and task 2, and α is a hyper-parameter. This method models the task relatedness with the magnitude of α.</p><p>Cross-Stitch <ref type="bibr" target="#b26">[27]</ref>: This method shares knowledge between two tasks by introducing a "Cross-Stitch" unit. The Cross-Stitch unit takes the input of separated hidden layers x 1 and x 2 from task 1 and 2, and outputs xi 1 and xi 2 respectively by the following equation: xi</p><formula xml:id="formula_11">1 xi 2 = α 11 α 12 α 21 α 22 x i 1 x i 2 ,</formula><p>where α jk , j, k = 1, 2 is a trainable parameter representing the cross transfer from task k to task j. The x1 and x2 are sent to the higher level layer in task 1 and task 2 respectively.</p><p>Tensor-Factorization <ref type="bibr" target="#b33">[34]</ref>: In this method, weights from multiple tasks are modeled as tensors and tensor factorization methods are used for parameter sharing across tasks. For our comparison, we implement Tucker decomposition for learning multi-task models, which is reported to deliver the most reliable results <ref type="bibr" target="#b33">[34]</ref>. For example, given input hidden-layer size m, output hidden-layer size n and task number k, the weights W, which is a m × n × k tensor, is derived from the following equation:</p><formula xml:id="formula_12">W = r 1 i 1 r 2 i 2 r 3 i 3 S(i 1 , i 2 , i 3 ) • U 1 (:, i 1 ) • U 2 (:, i 2 ) • U 3 (:, i 3 ),</formula><p>where tensor S of size r 1 × r 2 × r 3 , matrix U 1 of size m × r 1 , U 2 of size n × r 2 , and U 3 of size k × r 3 are trainable parameters. All of them are trained together via standard backpropagation. r 1 , r 2 and r 3 are hyper-parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Hyper-Parameter Tuning</head><p>We adopt a hyper-parameter tuner, which is used in recent deep learning frameworks <ref type="bibr" target="#b9">[10]</ref>, to search the best hyperparameters for all the models in the experiments with real datasets. The tuning algorithm is a Gaussian Process model similar to Spearmint as introduced in <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b31">32]</ref>. To make the comparison fair, we constrain the maximum model size of all methods by setting a same upper bound for the number of hidden units per layer, which is 2048. For MMoE, it is the "number of experts" × "hidden units per expert". Our approach and all baseline methods are implemented using TensorFlow <ref type="bibr" target="#b0">[1]</ref>.</p><p>We tune the learning rates and the number of training steps for all methods. We also tune some method-speci c hyper-parameters:</p><p>• MMOE: Number of experts, number of hidden units per expert. • L2-Constrained: Hidden-layer size. Weight α of the L2 constraint. • Cross-Stitch: Hidden-layer size, Cross-Stitch layer size.</p><p>• Tensor-Factorization: r 1 , r 2 , r 3 for Tuck Decomposition, hidden-layer size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Census-income Data</head><p>In this subsection, we report and discuss experiment results on the census-income data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1">Dataset Description.</head><p>The UCI census-income dataset <ref type="bibr" target="#b1">[2]</ref> is extracted from the 1994 census database. It contains 299,285 instances of demographic information of American adults. There are 40 features in total. We construct two multi-task learning problems from this dataset by setting some of the features as prediction targets and calculate the absolute value of Pearson correlation of the task labels over 10,000 random samples:</p><p>(1) Task 1: Predict whether the income exceeds $50K; Task 2: Predict whether this person's marital status is never married. Absolute Pearson correlation: 0.1768. (2) Task 1: Predict whether the education level is at least college;</p><p>Task 2: Predict whether this person's marital status is never married. Absolute Pearson correlation: 0.2373.</p><p>In the dataset, there are 199,523 training examples and 99,762 test examples. We further randomly split test examples into a validation dataset and a test dataset by the fraction of 1:1.</p><p>Note that we remove education and marital status from input features as they are treated as labels in these setups. We compare MMoE with aforementioned baseline methods. Since both groups of tasks are binary classi cation problems, we use AUC scores as the evaluation metrics. In both groups, we treat the marital status task as the auxiliary task, and treat the income task in the rst group and the education task in the second group as the main tasks. For hyper-parameter tuning, we use the AUC of the main task on the validation set as the objective. For each method, we use the hyper-parameter tuner conducting thousands of experiments to nd the best hyper-parameter setup. After the hyper-parameter tuner nds the best hyper-parameter for each method, we train each method on training dataset 400 times with random parameter initialization and report the results on the test dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.2">Results</head><p>. For both groups, we report the mean AUC over 400 runs, and the AUC of the run where best main task performance is obtained. Table <ref type="table" target="#tab_2">1</ref> and Table <ref type="table" target="#tab_3">2</ref> show the results of two groups of tasks. We also tune and train single-task models by training a separate model for each task and report their results. Given the task relatedness (roughly measured by the Pearson correlation) is not very strong in either group, the Shared-Bottom model is almost always the worst among multi-task models (except for Tensor-Factorization). Both L2-Constrained and Cross-Stitch have separate model parameters for each task and add constraints on how to learn these parameters, and therefore perform better than Shared-Bottom. However, having constraints on model parameter learning heavily relies on the task relationship assumptions, which is less exible than the parameter modulation mechanism used by MMoE. So MMoE outperforms other multi-task models in all means in group 2, where the task relatedness is even smaller than group 1.</p><p>The Tensor-Factorization method is the worst in both groups. This is because it tends to generalize the hidden-layer weights for all of the tasks in lower rank tensor and matrices. This method can be very sensitive to task relatedness, since it tends to over-generalize when tasks are less related, and needs more data and longer time to train.</p><p>The multi-task models are not tuned for the auxiliary marital status task on validation set while the single-task model is. So it is reasonable that the single-task model gets the best performance on the auxiliary task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Large-scale Content Recommendation</head><p>In this subsection, we conduct experiments on a large-scale content recommendation system in Google Inc., where the recommendations are generated from hundreds of millions of unique items for billions of users. Speci cally, given a user's current behavior of consuming an item, this recommendation system targets at showing the user a list of relevant items to consume next.</p><p>Our recommendation system adopts similar framework as proposed in some existing content recommendation frameworks <ref type="bibr" target="#b10">[11]</ref>, which has a candidate generator followed by a deep ranking model. The deep ranking model in our setup is trained to optimize for two types of ranking objectives: (1) optimizing for engagement related objectives such as click through rate and engagement time; (2) optimizing for satisfaction related objectives, such as like rate. Our training data include hundreds of billions of user implicit feedbacks such as clicks and likes. If trained separately, the model for each task needs to learn billions of parameters. Therefore, compared to learning multiple objectives separately, a Shared-Bottom architecture comes with the bene t of smaller model size. In fact, such a Shared-Bottom model is already used in production.</p><p>6.4.1 Experiment Setup. We evaluate the multi-task models by creating two binary classi cation tasks for the deep ranking model: (1) predicting a user engagement related behavior; (2) predicting a user satisfaction related behavior. We name these two tasks as engagement subtask and satisfaction subtask.</p><p>Our recommendation system uses embeddings for sparse features and normalizes all dense features to [0, 1] scale. For the Shared-Bottom model, we implement the shared bottom network as a feedforward neural network with several fully-connected layers with ReLU activation. A fully-connected layer built on top of the shared bottom network for each task serves as the tower network. For MMoE, we simply change the top layer of the shared bottom network to an MMoE layer and keep the output hidden units with the same dimensionality. Therefore, we don't add extra noticeable computation costs in model training and serving. We also implement baseline methods such as L2-Constrained and Cross-Stitch. Due to their model architectures, they have roughly double the number of parameters comparing to the Shared-Bottom model. We do not compare with Tensor-Factorization because the computation of the Tucker product cannot scale up to billion level without heavy e ciency engineering. All models are optimized using mini-batch Stochastic Gradient Descent (SGD) with batch size 1024.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.2">O line Evaluation Results.</head><p>For o ine evaluation, we train the models on a xed set of 30 billion user implicit feedbacks and evaluate on a 1 million hold-out dataset. Given that the label of the satisfaction subtask is much sparser than the engagement subtask, the o ine results have very high noise levels. We only show the AUC scores and R-Squared scores on the engagement subtask in Table <ref type="table">3</ref>.</p><p>We show the results after training 2 million steps (10 billion examples with batch size 1024), 4 million steps and 6 million steps. MMoE outperforms other models in terms of both metrics. L2-Constrained and Cross-Stitch are worse than the Shared-Bottom model. This is likely because these two models are built upon two Table <ref type="table">3</ref>: Engagement performance on the real large-scale recommendation system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metric</head><p>AUC@2M AUC@4M AUC@6M R2@2M R2@4M R2 To better understand how the gates work, we show the distribution of the softmax gate of each task in Figure <ref type="figure" target="#fig_3">6</ref>. We can see that MMoE learns the di erence between these two tasks and automatically balances the shared and non-shared parameters. Since satisfaction subtask's labels are sparser than the engagement subtask's, the gate for satisfaction subtask is more focused on a single expert. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.3">Live Experiment Results</head><p>. At last, we conduct live experiments for our MMoE model on the content recommendation system. We do not conduct live experiments for L2-Constrained and Cross-Stitch methods because both models double the serving time by introducing more parameters.</p><p>We conduct two sets of experiments. The rst experiment is to compare a Shared-Bottom model with a Single-Task model. The Shared-Bottom model is trained on both engagement subtask and satisfaction subtask. The Single-Task model is trained on the engagement subtask only. Note that though not trained on the satisfaction subtask, the Single-Task model serves as a ranking model at test time so we can also calculate satisfaction metrics on it. The second experiment is to compare our MMoE model with the Shared-Bottom model in the rst experiment. Both experiments are done using the same amount of live tra c.</p><p>Table <ref type="table" target="#tab_5">4</ref> shows the results of these live experiments. First, by using Shared-Bottom model, we see a huge improvement on the satisfaction live metric of 19.72%, and a slight decrease of -0.22% on the engagement live metric. Second, by using MMoE, we improve both metrics comparing with the Shared-Bottom model. In this recommendation system, engagement metric has a much larger </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>We propose a novel multi-task learning approach, Multi-gate MoE (MMoE), that explicitly learns to model task relationship from data. We show by control experiments on synthetic data that the proposed approach can better handle the scenario where tasks are less related. We also show that the MMoE is easier to train compared to baseline methods. With experiments on benchmark dataset and a real large-scale recommendation system, we demonstrate the success of the proposed method over several state-of-the-art baseline multi-task learning models.</p><p>Besides the bene ts above, another major design consideration in real machine learning production systems is the computational e ciency. This is also one of the most important reasons that the Shared-Bottom multi-task model is widely used. The shared part of the model saves a lot of computation at serving time <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b28">29]</ref>. All of the three state-of-the-art baseline models (see section 6.1) learn the task relationship at the loss of this computational bene t. The MMoE model, however, largely preserves the computational advantage since the gating networks are usually light-weight and the expert networks are shared across all the tasks. Moreover, this model has the potential to achieve even better computational eciency by making the gating network as a sparse top-k gate <ref type="bibr" target="#b30">[31]</ref>. We hope this work inspire other researchers to further investigate multi-task modeling using these approaches.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: (a) Shared-Bottom model. (b) One-gate MoE model. (c) Multi-gate MoE model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Average performance of MMoE, OMoE, and Shared-Bottom on synthetic data with di erent correlations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Histogram of performance of MMoE, OMoE, and Shared-Bottom multi-task model on synthetic data with di erent correlations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Softmax Gate Distribution for Engagement and Satisfaction Subtasks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>4.2 Multi-gate Mixture-of-ExpertsWe propose a new MoE model that is designed to capture the task di erences without requiring signi cantly more model parameters compared to the shared-bottom multi-task model. The new model is called Multi-gate Mixture-of-Experts (MMoE) model, where the key idea is to substitute the shared bottom network f in Eq 1 with the MoE layer in Eq 5. More importantly, we add a separate gating network k for each task k. More precisely, the output of task k is</figDesc><table><row><cell>k</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Performance on the rst group of UCI Censusincome dataset.</figDesc><table><row><cell>Group 1</cell><cell>AUC/Income best mean</cell><cell cols="2">AUC/Marital Stat w/ best income mean</cell></row><row><cell>Single-Task</cell><cell cols="3">0.9398 0.9337 0.9933 0.9922</cell></row><row><cell>Shared-Bottom</cell><cell>0.9361 0.9295</cell><cell>0.9915</cell><cell>0.9921</cell></row><row><cell>L2-Constrained</cell><cell>0.9389 0.9359</cell><cell>0.9922</cell><cell>0.9918</cell></row><row><cell>Cross-Stitch</cell><cell cols="2">0.9406 0.9361 0.9917</cell><cell>0.9922</cell></row><row><cell cols="2">Tensor-Factorization 0.7460 0.6765</cell><cell>0.8175</cell><cell>0.8412</cell></row><row><cell>OMoE</cell><cell>0.9387 0.9319</cell><cell>0.9928</cell><cell>0.9923</cell></row><row><cell>MMoE</cell><cell>0.9410 0.9359</cell><cell cols="2">0.9926 0.9927</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Performance on the second group of UCI Censusincome dataset.</figDesc><table><row><cell>Group 2</cell><cell>AUC/Education best mean</cell><cell cols="2">AUC/Marital Stat w/ best education mean</cell></row><row><cell>Single-Task</cell><cell>0.8843 0.8792</cell><cell>0.9933</cell><cell>0.9922</cell></row><row><cell>Shared-Bottom</cell><cell>0.8836 0.8813</cell><cell>0.9927</cell><cell>0.9917</cell></row><row><cell>L2-Constrained</cell><cell>0.8855 0.8823</cell><cell>0.9923</cell><cell>0.9918</cell></row><row><cell>Cross-Stitch</cell><cell>0.8855 0.8819</cell><cell>0.9919</cell><cell>0.9921</cell></row><row><cell cols="2">Tensor-Factorization 0.7367 0.7256</cell><cell>0.7453</cell><cell>0.7497</cell></row><row><cell>OMoE</cell><cell>0.8852 0.8813</cell><cell>0.9915</cell><cell>0.9912</cell></row><row><cell>MMoE</cell><cell>0.8860 0.8826</cell><cell>0.9932</cell><cell>0.9924</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Live experiment results indicates con dence interval level 90% ** indicates con dence interval level 95% raw value than the satisfaction metric, and it is desirable to have no engagement metric loss or even gains while improving satisfaction metric.</figDesc><table><row><cell>Live experiment</cell><cell cols="2">Engagement Metric Satisfaction Metric</cell></row><row><cell>Shared-Bottom</cell><cell></cell><cell></cell></row><row><cell>Improvement over</cell><cell>-0.22% *</cell><cell>19.72% **</cell></row><row><cell>Single-Task</cell><cell></cell><cell></cell></row><row><cell>MMoE</cell><cell></cell><cell></cell></row><row><cell>Improvement over</cell><cell>0.25% **</cell><cell>2.65% **</cell></row><row><cell>Shared-Bottom</cell><cell></cell><cell></cell></row></table><note>*</note></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts. In Proceedings of The 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD '18). ACM, New York, NY, USA, 10 pages.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Tensor ow: Large-scale machine learning on heterogeneous distributed systems</title>
		<author>
			<persName><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eugene</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Craig</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Je</forename><surname>Rey Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04467</idno>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">UCI machine learning repository</title>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Asuncion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Newman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Ask the gru: Multitask learning for deep text recommendations</title>
		<author>
			<persName><forename type="first">Trapit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM Conference on Recommender Systems</title>
				<meeting>the 10th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="107" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A model of inductive bias learning</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Baxter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res.(JAIR)</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2000">2000. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A theoretical framework for learning from a pool of disparate data sources</title>
		<author>
			<persName><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reba</forename><surname>Schuller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining</title>
				<meeting>the eighth ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="443" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Exploiting task relatedness for multiple task learning</title>
		<author>
			<persName><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reba</forename><surname>Schuller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lecture notes in computer science</title>
				<imprint>
			<date type="published" when="2003">2003. 2003</date>
			<biblScope unit="page" from="567" to="580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Estimating or propagating gradients through stochastic neurons for conditional computation</title>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Léonard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1308.3432</idno>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multitask learning</title>
		<author>
			<persName><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning to learn</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="95" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multitask learning: A knowledge-based source of inductive bias</title>
		<author>
			<persName><surname>Caruna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning: Proceedings of the Tenth International Conference</title>
				<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Jasmine</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Sussillo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.09913</idno>
		<title level="m">Capacity and Trainability in Recurrent Neural Networks</title>
				<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep neural networks for youtube recommendations</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Covington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emre</forename><surname>Sargin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM Conference on Recommender Systems</title>
				<meeting>the 10th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="191" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Low-rank approximations for conditional feedforward computation in deep neural networks</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Itamar</forename><surname>Arel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.4461</idno>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Large scale distributed deep networks</title>
		<author>
			<persName><forename type="first">Greg</forename><surname>Je Rey Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajat</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthieu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><surname>Quoc V Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1223" to="1231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Parallelizing exploration-exploitation tradeo s in gaussian process bandit optimization</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Desautels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><forename type="middle">W</forename><surname>Burdick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3873" to="3923" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Low Resource Dependency Parsing: Cross-lingual Parameter Sharing in a Neural Network Parser</title>
		<author>
			<persName><forename type="first">Long</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="845" to="850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">David</forename><surname>Eigen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><forename type="middle">'</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.4314</idno>
		<title level="m">Learning factored representations in a deep mixture of experts</title>
				<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Pathnet: Evolution channels gradient descent in super neural networks</title>
		<author>
			<persName><forename type="first">Chrisantha</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dylan</forename><surname>Banarse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yori</forename><surname>Zwols</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.08734</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fast r-cnn</title>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
				<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Understanding the di culty of training deep feedforward neural networks</title>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth International Conference on Arti cial Intelligence and Statistics</title>
				<meeting>the Thirteenth International Conference on Arti cial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Geo</forename><surname>Rey Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Je</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<title level="m">Distilling the knowledge in a neural network</title>
				<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Adaptive mixtures of local experts</title>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">A</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Nowlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geo</forename><surname>Rey E Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="79" to="87" />
			<date type="published" when="1991">1991. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Google&apos;s multilingual neural machine translation system: enabling zeroshot translation</title>
		<author>
			<persName><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxim</forename><surname>Quoc V Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonghui</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernanda</forename><surname>Thorat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName><surname>Corrado</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.04558</idno>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05137</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">One Model To Learn Them All. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning with whom to share in multi-task feature learning</title>
		<author>
			<persName><forename type="first">Zhuoliang</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristen</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning</title>
				<meeting>the 28th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="521" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
				<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06114</idno>
		<title level="m">Multi-task sequence to sequence learning</title>
				<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Cross-stitch networks for multi-task learning</title>
		<author>
			<persName><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martial</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3994" to="4003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multi-task learning for recommender system</title>
		<author>
			<persName><forename type="first">Xia</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2nd Asian Conference on Machine Learning</title>
				<meeting>2nd Asian Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="269" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Faster R-CNN: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">An overview of multi-task learning in</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05098</idno>
	</analytic>
	<monogr>
		<title level="m">deep neural networks</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Azalia</forename><surname>Mirhoseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krzysztof</forename><surname>Maziarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geo</forename><surname>Rey Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Je</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.06538</idno>
		<title level="m">Outrageously large neural networks: The sparsely-gated mixture-of-experts layer</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Practical bayesian optimization of machine learning algorithms</title>
		<author>
			<persName><forename type="first">Jasper</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2951" to="2959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning Structured Weight Uncertainty in Bayesian Neural Networks</title>
		<author>
			<persName><forename type="first">Shengyang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changyou</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Carin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Arti cial Intelligence and Statistics</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1283" to="1292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.06391</idno>
		<title level="m">Deep multi-task representation learning: A tensor factorisation approach</title>
				<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Improving user topic interest pro les by behavior factorization</title>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lichan</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</title>
				<meeting>the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1406" to="1416" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
