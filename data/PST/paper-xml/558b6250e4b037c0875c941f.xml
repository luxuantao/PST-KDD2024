<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">NETWORK PERFORMANCE EVALUATION USING FRAME SIZE AND QUALITY TRACES OF SINGLE-LAYER AND TWO-LAYER VIDEO: A TUTORIAL</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Seeling</surname></persName>
						</author>
						<author>
							<persName><roleName>AND</roleName><forename type="first">Martin</forename><surname>Reisslein</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Beshan</forename><surname>Kulapala</surname></persName>
						</author>
						<title level="a" type="main">NETWORK PERFORMANCE EVALUATION USING FRAME SIZE AND QUALITY TRACES OF SINGLE-LAYER AND TWO-LAYER VIDEO: A TUTORIAL</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E23526C464DD4DE69EBCED3CBFF48424</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Video traffic is widely expected to account for a large portion of the traffic in future wireline and wireless networks, as multimedia applications are becoming increasingly popular. Consequently, the performance evaluation of networking architectures, protocols, and mechanisms for video traffic becomes increasingly important. Video traces, which give the sizes, deadlines, and qualities of the individual video frames in a video sequence, have been emerging as convenient video characterizations for networking studies. In this tutorial we give an introduction to the use of video traces in networking studies. First we give a brief overview of digital video and its encoding and playout. Then we present a library of traces of single-and two-layer encoded video. We discuss the statistical properties of the traces and the resulting implications for the transport of video over networks. Finally we discuss the factors that need to be considered when using video traces in network performance evaluations.</p><p>In particular, we introduce performance metrics that quantify the quality of the delivered video. We outline a procedure for generating video load for network simulations from the traces, and discuss how to meaningfully analyze the outcomes of these simulations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ith the increasing popularity of networked multimedia applications, video data is expected to account for a large portion of the traffic in the Internet of the future and next-generation wireless systems. For transport over networks, video is typically encoded (i.e., compressed) to reduce the bandwidth requirements. Even compressed video, however, requires large bandwidths of the order of hundreds of kb/s or Mb/s, as will be shown later in this tutorial. In addition, compressed video streams typically exhibit highly variable bit rates (VBR) as well as long range dependence (LRD) properties, as will be demonstrated later in this tutorial. This, in conjunction with the stringent Quality of Service (QoS) requirements (loss and delay) of video traffic, makes the transport of video traffic over communication networks a challenging problem. As a consequence, in the last decade the networking research community has witnessed an explosion in research on all aspects of video transport. The characteristics of video traffic, video traffic modeling, as well as protocols and mechanisms for the efficient transport of video streams, have received a great deal of interest among networking researchers and network operators.</p><p>Significant research effort has gone into the development of coding schemes that are tailored for video transport over networks and heterogeneous receiver-oriented display. Networks provide variable bit rates for video streams and may drop packets carrying video data (especially when wireless links are involved). The devices used for video display (e.g., TV sets, laptop computers, PDAs, cell phones) vary widely in W S U R V E Y S their display formats (screen sizes), and processing capabilities. Also, users may want different display formats and qualities for different application scenarios.</p><p>Clearly, one way to provide the different video formats and qualities is to encode each video into different versions, each a single layer encoding with a fixed format and quality. The main drawbacks of versions are the increased storage requirement at the origin video server and the video proxy caches distributed throughout the network, and the need to stream multiple versions into the network to be able to quickly adapt to variations in the available bandwidth at a downstream link, for example, on a wireless last hop. Scalable encoded video overcomes these drawbacks and can provide the different video formats and qualities with one encoding. With conventional scalable encoding, the video is encoded into a base layer and one or multiple enhancement layers. The base layer provides a basic video quality, and each additional enhancement layer provides quality improvement. With these layered (hierarchical) encodings, the video quality (and required bit rate for transport) can be adjusted at the granularity of layers.</p><p>Given these developments in video coding it is widely expected that the encoded video carried over the Internet of the future and next-generation wireless systems will be heterogeneous in several aspects. First, future networks will carry video coded using a wide variety of encoding schemes, such as H.263, H.263+, MPEG-2, MPEG-4, divx, RealVideo, and WindowsMedia. Second, future networks will carry video of different quality levels, such as video coded with different spatial resolutions and/or signal to noise ratios (SNR). Third, and perhaps most importantly, the video carried in future networks will be to a large extent scalable encoded video since this type of video facilitates heterogeneous multimedia services over heterogeneous wire-line and wireless networks, as noted above.</p><p>Typically, studies on the network transport of video use video traces. Video frame size traces -the simplest form of video traces -give the sizes of each individual encoded video frame. Single layer MPEG-1 encoded videos have been available since the mid 1990s <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>. More elaborate video traces containing frame sizes as well as frame qualities have recently become available <ref type="bibr" target="#b5">[6]</ref>. These more elaborate traces have become available for single-layer encoded video of different video formats and quality levels, as well as scalable encoded video. In this tutorial we explain how to conduct meaningful network studies with video traces, covering the spectrum from single frame size traces of single-layer MPEG-1 encoded video to elaborate traces of scalable MPEG-4 encodings.</p><p>This tutorial serves three main objectives:</p><p>•The communications and networking generalist who has no specific knowledge of video signal processing is introduced to the basic concepts of digital video and the characterization of encoded video for networking studies. In particular, we explain the basic principles that are employed in the common video coding standards and describe how these principles are employed to generate scalable (layered) video. We also explain the timing of the playout process of the digital video on the screen of the client device.</p><p>•We provide the reader with an overview of the main statistical characteristics of the video traffic and quality for single-layer and two-layer encoded video. We present the average traffic rates and qualities and the traffic and quality variabilities for encodings with different levels of video quality. We summarize the main insights from the statistical analysis of the traces in recommendations for the use of video traces in networking studies.</p><p>•We introduce the reader who is familiar with basic network performance analysis and network simulation to the unique issues that arise when using video traces in network simulations. In particular, we explain how to estimate the starvation probabilities and the video quality from simulations with video traces. We discuss the factors that need to be considered when generating a video traffic workload from video traces for the simulation of a network. We finally explain how to meaningfully analyze and interpret the outcomes of these simulations.</p><p>Overall, the objective of this tutorial is to enable networking generalists to design networking protocols and mechanisms for the transport of encoded video that take the properties of the video traffic into consideration. Furthermore, the goal is to enable the networking generalist to design and carry out simulations to evaluate performance using video traces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OVERVIEW OF VIDEO CODING AND PLAYOUT</head><p>In this section we give an introduction to the basic principles employed in video compression (coding). We first introduce digital video, which is the input to the video coder. We also discuss the implications of video coding on the playout of the video after network transport. The issues relating to the evaluation of the network transport, that is, the evaluation of network metrics such as packet delay and loss and link utilization, as well as the evaluation of the quality of the received video, are discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OVERVIEW OF DIGITAL VIDEO</head><p>Digital video consists of video frames (images) that are displayed at a prescribed frame rate; a frame rate of 30 frames/sec is used in the National Television Standards Committee (NTSC) video. The reciprocal of the frame rate gives the display time of a frame on the screen and is commonly referred to as frame period. Each individual video frame consists of picture elements (usually referred to as pixels or pels). The frame format specifies the size of the individual frames in terms of pixels. The ITU-R/CCIR-601 format (the common TV format) has 720 × 480 pixels (i.e., 720 pixels in the horizontal direction and 480 pixels in the vertical direction), while the Common Intermediate Format (CIF) format has 352 × 288 pixels, and the Quarter CIF (QCIF) format has 176 × 144 pixels. The CIF and QCIF formats are typically considered in network related studies. Each pixel is represented by three components: the luminance component (Y), and the two chrominance components, hue (U) and intensity (V). (An alternative representation is the RGB (red, green, and blue) representation, which can be converted to (and from) YUV with a fixed conversion matrix. We focus on the YUV representation, which is typically used in video encoder studies.) Since the human visual system is less sensitive to the color information than to the luminance information, the chrominance components are typically sub-sampled to one set of U and V samples per four Y samples. Thus, with chroma subsampling there are 352 × 288 Y samples, 176 × 144 U samples, and 176 × 144 V samples in each CIF video frame. Each sample is typically quantized into 8 bits, resulting in a frame size of 152,064 bytes for an uncompressed CIF video frame (and a corresponding bit rate of 36.5 Mb/s).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PRINCIPLES OF NON-SCALABLE VIDEO ENCODING</head><p>In this section we give a brief overview of the main principles of non-scalable (single-layer) video encoding (compression), we refer the interested reader to <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref> for more details. We focus in this overview on the principles employed in the MPEG and H.26x standards and note that most commercial codecs, such as RealVideo and WindowsMedia, are derived from these standards. The two main principles in MPEG and H.26x video coding are intra-frame coding using the discrete cosine transform (DCT), and inter-frame coding using motion estimation and compensation between successive video frames.</p><p>In intra-frame coding each video frame is divided into blocks of 8 × 8 samples of Y samples, U samples, and V samples. Each block is transformed using the DCT into a block of 8 × 8 transform coefficients, which represent the spatial frequency components in the original block. These transform coefficients are then quantized by an 8 × 8 quantization matrix that contains the quantization step size for each coefficient. The quantization step sizes in the quantization matrix are obtained by multiplying a base matrix by a quantization scale. This quantization scale is typically used to control the video encoding. A larger quantization scale gives a coarser quantization, resulting in a smaller size (in bits) of the encoded video frame as well as a lower quality. The quantized coefficients are then zigzag scanned, run-level coded, and variable-length coded to achieve further compression.</p><p>In inter-frame coding, MPEG introduced the frame types intra-coded (I), inter-coded (P), and bidirectional coded (B); similar frame types exist in H.26x video coding. These different frame types are organized into so called groups of pictures (GoPs). More specifically, the sequence of frames from a given I frame up to and including the frame preceding the next I frame is referred to as one GoP. The pattern of I, P, and B frames that make up a GoP is commonly referred to as GoP pattern or GoP structure. A typical GoP pattern with three P frames in a GoP and two B frames before and after each P frame is illustrated in Fig. <ref type="figure">1</ref>. The different frame types are encoded as follows. In an I frame all blocks are intracoded as outlined above. In a P frame the macroblocks (whereby a macroblock consists of four blocks of 8 × 8 samples) are inter-coded (as explained shortly) with reference to the preceding I or P frame, that is, the preceding I or P frame serves as a forward reference, as illustrated by the solid arrows in Fig. <ref type="figure">1</ref>. In a B frame the macroblocks are intercoded with reference to the preceding I or P frame, which serves as forward reference, and the succeeding I or P frame, which serves as backward reference, as illustrated by the dashed arrows in Fig. <ref type="figure">1</ref>.</p><p>To intercode a given macroblock the best matching macroblock in the reference frame(s) is determined and identified by a motion vector; this process is commonly referred to as motion estimation. Any (typically small) difference between the block to be encoded and the best matching block is transformed using the DCT, quantized, and coded as outlined above; this process is commonly referred to as motion compensation. If a good match cannot be found in the reference frame(s), then the macroblock is intra coded. (In the optional 4MV mode the above processes are applied to blocks instead of macroblocks.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PRINCIPLES OF SCALABLE VIDEO ENCODING</head><p>With conventional layered encoding the video is encoded hierarchically into a base layer and one (or more) enhancement layer(s). Decoding the base layer provides a basic video quality, while decoding the base layer together with the enhancement layer(s) provides an enhanced video quality. MPEG has standardized the following scalability modes: data partitioning, temporal, spatial, and signal-to-noise (SNR). We briefly review the temporal and spatial scalability modes as they are considered in the later discussion of the trace statistics.</p><p>With temporal scalable encoding the enhancement layer frames are interleaved between base layer frames. Each enhancement layer frame is inter-coded with reference to the immediately preceding base layer frame and the immediately succeeding base layer frame (as illustrated in Fig. <ref type="figure">2</ref>) for a scenario where I and P frames form the base layer and B frames form the enhancement layer.</p><p>The base layer of the temporal scalable encoding provides a basic video quality with a low frame rate. Adding the enhancement layer to the base layer increases the frame rate. Note that the base layer can be decoded independently of the enhancement layer since each base layer frame is only encoded with reference to another base layer frame. On the other hand, the enhancement layer requires the base layer for decoding since the enhancement layer frames are encoded with reference to base layer frames.</p><p>With spatial scalability the base layer provides a small video format (e.g., QCIF); adding the enhancement layer increases the video format (e.g., to CIF). The base layer of the spatial n n n nFIGURE 1. Typical MPEG group of pictures (GoP) pattern with references used for predictive coding of P and B frames. scalable encoding can be up-sampled to give a coarse video at the larger format. To generate a spatial scalable encoding, the original (uncompressed) video is first downsampled to the smaller base layer format and the downsampled video is encoded employing the intra and inter coding techniques described above. A base layer consisting of only I and P frames is illustrated in Fig. <ref type="figure">3</ref>. The encoded base layer is subsequently decoded and upsampled. The difference between a decoded and upsampled base layer frame and the corresponding uncompressed frame is then encoded using the DCT transform coding (and possibly intercoding within the enhancement layer). More specifically, a given enhancement layer frame can be encoded with reference to the corresponding base layer frame, which is referred to as backward reference in this context, and with respect to a preceding frame in the enhancement layer, which serves as forward reference. In the example illustrated in Fig. <ref type="figure">3</ref> the enhancement layer frames are coded as either P or B frames. A P frame in the enhancement layer is coded with reference to the corresponding I frame in the base layer. A B frame in the enhancement layer is coded with reference to the corresponding P frame in the base layer and the preceding P frame in the enhancement layer. We close this overview of scalable encoding by noting that aside from the layered coding considered here a number of other methods to achieve scalable encoding have been developed. Fine granular scalability (FGS) <ref type="bibr" target="#b8">[9]</ref> encodes the video into a base layer and one enhancement layer. The special property of the FGS enhancement layer is that it can be cut anywhere at the granularity of bits allowing the video stream to finely adapt to changing network bandwidths. With conventional layered coding, on the other hand, the video stream can only adapt at the granularity of complete enhancement layers. With Multiple Description Coding (MDC) <ref type="bibr" target="#b9">[10]</ref> the video is encoded into several streams (descriptions). Each of the descriptions contributes to the decoded video quality. Decoding all the descriptions gives the high video quality while decoding an arbitrary subset of the descriptions results in lower quality. This is in contrast to conventional hierarchical layered videos where a received enhancement layer is useless if the corresponding base layer is missing. With wavelet transform coding <ref type="bibr" target="#b10">[11]</ref> a video frame is not divided into blocks, as with the DCT-based MPEG coding. Instead, the entire frame is coded into several subbands using the wavelet transform. We note that these methodss to achieve scalable video coding are beyond the scope of this article. This article is focused on the network performance evaluation for conventional nonscalable (single-layer) and layered (hierarchical) encoded video, for which traces are currently publicly available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIDEO PLAYOUT</head><p>The intercoding of the video frames has important implications for the video playout at the receiver, which we explain in this section, as these implications affect the structure of video traces and video traffic simulations. Recall that a P frame is encoded with reference to the preceding I or P frame and that a B frame is encoded with reference to the preceding I(P) frame and the succeeding P(I) frame. In any case, the reference frame(s) must be decoded before the decoding of the intercoded P or B frame can commence. Consider, for instance, the GoP pattern IBBPBBPBBPBBIBBP…, with three P frames between two successive I frames and two B frames between successive I(P) and P(I) frames. With the considered GoP pattern, the decoder needs both the preceding I (or P) and the succeeding P (or I) frame for decoding a B frame. Therefore, the encoder emits the frames in the order IPBBPBBPBBIBBP…, which we refer to as the codec sequence. In contrast, we refer to the frame order IBBPBBPBBPBBIBBP… as the display sequence since the video frames are displayed in that order on the screen.</p><p>To better understand the start of the playout process consider the scenario in Fig. <ref type="figure">4</ref>, in which the frames are received in the coded sequence. In the depicted scenario the reception of the first I frame commences at time zero and is completed at time T, which denotes the frame period of the video. Each subsequent frame takes T seconds for reception. The decoding of the first B frame commences at time 3T, and we sup-  pose for illustration that the decoding of a frame takes δ seconds. Thus, the first B frame is available for display at time 3T + δ, allowing us to commence the playback by displaying the first I frame at time 2T + δ. Next consider the scenario in which the encoded frames are received in the display sequence. For this scenario it is straightforward to verify with a similar argument that the playback can commence at time 3T + δ.</p><formula xml:id="formula_0">n</formula><p>We briefly note that the difference between the codec sequence and the display sequence can be exploited to relax the delivery deadlines of the I and P frames <ref type="bibr" target="#b11">[12]</ref>. In the scenario illustrated in Fig. <ref type="figure">4</ref> the I frame is not needed at the decoding client until time 2T to ensure that it is decoded and ready for display at time 2T + δ. Similarly, the P frame is not needed until the time 3T, assuming that both the P and the first B frame can be decoded within δ seconds to ensure that the B frame is available for display at time 3T + δ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DIFFERENT TYPES OF VIDEO CHARACTERIZATION FOR NETWORK PERFORMANCE EVALUATION</head><p>Generally, there are three different methods to characterize encoded video for the purpose of networking research: video bit stream, video traffic trace, and video traffic model.</p><p>The video bit stream, which is generated using the encoding mechanisms presented in the preceding section, contains the complete video information. The traffic characterization (e.g., the frame size) can be obtained by measuring the traffic or by parsing the bit stream. The video quality can be determined by subjective (viewing) evaluation <ref type="bibr" target="#b12">[13]</ref> or objective methods <ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref>. The advantage of the bit stream is that it allows for networking experiments where the quality of the video -after suffering losses in the network -is evaluated, as in <ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref>. One limitation of the bit stream is that it is very large in size: several GBytes for one hour of compressed video or several tens of GBytes for one hour of uncompressed video. Another limitation of bit streams is that they are usually proprietary and/or protected by copyright. This limits the access of networking researchers to bit streams, and also limits the exchange of bit streams among research groups.</p><p>Video traces are an alternative to bit streams. While the bit streams give the actual bits carrying the video information, the traces only give the number of bits used for the encoding of the individual video frames, as described in the following section in more detail. Thus, there are no copyright issues.</p><p>Video traffic models, which can be derived from video traces, have received a great deal of attention in the literature (see, for example, <ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref>). The goal of a traffic model is to capture the essential properties of the real traffic in an accurate, computationally efficient, and preferably mathematically tractable description that should also be parsimonious, that is, require only a small number of parameters. A traffic model is typically developed based on the statistical properties of a set of video trace samples of the real video traffic. The developed traffic model is verified by comparing the traffic it generates with the video traces. If the traffic model is deemed sufficiently accurate, it can be used for the mathematical analysis of networks, for model driven simulations, and also for generating so called virtual (synthetic) video traces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STRUCTURE OF VIDEO TRACES</head><p>In this section we give a general overview of video trace structures and define the quantities in the traces. First we intro-duce the notation for the traffic and quality characterization of the video. Let N denote the number of video frames in a given trace. Let t n , n = 0, …, N -1, denote the frame period (display time) of frame n. Let T n , n = 1, …, N, denote the cumulative display time up to (and including) frame n -1, that is, T n = Σ k=0 n-1 t k (and define T 0 = 0). Let X n , n = 0, …, N -1, denote the frame size (number of bit or byte) of the encoded (compressed) video frame n. Let Q n Y , n = 0, …, N -1, denote the quality of the luminance component of the encoded (and subsequently decoded) video frame n (in dB). Similarly, let Q n U and Q n V , n = 0, …, N -1, denote the qualities of the two chrominance components hue (U) and saturation(V) of the encoded video frame n (in dB).</p><p>A video trace gives these defined quantities typically in an ASCII file with one line per frame. Some traces give only the frame sizes X n ; these traces are often referred to as terse. Verbose traces, on the other hand, give several of the defined quantities. For example, a line of a verbose trace may give frame number n, cumulative display time T n , frame type (I, P, or B), frame size X n (in bit), and luminance quality Q n Y (in dB) for frame n.</p><p>Generally, for layered encodings the base layer trace gives the frame sizes of the base layer and the quality values for the decoded base layer, while the enhancement layer traces give the sizes of the encoded video frames in the enhancement layer and the improvement in the quality obtained by adding the enhancement layer to the base layer (i.e., the difference in quality between the aggregate (base + enhancement layer) video stream and base layer video stream). In other words, the base layer traces give the traffic and quality of the base layer video stream. The enhancement layer traces give the enhancement layer traffic and the quality improvement obtained by adding the enhancement layer to the base layer.</p><p>A subtlety in the traces is the order of the frames, which may depend on the GoP pattern. In particular, some video traces give the frames in the display sequence, while others give the frames in the codec sequence, which we introduced earlier. The frame index n, n = 0, …, N -1, however, always refers to the position of the corresponding frame in the display sequence. As an example consider the GoP pattern IBBPBBPBBPBBIBBP…, with three P frames between two successive I frames and two B frames between successive I(P) and P(I) frames. If the frames are ordered in the display sequence in the trace, then frame n, n = 0, 1, …, N -1, is on line n of the trace. On the other hand, if the frames are ordered in the codec sequence in the trace, then frame n = 0 is on line 0, frame number n = 3 is on line 1, frames 1 and 2 are on lines 2 and 3, frame 6 on line 4, and frames 4 and 5 on lines 5 and 6, and so on. This subtlety must be considered when using traces in networking studies, as elaborated above.</p><p>In summary, in this section we have provided a general overview of the different structures of video traces. The various available collections of video traces can be categorized according to the structure used in the traces. The collections <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>, for instance, have adopted the terse format and give the frames in the display sequence. The collection <ref type="bibr" target="#b5">[6]</ref>, which we study in the next section, provides both verbose traces with frames in the codec sequence as well as terse traces with frames in the display sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIDEO TRACE STATISTICS</head><p>In this section we present a publicly available library of traces of heterogeneous and scalable encoded video. The traces have been generated from more than 15 videos of one hour each, which have been encoded into a single layer at heterogeneous qualities and into two layers using the temporal scalability and spatial scalability modes of MPEG-4. Due to space constraints we include here only a brief overview of the trace library and the trace statistics and refer the interested reader to <ref type="bibr" target="#b5">[6]</ref> for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIDEOS AND ENCODER MODES</head><p>We consider the traces of the videos in Table <ref type="table">1</ref>. All considered videos are 60 minutes long, corresponding to 108,000 frames, and are in the QCIF format. For spatial scalable encoding only 30 minutes (54,000 frames) of the videos in the CIF format are considered. We consider the encodings without rate control with the fixed quantization scales in Table <ref type="table" target="#tab_6">2</ref>, where we use the abbreviation (x, y, z) to refer to the quantization scales for I, P, and B frames, as is common in video encoding studies. For the rate control encodings we consider TM5 <ref type="bibr" target="#b32">[33]</ref> rate control with the target bit rate settings summarized in Table <ref type="table" target="#tab_2">3</ref>.</p><p>The base layer of the considered temporal scalable encoding gives a basic video quality by providing a frame rate of 10 frames per second. Adding the enhancement layer improves the video quality by providing the (original) frame rate of 30 frames per second. With the considered spatial scalable encoding, the base layer provides video frames that are one fourth of the original size (at the original frame rate), that is, the number of pixels in the video frames is cut in half in both the horizontal and vertical direction. (These quarter-size frames can be up-sampled to give a coarse grained video with the original size.) Adding the enhancement layer to the base layer gives the video frames in the original size (format).</p><p>For each video and scalability mode we have generated traces for videos encoded without rate control and for videos encoded with rate control. For the encodings without rate control we keep the quantization parameters fixed, which produces nearly constant quality video (for both the base layer and the aggregate (base + enhancement layer) stream, respectively) but highly variable video traffic. For the encodings with rate control we employ the TM5 rate control, which strives to keep the bit rate around a target bit rate by varying the quantization parameters, and thus the video quality. We apply rate control only to the base layer of scalable encodings and encode the enhancement layer with fixed quantization parameters. Thus, the bit rate of the base layer is close to a constant bit rate, while the bit rate of the enhancement layer is highly variable. This approach is motivated by networking schemes that provide constant bit rate transport with very stringent Quality of Service for the base layer, and variable bit rate transport with less stringent Quality of Service for the enhancement layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SINGLE-LAYER ENCODED VIDEO</head><p>In this section we give an overview of the video traffic and quality statistics of the single-layer encodings, which are studied in detail in <ref type="bibr" target="#b33">[34]</ref>. In Table <ref type="table">4</ref> we give an overview of the elementary frame size and bit rate statistics. We consider the average frame size X -, the coefficient of variation CoV X (defined as the standard deviation of the frame size normalized by the mean frame size), the peak-to-mean ratio of the frame size X max /X -, and the mean and peak bit rates, as well as the average PSNR quality Q -and the coefficient of the quality variation CoQV. We note that the PSNR does not completely capture the many facets of video quality. However, analyzing a large number of videos subjectively becomes impractical. Moreover, recent studies have found that the PSNR is as good a measure of video quality as other more sophisticated objective quality metrics <ref type="bibr" target="#b34">[35]</ref>. As the PSNR is well defined only for the luminance (Y) component <ref type="bibr" target="#b35">[36]</ref>, and since the human visual system is more sensitive to small changes in the luminance, we focus on the luminance PSNR values.</p><formula xml:id="formula_1">n</formula><p>For a compact presentation we report for each metric the minimum, mean, and maximum of the set of videos given in Table <ref type="table">1</ref>. This presentation, which we adopt for most tables in this article, conveys the main characteristics of the different encoding and scalability modes. However, it does not convey the impact of the different video genres and content features on the video traffic and quality, for which we refer to <ref type="bibr" target="#b5">[6]</ref>.</p><p>Focusing for now on the encodings without rate control, we observe that the coefficient of variation CoV X and the peak-tomean ratio X max /X -increase as the quantization scales increase (i.e., as the video quality decreases), indicating that the video traffic becomes more variable. As the quality decreases further, the coefficient of variation and peak-to-mean ratio decrease. In other words, we observe a concave shape of the coefficient of variation and the peak-to-mean ratio of the frame sizes as a function of the encoded video quality, with a maximum of the coefficient of variation and the peak to mean ratio for intermediate video quality. This concavity has important implications for resource allocation for video traffic in networks. The maximum in the peak-to-mean frame size ratio for the intermediate video quality, for instance, results in a small mean network utilization for this quality level when allo-cating network resources according to the peak rate.</p><p>Next we examine the GoP sizes. Recall that a GoP consists of the group of frames from an I frame up to and including the frame preceding the next I frame. We refer to the sum of the sizes of the frames in a GoP as the GoP size (in bit) and denote it by Y. From Table <ref type="table">4</ref> we observe that the coefficient of variation and the peak-to-mean ratios of the GoP size also exhibit a concave shape with a maximum at an intermediate quality level. These observations build on earlier studies <ref type="bibr" target="#b36">[37]</ref> which considered a smaller range of the quantization scale and uncovered only an increasing trend in the coefficient of variation and the peak-to-mean ratio for increasing quantization scales (i.e., decreasing video quality). While the origins of this concave shape of the coefficient of variation and the peak to mean ratio of the frame sizes are under investigation in ongoing work, we can draw some immediate guidelines for networking studies, which are detailed later.</p><p>Next we observe that the encodings with rate control with target bit rates of 64 kb/s and 128 kb/s tend to have significantly larger coefficients of variation than the encodings without rate control. This is primarily because the employed TM5 rate control algorithm allocates target bit rates to each of the frame types (I, P, and B) and thus provides effective rate control at the GoP time scale, with potentially large variations of the individual frame sizes. Even with TM5 rate control, however, there are some small variations in the GoP sizes (see Table <ref type="table">4</ref>). These variations are mostly due to relatively few outliers, resulting in the quite significant peak-to-mean ratio, yet very small coefficient of variation. (As a side note, we remark that the 128 kb/s and 256 kb/s target bit rates are met perfectly (in the long run average), while the 64 kb/s is not always met. This is because the employed encoder does not n n n nTable 4. Overview of frame statistics of single-layer traces (QCIF). <ref type="bibr">(</ref> allow for quantization scales smaller than <ref type="bibr" target="#b29">(30,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b29">30)</ref>, which gives average bit rate above 64 kb/s for some videos.) Both the typically very large frame size variations with rate control, and the residual variation at the larger GoP time scale, need to be taken into consideration in networking studies. An important aspect of video traffic is its correlation over time <ref type="bibr" target="#b37">[38]</ref>. For a first assessment of the correlations in video traffic we consider the autocorrelation function of the frame sizes, that is, of the series { X 0 , X 1 , …, X N -1 }, and the autocorrelation function of the GoP sizes. In Fig. <ref type="figure">5</ref> we plot these autocorrelation functions for the (4, 4, 4) encoding of the Star Wars video. We observe from Fig. <ref type="figure">5</ref> (left) that the autocorrelation function of the frame sizes consists of a periodic "spike" pattern that is superimposed on a decaying curve. The periodic spike pattern is due to the MPEG frame types in a GoP. In particular, I frames are typically the largest frames, resulting in the high spikes that are spaced 12 frames apart in the autocorrelation function. The P frames are typically smaller than the I frames but larger than the B frames, resulting in the three intermediate spikes. The B frames are typically the smallest frames, resulting in the two small autocorrelation values between successive spikes due to I and P frames. The autocorrelation function of the GoP sizes plotted in Fig. <ref type="figure">5</ref> (right) gives a better picture of the underlying decay of the autocorrelation function. We observe that this autocorrelation function decays relatively slowly. For a lag of 100 GoPs, which correspond to approximately 40 seconds, the autocorrelation coefficient is approximately 0.15. This indicates fairly significant correlations over relatively long time periods, which are mainly due to the correlations in the content of the video (e.g., scenes of persistent high motion or a high level of detail). In more extensive investigations we have found that these behaviors of the frame size and GoP size autocorrelation functions are typical for encodings without rate control, whereby there are typically only minor differences between the autocorrelation functions for encodings with different quality levels. For the encodings with rate control the autocorrelation of the GoP sizes drops immediately to zero, and the frame size autocorrelation function exhibits the periodic spike pattern due to the different MPEG frame types around zero. This behavior of the autocorrelation function is a consequence of the rate control, which adjusts the quantization scales to keep the bit rate averaged over a GoP close to the specified target bit rate, independent of the video content.</p><p>To assess the long-range dependence properties of the encoded videos, we determined the Hurst parameter of the frame size traces using the R/S plot, the periodogram, the variance-time plot, and the logscale diagram (see <ref type="bibr" target="#b38">[39]</ref> for details). We have found that the encodings without rate control typically exhibit long-range dependence with the Hurst parameter typically ranging between 0.75 and 0.95. The encodings with rate control do not typically exhibit long-range dependence (except for the cases where the 64 kb/s target bit rate could not be reached due to the quantization scale being limited to at most 30). We have also found that the Hurst parameter estimates are roughly the same when comparing different quality levels.</p><p>We have also investigated the multifractal scaling characteristic of the video traffic using the wavelet-based multiscale diagram <ref type="bibr" target="#b39">[40]</ref>. We found that the linear multiscale diagram generally does not differ significantly from a horizontal line. This indicates that the video traffic is mono-fractal, that is, does not exhibit a significant multi-fractal behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TEMPORAL SCALABLE ENCODED VIDEO</head><p>Base Layer -Table <ref type="table">5</ref> summarizes the frame size and quality statistics of the base layer of the temporal scalable encoded video. Recall that in the considered temporal scalable encodings, the I and P frames constitute the base layer and the B frames constitute the enhancement layer. With the IBBPBBPBBPBBPBBIBB…GoP structure, the frame sizes X 3k+1 b and X 3k+2 b , k = 0, …, N/3 -1 are zero as these correspond to gaps in the base layer frame sequence. We observe for the encodings without rate control that the temporal base layer traffic is significantly more variable than the corresponding single-layer traffic. The peak-to-mean ratio X max b /X b of the base layer frame sizes is roughly 1.5 to 2 times larger than the corresponding X max /X -of the single-layer traces (from Table <ref type="table">4</ref>). This larger variability of the base layer of the temporal scalable encoding is due to the fact that the frames missing in the base layer are counted as zeros in the frame size analysis, that is, the frame size analysis considers a scenario where each frame is transmitted during its frame period of 33 msec and nothing is transmitted during the periods of the skipped frames. To overcome the large variabilities of the base layer we consider averaging three base layer frames, that is, an I or P frame and the subsequent two missing frames of size zero, and denote the averaged base layer frame size by X b (3) . For example, consider the base layer trace segment X I , 0, 0, X P , 0, 0, where X I and X P denote the size of an I and P frame, respectively. With three-frame smoothing this trace segment n n n nFIGURE 5. Autocorrelation function for frame sizes (left) and GoP sizes (right) of single-layer encoding with quantization scales <ref type="bibr" target="#b3">(4,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b3">4)</ref> of the Star Wars IV video. becomes X I /3, X I /3, X I /3, X P /3, X P /3, X P /3. We observe from Table <ref type="table">5</ref> that with this averaging (smoothing), which is equivalent to spreading the transmission of each base layer frame over three frame periods (100 msec), the variability of the base layer traffic is dramatically reduced. We also observe that the X max b(3) /X b is typically one half to two thirds of the corresponding X max /X -in Table <ref type="table">4</ref>. Noting that the peak-to-mean ratio of the time series X I /3, X I /3, X I /3, X P /3, X P /3, X P /3,… is equal to the peak-to-mean ratio of the time series X I , X P , …, that is, the time series containing only the sizes of the I and P frames, we may conclude from this observation that the I and P frames are relatively less variable in size compared to the B frames. This has been confirmed in more extensive studies <ref type="bibr" target="#b5">[6]</ref> and is intuitive as B frames can cover the entire range from being completely intra-coded (e.g., when a scene change occurs at that frame) to being completely inter-coded.</p><p>For the encodings with rate control, we observe from Table <ref type="table">5</ref> in comparison with Table <ref type="table">4</ref> that the smoothed (over three frames or GoP) base layers are significantly less variable than the corresponding single layer encodings. This is again primarily due to the generally smaller variability of the I and P frames in the base layer. The peak bit rates of the 128 kb/s and 256 kb/s base layers with GoP smoothing are typically less than 200 kb/s and 300 kb/s, respectively. This enables the transport of the base layer with rate control over reliable constant bit rate network "pipes," provisioned, for instance, using the guaranteed services paradigm <ref type="bibr" target="#b40">[41]</ref>. We note, however, that even the rate controlled base layers smoothed over GoPs require some over-provisioning since the peak rates are larger than the average bit rates. In more detailed studies <ref type="bibr" target="#b41">[42]</ref> we have found that the excursions above (and below) the average bit rate are typically short-lived. Therefore, any of the com-mon smoothing algorithms (e.g., <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44]</ref>) should result in a reduction of the peak rates of the GoP streams to rates very close to the mean bit rate with a moderately sized smoothing buffer. In addition, we note that the TM5 rate control employed in our encodings is a basic rate control scheme that is standardized and widely used. More sophisticated and refined rate control schemes (e.g., <ref type="bibr" target="#b44">[45]</ref>) may further reduce the variability of the traffic. In summary, we recommend using our traces obtained with TM5 rate control in scenarios where the video traffic is smoothed over the individual frames in a GoP (which incurs a delay of approximately 0.4 sec) or use some other smoothing algorithm. Now turning to the video frame PSNR quality, we observe that the average quality Q -is significantly lower and the variability in the quality significantly larger compared to the single-layer encoding. This severe drop in quality and increase in quality variation are due to decoding only every third frame and displaying it in place of the missing two B frames. The reduction in quality with respect to the single-layer encoding is not as severe for the rate controlled encodings, which now can allocate the full target bit rate to the I and P frames.</p><p>Enhancement Layer -The main observations from the enhancement layer traffic statistics in Table <ref type="table">6</ref> are a very pronounced maximum in the variability and a relatively large variability, even when smoothing the two B frames over three frame periods or over a GoP. For the enhancement layers corresponding to the base layers with rate control, we observe that the average enhancement layer bit rate decreases as the target bit rate of the base layer increases. This is to be expected as the higher bit rate base layer contains a more accurate encoding of the video, leaving less n n n nTable 5. Overview of frame statistics for the base layer of temporal scalability (QCIF). </p><formula xml:id="formula_2">-b CoV X b X max b /X X -b X X -b /T X max b /T CoV X b(3) X max b(3) /X X -b CoV Y b Y max b /Y -b Q -b</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CoQV b Encoding mode [kbyte] [Mb/s] [Mb/s] [dB]</head><p>information to be encoded in the enhancement layer. We also observe that the enhancement layers of the rate controlled layers tend to have a somewhat higher variability than the (10, 14, 16) single-layer encoding, which uses the same quantization parameters as the enhancement layer of the rate-controlled base layer.</p><p>Aggregate (Base + Enhancement Layer) Stream -Table <ref type="table">7</ref> gives the traffic and quality statistics of the aggregate (base+enhancement layer) streams with temporal scalability. We observe that for the encodings without rate control, the aggregate stream statistics are approximately equal to the corresponding statistics of the single layer encodings (in Table <ref type="table">4</ref>). Indeed, we have verified that for encodings without rate control, extracting the I and P frames out of a singlelayer encoding is equivalent to the base layer of a temporal scalable encoding. Extracting the B frames out of a singlelayer encoding gives a stream equivalent to the enhancement layer of a temporal scalable encoding. This is to be expected since temporal scalable encoding adds essentially no overhead. The situation is fundamentally different for the temporal scalable encodings with rate control, where the rate-controlled base layer and the open-loop encoded enhancement layer are aggregated. If rate control is employed for the base layer encoding, the obtained base layer is very different from the I and P frame sequence of a single-layer encoding (both when the single layer is encoded with and without rate control). Similarly, the enhancement layer obtained from an actual temporal scalable encoding with a rate controlled base layer is quite different from the B frame sequence of a single-layer encoding, even though the enhancement layer of the temporal scalable encoding is coded with fixed quantization parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SPATIAL SCALABLE ENCODED VIDEO</head><p>In this section we give an overview of the video traffic and quality statistics of spatial scalable encoded video, which are studied in detail in <ref type="bibr" target="#b45">[46]</ref>. In the considered spatial scalable encoding the base layer provides the video in QCIF format.</p><p>Adding the enhancement layer to the base layer gives the video in the CIF format. Table <ref type="table">8</ref> gives an overview of the videos that have been studied for spatial scalability.</p><p>Base Layer -Table <ref type="table">9</ref> gives an overview of the frame size and quality statistics of the base layers of the spatial scalable encodings. Focusing for now on the encodings without rate control, we observe again a concave shape of the coefficients of variation and the peak-to-mean ratios of both the frame sizes and (somewhat less pronounced) the GoP sizes with maxima at intermediate quality levels. Comparing these base layers which provide the video in the QCIF format with the single layer QCIF video in Table <ref type="table">4</ref>, we observe that the frame size, bit rate, and GoP size statistics are roughly the same. The observed differences are primarily due to considering a different set of videos in the spatial scalability study. A comparison for the individual videos <ref type="bibr" target="#b5">[6]</ref> reveals that the traffic statistics of the QCIF base layer are typically almost identical to the corresponding statistics of the single-layer QCIF encodings.</p><p>Next consider the frame qualities of the base layer in Table <ref type="table">9</ref>. These qualities are obtained by up-sampling the QCIF base layer frames to CIF format and comparing these CIF frames with the original CIF frames. We observe that the PSNR qualities of these up-sampled base layer frames are n n n nTable 6. Overview of frame statistics of the enhancement layers of temporal scalability. <ref type="bibr">(</ref> quite low compared to the single-layer QCIF frames. In fact, the mean frame qualities are quite similar to the PSNR qualities of the temporal base layer. The traffic characteristics of the base layers with rate control are generally similar to the corresponding traffic statistics of the single-layer encodings. In particular, the rate controlled base layers exhibit quite significant traffic variability even at the GoP level (and in particular for small bit rates), which may require substantial over-provisioning or smoothing to reliably transmit the base layer. This is in contrast to the base layer of the temporal scalable encoding, which exhibited smaller traffic variability at the GoP level. The primary reason for this phenomenon is that, as noted earlier, the temporal base layer dedicates the entire target bit rate to the less variable (when viewed at the GoP level) I and P frames.</p><p>Enhancement Layer -From the summary of the statistics of the enhancement layer of the spatial scalable encodings in Table <ref type="table">10</ref> we first observe for the encodings with fixed quan-tization scales that the mean frame sizes and bit rates of the enhancement layer are roughly three times larger than the corresponding base layer frame sizes and bit rates. This is to be expected as the enhancement layer stream increases the frame format from one quarter of the CIF format to the full CIF format. Next we observe that the coefficient of variation of the frame sizes and the GoP sizes of the enhancement layer as a function of the encoded quality level exhibit a concave shape with a maximum at an intermediate quality level and decreasing coefficient of variation and peak to mean ratio for lower quality levels. The peak-to-mean ratio of the frame sizes, on the other hand, only increases with increasing quantization scales (i.e., decreasing video quality). This effect is the subject of ongoing studies. Another noteworthy observation is that the GoP size variability of the enhancement layer is significantly larger than for the base layer (or the single-layer QCIF video), especially for larger quantization scales. This indicates that the enhancement layer is typically more difficult to accommodate in packet-switched networks.</p><p>n n n nTable 7. Overview of frame statistics of the aggregate (base + enhancement layer) stream with temporal scalability. <ref type="bibr">(</ref> Next, we turn to the enhancement layers corresponding to the base layers encoded with rate control. These enhancement layers are encoded with the fixed quantization scales <ref type="bibr" target="#b9">(10,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b15">16)</ref>. Similar to the encodings with temporal scalability, we observe that the average enhancement layer traffic decreases as the target bit rate for the base layer increases. We also observe that the variability of the enhancement layers corresponding to the rate controlled base layers is slightly higher than the variability of the enhancement layer of the encoding with fixed (10, 14, 16) quantization scales.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Aggregate (Base + Enhancement Layer) Stream -In</head><p>Table <ref type="table">11</ref> we summarize the traffic and quality statistics of the aggregate spatial scalable stream which gives the video in the CIF format. For comparison we provide in Table <ref type="table" target="#tab_6">12</ref> the traffic and quality statistics of single-layer CIF format encodings of the videos. For the encodings without rate control, we observe that the aggregate spatial scalable video tends to have larger average frame and GoP sizes and bit rates as well as lower PSNR quality. This is primarily due to the overhead of spatial scalable encodings. In a more detailed study we determined this overhead by comparing the bit rates of aggregate spatial and single-layer encodings with essentially the same average PSNR quality to be approximately 20 percent <ref type="bibr" target="#b45">[46]</ref>. Aside from this overhead, the statistics of the aggregate spatial scalable encodings and the corresponding single-layer CIF encodings are quite similar. Note, however, that the frame sizes and bit rates of the spatial scalable encodings with rate control are significantly larger than the corresponding frame sizes and bit rates of the single-layer CIF encodings. This is because the fixed target bit rate is allocated to the QCIF-sized base layer in the spatial scalable encodings, whereas it is allocated to the full CIF-sized video in the single-layer encodings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUMMARY OF INSIGHTS FROM TRACE STATISTICS</head><p>We now briefly summarize the main insights from the video trace statistics presented in the preceding sections. We have learned that video traffic typically exhibits a concave shape of the traffic variability (in terms of the coefficient of variation or peak-to-mean ratio of the frame or GoP sizes) as a function of the encoded video quality, with a maximum in the traffic variability at an intermediate quality level. We have observed this phenomenon for single-layer encoded video as well as for the individual layers of layered encoded video. This phenomenon, which can critically affect the resource utilization in networks, requires the network engineer to pay attention to the quality level (or mix of quality levels) of the video that is to be transported over the network under study.</p><p>We have reconfirmed the fairly well known effect of longrange dependence in the video traffic. From our study of video encoded with rate control (both single-layer video and the rate controlled base layer of scalable video), we have found that rate controlled video may exhibit significant variability over short time scales (e.g., within a GoP) and typically has a small level of traffic variability over longer time scales. Rate controlled video may thus require a simple smoothing technique (e.g., traffic averaging for fixed time intervals) for the short-time scale traffic fluctuations and some additional smoothing over longer time scales to fit into constant bit rate channels. From our study of temporal scalable encoded video we have found that smoothing the transmission of the frames n n n n Table <ref type="table">9</ref>. Overview of frame statistics for the base layer of spatial scalability (CIF). <ref type="bibr">(</ref> </p><formula xml:id="formula_3">-b CoV X b X max b /X -b X -b /T X max b /T CoV Y b Y max b /Y -b Q -b</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CoQv b Encoding mode [kbyte] [Mb/s] [Mb/s] [dB]</head><p>of one layer over the gaps created by the frames in the other layer (e.g., the three-frame smoothing in the context of the form of temporal scalable encoding considered earlier) reduces the variability of the layer traffic dramatically. An important aspect of the video trace statistics that was not explicitly studied in the preceding sections is the content dependency of the statistics. For a compact presentation we have reported the minimum, mean, and maximum across the videos in Table <ref type="table">1</ref> for each statistical metric. It is important to keep in mind, however, that the traffic and quality statistics of the encoded video depend on the video content and generally differ according to the content quite significantly from video to video, as indicated by the Min to Max ranges in the above tables. When evaluating a network it is thus important to consider a mix of videos that is representative of the typical mix of videos supported by the network. We also note that there are additional genres of videos with content quite different from the genres considered here. One such example are lecture videos employed in distance education. These videos have quite different content dynamics, resulting in correspondingly different traffic and quality statistics from the entertainment and sports videos considered here (see <ref type="bibr" target="#b5">[6]</ref>). This needs to be taken into consideration when designing and evaluating networks dedicated to special applications, such as distance education.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>USING VIDEO TRACES IN NETWORK PERFORMANCE EVALUATIONS</head><p>In this section we discuss the issues involved in using video traces in network performance evaluation studies. We focus primarily on how to use the traces in simulations, but our dis-cussions apply analogously for using traces as a basis for traffic modeling. Our focus throughout this section is on the aspects that are unique to simulations using video traces. For general instructions on how to conduct simulations we refer to the standard simulation textbooks, for example, <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b47">48]</ref>.</p><p>There are three broad areas that require special consideration when using video traces in simulations: the definition of the video-related performance metrics; the generation of the video traffic work load for the system under study; and the statistically sound estimation of the performance metrics of interest. We discuss these three areas in the following three subsections. We note that the purpose of our discussions is not to develop a specific simulation design to evaluate a specific set of performance metrics for a particular network set-up. Instead, our goal is to explain the issues and considerations involved in simulations using video traces in general terms, so as to enable the reader to design simulations that use video traces for the specific networking systems of interest to the reader and to obtain meaningful insights from such simulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIDEO RELATED PERFORMANCE METRICS</head><p>Simulations with video traces can be used to evaluate conventional network performance metrics, such as the utilization of networking resources, the delay and delay jitter, buffer occupancies, and buffer overflow probabilities, for networks carrying video traffic. In addition, simulations with video traces can be used to evaluate performance metrics that are related to the video, namely the starvation probability and the video quality. These two metrics give some indication of the quality of the video delivered to the user over the network under study.</p><p>n n n nTable 10. Overview of frame statistics of the enhancement layers of spatial scalability. <ref type="bibr">(</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Encoding mode [kbyte] [Mb/s] [Mb/s]</head><p>Starvation Probability -Starvation (loss) probability comes in two main forms. The frame starvation probability is the long-run fraction of video frames that miss their decoding (playout) deadline, that is, those frames that are not completely delivered to the receiver by the time the receiver needs them to start the decoding. The frame starvation probability may be estimated for individual clients or for the complete system under study.</p><p>The information loss probability is the long-run fraction of encoding information (bits) that misses its decoding (playout) deadline. The information loss probability has a finer granularity than the frame loss probability because a partially delivered frame is considered as one lost frame toward the frame loss probability (irrespective of how much of the frame was delivered/not delivered in time), whereas the information loss probability counts only the fraction of the frame's information bits that were not delivered in time. As an illustrative example consider the transmission of 10 frames each of size 240 bits to a client, and suppose only 120 bits of the first frame are delivered on time (and the other 120 bits arrive after the decoding deadline). Also suppose the remaining nine frames are all completely delivered ahead of their respective decoding deadlines. In this scenario the frame loss probability is 1/10 = 10 percent, whereas the information loss probability is 120/(10 ⋅ 240) = 5 percent. We note that in this example and throughout this discussion so far on the loss probability, we have ignored the dependencies between the encoded video frames. Specifically, in an MPEG encoding, the I frame in a GoP is required to decode all other P and B frames in the GoP (as well as the B frames in the preceding GoP encoded with reference to the I frame starting the next GoP). Thus, the loss of an I frame is essentially equivalent to the loss of all the frames in the GoP (as well as some frames in the preceding GoP). Similarly, a given P frame is required to decode all the successive P frames in the same GoP as well as the B frames encoded with respect to these P frames. Thus, the loss of a P frame is equivalent to the loss of all these dependent frames.</p><p>The information loss probability is mainly motivated by error concealment and error resilience techniques <ref type="bibr" target="#b48">[49]</ref> that allow for the decoding of partially received video frames. Error resilience techniques are currently a subject of intense research efforts, and more advances in this area are to be expected. The deployment of these techniques may be affected by the required computational effort and energy, which are often limited in wireless devices.</p><p>Video Quality -The frame loss probability and information loss probability are convenient performance metrics for video networking as they can be directly obtained from network simulation with video traces. However, these loss probabilities are to a large extend still "network" metrics and provide only limited insight into the video quality perceived by the user. It is certainly true that a smaller loss probability corresponds in general to a higher video quality. However, it is difficult to quantify this relationship, because the rate-distortion curves of encoders relate only the bit rates of completely received streams (layers) to the corresponding PSNR video quality. Hence, we should keep in mind that the PSNR provides only a limited, albeit widely used, characterization of the video quality. If a part of a stream (layer) is lost, the video quality can no longer be obtained from the encoder rate-distortion curve. In general, experiments with actual encoders, decoders, n n n nTable 11. Overview of frame statistics of the aggregate (base + enhancement layer) stream with spatial scalability (CIF). <ref type="bibr">(</ref> and video data are required to obtain the video quality after lossy network transport. There are, however, scenarios in which it is possible to obtain the approximate PSNR video quality after lossy network transport. One such scenario is the network transport of layered encoded video with priority for the base layer, that is, the enhancement layer data is dropped before the base layer data when congestion arises. First consider temporal scalable encoded video in this context. If an enhancement layer frame is completely received (and all the frames that are used as encoding references are also completely received), then the PSNR quality of the frame is obtained by adding the base layer PSNR quality of the frame (from the base layer trace) and the enhancement layer PSNR quality improvement of the frame (from the enhancement layer trace). If all the referenced frames are completely received and a part of or all of the enhancement layer is lost, then one can (conservatively) approximate the quality of the frame by the PSNR quality of the base layer trace. If a part or all of a frame that serves as a reference frame for the encoding of other frame(s) is lost, for example, a P frame (in the base layer) of the encoding considered in Fig. <ref type="figure">2</ref>, then all frames that depend on the (partially) lost reference frame are affected. The quantitative impact of such a loss can currently only be determined from experiments with the actual video. Note that quantitatively capturing such losses in traces would require a separate trace for each possible combination of reference frame loss (e.g., only the last P frame in the GoP is lost, only the second to last P frame is lost, etc.), in conjunction with different error concealment mechanisms. For network researchers using the currently available traces it appears reasonable to approximate the PSNR quality of the lost reference frame and all dependent frames by a very small PSNR value, e.g., less than 20 dB. In summary, the impact of losses of enhancement layer frames (without any dependent frames), for example, losses of B frames in Fig. <ref type="figure">2</ref>, can be assessed with fairly reasonable accuracy using the PSNR values in the trace structures outlined earlier. If frames that are referenced by other frames suffer losses, then the impact is very difficult to assess and only very rough approximations can be made. Generally, when transporting video it is recommended to stay within an operating regime where losses are limited to B frames, since losses of I and P frames typically deteriorate the video quality quite significantly.</p><p>Next consider scalable encoded video where each video frame has a base layer component and an enhancement layer component, for example, the spatial scalable encoding considered earlier. If a frame is completely received, then the PSNR quality of the received frame is the PSNR quality of the base layer frame (from the base layer trace) plus the PSNR quality improvement of the enhancement layer (from the enhancement layer trace). If the base layer component of the frame is completely received but a part (or all) of the enhancement layer of the frame is lost, then one can approximate the quality of the received frame by the PSNR quality of the base layer frame. Finally, if a part (or all) of the base layer is lost, then one has to roughly approximate the quality of the received frame by a very small PSNR value. This discussion so far has ignored frame dependencies, which are illustrated in Fig. <ref type="figure">3</ref> for a typical spatial scalable encoding scenario. Assessing the impact of losses in a frame component that is referenced by some other frame requires experiments with actual videos. For simulations using traces, it is again recommended to stay in an operation range that completely avoids the loss of refer-n n n nTable 12. Overview of frame statistics of the single layer stream (CIF). <ref type="bibr">(</ref> enced frame components.</p><p>Another scenario in which one can assess the video quality of the received video after lossy network transport is transcoding (also referred to as the cropping scenario <ref type="bibr" target="#b49">[50]</ref>). In this scenario single-layer encoded video is transported through a network. Whenever congestion arises the video is transcoded <ref type="bibr" target="#b50">[51]</ref> to a lower quality (corresponding to a larger quantization scale, so that the transcoded video fits into the available bandwidth). This scenario can be (approximately) simulated using the single-layer video traces by switching to the trace of a lower-quality encoding of the same video.</p><p>To conclude this section on video quality as a performance metric in video trace simulations, we note that the received video quality is generally maximized by maximizing the average frame quality and minimizing the quality variations. More specifically, the received video quality is maximized by maximizing the qualities of the individual video frames and minimizing the variations in quality between consecutive video frames.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GENERATING VIDEO TRAFFIC WORKLOAD FROM TRACES</head><p>In this section we discuss how to generate a video traffic workload for a network under study from traces. When generating the video traffic workload there are a number of issues to consider. These issues range from choosing and preparing the video streams (traces) to the packetization of the video frames. We first address the issues at the stream level and then turn to the issues at the level of individual video frames and packets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stream-Level Considerations</head><p>Selecting the Videos (Titles) -The first consideration at the stream level is typically to select the videos (titles) to be used in the evaluation. As alluded to earlier, it is important to consider the content of the videos that will be transported over the network under study. If the network is being designed for the transport of lecture videos, for instance, then traces of lecture videos should be used in the simulations. Generally, it is advisable to select as many different videos as possible (available) from the video genre(s) that will be transported over the network. Let M denote the number of different videos selected for a given evaluation study.</p><p>Composing the Workload -Next, one needs to decide how to compose the workload from the selected set of video traces. The main consideration in composing the workload is typically whether or not the networking protocol or mechanism under evaluation exploits localities of reference. A video caching mechanism, for instance, relies on localities of reference and strives to improve the network performance by caching the most frequently requested videos. A scheduling mechanism for a router output port, on the other hand, typically does not exploit any locality of reference. Thus, for evaluations of protocols and mechanisms that exploit localities of reference the workload should be composed according to the appropriate distribution. For example, studies of streaming media servers, for example, <ref type="bibr" target="#b51">[52]</ref>, indicate that video popularity follows a Zipf distribution <ref type="bibr" target="#b52">[53]</ref>. More specially, if there are M videos available, with video 1 being the most popular and video M being the least popular, then the probability that a given request is for the mth most popular video is <ref type="bibr" target="#b0">(1)</ref> where <ref type="bibr" target="#b1">(2)</ref> The Zipf distribution is characterized by the parameter ζ ≥ 0. The larger ζ, the more localized the Zipf distribution, that is, the more popular is the most popular video. In an initial measurement study requests for streaming videos were found to be distributed according to a Zipf distribution with ζ around 0.5 <ref type="bibr" target="#b51">[52]</ref>. It has been observed that the request for movies in video rental stores and video-on-demand systems are well described by a Zipf distribution, with ζ in the vicinity of 1 <ref type="bibr" target="#b53">[54]</ref>. Furthermore, studies of Web caches indicate that requests for HTML documents and images follow approximately a Zipf distribution, with ζ in the vicinity of 1 <ref type="bibr" target="#b54">[55]</ref>. It is therefore reasonable to expect that requests for streaming videos generally follow a Zipf distribution with ζ in the range between 0.5 and 1.</p><p>If locality of reference plays no role in the studied network protocol it is reasonable to select the videos according to a discrete uniform distribution U <ref type="bibr">[1, M]</ref>, that is, each video is equally likely selected with probability 1/M to satisfy a client request. This uniform random video selection ensures that the traffic patterns in the selected mix of M videos are roughly uniformly "experienced" by the protocol under study.</p><p>Select Encoding Mode -The next step in setting up a simulation study is typically the selection of the appropriate encoding mode(s) for the individual videos. The choice of appropriate encoding mode, that is, single-layer or scalable encoded video, with or without rate control, depends largely on the particular protocol or mechanisms under study. We provide here a few general considerations and recommendations.</p><p>Generally, one should avoid scaling the video traces. By scaling we mean multiplying the size of each individual video frame by a constant to adjust the average bit rate of the video trace to some desired level. Scaling generally does not provide valid traces for the desired average bit rate. To see this, consider scaling a trace for the single-layer <ref type="bibr" target="#b3">(4,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b3">4)</ref> encoded video with high quality and bit rate to smaller bit rates see (Table <ref type="table">4</ref>). To obtain average bit rates of the trace of the <ref type="bibr" target="#b29">(30,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b29">30)</ref> encoded video, for instance, one would need to divide the size of every frame in the <ref type="bibr" target="#b3">(4,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b3">4)</ref> trace by approximately 10. The <ref type="bibr" target="#b3">(4,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b3">4)</ref> trace scaled in this manner would have the average bit rate of a <ref type="bibr" target="#b29">(30,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b29">30)</ref> trace, but the variability (CoV and peak-to-mean ratio) of the scaled (4, 4, 4) trace would still be the same as for the original <ref type="bibr" target="#b3">(4,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b3">4)</ref> trace. The variability of the (4, 4, 4) trace, however, is quite different from the variability of a <ref type="bibr" target="#b29">(30,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b29">30)</ref> trace, as is evident from Table <ref type="table">4</ref>. It is therefore generally recommended to avoid scaling the traces.</p><p>Nevertheless, for some evaluations it may be desirable and convenient to use traces for rate controlled video with a different bit rate than available. For other evaluations it may be convenient to use traces for different open-loop encoded videos, with the same average bit rate of some prespecified level. With scaling, each open-loop encoded video (title) contributes equally to the system utilization, which makes it easy to maintain a prespecified constant utilization with a mix of different videos. For these reasons it may be necessary to scale traces before using them in network simulations. In such situations it is recommended to use the trace with the average bit rate closest to the desired bit rate so that the scaling factor is as close to 1 as possible.</p><formula xml:id="formula_4">K M = + +…+ 1 1 1 2 1 ζ ζ . K m m M ζ , , , , = …<label>1</label></formula><p>Constant Utilization Simulation Scenario -We conclude this discussion of the stream-level issues by outlining the trace usage in two streaming scenarios, which may be useful for the reader in setting up his/her own networking simulation study. First we outline a "constant utilization" scenario. Suppose we wish to examine the performance of a multiplexer, scheduler, or similar network system that is fed by several streams for a specific long-run average utilization level. Furthermore, suppose that we wish to examine the system performance for open-loop VBR encoded video titles and scaled the closest traces to a common average bit rate X -/T. Let J denote the number of simultaneous video streams required to achieve a desired level of system utilization J ⋅ X -/(C ⋅ T), where C denotes the capacity of the system. For each of the J video streams we uniformly randomly select one of the M traces.</p><p>For each selected trace we independently draw a starting (frame) phase from a discrete uniform distribution U <ref type="bibr">[1, N]</ref> over the N frames in the trace. The video frames are then processed according to the protocol or mechanism under study from the starting frame onward. The next question that arises is for how long, that is, how many frames, should the mechanism under study be simulated? One option is to continue the simulation for N frames, that is, for the full length of the traces. (Note that due to the random starting frame, the end of the traces may be reached before processing all N frames. When the end of a trace is reached the trace is "wrapped around," that is, the processing continues from the beginning of the trace.) Once all N frames have been processed, we immediately randomly select a new trace and starting phase into the trace for each of the J streams. Thus there are always J streams in progress.</p><p>There are a number of variations of the outlined constant utilization simulation, which may be appropriate depending on the protocol under study. One variation is to not continue the simulation after all N frames of a trace have been processed, but to draw a random independent stream duration (bounded by N) instead. With this approach one can study the effect of new streams starting up and the stream duration (lifetime) by varying the distribution used to draw the random stream duration.</p><p>Another variation is to use the original unscaled traces to achieve a constant utilization. This is achieved by fixing the composition J 1 , J 2 , …, J M of the streams that achieves a specific utilization, . With this approach the videos are not chosen randomly. Instead, there are always J m streams with video m ongoing. For each stream a random uniform start phase into the corresponding trace is selected. When all the frames of a given trace have been processed or a stream's lifetime expires, the same video is immediately started up, but with a new independent random starting phase. Thus, with this approach the number of ongoing streams of each video title is deterministic, but the traffic is random due to the random phase profiles. The advantage of this approach is that it avoids the scaling of the videos and allows for studies with streams with heterogeneous average bit rates.</p><p>We conclude this discussion of the constant utilization approaches by noting that they are appropriate to examine performance metrics at the packet-level and burst-level time scale, such as packet loss and delay. However, the constant utilization approaches are not suitable for examining call-level metrics, such as call blocking probabilities. Therefore, we outline next a "varying utilization" simulation scenario that is appropriate for call-level evaluations, as they are required for call admission control and caching mechanisms, for instance.</p><p>Varying Utilization Simulation Scenario -To illustrate the "varying utilization" simulation scenario, suppose we wish to examine the performance of a call admission or caching mechanism that processes incoming requests for video streams. Depending on the current system load, cache contents, and traffic characteristics of the currently supported streams and the requested stream, the new request is either granted or denied.</p><p>Suppose that we have selected a set of M video traces for the evaluation. To run the simulation we need to generate requests according to some stochastic process. The Poisson process, in which the time between successive arrivals is exponentially distributed, is generally a good model for request arrivals. For each new client request we draw independently the video (e.g., according to a uniform or Zipf distribution), the starting phase, and the lifetime (duration) of the stream. Whenever the end of a stream lifetime is reached, the stream is simply removed from consideration, freeing up the system resources it occupied. The distribution of the lifetime (for which the exponential distribution is generally a good choice) and the request arrival process are adjusted to achieve the desired load level of the system. To illustrate the load-level adjustment consider a system with capacity C b/s to which requests for (scaled) video streams with an average bit rate of X -/T arrive, and suppose each accepted video stream consumes the bandwidth X -/T of the available bandwidth C. The stability limit of such a system is J max = C ⋅ T/X -streams. Let L denote the mean of the lifetime distribution in frame periods and let ρ denote the mean request arrival rate in requests per frame period. The long run average fraction of calls (requests) that can be accepted is given by <ref type="bibr" target="#b2">(3)</ref> To see this, note that 1/ρ is the average spacing between request arrivals in frame periods, and L/J max is the average spacing in frame periods between call departures (streams reaching the end of their lifetime) when the system is fully loaded. We considered scaled video streams for this illustrative calculation of the load level, because some mechanisms may give preference to requests according to the average bit rate of the requested stream. With such a preferential granting of requests, the average of the average bit rates of the currently supported streams may be quite different from the average of the average bit rates of the stream requests.</p><p>In concluding this discussion of the "varying utilization" simulation scenario, we point out one subtle issue with the average bit rates of the streams. The average bit rate of an original or scaled trace is calculated over all N frames of the trace. When generating a video stream from a trace by drawing a starting phase from a discrete uniform distribution U [1, N] over all frames in the trace, and a random lifetime, the average bit rate of a given thus generated stream may be quite different from the average bit rate of the trace. In particular, the average stream bit rate may be quite different from the average trace bit rate if the lifetime is relatively short compared to the length of the trace. This is because a short lifetime may "sample" a part of the trace that has unusual characteristics compared to the overall trace. (It should also</p><formula xml:id="formula_5">1 ρ L J max . J X T C m m m M ⋅ = ∑ 1</formula><p>be noted that in the opposite extreme with a lifetime significantly longer than the trace, and wraparound whenever the end of the trace is reached, the generated stream contains duplicate traffic patterns.) One way to enforce a desired average bit rate for each individual stream generated from a trace is to scale the randomly selected video trace segment (from the starting phase onward until the end of the stream lifetime). Such per-stream scaling, however, is computationally demanding and, as noted above, may falsify the true variability characteristics. On the other hand, by generating many (short) streams from a given trace (without any per-stream scaling) the average bit rate of the streams converges to the average bit rate of the trace. It is recommended to keep these subtleties in mind when designing and evaluating a simulation study using video traces.</p><p>Frame/Packet Level Issues -In this section we discuss the issues arising at the level of individual video frames and network packets (e.g., IP packets, data link-layer frames). A key consideration at the frame level is to determine whether a frame meets its playout deadline. This is especially important when the frame or information starvation probability is one of the considered performance metrics. Recall that the decoder in the video client consumes the frames in the codec sequence and displays the frames in the display sequence on the screen. The client suffers playout starvation when it wants to start the decoding of a video frame but has not yet fully received that frame or its reference frame(s). The client may use error concealment techniques <ref type="bibr" target="#b48">[49]</ref> to conceal the missing video information. The simplest technique is to continue displaying the last fully and on-time received frame. There is a range of more sophisticated techniques that attempt to decode partially received frames or extrapolate the missing frame from preceding frames.</p><p>A related consideration is that for many networking studies it may be preferable to simulate the transmission of frames in the IBBP… order, because the GoPs are successively transmitted with this frame order. With the IPBB… order, on the other hand, the I frame of the second GoP is transmitted before the last two B frames of the first GoP. Consequently, there is a combined total of nine P and B frames transmitted between the first two I frames and a total of 11 P and B frames between all successive I frames. This may lead to difficulties for mechanisms that smooth the video frames in individual GoPs, and also for mechanisms that exploit specific alignments of the I frames in the supported streams.</p><p>In addition, it should be noted that for many networking studies it may be appropriate to consider start-up delays introduced by the networking protocol under study in isolation from the playout commencement delay due to the MPEG encoder (discussed earlier and illustrated in Fig. <ref type="figure">4</ref>). For such studies it may very well be appropriate to assume that the first frame (I frame) is decoded and displayed at a time governed by the network protocol and the subsequent frame (B frame, when using the IBBP ordering) is independently decoded and then displayed when the frame period of the I frame expires. With such a simulation, the playout commencement delay due to the MPEG frame encoder order is added to the networkintroduced start-up delay and possibly other delay components (e.g., server delay) to give the total start-up delay experienced by the user.</p><p>Packetization -For the transport over packet-switched networks the video traffic is typically packetized, that is, the video data is packaged into packets. In general, the packetization strategy of choice can be selected from a large set of alternatives depending on the overall objective and set-up of a specific simulation. To illustrate the issues involved in the packetization of the video traffic, we discuss the packetization of the video traffic in the context of the Real Time Protocol (RTP) <ref type="bibr" target="#b55">[56]</ref>. An RTP packet consists of the 12-byte RTP header, an 8-byte UDP header, and 20-byte IPv4 header/40-byte IPv6 header. (When TCP is used for the video transport a 20byte TCP header is used instead of the UDP header.) The packetization of MPEG-4 encoded video into RTP packets is described in RFC 3016 <ref type="bibr" target="#b56">[57]</ref>. This RFC recommends that a given RTP packet carries data from only one video frame, such that the loss of an RTP packet will affect only one video frame. The amount of video data in an RTP packet should be adjusted such that the complete RTP packet (consisting of video data plus headers) is no larger than the maximum transfer unit (MTU) on the path through the network to avoid fragmentation in the network (except for wireless links that may perform fragmentation of the RTP packet carried over the wired network). In case the video frames are small it is permitted to carry multiple consecutive video frames in one RTP packet.</p><p>We note that the packet headers may contribute significantly to the total traffic, especially when low bit rate video streams are transmitted with tight real-time constraints that prohibit the grouping of multiple frames into one RTP packet. Header compression schemes have been proposed to limit the waste of bandwidth due to protocol headers in such situations (see, for example, <ref type="bibr" target="#b57">[58]</ref>).</p><p>It should also be noted that with scalable (layered) encoded video, each layer is typically packetized independently to allow for the different treatment of the layers in the network (e.g., at the IP level). Furthermore, we note that the video traces reflect only the video data; typical video display, however, consists of video and audio. The bit rate of the encoded audio is in many scenarios negligible compared to the bit rate of the encoded video (see, for example, <ref type="bibr" target="#b58">[59]</ref>). The encoded audio stream, however, is typically packetized independently from the video. This packetized audio stream may make a significant contribution to the total (video + audio) traffic.</p><p>Packet Transmission -A final consideration at the packet level is the transmission of the individual packets. First consider the simple case in which one packet carries a complete video frame. Depending on the overall simulation setup the packet may be sent at once, which may be appropriate for a packet-level simulation that keeps track of the individual packets but not the individual bits. For a fluid traffic simulation running at the granularity of frame periods, on the other hand, it may be appropriate to transmit a packet of size S bits at the constant bit rate S/T b/s over the duration of one frame period of length T secs.</p><p>If a single video frame is packetized into multiple packets, it may be appropriate (depending on how the simulation is set up) to space out the transmission instants of the individual packets equally over one frame period in a packet-level simulation, whereas in a fluid simulation the aggregate size of all the packets could be transmitted at a constant bit rate over one frame period.</p><p>Finally, consider the case in which multiple video frames are packetized into a single packet into a fluid simulation. Depending on the simulation scenario, it may be preferable to transmit this single packet over one frame period (e.g., in a real-time scenario), or to transmit it over as many frame periods as there are video frames in the packet (e.g., in a nonreal-time scenario).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ESTIMATING PERFORMANCE METRICS</head><p>In this section we discuss the analysis of the output of a simulation involving video traces in order to draw meaningful conclusions about the networking system, protocol, or mechanisms under study. As with any simulation, a key consideration when simulating a network mechanism or protocol using video traces is the statistical validity of the obtained results. We refer the reader to standard simulation texts (e.g. <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b47">48]</ref>) for general instructions on how to obtain statistically meaningful simulation results and focus here primarily on the aspects unique to simulation using video traces.</p><p>Video traces, in general, and the constant utilization and varying utilization simulation scenarios outlined earlier lend themselves both to terminating simulations and steady-state simulations. In terminating simulations, as defined in <ref type="bibr" target="#b47">[48]</ref>, several independent simulation runs are performed and the estimates of the metrics of interest are obtained by averaging the metric estimates obtained from the individual runs. A terminating simulation of the constant utilization scenario can be conducted by running several simulations, as outlined above. Each simulation is started with independently randomly selected traces, starting phases (and possibly stream lifetimes). The advantage of this terminating simulation approach is that the individual simulation runs are independent and thus the classical student t or normal distribution-based statistics can be used to evaluate the confidence intervals around the estimated sample means.</p><p>The disadvantage of the terminating simulation approach is that each simulation run needs to be "warmed up" sufficiently to remove the initial transient. While this is not a problem for system simulations that do not require any warmup (e.g., the simulation of a bufferless multiplexer for a constant utilization), the warm-up may be a significant problem for systems that need warm-up (e.g., buffered multiplexers). This problem of warming up simulations driven by self-similar input is to the best of our knowledge an open problem. We therefore only note that it is widely expected that the transient period is longer when driving simulations with self-similar input traffic and that the conventional methods (e.g., <ref type="bibr" target="#b59">[60]</ref>), may underestimate the required warm-up period. One way to mitigate this warm-up problem is to start up the entire system in steady state (in case it is known) or at least to start up the traffic load of the system at (or close to) the steady state load.</p><p>Next we consider steady-state simulations where, as defined in <ref type="bibr" target="#b47">[48]</ref>, a single (typically very long) simulation run is performed and the metrics of interest are typically obtained by averaging metric estimates obtained during independent observation periods (usually referred to as batches). A steadystate simulation with video traces can be conducted by running one long constant utilization simulation as outlined above or one long varying utilization simulation as outlined above. The advantage of the steady-state simulation is that the warm-up period (during which the system is not observed) is incurred only once. The challenge of the steady-state simulation of systems with video traces is that due to the long-range dependence in the video traffic, the metric estimates of successive (non-overlapping) observation periods (batches) are typically somewhat correlated. The problem of estimating confidence intervals from these batches has received some initial interest (e.g., the studies <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b61">62]</ref>) to which we refer for details on the estimation methods.</p><p>We note that a simple heuristic to obtain uncorrelated batches despite long-range dependent video traffic is to separate successive observation periods (batches) such that they are (approximately) independent. More specifically, the heuristic is to run the constant utilization or varying utilization simulation and to truncate the distribution of the stream duration at a specific value ∆. Then, separating successive batches by at least ∆ will ensure that none of the video streams that contribute to the traffic load during a given batch contributes to the traffic load during the next batch. This ensures that the successive batches are independent, provided the system under study has only a small amount of "memory." This heuristic provides a simple method to obtain statistically meaningful performance metrics at the expense of increased simulation duration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSION</head><p>In this tutorial we have explained how to evaluate the network performance for single-layer and two-layer encoded video using traces. We have given an overview of a library of traces of single-layer encoded video and video encoded in two layers using the temporal and spatial scalability modes. We have outlined a procedure for conducting network simulations using the traces, and we have explored the analysis of the output of such simulations.</p><p>Throughout this tutorial we have made an effort to keep the discussions general to ensure this tutorial is relevant and useful for traces of all types of single-layer and multi-layer encoded video. In addition, we have strived to provide generally valid yet detailed instructions that enable the reader to conduct simulations for any networking architecture, protocol, or mechanism.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Overview of studied encoding modes.</figDesc><table><row><cell>Class</cell><cell>Video</cell><cell>Genre</cell><cell>Quantization scale settings (from Table 2)</cell></row><row><cell>Movies</cell><cell>Citizen Kane</cell><cell>Drama</cell><cell>(30, 30, 30); (10, 14, 16); (4, 4, 4)</cell></row><row><cell></cell><cell>Die Hard I</cell><cell>Action</cell><cell>(30, 30, 30); (10, 14, 16); (4, 4, 4)</cell></row><row><cell></cell><cell>Jurassic Park I</cell><cell>Action</cell><cell>(30, 30, 30); (24, 24, 24); (10, 14, 16);</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(10, 10, 10); (4, 4, 4)</cell></row><row><cell></cell><cell>Silence of the Lambs</cell><cell>Drama</cell><cell>(30, 30, 30); (10, 14, 16); (4, 4, 4)</cell></row><row><cell></cell><cell>Star Wars IV</cell><cell>Sci-fi</cell><cell>(30, 30, 30); (24, 24, 24); (10, 14, 16);</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(10, 10, 10); (4, 4, 4)</cell></row><row><cell></cell><cell>Star Wars V</cell><cell>Sci-fi</cell><cell>(30, 30, 30); (10, 14, 16); (4, 4, 4)</cell></row><row><cell></cell><cell>The Firm</cell><cell>Drama</cell><cell>(30, 30, 30); (24, 24, 24); (10, 14, 16);</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(10, 10, 10); (4, 4, 4)</cell></row><row><cell></cell><cell>The Terminator I</cell><cell>Action</cell><cell>(30, 30, 30); (10, 14, 16); (4, 4, 4)</cell></row><row><cell></cell><cell>Total Recall</cell><cell>Action</cell><cell>(30, 30, 30); (10, 14, 16); (4, 4, 4)</cell></row><row><cell>Cartoons</cell><cell>Aladdin</cell><cell>Cartoon</cell><cell>(30, 30, 30); (10, 14, 16); (4, 4, 4)</cell></row><row><cell></cell><cell>Cinderella</cell><cell>Cartoon</cell><cell>(30, 30, 30); (10, 14, 16); (4, 4, 4)</cell></row><row><cell>Sports</cell><cell>Baseball</cell><cell>Game 7 of the 2001 World Series</cell><cell>(30, 30, 30); (10, 14, 16); (4, 4, 4)</cell></row><row><cell></cell><cell>Snowboarding</cell><cell>Snowboarding Competition</cell><cell>(30, 30, 30); (10, 14, 16); (4, 4, 4)</cell></row><row><cell>TV sequences</cell><cell>Tonight Show</cell><cell>Late Night Show</cell><cell>(30, 30, 30); (24, 24, 24); (10, 14, 16);</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(10, 10, 10); (4, 4, 4)</cell></row></table><note><p>n n nTable 1. Overview of studied video sequences in QCIF format. n n n nTable 2. Quantization scale settings for encodings without rate control.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2 )</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Frame size</cell><cell cols="2">Bit rate</cell><cell></cell><cell>GoP</cell><cell cols="2">Frame quality</cell></row><row><cell></cell><cell></cell><cell>Mean</cell><cell>CoV</cell><cell>Peak/M.</cell><cell>Mean</cell><cell>Peak</cell><cell>CoV</cell><cell>Peak/M.</cell><cell>Mean</cell><cell>CoV</cell></row><row><cell></cell><cell></cell><cell>X -b+e</cell><cell>CoV X b+e</cell><cell>X max b+e /X -b+e</cell><cell>X -b+e /T</cell><cell>X max b+e /T</cell><cell>CoV Y b+e</cell><cell>Y max b+e /Y -b+e</cell><cell>Q -b+e</cell><cell>CoQV b+e</cell></row><row><cell cols="2">Encoding mode</cell><cell>[kbyte]</cell><cell></cell><cell></cell><cell>[Mb/s]</cell><cell>[Mb/s]</cell><cell></cell><cell></cell><cell>[dB]</cell><cell></cell></row><row><cell>4, 4, 4)</cell><cell>Min</cell><cell>1.881</cell><cell>0.399</cell><cell>4.097</cell><cell>0.451</cell><cell>3.606</cell><cell>0.284</cell><cell>2.707</cell><cell>35.996</cell><cell>0.162</cell></row><row><cell></cell><cell>Mean</cell><cell>3.163</cell><cell>0.626</cell><cell>6.493</cell><cell>0.759</cell><cell>4.575</cell><cell>0.443</cell><cell>4.319</cell><cell>36.803</cell><cell>0.321</cell></row><row><cell></cell><cell>Max</cell><cell>5.488</cell><cell>0.881</cell><cell>8.884</cell><cell>1.317</cell><cell>6.174</cell><cell>0.709</cell><cell>7.372</cell><cell>37.676</cell><cell>0.620</cell></row><row><cell>(10, 10, 10)</cell><cell>Min</cell><cell>0.61</cell><cell>1.021</cell><cell>9.382</cell><cell>0.146</cell><cell>1.918</cell><cell>0.538</cell><cell>6.072</cell><cell>30.786</cell><cell>0.353</cell></row><row><cell></cell><cell>Mean</cell><cell>0.735</cell><cell>1.15</cell><cell>12.728</cell><cell>0.176</cell><cell>2.179</cell><cell>0.646</cell><cell>6.783</cell><cell>31.709</cell><cell>0.561</cell></row><row><cell></cell><cell>Max</cell><cell>0.946</cell><cell>1.363</cell><cell>16.371</cell><cell>0.227</cell><cell>2.398</cell><cell>0.802</cell><cell>7.928</cell><cell>32.459</cell><cell>0.914</cell></row><row><cell>(10, 14, 16)</cell><cell>Min</cell><cell>0.332</cell><cell>1.174</cell><cell>10.659</cell><cell>0.08</cell><cell>1.586</cell><cell>0.445</cell><cell>3.731</cell><cell>28.893</cell><cell>0.418</cell></row><row><cell></cell><cell>Mean</cell><cell>0.549</cell><cell>1.497</cell><cell>16.498</cell><cell>0.132</cell><cell>2.045</cell><cell>0.550</cell><cell>6.07</cell><cell>30.302</cell><cell>0.614</cell></row><row><cell></cell><cell>Max</cell><cell>0.877</cell><cell>2.139</cell><cell>25.477</cell><cell>0.21</cell><cell>2.708</cell><cell>0.77</cell><cell>12.348</cell><cell>31.892</cell><cell>1.207</cell></row><row><cell>(24, 24, 24)</cell><cell>Min</cell><cell>0.228</cell><cell>1.044</cell><cell>11.569</cell><cell>0.055</cell><cell>0.784</cell><cell>0.455</cell><cell>4.443</cell><cell>26.538</cell><cell>0.438</cell></row><row><cell></cell><cell>Mean</cell><cell>0.270</cell><cell>1.219</cell><cell>15.753</cell><cell>0.065</cell><cell>1.002</cell><cell>0.552</cell><cell>5.434</cell><cell>27.542</cell><cell>0.832</cell></row><row><cell></cell><cell>Max</cell><cell>0.324</cell><cell>1.565</cell><cell>19.627</cell><cell>0.078</cell><cell>1.272</cell><cell>0.749</cell><cell>6.13</cell><cell>28.748</cell><cell>1.127</cell></row><row><cell>(30, 30, 30)</cell><cell>Min</cell><cell>0.191</cell><cell>0.833</cell><cell>8.208</cell><cell>0.046</cell><cell>0.556</cell><cell>0.395</cell><cell>3.076</cell><cell>25.17</cell><cell>0.394</cell></row><row><cell></cell><cell>Mean</cell><cell>0.28</cell><cell>0.954</cell><cell>11.585</cell><cell>0.067</cell><cell>0.753</cell><cell>0.449</cell><cell>4.685</cell><cell>26.586</cell><cell>0.564</cell></row><row><cell></cell><cell>Max</cell><cell>0.391</cell><cell>1.39</cell><cell>17.926</cell><cell>0.094</cell><cell>1.104</cell><cell>0.673</cell><cell>8.442</cell><cell>28.438</cell><cell>1.033</cell></row><row><cell>64 kb/s</cell><cell>Min</cell><cell>0.42</cell><cell>0.583</cell><cell>13.026</cell><cell>0.101</cell><cell>1.594</cell><cell>0.359</cell><cell>3.031</cell><cell>26.655</cell><cell>0.566</cell></row><row><cell></cell><cell>Mean</cell><cell>0.56</cell><cell>0.893</cell><cell>20.469</cell><cell>0.134</cell><cell>2.723</cell><cell>0.422</cell><cell>4.807</cell><cell>28.713</cell><cell>0.783</cell></row><row><cell></cell><cell>Max</cell><cell>0.814</cell><cell>1.229</cell><cell>32.596</cell><cell>0.195</cell><cell>4.511</cell><cell>0.473</cell><cell>7.982</cell><cell>31.351</cell><cell>1.439</cell></row><row><cell>128 kb/s</cell><cell>Min</cell><cell>0.652</cell><cell>0.817</cell><cell>7.495</cell><cell>0.157</cell><cell>1.357</cell><cell>0.176</cell><cell>2.18</cell><cell>28.207</cell><cell>0.572</cell></row><row><cell></cell><cell>Mean</cell><cell>0.742</cell><cell>1.131</cell><cell>9.304</cell><cell>0.178</cell><cell>1.656</cell><cell>0.228</cell><cell>3.569</cell><cell>30.56</cell><cell>0.77</cell></row><row><cell></cell><cell>Max</cell><cell>0.921</cell><cell>1.394</cell><cell>11.642</cell><cell>0.221</cell><cell>2.404</cell><cell>0.319</cell><cell>6.43</cell><cell>32.973</cell><cell>1.126</cell></row><row><cell>256 kb/s</cell><cell>Min</cell><cell>1.176</cell><cell>1.049</cell><cell>6.561</cell><cell>0.282</cell><cell>2.177</cell><cell>0.076</cell><cell>1.552</cell><cell>29.695</cell><cell>0.507</cell></row><row><cell></cell><cell>Mean</cell><cell>1.248</cell><cell>1.245</cell><cell>8.698</cell><cell>0.3</cell><cell>2.593</cell><cell>0.109</cell><cell>2.356</cell><cell>32.196</cell><cell>0.713</cell></row><row><cell></cell><cell>Max</cell><cell>1.387</cell><cell>1.391</cell><cell>10.578</cell><cell>0.333</cell><cell>2.987</cell><cell>0.168</cell><cell>4.032</cell><cell>34.316</cell><cell>0.954</cell></row><row><cell>Class</cell><cell>Video</cell><cell></cell><cell cols="2">Genre</cell><cell></cell><cell cols="3">Quantization scale settings (from</cell><cell></cell><cell></cell></row><row><cell>Movies</cell><cell cols="2">Silence of the Lambs</cell><cell cols="2">Drama</cell><cell></cell><cell cols="5">(30, 30, 30); (24, 24, 24); (10, 14, 16); (10, 10, 10); (4, 4, 4)</cell></row><row><cell></cell><cell cols="2">The Terminator I</cell><cell cols="2">Action</cell><cell></cell><cell cols="5">(30, 30, 30); (24, 24, 24); (10, 14, 16); (10, 10, 10); (4, 4, 4)</cell></row><row><cell>Sports</cell><cell cols="2">Snowboarding</cell><cell cols="3">Snowboarding competition</cell><cell cols="5">(30, 30, 30); (24, 24, 24); (10, 14, 16); (10, 10, 10); (4, 4, 4)</cell></row><row><cell>Lecture and</cell><cell cols="4">Lecture Martin Reisslein Lecture</cell><cell></cell><cell cols="5">(30, 30, 30); (24, 24, 24); (10, 14, 16); (10, 10, 10); (4, 4, 4)</cell></row><row><cell>surveillance</cell><cell cols="2">Parking Lot Cam</cell><cell cols="2">Surveillance</cell><cell></cell><cell cols="5">(30, 30, 30); (24, 24, 24); (10, 14, 16); (10, 10, 10); (4, 4, 4)</cell></row></table><note><p>n n n nTable 8. Overview of video sequences in CIF format considered in spatial scalability study.</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>We are grateful to Associate Editor-in-Chief John Daigle and the anonymous reviewers for their detailed and thoughtful comments on earlier versions of this article, which have greatly improved its quality. We are grateful to Osama Lotfallah and Sethuraman Panchanathan for help with the encoder software.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supported in part by the National Science</head><p>Foundation under grant no. Career ANI-0133252 and grant no. ANI-0136774. Supported in part by the State of Arizona through the IT301 initiative. Supported in part by two matching grants from Sun Microsystems.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BIOGRAPHIES</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Video-on-Demand Services: Efficient Transportation and Decompression of Variable Bit Rate Video</title>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Feng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996-04">Apr. 1996</date>
		</imprint>
		<respStmt>
			<orgName>University of Michigan</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Buffering Techniques for Delivery of Compressed Video in Video-on-Demand Systems</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Kluwer Academic Publisher</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Contributions Toward Real-Time Services on Packet Networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Garret</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993-05">May 1993</date>
		</imprint>
		<respStmt>
			<orgName>Columbia University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Statistical Characteristics and Multiplexing of MPEG Streams</title>
		<author>
			<persName><forename type="first">M</forename><surname>Krunz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hughes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Infocom &apos;95</title>
		<meeting>IEEE Infocom &apos;95<address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-04">April 1995</date>
			<biblScope unit="page" from="455" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Statistical Properties of MPEG Video Traffic and their Impact on Traffic Modelling in ATM Systems</title>
		<author>
			<persName><forename type="first">O</forename><surname>Rose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Univ. of Wuerzburg, Inst. of Computer Science, Tech. Rep</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<date type="published" when="1995-02">Feb. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Traffic and Quality Characterization of Scalable Encoded Video: A Large-Scale Trace-Based Study</title>
		<author>
			<persName><forename type="first">M</forename><surname>Reisslein</surname></persName>
		</author>
		<ptr target="http://trace.eas.asu.edu" />
	</analytic>
	<monogr>
		<title level="j">Dept. of Elect. Eng., Tech. Rep</title>
		<imprint>
			<date type="published" when="2003-12">Dec. 2003</date>
		</imprint>
		<respStmt>
			<orgName>Arizona State University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">MPEG Digital Video Coding Standards</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sikora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Electronics Consumer Handbook</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>McGraw Hill</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Standard Codecs: Image Compression to Advanced Video Coding</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ghanbari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEE</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Overview of Fine Granularity Scalability in MPEG-4 Video Standard</title>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits and Systems for Video Tech</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="301" to="317" />
			<date type="published" when="2001-03">Mar. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multiple Description Coding: Compression Meets the Network</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">K</forename><surname>Goyal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Mag</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="74" to="93" />
			<date type="published" when="2001-09">Sept. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Taubman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Marcellin</surname></persName>
		</author>
		<title level="m">JPEG 2000: Image Compression Fundamentals, Standards and Practice</title>
		<imprint>
			<publisher>Kluwer Academic Publishers</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Packet Classification Schemes for Streaming MPEG Video over Delay and Loss Differentiated Networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zakhor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Packet Video Wksp</title>
		<meeting>Packet Video Wksp<address><addrLine>Kyongju, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-04">April 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Recommendation BT.500-8 -Methodology for the Subjective Assessment of the Quality of Television Pictures</title>
		<idno>ITU-500-R</idno>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Study of MPEG-2 Coding Performance Based on a Perceptual Quality Metric</title>
		<author>
			<persName><forename type="first">A</forename><surname>Basso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Picture Coding Symp</title>
		<meeting>Picture Coding Symp<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-03">Mar. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An Objective Video Quality Assessment System Based on Human Perception</title>
		<author>
			<persName><forename type="first">A</forename><surname>Webster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE Human Vision, Visual Processing and Digital Display</title>
		<meeting>SPIE Human Vision, Visual essing and Digital Display</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">1913</biblScope>
			<biblScope unit="page">1526</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Perceptual Distortion Metric for Digital Color Video</title>
		<author>
			<persName><forename type="first">S</forename><surname>Winkler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE Human Vision and Electronic Imaging</title>
		<meeting>SPIE Human Vision and Electronic Imaging</meeting>
		<imprint>
			<date type="published" when="1999-01">Jan. 1999</date>
			<biblScope unit="volume">3644</biblScope>
			<biblScope unit="page" from="175" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Performance of H.263 Video Transmission over Wireless Networks using Hybrid ARQ</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Zarki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE JSAC</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1775" to="1786" />
			<date type="published" when="1997-12">Dec. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Analysis of Error Concealment Schemes for MPEG-2 Video Transmission over ATM Based Networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Zarki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE Visual Communications and Image Processing</title>
		<meeting>SPIE Visual Communications and Image essing<address><addrLine>Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-05">1995. May 1995</date>
			<biblScope unit="page" from="102" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">MPEG2Tool: A Toolkit for the Study of MPEG-2 Video Transmission over ATM-Based Networks</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
		<respStmt>
			<orgName>Dept. of Electrical Engineering, Univ. of Pennsylvania, Tech. Rep.</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An Integrated Source Transcoding and Congestion Control Paradigm for Video Streaming in the Internet</title>
		<author>
			<persName><forename type="first">R</forename><surname>Puri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="18" to="32" />
			<date type="published" when="2001-03">Mar. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Quality-of-Service Mapping Mechanism for Packet Video in Differentiated Services Network</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-C</forename><forename type="middle">J</forename><surname>Kuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="219" to="231" />
			<date type="published" when="2001-06">June 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Characterization of Quality and Traffic for Various Video Encoding Schemes and Various Encoder Control Schemes</title>
		<author>
			<persName><forename type="first">I</forename><surname>Dalgic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Tobagi</surname></persName>
		</author>
		<idno>CSL-TR-96-701</idno>
	</analytic>
	<monogr>
		<title level="j">Stanford Univ., Dept. of Elec. Eng. and Comp. Science</title>
		<imprint>
			<date type="published" when="1996-08">Aug. 1996</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Gamma-Based Framework for Modeling Variable-Rate MPEG Video Sources: The GOP GBAR model</title>
		<author>
			<persName><forename type="first">M</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nguyen-Quang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Net</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="710" to="719" />
			<date type="published" when="2000-12">Dec. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The GBAR Source Model for VBR Video Conferencing</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Heyman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Net</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="554" to="560" />
			<date type="published" when="1997-08">Aug. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Analysis, Modeling, and Generation of Self-Similar VBR Video Traffic</title>
		<author>
			<persName><forename type="first">M</forename><surname>Garrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Willinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Sigcomm</title>
		<meeting>ACM Sigcomm<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-09">Sept. 1994</date>
			<biblScope unit="page" from="269" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Source Models for VBR Broadcast Video Traffic</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Heyman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">V</forename><surname>Lakshman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Net</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="48" />
			<date type="published" when="1996-01">Jan. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A Source Model for VBR Video Traffic Based on M/G/∞ Input Processes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Krunz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Infocom</title>
		<meeting>IEEE Infocom<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-04">Apr. 1998</date>
			<biblScope unit="page" from="1441" to="1449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On the Characterization of VBR MPEG Streams</title>
		<author>
			<persName><forename type="first">M</forename><surname>Krunz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tripathi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGMETRICS</title>
		<meeting>ACM SIGMETRICS<address><addrLine>Seattle, WA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997-06">June 1997</date>
			<biblScope unit="page" from="192" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Methods for Performance Evaluation of VBR Video Traffic Models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lucantoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Neuts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Reibman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Net</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="176" to="180" />
			<date type="published" when="1994-04">Apr. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Simple and Efficient Models for Variable Bit Rate MPEG Video Traffic</title>
		<author>
			<persName><forename type="first">O</forename><surname>Rose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Performance Evaluation</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="69" to="85" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Modeling and Simulation of Broadband Satellite Networks -Part II: Traffic Modeling</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ryu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Commun. Mag</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="48" to="56" />
			<date type="published" when="1999-07">July 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Characterization and Modeling of MPEG Video Traffic on Multiple Timescales</title>
		<author>
			<persName><forename type="first">N</forename><surname>Semret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tech. Rep</title>
		<imprint>
			<date type="published" when="1995-05">May 1995</date>
			<pubPlace>New York</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Columbia University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">MPEG-2 video Test Model 5, iso/iecjtc1/sc29wg11 mpeg93/457</title>
	</analytic>
	<monogr>
		<title level="m">Test Model Editing Committee</title>
		<imprint>
			<date type="published" when="1993-04">Apr. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Traffic and Quality Characterization of Scalable Encoded Video: A Large-Scale Trace-Based Study, Part 2: Statistical Analysis of Single-Layer Encoded Video</title>
		<author>
			<persName><forename type="first">M</forename><surname>Reisslein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002-12">Dec. 2002</date>
		</imprint>
		<respStmt>
			<orgName>Arizona State University, Dept. of Electrical Engineering, Tech. Rep.</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Video Quality Experts Group: Current Results and Future Directions</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rohaly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE Visual Commun. and Image Processing</title>
		<meeting>SPIE Visual Commun. and Image essing<address><addrLine>Perth, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-06">June 2000</date>
			<biblScope unit="volume">4067</biblScope>
			<biblScope unit="page" from="742" to="753" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Vision Models and Quality Metrics for Image Processing Applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Winkler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
		<respStmt>
			<orgName>EPFL, Switzerland</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">MPEG-4 and H.263 Video Traces for Network Performance Evaluation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Fitzek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reisslein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="40" to="54" />
			<date type="published" when="2001-12">Nov./Dec. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Long-Range Dependence in Variable-Bit-Rate Video Traffic</title>
		<author>
			<persName><forename type="first">J</forename><surname>Beran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2/3/4</biblScope>
			<biblScope unit="page" from="1566" to="1579" />
			<date type="published" when="1995-04">Feb./Mar./Apr. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Traffic and Quality Characterization of Scalable Encoded Video: A Large-Scale Trace-Based Study, Part 1: Overview and Definitions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Reisslein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tech. Rep</title>
		<imprint>
			<date type="published" when="2002-12">Dec. 2002</date>
		</imprint>
		<respStmt>
			<orgName>Arizona State Univ., Telecommunications Research Center</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A Wavelet-Based Joint Estimator of the Parameters of Long-Range Dependence</title>
		<author>
			<persName><forename type="first">D</forename><surname>Veitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="878" to="897" />
			<date type="published" when="1999-04">Apr. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Request for Comments 2212: Specification of Guaranteed Quality of Service</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Partridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guerin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997-09">Sept. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Traffic and Quality Characterization of Scalable Encoded Video: A Large-Scale Trace-Based Study, Part 3: Statistical Analysis of Temporal Scalable Encoded Video</title>
		<author>
			<persName><forename type="first">M</forename><surname>Reisslein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tech. Rep</title>
		<imprint>
			<date type="published" when="2002-12">Dec. 2002</date>
		</imprint>
		<respStmt>
			<orgName>Arizona State University, Dept. of Electrical Engineering</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A Comparison of Bandwidth Smoothing Techniques for the Transmission of Prerecorded Compressed Video</title>
		<author>
			<persName><forename type="first">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rexford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Infocom</title>
		<meeting>IEEE Infocom<address><addrLine>Kobe, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997-04">Apr. 1997</date>
			<biblScope unit="page" from="58" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Bandwidth Allocation Strategies for Transporting Variable-Bit-Rate Video Traffic</title>
		<author>
			<persName><forename type="first">M</forename><surname>Krunz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Commun. Mag</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="46" />
			<date type="published" when="1999-01">Jan. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A Unified Rate-Distortion Analysis Framework for Transform Coding</title>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits and Sys. for Video Tech</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1221" to="1236" />
			<date type="published" when="2001-12">Dec. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Traffic and Quality Characterization of Scalable Encoded Video: A Large-Scale Trace-Based Study, Part 4: Statistical Analysis of Spatial Scalable Encoded Video</title>
		<author>
			<persName><forename type="first">M</forename><surname>Reisslein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tech. Rep</title>
		<imprint>
			<date type="published" when="2003-08">Aug. 2003</date>
		</imprint>
		<respStmt>
			<orgName>Arizona State University, Dept. of Electrical Engineering</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Principles of Discrete Event Simulation</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Fishman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Kelton</surname></persName>
		</author>
		<title level="m">Simulation, Modeling and Analysis</title>
		<imprint>
			<publisher>McGraw Hill</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Error Control and Concealment for Video Communication: A Review</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1998-05">May 1998</date>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="974" to="997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Issues of Quality and Multiplexing when Smoothing Rate Adaptive Video</title>
		<author>
			<persName><forename type="first">N</forename><surname>Duffield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Reibman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="53" to="68" />
			<date type="published" when="1999-12">Dec. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Heterogeneous Video Transcoding to Lower Patio-Temporal Resolutions and Different Encoding Formats</title>
		<author>
			<persName><forename type="first">T</forename><surname>Shanableh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghanbari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="101" to="110" />
			<date type="published" when="2000-06">June 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Measurement and Analysis of a Streaming Media Workload</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chesire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. USITS</title>
		<meeting>USITS<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-03">Mar. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Human Behavior and Principle of Least Effort: An Introduction to Human Ecology</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">K</forename><surname>Zipf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1949">1949</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Dynamic Batching Policies for An On-Demand Video Server</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sitaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shahabuddin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimedia Systems</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="112" to="121" />
			<date type="published" when="1996-03">Mar. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Web Caching and Zipf-Like Distributions: Evidence and Implications</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breslau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Infocom</title>
		<meeting>IEEE Infocom<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-03">1999. Mar. 1999</date>
			<biblScope unit="page" from="126" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Audio-Video Transport Working Group</title>
		<author>
			<persName><forename type="first">H</forename><surname>Schulzrinne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RFC1889: RTP -A Transport Protocol for Real-Time Applications</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
	<note>work in progress</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">RFC3016: RTP Payload Format for MPEG-4 Audio/Visual Streams</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kikuchi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note>work in progress</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Video Quality Evaluation for Wireless Transmission with Robust Header Compression</title>
		<author>
			<persName><forename type="first">P</forename><surname>Seeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th IEEE Int&apos;l. Conf. Info., Commun. &amp; Signal Processing and 4th Pacific-Rim Conf. Multimedia (ICICS-PCM 2003</title>
		<meeting>4th IEEE Int&apos;l. Conf. Info., Commun. &amp; Signal essing and 4th Pacific-Rim Conf. Multimedia (ICICS-PCM 2003<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-12">Dec. 2003</date>
			<biblScope unit="page" from="1346" to="1350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Video and Audio Trace Files of Pre-Encoded Video Content for Network Performance Measurements</title>
		<author>
			<persName><forename type="first">F</forename><surname>Fitzek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Consumer Commun. and Net. Conf. (CCNC)</title>
		<meeting>IEEE Consumer Commun. and Net. Conf. (CCNC)<address><addrLine>Las Vegas, NV</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-01">Jan. 2004</date>
			<biblScope unit="page" from="245" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Initialization Bias in Simulation Output</title>
		<author>
			<persName><forename type="first">L</forename><surname>Schruben</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="569" to="590" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Statistics for Long-Memory Process</title>
		<author>
			<persName><forename type="first">J</forename><surname>Beran</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>Chapman and Hall/CRC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">A Batch Means Procedure for Mean Value Estimation of Processes Exhibiting Long-Range Dependence</title>
		<author>
			<persName><forename type="first">A</forename><surname>Suarez-Gonzales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2002 Winter Simulation Conf</title>
		<meeting>2002 Winter Simulation Conf<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-12">Dec. 2002</date>
			<biblScope unit="page" from="456" to="464" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
