<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Scalable Omniscient Debugging</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Guillaume</forename><surname>Pothier</surname></persName>
							<email>gpothier@dcc.uchile.cl</email>
							<affiliation key="aff0">
								<orgName type="institution">DCC -University of Chile</orgName>
								<address>
									<postCode>2120</postCode>
									<settlement>Santiago</settlement>
									<country key="CL">Chile</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Éric</forename><surname>Tanter</surname></persName>
							<email>etanter@dcc.uchile.cl</email>
							<affiliation key="aff0">
								<orgName type="institution">DCC -University of Chile</orgName>
								<address>
									<postCode>2120</postCode>
									<settlement>Santiago</settlement>
									<country key="CL">Chile</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">José</forename><surname>Piquer</surname></persName>
							<email>jpiquer@dcc.uchile.cl</email>
							<affiliation key="aff0">
								<orgName type="institution">DCC -University of Chile</orgName>
								<address>
									<postCode>2120</postCode>
									<settlement>Santiago</settlement>
									<country key="CL">Chile</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Scalable Omniscient Debugging</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C472F4398BDF7A2F954D2962116B97D0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>D.2.5 [Testing and Debugging]: Debugging aids</term>
					<term>D.2.6 [Programming Environments]: Integrated environments</term>
					<term>D.3.4 [Processors]: Debuggers</term>
					<term>H.2.3 [Languages]: Query languages</term>
					<term>H.2.4 [Systems]: Distributed databases</term>
					<term>H.2.4 [Systems]: Query processing General Terms Algorithms, Design, Performance Omniscient debugging, scalability, execution traces, specialized distributed database, partial traces, interface components</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Omniscient debuggers make it possible to navigate backwards in time within a program execution trace, drastically improving the task of debugging complex applications. Still, they are mostly ignored in practice due to the challenges raised by the potentially huge size of the execution traces. This paper shows that omniscient debugging can be realistically realized through the use of different techniques addressing efficiency, scalability and usability. We present TOD, a portable Trace-Oriented Debugger for Java, which combines an efficient instrumentation for event generation, a specialized distributed database for scalable storage and efficient querying, support for partial traces in order to reduce the trace volume to relevant events, and innovative interface components for interactive trace navigation and analysis in the development environment. Provided a reasonable infrastructure, the performance of TOD allows a responsive debugging experience in the face of large programs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Debugging software is a major task of the software development process, both in terms of time and cost. Unfortunately debuggers in most development environments only provide very minimal assistance and debugging remains a tedious and time-consuming task.</p><p>There are two traditional approaches to debugging: logbased debugging and breakpoint-based debugging. The first approach consists in inserting logging statements within the source code, in order to produce an ad-hoc trace during program execution. This technique exposes the actual history of execution but (a) it requires cumbersome and widespread modifications to the source code, and (b) it does not scale because manual analysis of huge traces is hard. The second approach consists in running the program under a dedicated debugger which allows the programmer to pause the execution at determined points, inspect memory contents, and then continue execution step-by-step. Although not subject to the two issues of log-based debugging, breakpoint-based debugging is limited: when execution is paused, the information about the previous state and activity of the program is limited to introspection of the current call stack.</p><p>Omniscient debuggers, also known as back-in-time or post-mortem debuggers, overcome all these issues <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b16">17]</ref>. An omniscient debugger records the events that occur during the execution of the debugged program, and then lets the user conveniently navigate through the obtained execution trace. This approach combines the advantages of logbased debugging -past activity is never lost-and those of breakpoint-based debugging -easy navigation, step-by-step execution, complete stack inspection. An omniscient debugger can simulate step-by-step execution forward and backward, and makes it possible to immediately answer questions that would otherwise require a significant effort, like "At what point was variable x assigned value y ?" or "What was the state of object o when it was passed as an argument to the method foo ?".</p><p>While the advantages of omniscient debugging over traditional approaches are incredibly clear, it has had a very limited impact in production environments, and is still mostly seen as an unrealistic approach. It is true that omniscient debugging raises important issues. First, except when us-ing specialized hardware probing ports <ref type="bibr" target="#b9">[10]</ref>, the emission of events causes a significant overhead to the debugged application. Second, as emphasized in <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b27">28]</ref>, for CPUintensive applications, the execution trace can rapidly become huge (hundreds of million events), implying that (a) trace data must be stored very quickly and requires scalable storage; and (b) the user interface of the debugger must be responsive enough -this requires fast query execution on huge traces-, and must assist the user in overcoming the cognitive burden of dealing with a large amount of information in order to rapidly locate the points of interest.</p><p>The contribution of this paper is to show that omniscient debugging can be realistically realized through the use of different techniques enhancing efficiency, scalability, and usability. This claim is validated by TOD <ref type="foot" target="#foot_0">1</ref> , a portable Trace-Oriented Debugger for Java integrated into the Eclipse IDE <ref type="bibr" target="#b4">[5]</ref>. TOD features:</p><p>• Efficient event generation based on a compact trace model, a custom binary encoding of events, and a fast, portable low-level weaver.</p><p>• Specialized distributed database engine for scalable and fast storing and querying of events, which leverages the highly-constrained nature of execution traces. On a dedicated 10-node cluster TOD handles a sustained input rate of approx. 470kEv/s (thousands events per second), and hundreds of queries per second.</p><p>• Support for partial traces by offering static and dynamic mechanisms for selective trace generation, and adequate reporting of incomplete information.</p><p>• Responsive GUI thanks to efficient query processing; TOD was used to debug an application as complex as Eclipse while preserving interactivity.</p><p>• Specialized GUI components providing high-level views on huge event traces for more effective navigation, such as thread murals.</p><p>Section 2 details the features and challenges of omniscient debugging. Section 3 overviews the architecture of TOD, the event model, and the GUI components. Section 4 describes the efficient indexing scheme of TOD for storing and querying events, and Section 5 shows how it is parallelized. Benchmarks are provided in Section 6. We explain the advantage of partial traces and how they are dealt with in Section 7. Related work is discussed in details in Section 8. Section 9 concludes, and identifies opportunities for further enhancements in the field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Challenges of Omniscient Debugging</head><p>We now present the main features of an omniscient debugger compared to traditional debuggers, and outline the scalability challenges of omniscient debugging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Features of an omniscient debugger</head><p>An omniscient debugger (OD) provides four major features: stepping, state reconstitution, control flow reconstitution, and root cause finding. The latter is unique to omniscient debuggers, while others are typical debugger features.</p><p>In breakpoint-based debuggers, Stepping consists in executing the target program one instruction at a time. There are two variants of stepping: step over executes behavior <ref type="foot" target="#foot_1">2</ref> call statements without halting inside the called behavior, while step into halts at the beginning of the called behavior. State reconstitution consists in letting the programmer inspect object state when the target program is halted. Control flow reconstitution permits to obtain a view on the current call stack of the program, with bound variables and objects. ODs extend these three features with complete freedom with respect to time: stepping can be done both forward and backward in time, programmers can inspect the state of objects as they were at any given point in time, and can freely browse the control flow tree.</p><p>Finally, one of the most useful features of ODs is their ability to find when and in which context a particular field or variable was given a certain value. Indeed, bugs often manifest long after their root cause occurs. For instance, trying to dereference a null reference obtained from a given field causes a crash, which is the symptom of the bug. The information the programmer needs is when was the field set to null. With breakpoint-based debuggers, even if execution is halted just before the faulty dereference, the root cause of the bug can be already lost, e.g.because the code that caused it is not in the call stack anymore.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Scalability challenges</head><p>Underlying the features presented above lies the necessity to generate and record execution traces. The potentially huge size of these traces poses several scalability challenges, which are the main reason for the lack of production-quality ODs.</p><p>• Events must be recorded quickly, preferably in real time, so that (a) debugging can begin immediately after the target program terminates or crashes, and (b) runtime overhead is minimized to preserve overall performance of the debugged program, and interactivity when needed (e.g. debugging Eclipse).</p><p>• The debugger should cause minimal interference to the target program in order to not affect its behavior. In particular, the address space and memory management of the target process should not be altered. • The event storage capacity of an omniscient debugger must be aligned with the expected number of events in a useful trace: with GHz CPUs, hundreds of millions events can be generated in only a few minutes of execution.</p><p>• Queries on the execution trace must execute at a speed compatible with user interaction, e.g. in tenths of seconds for operations like stepping.</p><p>• Information must be presented in a way that addresses the cognitive burden of navigating through huge event traces, enabling rapid bug identification.</p><p>This work addresses the above issues via optimized event representations and aggressive indexing, a simple query model, a distributed database backend, support for partial traces, and specialized presentation and interaction components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Overview of TOD</head><p>TOD is a Trace-Oriented Debugger for Java that addresses the scalability issues identified above. The objective is to address these issues in order to obtain an omniscient debugger that is practically applicable. This section gives an overview of TOD via its architecture, the event model, and the GUI components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Architecture</head><p>TOD is designed around two central ideas: to decouple the core of the debugger from the target program execution, and to be portable. It is made up of three components (Fig. <ref type="figure" target="#fig_0">1</ref>): the target Java Virtual Machine (JVM) in which the debugged program runs and emits events, the debugger core that implements the main functionalities of TOD, and the debugger frontend through which the user interactively queries and navigates in the execution trace.</p><p>The rationale for storing events in a database rather than in memory as done in other omniscient debuggers <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b16">17]</ref> is precisely to address some of the challenges discussed in Sect. 2.2: storing events in the address space of the target application is not scalable past a few hundred megabytes of trace data, and interferes with memory management, in particular with the garbage collector. The increased capture cost incurred by the use of a database is compensated by a better scalability and non intrusiveness. As a side effect, the ability to serialize execution traces allows for post-mortem de-bugging, which opens interesting perspectives for software companies willing to offer software with high-quality support: overlooking the storage cost, a navigatable execution trace is a far more relevant input for a bug report than an ad-hoc text description.</p><p>During execution, the target application emits events that are sent to the debugger core, where they are recorded and indexed in an event database. The way events are emitted is discussed later. The event database leverages the peculiarities of the event stream and the restricted set of possible queries to provide both high recording throughput and good query performance (see Sect. 4 and 5). The debugger core contains another database, the structure database, which contains static information about the target application. In particular it keeps track of the 32-bit integer identifiers that are assigned to structural elements of the target program (i.e. classes, methods, and fields). Queries performed by the user rely on both the event and the structure databases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Representation and emission of events</head><p>We now introduce the representation of events and event traces, as well as how events are emitted by a debugged application in TOD.</p><p>Event and trace model. An event is a structure characterized by a number of attributes chosen among the set A = {a 0 , ..., a k }. We note e.a j the value of attribute a j of event e. For each j ∈ [0..k], let D j be the domain of a j , i.e. the set of all distinct values that can be taken by a j for any event in the trace. An event trace T = e 1 , ..., e n is an ordered sequence of n heterogeneous events.</p><p>The a 0 attribute corresponds to the timestamp of the event; it is characterized by the fact that (a) all events have a value for a 0 , (b) there exists a complete order on D 0 and (c) the events in T are ordered by their value of a 0 . Table <ref type="table">1</ref> shows which concrete events are captured and what are their attributes.</p><p>Emission of events. The debugger core of TOD captures events emitted by the target application (Fig. <ref type="figure" target="#fig_0">1</ref>). There are three ways in which events can be emitted: specialized hardware trace ports <ref type="bibr" target="#b9">[10]</ref>, virtual machine or interpreter instrumentation <ref type="bibr" target="#b15">[16]</ref>, and application code instrumentation <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b14">15]</ref>. TOD uses the last one: although not as fast as hardware probes and significantly more space-consuming than VM-level instrumentation in terms of code size, application instrumentation is also much more portable and easier to implement.</p><p>In TOD, the JVM that hosts the target application is set up to use a JVMTI 3 native agent. The agent intercepts class load events and replaces the original class definitions by instrumented versions. Instrumentation itself is performed by the weaver in the debugger core: the agent sends the original bytecode to the core, the weaver instruments the class and Table <ref type="table">1</ref>. Events and their attributes. stores structural information in the structure database, and the modified class is sent back to the target JVM where it is eventually loaded (Fig. <ref type="figure" target="#fig_0">1</ref>). The agent caches instrumented classes on the hard disk to reduce the number of interprocess round trips. This is particularly useful for frequentlyused classes such as those in the JDK.</p><p>Instrumentation is done using the ASM bytecode manipulation library <ref type="bibr" target="#b2">[3]</ref>: event emission code is added before and/or after specific bytecode patterns in the original code, such as a field write or a method call. When the instrumented code is executed, events are constructed along with their attributes, serialized in a custom binary format, and sent through a socket to the event database.</p><p>Non-ambiguous event timing. Although event timestamps are obtained through the nanosecond-precision time service of Java, its potential lack of accuracy makes it is possible for several events of the same thread to share the same timestamp value. As this is incompatible with the event indexing scheme used by TOD (Sect. 4), we shift original timestamp values a few bits to the left and use the free bits to differentiate events of the same thread that share the same timestamp. When comparing the timestamps of events of different threads, we use the original timestamps to preserve inter-thread event ordering.</p><p>Scoped trace capture. The instrumentation scheme described above is selective, that is, it is possible to supply user-defined filters that limit the number of emitted events. This feature is described in Section 7.</p><p>Object identification. The JVMTI agent of TOD assigns a unique identifier to each object in the target application; whenever an event needs to refer to an object it uses this identifier. Additionally objects whose state cannot be reconstituted, like String and Exception, are sent in a serialized form the first time they are referenced. As an exception to this mechanism objects that represent primitive values (e.g. Integer, Float, etc.) are passed by value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Low-level queries: cursors and counts</head><p>All the features presented in Section 2.1 (stepping, state reconstitution, control flow reconstitution and root cause</p><p>The current position of the cursor is depicted by the bold line between events 4 and 5. Events that match the cursor's predicate are grayed. Successive calls to next() return events 5, 6, 11 and 14; calling posN ext <ref type="bibr" target="#b10">(11)</ref> positions the cursor between events 10 and 11; calling posP rev <ref type="bibr" target="#b10">(11)</ref> positions it between events 11 and 12. operation semantics next()/ Returns the next/previous matching event prev() and moves the cursor forward/backward. posN ext(t)/ Moves so that the next call to next()/prev() posP rev(t) returns the first/last event whose timestamp is greater/lesser than or equal to t. posN ext(ev)/ Moves so that the next call to next()/prev() posP rev(ev) returns the given event.</p><p>Table <ref type="table">2</ref>. Cursor operations. finding) can be expressed in terms of two low-level queries: cursors and counts, which we introduce below. Both are based on filtering events in the trace according to some conditions on their attributes. Conditions can be any boolean combination of simple predicates of the form attribute = value, where value is a constant. For instance (kind = F W ∨ kind = BC) ∧ target = obj145. If Q is such a condition and e is an event, we define the predicate function Q(e) whose value is true iff e verifies condition Q.</p><p>Cursors. We define cursor(Q) as an iterator over events that match condition Q (Fig. <ref type="figure" target="#fig_1">2</ref>). Cursors have a current position that is situated between two consecutive events (or at the beginning or end of the trace). A cursor supports a number of navigation operations, as shown in Table <ref type="table">2</ref>.</p><p>Counts. Given a time interval [t 1 , t 2 ] divided in s slices of length δt = (t 2 -t 1 )/s each, and a condition Q on event attributes, a count query returns an array of s integers such that s[i] = |{e ∈ T : within(e, t 1 + i • δt) ∧ Q(e)}| where within(e, t) ⇔ e.ts ≥ t ∧ e.ts &lt; t + δt. Each slot of the array contains the number of events matching Q that occur during the corresponding time slice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">High-level queries</head><p>We now explain how cursors and counts are algorithmically combined to implement the high-level features described in Sect. 2.1. Section 4 discusses the aggressive database optimization enabled by using only filtering-based queries.</p><p>Stepping. We define stepper as an object that has a current event ev and supports forward and backward step into and step over operations. For instance, forward step into is defined as follows:</p><p>c ← cursor(thread = ev.thread) c.posP rev(ev); ev ← c.next() Forward step over changes the cursor condition to: thread = ev.thread ∧ depth = ev.depth. Backward stepping is symmetric to forward stepping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>State reconstitution.</head><p>The value v of a field f of a particular object o at time t can be retrieved as follows:</p><formula xml:id="formula_0">c ← cursor(kind = F W ∧ f id = f ∧ target = o) c.posP rev(t); v ← c.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>prev().val</head><p>The state of an object can be retrieved by performing the same operation for each field. Stack frames are reconstituted in a similar way, using variable write events instead of field write events.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Control flow reconstitution.</head><p>Events that occurred in the top-level control flow of a given method call event e are retrieved as follows:</p><p>c ← cursor(thread = e.thread ∧ depth = e.depth + 1) c.posP rev(e.ts); cf low = repeat ev = c.next(); cf low ← cf low ∪ ev until ev.kind = BEx Root cause finder. Determining how a field has been assigned an undesired value is as direct as the state reconstruction query above: instead of obtaining the value of the field write event that assigned the value to the field, the event itself is made current, giving access to the context at that time. Backward-in-time exploration of the cause can go on like this, up to the root cause.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">User interface components</head><p>The frontend of TOD can be used standalone or as a plugin for the Eclipse Java IDE (Fig. <ref type="figure" target="#fig_2">3</ref>). The user navigates between different views using widely-understood web browser metaphors (hyperlinks, back button). The available views are: object inspector, control flow, and murals. The object inspector view shows reconstitutions of objects, and allows root cause finding for field values through a convenient why? link next to each field. The control flow view shows a recon-stitution of the control flow and allows stepping operations as well as root cause finding for local variable values.</p><p>Murals. High-level overviews are useful for spotting abnormal behavior patterns. However representing a huge number of events in a limited number of pixels is difficult. Jerding and Stasko introduced the information mural <ref type="bibr" target="#b11">[12]</ref> as a "reduced representation of an entire information space that fits entirely within a display window". TOD features event murals, which are graphs that show the evolution of event density, or number of events per unit of time, in a given period:</p><p>• Thread murals show the event density of each thread for the whole execution of the target application (Fig. <ref type="figure" target="#fig_3">4</ref>).</p><p>• Object activity murals show the density of calls to methods of a particular object.</p><p>• Method murals show the density of calls to a particular method on any object.</p><p>In all cases densities are obtained through counts (Sect. 3.3), where the length of the time slices corresponds to the space occupied by a single pixel bar in the mural. The user can zoom and pan the murals; when the zoom level permits to distinguish individual events the user can select an event and see its context in a stepper view. Thread murals have a variety of applications, e.g. to understand the interplay between threads, or spotting dead-and livelocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">High-Speed Database Backend</head><p>We now describe and analyze the database backend of TOD, which allows for efficient query execution while being fast enough to allow a high recording throughput. Section 5 shows how our solution is amenable to parallelization, and Section 6 reports on actual performance measurements.</p><p>The need to develop a specialized database backend for TOD was motivated by the poor performance of widely-used database management systems for our purposes: for instance Postgres and Oracle only support storing events at a rate of 50 and 500 events per second respectively, while we rather aim at rates in the order of hundreds of thousands events per second <ref type="bibr" target="#b21">[22]</ref>. Our high-throughput specialized database backend leverages the following specificities of the event stream of an execution trace: (a) the event stream is readonly, (b) events arrive ordered by timestamp<ref type="foot" target="#foot_4">4</ref> and (c) queries are limited to filtering.</p><p>Sect. 4.1 describes the indexing scheme used by the database. Sections 4.2, 4.3 and 4.4 analyze the cost of executing the queries described in Sect. 3.3. Finally Sect. 4.5 analyzes the recording throughput that can be achieved by the Button (A) launches the program with trace recording. The user navigates in the control flow (B) using stepping buttons (C), or by clicking on an event. The line corresponding to the current event is highlighted in the source window (D). The state of the stack frames and current object is shown in window (E). The user can jump to the instruction that set a variable or field to its current value by clicking the why? link next to it.  system and presents an important trade-off between memory requirements and efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Aggressive indexing of events</head><p>In most database management systems the indexing scheme consists in maintaining one index on attribute value for selected attributes. Such an index permits to quickly retrieve the records that have a specific value for the indexed attribute. TOD adopts a more aggressive indexing scheme in which there is a separate index on timestamp for each distinct value of each attribute. This enables a highly-efficient processing of the cursors and counts queries defined in Sect. 3.3, and at the same time permits to sustain a high recording throughput.</p><p>Using the notation defined in Section 3.2 we define the index set of trace T on attribute a j as, in a first approximation, a function IS j : D j → N * for j ∈ [1..k] so that IS j maps any possible value v of a j to an index, which is a sequence of event pointers. A pointer i appears in index IS j (v) if and only if e i .a j = v, where e i is the i th event of T . Those indexes can be used directly to retrieve all events that match a simple query of the form a j = v; compound conditions are discussed in Sect. 4.2.</p><p>However, TOD queries consist not only in finding matching events, but also in finding matching events that occurred at, after or before a particular point in time. Therefore indexes contain timestamps in addition to event pointers. Hence in a second approximation, an index IS j (v) is a sequence of (ts, i) entries, ordered by their value of ts. In such an index an event near a particular timestamp can be retrieved using a binary search.</p><p>It is nevertheless much more efficient to use a B+Tree structure (Fig. <ref type="figure" target="#fig_4">5</ref>). Refining the above definition, the index IS j (v) becomes a hierarchical index comprising several levels. The index sequence described above constitutes level 0. The (ts, i) entries of that level-0 index are stored on the hard disk in small pages, where each page contains a number of entries pertaining to the same index. When such a page is full, an entry of the form (ts, pid) is created in the level-1 index: ts is taken from the first (ts, i) entry of the recentlyfilled page, and pid is a pointer to that page. Level-1 entries are in turn accumulated in pages; when a level-1 page is filled, a level-2 entry is created, and so on. The top level always contains a single page, called the root page. The number of levels above level 0 of an index is called the height of the index. In such a structure the number of page accesses necessary to retrieve an event near a given timestamp is at most the height of the index.</p><p>Storage requirements Experiments show that the average size of an event is e = 38 bytes. The size of a level-0 entry is (ts, i) = 16 bytes (two 64-bits integers). The size of upper-level entries is (ts, pid) = 12 bytes (pid is only 32 bits). The experimentally-determined optimal page size is P = 4096 bytes, therefore level-0 index pages contain 256 entries, upper-level index pages contain 341 entries and event pages contain 108 events in average. The height h of indexes is logarithmic with respect to the number of entries and in practice never exceeds 5 (an index of height 5 allows for 341 5 ≈ 4 • 10 12 entries).</p><p>The amount of index data generated for each event is actually greater than the event itself. In our experiments we found that in average an event plus the associated index data occupies 190 bytes of storage, although the event itself occupies only 38 bytes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Cost of event retrieval</head><p>We now present the algorithms that permit to retrieve events matching an arbitrary predicate in linear time with respect to the size of the involved indexes. The algorithms are for timestamp-order retrieval; reverse-timestamp retrieval has the same cost.</p><p>Single-term conditions. For a simple condition of the form a j = C where C is a constant, we can retrieve matching events ordered by timestamp simply by obtaining the (ts, i) entries from I j (C). If the actual event is needed (i.e. for cursors), it is directly retrieved from the trace as e i ; otherwise (i.e. for counts) the event does not need to be accessed. In any case, all entries can be retrieved in linear time, as the index is simply scanned once.</p><p>Conjunctive conditions. For a boolean conjunction of simple conditions of the form </p><formula xml:id="formula_1">a j1 = C 1 ∧ . . . ∧ a jm = C m , we</formula><formula xml:id="formula_2">if ref I = -1 then ref I ← curI else if curI = ref I then match ← f alse if curT S &lt; minT S then minT S ← curT S, minL ← l if match then result ← result ∪ {s ref I } pos[minL] ← pos[minL] + 1</formula><p>use a variant of the sort merge join algorithm <ref type="bibr" target="#b0">[1]</ref>, widelyused in database management systems, to identify matching events without accessing them (Algorithm 1): we obtain the I j l (C l ) for every simple condition, and for each we maintain a pointer to a current (ts l , i l ) entry. Then we loop: at every step we check if all of the i l are equal, in which case we add any of the current entries to the result: the fact that they all point to the same event means that the event matches all conditions. Then we advance the pointer of the index whose current entry has the minimum value of ts. As each index is scanned only once and there is no nested loop, merge join runs in linear time with respect to the sum of the sizes of the considered indexes.</p><p>Generic boolean conditions. The above can be generalized to any compound boolean condition, by performing a merge join for each conjunction and a regular merge (the merging step of merge sort) for each disjunction. The cost thus remains linear with respect to the sum of the sizes of the considered indexes. Because both merge join and regular merge are stream operators (i.e. they produce an output tuple as soon as they have received enough input tuples, without needing past or future input tuples), it is possible to pipeline them so that no intermediate results have to be stored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Cost of cursors</head><p>Cursors support retrieving matching events in forward or backward timestamp order, and absolute positioning by timestamp. Given a compound filtering condition, one index is used for each simple condition component. A pointer to a current entry is associated to each index and the merging algorithms described above are applied, incrementing or decrementing the pointer of each index as dictated by the desired retrieval order. The cost of retrieving successive matching events is extremely variable depending on the number of components of the condition and the density of matching events. For absolute positioning, we reposition the pointer of each index so that the next timestamp of the entry is immediately before or after the specified timestamp. This is achieved by performing a binary search of the given timestamp at each level of the index, starting by the root (Algorithm 2). The number of page accesses needed by this operation is at most equal to the height of the index, and can be less if some pages are found in the page buffer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Cost of counts</head><p>The counts queries retrieve the number of matching events in every time slice of length δt of a given interval. There are two ways these counts can be obtained.</p><p>Merge counts. The simplest way is to use the merging algorithms described previously: whenever a (ts, i) index entry corresponding to a matching event is found, the count of the time slice containing ts is incremented, without needing to fetch the actual event. This method works for arbitrary compound conditions but can be very costly if counts are required over a large interval.</p><p>Fast counts. In some cases we can leverage our hierarchical index structure to obtain counts at a much lower cost. Although this optimization applies only to simple conditions, it is useful e.g. to compute thread murals of the whole execution trace. Its scope can be extended if indexes of compound conditions are materialized (i.e. a new index is generated that references events that match the compound condition), a topic we do not address here.</p><p>The number of time slices requested in a counting query usually does not depend on the size of the interval but rather on the number of pixels of the debugger frontend window (Sect. 3.4). Therefore when counts are requested over a large interval, each time slice is also large. Because a higherlevel index entry is created when a lower-level page is full (Sect. 4.1), we can know the number n of level-0 entries that are between two level-l entries for l &gt; 0:</p><formula xml:id="formula_3">n = (ts, i) P • (ts, pid) P l-1</formula><p>Given two consecutive level-l entries (ts 1 , pid 1 ) and (ts 2 , pid 2 ) of index I j (C) we know that n events matching a j = C occurred between ts 1 and ts 2 . This information can then be used to provide average counts at a reduced cost. The index levels to use are determined by the ratio between the requested time slice length δt and the interval ts 2 -ts 1 between successive entries in each level. Note that various levels can be used during the execution of the same request, taking into account variations in the distribution of matching events: if the time between successive entries in level l is larger than δt we drill down into level l -1, and conversely we roll up to level l + 1 if the time interval is too short.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Cost of indexing</head><p>The above sections show that the indexing scheme of the database allows for efficient query execution. It remains to show that indexes can be created efficiently so as to allow a high recording throughput. This section shows that this can be achieved by carefully tuning memory requirements.</p><p>For each event that enters the database there are at most k = |A| -1 indexes to update (as there is no separate index on a 0 ). Experiments indicate that on average k = 10. Given that events arrive in order with respect to a 0 , it is not necessary to use the costly B+Tree insert method for updating an index. Instead, the much cheaper bulk load method is used, which consists in appending an entry at the end of the current level-0 page, and at the end of higherlevel pages whenever a lower-level page is filled. The I/O and memory costs of this operation are as follows:</p><p>• If the current page of each level of the index can be kept in memory, an I/O cost is incurred only when a page is filled. The average number of page accesses per incoming event is:</p><formula xml:id="formula_4">e + k • ( (ts, i) + A) P 0.05</formula><p>where A is the contribution of level 1 and above:</p><formula xml:id="formula_5">A = (ts, i) P • (ts, pid) • h-1 i=0</formula><p>(ts, pid) P i</p><p>• If only the current level-0 page of the index can be kept in memory, when a page is filled it must be written, the current level-1 page read, updated and written back to disk. The contribution of higher levels become:</p><formula xml:id="formula_6">A = (ts, i) P • 2P • h-1 i=0 (ts, pid) P i</formula><p>The average number of page access per incoming event is then 0.13.</p><p>• If no index page can be kept in memory, every update implies the three operations above, giving 2 • k = 20 accesses per event.</p><p>In order to achieve a high recording throughput it is therefore crucial to minimize the number of page accesses per incoming event: at least one page per index should be kept in memory so as to avoid the last situation, which is 150 times more costly than the second situation above. The number of indexes varies from 7 for the kind index set to more than 8 millions for the object index set in an execution trace of 720 million events. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Memory requirements</head><p>The memory requirements of the system depend on the number of indexes to maintain, which in turn depends on the size of the domain of each attribute.</p><p>Figure <ref type="figure" target="#fig_7">6</ref> shows the domain size of each attribute as observed with a large execution trace of an Eclipse session (720 millions events). The domain of object ids largely dominates all other domains, reaching almost 10 millions distinct values. Maintaining the corresponding indexes would require P • 10 7 = 40GB of buffer space, which is not a reasonable figure . A solution to this problem is to split the index sets of large attributes, as explained below.</p><p>Index set splitting As maintaining millions of indexes is not practically feasible, we devised a strategy that permits to trade memory requirements for recording throughput and querying efficiency: attributes with large domains are split into components that are indexed separately. Let a j be an attribute and d = |D j | the number of distinct values it can take (hence d is also the number of indexes in the corresponding index set). Assuming that all the distinct values are the first d positive integers -which is always the case in practice-, any value v of D j can be represented in binary by n = log 2 (d) bits. Such a value can be split into N components of n/N bits each, and instead of having a single index set on attribute a j there are now N index sets, one for each component. The number of indexes to maintain becomes N •2 n/N = N • N √ d instead of d, yielding a dramatic reduction of memory requirements, even for N as low as 2. For instance with d = 10 7 , corresponding to the size of the object id domain, the memory requirements using index set splitting with N = 2 would be reduced from 40GB to 25MB.</p><p>Index set splitting therefore implies huge reduction of memory requirements. Let us now assess the impact of this technique on efficiency. For recording, the number of index updates is multiplied at most by N . Given that not all events have values for split attributes, the actual slowdown is lower.</p><p>For querying, boolean expressions involving split indexes are replaced by a conjunction of N conditions, one for each  </p><formula xml:id="formula_7">N • B/d , yielding a slowdown of N • d/d = N • d 1-1</formula><p>N . For instance, with d = 10 7 and N = 2, the slowdown would be approx. 6, 300. Although this might seem prohibitive, it is important to note that the index sets that are subject to splitting have domains orders of magnitude larger than other index sets (Fig. <ref type="figure" target="#fig_7">6</ref>), thus each individual index is small compared to the indexes of non-split index sets. As in practice most queries are compound and involve both split and nonsplit index sets, the contribution of split index sets to the total cost of the query is reasonable.</p><p>To illustrate this, let us consider the state reconstitution query of Sect. 3.4, which is based on a conjunction of conditions on the field id and object id attributes <ref type="foot" target="#foot_5">5</ref> . In the Eclipse trace previously mentioned there are about 10, 000 distinct field id values and 10, 000, 000 distinct object id values (Fig. <ref type="figure" target="#fig_7">6</ref>). With a trace containing B events, assuming a uniform distribution of field id and object id values, and assuming that every event has a value for both attributes, each index on field id would contain B/10 4 entries; each index on object id would contain B/10 7 entries without index set splitting, and approx. B/ √ 10 7 = B/3, 160 with index set splitting and N = 2. Therefore the actual slowdown of index set splitting for the compound query is: cost with splitting cost without splitting = 1/10 4 + 2/3160 1/10 4 + 1/10 7 ≈ 7</p><p>Despite this slowdown, state reconstitution queries execute fast enough to be used interactively in the debugger frontend, as will be shown in Sect. 6.2. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Scaling Up with a Debugging Cluster</head><p>The efficient indexing and retrieval techniques used in the event database of TOD can benefit from parallelization. This section shows how TOD supports a distributed database backend, allowing its efficiency to increase linearly in terms of the number of nodes, within certain limits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Distributed Architecture</head><p>The architecture of the distributed backend of TOD consists of three layers (Fig. <ref type="figure" target="#fig_8">7</ref>):</p><p>• A dispatcher that receives the events from the target program and distributes them to a number of database nodes. The dispatcher maintains a local sending queue for each connected database node. A receiving thread reads each incoming event and forwards it to the smallest queue, so as to achieve proper load balancing between database nodes.</p><p>• A number of database nodes, each of which receives a subset of all generated events. They are individually able to index events and process queries in the same way as the non-distributed backend described in Section 4. No change to the indexing structure is necessary.</p><p>• A query aggregator that receives queries from the debugger frontend, passes them to each database node and aggregates the results before returning them to the frontend.</p><p>Note that neither the structure database nor the weaver mentioned in 3.1 need to be parallelized as their processing and storage requirements are modest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Scalability</head><p>Parallelization Both event recording and query processing are embarrassingly parallel problems, that is to say, their parallelization is straightforward because no special coordination is required between the parallel tasks. In particular, queries do not need to perform any kind of joins between events. All database nodes can perform the same query independently and then send their results to the aggregator, which is able to merge them efficiently.</p><p>Furthermore, cursors and counts have very light processing and bandwidth requirements on the aggregator, enabling excellent scalability properties: Parallel cursors. When the aggregator receives a cursor query with filtering condition Q it requests a similar cursor to each database node and returns an aggregating cursor to the client. In the same way regular cursors merge entries from various indexes, the aggregating cursor merges events from each of its base cursors using the regular merge algorithm from merge sort.</p><p>Parallel counts. The aggregator obtains partial count results from each node and simply returns a new counts array where the value of each slot is the sum of the values of the corresponding slot in each partial result array.</p><p>Scalability limits The throughput of this architecture is theoretically linear in terms of the number of database nodes. However the scalability is in practice limited by one of these factors: the dispatcher (resp. aggregator) can act as a bottleneck for recording throughput (resp. query processing), or the network link bandwidth can be saturated. In our current implementation, the actual bottleneck is the dispatcher, as reported in details in the following benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Benchmarks</head><p>This section reports on a first set of benchmarks evaluating different aspects of TOD. In particular, we first measure the overhead imposed on a running application debugged with TOD, and then report on the efficiency and scalability of the distributed database backend, both in terms of recording throughput and query evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Trace capture overhead</head><p>Capturing the execution trace of a debugged program causes a significant runtime overhead. We measured it in two different scenarios:</p><p>• A fully-instrumented, CPU-intensive toy program designed to represent a worst-case situation, in which the debugged applications emits events at a rate as high as the CPU can handle;</p><p>• An interactive Eclipse session reflecting a real-world situation, in which the JDK classes are not instrumented (partial traces are further discussed in Sect. 7), and in which the interaction between the user and the debugged application entails that the event emission rate is less sustained in time than in the worst case above.</p><p>In these experiments only the event emission overhead caused by TOD is measured, not its database performance. Therefore events are simply written to disk, without any indexing. Both benchmarks were conducted on a Pentium M 2GHz notebook with 1GB of RAM running Linux kernel 2.6.17 and the Sun 1.5.0 08 JVM.  Worst-case scenario We use a CPU-intensive program that creates 100 Object instances and then iterates 10 million times in a loop taking one of these objects at random and passing it to a method that performs a simple arithmetic operation on its hash code. The program does not call any non-instrumented method. Therefore, every execution step emit events, so the event emission rate is bounded only by the CPU speed. We compare the execution time of this program running (a) standalone, (b) with TOD and (c) with the ODB <ref type="bibr" target="#b14">[15]</ref> omniscient debugger for Java. Results are presented in Table <ref type="table" target="#tab_4">4</ref>. With ODB, events are stored in the JVM heap of the target program; old events are discarded when the heap is full. We therefore conducted two ODB tests, varying the JVM heap size: with 500MB of heap we were able to record 5 million events out of the 110 million emitted during program execution, while with 64MB we could record only 500,000 events. On the other hand with TOD we were able to record all emitted events <ref type="foot" target="#foot_6">6</ref> without interfering with the JVM heap. In spite of the heavier processing in the case of TOD -where events are serialized and written to disk rather than simply kept in RAM-the overhead imposed on the application execution time is similar in TOD and ODB: around 115 times the cost of standalone execution. The execution trace generated by TOD weighs in at 3.6GB.</p><p>Eclipse session This experiment consists in performing a sequence of actions in the Eclipse IDE, with and without trace capture. Note that only the classes of the Eclipse IDE are instrumented, not those of the JDK (Sect. 7).</p><p>The actions performed are: creation of a new project, creation of a few classes, edition of their source code using auto-completion and other productivity features, execution of a rename refactoring, and step-by-step execution of the created program under the Eclipse integrated debugger. The following quantitative observations can be made:</p><p>• The Eclipse session is 10 times slower with trace capture enabled: it takes 244s (4 min.) without trace capture and 2324s (38 min.) with trace capture.</p><p>• The recorded execution trace comprises around 720 million events and weighs in at 33GB. The average event emission rate is 313kEv/s, 40% less than the worst-case scenario presented above.</p><p>On the qualitative side, this experiment shows that:</p><p>• The start-up time of Eclipse is greatly augmented when trace capture is enabled, due to the loading of instrumented classes (which are roughly 3 times bigger than non-instrumented classes).</p><p>• The Java source editor remains interactive for typing, although there is a noticeable slowdown.</p><p>• Some operations, such as invoking auto-completion, generating constructors or getters, or stepping with the debugger, are significantly slower with trace capture, but at a tolerable level.</p><p>Even though using TOD implies a perceptible slowdown of the debugged program, we believe that the benefits of omniscient debugging in quickly pinpointing hard-to-find bugs far outweigh this inconvenience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Database performance</head><p>To evaluate the performance of the distributed database of TOD we conducted measurements of recording throughput and query performance against the captured Eclipse trace of Sect. 6.1. Recall that the database performance is crucial to the debugging experience: (a) trace recording should ideally be in real time so that it is possible to start a debugging session as soon as the debugged program terminates (or reaches some determined state), and (b) the database must process queries in times compatible with human interaction so that the navigation interface is responsive.</p><p>Cluster setup. The TOD distributed trace database was deployed for these experiments on a dedicated cluster consisting of 10 database nodes (3GHz Intel Pentium 4 with Hyper-Threading disabled, 1GB of RAM, Sun JDK 1.5.0 08) and one dispatcher node (2.13GHz Intel Core2, 2GB of RAM, Sun JDK 1.6.0). The nodes are connected through a Gigabit Ethernet switch, but only the dispatcher node has a Gigabit link; the database nodes have a 100Mbit/s link. Each database node has a partition with 38GB of free space on a 80GB 7200RPM SATA hard drive.</p><p>Recording. The first experiment consists in determining the maximum throughput achievable by the dispatcher, with event storage and indexing disabled in the database nodes.</p><p>As shown in Fig. <ref type="figure" target="#fig_9">8</ref>, in the setup with only one database node, the recording throughput is limited to 250kEv/s, which corresponds to the limitation imposed by the 100Mbit/s network link. With more than one node, the dispatcher is able to handle up to 470kEv/s, regardless of the number of nodes. This represents around 20MB/s of outgoing network traffic on the dispatcher, which is lower than what is achievable with a Gigabit link: surprisingly the bottleneck of the dispatcher is the CPU. Profiling shows that most of the time is spent copying buffers in methods of the java.io framework. We assume that this issue would disappear in an optimized C version of the dispatcher.</p><p>Fig. <ref type="figure">9</ref> shows the evolution of recording throughput as events are added to the database. In average, a single database node is able to handle around 54kEv/s, and with 10 nodes we reach the dispatcher limit with 470kEv/s. The throughput of 54kEv/s of a single node translates to around 10MB/s of disk writes. This is lower than the maximum throughput of the disks that were used (around 40MB/s), and again the bottleneck is the CPU: most of the time is spent in methods of DataInputStream marshalling and unmarshalling primitive values. Note that with less than 4 nodes it is impossible to record the whole trace due to disk space constraints; therefore the following benchmarks consider scalability starting at 4 nodes.</p><p>Stepping queries. Figure <ref type="figure" target="#fig_5">10</ref> shows the efficiency of the step into and step over queries (Sect. 3.4). These results are obtained by starting a stepper at a random timestamp on each of the 350 threads of the recorded Eclipse session and performing 100 step operations. It is clear that step into queries are faster than step over queries, due to the fact that the former translate to a cursor query on thread id while the latter additionally use the call stack depth. The efficiency of both step queries surprisingly decreases as more database nodes are used; we are currently investigating this issue more thoroughly. In any case, step queries are fast enough to be used interactively, since they execute in less than a hundred milliseconds in the worst case.</p><p>Object reconstitution queries. The efficiency of object reconstitution queries is measured as the time taken to reconstitute the state of random objects of the Eclipse execution trace at different points in time. Figure <ref type="figure" target="#fig_5">11</ref> shows that these queries scale well with the number of nodes. On average, individual field values are retrieved in 120ms to 350ms. The time to reconstitute a full object is directly proportional to nodes merge (ms) fast (ms) speedup dist. (%) The merge and fast columns indicate the average query execution time using two counting methods. The speedup column indicates how much faster is the fast method. The dist. column is the distortion of the fast method compared to the exact merge method.</p><p>Table <ref type="table">5</ref>. Comparison of merge and fast count queries.</p><p>the number of its fields, thus the time to reconstitute an object of 7 fields (an average number) is comprised between 0.8s and 2.4s. Note that the object inspector window of TOD updates asynchronously, so that the user is not blocked until the state of the current object is fully reconstituted.</p><p>Count queries. We measured the execution speed of count queries and compared the two counting methods described in Sect. 4.4: merge counts and fast counts. We requested the event counts for each of the 350 threads of the Eclipse execution trace, on the entire time span of the trace and divided in n = 1, 000 subintervals. A comparison of the two count techniques is shown in Table <ref type="table">5</ref>. Fast counts perform 10 to 30 time faster than merge counts while providing a very precise approximation, with a distortion<ref type="foot" target="#foot_7">7</ref> below 2%. Figure <ref type="figure" target="#fig_12">12</ref> shows that merge counts scale very well but fast counts less so, because as each node records less events, the fast count algorithm must more frequently resort to lower-level indexes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Summary</head><p>Figure <ref type="figure" target="#fig_13">13</ref> summarizes our experimental results regarding trace capture and recording: the rate of event emission varies from 313kEv/s for a partially-instrumented interactive Eclipse session to 520kEv/s for a fully-instrumented CPU-intensive program; the recording throughput boasts a perfect scalability up to 8 nodes, and reaches 470kEv/s with 10 database nodes, where it is limited by the dispatcher bottleneck. It is therefore possible to record execution traces almost in real time. Count queries display good scalability, while step queries scale poorly. Still, the database is able to execute queries at a speed compatible with interactive navigation.</p><p>As a bottom line, although the results presented in this section could with no doubt be further enhanced through various optimizations, they already represent a consequent improvement over other existing implementations of omniscient debuggers. TOD is practically usable today, even on large traces produced by complex applications.  The graph shows the number of field values that can be reconstituted per second.</p><p>Figure <ref type="figure" target="#fig_5">11</ref>. Efficiency of object reconstitution queries.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Working with Partial Traces</head><p>Although TOD is designed to support huge execution traces, it is not always practical to record each and every event: the runtime overhead of event capture is important (Sect. 6.1), and so is the storage requirement. The idea of partial traces is to leverage the fact that during the development of a piece of software, some components are trusted, i.e. mature and well-tested, and it may not be necessary to generate and store events for the inner activities of these components. This section shows how scoped trace capture can facilitate debugging and how TOD makes it possible to work with partial traces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Motivating example: debugging the TOD Eclipse plugin</head><p>Let us consider as an example the debugging of the TOD Eclipse plugin itself. This example is fairly representative of component development for existing, trusted, frameworks or plugin architectures. Here, we might be interested in two types of bugs: those that are internal to the plugin and those that relate to the interaction between the plugin and the platform. In the first case, we do not need to capture events that occur within the Eclipse platform because it is considered trusted. In the second case, we have to record events that occur within the platform, but not necessarily all of them: it might be enough to record events of the Java tooling (JDT), or only of some part of it, for instance the UI. Figure <ref type="figure" target="#fig_5">14</ref> shows the impact of different trace scoping strategies on both the number of emitted events and the runtime overhead of trace capture, during different phases of the execution of the TOD plugin. In this small experiment we see that by appropriately scoping the trace capture, there are up to five orders of magnitude of difference in the number of emitted events (Fig. <ref type="figure" target="#fig_5">14a</ref>), and that the gains in runtime overhead can be up to 20 times (Fig. <ref type="figure" target="#fig_5">14b</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Dealing with missing information</head><p>Working with partial traces greatly enhances the applicability of TOD, but it implies that some information is lacking to reconstruct the whole history of the debugged program. It is therefore important that TOD systematically reports on missing information so that the user can soundly reason about the presented information. Missing information manifests in control flow and state reconstitution. The measures are taken after the following execution phases are passed: the IDE starts up; the TOD launch configuration dialog is opened; the target program is run; the control flow view is opened; events are navigated step by step; and the IDE exits.</p><p>Figure <ref type="figure" target="#fig_5">14</ref>. Emitted events and runtime overhead using scoped capture.</p><p>Control flow reconstitution. When non-instrumented code is called from instrumented code, and in turn calls instrumented code, some control flow information is lost. Such a case is illustrated in Fig. <ref type="figure" target="#fig_15">15</ref>. The code in Fig. <ref type="figure" target="#fig_15">15a</ref> calls a non-instrumented JDK method (Collections.sort) from an instrumented one (the main method). The sort method in turn calls the instrumented Comp.compare method, but indirectly (through the sort and mergeSort methods of Arrays). In Fig. <ref type="figure" target="#fig_15">15b</ref> the small dots indicate that control flow information is missing. In the absence of such an indication the user might think that Comp.compare was called directly and was the only method called by sort, which is not the case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>State reconstitution.</head><p>If a class has a non-private field that is written to by non-instrumented code, the value of this field at a given point in time cannot be determined accurately. TOD represents these fields in a distinctive color in the corresponding views. Again, without such a warning the user might not be able to reason accurately about the program.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Specifying partial traces</head><p>Partial traces are supported by means of mechanisms similar to those of partial behavioral reflection <ref type="bibr" target="#b26">[27]</ref>: both spatial and temporal selection of event generation. For spatial scoping, TOD supports class selectors, which are predicates on classes that should generate events (e.g. classes of a certain set of packages). <ref type="foot" target="#foot_8">8</ref> For temporal scoping, TOD supports dynamic activation of event generation, either globally or per thread, through a simple API. This is particularly useful in situations where a bug occurs after a long running time, or under specific dynamic conditions (which may for instance be related to control or data flow properties).</p><p>Implementation In our current prototype event emission code is woven with the original application code at load time. As a consequence, the spatial scope of event emission is fixed for the whole debugging session. <ref type="foot" target="#foot_9">9</ref> Temporal scoping is achieved by a flag check in event emission code, so there is still very light runtime overhead when event emission is disabled at runtime, compared to non-instrumented code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Related work</head><p>The work on TOD relates to different areas. Omniscient debugging of course, but execution trace recording is also used in a broader range of program understanding approaches, in particular query-based debugging and profiling. Techniques improving the efficiency of program understanding have been proposed in several areas like profiling and debugging of distributed application. We also discuss how our work on the database of TOD relates to general database techniques.</p><p>Omniscient debugging. Three proposals of omniscient debuggers are related to TOD. ZStep 95 is a reversible stepper for Lisp. In addition to the standard features of omniscient debuggers, ZStep 95 provides animated views of data structures of the debugged program. It provides excellent solutions to the cognitive issues of debugging but does not address performance and scalability. More recently, Bil Lewis proposed an omniscient debugger for Java, ODB <ref type="bibr" target="#b14">[15]</ref>, and Hofer et al. implemented a similar system for Smalltalk, called Unstuck <ref type="bibr" target="#b10">[11]</ref>. The work on TOD was actually inspired by the omniscient debugger of Bil Lewis. It has the ability to not only navigate the execution history but also to restore the state of the program as it was at any given point in time, so that its execution can be resumed at that point. Events are stored in the target program's address space, which has serious limitations in terms of scalability and potential influence of the debugger on the behavior of the debugged application. For scalability, ODB makes it possible to set a fixed limit on the number of events that can be kept in the execution trace; older events are discarded. TOD provides much better scalability, as demonstrated in this paper. Furthermore, both ODB and Unstuck lack the high-level overviews that are provided by TOD in murals.</p><p>CodeGuide <ref type="bibr" target="#b20">[21]</ref> is a commercial development environment for Java that features a back-in-time debugger. Breakpoint-based debugging can be combined with tracebased, bi-directional stepping. The trace is however limited to the last few thousands events, and the important feature of root cause finding is not available. High-level overviews are also not provided.</p><p>Query-based debugging. Query-based debugging consists in identifying events that match a query expressed in a highlevel language. Queries can be formulated a priori (before running the program) or a posteriori (after the program has been executed). In Hy+ <ref type="bibr" target="#b3">[4]</ref> a-posteriori queries are expressed in a graphical language and deal with distributed computations. PQL <ref type="bibr" target="#b18">[19]</ref> provides a very high-level and powerful a-priori query model. Whyline <ref type="bibr" target="#b12">[13]</ref> guides the programmer by proposing a set of possible a-posteriori queries. The TQuel language allows programmers to express a-priori queries declaratively, providing explicit support for temporal queries <ref type="bibr" target="#b24">[25]</ref>. LeDoux and Parker <ref type="bibr" target="#b13">[14]</ref> formulate a-posteriori Prolog queries on the execution of concurrent Ada programs. Opium <ref type="bibr" target="#b6">[7]</ref> uses Prolog queries to debug Prolog programs and seamlessly supports breakpoint-based debugging and trace-based debugging. Coca <ref type="bibr" target="#b5">[6]</ref> uses a-priori Prolog queries to debug C programs. In an upside down approach the Mercury Declarative Debugger <ref type="bibr" target="#b17">[18]</ref> asks the user questions about the correctness of computations performed by the program so as to quickly locate incorrect ones.</p><p>The limited class of queries supported by TOD is sufficient for the features of omniscient debugging, but scalability and efficiency come at the expense of a much less expressive query model than those provided in the above approaches. Although in TOD basic queries can be combined algorithmically, queries that relate several events cannot be executed efficiently.</p><p>Trace reduction. One of the priorities of profiling is to reduce the performance impact of the tool on the target application. One technique consists in reducing the trace via clustering <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b27">28]</ref>, which also reduces the overhead of capture, although at the price of a loss in precision. Debugging distributed applications benefits from high-level trace recording, as only message sends between nodes need be recorded <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b3">4]</ref>: useful views of the computations can be provided with much less information than that used in omniscient debugging. Opium <ref type="bibr" target="#b6">[7]</ref> lets the user specify prefiltering predicates, that by filtering out uninteresting events permit to reduce the number of context switches between the debugged process and the debugger. Mercury <ref type="bibr" target="#b17">[18]</ref> by default only records events up to a certain call depth; if more detail is needed relevant goals are automatically re-executed.</p><p>With TOD we took the opposite approach, providing a scalable event database that copes with huge execution traces. However TOD also provides a mean for reducing the size of the execution traces by letting the user select which parts of the program emit events.</p><p>Replay-based debugging. Back-in-time debugging can be achieved by replaying the debugged program until some determined point before the current execution point. Igor <ref type="bibr" target="#b7">[8]</ref> and Bdb <ref type="bibr" target="#b1">[2]</ref> make use of periodic state saving, or checkpoints, to reduce the time needed to reach a particular past execution point: execution is resumed at the last checkpoint preceding the desired execution point. The main advantage of replay-based debugging compared to trace capture is the lower runtime overhead (around 2x for Bdb and 4x for Igor, versus a maximum of 115x for TOD). However, backward debugging moves can be slow, especially when going far away from the current execution point. Furthermore, if the execution point is moved backwards, moving it again forwards means re-executing the program, which is not practical for long-running programs. With TOD the entire history of the program is available and freely navigatable.</p><p>A crucial issue of replay-based debugging is that of deterministic replay: system calls that rely on external resources such as network connections might return different results at different times. Bdb <ref type="bibr" target="#b1">[2]</ref> and Jockey <ref type="bibr" target="#b22">[23]</ref> address this by recording the results of non-deterministic system calls and reinjecting them into the program when it is replayed. However this is a brittle solution as many system calls must be handled in different ways.</p><p>Database techniques. Finally, the importance of physical data layout in the efficiency of several relational data indexing techniques has been shown in <ref type="bibr" target="#b0">[1]</ref>. Seshadri et al. <ref type="bibr" target="#b23">[24]</ref> present query plan optimization techniques for sequential databases, a superset of execution trace databases like ours. Stonebraker et al. <ref type="bibr" target="#b25">[26]</ref> make a strong point in favor of specialized database management systems for specific applications. Our work on TOD applies classical indexing and paging techniques in a domain-specific manner, leveraging the very specificities of execution traces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Conclusion</head><p>Assuming the great potential of omniscient debuggers in alleviating one of the most tedious and costly part of software development, this work shows that it is realistic to provide omniscient debuggers in modern development environments if appropriate measures are taken to address the associated efficiency, scalability, and usability issues.</p><p>We have presented TOD, a Trace-Oriented Debugger for Java, which contributes to the scalability of omniscient debugging at three levels: (a) at the trace generation level, by relying on an efficient ad-hoc weaver providing selective emission of events encoded in a concise binary format; (b) at the storage and query level, by proposing a specialized distributed database with an optimized indexing scheme; and (c) at the user interface level, by providing specialized interface components, in particular murals, which ease the interactive analysis of huge event traces, and visual feedback supporting the use of partial traces. The scalability of TOD has been shown by giving both a complexity analysis of the indexing and querying algorithms, and by reporting on benchmarks of the actual prototype.</p><p>There are several promising directions for experimenting with other techniques enhancing the applicability of omniscient debuggers. Full-scale experiments of using TOD in large real-world development projects would be invaluable for empirically assessing the benefits of omniscient debugging. At the database level, indexes for frequently-used compound conditions could be materialized so as to improve query efficiency, and the overhead caused by event emission could be strongly reduced by not reifying redundant information. For dealing with partial traces, it would be interesting to leverage the hot swap feature of modern JVMs for adding or removing instrumentation at runtime. It would also be worthy to refine spatial scoping to the expression level, and to explore the use of static analysis to reduce even more the set of generated events. Finally, specific behavior simulations could be provided for trusted and widely-used classes (e.g. ArrayList), so that their state could be reconstituted without needing to fully instrument their internals.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. High-level architecture of TOD</figDesc><graphic coords="3,54.00,72.00,239.10,70.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Navigation among events matching a cursor predicate.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Stepping with TOD in Eclipse.</figDesc><graphic coords="6,134.98,72.00,340.16,195.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Thread murals.</figDesc><graphic coords="6,104.21,333.23,401.70,109.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. B+Tree index.</figDesc><graphic coords="7,54.00,72.00,239.11,94.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Algorithm 1</head><label>1</label><figDesc>MERGE-JOIN merge-join(S, j 1 ,. . . ,jm,C 1 ,. . . ,Cm): result ← ∅ for l = 1 to m do index[l] ← I j l (C l ), pos[l] ← 1 while there are more elements do match ← true, ref I ← -1 minL ← -1, minT S ← +∞ for l = 1 to m do (curT S, curI) ← index[l][pos[l]]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Number of indexes for each index set in an Eclipse execution trace.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Architecture of the distributed database backend.</figDesc><graphic coords="10,54.00,72.00,239.10,136.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Dispatcher throughput.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 .Figure 10 .</head><label>910</label><figDesc>Figure 9. Recording throughput.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 12 .</head><label>12</label><figDesc>Figure 12. Efficiency of counts queries.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 13 .</head><label>13</label><figDesc>Figure 13. Experimental results for trace emission, dispatching, and recording.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 15 .</head><label>15</label><figDesc>Figure 15. Materialization of incomplete control flow information.</figDesc><graphic coords="14,317.01,220.16,239.11,64.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Effect of index set splitting on the number of indexes, number of entries per index, and query cost. N is the number of split components and B is the total number of entries in the index set.</figDesc><table><row><cell>Index set</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Entries</cell><cell>Query</cell></row><row><cell cols="4">splitting Number of indexes</cell><cell cols="2">per index</cell><cell>cost</cell></row><row><cell>No</cell><cell></cell><cell>d N √</cell><cell>d</cell><cell>B/d B/ N √</cell><cell>d</cell><cell>B/d</cell></row><row><cell>Yes</cell><cell>. . .</cell><cell>. . . N √</cell><cell>d</cell><cell>. . . B/ N √</cell><cell>d</cell><cell>N •B N √ d</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Index set splitting. value component. As shown in Sect. 4.2, the efficiency of queries is proportional to the size of the involved indexes. Table 3 summarizes the slowdown incurred by splitting an index set containing d indexes and totalling B entries. Each index in the set contains on average B/d entries, thus the cost of a query on one of those indexes is proportional to B/d. If the index set is split the number of indexes per index set becomes d = N √ d and there are on average B/d entries per index. The cost of the query becomes proportional to</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>The RAM column is the JVM heap size in MB. The time column is the execution time in seconds. The emit. and rec. columns indicate the number of events emitted, and recorded (available to the debugger). The rate column is the recording throughput, in kEv/s. The ovh. column is the overhead compared to the standalone execution.</figDesc><table><row><cell cols="4">Setup RAM time emit.</cell><cell cols="3">rec. rate ovh.</cell></row><row><cell>None</cell><cell>16</cell><cell>1.53</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>1</cell></row><row><cell>ODB1</cell><cell>500</cell><cell cols="2">179 110m</cell><cell>5m</cell><cell cols="2">614 116</cell></row><row><cell>ODB2</cell><cell>64</cell><cell cols="5">188 110m 530k 585 122</cell></row><row><cell>TOD</cell><cell>16</cell><cell>173</cell><cell>90m</cell><cell cols="3">90m 520 113</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Overhead of event emission.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>http://reflex.dcc.uchile.cl/TOD for download and small illustrative videos.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>We give methods and constructors the collective name of behaviors.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>JVMTI: Java Virtual Machine Tool Interface, part of the Java 5 platform.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>Row headers are event kinds and column headers are the possible attributes (ts: timestamp, tid: thread id, depth: call stack depth, pev: pointer to parent event, loc: source code location, fid: field id, bid: behavior id, vid: local variable id, idx: array index, val: value, ret: return value, tgt: target, exc: exception, args: arguments).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4"><p>Events of different threads might arrive out of order because of the way serialized events are buffered; as reordering them is cheap (only the last few events must be considered) we assume events have been reordered before they reach the backend.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5"><p>The kind = F W part of the query is omitted in practice because only Field Write events have a value for the field id attribute.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_6"><p>The different numbers of emitted events between TOD and ODB are apparently due to differences in the trace model.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_7"><p>Calculated as: ( P n i=1 |merge[i] -f ast[i]|)/ P n i=1 merge[i]</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_8"><p>It would be possible to refine spatial scoping using operation selectors<ref type="bibr" target="#b26">[27]</ref>, enabling expression-level selection to further reduce the size of the execution trace. This feature has not yet been integrated in TOD.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_9"><p><ref type="bibr" target="#b8">9</ref> Although recent JVMs allow classes to be modified at runtime, we do not yet use this feature.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Bil Lewis for his inspiring work on the Omniscient Debugger, Johan Fabry and Jacques Noyé for their invaluable feedback on this manuscript, and Sergio Aguilera and Hernan Cuevas for their support with the cluster used for the benchmarks. We also thank the anonymous OOPSLA reviewers for their insightful comments. This work is partially financed by the EU NoE CoreGRID.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Guillaume Pothier is financed by a PhD grant from NIC Chile † É. Tanter is partially financed by the Millenium Nucleus Center for Web Research, Grant P04-067-F, Mideplan, Chile, and by FONDECYT Project 11060493.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Storage and access in relational databases</title>
		<author>
			<persName><forename type="first">M</forename><surname>Blasgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Eswaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Systems Journal</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">363</biblScope>
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Efficient algorithms for bidirectional debugging</title>
		<author>
			<persName><forename type="first">Bob</forename><surname>Boothe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI &apos;00: Proceedings of the ACM SIGPLAN 2000 conference on Programming language design and implementation</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="299" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">ASM: a code manipulation tool to implement adaptable systems</title>
		<author>
			<persName><forename type="first">Éric</forename><surname>Bruneton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Romain</forename><surname>Lenglet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thierry</forename><surname>Coupaye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ASF (ACM SIGOPS France) Journées Composants 2002: Adaptable and extensible component systems</title>
		<meeting>the ASF (ACM SIGOPS France) Journées Composants 2002: Adaptable and extensible component systems</meeting>
		<imprint>
			<date type="published" when="2002-11">November 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Visualizing and querying distributed event traces with Hy+</title>
		<author>
			<persName><forename type="first">Mariano</forename><forename type="middle">P</forename><surname>Consens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Masum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><forename type="middle">O</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName><surname>Mendelzon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Application of Databases</title>
		<meeting>the International Conference on Application of Databases</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">819</biblScope>
			<biblScope unit="page" from="123" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Eclipse: A platform for integrating development tools</title>
		<author>
			<persName><forename type="first">Jim</forename><surname>Des</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rivières</forename></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Wiegand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Systems Journal</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="371" to="383" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Coca: an automated debugger for c</title>
		<author>
			<persName><forename type="first">Mireille</forename><surname>Ducassé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICSE &apos;99: Proceedings of the 21st international conference on Software engineering</title>
		<meeting><address><addrLine>Los Alamitos, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="504" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Opium: An extendable trace analyzer for prolog</title>
		<author>
			<persName><forename type="first">Mireille</forename><surname>Ducassé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Logic Programming</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="177" to="223" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Igor: a system for program debugging via reversible execution</title>
		<author>
			<persName><forename type="first">I</forename><surname>Stuart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Channing</forename><forename type="middle">B</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PADD &apos;88: Proceedings of the 1988 ACM SIGPLAN and SIGOPS workshop on Parallel and distributed debugging</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="112" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Compression techniques to simplify the analysis of large execution traces</title>
		<author>
			<persName><forename type="first">Abdelwahab</forename><surname>Hamou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-Lhadj</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">C</forename><surname>Lethbridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IWPC &apos;02: Proceedings of the 10th International Workshop on Program Comprehension</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">159</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A real-time microprocessor debugging technique</title>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">R</forename><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGSOFT &apos;83: Proceedings of the symposium on High-level debugging</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1983">1983</date>
			<biblScope unit="page" from="145" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Implementing a backward-in-time debugger</title>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Hofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcus</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stéphane</forename><surname>Ducasse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NODe&apos;06</title>
		<title level="s">Lecture Notes in Informatics</title>
		<meeting>NODe&apos;06</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="17" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The information mural: A technique for displaying and navigating large information spaces</title>
		<author>
			<persName><forename type="first">Dean</forename><forename type="middle">F</forename><surname>Jerding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">T</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="257" to="271" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Designing the whyline: a debugging interface for asking questions about program behavior</title>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">J</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brad</forename><forename type="middle">A</forename><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<editor>
			<persName><forename type="first">Elizabeth</forename><surname>Dykstra-Erickson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Manfred</forename><surname>Tscheligi</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="151" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Saving traces for ada debugging</title>
		<author>
			<persName><forename type="first">Carol</forename><forename type="middle">H</forename><surname>Ledoux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stott Parker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jr</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ada in Use, Proceedings of the Ada International Conference</title>
		<imprint>
			<date type="published" when="1985-09">September 1985</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="97" to="108" />
		</imprint>
	</monogr>
	<note>Published as</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Debugging backwards in time</title>
		<author>
			<persName><forename type="first">Bil</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Workshop on Automated Debugging (AADEBUG 2003)</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Ronsse</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">De</forename><surname>Bosschere</surname></persName>
		</editor>
		<meeting>the Fifth International Workshop on Automated Debugging (AADEBUG 2003)<address><addrLine>Ghent, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Reversible object-oriented interpreters</title>
		<author>
			<persName><forename type="first">Henry</forename><surname>Lieberman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Jean</forename><surname>Bézivin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jean-Marie</forename><surname>Hullot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Pierre</forename><surname>Cointe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Henry</forename><surname>Lieberman</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">276</biblScope>
			<biblScope unit="page" from="11" to="19" />
			<date type="published" when="1987">1987</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">ZStep 95: A reversible, animated source code stepper</title>
		<author>
			<persName><forename type="first">Henry</forename><surname>Lieberman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoper</forename><surname>Fry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Visualization -Programming as a Multimedia Experience</title>
		<editor>
			<persName><forename type="first">John</forename><surname>Stasko</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">John</forename><surname>Domingue</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Marc</forename><forename type="middle">H</forename><surname>Brown</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Blaine</forename><forename type="middle">A</forename><surname>Price</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA-London</addrLine></address></meeting>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="277" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Divideand-query and subterm dependency tracking in the mercury declarative debugger</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Maclarty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zoltan</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AADEBUG&apos;05: Proceedings of the sixth international symposium on Automated analysis-driven debugging</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="59" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Finding application errors and security flaws using PQL: a program query language</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Livshits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monica</forename><forename type="middle">S</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGPLAN Notices</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="365" to="383" />
			<date type="published" when="2005-10">October 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Realtime statistical clustering for event trace reduction</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">Y</forename><surname>Nickolayev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Reed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Supercomputer Applications and High Performance Computing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="144" to="159" />
			<date type="published" when="1997">1997</date>
			<pubPlace>Summer</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Codeguide back-in-time debugger</title>
		<author>
			<persName><surname>Omnicore</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Benchmarks of COTS database management systems</title>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Pothier</surname></persName>
		</author>
		<idno>TR/DCC-2006-16</idno>
		<imprint>
			<date type="published" when="2006-10">October 2006</date>
		</imprint>
		<respStmt>
			<orgName>University of Chile</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Jockey: a user-space library for record-replay debugging</title>
		<author>
			<persName><forename type="first">Yasushi</forename><surname>Saito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixth international symposium on Automated analysis-driven debugging (AADEBUG 2005)</title>
		<meeting>the sixth international symposium on Automated analysis-driven debugging (AADEBUG 2005)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="69" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sequence query processing</title>
		<author>
			<persName><forename type="first">Praveen</forename><surname>Seshadri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miron</forename><surname>Livny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raghu</forename><surname>Ramakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGMOD Record (ACM Special Interest Group on Management of Data)</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="430" to="441" />
			<date type="published" when="1994-06">June 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Monitoring in a software development environment: A relational approach</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Snodgrass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGPLAN Not</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="124" to="131" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">One size fits all? part 2: Benchmarking studies</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Stonebraker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuck</forename><surname>Bear</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ugur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitch</forename><surname>¸etintemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tingjian</forename><surname>Cherniack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nabil</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stavros</forename><surname>Hachem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Harizopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennie</forename><surname>Lifter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stanley</forename><forename type="middle">B</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><surname>Zdonik</surname></persName>
		</author>
		<ptr target="www.crdrdb.org" />
	</analytic>
	<monogr>
		<title level="m">Conference on Innovative Data Systems Research (CIDR 2007)</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="173" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Partial behavioral reflection: Spatial and temporal selection of reification</title>
		<author>
			<persName><forename type="first">Éric</forename><surname>Tanter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacques</forename><surname>Noyé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denis</forename><surname>Caromel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Cointe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM SIGPLAN Conference on Object-Oriented Programming Systems, Languages and Applications (OOPSLA 2003)</title>
		<editor>
			<persName><forename type="first">Ron</forename><surname>Crocker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Guy</forename><forename type="middle">L</forename><surname>Steele</surname><genName>Jr</genName></persName>
		</editor>
		<meeting>the 18th ACM SIGPLAN Conference on Object-Oriented Programming Systems, Languages and Applications (OOPSLA 2003)<address><addrLine>Anaheim, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2003-10">October 2003</date>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="27" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Managing trace data volume through a heuristical clustering process based on event execution frequency</title>
		<author>
			<persName><forename type="first">Andy</forename><surname>Zaidman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serge</forename><surname>Demeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CSMR &apos;04: Proceedings of the Eighth Euromicro Working Conference on Software Maintenance and Reengineering (CSMR&apos;04)</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">329</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
