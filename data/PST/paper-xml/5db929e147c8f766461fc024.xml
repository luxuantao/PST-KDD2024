<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Improved Neural Baseline for Temporal Relation Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Qiang</forename><surname>Ning</surname></persName>
							<email>qning2@illinois.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sanjay</forename><surname>Subramanian</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
							<email>danroth@seas.upenn.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">An Improved Neural Baseline for Temporal Relation Extraction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Determining temporal relations (e.g., before or after) between events has been a challenging natural language understanding task, partly due to the difficulty to generate large amounts of high-quality training data. Consequently, neural approaches have not been widely used on it, or showed only moderate improvements. This paper proposes a new neural system that achieves about 10% absolute improvement in accuracy over the previous best system (25% error reduction) on two benchmark datasets. The proposed system is trained on the stateof-the-art MATRES dataset and applies contextualized word embeddings, a Siamese encoder of a temporal common sense knowledge base, and global inference via integer linear programming (ILP). We suggest that the new approach could serve as a strong baseline for future research in this area.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Temporal relation (TempRel) extraction has been considered as a major component of understanding time in natural language <ref type="bibr" target="#b15">(Do et al., 2012;</ref><ref type="bibr">Uz-Zaman et al., 2013;</ref><ref type="bibr" target="#b26">Minard et al., 2015;</ref><ref type="bibr" target="#b22">Llorens et al., 2015;</ref><ref type="bibr" target="#b29">Ning et al., 2018a)</ref>. However, the annotation process for TempRels is known to be time consuming and difficult even for humans, and existing datasets are usually small and/or have low inter-annotator agreements (IAA); e.g., <ref type="bibr" target="#b39">UzZaman et al. (2013)</ref>; <ref type="bibr" target="#b7">Chambers et al. (2014)</ref>; <ref type="bibr" target="#b33">O'Gorman et al. (2016)</ref> reported Kohen's ï£¿ and F 1 in the 60's. Albeit the significant progress in deep learning nowadays, neural approaches have not been used extensively for this task, or showed only moderate improvements <ref type="bibr" target="#b14">(Dligach et al., 2017;</ref><ref type="bibr" target="#b21">Lin et al., 2017;</ref><ref type="bibr" target="#b24">Meng and Rumshisky, 2018)</ref>. We think it is important for to understand: is it because we missed a "magic" neural architecture, because the training dataset is small, or because the quality of the dataset should be improved?</p><p>Recently, <ref type="bibr" target="#b31">Ning et al. (2018c)</ref> introduced a new dataset called Multi-Axis Temporal RElations for Start-points (MATRES). MATRES is still relatively small in its size (15K TempRels), but has a higher annotation quality from its improved task definition and annotation guideline. This paper uses MATRES to show that a long short-term memory (LSTM) <ref type="bibr" target="#b17">(Hochreiter and Schmidhuber, 1997)</ref> system can readily outperform the previous state-of-the-art system, CogCompTime <ref type="bibr" target="#b32">(Ning et al., 2018d)</ref>, by a large margin. The fact that a standard LSTM system can significantly improve over a feature-based system on MATRES indicates that neural approaches have been mainly dwarfed by the quality of annotation, instead of specific neural architectures or the small size of data.</p><p>To gain a better understanding of the standard LSTM method, we extensively compare the usage of various word embedding techniques, including word2vec <ref type="bibr" target="#b25">(Mikolov et al., 2013)</ref>, GloVe <ref type="bibr" target="#b35">(Pennington et al., 2014)</ref>, FastText <ref type="bibr" target="#b4">(Bojanowski et al., 2016)</ref>, ELMo <ref type="bibr" target="#b36">(Peters et al., 2018)</ref>, and BERT <ref type="bibr" target="#b12">(Devlin et al., 2018)</ref>, and show their impact on TempRel extraction. Moreover, we further improve the LSTM system by injecting knowledge from an updated version of TEMPROB, an automatically induced temporal common sense knowledge base that provides typical TempRels between events<ref type="foot" target="#foot_0">1</ref>  <ref type="bibr" target="#b30">(Ning et al., 2018b)</ref>. Altogether, these components improve over CogCompTime by about 10% in F 1 and accuracy. The proposed system is public<ref type="foot" target="#foot_1">2</ref> and can serve as a strong baseline for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Early computational attempts to TempRel extraction include <ref type="bibr" target="#b23">Mani et al. (2006)</ref>; <ref type="bibr" target="#b10">Chambers et al. (2007)</ref>; <ref type="bibr" target="#b1">Bethard et al. (2007)</ref>; <ref type="bibr" target="#b41">Verhagen and Pustejovsky (2008)</ref>, which aimed at building classic learning algorithms (e.g., perceptron, SVM, and logistic regression) using hand-engineered features extracted for each pair of events. The frontier was later pushed forward through continuous efforts in a series of SemEval workshops <ref type="bibr" target="#b40">(Verhagen et al., 2007</ref><ref type="bibr" target="#b42">(Verhagen et al., , 2010;;</ref><ref type="bibr" target="#b39">UzZaman et al., 2013;</ref><ref type="bibr" target="#b0">Bethard et al., 2015</ref><ref type="bibr" target="#b2">Bethard et al., , 2016</ref><ref type="bibr" target="#b3">Bethard et al., , 2017))</ref>, and significant progresses were made in terms of data annotation <ref type="bibr" target="#b37">(Styler IV et al., 2014;</ref><ref type="bibr" target="#b6">Cassidy et al., 2014;</ref><ref type="bibr" target="#b27">Mostafazadeh et al., 2016;</ref><ref type="bibr" target="#b33">O'Gorman et al., 2016)</ref>, structured inference <ref type="bibr" target="#b8">(Chambers and Jurafsky, 2008a;</ref><ref type="bibr" target="#b15">Do et al., 2012;</ref><ref type="bibr" target="#b7">Chambers et al., 2014;</ref><ref type="bibr" target="#b29">Ning et al., 2018a)</ref>, and structured machine learning <ref type="bibr" target="#b43">(Yoshikawa et al., 2009;</ref><ref type="bibr" target="#b19">Leeuwenberg and Moens, 2017;</ref><ref type="bibr" target="#b28">Ning et al., 2017)</ref>.</p><p>Since TempRel is a specific relation type, it is natural to borrow recent neural relation extraction approaches <ref type="bibr" target="#b44">(Zeng et al., 2014;</ref><ref type="bibr">Zhang et al., 2015;</ref><ref type="bibr" target="#b45">Zhang and Wang, 2015;</ref><ref type="bibr" target="#b43">Xu et al., 2016)</ref>. There have indeed been such attempts, e.g., in clinical narratives <ref type="bibr" target="#b14">(Dligach et al., 2017;</ref><ref type="bibr" target="#b21">Lin et al., 2017;</ref><ref type="bibr" target="#b38">Tourille et al., 2017)</ref> and in newswire <ref type="bibr" target="#b11">(Cheng and Miyao, 2017;</ref><ref type="bibr" target="#b24">Meng and Rumshisky, 2018;</ref><ref type="bibr" target="#b20">Leeuwenberg and Moens, 2018)</ref>. However, their improvements over feature-based methods were moderate <ref type="bibr" target="#b21">(Lin et al. (2017)</ref> even showed negative results). Given the low IAAs in those datasets, it was unclear whether it was simply due to the low data quality or neural methods inherently do not work well for this task.</p><p>A recent annotation scheme, <ref type="bibr" target="#b31">Ning et al. (2018c)</ref>, introduced the notion of multi-axis to represent the temporal structure of text, and identified that one of the sources of confusions in human annotation is asking annotators for TempRels across different axes. When annotating only sameaxis TempRels, along with some other improvements to the annotation guidelines, MATRES was able to achieve much higher IAAs. <ref type="foot" target="#foot_2">3</ref> This dataset opens up opportunities to study neural methods for this problem. In Sec. 3, we will explain our proposed LSTM system, and also highlight the major differences from previous neural attempts.</p><p>agate to subsequent modules. Here we study the usage of LSTM networks<ref type="foot" target="#foot_3">4</ref> on the TempRel extraction problem as an end-to-end approach that only takes a sequence of word embeddings as input (assuming that the position of events are known). Conceptually, we need to feed those word embeddings to LSTMs and obtain a vector representation for a particular pair of events, which is followed by a fully-connected, feed-forward neural network (FFNN) to generate confidence scores for each output label. Based on the confidence scores, global inference is performed via integer linear programming (ILP), which is a standard procedure used in many existing works to enforce the transitivity property of time <ref type="bibr" target="#b9">(Chambers and Jurafsky, 2008b;</ref><ref type="bibr" target="#b15">Do et al., 2012;</ref><ref type="bibr" target="#b28">Ning et al., 2017</ref>). An overview of the proposed network structure and corresponding parameters can be found in Fig. <ref type="figure">1</ref>. Below we also explain the main components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Handling Event Positions</head><p>Each TempRel is associated with two events, and for the same text, different pairs of events possess different relations, so it is critical to indicate the positions of those events when we train LSTMs for the task. The most straightforward way is to concatenate the hidden states from both time steps that correspond to the location of those events (Fig. <ref type="figure">1b</ref>). <ref type="bibr" target="#b14">Dligach et al. (2017)</ref> handled this issue differently, by adding XML tags immediately before and after each event (Fig. <ref type="figure">1a</ref>). For example, in the sentence, After eating dinner, he slept comfortably, where the two events are bold-faced, they will convert the sequence into After &lt;e1&gt; eating &lt;/e1&gt; dinner, he &lt;e2&gt; slept &lt;/e2&gt; comfortably. The XML markups, which was initially proposed under the name of position indicators for relation extraction <ref type="bibr" target="#b45">(Zhang and Wang, 2015)</ref>, uniquely indicate the event positions to LSTM, such that the final output of LSTM can be used as a representation of those events and their context. We compare both methods in this paper, and as we show later, the straightforward concatenation method is already as good as XML tags for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Common Sense Encoder (CSE)</head><p>In naturally occurring text that expresses TempRels, connective words such as since, when, or until are often not explicit; nevertheless, humans can still infer the TempRels using common sense with respect to the events. For example, even without context, we know that die is typically after explode and schedule typically before attend. <ref type="bibr" target="#b30">Ning et al. (2018b)</ref> was an initial attempt to acquire such knowledge, by aggregating automatically extracted TempRels from a large corpus. The resulting knowledge base, TEMPROB, contains observed frequencies of tuples (v1, v2, r) representing the probability of verb 1 and verb 2 having relation r and it was shown a useful resource for TempRel extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LSTM</head><p>However, TEMPROB is a simple counting model and fails (or is unreliable) for unseen (or rare) tuples. For example, we may see (ambush, die) less frequently than (attack, die) in a corpus, and the observed frequency of (ambush, die) being before or after is thus less reliable. However, since "ambush" is semantically similar to "attack", the statistics of (attack, die) can actually serve as an auxiliary signal to (ambush, die). Motivated by this idea, we introduce common sense encoder (CSE): We fit an updated version of TEMPROB via a Siamese network <ref type="bibr" target="#b5">(Bromley et al., 1994)</ref> that generalizes to unseen tuples through the resulting embeddings for each verb (Fig. <ref type="figure">1c</ref>). Note that the TEMPROB we use is reconstructed using the same method described in <ref type="bibr" target="#b30">Ning et al. (2018b)</ref> with the base method changed to CogCompTime. Once trained, CSE will remain fixed when training the LSTM part (Fig. <ref type="figure">1a or b</ref>) and the feedforward neural network part (Fig. <ref type="figure">1d</ref>). We only use CSE for its output. In the beginning, we tried to directly use the output (i.e., a scalar) and the influence on performance was negligible. Therefore, here we discretize the CSE output, change it to categorical embeddings, concatenate them with the LSTM output, and then produce the confidence scores (Fig. <ref type="figure">1d</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>The MATRES dataset<ref type="foot" target="#foot_4">5</ref> contains 275 news articles from the TempEval3 workshop <ref type="bibr" target="#b39">(UzZaman et al., 2013)</ref> with newly annotated events and TempRels. It has 3 sections: TimeBank (TB), AQUAINT (AQ), and Platinum (PT). We followed the official split (i.e., TB+AQ for training and PT for testing), and further set aside 20% of the training data as the development set to tune learning rates and epochs. We also show our performance on another dataset, TCR<ref type="foot" target="#foot_5">6</ref>  <ref type="bibr" target="#b29">(Ning et al., 2018a)</ref>, which contains both temporal and causal relations and we only need the temporal part. The label set for both datasets are before, after, equal, and vague. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results and Discussion</head><p>We compare with the most recent version of CogCompTime, the state-of-the-art on MATRES.<ref type="foot" target="#foot_6">7</ref> Note that in Table <ref type="table" target="#tab_2">2</ref>, CogCompTime performed slightly different to <ref type="bibr" target="#b32">Ning et al. (2018d)</ref>: Cog-CompTime reportedly had F 1 =65.9 (Table <ref type="table" target="#tab_2">2</ref> Line 3 therein) and here we obtained F 1 =66.6. In addition, <ref type="bibr" target="#b32">Ning et al. (2018d)</ref> only reported F 1 scores, while we also use another two metrics for a more thorough comparison: classification accuracy (acc.) and temporal awareness F aware , where the awareness score is for the graphs represented by a group of related TempRels (more details in the appendix). We also report the average of those three metrics in our experiments.</p><p>Table <ref type="table" target="#tab_2">2</ref> compares the two different ways to handle event positions discussed in Sec. 3.1: position indicators (P.I.) and simple concatenation (Concat), both of which are followed by network (d) in Fig. <ref type="figure">1</ref> (i.e., without using Siamese yet). We extensively studied the usage of various pretrained word embeddings, including conventional embeddings (i.e., the medium versions of word2vec, GloVe, and FastText provided in the Magnitude package <ref type="bibr" target="#b34">(Patel et al., 2018)</ref>) and contextualized embeddings (i.e., the original ELMo and large uncased BERT, respectively); except for the input embeddings, we kept all other parameters the same. We used cross-entropy loss and the StepLR optimizer in PyTorch that decays the learning rate by 0.5 every 10 epochs (performance not sensitive to it).</p><p>Comparing to the previously used P.I. <ref type="bibr" target="#b14">(Dligach et al., 2017)</ref>, we find that, with only two exceptions (underlined in Given the above two observations, we further incorporated our common sense encoder (CSE) into "Concat" with ELMo and BERT in Table <ref type="table" target="#tab_2">2</ref>. We split TEMPROB into train (80%) and validation (20%). The proposed Siamese network (Fig. <ref type="figure">1c</ref>) was trained by minimizing the crossentropy loss using Adam <ref type="bibr" target="#b18">(Kingma and Ba, 2014)</ref> (learning rate 1e-4, 20 epochs, and batch size 500). We first see that CSE improved on top of Concat for both ELMo and BERT under all metrics, confirming the benefit of TEMPROB; second, as compared to CogCompTime, the proposed Con-cat+CSE achieved about 10% absolute gains in accuracy and F 1 , 5% in awareness score F aware , and 8% in the three-metric-average metric, with p &lt; 0.001 per the McNemar's test. Roughly speaking, the 8% gain is contributed by LSTMs for 2%, contextualized embeddings for 4%, and CSE for 2%. Again, no statistical significance were observed between using ELMo and BERT. Table <ref type="table">3</ref> furthermore applies CogCompTime and the proposed Concat+CSE system on a different test set called TCR <ref type="bibr" target="#b29">(Ning et al., 2018a)</ref>. Both systems achieved better scores (suggesting that TCR is easier than MATRES), while the proposed sys-tem still outperformed CogCompTime by roughly 8% under the three-metric-average metric, consistent with our improvement on MATRES. Table <ref type="table">3</ref>: Further evaluation of the proposed system, i.e., Concat (Table <ref type="table">3</ref>.1) plus CSE (Sec. 3.2), on the TCR dataset <ref type="bibr" target="#b29">(Ning et al., 2018a)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Temporal relation extraction has long been an important yet challenging task in natural language processing. Lack of high-quality data and difficulty in the learning problem defined by previous annotation schemes inhibited performance of neural-based approaches. The discoveries that LSTMs readily improve the feature-based stateof-the-art CogCompTime on the MATRES and TCR datasets by a large margin not only give the community a strong baseline, but also indicate that the learning problem is probably better defined by MATRES and TCR. Therefore, we should move along that direction to collect more high-quality data, which can facilitate more advanced learning algorithms in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Figure 1: Overview of the neural network structures studied in this paper. Networks (a) and (b) are two ways to handle event positions in LSTMs (Sec. 3.1). (c) The Siamese network used to fit TemProb (Sec. 3.2). Once trained on TemProb, the Siamese network is fixed when training other parts of the system. (d) The FFNN that generates confidence scores for each label. Sizes of hidden layers are already noted. Embeddings of the same color share the same matrix.</figDesc><table><row><cell cols="4">(a)LSTM w/ position indicators (or, xml markups)</cell><cell></cell></row><row><cell cols="2">(previously used for this task)</cell><cell></cell><cell></cell><cell></cell><cell>(c)Siamese network</cell></row><row><cell></cell><cell></cell><cell>h out</cell><cell>(omitted)</cell><cell>200</cell><cell>trained on TemProb v 1 v 2</cell><cell>200</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>60</cell><cell>dropout 0.3</cell></row><row><cell>word</cell><cell></cell><cell cols="2">128 or 256</cell><cell></cell></row><row><cell>embeddings</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">t 0 &lt;e1&gt; t 1 &lt;/e1&gt;</cell><cell>t n</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>h e1</cell></row><row><cell>h e1</cell><cell>LSTM h e2</cell><cell></cell><cell></cell><cell></cell><cell>128</cell><cell>output</cell></row><row><cell>word embeddings</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>128 h e2</cell><cell>64</cell><cell>before after equal vague</cell></row><row><cell cols="2">t 0 t 1 t 2</cell><cell>t n</cell><cell></cell><cell></cell></row><row><cell cols="4">(b)LSTM w/ concatenations of two hidden states</cell><cell cols="2">(d) Confidence from FFNN</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 )</head><label>2</label><figDesc>, the Concat system saw consistent gains under various embeddings and metrics. In addition, contextualized embeddings (ELMo and BERT) expectedly improved over the conventional ones significantly, although no statistical significance were observed between using ELMo or BERT (more significance tests in Appendix).</figDesc><table><row><cell>System</cell><cell>Emb.</cell><cell>Acc.</cell><cell>F1</cell><cell cols="2">Faware Avg.</cell></row><row><cell></cell><cell cols="3">word2vec 63.2 67.6</cell><cell>60.5</cell><cell>63.8</cell></row><row><cell></cell><cell>GloVe</cell><cell cols="2">64.5 69.0</cell><cell>61.1</cell><cell>64.9</cell></row><row><cell>P.I.</cell><cell>FastText</cell><cell cols="2">60.5 64.7</cell><cell>59.5</cell><cell>61.6</cell></row><row><cell></cell><cell>ELMo</cell><cell cols="2">67.5 73.9</cell><cell>63.0</cell><cell>68.1</cell></row><row><cell></cell><cell>BERT</cell><cell cols="2">68.8 73.6</cell><cell>61.7</cell><cell>68.0</cell></row><row><cell></cell><cell cols="3">word2vec 65.0 69.5</cell><cell>59.4</cell><cell>64.6</cell></row><row><cell></cell><cell>GloVe</cell><cell cols="2">64.9 69.5</cell><cell>60.9</cell><cell>65.1</cell></row><row><cell>Concat</cell><cell>FastText</cell><cell cols="2">64.0 68.6</cell><cell>60.1</cell><cell>64.2</cell></row><row><cell></cell><cell>ELMo</cell><cell cols="2">67.7 74.0</cell><cell>63.3</cell><cell>68.3</cell></row><row><cell></cell><cell>BERT</cell><cell cols="2">69.1 74.4</cell><cell>63.7</cell><cell>69.1</cell></row><row><cell>Concat+CSE</cell><cell>ELMo BERT</cell><cell cols="2">71.7 76.7 71.3 76.3</cell><cell>66.0 66.5</cell><cell>71.5 71.4</cell></row><row><cell>CogCompTime</cell><cell>-</cell><cell cols="2">61.6 66.6</cell><cell>60.8</cell><cell>63.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Performances on the MATRES test set (i.e., the PT section). CogCompTime<ref type="bibr" target="#b32">(Ning et al., 2018d)</ref> is the previous state-of-the-art feature-based system.</figDesc><table /><note>Position indicator (P.I.) and concatenation (Concat) are two ways to handle event positions in LSTMs (Sec. 3.1). Concat+CSE achieves significant improvement over CogCompTime on MATRES.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">For example, "explode" typically happens before "die".</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">https://cogcomp.org/page/publication_ view/879</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">Neural TempRel ExtractionOne major disadvantage of feature-based systems is that errors occurred in feature extraction prop-3 Between experts: Kohen's ï£¿ â¡ 0.84. Among crowdsourcers: accuracy 88%. More details in<ref type="bibr" target="#b31">Ning et al. (2018c)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">We also tried convolutional neural networks but did not observe that CNNs improved performance significantly compared to the LSTMs. Comparison between LSTM and CNN is also not the focus of this paper.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4">http://cogcomp.org/page/publication_ view/834</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5">http://cogcomp.org/page/publication_ view/835</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6">http://cogcomp.org/page/publication_ view/844</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research is supported by a grant from the Allen Institute for Artificial Intelligence (allenai.org), the IBM-ILLINOIS Center for Cognitive Computing Systems Research (C3SR) -a research collaboration as part of the IBM AI Horizons Network, and contract HR0011-18-2-0052 with the US Defense Advanced Research Projects Agency (DARPA). Approved for Public Release, Distribution Unlimited. The views expressed are those of the authors and do not reflect the official policy or position of the Department of Defense or the U.S. Government.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guergana</forename><surname>Savova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation</title>
				<meeting>the 9th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2015">2015. SemEval 2015</date>
			<biblScope unit="page" from="806" to="814" />
		</imprint>
	</monogr>
	<note>SemEval-2015 Task 6: Clinical TempEval</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Timelines from text: Identification of syntactic temporal relations</title>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">H</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Klingenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Semantic Computing, 2007. ICSC 2007. International Conference on</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">SemEval-2016 Task 12: Clinical TempEval</title>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guergana</forename><surname>Savova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Te</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1052" to="1062" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semeval-2017 task 12: Clinical tempeval</title>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guergana</forename><surname>Savova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</title>
				<meeting>the 11th International Workshop on Semantic Evaluation (SemEval-2017)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="565" to="572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.04606</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Signature verification using a &quot;siamese&quot; time delay neural network</title>
		<author>
			<persName><forename type="first">Jane</forename><surname>Bromley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabelle</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>SÃ¤ckinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roopak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Conference on Advances in Neural Information Processing Systems (NIPS)</title>
				<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="737" to="744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An annotation framework for dense event ordering</title>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Cassidy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Mcdowell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathanel</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL)</title>
				<meeting>of the Annual Meeting of the Association of Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="501" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dense event ordering with a multi-pass architecture</title>
		<author>
			<persName><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Cassidy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Mcdowell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="273" to="284" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Jointly combining implicit constraints improves temporal ordering</title>
		<author>
			<persName><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Empirical Methods for Natural Language Processing (EMNLP)</title>
				<meeting>of the Conference on Empirical Methods for Natural Language essing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2008">2008a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unsupervised Learning of Narrative Event Chains</title>
		<author>
			<persName><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics, ACL 2008</title>
				<meeting>the 46th Annual Meeting of the Association for Computational Linguistics, ACL 2008</meeting>
		<imprint>
			<date type="published" when="2008">2008b</date>
			<biblScope unit="page" from="789" to="797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Classifying temporal relations between events</title>
		<author>
			<persName><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions</title>
				<meeting>the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="173" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Classifying temporal relations by bidirectional LSTM over dependency paths</title>
		<author>
			<persName><forename type="first">Fei</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL)</title>
				<meeting>of the Annual Meeting of the Association of Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Approximate statistical tests for comparing supervised classification learning algorithms</title>
		<author>
			<persName><forename type="first">G</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Neural temporal relation extraction</title>
		<author>
			<persName><forename type="first">Dmitriy</forename><surname>Dligach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guergana</forename><surname>Savova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Joint inference for event timeline construction</title>
		<author>
			<persName><forename type="first">Quang</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Brian</forename><forename type="middle">S</forename><surname>Everitt</surname></persName>
		</author>
		<title level="m">The analysis of contingency tables</title>
				<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">JÃ¼rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Structured learning for temporal relation extraction from clinical records</title>
		<author>
			<persName><forename type="first">Artuur</forename><surname>Leeuwenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter</title>
		<title level="s">the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Temporal information extraction by predicting relative time-lines</title>
		<author>
			<persName><forename type="first">Artuur</forename><surname>Leeuwenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Empirical Methods for Natural Language Processing (EMNLP)</title>
				<meeting>of the Conference on Empirical Methods for Natural Language essing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Representations of time expressions for temporal relation extraction with convolutional neural networks</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitriy</forename><surname>Dligach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guergana</forename><surname>Savova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioNLP</title>
		<imprint>
			<biblScope unit="page" from="322" to="327" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">SemEval-2015 Task 5: QA TEMPEVAL -evaluating temporal information understanding with question answering</title>
		<author>
			<persName><forename type="first">Hector</forename><surname>Llorens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naushad</forename><surname>Uzzaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation</title>
				<meeting>the 9th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2015">2015. SemEval 2015</date>
			<biblScope unit="page" from="792" to="800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Machine learning of temporal relations</title>
		<author>
			<persName><forename type="first">Inderjeet</forename><surname>Mani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Wellner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</title>
				<meeting>the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="753" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Contextaware neural model for temporal information extraction</title>
		<author>
			<persName><forename type="first">Yuanliang</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Rumshisky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL)</title>
				<meeting>of the Annual Meeting of the Association of Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="527" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Distributed Representations of Words and Phrases and their Compositionality</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS 2013</title>
				<meeting>NIPS 2013</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">TimeLine: Cross-document event ordering</title>
		<author>
			<persName><forename type="first">Anne-Lyse</forename><surname>Minard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuela</forename><surname>Speranza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Itziar</forename><surname>Aldabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><surname>Marieke Van Erp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">German</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruben</forename><surname>Rigau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fondazione</forename><forename type="middle">Bruno</forename><surname>Urizar</surname></persName>
		</author>
		<author>
			<persName><surname>Kessler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation</title>
				<meeting>the 9th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2015">2015. SemEval 2015</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="778" to="786" />
		</imprint>
	</monogr>
	<note>SemEval-2015 Task</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">CaTeRS: Causal and temporal relation scheme for semantic annotation of event structures</title>
		<author>
			<persName><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alyson</forename><surname>Grealish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Events: Definition, Detection, Coreference, and Representation</title>
				<meeting>the 4th Workshop on Events: Definition, Detection, Coreference, and Representation</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="51" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A structured learning approach to temporal relation extraction</title>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhili</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods for Natural Language Processing (EMNLP)</title>
				<meeting>the Conference on Empirical Methods for Natural Language Processing (EMNLP)<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1038" to="1048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Joint reasoning for temporal and causal relations</title>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhili</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association of Computational Linguistics (ACL)</title>
				<meeting>the Annual Meeting of the Association of Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2018">2018a</date>
			<biblScope unit="page" from="2278" to="2288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Improving temporal relation extraction with a globally acquired statistical resource</title>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoruo</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the North American Association of Computational Linguistics (NAACL)</title>
				<meeting>the Annual Meeting of the North American Association of Computational Linguistics (NAACL)</meeting>
		<imprint>
			<date type="published" when="2018">2018b</date>
			<biblScope unit="page" from="841" to="851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A multiaxis annotation scheme for event temporal relations</title>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association of Computational Linguistics (ACL)</title>
				<meeting>the Annual Meeting of the Association of Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2018">2018c</date>
			<biblScope unit="page" from="1318" to="1328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Cogcomptime: A tool for understanding time in natural language</title>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhili</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoruo</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods for Natural Language Processing (EMNLP)</title>
				<meeting>the Conference on Empirical Methods for Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2018">2018d</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Richer event description: Integrating event coreference with temporal, causal and bridging annotation</title>
		<author>
			<persName><forename type="first">Kristin</forename><surname>Tim O'gorman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>Wright-Bettner</surname></persName>
		</author>
		<author>
			<persName><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Computing News Storylines (CNS 2016)</title>
				<meeting>the 2nd Workshop on Computing News Storylines (CNS 2016)<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="47" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Magnitude: A fast, efficient universal vector embedding utility package</title>
		<author>
			<persName><forename type="first">Ajay</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Sands</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marianna</forename><surname>Apidianaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Empirical Methods for Natural Language Processing</title>
				<meeting>of the Conference on Empirical Methods for Natural Language essing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the North American Association of Computational Linguistics (NAACL)</title>
				<meeting>of the Annual Meeting of the North American Association of Computational Linguistics (NAACL)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Temporal annotation in the clinical domain</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename><surname>William F Styler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Finan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piet</forename><forename type="middle">C</forename><surname>De Groen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brad</forename><surname>Erickson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guergana</forename><surname>Savova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Transactions of the Association for Computational Linguistics</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">143</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Neural architecture for temporal relation extraction: A bi-lstm approach for detecting narrative containers</title>
		<author>
			<persName><forename type="first">Julien</forename><surname>Tourille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Ferret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelie</forename><surname>Neveol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Tannier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL)</title>
				<meeting>of the Annual Meeting of the Association of Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="224" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">Naushad</forename><surname>Uzzaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hector</forename><surname>Llorens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
		<title level="m">SemEval-2013 Task 1: TEMPEVAL-3: Evaluating time expressions, events, and temporal relations. *SEM</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">SemEval-2007 Task 15: TempEval temporal relation identification</title>
		<author>
			<persName><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Schilder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Hepple</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Workshop on Semantic Evaluations</title>
				<meeting>the 4th International Workshop on Semantic Evaluations</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="75" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Temporal processing with the TARSQI toolkit</title>
		<author>
			<persName><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">22nd International Conference on on Computational Linguistics: Demonstration Papers</title>
				<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="189" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">SemEval-2010 Task 13: TempEval-2</title>
		<author>
			<persName><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roser</forename><surname>Sauri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tommaso</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th international workshop on semantic evaluation</title>
				<meeting>the 5th international workshop on semantic evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="57" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Recurrent convolutional neural network for video classification</title>
		<author>
			<persName><forename type="first">Zhenqi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiani</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihong</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">Ieee</forename><surname>Yoshikawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masayuki</forename><surname>Asahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
				<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009">2016. 2016. 2009</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="405" to="413" />
		</imprint>
	</monogr>
	<note>IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Relation classification via convolutional deep neural network</title>
		<author>
			<persName><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siwei</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the International Conference on Computational Linguistics (COLING)</title>
				<meeting>the International Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2335" to="2344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">Dongxu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.01006</idno>
		<title level="m">Relation classification via recurrent neural network</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Bidirectional long short-term memory networks for relation classification</title>
		<author>
			<persName><forename type="first">Shu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dequan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinchen</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Pacific Asia Conference on Language, Information and Computation</title>
				<meeting>the 29th Pacific Asia Conference on Language, Information and Computation</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="73" to="78" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
