<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Foofah: Transforming Data By Example</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhongjun</forename><surname>Jin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<settlement>Ann Arbor</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><forename type="middle">R</forename><surname>Anderson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<settlement>Ann Arbor</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Cafarella</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<settlement>Ann Arbor</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<settlement>Ann Arbor</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Foofah: Transforming Data By Example</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">73050C685AF4644E7946BA063D126B2C</idno>
					<idno type="DOI">10.1145/3035918.3064034</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Data Transformation</term>
					<term>Program Synthesis</term>
					<term>Programming By Example</term>
					<term>A* algorithm</term>
					<term>Heuristic</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Data transformation is a critical first step in modern data analysis: before any analysis can be done, data from a variety of sources must be wrangled into a uniform format that is amenable to the intended analysis and analytical software package. This data transformation task is tedious, time-consuming, and often requires programming skills beyond the expertise of data analysts. In this paper, we develop a technique to synthesize data transformation programs by example, reducing this burden by allowing the analyst to describe the transformation with a small input-output example pair, without being concerned with the transformation steps required to get there. We implemented our technique in a system, Foofah, that efficiently searches the space of possible data transformation operations to generate a program that will perform the desired transformation. We experimentally show that data transformation programs can be created quickly with Foofah for a wide variety of cases, with 60% less user effort than the well-known Wrangler system.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The many fields that depend on data for decision making have at least one thing in common: raw data is often in a nonrelational or poorly structured form, possibly with extraneous information, and cannot be directly used by a downstream information system, like a database or visualization system. Figure <ref type="figure" target="#fig_0">1</ref> from <ref type="bibr" target="#b16">[16]</ref> is a good example of such raw data. In modern data analytics, data transformation (or data wrangling) is usually a crucial first step that reorganizes raw data into a more desirable format that can be easily consumed by other systems. Figure <ref type="figure" target="#fig_1">2</ref> showcases a relational form obtained by transforming Figure <ref type="figure" target="#fig_0">1</ref>.</p><p>Traditionally, domain experts handwrite task specific scripts to transform unstructured data-a task that is often labor-  intensive and tedious. The requirement for programming hamstrings data users that are capable analysts but have limited coding skills. Even worse, these scripts are tailored to particular data sources and cannot adapt when new sources are acquired. People normally spend more time preparing data than analyzing it; up to 80% of a data scientist's time can be spent on transforming data into a usable state <ref type="bibr" target="#b28">[28]</ref>.</p><p>Recent research into automated and assisted data transformation systems have tried to reduce the need of a programming background for users, with some success <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b22">22,</ref><ref type="bibr" target="#b41">41]</ref>. These tools help users generate reusable data transformation programs, but they still require users to know which data transformation operations are needed and in what order they should be applied. Current tools still require some level of imperative programming, placing a significant burden on data users. Take Wrangler <ref type="bibr" target="#b22">[22]</ref>, for example, where a user must select the correct operators and parameters to complete a data transformation task. This is often challenging if the user has no experience in data transformation or programming.</p><p>In general, existing data transformation tools are difficult to use due to two usability issues:</p><p>• High Skill : Users must be familiar with the often complicated transformation operations and then decide which operations to use and in what order.</p><p>• High Effort: The amount of user effort increases as the data transformation program gets lengthy.</p><p>To resolve the above usability issues, we envision a data transformation program synthesizer that can be successfully used by people without a programming background and that requires minimal user effort. Unlike Wrangler, which asks the user for procedural hints, this system should allow the user to specify a desired transformation simply by providing an input-output example: the user only needs to know how to describe the transformed data, as opposed to knowing any particular transformation operation that must be performed.</p><p>Our Approach -In this paper, we solve the data transformation program synthesis problem using a Programming By Example (PBE) approach. Our proposed technique aims to help an unsophisticated user easily generate a quality data transformation program using purely input-output examples. The synthesized program is designed to be easy-tounderstand (it is a straight-line program comprised of simple primitives), so an unsophisticated user can understand the semantics of the program and validate it. Because it is often infeasible to examine and approve a very large transformed dataset synthesizing a readable transformation program is preferred over performing an opaque transformation.</p><p>We model program synthesis as a search problem in a state space graph and use a heuristic search approach based on the classic A* algorithm to synthesize the program. A major challenge in applying A* to program synthesis is to create a heuristic function estimating the cost of any proposed partial solution. Unlike robotic path planning, where a metric like Euclidean distance naturally serves as a good heuristic function, there is no straightforward heuristic for data transformation. In this work, we define an effective A* heuristic for data transformation, as well as lossless pruning rules that significantly reduce the size of the search space. We have implemented our methods in a prototype data transformation program synthesizer called Foofah.</p><p>Organization -After motivating our problem with an example in Section 2 and formally defining the problem in Section 3, we discuss the following contributions:</p><p>• We present a PBE data transformation program synthesis technique backed by an efficient heuristic-searchbased algorithm inspired by the A* algorithm. It has a novel, operator-independent heuristic, Table <ref type="table">Edit</ref> Distance Batch, along with pruning rules designed specifically for data transformation (Section 4).</p><p>• We prototype our method in a system, Foofah, and evaluate it with a comprehensive set of benchmark test scenarios that show it is both effective and efficient in synthesizing data transformation programs. We also present a user study that shows Foofah requires about 60% less user effort than Wrangler(Section 5).</p><p>We explore Related Work in Section 6 and finish with a discussion of future work in Section 7</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">MOTIVATING EXAMPLE</head><p>Data transformation can be a tedious task involving the application of complex operations that may be difficult for a naïve user to understand, as illustrated by the following simple but realistic scenario:</p><p>Example 1. Bob wants to load a spreadsheet of business contact information (Figure <ref type="figure" target="#fig_0">1</ref>) into a database system. Unfortunately, the raw data cannot be loaded in its original format, so Bob hopes to transform it into a relational format (Figure <ref type="figure" target="#fig_1">2</ref>). Manually transforming the data record-by-record would be tedious and error-prone, so he uses the interactive data cleaning tool Wrangler <ref type="bibr" target="#b22">[22]</ref>.   Bob first removes the rows of irrelevant data (rows 1 and 2) and empty rows (rows 5, 8, and more). He then splits the cells containing phone numbers on ":", extracting the phone numbers into a new column. Now that almost all the cells from the desired table exist in the intermediate table (Figure <ref type="figure" target="#fig_2">3</ref>), Bob intends to perform a cross-tabulation operation that tabulates phone numbers of each category against the human names. He looks through Wrangler's provided operations and finally decides that Unfold should be used. But Unfold does not transform the intermediate table correctly, since there are missing values in the column of names, resulting in "null" being the unique identifier for all rows without a human name (Figure <ref type="figure" target="#fig_3">4</ref>). Bob backtracks and performs a Fill operation to fill in the empty cells with the appropriate names before finally performing the Unfold operation. The final data transformation program is shown in Figure <ref type="figure">5</ref>.</p><p>The usability issues described in Section 1 have occurred in this example. Lines 1-3 in Figure <ref type="figure">5</ref> are lengthy and repetitive (High Effort). Lines 5-6 require a good understanding of the Unfold operation, causing difficulty for the naïve user (High Skill ). Note that Deletes in Lines 1-2 are different from the Delete in Line 3 in that the latter could apply to the entire file. Non-savvy users may find such conditional usage of Delete difficult to discover, further illustrating the High Skill issue.</p><p>Consider another scenario where the same task becomes much easier for Bob, our data analyst:</p><p>Example 2. Bob decides to use an alternative data transformation system, Foofah. To use Foofah, Bob simply needs to choose a small sample of the raw data (Figure <ref type="figure" target="#fig_0">1</ref>) and describe what this sample should be after being transformed (Figure <ref type="figure" target="#fig_1">2</ref>). Foofah automatically infers the data transformation program in Figure <ref type="figure" target="#fig_4">6</ref> (which is semantically the same as Figure <ref type="figure">5</ref>, and even more succinct). Bob takes this inferred program and executes it on the entire raw dataset and finds that raw data are transformed exactly as desired.</p><p>The motivating example above gives an idea of the realworld data transformation tasks our proposed technique is designed to address. In general, we aim to transform a poorly-structured grid of values (e.g., a spreadsheet table) to a relational table with coherent rows and columns. Such a transformation can be a combination of the following chores:  We assume that the input data should be transformed without any extra semantic information, so, for example, transforming "NY" to "New York" is not possible (previous projects <ref type="bibr" target="#b1">[1,</ref><ref type="bibr">9,</ref><ref type="bibr" target="#b37">37]</ref> have addressed such semantic transformations). Transformations should not add new information that is not in the input table, such as adding a column header. We provide another example use case in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">PROBLEM DEFINITION</head><p>To help the user synthesize a correct data transformation program, we take a Programming By Example (PBE) approach: the user provides an input-output example pair, and the system generates a program satisfying the example pair and hopefully can correctly transform the full dataset R.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Definition</head><p>With all notations summarized in Table <ref type="table" target="#tab_3">1</ref>, we define this problem formally:</p><p>Problem Given a user's set of input-output examples E = (ei, eo), where ei is drawn from raw dataset R and eo is the desired transformed form of ei, synthesize a data transformation program P, parameterized with a library of data transformation operators, that will transform ei to eo.</p><p>Like previous work in data transformation <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b22">22]</ref>, we assume the raw data R is a grid of values. R might not be relational but must have some regular structure (and thus may have been programmatically generated). Further, R may contain schematic information (e.g., column or row headers) as table values, and even some extraneous information (e.g., "Bureau of I.A." in Figure <ref type="figure" target="#fig_0">1</ref>).</p><p>Once the raw data and the desired transformation meet the above criteria, the user must choose the input sample and specify the corresponding output example. More issues with creating quality input-output examples will be discussed in detail in Section 4.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data Transformation Programs</head><p>Transforming tabular data into a relational table usually require two types of transformations: syntactic transformations and layout transformations <ref type="bibr" target="#b13">[13]</ref>. Syntactic transformations reformat cell contents (e.g., split a cell of "mm/dd/yyyy" into three cells containing month, day, year). Layout transformations do not modify cell contents, but instead change how the cells are arranged in the table (e.g., relocating cells containing month information to be column headers).</p><p>We find that the data transformation operators shown in Table <ref type="table" target="#tab_4">2</ref> (defined in Potter's Wheel project <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b34">34]</ref> and used by state-of-art data transformation tool Wrangler <ref type="bibr" target="#b22">[22]</ref>) are   expressive enough to describe these two types of transformations. We use these operations in Foofah: operators like Split and Merge are syntactic transformations and operators like Fold, and Unfold are layout transformations. To illustrate the type of operations in our library, consider Split. When applying Split parameterized by ':' to the data in Figure <ref type="figure">7</ref>, we get Figure <ref type="figure">8</ref> as the output. Detailed definitions for each operator are shown in Appendix A.</p><p>Our proposed technique is not limited to supporting Potter's Wheel operations; users are able to add new operators as needed to improve the expressiveness of the program synthesis system. We assume that new operators will match our system's focus on syntactic and layout transformations (as described in Section 2); if an operator attempts a semantic transformation, our system may not correctly synthesize programs that use it. As we describe below, the synthesized programs do not contain loops, so novel operators must be useful outside a loop's body.</p><p>We have tuned the system to work especially effectively when operators make "conventional" transformations that apply to an entire row or column at a time. If operators were to do otherwise -such as an operator for "Removing the cell values at odd numbered rows in a certain column", or for "Splitting the cell values on Space in cells whose values start with 'Math"' -the system will run more slowly. Experimental results in Section 5.5 show evidence that adding operators can enhance the expressiveness of our synthesis technique without hurting efficiency.  <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b22">22,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b42">42]</ref>. We use the operators mentioned above as base components. Synthesizing loops is usually unnecessary in our case because the operators in our operator library are defined to potentially apply to multiple values. Nevertheless, the loopfree program structure could restrict us from synthesizing programs that require an undetermined number of iterations of a data transformation operation, or could lead to verbose programs with "unrolled loops." For example, if the user wants to "Drop column 1 to column k/2 where k is the number of columns in the table" our system will be unable to synthesize a loop-based implementation and instead will simply repeat Drop many times. Motivated by the above considerations, we formally define the data transformation to be synthesized as follows: Definition 3.1 (Data transformation program P). P is a loop-free series of operations (p1, p2, ..., p k ) such that: 1. Each operation pi = (opi, par1, . . . ) : tin → tout. pi includes operator opi with corresponding parameter(s) and transforms an input data table tin to an output data table tout. 2. The output of operation pi is the input of pi+1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">PROGRAM SYNTHESIS</head><p>We formulate data transformation program synthesis as a search problem. Other program synthesis approaches are not efficient enough given the huge search space in our problem setting (Section 4.1). We thus propose an efficient heuristic search method, inspired by the classic A* algorithm. In Section 4.2, we introduce a straw man heuristic and then present our novel operator-independent heuristic, Table <ref type="table">Edit</ref> Distance Batch (TED Batch), based on a a novel metric, Table Edit Distance (TED), which measures the dissimilarity between tables. In addition, we propose a set of pruning rules for data transformation problems to boost search speed (Section 4.3). We compare the time complexity of our technique with other previous projects (Section 4.4). Finally, we discuss issues about creating examples and validation (Section 4.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Program Synthesis Techniques</head><p>In Section 3.2, we described the structure of our desired data transformation program to be component-based and loop-free. Gulwani et al. proposed a constraint-based program synthesis technique to synthesize loop-free bit-manipulation programs <ref type="bibr" target="#b15">[15,</ref><ref type="bibr" target="#b21">21]</ref> using logic solvers, like the SMT solver. However, the constraint-based technique is impractical for our interactive PBE system because the number of constraints dramatically increases as the size of data increases, scaling the problem beyond the capabilities of modern logic solvers.</p><p>Other methods for synthesizing component programs include sketching and version space algebra. Solar-Lezama's work with sketching <ref type="bibr" target="#b40">[40]</ref> attempts to formulate certain types of program automatically through clever formulation of SAT solving methods. This approach focuses on programs that are "difficult and important" for humans to write by hand, such for thread locking or decoding compressed data streams, so it is acceptable for the solver to run for long periods. In contrast, our aims to improve productivity on tasks that are "easy but boring" for humans. To preserve interactivity for the user, our system must find a solution quickly.</p><p>Version space algebra requires a complete search space of programs between two states, which make it more suitable for a Programming By Demonstration problem where the user explicitly provides intermediate states and the search space between these states is small <ref type="bibr" target="#b27">[27]</ref> or for PBE problems that can be easily divided into independent sub-problems <ref type="bibr" target="#b12">[12]</ref>. In our problem, the search space of the synthesized programs is exponential, and thus version space algebra is not practical.</p><p>Search-based techniques are another common approach used by previous program synthesis projects <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b35">35]</ref>. For our problem, we formulate program synthesis as a search problem in a state space graph defined as follows: Given input-output examples E = (ei, eo), we construct a state space graph G(V, A) where arcs A represent candidate data transformation operations, vertices V represent intermediate states of the data as transformed by the operation on previously traversed arcs, ei is the initial state v0, and eo is the goal state vn. Synthesizing a data transformation program is finding a path that is a sequence of operations leading from v0 to vn in G.</p><p>Graph Construction -To build a state space graph G, we first expand the graph from v0 by adding out-going edges corresponding to data transformation operators (e.g., Drop, Fold) with all possible parameterizations (parameters and their domains for each operator are defined both in <ref type="bibr" target="#b34">[34]</ref> and Appendix A). The resulting intermediate tables become the vertices in G. Since the domain for all parameters of our operator set is restricted, the number of arcs is still tractable. More importantly, in practice, the pruning rules introduced in Section 4.3 trim away many obviously incorrect operations and states, making the actual number of arcs added for each state reasonably small (e.g., the initial state ei in Figure <ref type="figure" target="#fig_0">10</ref> has 15 child states, after 161 are pruned).</p><p>If no child of v0 happens to be the goal state vn, we recursively expand the most promising child state (evaluated using the method introduced in Section 4.2) until we finally reach vn. When the search terminates, the path from v0 to vn is the sequence of operations that comprise the synthesized data transformation program.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Search-based Program Synthesis</head><p>Due to our formulation of the synthesis problem, the search space is exponential in the number of the operations in the program. Searching for a program in a space of this size can be difficult. Brute-force search quickly becomes intractable. As a PBE solution needs to be responsive to preserve interactivity, we are exposed to a challenging search problem with a tight time constraint. To solve the problem, we develop a heuristic search algorithm for synthesizing data transformation programs inspired by the classic A* algorithm <ref type="bibr" target="#b18">[18]</ref>. With appropriate pruning rules and careful choice of exploration order, we are able to achieve good performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Operator Description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Add</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Add a cell to table Delete</head><p>Remove a cell from table</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Move</head><p>Move a cell from location (x 1 , y 1 ) to (x 2 , y 2 ) Transform Syntactically transform a cell into a new cell</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 3: Table Edit Operators</head><p>A* is a common approach to address search problems and has been successfully applied in previous work on program synthesis <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b35">35]</ref>. To find a path in the graph from the initial state to the goal state, the A* algorithm continually expands the state with the minimum cost f (n) = g(n) + h(n), where g(n) is the cost to reach state n from the initial state and heuristic function h(n) is the approximate cost of the cheapest path from state n to the goal state. The definition of cost depends on the performance measure of the search task. In robotic pathfinding, the cost is typically distance traveled. In our problem, we prefer shorter programs over longer ones, because we believe shorter programs will be easier to understand. For these programs, correctness and readability are far more important than the program's computational efficiency (our operators all have complexity linear in the size of the input file), so we do not search for computationally "cheap" programs. We define cost as follows: Definition 4.2 (Data transformation cost). Given any two states (vi, vj) in graph G, cost is the minimum number of data transformation operations needed to transform vi to vj.</p><p>Note that we treat all operators equally. Although, some operators like Fold might be conceptually more complex for users to understand, we observe that such operators rarely occur more than once in our benchmarks.</p><p>Additionally, an admissible heuristic helps synthesize a program with the minimum number of data transformation operations. This is ideal but not necessary. By relaxing the need for admissibility, we may accept a program that is slightly longer than the program with the minimal length.</p><p>Naïve Heuristic -Possibly the most straightforward heuristic is a rule-based one. The intuition is that we create some rules, based on our domain knowledge, to estimate whether a certain Potter's Wheel operator is needed given E, and use the total count as the final heuristic score in the end. An example heuristic rule for the Split operator is "number of cells from Ti[k] (i.e., the row k in Ti) with strings that do not appear fully in To[k], but do have substrings that appear in To <ref type="bibr">[k]</ref>." (This is a reasonable rule because the Split operator splits a cell value in the input table into two or more pieces in the output table, as in Figures <ref type="figure">7</ref> and<ref type="figure">8</ref>.) The details about this naïve heuristic are presented in Appendix C.</p><p>Although this naïve heuristic might appear to be effective for our problem, it is weak for two reasons. First, the estimation is likely to be inaccurate when the best program entails layout transformations. Second, the heuristic is defined in terms of the existing operators and will not easily adapt to new operators in the future. We expect different operators to be helpful in different application scenarios and our framework is designed to be operator independent.</p><p>To overcome these shortcomings, we have designd a novel heuristic function explicitly for tabular data transformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Table Edit Distance</head><p>The purpose of the heuristic function in A* is guiding the search process towards a more promising direction. Inspired  </p><formula xml:id="formula_0">TED(T1, T2) = min (p 1 ,...,p k )∈P (T 1 ,T 2 ) k i=i cost(pi)<label>(1)</label></formula><p>TED is the minimum total cost of table edit operations needed to transform T1 to T2, where P (T1, T2) denotes the set of edit paths transforming T1 to T2 and cost(pi) is the cost of each table edit operation pi. The table edit operations include Add, Delete, Move, Transform (see Table <ref type="table">3</ref> for definition).</p><p>Inspired by the graph edit distance algorithm <ref type="bibr" target="#b31">[31]</ref>, we designed an algorithm to calculate the exact TED. Unfortunately, computing TED in real time is not practical: it is equivalent to computing graph edit distance, which is NP-complete <ref type="bibr" target="#b11">[11]</ref>. (See Appendix D for this algorithm.)</p><p>We therefore designed an efficient greedy algorithm to approximate TED, shown in Algorithm 1. The idea behind Algorithm 1 is to greedily add the cheapest operations among the candidate operations to formulate each cell in the output table eo, building up a sequence of edits until we obtain a complete edit path. The edit path formulates the entire output table . The final heuristic score is the total cost of this path.</p><p>Algorithm 1 consists of three core steps. We use Figure <ref type="figure" target="#fig_0">10</ref>, which describes the edit path found to transform input table ei to eo in Figure <ref type="figure">9</ref>, as an example to explain each step.</p><p>Step 1. (lines 3-19) For each unprocessed cell in the output table (picked in row-major order), we choose the cheapest cell-specific operation sequence (a tie is broken by row-major order of the cell from the input table), from one of: </p><formula xml:id="formula_1">p f inal ← p f inal ∪ argmin ∀p∈p temp cost(p) ; Let {u1, . . . , uj} &amp; {v1, . . . , v k } be processed cells; if j &lt;| ex | then for w ∈ {uj+1, . . . , u |ex| } do add Delete (w) to p f inal if k &lt;| eo | then for q ∈ {v k+1 , . . . , v |eo| } do ptemp ← ∅;</formula><p>for w ∈ {u1, . . . , u |ex| } do add AddCandT ransf orm(w, q) to ptemp; add Add (q) to ptemp;</p><formula xml:id="formula_2">p f inal ← p f inal ∪ argmin ∀p∈p temp cost(p) ; Return cost(p f inal ), p f inal</formula><p>After picking an operation sequence, we hypothesize an edit path (ptemp) for each cell that consists of all edits made so far, plus the chosen operation. We measure the cost of each edit path using the cost function. By default, all table edit operations have equal cost; however, we assign a cost of infinity to: <ref type="bibr" target="#b1">(1)</ref> Transform operations between cells with no string containment relationship and (2) Add operations for non-empty cells. (These fall into the category of tasks beyond the scope of our technique described in Section 2.)</p><p>For example, for O1 in Figure <ref type="figure" target="#fig_0">10</ref> 1 , Algorithm 1 finds that transforming from I2 to O1 to is the best, because the costs of transforming from I1, I3, and I5 are all infinite (no string containment), and although transforming from I4 or I6 costs the same as transforming from I2, I2 has a higher row-major order in the input table. For O2, we find that transforming from any unprocessed cell in the input example (i.e., I1,3,4,5,6) to O2 yields an infinite cost, so using only the unprocessed cells would not result in a reasonable edit path. We fix this problem by adding transformations from the processed cells in lines <ref type="bibr">13-18;</ref> this helps find the cheapest edit operation to formulate O2: transforming from I2 to O2. 1 On means cell n from eo. Im means cell m from ei.</p><p>Step 2. (line 20-22) Delete all unprocessed cells from ex.</p><p>In our running example, after we have discovered edit operations for all cells in the output example, we find that cells 1, 3, and 5 from the input example remain unprocessed. We simply add Delete operations to remove them.</p><p>Step 3. (line 23-29) When we have unprocessed cells in eo, but no remaining unprocessed cells in ex, our only options are to: (1) Transform from a processed cell in ex, (we process every input cell at least one time before processing any cell for a second time) OR (2) Add a new cell.</p><p>The edit path discovered in Figure <ref type="figure" target="#fig_0">10</ref> is as follows: </p><formula xml:id="formula_3">2 P0 =              Transform((1,2),(1,1)), Move((1,2),(<label>1</label></formula><formula xml:id="formula_4">            </formula><p>Figure <ref type="figure">9</ref> shows a data transformation task, where ei is the input example and eo is the output example. c1 and c2 are two child states of ei representing outcomes of two possible candidate operations applied to ei. Below we define P1 and P2, the edit paths discovered by Algorithm 1 for c1 and c2: </p><formula xml:id="formula_5">P1 =          Transform((1,1),(1,1)), Transform((1,1),(1,2)) Move(<label>(1,1),(1,2)) , Transform((2,1),(2,1)</label></formula><p>) </p><formula xml:id="formula_7">         P2 =                          Transform(<label>(1,3),(1,1)), Move((1,3),(1,1)</label></formula><formula xml:id="formula_8">                        </formula><p>. The actual cost of edit paths P0, P1, and P2 are 12, 9, and 18, respectively. These costs suggest that the child state c1, as an intermediate state, is closer to the goal than both its "parent" ei and its "sibling" c2. Those costs are consistent with the fact that Drop(0) is a more promising operation than Split(0,' ') from the initial state. (Only one operation-Split(1,':')-is needed to get from c1 to eo, whereas three operations are needed to transform c2 to eo). This example shows that our proposed heuristic is effective in prioritizing the good operations over the bad ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Table Edit Distance Batch</head><p>Although TED seems to be a good metric for Return cost;</p><p>(2) the TED score depends on the number of cells in the example tables The scaling problem in our setting cannot be fixed by simply multiplying the cost by a constant like has been done in other domains <ref type="bibr" target="#b20">[20]</ref>, because different Potter's Wheel operators affect different number of cells.</p><p>We have developed a novel method called Table Edit Distance Batch (TED Batch) (Algorithm 2) that approximates the number of Potter's Wheel operators by grouping table edit operations belonging to certain geometric patterns into batches and compacting the cost of each batch. The intuition behind this methodology is based on the observation that data transformation operators usually transform, remove or add cells within the same column or same row or that are geometrically adjacent to each other. Consider Split, for example: it transforms one column in the input table into two or more columns, so instead of counting the individual table edit operations for each affected cell, the operations are batched into groups representing the affected columns.</p><p>The definitions of the geometric patterns and related data transformation operators are presented in Table <ref type="table" target="#tab_9">4</ref>. For example, "Vertical to Vertical" captures the edit operations that are from vertically adjacent cells (in the same column) in the input table to vertically adjacent cells in the output table. In Figure <ref type="figure" target="#fig_0">10</ref>, Deletes of I1,3,5 are a batch of edit operations that follow "Vertical to Vertical" pattern.</p><p>To recalculate the heuristic score using this idea, we propose Algorithm 2, which consists of the following three steps. We use Figure <ref type="figure" target="#fig_0">10</ref> and P0 to demonstrate each step.</p><p>Step 1. (lines 3 -6) Find all sets of edit operations (from the edit path obtained by Algorithm 1) following each geometric pattern. Each set is a candidate batch. Each edit operator could only be batched with operators of same type (e.g., Move should not be in the same batch as Drop); line 3 first groups operations by types.</p><p>In P0, Transform((1,2),(1,1)) (I2 to O1 in Figure <ref type="figure" target="#fig_0">10</ref>) should be grouped by pattern "Vertical to Vertical" with Transform((2,2),(2,1)) (I4 to O3) and Transform((3,2),(3,1)) (I6 to O5). Meanwhile, it could also be grouped by pattern "One to Horizontal" with Transform((2,2),(2,2)) (I2 to O2).</p><p>Step 2. (lines 7 -11) One edit operation might be included in multiple batches in Step 1. To finalize the grouping, Algorithm 2 repeatedly chooses the batch with the maximum number of edit operations, and none of the operations in this batch should be already included batch final . The finalization terminates when batch final covers a complete edit path.</p><p>In the example in Step 1, Transform((1,2),(1,1)) will be assigned to the "Vertical to Vertical" group because it has more members than the "One to Horizontal" group.</p><p>Step 3. (lines <ref type="bibr">13 -17)</ref> The final heuristic score is the sum of the mean cost of edit operations within each chosen batch.</p><p>In this case, the cost of the batch with Transform((1,2),(1,1)), Transform((2,2),(2,1)) and Transform((3,2),(3,1)) will be 1, not 3. Finally, the batched form of P0 is {p1, p2, p3, p4}, where The estimated cost of P0 is reduced to 4 which is closer to the actual Potter's Wheel cost and less related to the number of cells than using TED alone. Likewise, cost of P1 is now 3 and cost of P2 is now 6. In general, this shows that the TED Batch algorithm effectively "scales down" the TED heuristic and reduces the heuristic's correlation to the table size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Pruning Techniques for Better Efficiency</head><p>If we indiscriminately tried all possible operations during graph expansion, the search would quickly become intractable. However, not all the potential operations are valid or reasonable. To reduce the size of the graph and improve the runtime of the search, we created three global pruning rules (which apply to all operators) and two property-specific pruning rules (which apply to any operators with certain specified properties). The following pruning rules are designed to boost efficiency; our proposed data transformation program synthesis technique is still complete without them.</p><p>Global Pruning Rules -These pruning rules apply to all operations in the library.</p><p>• Missing Alphanumerics -Prune the operation if any letter (a-z, A-Z) or digit (0-9) in eo does not appear in the resulting child state. We assume transformations will not introduce new information, thus if an operation completely eliminates a character present in eo from current state, no valid path to the goal state exists.</p><p>• No Effect -Prune the operation that generates a child state identical to the parent state. In this case, this operation is meaningless and should be removed.</p><p>• Introducing Novel Symbols -Prune the operation if it introduces a printable non-alphanumeric symbol that is not present in eo. If an operator were to add such a symbol, it would inevitably require an additional operation later to remove the unneeded symbol.</p><p>Pattern Formulation (X is a table edit operator) Related Operators</p><p>Horizontal to Horizontal {X((x i , y i ), (x j , y j )), X((x i , y i + 1), (x j , y j + 1)), . . . } Delete(Possibly) Horizontal to Vertical {X((x i , y i ), (x j , y j )), X((x i , y i + 1), (x j + 1, y j )), . . . } Fold, Transpose Vertical to Horizontal {X((x i , y i ), (x j , y j )), X((x i + 1, y i ), (x j , y j + 1)), . . . } Unfold,Transpose Vertical to Vertical {X((x i , y i ), (x j , y j )), X((x i + 1, y i ), (x j + 1, y j )), . . . } Move, Copy, Merge, Split, Extract, Drop One to Horizontal {X((x i , y i ), (x j , y j )), X((x i , y i ), (x j , y j + 1)), . . . } Fold(Possibly), Fill(Possibly) One to Vertical {X((x i , y i ), (x j , y j )), X((x i , y i ), (x j + 1, y j )), . . . } Fold, Fill Remove Horizontal {X((x i , y i )), X((x i , y i + 1)), . . . } Delete Remove Vertical {X((x i , y i )), X(( </p><formula xml:id="formula_9">x i + 1, y i )), . . . } Drop, Unfold</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Complexity Analysis</head><p>The worst-case time complexity for our proposed program synthesis technique is O((kmn) d ), where m is the number of cells in input example ei, n is the number of cells in the output example eo, k is the number of candidate data transformation operations for each intermediate table, and d is the number of components in the final synthesized program. In comparison, two of the previous works related to our project, ProgFromEx and FlashRelate, have worst-case time complexities that are exponential in the size of the example the user provides. ProgFromEx's worst-case time complexity is O(m n ), where m is the number of cells in the input example and n is the number of cells in the output example. FlashRelate's worst-case complexity is O(t t-2 ), where t is the number of columns in the output table.</p><p>In practice, we believe the complexity exponential in input size will not cause a severe performance issue because none of the three PBE techniques require large amount of user input. However, if a new usage model arises in the future that allows the user to provide a large example easily, ProgFromEx might become impractical.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Synthesizing Perfect Programs</head><p>Since the input-output example E is the only clue about the desired transformation provided by the user, the effectiveness of our technique could be greatly impacted by the quality of E. We can consider its fidelity and representativeness.</p><p>Fidelity of E -The success of synthesizing a program is premised on the fidelity of the user-specified example E: the end user must not make any mistake while specifying E. Some common mistakes a user might make are: typos, copypaste-mistakes, and loss of information. This last mistake occurs when the user forgets to include important information, such as column headers, when specifying E. When such mistakes occur, our proposed technique is almost certain to fail. However, the required user input is small, and, as we show in Section 5.6, our system usually fails quickly. As a result, it is easy for the user to fix any errors. In Section 7, we describe future work that allows tolerance for user error.</p><p>Representativeness of E -Once a program P is generated given the user input, the synthesized program is guaranteed to be correct: P must transform the input example ei to the output example eo. However, we do not promise that P is perfect, or guarantees to transform the entire raw data R as the user may expect. How well a synthesized program generalizes to R relies heavily on the representativeness of E, or how accurately E reflects the desired transformation. Our proposed synthesis technique requires the user to carefully choose a representative sample from R as the input example to formulate E. With a small sample from R, there is a risk of synthesizing a P that will not generalize to R (similar to overfitting when building a machine learning model with too few training examples). Experimentally, however, we see that a small number (e.g., 2 or 3) of raw data records usually suffices to formulate E (Section 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Validation -[C2]</head><p>In Section 1, we mentioned that one way the user can validate the synthesized program is by understanding the semantics of the program. Alternatively, the user could follow the sampling-based lazy approach of Gulwani et al. <ref type="bibr" target="#b17">[17]</ref> To the best of our knowledge, no existing work in the PBE area provides guarantees about the reliability of this approach or how many samples it may require. Of course, not only PBE systems, but work in machine learning and the program test literature must wrestle with the same sampling challenges. Our system neither exacerbates nor ameliorates the situation, so we do not address these issues here.</p><p>• What happens to Foofah if we add new operators to the operator library? (Section 5.5)</p><p>• How much effort does Foofah save the end users compared to the baseline system Wrangler? (Section 5.6)</p><p>• How does Foofah compare to other PBE data transformation systems? (Section 5.7)</p><p>Overall, when supplied with an input-output example comprising two records, Foofah can synthesize perfect data transformation programs for over 85% of test scenarios within five seconds. We also show Foofah requires 60% less user effort than a state-of-art data transformation tool, Wrangler.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Benchmarks</head><p>To empirically evaluate Foofah, we constructed a test set of data transformation tasks. Initially, we found 61 test scenarios used in related work including ProgFromEx <ref type="bibr" target="#b17">[17]</ref>, Wrangler <ref type="bibr" target="#b22">[22]</ref>, Potter's Wheel (PW) <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b34">34]</ref> and Proactive Wrangler (Proactive) <ref type="bibr" target="#b16">[16]</ref> that were candidate benchmark tests. However, not all test scenarios discovered were appropriate for evaluating Foofah. One of our design assumptions is that the output table must be relational; we eliminated 11 scenarios which violated this assumption. In the end, we created a set of benchmarks with 50 test scenarios 3 , among which 37 are real-world data transformation tasks collected in Microsoft Excel forums (from ProgFromEx <ref type="bibr" target="#b17">[17]</ref>) and the rest are synthetic tasks used by other related work.</p><p>For test scenarios with very little data, we asked a Computer Science student not involved with this project to synthesize more data for each of them following a format similar to the existing raw data of the scenario. This provided sufficient data records to evaluate each test scenario in Section 5.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Performance Evaluation</head><p>In this section, we experimentally evaluate the response time of Foofah and the perfectness of the synthesized programs on all test scenarios. Our experiments were designed in a way similar to that used by an influential work in spreadsheet data transformation, ProgFromEx <ref type="bibr" target="#b17">[17]</ref>, as well as other related work in data transformation <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b24">24]</ref>.</p><p>Overview -For each test scenario, we initially created an input-output example pair using a single data record chosen from the raw data and sent this pair to Foofah to synthesize a data transformation program. We executed this program on the entire raw data of the test scenario to check if the raw data was completely transformed as expected. If the inferred program did transform the raw data correctly, Foofah synthesized what we term a perfect program. If the inferred program did not transform the raw data correctly, we created a new input-output example that included one more data record chosen from the raw data, making the example more descriptive. We gave the new example to Foofah and again checked if the synthesized program correctly transformed the raw data. We repeated this process until Foofah found a perfect program, giving each round a time limit of 60 seconds.</p><p>Results -Figure <ref type="figure" target="#fig_0">11a</ref> shows numbers of data records required to synthesize a perfect program. Foofah was able to synthesize perfect programs for 90% of the test scenarios (45 of 50) using input-output examples comprising only 1 3 https://github.com/markjin1990/foofah benchmarks or 2 records from the raw data. Foofah did not find perfect programs for 5 of the 50 test scenarios. The five failed test scenarios were real-world tasks from ProgFromEx, but overall Foofah still found perfect programs for more than 85% of the real-world test scenarios (32 of 37).</p><p>Among the five failed test scenarios, four required unique data transformations that cannot be expressed using our current library of operators; Foofah could not possibly synthesize a program that would successfully perform the desired transformation. The remaining failed test scenario required a program that can be expressed with Foofah's current operations. This program has five steps, which contain two Divide operations. Foofah likely failed in this case because Divide separates a column of cells in two columns conditionally, which requires moves of cells following no geometric patterns we defined for TED Batch. The TED Batch heuristic overestimates the cost of paths that include Divide. Foofah required more computing time to find the correct path, causing it to reach the 60 second timeout.</p><p>Figure <ref type="figure" target="#fig_0">11b</ref> shows the average and worst synthesis time of each interaction in all test scenarios. The y-axis indicates the synthesis time in seconds taken by Foofah; the x-axis indicates the percentage of test scenarios that completed within this time. The worst synthesis time in each interaction is less than 1 second for over 74% of the test scenarios (37 of 50) and is less than 5 seconds for nearly 86% of the test scenarios (43 of 50), and the average synthesis time is 1.4 seconds for successfully synthesized perfect programs.</p><p>Overall, these experiments suggest that Foofah, aided by our novel TED Batch heuristic search strategy, can efficiently and effectively synthesize data transformation programs. In general, Foofah can usually find a perfect program within interactive response times when supplied with an input-output example made up of two data records from the raw data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Comparing Search Strategies</head><p>In this section, we evaluate several search strategies to justify our choice of TED Batch.</p><p>Overview -We considered Breadth First Search (BFS) and A* search with a rule-based heuristic (Rule), both mentioned in Section 4, and a baseline, Breadth First Search without pruning rules (BFS NoPrune). Based on the conclusion from Section 5.1, we created a set of test cases of input-output pairs comprising two records for all test scenarios. In this experiment, each search strategy was evaluated on the entire test set and the synthesis times were measured. The perfectness of the synthesized programs was not considered. A time limit of 300 seconds was set for all tests. When a program was synthesized within 300 seconds, we say Foofah was successful for the given test case.</p><p>Results -Figure <ref type="figure" target="#fig_0">11c</ref> shows that TED Batch achieves the most successes among all four search strategies and significantly more than the baseline "BFS NoPrune" over the full test suite. To understand the performance of the search strategies in different type of data transformation tasks, we examined the data for two specific categories of test cases.</p><p>We first checked the test cases requiring lengthy data transformation programs, since program length is a key factor affecting the efficiency of the search in the state space graph. We considered the a program to be lengthy if it required four or more operations. Figure <ref type="figure" target="#fig_0">11c</ref> shows the success rate for all four search strategies in lengthy test cases. TED Batch achieves the highest success rate of any of the strategies, with a margin larger than that for over all test cases. This indicates that our proposed strategy, TED Batch, is effective at speeding up the synthesis of lengthy programs. Since end users often feel frustrated when handling complex data transformations, we wished to know how TED Batch fared compared to other search strategies on complex tasks. We considered test cases that required the operators Fold, Unfold, Divide, Extract to be complex. Figure <ref type="figure" target="#fig_0">11c</ref> shows the success rate for those complex test cases. TED Batch outperforms the other three strategies.</p><p>Figure <ref type="figure" target="#fig_1">12a</ref> shows the time required to synthesize the programs for our set of tests for each search strategy. The TED Batch search strategy is significantly the fastest, with over 90% of the tests completing in under 10 seconds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Effectiveness of Pruning Rules</head><p>One contribution of our work is the creation of a set of pruning rules for data transformation. We examine the efficiency of Foofah with and without these pruning rules to show how effectively these pruning rules boost the search speed, using the benchmarks from Section 5.1.</p><p>Figure <ref type="figure" target="#fig_1">12b</ref> presents the response times of Foofah with pruning rules removed. The pruning rules do improving the efficiency of the program synthesis. However, the difference between the response time of Foofah with and without pruning rules is only moderate in size. This is because the search strategy we use-TED Batch-is itself also very effective in "pruning" bad states, by giving them low priority in search. In fact, if we look at "BFS NoPrune" and "BFS" in Figure <ref type="figure" target="#fig_1">12a</ref>, the difference between their response time is quite significant, showing that the pruning rules are indeed quite helpful at reducing the size of the search space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Adaptiveness to New Operators</head><p>A property of our program synthesis technique is its operatorindependence, as we discussed in Section 4. To demonstrate this, we compared the efficiency of our prototype, Foofah, with and without a newly added operator: Wrap (defined in Appendix A). Wrap has three variants: Wrap on column x (W1), Wrap every n rows (W2) and Wrap into one row (W3). We examined the responsiveness of Foofah on all test cases as we sequentially added the three variants of Wrap.</p><p>Figure <ref type="figure" target="#fig_1">12c</ref> shows the response time of Foofah as we add new variants of Wrap, using the same set of test cases as in Section 5.3. The addition of the Wrap operations allowed more test scenarios to be successfully completed, while the synthesis time of overall test cases did not increase. This is evidence that the system can be improved through the addition of new operators, which can be easily incorporated without rewriting the core algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">User Effort Study</head><p>Foofah provides a Programming By Example interaction model in hopes of saving user effort. In this experiment, we asked participants to work on both Wrangler and Foofah and compared the user effort required by both systems.</p><p>Overview -We invited 10 graduate students in Computer Science with no experience in data transformation to participate in our user study. From our benchmark test suite, we chose eight user study tasks of varied length and complexity, shown in  use both Wrangler and Foofah with documentation and a complex running example. During the experiment, each participant was given four randomly selected tasks, covering complex, easy, lengthy, and short tasks, to complete on both systems. Each task had a 10 minute time limit.</p><p>Evaluation Metrics -To quantify the amount of user effort on both systems, we measured the time a user spends to finish each user study task. In addition to time, we also measured the number of user mouse clicks and key strokes.</p><p>Results -Table <ref type="table" target="#tab_10">5</ref> presents the measurement of the average user efforts on both Wrangler and Foofah over our 8 user study tasks. The percentages of time saving in each test is presented to the right of the time statistics of Foofah.</p><p>The timing results show that Foofah required 60% less interaction time in every test on average. Foofah also saved more time on complex tasks. On these tasks, Foofah took one third as much interaction time as Wrangler. On the lengthy and complex "Wrangler3" case, 4 of 5 test takers could not find a solution within 10 minutes using Wrangler, but all found a solution within 3 minutes using Foofah.</p><p>Additionally, in Table <ref type="table" target="#tab_10">5</ref> we see that Foofah required an equal or smaller number of mouse clicks than Wrangler. This partially explains why Foofah required less interaction time and user effort. Table <ref type="table" target="#tab_10">5</ref> also shows that Foofah required more typing than Wrangler, mainly due to Foofah's interaction model. Typing can be unavoidable when specifying examples, while Wrangler often only requires mouse clicks.</p><p>Another observation from the user study was that participants often felt frustrated after 5 minutes and became less willing to continue if they could not find a solution, which justifies our view that a Programming By Demonstration data transformation tool can be hard to use for naïve users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Comparison with Other Systems</head><p>Foofah is not the first PBE data transformation system. There are two other closely related pieces of previous work: ProgFromEx <ref type="bibr" target="#b17">[17]</ref> and FlashRelate <ref type="bibr" target="#b4">[4]</ref>. In general, both ProgFromEx and FlashRelate are less expressive than Foofah; they are limited to layout transformations and cannot handle syntactic transformations. Further, in practice, both systems are likely to require more user effort and to be less efficient than Foofah on complex tasks.</p><p>Source code and full implementation details for these systems are not available. However, their published experimental benchmarks overlap with our own, allowing us to use their published results in some cases and hand-simulate their results in other cases. As a result, we can compare our system's success rate to that of ProgFromEx and FlashRelate on at least some tasks, as seen in Table <ref type="table" target="#tab_13">6</ref>. Note that syntactic transformation tasks may also entail layout transformation steps, but the reverse is not true.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7.1">ProgFromEx</head><p>The ProgFromEx project employs the same usage model as Foofah: the user gives an "input" grid of values, plus a desired "output" grid, and the system formulates a program to transform the input into the output. A ProgFromEx program consists of a set of component programs. Each component program takes in the input table and yields a map, a set of input-output cell coordinate pairs that copies cells from the input table to some location in the output table.</p><p>A component program can be either a filter program or an associative program. A filter program consists of a mapping condition (in the form of a conjunction of cell predicates) plus a sequencer (a geometric summary of where to place data in the output table). To execute a filter program, ProgFromEx tests each cell in the input table, finds all cells that match the mapping condition, and lets the sequencer decide the coordinates in the output table to which the matching cells are mapped. An associative program takes a component program and applies an additional transformation function to the output cell coordinates, allowing the user to produce output tables using copy patterns that are not strictly oneto-one (e.g., a single cell from the input might be copied to multiple distinct locations in the output).</p><p>Expressiveness -The biggest limitation of ProgFromEx is that it cannot describe syntactic transformations. It is designed to move values from an input grid cell to an output grid cell; there is no way to perform operations like Split or Merge to modify existing values. Moreover, it is not clear how to integrate such operators into their cell mapping framework. In contrast, our system successfully synthesizes programs for 100% of our benchmark syntactic transformation tasks, as well as 90% of the layout transformation tasks (see Table <ref type="table" target="#tab_13">6</ref>). (Other systems can handle these critical syntactic transformation tasks <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b22">22,</ref><ref type="bibr" target="#b34">34]</ref>, but Foofah is the first PBE system to do so that we know of). ProgFromEx handles slightly more layout transformations in the benchmark suite than our current Foofah prototype, but ProgFromEx's performance comes at a price: the system administrator or the user must pre-define a good set of cell mapping conditions. If the user were willing to do a similar amount of work on Foofah by adding operators, we could obtain a comparable result.</p><p>User Effort and Efficiency -For the subset of our benchmark suite that both systems handle successfully (i.e., cases without any syntactic transformations), ProgFromEx and Foofah require roughly equal amounts of user effort. As we describe in Section 5.1, 37 of our 50 benchmark test scenarios are borrowed from the benchmarks of ProgFromEx. For each of these 37 benchmarks, both ProgFromEx and Foofah can construct a successful program with three or fewer user-provided examples. Both systems yielded wait times under 10 seconds for most cases.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">RELATED WORK</head><p>Both program synthesis and data transformation have been the focus of much research, which we discuss in depth below. Program Synthesis -Several common techniques to synthesize programs have been discussed in Section 4.1: constraintbase program synthesis <ref type="bibr" target="#b15">[15,</ref><ref type="bibr" target="#b21">21]</ref> does not fit our problem because existing logic solvers could not scale to solve a large number of constraints quadratic in the input size; sketching <ref type="bibr" target="#b40">[40]</ref> is computationally unfeasible for interactive data transformation; version space algebra <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b23">23]</ref> is usually applied in PBD systems. Therefore, we formulate our problem as a search problem in the state space graph and solve it using a search-based technology with a novel heuristic-TED Batch-as well as some pruning rules.</p><p>Researchers have applied program synthesis techniques to a variety of problem domains: parsers <ref type="bibr" target="#b25">[25]</ref>, regular expressions <ref type="bibr" target="#b5">[5]</ref>, bit-manipulation programs <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b21">21]</ref>, data structures <ref type="bibr" target="#b39">[39]</ref>; code snippets and suggestions in IDEs <ref type="bibr" target="#b29">[29,</ref><ref type="bibr" target="#b35">35]</ref>, and SQL query based on natural language queries <ref type="bibr" target="#b26">[26]</ref> and data handling logic <ref type="bibr" target="#b10">[10]</ref>, schema mappings <ref type="bibr" target="#b2">[2]</ref>. There are also several projects that synthesize data transformation and extraction programs, discussed in more detail next.</p><p>Data Transformation -Data extraction seeks to extract data from unstructured or semi-structured data. Various data extraction tools and synthesizers have been created to automate this process: TextRunner <ref type="bibr" target="#b3">[3]</ref> and WebTables <ref type="bibr" target="#b6">[6]</ref> extract relational data from web pages; Senbazuru <ref type="bibr" target="#b7">[7,</ref><ref type="bibr" target="#b8">8]</ref> and FlashRelate <ref type="bibr" target="#b4">[4]</ref> extract relations from spreadsheets; FlashExtract <ref type="bibr" target="#b24">[24]</ref> extracts data from a broader range of documents including text files, web pages, and spreadsheets, based on examples provided by the user.</p><p>Data transformation (or data wrangling) is usually a followup step after data extraction, in which the extracted content is manipulated into a form suitable for input into analytics systems or databases. Work by Wu et al. <ref type="bibr" target="#b43">[43]</ref><ref type="bibr" target="#b44">[44]</ref><ref type="bibr" target="#b45">[45]</ref>, as well as FlashFill <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b38">38]</ref> and BlinkFill <ref type="bibr" target="#b36">[36]</ref> are built for syntactic transformation. DataXFormer <ref type="bibr" target="#b1">[1]</ref> and work by Singh and Gulwani <ref type="bibr" target="#b37">[37]</ref> are built for semantic transformation. ProgFromEx <ref type="bibr" target="#b17">[17]</ref> is built for layout transformation, and Wrangler <ref type="bibr" target="#b22">[22]</ref> provides an interactive user interface for data cleaning, manipulation and transformation. Some existing data transformation program synthesizers follow Programming By Example paradigm similar to Foofah <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b13">13,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b36">36,</ref><ref type="bibr" target="#b43">[43]</ref><ref type="bibr" target="#b44">[44]</ref><ref type="bibr" target="#b45">[45]</ref>. ProgFromEx <ref type="bibr" target="#b17">[17]</ref> and FlashRelate <ref type="bibr" target="#b4">[4]</ref> are two important projects in PBE data transformation which have been compared with our proposed technique in Section 5.7. In general, their lack of expressiveness for syntactic transformations prevent them from addressing many real-world data transformation tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSION AND FUTURE WORK</head><p>In this paper, we have presented a Programming By Example data transformation program synthesis technique that reduces the user effort for naïve end users. It takes descriptive hints in form of input-output examples from the user and generates a data transformation program that transforms the input example to the output example. The synthesis problem is formulated as a search problem, and solved by a heuristic search strategy guided by a novel operator-independent heuristic function, TED Batch, with a set of pruning rules. The experiments show that our proposed PBE data transformation program synthesis technique is effective and efficient in generating perfect programs. The user study shows that the user effort is 60% less using our PBE paradigm compared to Wrangler <ref type="bibr" target="#b22">[22]</ref>.</p><p>In the future, we would like to extend our system with an interface allowing the user to easily add new data transformation operators and to explore advanced methods of generating the geometric patterns for batching. Additionally, we would like to generate useful programs even when the user's examples may contain errors. We could do so by alerting the user when the system observes unusual example pairs that may be mistakes, or by synthesizing programs that yield outputs very similar to the user's specified example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">ACKNOWLEDGMENTS</head><p>This project is supported by National Science Foundation grants IIS-1250880, IIS-1054913, NSF IGERT grant 0903629, as well as a Sloan Research Fellowship and a CSE Department Fellowship. We would like to thank our anonymous reviewers for their careful reading of our manuscript and many insightful comments and suggestions. We also thank our user study participants and Andreas Dressel for his ideas. the table to the goal state, and assign the total count as the heuristic score for this intermediate table.</p><p>In Algorithm 3, we create estimates for both kinds of operators separately: lines 4-7 estimate how many one-toone operators are used, while lines 9-12 estimate how many many-to-many operators and additional one-to-one operators are used. Line 9 checks if the number of rows in Ti equals the number of rows in To to determine if a many-to-many operator is needed, since we observe that many-to-many operators usually change the total number of rows in the table, while one-to-one operators never do. We evaluate the two cases separately since it is easier to estimate the number oneto-one operators that are used if many-to-many operations can be ignored. Take Table <ref type="table">7</ref> and Table <ref type="table">8</ref> as an example, neither of the two cells in the third row in Table <ref type="table">8</ref> has an exact match in cell contents in the third row in Table <ref type="table">7</ref>, but both of them are substrings of the first cell in third column of Table <ref type="table">7</ref>. Hence, we know that a Split operator is likely used. Similar rules used for other operators are presented in Table <ref type="table" target="#tab_3">10</ref>. We evaluate the cost individually for each row in Ti and To and finally take the median of all the costs as the final cost (line 7) as the final estimate.</p><p>For many-to-many operators, the estimation becomes harder, because many-to-many operators always perform layout transformations, and depending on the size of the input table and the chosen parameterization for the operator, a many-tomany operator may move a cell to many different locations in the table. Fortunately, we found that each of the many-tomany operator change the shape, width (number of columns) and height (number of rows), of the input table in a unique way, so there is a possibility that we can tell which operator is used by simple comparing the shapes of Ti and To. For example, Transpose is a many-to-many operator that flips the table converting columns into rows and vice versa, hence the width of Ti becomes the height of To and the height of Ti becomes the width of To. Other rules detecting many-to-many operators are shown in Table <ref type="table" target="#tab_3">11</ref>. Note that when more than one many-to-many operators are used in a transformation, none of rules in Table <ref type="table" target="#tab_3">11</ref> might work, making it hard to make an estimate about which are the operators needed. In this case, we simply assume that two many-to-many operators</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A spreadsheet of business contact information Tel Fax Niles C. (800)645-8397 (907)586-7252 Jean H. (918)781-4600 (918)781-4604 Frank K. (615)564-6500 (615)564-6701 . . .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A relational form of Figure 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Intermediate table state</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Perform Unfold before Fill</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Program synthesized with Foofah</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Definition 4 . 1 (</head><label>41</label><figDesc>Program synthesis as a search problem).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>FrankFigure 9 :Figure 10 :</head><label>910</label><figDesc>Figure 9: An example data transformation task</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>1),(3,1)), Transform((3,1),(</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>p1 = {Transform((1,2),(1,1)), Transform((2,2),(2,1)), Transform((3,2),(3,1))}, p2 = {Transform((1,2),(1,2)), Transform((2,2),(2,2)), Transform((3,2),(3,2))}, p3 = {Move((1,2),(1,1)), Move((2,2),(2,1)), Move((3,2),(3,1))}, p4 = {Delete((1,1)), Delete((2,1)), Delete((3,1))}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 11 :Figure 12 :</head><label>1112</label><figDesc>Figure 11: (a) and (b) show number of records and synthesis time required by Foofah in the experiments of Section 5.1; (c) Percentage of successes for different search strategies in the experiments of Section 5.3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>if existSyntacticalHeterogeneities(Ti, To) = T rue then 12 cost ← cost + 1 13 return cost;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Delete rows where column 2 is null 4 Split column 2 on ':' 5 Fill split with values from above 6 Unfold column 2 on column 3</figDesc><table><row><cell>1 Delete row 1</cell></row><row><cell>2 Delete row 2</cell></row><row><cell>3 Figure 5: Program created with Wrangler</cell></row><row><cell>1 t = split(t, 1, ':')</cell></row><row><cell>2 t = delete(t, 2)</cell></row><row><cell>3 t = fill(t, 0)</cell></row><row><cell>4 t = unfold(t, 1)</cell></row><row><cell>1. changing the structure of the table</cell></row><row><cell>2. removing unnecessary data fields</cell></row><row><cell>3. filling in missing values</cell></row><row><cell>4. extracting values from cells</cell></row><row><cell>5. creating new cell values out of several cell values</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Notation Description P = {p 1 , . . . , pn} Data transformation program p i = (op i , par 1 , . . . ) Transformation operation with operator op i and parameters par 1 , par 2 , etc.</figDesc><table><row><cell>R</cell><cell>Raw dataset to be transformed</cell></row><row><cell>e i ∈ R</cell><cell>Example input sampled from R by user</cell></row><row><cell>eo = P(e i )</cell><cell>Example output provided by user, trans-</cell></row><row><cell></cell><cell>formed from e i</cell></row><row><cell>E = (e i , eo)</cell><cell>Input-output example table pair, pro-</cell></row><row><cell></cell><cell>vided as input to the system by user</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Frequently used notation</figDesc><table><row><cell>Operator</cell><cell>Description</cell></row><row><cell>Drop</cell><cell>Deletes a column in the table</cell></row><row><cell>Move</cell><cell>Relocates a column from one position to an-</cell></row><row><cell></cell><cell>other in the table</cell></row><row><cell>Copy</cell><cell>Duplicates a column and append the copied</cell></row><row><cell></cell><cell>column to the end of the table</cell></row><row><cell>Merge</cell><cell>Concatenates two columns and append the</cell></row><row><cell></cell><cell>merged column to the end of the table</cell></row><row><cell>Split</cell><cell>Separates a column into two or more halves</cell></row><row><cell></cell><cell>at the occurrences of the delimiter</cell></row><row><cell>Fold</cell><cell>Collapses all columns after a specific column</cell></row><row><cell></cell><cell>into one column in the output table</cell></row><row><cell>Unfold</cell><cell>"Unflatten" tables and move information from</cell></row><row><cell></cell><cell>data values to column names</cell></row><row><cell>Fill</cell><cell>Fill empty cells with the value from above</cell></row><row><cell>Divide</cell><cell>Divide is used to divide one column into two</cell></row><row><cell></cell><cell>columns based on some predicate</cell></row><row><cell>Delete</cell><cell>Delete rows or columns that match a given</cell></row><row><cell></cell><cell>predicate</cell></row><row><cell>Extract</cell><cell>Extract first match of a given regular expres-</cell></row><row><cell></cell><cell>sion each cell of a designated column</cell></row><row><cell>Transpose</cell><cell>Transpose the rows and columns of the table</cell></row><row><cell cols="2">Wrap (added) Concatenate multiple rows conditionally</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Data transformation operators used by Foofah</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Approximate TED Algorithm Data: Intermediate Table ex = {u1, u2, . . . , u |ex| }, where ui represents a cell from ex; Example Output Table eo = {v1, v2, . . . , v |eo| }, where vi represents a cell from eo Result: cost, edit path 1 p f inal ← ∅; 2 ptemp ← ∅; 3 for w in ex do add Add(v1) to ptemp; 6 p f inal ← argmin ∀p∈p temp cost(p) ; 7 Let {u1, . . . , uj} &amp; {v1, . . . , v k } be processed cells; 8 while j &lt;| ex | and k &lt;| eo | do for w ∈ {u1, . . . , u |ex| } do add AddCandT ransf orm(w, v k+1 ) to ptemp; add Add (v k+1 ) to ptemp;</figDesc><table><row><cell>4</cell><cell>add AddCandT ransf orm(w, v1) to ptemp;</cell></row><row><cell>9</cell><cell>ptemp ← ∅;</cell></row><row><cell></cell><cell>for w ∈ {uj+1, . . . , u |ex| } do</cell></row><row><cell></cell><cell>add AddCandT ransf orm(w, v k+1 ) to ptemp;</cell></row><row><cell></cell><cell>add Add(v k+1 ) to ptemp;</cell></row><row><cell></cell><cell>if cost(argmin ∀p∈p temp cost(p)) ≥ ∞ then</cell></row><row><cell></cell><cell>ptemp ← ∅;</cell></row></table><note><p><p><p><p><p>1. Transformation from an unprocessed cell in ex into a cell in eo. Transformation sequences for a pair of cells is generated by the function "AddCandTransform" and can include a Move operator (if the cell coordinates differ), a Transform operator (if the cell contents differ), or both operators (if both conditions apply).</p>2.</p>Add a new cell to eo.</p>Algorithm 1:</p>5</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>table dissimilarity, it is not yet a good heuristic function in our problem because (1) it is an estimate of the cost of table edit path at a cell level which is on a scale different from our data transformation operations cost defined in Definition 4.2 and Algorithm 2: Table Edit Distance Batch Data: p f inal = {ui1 → v1, . . . , u i|T 2 | → v |T 2 | }, patterns from Table 4 Result: cost 1 batchtemp ← ∅; 2 batch f inal ← ∅; 3 Gtype ← Group p f inal by table edit operators type ; 4 for g ∈ Gtype do</figDesc><table><row><cell>5</cell><cell cols="2">for p ∈ patterns do</cell></row><row><cell>6</cell><cell></cell><cell>batchtemp ← batchtemp ∪ Group g by p;</cell></row><row><cell cols="2">7 while</cell><cell>batch f inal is not a complete edit path do</cell></row></table><note><p>8 batchmax ← argmax b∈batch temp size(b) ; 9 if batchmax ∩ batch f inal = ∅ then add batchmax to batch f inal ; batchtemp ← batchtemp\batchmax; cost ← 0; for group ∈ batch f inal do sum ← 0; for editOp ∈ group do sum ← sum + cost(editOp); cost ← cost + sum/size(group);</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4 :</head><label>4</label><figDesc>Geometric patternsProperty-specific Pruning Rules -The properties of certain operators allow us to define further pruning rules.• Generating Empty Columns -Prune the operation if it adds an empty column in the resulting state when it should not. This applies to Split, Divide, Extract, and Fold. For example, Split adds an empty column to a table when parameterized by a delimiter not present in the input column; this Split useless and can be pruned.</figDesc><table /><note><p>• Null In Column -Prune the operation if a column in the parent state or resulting child state has null value that would cause an error. This applies to Unfold, Fold and Divide. For example, Unfold takes in one column as header and one column as data values: if the header column has null values, it means the operation is invalid, since column headers should not be null values.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 5 .</head><label>5</label><figDesc>Column "Complex" indicates if a task requires a complex operator: Fold, Unfold, Divide, and Extract. Column "≥ 4 Ops" indicates if a task requires a data transformation program with 4 or more operations.Before the experiment, we educated participants on how to</figDesc><table><row><cell>Wrangler</cell><cell>Foofah</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 5 :</head><label>5</label><figDesc>User study experiment results</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>Layout Trans. Syntactic Trans.</figDesc><table><row><cell>Foofah</cell><cell>88.4%</cell><cell>100%</cell></row><row><cell>ProgFromEx</cell><cell>97.7%</cell><cell>0%</cell></row><row><cell>FlashRelate</cell><cell>74.4%</cell><cell>0%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 6 :</head><label>6</label><figDesc>Success rates for different techniques on both layout transformation and syntactic transformation benchmarks5.7.2 FlashRelateFlashRelate is a more recent PBE data transformation project that, unlike ProgFromEx and Foofah, only requires the user to provide output examples, not input examples. However, the core FlashRelate algorithm is similar to that of ProgFromEx: it conditionally maps cells from a spreadsheet to a relational output table. FlashRelate's cell condition tests are more sophisticated than those in ProgFromEx (e.g., they can match on regular expressions and geometric constraints). Expressiveness -Like ProgFromEx, FlashRelate cannot express syntactic transformations, because FlashRelate requires exact matches between regular expressions and cell contents for cell mapping. Moreover, certain cell-level constraints require accurate schematic information, such as column headers, in the input table. FlashRelate achieves a lower success rate than Foofah in Table6. In principle, FlashRelate should be able to handle some tasks that ProgFromEx cannot, but we do not observe any of these in our benchmark suite. User Effort and Efficiency -FlashRelate only requires the user to provide output examples, suggesting that it might require less overall user effort than Foofah or ProgFromEx. However, on more than half of the benchmark cases processed by both FlashRelate and Foofah, FlashRelate required five or more user examples to synthesize a correct transformation program, indicating that the effort using FlashRelate is not less than either ProgFromEx or Foofah. Published results show that more than 80% of tasks complete within 10 seconds, suggesting that FlashRelate's runtime efficiency is comparable to that of Foofah and ProgFromEx.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>Transform((a1,a2),(b1,b2)) means Transform the cell at (a1,a2) in ei to the cell at (b1,b2) in eo. Move((a1,a2),(b1,b2)) means Move the cell from (a1,a2) in ei to (b1,b2) in eo Delete((c1,c2)) means Delete the cell at (c1,c2) in ei.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EXPERIMENTS</head><p>In this section, we evaluate the effectiveness and efficiency of our PBE data transformation synthesis technique and how much user effort it requires. We implemented our technique in a system called Foofah. Foofah is written in Python and C++ and runs on a 16-core (2.53GHz) Intel Xeon E5630 server with 120 GB RAM.</p><p>We first present our benchmarks and then evaluate Foofah using the benchmarks to answer several questions:</p><p>• How generalizeable are the synthesized programs output by Foofah? (Section 5.2)</p><p>• How efficient is Foofah at synthesizing data transformation programs? (Section 5.2)</p><p>• How is the chosen search method using the TED Batch heuristic better than other search strategies, including BFS and a naïve rule-based heuristic? (Section 5.3)</p><p>• How effectively do our pruning rules boost the search speed? (Section 5.4)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A. DEFINITIONS OF ALL TABLE TRANS-FORMATION OPERATIONS</head><p>Note that all operators have R as a default input parameter, which represents the input example table. a1, a2, . . . represent the columns. The domains for all column indexes is {1, . . . , k}, where k is the number of columns in R. </p><p>• Unfold "unflattens" tables and move information from data values to column names. Definition: U nf old(R, i, j) takes in two columns, i and j. It creates new columns for each unique value found in column i and takes data in column j as the column headers of new columns.</p><p>• Divide divides one column into two columns based on some predicate. Its input parameters include a column index i and a predicate. The domain of predicates in our prototype includes "if all digits", "if all alphabets", "if all alphanumerics". Definition: • Fill assign empty cells with the value from above. Its input parameter is a column index.</p><p>• Delete removes rows that matches a given predicates.</p><p>In our case, we restrict Delete to remove rows that has an empty cell in a given column. Its input parameter is a column index.</p><p>• Transpose Transpose the rows and columns of the table. It has no other input parameter.</p><p>• Wrap Wrap has three options:</p><p>1. Concatenates rows on one column. It has an input parameter of column index i. Definition: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. EXTRA USE CASE EXAMPLES</head><p>Example 1 -The following tables show another example use case borrowed from <ref type="bibr" target="#b33">[33]</ref> where the end user needs some data extraction and table reshaping. Simple as the task seems, it is indeed complex (as in the motivating example) in that it relies on syntactic transformations to extract each individual first name into a separate column, using Split (line 1-2), and then a layout transformation to reshape the table by collapsing the second column and third column into one column using Fold. Finally, Delete removes the rows with no first name in the second column. Example 2 -This example shows how our data transformation technique can extract data from less-structured text files that are initially seen as tables with a single cell. Figure <ref type="figure">13</ref> is detailed directory listing information output by the "ls -l" linux command 4 . The user wants to extract the file names and the owner names. The synthesized program (Figure <ref type="figure">14</ref>) first splits the raw data into rows (line 1-2) and then performs operations to extract the desired fields.</p><p>-rw-r-r-1 mjc staff 180 Mar 12 07:18 accesses.txt -rw-r-r-1 mjc staff 183 Mar 12 07:15 accesses.txt∼ drwxr-xr-x 5 mjc staff 170 Mar 14 14:14 bin   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. NAÏVE HEURISTIC FUNCTION</head><p>The Potter's Wheel operators in our library can be divided into two groups: one-to-one and many-to-many <ref type="bibr" target="#b34">[34]</ref>. One-toone operations (e.g., Split) transform the same column(s) in each row, and to estimate the required number of one-to-one operations, it is often effective to apply some operator-specific rules on cells in the same row of both input and output tables (lines 4-6). In contrast, many-to-many operations, such as Fold, structurally transform the entire table. We propose Algorithm 3 to iteratively estimate if each Potter's Wheel operator should be used to transform the current state of   are used, because it is rare that two or more many-to-many operators are used in a real-world data transformation task. When many-to-many operators are used in a transformation task, one-to-one operators can also be used (e.g., the example in Section 2). However, given the fact that manyto-many operators may move the cells to any position in the output table, estimating one-to-one operators row by row like is done lines 2-7 using the rules form Table <ref type="table">10</ref> is not feasible. We therefore give a rough estimate: assume at least one one-to-one operator is used if there is a cell in To without an exact match on cell content in Ti (checked by existSyntacticalHeterogeneities in line 11).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 4:</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. OPTIMAL TED ALGORITHM</head><p>In Algorithm 4, we show an optimal Table Edit Distance Algorithm. The set Open contains all partial edit paths (line 1). In each iteration, it selects the most promising partial edit path with minimum total cost (line 7). It creates a set of successors of this path by taking an unprocessed cell ui from input table ex and substituting it with all unprocessed cells w from output table eo and then deleting the cell ui (lines <ref type="bibr" target="#b13">[13]</ref><ref type="bibr" target="#b14">[14]</ref><ref type="bibr" target="#b15">[15]</ref><ref type="bibr" target="#b16">[16]</ref><ref type="bibr" target="#b17">[17]</ref>. When there are no more unprocessed cells in ex, all remaining cells in eo will be added (line <ref type="bibr" target="#b19">19)</ref>. The algorithm terminates when there is an complete edit path (lines 9-10). Finally, Algorithm 4 returns the cost of the cheapest path.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">DataXFormer: A robust transformation discovery system</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Abedjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Morcos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ouzzani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Papotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Characterizing schema mappings via data examples</title>
		<author>
			<persName><forename type="first">B</forename><surname>Alexe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Cate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Kolaitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Database Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">23</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Open information extraction for the web</title>
		<author>
			<persName><forename type="first">M</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Broadhead</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Flashrelate: Extracting relational data from semi-structured spreadsheets using examples</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Barowy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gulwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Swyn: A visual representation for regular expressions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Blackwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Your Wish is My Command: Programming by Example</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="245" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Webtables: exploring the power of tables on the web</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Halevy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="538" to="549" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automatic web spreadsheet data extraction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cafarella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Workshop on Semantic Search over the Web</title>
		<meeting>the 3rd International Workshop on Semantic Search over the Web</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Senbazuru: a prototype spreadsheet database management system</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Prevo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1202" to="1205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Long-tail vocabulary dictionary extraction from the web</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jagadish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Optimizing database-backed applications with query synthesis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Solar-Lezama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Computers and intractability: A guide to the theory of np-completeness</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Gary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automating string processing in spreadsheets using input-output examples</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gulwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">POPL</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Spreadsheet data manipulation using examples</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gulwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="97" to="105" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Component based synthesis applied to bitvector circuits</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gulwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tiwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Venkatesan</surname></persName>
		</author>
		<idno>MSR-TR-2010-12</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Microsoft Research</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Synthesis of loop-free programs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gulwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tiwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Venkatesan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Proactive wrangling: Mixed-initiative end-user programming of data transformation scripts</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kandel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UIST</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Spreadsheet table transformations from examples</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gulwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A formal basis for the heuristic determination of minimum cost paths. Systems Science and Cybernetics</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Raphael</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="100" to="107" />
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">D</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mazzocchi</surname></persName>
		</author>
		<author>
			<persName><surname>Openrefine</surname></persName>
		</author>
		<ptr target="http://openrefine.org" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dynamic multi-heuristic a*</title>
		<author>
			<persName><forename type="first">F</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Likhachev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Oracle-guided component-based program synthesis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gulwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Seshia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tiwari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICSE</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Wrangler: Interactive visual specification of data transformation scripts</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kandel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Paepcke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hellerstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Version space algebra and its application to programming by demonstration</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Domingos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">FlashExtract: A framework for data extraction by examples</title>
		<author>
			<persName><forename type="first">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gulwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Interactive parser synthesis by example</title>
		<author>
			<persName><forename type="first">A</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sarracino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lerner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Constructing an interactive natural language interface for relational databases</title>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jagadish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="73" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Your wish is my command: Programming by example</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lieberman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">For big-data scientists, janitor work is key hurdle to insights</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lohr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The New York Times</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Jungloid mining: helping to navigate the api jungle</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mandelin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bodík</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kimelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Superoptimizer: a look at the smallest program</title>
		<author>
			<persName><forename type="first">H</forename><surname>Massalin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASPLOS II</title>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Bridging the gap between graph edit distance and kernel machines</title>
		<author>
			<persName><forename type="first">M</forename><surname>Neuhaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bunke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>World Scientific Publishing Co., Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Scaling up superoptimization</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Phothilimthana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bodik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dhurjati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASPLOS</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">An interactive framework for data cleaning</title>
		<author>
			<persName><forename type="first">V</forename><surname>Raman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hellerstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Potter&apos;s Wheel: An interactive data cleaning system</title>
		<author>
			<persName><forename type="first">V</forename><surname>Raman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="381" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Refactoring with synthesis</title>
		<author>
			<persName><forename type="first">V</forename><surname>Raychev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sridharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vechev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OOPSLA</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">BlinkFill: Semi-supervised programming by example for syntactic string transformations</title>
		<author>
			<persName><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="816" to="827" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning semantic string transformations from examples</title>
		<author>
			<persName><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gulwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="740" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Predicting a correct program in programming by example</title>
		<author>
			<persName><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gulwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Aided Verification</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="398" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Synthesizing data structure manipulations from storyboards</title>
		<author>
			<persName><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Solar-Lezama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ESEC/FSE</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Program synthesis by sketching</title>
		<author>
			<persName><forename type="first">A</forename><surname>Solar-Lezama</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>ProQuest</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Data curation at scale: The Data Tamer system</title>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">F</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Beskales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cherniack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Zdonik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Tels: Learning text editing tasks from examples</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Watch what I do</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="183" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">An iterative approach to synthesize data transformation programs</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Knoblock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Learning data transformation rules through examples: Preliminary results</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szekely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Knoblock</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>IIWeb</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Minimizing user effort in transforming data by example</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szekely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Knoblock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IUI</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
