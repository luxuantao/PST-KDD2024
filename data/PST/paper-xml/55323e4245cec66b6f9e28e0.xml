<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Passive Image-Splicing Detection by a 2-D Noncausal Markov Model</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Xudong</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic Information and Electrical Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<postCode>200240</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Shilin</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic Information and Electrical Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<postCode>200240</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><roleName>Member, IEEE</roleName><forename type="first">Shenghong</forename><surname>Li</surname></persName>
							<email>shli@sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic Information and Electrical Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<postCode>200240</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jianhua</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic Information and Electrical Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<postCode>200240</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Passive Image-Splicing Detection by a 2-D Noncausal Markov Model</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">367FBA71A4013E97ECC92D45B5469B0E</idno>
					<idno type="DOI">10.1109/TCSVT.2014.2347513</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, a 2-D noncausal Markov model is proposed for passive digital image-splicing detection. Different from the traditional Markov model, the proposed approach models an image as a 2-D noncausal signal and captures the underlying dependencies between the current node and its neighbors. The model parameters are treated as the discriminative features to differentiate the spliced images from the natural ones. We apply the model in the block discrete cosine transformation domain and the discrete Meyer wavelet transform domain, and the cross-domain features are treated as the final discriminative features for classification. The support vector machine which is the most popular classifier used in the image-splicing detection is exploited in our paper for classification. To evaluate the performance of the proposed method, all the experiments are conducted on public image-splicing detection evaluation data sets, and the experimental results have shown that the proposed approach outperforms some state-of-the-art methods. Index Terms-2-D noncausal Markov model, block discrete cosine transformation (BDCT), discrete Meyer wavelet transform, passive image-splicing detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>W ITH the development of the digital image process- ing technology and the popularity of digital cameras, tampered images are flooded in our daily life. Some image-tampering processes are harmless; for example, image contrast adjustment, skin smoothing, and white balancing. However, tampered images (especially the spliced images) with malicious purposes could lead to adverse social effects. To regain trust on digital images, many researchers have proposed various approaches to authenticate image data. These approaches can be roughly divided into two main categories: active methods [1]-[4] and passive methods [5]- <ref type="bibr" target="#b22">[23]</ref>. The active methods (e.g., digital watermarking and digital signature) try to verify the authenticity of images by checking</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>whether the previous embedded watermark or digital signature has been destroyed. This kind of approaches can detect image tampering and locate the manipulated regions effectively; however, certain watermarks or signatures have to be inserted into the digital image in the imaging process, which is impractical for most of the commercial cameras. In contrast, the passive methods do not require any prior information and thus they are more suitable for detecting image forgeries on the Internet. The passive methods try to detect image forgeries under the assumption that image tampering would change the underlying statistical characteristics of the original images. The inconsistence of the statistical characteristics is therefore treated as the evidences for image-tampering detection. Among all kinds of image-tampering operations, splicing is the most fundamental and essential operation in creating image forgeries <ref type="bibr" target="#b6">[7]</ref>. Hence image-splicing detection is of vital importance in digital image forensics. In this paper, we focus our research on the passive image-splicing detection method.</p><p>In recent years, various kinds of passive image-splicing detection approaches have been proposed. Shi et al. <ref type="bibr" target="#b14">[15]</ref> proposed a natural image model for image-splicing detection. They treated the neighboring differences of block discrete cosine transformation (BDCT) coefficients of an image as a (1-D) signal. The dependencies between neighboring nodes (or rounded BDCT coefficients) along certain direction (horizontal or vertical) were modeled as a causal Markov model and the transition probability matrix, which was regarded as a discriminative feature vector for support vector machine (SVM) classification. Wang et al. <ref type="bibr" target="#b15">[16]</ref> proposed a gray co-occurrence matrix-based method to detect image splicing. The adjacent difference array of pixel intensities was modeled as 1-D signal and the second-order statistics, that is, gray co-occurrence matrix, were extracted as discriminative features for classification. Sutthiwan et al. <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref> and Wang et al. <ref type="bibr" target="#b18">[19]</ref> introduced the causal Markov model, respectively, in the BDCT domain and spatial domain to detect image tampering in chroma channels, and their experiments have shown that the detection rate over CASIA data set can achieve as high as 99%. However, Patchara et al. <ref type="bibr" target="#b19">[20]</ref> have verified that the high detection rate in <ref type="bibr" target="#b16">[17]</ref>- <ref type="bibr" target="#b18">[19]</ref> may be related to the artifacts introduced by the postprocessing (double JPEG compressions) in CASIA. Patchara et al. <ref type="bibr" target="#b19">[20]</ref> rectified the CASIA data set and the experimental results showed that the detection rate of the causal Markov model-based features was reduced to 78% on the rectified data set. Pevný et al. <ref type="bibr" target="#b20">[21]</ref> proposed subtractive pixel adjacency matrix (SPAM)-based features for steganalysis; they model SPAM as a Markov process and the second-order Markov transition probability matrices along different directions (i.e., →, ←, ↓, ↑, , , , ) are treated as features for SVM prediction. Kirchner and Fridrich <ref type="bibr" target="#b21">[22]</ref> extended the SPAM features to detect median filtering of JPEG compressed images, and experimental results proved that SPAM can be treated as a generalpurpose detector for image-tampering detection. Recently, He et al. <ref type="bibr" target="#b22">[23]</ref> introduced the causal Markov model to both Discrete Cosine Transformation (DCT) and DWT domains and detected the image splicing by the cross-domain Markov features.</p><p>Among all the statistical features for image-splicing detection, the Markov-based features <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b16">[17]</ref>- <ref type="bibr" target="#b22">[23]</ref> have been demonstrated to be one of the most effective features. The traditional approaches based on the Markov model usually treated the image as 1-D signal and captured the dependency between current node and its previous node along certain direction. However, as an image is a 2-D signal in nature, each element in an image is usually related with its surrounding neighbors in all directions. The simplified Markov model used in the traditional approaches may not depict the image characteristics sufficiently. To solve this problem, a noncausal Markov model has been proposed in this paper which treats the image as a 2-D signal and the dependencies between the current node and its neighbors in all directions are considered. Because there is no analytic solution to the 2-D noncausal model, we split the noncausal model into several 2-D causal models and analyze these models sequentially to approximate the 2-D noncausal model. The 2-D causal submodels can be depicted by the state transition probability matrix, probability density function of each state, and the prior probability of each state. The transition probability matrix depicts the statistical dependency characteristics among neighboring nodes in the model. The probability density function describes the distribution of the observations of each state. The prior probability calculates the frequency of occurrences of each state. Because the proposed feature vector is usually of high dimensionality, SVM is employed as the classifier to overcome the possible overfitting problem. The experimental results demonstrate that the proposed 2-D noncausal Markov model could effectively differentiate the spliced images from the authentic ones over the public data set <ref type="bibr" target="#b23">[24]</ref> and the detection rates of proposed features outperforms the state-of-the-art approaches.</p><p>The rest of this paper is organized as follows. The proposed 2-D noncausal Markov model and its solution are introduced in Section II. Image-splicing detection using the proposed 2-D noncausal Markov model is described in Section III. Section IV presents the experimental results of the proposed approach compared with those of several state-of-the-art methods. Discussions on these experimental results are also given in this section. Finally, Section V draws the conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. 2-D NONCAUSAL MARKOV MODEL AND ITS SOLUTION</head><p>The classical 1-D Markov model depicts the state dependences in the 1-D sense along certain direction which is shown in Fig. <ref type="figure" target="#fig_0">1</ref>. It is observed from the figure that the current state (denoted by the black filled circle) is only dependent on its previous state (denoted by the gray filled circle). However, image is a 2-D signal in natural and each state in an image is affected by its surrounding states (nodes). Generalization of the classical 1-D Markov model to represent the state dependencies from surrounding neighbors in all directions leads to a generalized 2-D noncausal model <ref type="bibr" target="#b24">[25]</ref> as shown in Fig. <ref type="figure">2(a)</ref>. Although the generalized noncausal model could depict as much underlying information as possible, it is computationally infeasible. In this paper, we simplify the generalized noncausal model to reduce the computational complexity and only consider the nearest four neighbors' noncausal dependencies, which deduces a 2-D noncausal Markov model as shown in Fig. <ref type="figure">2</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(b).</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. 2-D Noncausal Markov Model</head><p>Ma et al. <ref type="bibr" target="#b25">[26]</ref> gives the definition of a noncausal multidimensional hidden Markov model.</p><p>1) There are two layers of random variable sets, that is, the hidden states S = {S(i, j ), i = 1 : M, j = 1 : N} and corresponding observations O = {O(i, j ), i = 1 : M, j = 1 : N}. The hidden state variable nodes S(i, j ) lay on a 2-D grid where the relative positions of nodes reflex spatial dependencies between them. The hidden states are not observable, but can only be observed through the observations. 2) For each state node S(i, j ), its conditional distribution is determined by a set of neighboring nodes that affects it, that is,</p><formula xml:id="formula_0">P(S(i, j )|S(m, n) ∈ S, (m, n) = (i, j )) = P(S(i, j )|S(m, n) ∈ N, (m, n) = (i, j ))</formula><p>, where in this equation, N ⊂ S is a set of neighboring nodes of node S(i, j ). In this paper, we propose a 2-D hidden noncausal Markov model which follows the above definitions correspondingly, and it consists of three parts.</p><p>1</p><formula xml:id="formula_1">) Let S = {s(i, j )|1 ≤ i ≤ I, 1 ≤ j ≤ J } and O = {o(i, j )|1 ≤ i ≤ I, 1 ≤ j ≤ J }</formula><p>be the state set and the observation set, respectively, where i and j are the spatial coordinates, and I and J are the number of rows and columns in the image. Each observation o(i, j ) corresponds to the state s(i, j ). Observations in the image can be defined according to the practical issues, for example, BDCT coefficient difference array <ref type="bibr" target="#b14">[15]</ref>, DWT coefficient array <ref type="bibr" target="#b22">[23]</ref> or pixel intensity difference array <ref type="bibr" target="#b15">[16]</ref>, and so forth. 2) Let P(s(i, j )|N(s(i, j ))) be the state dependence in the image, where N(s(i, j )) is the set of neighboring states that will affect the current state, that is, s(i, j ). For a noncausal model, N(s(i, j )) consists of the neighboring states from all the directions as shown in Fig. <ref type="figure">2(a)</ref>. Generally speaking, the generalized noncausal model is computationally infeasible; therefore, the markovian process (i.e., the current state only depends on its nearest states) is introduced to reduce the computational complexity. The structure of 2-D noncausal Markov model proposed is shown in Fig. <ref type="figure">2(b</ref>). In the model, the current state (black filled circle) is affected by its four nearest neighbors (gray filled circles), and the mutual dependences between neighboring nodes are depicted by the double-headed arrows. Specifically, when considering four directional neighbors, the state dependence can be formulated as</p><formula xml:id="formula_2">P(s(i, j )|N(s(i, j ))) = P(s(i, j )|s(i -1, j ), s(i, j -1), s(i, j + 1), s(i + 1, j )). (1)</formula><p>3) Let Q be the total number of states and thus s(i, j ) ∈ {1, 2, . . . , Q}. The distribution of o(i, j ) corresponding to state s(i, j ) is formulated as f (o(i, j )|s(i, j )). If the state set S is unknown, the model would evolve to be a 2-D noncausal hidden Markov <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref> model which is computationally expensive. To simplify the problem, we separate the state set into 2q + 1 levels (2q + 1 = Q) according to the distribution of observations. An example is shown in Fig. <ref type="figure" target="#fig_2">3</ref> which gives the distributions of BDCT coefficient difference arrays (horizontal direction and vertical direction) over the data set in <ref type="bibr" target="#b23">[24]</ref>. The observations are separated into 2q + 1 (q = 5 in Fig. <ref type="figure" target="#fig_2">3</ref>) levels and for a random observation o(i, j ) s(i, j ) = s if {s -0.5 &lt; o(i, j ) &lt; s + 0.5|s ∈ {-q, -q + 1, . . . , q -1, q}}.</p><p>(2)</p><formula xml:id="formula_3">f (o(i, j )|s(i, j ) = s) ( f s (o(i, j )) in short)</formula><p>is the probability density function of state s and the formulation of f s (o(i, j )) usually varies according to various applications. The fundamental three parts in the proposed model satisfy the definitions of the noncausal multidimensional (in 2-D sense) hidden Markov model given in <ref type="bibr" target="#b25">[26]</ref>. Two layers, that is, the hidden state set S and the observation set O, are adopted in our model. The state set S lies on the 2-D grid and the relative positions of its nodes reflects the spatial dependencies between them. Hence, our model is in 2-D sense and the preceding definition (1) is satisfied. The state dependencies in our model are given as (1) where N(s(i, j )) is the set of nearest neighboring states of current state s(i, j ). Hence, our model is noncausal and definition (2) given previously is satisfied.</p><p>Although our model is designed according to the definitions of multidimensional noncausal Markov model given in <ref type="bibr" target="#b25">[26]</ref>, there are mainly two differences between these two models, which makes the proposed model more suitable for imagesplicing detection.</p><p>1) Ma et al. <ref type="bibr" target="#b25">[26]</ref> proposed a block-based noncausal Markov model for image segmentation. They split an input image into several nonoverlapping small blocks with the same sizes, and each block corresponds to a state. Although the block-based noncausal Markov model has been proved to be an effective tool for image content-based classification (which mainly focus on the low-frequency information <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>), directly applying it to imagesplicing detection (which tries to expose the splicing artifacts from the high-frequency information <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b14">[15]</ref>) is not appropriate. For the block-based model, the highfrequency coefficients in a block tend to be overwhelmed by the low-frequency coefficients, which would lead to performance degradation for splicing detection. In this paper, we apply the 2-D noncausal Markov model on the transformed domains (which would be introduced in Section III), and each coefficient in the 2-D array corresponds to an observation (state). Hence, the splicing artifacts reflected by the high-frequency coefficients could be captured by this elementwise 2-D noncausal Markov model. 2) The second difference is the way how to establish the state sequence. In <ref type="bibr" target="#b25">[26]</ref>, an iterative algorithm based on a general forward-backward (GFB) algorithm was proposed to estimate the state sequence. For a state sequence with length w(u), the GFB algorithm needs to calculate M w(u) (M is the number of states) possible subset-state sequences. GFB algorithm is computationally infeasible for the elementwise 2-D noncausal Markov model, because the length w(u) of the state sequence is too long to handle. To avoid the M w(u) order of magnitudes calculations involved in the GFB algorithm, we adopt the rule of (2) in the manuscript to estimate the state sequences and simplify the calculation. Therefore, the proposed model could capture the noncausal statistical characteristics in an efficient manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Solution to 2-D Noncausal Markov Model</head><p>Because there is no analytic approach to the noncausal Markov model, we would have to reformulate and simplify the problem first. Inspired by <ref type="bibr" target="#b25">[26]</ref>, we first divide the noncausal Markov model into several causal 2-D Markov models which are analytically solvable, then solve these causal submodels simultaneously to obtain a feasible solution to the noncausal Markov model. The 2-D noncausal Markov model shown in Fig. <ref type="figure">2(b</ref>) can be split into a series of causal submodels by the following steps as shown in Fig. <ref type="figure" target="#fig_3">4</ref>.</p><p>1) Input the observation 2-D array, get the noncausal state dependency topology and identify the noncausal state dependencies which are denoted by double-headed arrows. 2) Each noncausal dependency between neighboring states along certain direction (e.g., horizontal, vertical) is decomposed into a couple of causal dependencies (i.e., {→, ←}, {↑, ↓}) while preserving dependencies from other directions unchanged. 3) Repeat step 2) until all the noncausal state dependences (double-headed arrows) are replaced by causal state dependences (single-headed arrows). Finally, we can get the causal state-dependency graphs. For an arbitrary noncausal model, the number of decomposed causal models is 2 M where M is the number of bidirectional state dependencies in the model. In this paper, only the state dependencies along vertical and horizontal directions are considered, and thus the 2-D noncausal Markov model is decomposed into four causal submodels (the decomposition procedure is shown in Fig. <ref type="figure" target="#fig_3">4</ref>). In the decomposition procedure, the state dependencies information is well preserved. Furthermore, each causal model keeps the state dependencies along certain direction and all the submodels are correlated with each other. Therefore, the framework is not simply a collection of uncorrelated causal models but a precise representation of the original 2-D noncausal model.</p><p>After decomposing the noncausal Markov structure into four causal submodels, we solve each submodel, respectively, and obtain the submodel parameters. The 2-D causal Markov submodel is formulated by the following three fundamental parts, which can be denoted as {π, A, B}.</p><p>1) π is the initial probability vector for all the states, that is, π = {π 1 , π 2 , . . . , π Q }, where</p><formula xml:id="formula_4">π s = P(s(i, j ) = s), 1 ≤ i ≤ I, 1 ≤ j ≤ J, s ∈ {1, 2, . . . , Q}.</formula><p>2) A is the transition probability matrix, which is formulated as where a k uvw is the transition probability from the previous state set (v, w) to the current state u in the kth causal model</p><formula xml:id="formula_5">A = a k uvw |u, v, w ∈ {1, 2, . . . , Q}, k ∈ {1, 2, 3, 4}</formula><formula xml:id="formula_6">a k uvw = P(s(i, j ) = u|N k (s(i, j )) = (v, w)) = i j δ(s(i, j ) = u, N k (s(i, j )) = (v, w)) i j δ(N k (s(i, j )) = (v, w))<label>(3)</label></formula><p>where δ(•) is the delta function (1 for truth and 0 for false), N k (s(i, j )) is an ordered set of nearest neighbors of s(i, j ) in the kth causal model and is given as</p><formula xml:id="formula_7">N k (s(i, j )) = ⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩ (s(i + 1, j ), s(i, j -1)), k = 1 (s(i -1, j ), s(i, j -1)), k = 2 (s(i + 1, j ), s(i, j + 1)), k = 3 (s(i -1, j ), s(i, j + 1)), k = 4.<label>(4)</label></formula><p>From ( <ref type="formula" target="#formula_6">3</ref>) and (4), it can be observed that a k uvw ≥ 0 and Q u=1 a k uvw = 1. Different from that for 1-D signals, the transition probability for 2-D signals is a third-order statistics that reflects the state dependencies between the current state and the two neighboring states. Hence, the dimension of transition probability matrix of each causal submodel is Q 3 . 3) B is the parameter set for the probability density function f s (o(i, j )). The formulation of the probability density function usually depends on the distribution of the observations and the underlying data structure.</p><p>In our application of image-splicing detection, to remove the influence caused by image contents, the differences between adjacent pixels or nodes in spatial and frequency domain are usually adopted as observations. As shown in Fig. <ref type="figure" target="#fig_2">3</ref>, the distributions of the observations usually have an impulse-like shape, and thus a mixture model is applied to f s (o(i, j )) and the formulation of f s (o(i, j )) is given as</p><formula xml:id="formula_8">f s (o(i, j )) = ⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩ L l=1 P l s e - (o(i, j )-μ l ) 2 2σ 2 l , s = 0 L l=1 P l s λ l s e -λ l s (o(i, j )-s+0.5) , s = 0 (<label>5</label></formula><formula xml:id="formula_9">)</formula><p>where P l s ( L l=1 P l s = 1, P l s ≥ 0) is the prior probability (or weighting) of the lth component for state s, μ l and σ l are, respectively, the mean and standard deviation of the lth Gaussian mixture, and λ l s is the parameter of the lth component exponential function for state s. f s (o(i, j )) is modeled as L-component Gaussian mixture model for state 0 and L-component exponential mixture model for state s = 0 according to the distribution shown in Fig. <ref type="figure" target="#fig_2">3</ref>. Therefore, the parameter set B is composed of all the parameters of the two kinds of mixture models and is given as</p><formula xml:id="formula_10">B = P l s , μ l , σ l , λ l s s ∈ {-q, -q + 1, . . . , q -1, q}, l ∈ {1, 2, . . . , L} .</formula><p>All the parameters in B can be obtained via an EM algorithm <ref type="bibr" target="#b26">[27]</ref>. The EM algorithm tries to maximize the expectation of the log-likelihood function iteratively which is determined by the observations and the current estimates of parameters. Assuming the observations are mutually independent, the log-likelihood function can be expressed as </p><formula xml:id="formula_11">L(θ s ) = i j ln f s (o(i, j )|l; θ s )P l s × δ(s -0.5 &lt; o(i, j ) &lt; s + 0.5) = i j ln f s (o(i , j )|l; θ s )P l s where (i , j ) = {(i, j )|s -0.5 &lt; o(i, j ) &lt; s + 0.5},</formula><formula xml:id="formula_12">E(L(θ s )) = E ⎛ ⎝ i j ln f s (o(i , j )|l; θ s )P l s ⎞ ⎠ = i j L l P(l|o(i , j ); s ) × ln f s (o(i , j )|l; θ s )P l s .</formula><p>2) M-Step: Maximize the log-likelihood with respect to θ s and P l s and update the parameter set for the (t + 1)th iteration by ( <ref type="formula">6</ref>)- <ref type="bibr" target="#b8">(9)</ref>. Note that</p><formula xml:id="formula_13">θ s = {μ l , σ l |l ∈ {1, 2, . . . , L}} if s = 0, else θ s = {λ l s | l ∈ {1, 2, . . . , L}} μ l s (t + 1) = i j P(l|o(i , j ); s (t))o(i , j ) i j P(l|o(i , j ); s (t)) (6) σ l s (t + 1) = i j P(l|o(i , j ); s (t))||o(i , j ) -μ l s (t + 1)|| 2 i j P(l|o(i , j ); s (t)) (7) λ l s (t + 1) = i j P(l|o(i , j ); s (t)) i j P(l|o(i , j ); s (t))(o(i , j ) -s + 0.5)<label>(8)</label></formula><formula xml:id="formula_14">P l s (t + 1) = 1 I × J i j P(l|o(i , j ); s (t)) (9)</formula><p>where I and J are the maximum values of i and j , P(l|o(i , j ); s (t)) is a posterior probability and it can be derived by</p><formula xml:id="formula_15">P(l|o(i , j ); s t) = f s (o(i , j )|l; θ s (t))P l s (t) L l=1 f s (o(i , j )|l; θ s (t))P l s (t)</formula><p>.</p><p>The EM algorithm starts with a preset initial value and terminates when the estimation error is less than a preset small value.</p><p>In </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Feature Extraction</head><p>As we known, image splicing would introduce specific statistical artifacts in BDCT domain <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b19">[20]</ref> and DWT domain <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b22">[23]</ref>. In this paper, to verify the effectiveness and generalization ability of the proposed model, we model the adjacent coefficient difference array in the above two different domains as observations for the 2-D noncausal Markov model.</p><p>1) BDCT Domain Features: DCT presents good information-packing properties and in image processing, most image content-related information is usually contained in a few low-frequency DCT coefficients. Neglecting these low-frequency coefficients could put emphasis on some content-irrelevant traces caused by image tampering. For most of the spliced images, the region containing tampering traces is usually much smaller than the whole image. Hence, the block DCT transform, which focuses more on the local information, is adopted in image-splicing detection. In our paper, the block size of the BDCT transform is set to r × r (r = 2, 4, 8, 16) empirically which is sensitive to the splicing operation <ref type="bibr" target="#b14">[15]</ref>. The dependences among intrablock BDCT coefficients <ref type="bibr" target="#b14">[15]</ref> and interblock BDCT coefficients <ref type="bibr" target="#b22">[23]</ref> are employed by the proposed model. For a r × r BDCT transform, the entire image is divided into a number of nonoverlapping r × r blocks and the BDCT array denoted as D can be represented as</p><formula xml:id="formula_16">D = ⎡ ⎢ ⎢ ⎢ ⎣ D 1,1 D 1,2 . . . D 1,N D 2,1 D 2,2 . . . D 2,N . . . . . . . . . . . . D M,1 D M,2 . . . D M,N ⎤ ⎥ ⎥ ⎥ ⎦ where D m,n (1 ≤ m ≤ M, 1 ≤ n ≤ N) is a r × r</formula><p>DCT coefficient array. After the BDCT coefficients array has been computed, we can get four observation sets for the 2-D noncausal Markov model by</p><formula xml:id="formula_17">O h x = |D| ⊗ h x , O v x = |D| ⊗ h T x (<label>10</label></formula><formula xml:id="formula_18">)</formula><p>where subscript x ∈ {intra, inter}, | • | is an elementwise absolute value operator and ⊗ is the convolution operation.</p><formula xml:id="formula_19">h intra = [-1, 1]</formula><p>T and h inter = [-1, 0, 0, 0, 0, 0, 0, 0, 1] T are the filters for |D|. O h intra and O v intra are the intrablock adjacent difference arrays along horizontal and vertical directions; O h inter and O v inter are the interblock adjacent difference arrays along horizontal and vertical directions. O h intra and O v intra could capture the correlations in the intrablock coefficients, while the correlations caused by the r ×r blocking artifacts are ignored. Hence, we also consider the correlations between adjacent blocks, that is, O h inter and O v inter . Coefficients in the intrablock and interblock adjacent difference arrays (both horizontal and vertical) are treated as the observations and the relationship between the state and the observations can be formulated as</p><formula xml:id="formula_20">S h x = S h x (i, j ) = s|s -0.5 &lt; O h x (i, j ) &lt; s + 0.5, 1 ≤ i ≤ I, 1 ≤ j ≤ J S v x = S v x (i, j ) = s|s -0.5 &lt; O v x (i, j ) &lt; s + 0.5, 1 ≤ i ≤ I, 1 ≤ j ≤ J . (<label>11</label></formula><formula xml:id="formula_21">)</formula><p>After we get the observation sets and the corresponding state sets, the 2-D noncausal Markov model in BDCT domain with the structure shown in Fig. <ref type="figure">2</ref>(b) can be established, and it can be decomposed into four causal submodels as shown in Fig. <ref type="figure" target="#fig_3">4</ref>. Finally, we can solve the causal models sequentially and the parameters of each submodels, that is, {π, A i , B|1 ≤ i ≤ 4}, are extracted as discriminative features for classification. As we get four observation sets, there are total 4 × 4 causal submodels and the dimensionality of proposed features is</p><formula xml:id="formula_22">4 4Q 3 + 2(Q -1)L + 3L + Q = 16Q 3 + 8QL + 4L + 4Q</formula><p>where Q is the number of states and L is the number of components in the mixture model.</p><p>2) DWT Domain Features: Discrete wavelet decomposition has been proved as a useful tool for image-tampering detection in the past few years <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b22">[23]</ref>. He et al. <ref type="bibr" target="#b22">[23]</ref> introduced three-level DMWT for splicing detection and the dependencies of DMWT coefficients across positions, levels, and orientations were modeled as 82 traditional Markov transition probability matrices for classification. Image splicing would introduce abrupt changes in an image, which can be reflected by the high-frequency wavelet subbands (detail coefficients array) <ref type="bibr" target="#b6">[7]</ref>. According to <ref type="bibr" target="#b6">[7]</ref> and <ref type="bibr" target="#b22">[23]</ref>, we only apply one-level DMWT on the source images and the detail coefficient arrays at three orientations, that is, horizontal CH 1 , vertical CV 1 , and diagonal CD 1 are treated as the observation arrays for the proposed noncausal Markov model. CH 1 , CV 1 , and CD 1 could capture the abrupt changes in different directions which is suitable for detecting splicing signal in the background of image contents <ref type="bibr" target="#b15">[16]</ref>. Multilevel wavelet decomposition would introduce more information for classification; however, it also introduce excessive redundant information which could probably confuse the classifier and degrade the detection performance. In Section IV, we will analyze the impact of decomposition levels of DMWT on the image-splicing detection performance.</p><p>An illustration for DMWT is shown in Fig. <ref type="figure" target="#fig_5">5</ref>. An image in which the teddy bear is the spliced part is shown in the left part of Fig. <ref type="figure" target="#fig_5">5</ref> and its DMWT subbands, that is, CA 1 , CH 1 , CV 1 and CD 1 , are given in the right part. We crop the teddy bear from an authentic image and paste it into a background image by Photoshop CS5 without postprocessing. Note that since the coefficients in the high-frequency subbands are small, we linearly map these high-frequency coefficients to the range of [0, 255] to increase image contrast for better visual effect. It can be observed from Fig. <ref type="figure" target="#fig_5">5</ref> that much of the image background is removed in the high-frequency subbands, and the spliced details are emphasized. Image-splicing detection can be deemed as detecting weak signal (splicing artifacts) in the background of strong noise (image contents) <ref type="bibr" target="#b15">[16]</ref>, therefore, compared with the approximation array CA 1 , the </p><formula xml:id="formula_23">S h subband = S h subband (i, j ) = s|s -0.5 &lt; O h subband (i, j )&lt; s +0.5, 1 ≤ i ≤ I, 1 ≤ j ≤ J S v subband = S v subband (i, j ) = s|s -0.5 &lt; O v subband (i, j )&lt; s +0.5, 1 ≤ i ≤ I, 1 ≤ j ≤ J . (<label>13</label></formula><formula xml:id="formula_24">)</formula><p>Finally, we can establish the 2-D noncausal Markov model by the method given in Section II-A and get the model parameters (i.e., discriminative features) by the solution scheme introduced in Section II-B. As six observation sets are obtained, there are 24 causal submodels in total and the dimensionality of the proposed features is</p><formula xml:id="formula_25">6 4Q 3 +2(Q -1)L + 3L + Q = 24Q 3 + 12QL + 6L +6Q.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Classification and Framework of the Proposed Method</head><p>In our approach, the image-splicing detection is treated as a binary classification problem, that is, the extracted feature vector is fed into a classifier to predict whether it is spliced or not. Hence, the selection of classifier is important and a properly chosen classifier would greatly improve the detection accuracy. In this paper, SVM <ref type="bibr" target="#b27">[28]</ref> is adopted to evaluate the effectiveness of the proposed features for its robustness to overfitting problem. LIBSVM <ref type="bibr" target="#b28">[29]</ref> which is a library for SVM is used in our classification work and the radial basis function is selected as the kernel of SVM. Because SVM is a supervised machine learning method, we randomly split the entire feature set extracted into two sets: one for training and the other for testing. The training set is employed to find the optimal hyperplane for classification, and the testing set is used to test the effectiveness of the proposed features.</p><p>To handle high-dimensional features and reduce the time complexity, we introduce a distributed scheme to solve the proposed model synchronously. Two clients with six CPU cores are involved in the distributed scheme. A distributed scheme is adopted which can process all the submodels synchronously and reduce the processing time greatly in feature extraction, SVM training, and prediction. Details are given as follows. First, the causal Markov submodels are distributed to different clients (or CPU cores), so the features (or submodel parameters) could be extracted simultaneously. Second, we also conduct SVM parameter selection [i.e., (C, g) selection] on the distributed 2-D grid, that is split the (C, g) 2-D grid into several small 2-D grids which are then distributed to different CPU cores, and all the cores run the parameter-selection algorithm on their small grid synchronously. Third, the distributed scheme has also been introduced in the classifier predictions, since many rounds of experiments are involved to get the average detection accuracy, distributed predictions would greatly reduce the time cost. The detection framework of proposed method is shown in Fig. <ref type="figure" target="#fig_6">6</ref>, and the details are given as follows.</p><p>1) For a given image, transform it to the BDCT domain and DMWT domain, respectively. 2) Get the observation arrays and state arrays via <ref type="bibr" target="#b9">(10)</ref>, ( <ref type="formula" target="#formula_20">11</ref>), <ref type="bibr" target="#b11">(12)</ref>, and ( <ref type="formula" target="#formula_23">13</ref>). Construct 2-D noncausal Markov models for these arrays using the method described in Section II-A. Fig. <ref type="figure">7</ref>. Some example images in the DVMM data set <ref type="bibr" target="#b23">[24]</ref>.</p><p>3) Split the noncausal model into four causal submodels by the method proposed in Section II-B, distribute these submodels to the clients, one to each core by the scheduler. 4) Extract the parameter set {π, A, B} according to the method proposed in Section II-B synchronously on each core, and update the feature vector according to the output of each submodel. 5) Repeat the procedure 1)-4) to get all the feature vectors in the image data set and group all of them into a feature set. 6) Randomly split the feature set into training and testing set proportionally (e.g., 5/6 for training and 1/6 for testing). 7) Conduct SVM parameter selection (i.e., (C, g) selection <ref type="bibr" target="#b29">[30]</ref>) on the distributed 2-D grid. That is split the (C, g) 2-D grid into several small 2-D grids which are then distributed to different cores. All the cores run the parameter-selection algorithm on their small grid synchronously, and optimal parameters can be derived by comparing the suboptimal parameters on all the small grid. 8) Input the optimal parameter set (C, g) into SVM, and get the optimal hyperplane of training samples by the training algorithm. 9) Fed feature vectors in the testing set into the trained SVM in 8) and thus the detection accuracy can be obtained. 10) Repeat the steps 6) and 9) several times (e.g., <ref type="bibr" target="#b29">30)</ref> and employ the average detection accuracy to evaluate the effectiveness of the extracted feature to reduce the detection performance turbance caused by the various selections of the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL RESULTS AND ANALYSIS</head><p>In this section, we first introduce the image-spicing evaluation data set used in the experiments. Then performance evaluation of the proposed model with different parameter settings is provided. After that, we give the performance comparisons with several state-of-the-art splicing detection approaches. Finally, some real-image forgeries are introduced to testify the effectiveness of the proposed scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Image Data Set for Investigation</head><p>The Columbia Image-Splicing Detection Evaluation Data Set (DVMM) <ref type="bibr" target="#b23">[24]</ref> is adopted in our experiments. DVMM consists of 933 authentic images and 912 spliced images and it covers a variety of contents (e.g., smooth, textured, arbitrary object boundary and straight boundary, and so on). All the images in the data set are in BMP format with size of 128 × 128. The image is kept at a reasonable size (128 × 128) to ensure that sufficient statistical features can be estimated in each block. The spliced images are created from the authentic ones in the data set by crop-and-paste along object boundaries or crop-and-paste of horizontal (or vertical) strips. Some example images are shown in Fig. <ref type="figure">7</ref> where the authentic images are given in the first row and the spliced images are shown in the second row.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Detection Results and Discussions</head><p>We conduct our experiments over the DVMM data set according to the method proposed in Sections II and III. In the classification phase, to reduce the variations caused by different selections of the training samples, 30 random tests have been performed and the mean and standard deviations of the classification results are recorded. In each of the 30 runs, 5/6 authentic images and 5/6 spliced images are randomly selected to find the optimal (C, g) for SVM and to train the SVM. The rest images are used to test the detection results. The detection performance is measured by the following two criterions: 1) the true positive (TP) rate, true negative (TN) rate, and total accuracy (Accuracy) and 2) the value of the area under ROC curve (AUC) <ref type="bibr" target="#b30">[31]</ref>.</p><p>1) Detection Performance by the Proposed Method: We first investigate the impact of the decomposition level of DMWT on the performance of image-splicing detection. Table <ref type="table" target="#tab_1">I</ref> presents the detection accuracies of different subbands (subbands combinations) over image data set <ref type="bibr" target="#b23">[24]</ref>, where the subscript i denotes the level of the DMWT decomposition, standard deviations over 30 random test are given in the brackets. For fairness purpose, we set Q = 7 for all the subbands. It can be observed from Table <ref type="table" target="#tab_1">I</ref> that the first-level high-frequency subbands combination (i.e., CH 1 + CV 1 + CD 1 ) achieves the highest detection accuracy compared with other subbands or subbands combinations.  <ref type="bibr" target="#b23">[24]</ref> It is noted that the multilevel subbands combinations [i.e., 2 i=1 (CH i + CV i + CD i ) and 3 i=1 (CH i + CV i + CD i )] could not improve the detection accuracy, and the excessive redundant features involved would even degrade the detection performance. This experiment can be deemed as an evidence to support our claim in Section III-A2). In the following experiments, we only use CH 1 , CH 1 , and CD 1 for wavelet domain feature extraction.</p><p>The impact of block size r in BDCT on the detection performance is shown in Table <ref type="table" target="#tab_2">II</ref>, where Expanded BDCT is the features extracted from the observation arrays defined in <ref type="bibr" target="#b9">(10)</ref>, DMWT is the features extracted from the observation arrays defined in <ref type="bibr" target="#b11">(12)</ref>, and Expanded BDCT + DMWT is the combined features. For fairness purpose, we set Q = 7 for all the block sizes in BDCT. It can be observed in Table <ref type="table" target="#tab_2">II</ref> that with the increase of r the detection performance first increases then drops dramatically, and the 8×8 BDCT achieves the best detecting performance among all the block sizes. Hence, the choice of block size in the multisize BDCT is important for the detection work, and in the following experiments we set r = 8 for comparisons.</p><p>The detection performance of the proposed 2-D noncausal Markov model-based features with different number of states is presented in Table <ref type="table" target="#tab_3">III</ref>, and the averaged ROC curves and the corresponding AUCs are shown in Fig. <ref type="figure" target="#fig_7">8</ref>. It can be observed from Table <ref type="table" target="#tab_3">III</ref> and Fig. <ref type="figure" target="#fig_7">8</ref> as follows.</p><p>1) When the number of states increases, the detection performance first increases then converges rapidly and Q = 7 is observed to be a good selection which can provide almost the highest classification accuracy while the computational cost is also acceptable. 2) Both features in the expanded BDCT domain and DMWT domain contain discriminative information for splicing detection and the features in the expanded BDCT domain outperforms those in DMWT domain.</p><p>3) The combined features (or cross domain features) outperforms features in either domain which indicates that the features extracted from the two different domains compensate for each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Comparisons With Other Detection Approaches:</head><p>To comprehensively evaluate the proposed method, three stateof-the-art image-splicing/tampering detection methods, that is, Shi et al. <ref type="bibr" target="#b14">[15]</ref>, He et al. <ref type="bibr" target="#b22">[23]</ref>, and SPAM <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, are introduced in our experimental work for comparisons. SPAM with 686 features is a spatial approach which has achieved promising detection capability in image steganalysis and median filtering detection during the past few years. We introduce the SPAM method for experimental comparisons is based on <ref type="bibr" target="#b9">[10]</ref> which claims that a natural image model based on a set of carefully selected statistical features under the machine learning framework can be used for both steganalysis and splicing detection, and lessons learnt from steganalysis can be applied to splicing detection to boost the detection performance. To guarantee a fair comparison, we also apply the SPAM method in both BDCT domain and DMWT domain, and detection results of the cross domain features with dimensionality 2744 are presented. All the detection methods are conducted over data set <ref type="bibr" target="#b23">[24]</ref> using the classification scheme   <ref type="table" target="#tab_1">IV</ref>, our proposed method (Q = 7, r = 8) achieves a detection accuracy as high as 93.36%. Compared with the other three detection methods, the proposed features can achieve at least 2.2% higher average detection accuracy. The dimensionality of our features is 14 240 (Q = 7, r = 8), which is higher than the other three detection methods. However, we boost the image-splicing detection rate over 2.2% compared with the state-of-the-art (to our best knowledge) at the cost of higher feature dimensionality.</p><p>To comprehensively evaluate the performance of proposed model, we introduce time cost as another indicator  <ref type="bibr" target="#b14">[15]</ref>, He et al. <ref type="bibr" target="#b22">[23]</ref>, SPAM <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, and the proposed features with state number Q = 7 on the same client (Client I) with Intel(R) Core (TM) i7-2600 CPU 3.40 GHz, and the comparison results are presented in Table <ref type="table">V</ref>. It can be observed in Table V that: 1) Shi <ref type="bibr" target="#b14">[15]</ref> is the fastest detection method with the average detection accuracy 90.15% and 2) the proposed method achieves the highest detection accuracy at the cost of the highest time complexity. The dimensionality of the proposed features with Q = 7 is 14 240 which is higher than that of the other three methods, and the higher dimensionality inevitably increases the time cost of the detection work.</p><p>Then, to verify the effectiveness of the high-dimensional feature-processing scheme introduced in Section III-B, we also calculated the time cost of the proposed features on a distributed system which is composed of Client I and Client II with Intel(R) Duo E7500 CPU 2.93 GHz. The time cost of the distributed noncausal Markov model are listed as follows: Fea. time: 1060.9 s, (C, g) time: 1695.8 s, Pred. time: 388.4 s, and Total time 3145.1 s. Therefore, the high-dimensional feature-processing scheme proposed in Section III-B could dramatically reduce the time cost of the proposed method, and make the proposed high-dimensional features manageable. Because our approach splits a 2-D noncausal model into several causal submodels, it is naturally suitable for the distributed computing. All these submodels are allocated to different CPU cores, and all these cores run the feature extraction algorithm simultaneously, so the distributed scheme could reduce the time cost greatly. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Robustness Test</head><p>In this section, JPEG compression and median filtering operations are applied on the DVMM data set to test the robustness of the proposed splicing detection method. The JPEG compression level can be measured by the quality factor which is a positive integer in the range <ref type="bibr" target="#b0">[1,</ref><ref type="bibr">100]</ref>. Larger quality factors mean high quality (i.e., less compression) and vice versa. For median filtering, two sizes of filters, that is, 3 × 3 and 5 × 5 are used on the data set. After we get the post processed image data set, we conduct experiments according to the procedure shown in Fig. <ref type="figure" target="#fig_6">6</ref>. The detection accuracies of the four detection methods are shown in Fig. <ref type="figure" target="#fig_9">10</ref>. It can be seen Fig. <ref type="figure" target="#fig_9">10</ref>(a) that when the quality factor decreases, the detection accuracies of all the methods decrease. The proposed method with different compression rates always outperforms the other three methods, especially when the quality factors are high. Median filtering also has a negative effect on the detection performance and as it can be seen in Fig. <ref type="figure" target="#fig_11">10(b</ref>), the detection accuracies of the proposed method are still higher than that of the other methods.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Splicing Detection on Real-Image Forgeries</head><p>To demonstrate the effectiveness of the proposed approach in image forgery detection, we have also generated many image forgeries by the splicing operations for evaluation. The source images are from Columbia Uncompressed Image-Splicing Detection Evaluation Data Set <ref type="bibr" target="#b31">[32]</ref> and Uncompressed Color Image Database <ref type="bibr" target="#b32">[33]</ref>. We create image forgeries by crop one part of an image and paste it on another image. To eliminate the influence of double JPEG compression and to concentrate on the detection of splicing manipulations, all the source images are uncompressed images with TIFF format, and the image forgeries are also saved as uncompressed TIFF format. For real-image forgery detection, we first train the SVM classifier by the image samples in DVMM data set <ref type="bibr" target="#b23">[24]</ref> according to the training framework described in Section III-B, then split the input image 128 × 128 nonoverlapping small blocks (since our SVM classifier is trained by 128 × 128 small images of DVMM data set <ref type="bibr" target="#b23">[24]</ref>, here we split the image into small blocks with the same size for detection), finally, detect the these small image blocks one by one to get the detection result. Details are given in Algorithm 1, in which G is an image input, φ is a trained SVM with fixed parameters, C is a vector to store the position information of manipulated blocks. If the sum of C equals to zero, the input image is authentic, else spliced. We can also get the exact spliced areas by C, because the image is scanned from top to bottom and left to right, there is a unique mapping between c and the spatial position of the image. Finally, all the spliced areas can be labeled according to the spatial locations provided by C. Fig. <ref type="figure" target="#fig_10">11</ref> shows detection results on some real-image forgeries and the spliced areas are highlighted as the indication of image forgeries.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. First IEEE Information Forensics and Security Technical Committee Image Forensics Challenge</head><p>The First IEEE Information Forensics and Security Technical Committee (IFS-TC) Image Forensics Challenge <ref type="bibr" target="#b33">[34]</ref> is an international competition organized by IFS-TC. IFS-TC published a data set to evaluate the current stateof-the-art techniques with respect to their ability to detect image forgeries. The images in the challenge are captured from different digital cameras with various scenes. All of these images are grouped into two categories: pristine and forged, and the forged images comprise a set of different manipulation techniques such as copy/pasting and splicing. All the pristine and fake images are divided into a training set (1500 images) and a testing set (5713 images). Training set is provided to train a detector (classifier), while the testing set is used to verify the effectiveness of the detector. Detection results of Shi et al. <ref type="bibr" target="#b14">[15]</ref>, He et al. <ref type="bibr" target="#b22">[23]</ref>, SPAM <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, and the proposed method on the testing set are shown in Table <ref type="table" target="#tab_5">VI</ref>, where score is a performance indicator that describes the results of classification (high score corresponds to good classification) <ref type="bibr" target="#b33">[34]</ref>, Pred. time is the predicting time on all the images of the testing set. It can be observed in Table VI that the proposed method get a score 0.901 which is higher than that of the other three methods at the cost of longer prediction time (58.5 s). Although the prediction time of the proposed approach is longer than other methods, the average prediction time is about 0.01 s (i.e., 58.5/5713). And the proposed scheme could detect images in real time. There are a few state-of-the-art algorithms in the IFS-TC challenge perform better than the proposed scheme, and further research would be conducted to improve the detection performance of our method.</p><p>V. CONCLUSION The Markov model has been proved to be one of the most effective tools for image-tampering detection and image steganalysis. To our best knowledge, almost all the imagetampering detection approaches based on the Markov models (in BDCT domain or DWT domain) treated the image as a 1-D causal signal. Hence, the traditional model only depicts the state dependencies between adjacent states along certain directions (e.g., horizontal, vertical). To take more information into consideration, a 2-D noncausal Markov model is proposed in this paper to better model the 2-D image and each state in the proposed model depends on its surrounding states simultaneously. Because there is no direct analytic solution to this model, we decompose the noncausal model into four 2-D causal submodels and solve these submodels sequentially. For each causal submodel, the current state depends on its nearest states in the 2-D sense (2-D dependency or Markovian property for 2-D signals). These causal submodels are described by the prior probabilities of each state, the parameters of probability density function of each state and the state transition probability matrix. All these model parameters are treated as discriminative features for classification. We apply our model in the BDCT domain and DMWT domain, and the model proved its generalization and effectiveness in the two different domains. Experimental results show that the proposed noncausal Markov model outperforms some state-of-the-art methods over two published image-splicing detection evaluation data sets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Classical 1-D Markov model used in image splicing. Circles: states. Squares: observations corresponding to the states. (a) Horizontal direction. (b) Vertical direction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 . 2 -</head><label>22</label><figDesc>Fig. 2. 2-D noncausal models. (a) Generalized noncausal model. (b) Proposed 2-D noncausal Markov model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Distributions of the BDCT coefficient difference arrays over data set [24]. (a) Horizontal difference array. (b) Vertical difference array.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Decomposition procedure of 2-D noncausal Markov model into four 2-D causal Markov submodels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>summary, we propose an image-splicing-detection specific 2-D noncausal Markov model. During the model optimization stage, the proposed noncausal Markov model is decomposed into four 2-D strictly causal submodels which have analytic solutions, and then these submodels are solved collaboratively to derive an approximate solution to the 2-D noncausal Markov model. The observations are conditionally memoryless and the state transition is first-order Markovian in 2-D sense. It should be noted that since each 2-D causal submodel keeps the state dependencies along certain 2-D direction and all the submodels are correlated with each other, the mutual dependencies of states in the noncausal model are well preserved. Hence, compared with the traditional 1-D Markov model, the proposed model contains much more information about the underlying image characteristics and could better detect image splicing. III. IMAGE-SPLICING DETECTION BY THE PROPOSED MODEL The proposed detection method consists of two parts: feature extraction and classification. The 2-D noncausal Markov model-based features are extracted from the source arrays, and then the extracted features are fed into SVM to determine whether the target image has been spliced or not.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. First-level discrete Meyer wavelet decomposition.</figDesc><graphic coords="7,110.39,58.25,171.86,135.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Framework of the proposed detection method.</figDesc><graphic coords="8,60.59,156.89,175.46,98.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>8 .</head><label>8</label><figDesc>ROC curves and the corresponding AUCs for expanded BDCT, DMWT, and expanded BDCT + DMWT. (a) Q = 3. (b) Q = 5. (c) Q = 7. (d) Q = 9. described in Section III-B to ensure the fairness and validity. The detection results are given in Table IV and the corresponding ROC curves are shown in Fig. 9. As shown in Table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. ROC curves and the corresponding AUCs for different detection methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Robustness comparisons. (a) JPEG compression test. (b) Median filtering test.</figDesc><graphic coords="13,150.83,259.85,153.26,113.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Detection results of some image forgeries.</figDesc><graphic coords="13,151.31,376.01,100.70,141.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Algorithm 1</head><label>1</label><figDesc>Real-Image Forgery Detection by the Proposed Method Input: Unknown image G; Trained SVM classifier φ; c := 1, C := 0 Output: Label array C 1: Input unknown image G, get its size [I, J ]; 2: Divide it into I 128 × J 128 nonoverlapping image blocks; 3: Scan these image blocks from top to bottom and left to right, compute {π c , A c , B c } of the cth image block G c ; 4: Input {π c , A c , B c } to the trained SVM φ, and get the detection result c , A c , B c ); 5: If φ(π c , A c , B c ) &lt; 0, update label array C(c) = 1; 6: c := c + 1, go to step 3 until c = I 128 × J 128 ; 7: return C.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>θ s is the parameter set of the probability density function of state s. Let P s = [P 1 s , P 2 s , . . . , P L s ] T the unknown parameter vector s = [θ s , P s ] T . Two steps are involved to estimate the unknown parameters.</figDesc><table /><note><p>1) E-Step: Calculate the expectation of log-likelihood function</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I IMPACT</head><label>I</label><figDesc>OF THE DECOMPOSITION LEVEL OF DMWT ON THE DETECTION PERFORMANCE OVER DATA SET<ref type="bibr" target="#b23">[24]</ref> </figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II IMPACT</head><label>II</label><figDesc>OF BLOCK SIZE OF BDCT ON THE DETECTION PERFORMANCE OVER DATA SET</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III DETECTION</head><label>III</label><figDesc>PERFORMANCE OF THE NONCAUSAL MODEL WITH DIFFERENT NUMBER OF STATES OVER DATA SET<ref type="bibr" target="#b23">[24]</ref> </figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Feature extraction time, SVM (C, g) selection time, prediction time over 30 rounds, and the total time are adopted for comparisons. All the schemes are implemented on the same platform, that is, 64-b MATLAB 2013a. The comparison results are presented in Table V, where Fea. time is the feature extraction time, (C, g) time indicates the time cost of (C, g) selection, Pred. time denotes the prediction time over 30 rounds, and Total time equals to the sum of Fea. time, (C, g) time, and Pred. time. For a fair comparison, we first compare the time cost of Shi et al.</figDesc><table><row><cell>TABLE IV</cell></row><row><cell>COMPARISONS WITH OTHER DETECTION METHODS</cell></row><row><cell>TABLE V</cell></row><row><cell>COMPARISONS OF TIME COST</cell></row><row><cell>for comparisons.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE VI DETECTION</head><label>VI</label><figDesc>RESULTS ON IFS-TC DATA SET</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank Prof. Y. Q. Shi for the helpful comments for improving this paper. They would also like to thank the DVMM Laboratory, Columbia University, New York, NY, USA, for the use of the Columbia image splicing detection evaluation dataset, and the reviewers for giving insightful suggestions and comments.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the National Science Foundation of China under Grants 61271316, 61071152, 61271319, and 61271180; in part by the 973 Programs of China under Grants 2010CB731403, 2010CB731406, and 2013CB329605; in part by the National Twelfth Five-Year Plan for Science and Technology under Grant 2012BAH38B04; in part by the Key Laboratory for Shanghai Integrated Information Security Management Technology Research; and in part by the Chinese National Engineering Laboratory for Information Content Analysis Technology. This paper was recommended by Associate Editor P. Le Callet.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Digital watermarking</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="30" to="33" />
			<date type="published" when="1998-07">Jul. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A robust image authentication method distinguishing JPEG compression from malicious manipulation</title>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="153" to="168" />
			<date type="published" when="2001-02">Feb. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fast fingerprint verification using subregions of fingerprint images</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="95" to="101" />
			<date type="published" when="2004-01">Jan. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Wavelet-based image watermarking with visibility range estimation based on HVS and neural networks</title>
		<author>
			<persName><forename type="first">H.-H</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="751" to="763" />
			<date type="published" when="2011-04">Apr. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Higher-order wavelet statistics and their application to digital forensics</title>
		<author>
			<persName><forename type="first">H</forename><surname>Farid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Comput. Vis. Pattern Recognit. (CVPR) Workshop</title>
		<meeting>Conf. Comput. Vis. Pattern Recognit. (CVPR) Workshop<address><addrLine>Madison, WA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-06">Jun. 2003</date>
			<biblScope unit="page">94</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Blind detection of photomontage using higher order statistics</title>
		<author>
			<persName><forename type="first">T.-T</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Symp. Circuits Syst. (ISCAS)</title>
		<meeting>Int. Symp. Circuits Syst. (ISCAS)<address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-05">May 2004</date>
			<biblScope unit="page" from="688" to="691" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Image splicing detection using 2-D phase congruency and statistical moments of characteristic function</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE Conf. Secur., Steganogr., Watermarking Multimedia Contents</title>
		<meeting>SPIE Conf. Secur., Steganogr., Watermarking Multimedia Contents<address><addrLine>San Jose, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-01">Jan. 2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A passive-blind forgery detection scheme based on content-adaptive quantization table estimation</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>-I. Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-K</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-L</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="421" to="434" />
			<date type="published" when="2011-04">Apr. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Run-length and edge statistics based approach for image splicing detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Q</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th Int. Workshop Digit. Watermarking (IWDW)</title>
		<meeting>7th Int. Workshop Digit. Watermarking (IWDW)<address><addrLine>Busan, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="76" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Steganalysis versus splicing detection</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th Int. Workshop Digit. Watermarking (IWDW)</title>
		<meeting>6th Int. Workshop Digit. Watermarking (IWDW)<address><addrLine>Guangzhou, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="158" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Digital image splicing detection based on approximate run length</title>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit. Lett</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1591" to="1597" />
			<date type="published" when="2011-09">Sep. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Exposing digital image forgeries by detecting discrepancies in motion blur</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kakar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sudha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="443" to="452" />
			<date type="published" when="2011-06">Jun. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Detecting digital image splicing in chroma spaces</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 9th Int. Workshop Digit. Watermarking (IWDW)</title>
		<meeting>9th Int. Workshop Digit. Watermarking (IWDW)<address><addrLine>Seoul, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="12" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Exposing digital forgeries in complex lighting environments</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Farid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="450" to="461" />
			<date type="published" when="2007-09">Sep. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A natural image model approach to splicing detection</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 9th Workshop Multimedia Secur. (MM &amp; Sec)</title>
		<meeting>9th Workshop Multimedia Secur. (MM &amp; Sec)<address><addrLine>Dallas, TX, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="51" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Effective image splicing detection based on image chroma</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 16th IEEE Int. Conf. Image Process. (ICIP)</title>
		<meeting>16th IEEE Int. Conf. Image ess. (ICIP)<address><addrLine>Cairo, Egypt</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-11">Nov. 2009</date>
			<biblScope unit="page" from="1257" to="1260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">New developments in color image tampering detection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sutthiwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-T</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Circuits Syst. (ISCAS)</title>
		<meeting>IEEE Int. Symp. Circuits Syst. (ISCAS)<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-06">May/Jun. 2010</date>
			<biblScope unit="page" from="3064" to="3067" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Rake transform and edge statistics for image forgery detection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sutthiwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-T</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Multimedia Expo (ICME)</title>
		<meeting>IEEE Int. Conf. Multimedia Expo (ICME)<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-07">Jul. 2010</date>
			<biblScope unit="page" from="1463" to="1468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Image tampering detection based on stationary distribution of Markov chain</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 17th IEEE Int. Conf. Image Process. (ICIP)</title>
		<meeting>17th IEEE Int. Conf. Image ess. (ICIP)<address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-09">Sep. 2010</date>
			<biblScope unit="page" from="2101" to="2104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Markovian rake transform for digital image tampering detection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Patchara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-T</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Trans. Data Hiding Multimedia Secur. VI</title>
		<imprint>
			<date type="published" when="2011-07">Jul. 2011</date>
			<biblScope unit="volume">6730</biblScope>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Steganalysis by subtractive pixel adjacency matrix</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pevny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fridrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="215" to="224" />
			<date type="published" when="2010-06">Jun. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On detection of median filtering in digital images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kirchner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fridrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE, Media Forensics Secur</title>
		<meeting>SPIE, Media Forensics Secur</meeting>
		<imprint>
			<date type="published" when="2010-01">Jan. 2010</date>
			<biblScope unit="volume">II</biblScope>
			<biblScope unit="page" from="754110" to="754111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Digital image splicing detection based on Markov features in DCT and DWT domain</title>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4292" to="4299" />
			<date type="published" when="2012-12">Dec. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Columbia Image Splicing Detection Evaluation Dataset</title>
		<author>
			<persName><forename type="first">T.-T</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
		<ptr target="http://www.ee.columbia.edu/ln/dvmm/downloads/AuthSplicedDataSet/dlform.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Image classification by a twodimensional hidden Markov model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Najmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Gray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="517" to="533" />
			<date type="published" when="2000-02">Feb. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Video event classification and image segmentation based on noncausal multidimensional hidden Markov models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schonfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Khokhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1304" to="1313" />
			<date type="published" when="2009-06">Jun. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Roy. Statist. Soc. B</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<title level="m">Statistical Learning Theory</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">LIBSVM: A library for support vector machines</title>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Intell. Syst. Technol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A practical guide to support vector classification</title>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf" />
	</analytic>
	<monogr>
		<title level="j">Dept. Comput. Sci., Nat. Taiwan Univ</title>
		<imprint>
			<date type="published" when="2010-04">Apr. 2010</date>
			<pubPlace>Taipei, Taiwan</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">ROC graphs: Notes and practical considerations for data mining researchers</title>
		<author>
			<persName><forename type="first">T</forename><surname>Fawcett</surname></persName>
		</author>
		<idno>HPL-2003-4</idno>
	</analytic>
	<monogr>
		<title level="j">HP Labs</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<pubPlace>Palo Alto, CA, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Detecting image splicing using geometry invariants and camera characteristics consistency</title>
		<author>
			<persName><forename type="first">Y.-F</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Multimedia Expo</title>
		<meeting>IEEE Int. Conf. Multimedia Expo<address><addrLine>San Jose, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-07">Jul. 2006</date>
			<biblScope unit="page" from="549" to="552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">UCID-An uncompressed colour image database</title>
		<author>
			<persName><forename type="first">G</forename><surname>Schaefer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2003-12">Dec. 2003</date>
			<biblScope unit="volume">5307</biblScope>
			<biblScope unit="page" from="472" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The first IFS-TC image forensics challenge</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Piva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<ptr target="http://ifc.recod.ic.unicamp.br/fc.website/index.py" />
	</analytic>
	<monogr>
		<title level="m">Xudong Zhao (M&apos;13) received the M.S. degree in computer software and theory from</title>
		<title level="s">Shanghai. His research interests include digital image forensics and image processing</title>
		<meeting><address><addrLine>Shanghai, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">Nov. 2012. 2008</date>
		</imprint>
		<respStmt>
			<orgName>East China University of Science and Technology ; Department of Electronic Engineering, Shanghai Jiao Tong University</orgName>
		</respStmt>
	</monogr>
	<note>He is currently working toward the Ph.D. degree with the</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">He has been with the School of Information Security Engineering, Shanghai Jiao Tong University, since 2004, where he is currently an Associate Professor. His biography is listed in Marquis Who&apos;s Who in Science and Engineering. His research interests include image processing and pattern recognition. Shenghong Li (M&apos;12) received the B.Eng. and M.S. degrees in electrical engineering from Jilin University of Technology</title>
		<author>
			<persName><forename type="first">Shilin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">B</forename><surname>Eng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Kong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">as a Research Fellow, an Associate Professor, and a Professor, since 1999. In 2010 he was a Visiting Scholar with Nanyang Technological University</title>
		<meeting><address><addrLine>Shanghai, China; Changchun, China; Beijing, China; Shanghai, China; Singapore; Shanghai, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">2001. 2004. 1993 and 1996. 1999. 2006. 2007. 2009. 1998</date>
		</imprint>
		<respStmt>
			<orgName>Shanghai Jiao Tong University ; Department of Computer Engineering and Information Technology ; Shanghai Jiao Tong University</orgName>
		</respStmt>
	</monogr>
	<note>respectively. He received the Prize of Shanghai Science and Technology Progress in China in 2003. Jianhua Li received the Ph. He has been with the School of Information Security Engineering, Shanghai Jiao Tong University, since 2000, where he is currently a Professor. His research interests include information security and computer communication network</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
