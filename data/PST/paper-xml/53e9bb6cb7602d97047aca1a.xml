<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Co-evolutionary Particle Swarm Optimization to Solve min-max Problems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Yuhui</forename><surname>Shi</surname></persName>
							<email>yuhui.shi@@eds.com</email>
							<affiliation key="aff0">
								<orgName type="department">EDS Embedded Svstems G~OUD</orgName>
								<address>
									<addrLine>1401 E. Hoffer Street Kokomo</addrLine>
									<postCode>46902</postCode>
									<region>IN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Co-evolutionary Particle Swarm Optimization to Solve min-max Problems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">471EFF96641ACDAB822DF2105B4AD958</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T17:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, a eo-evolutionary particle swarm optimization @SO) to solve constrained optimization problems is proposed. First, we introduce the augmented Lagrangian to transform a constrained optimization to a min-max problem with the saddle-point solution. Next, a co-evolutionary PSO algorithm is developed with one PSO focusing on the minimum part of min-max problem while the another PSO focusing on the maximum part of the min-max problem. The two PSOs are connected through the fitness function. In the fitness calculation of one PSO, the another PSO serves as the environment to that PSO. The new algorithm is tested on three benchmark functions. The simulation results illustrate the efficiency and effectiveness of the new co-evolutionary particle swarm algorithm.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In the last few years, evolutionary algorithms (EAs) have shown to be a promising approach to solve complex constrained optimization problems [l]. One of the major issues is how to handle the constraints. Some algorithms have been proposed and they can be grouped as: 1) preservation of the feasible individuals, 2) repair of infeasible solutions, 3) use of decoders, 4) penalty functions, 5) and hybrid algorithms. The performance of these methods depends on the problem at hand. The main question is to evaluate the fitness of infeasible individuals. The most employed method is the use of penalty functions.</p><p>An, at least potentially, better approach is to transform a constrained optimization problem into an unconstrained optimization problem by introducing a Lagrange multiplier.</p><p>The problem then can be written in a min-max form, which arises in many areas of science and engineering. Min-max problems are also considered difficult to solve. <ref type="bibr">Hillis [2]</ref>, in his pioneering work, proposed a method inspired by the coevolution of populations. Two independent genetic algorithms (GAS) were used with one for sorting networks (host) and the another for testing cases (parasites). Both GAS evolve simultaneously and are coupled through the fitness function. In the traditional EA, the fitness depends only on the individual of the population to be evaluated. Although both co-evolutionary approaches have shown useful results for solving complex problems, we focus on the competitive co-evolution approach. In this case, the fitness of an individual is evaluated by means of a competition with the members of the other population [2], [3], and [4-51. Inspired by the work of <ref type="bibr">Hillis [2]</ref>, Barbosa [6-71 presented a method to solve min-max problems by using two independent populations of GA coupled by the fitness function. Also, along the same line, <ref type="bibr">Tahk and Sun [8]</ref> used a co-evolutionary augmented Lagrangian method to solve min-max problems by means of two populations of evolution strategies with an annealing scheme. The populations of the variable vector and the Lagrange multiplier vector approximate a zero-sum game by a static matrix game.</p><p>In this paper, inspired by the co-evolution of swarms, and based on the works of <ref type="bibr">Barbosa [7]</ref> and and Tahk and Sun [8], we propose a novel method to solve min-max problems based on the co-evolution of two PSOs. Two populations of independent PSOs are evolved simultaneously: one for evolving the variable vector, and the other for evolving the Lagrange multiplier vector. The rest of the paper is organized as follows: in section 2, the min-max problem formulation is described. PSO is briefly explained in section 3. In section 4, a new approach based on co-evolutionary PSO is proposed to solve the min-max problems; Benchmark optimization problems are presented in section 5 ; section 6 gives simulation results with some discussions, followed by conclusions in section 7. The set S E '3'' designates the search space, which is defined by the lower and upper bounds of the variables:  <ref type="figure">L(x,</ref><ref type="figure">p,</ref><ref type="figure">A)</ref> x AP * * provides the minimizer x* as well as the multiplier p , A .</p><p>(4)</p><p>For non-convex problems, however, the solution of the dual problem does not coincide with that of the primal problem. In this case, to the Lagrangian function is added a penalty function where P is a positive penalty parameter, and</p><formula xml:id="formula_0">gT(x&gt; = max (O,gi(x)), for i = l,...,m</formula><p>The augmented Lagrangian is written then as A very usually form to describe the augmented Lagrangian is as following [8]:</p><p>It can be demonstrated that the solution of the primal problem and the augmented Lagrangian are identical [9 . The main issue is how to find the saddle-point g,A*,p*/. In Section 4, a Co-PSO based on the evolution of both the variable vector and the Lagrangian multiplier is proposed to solve the min-max problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PARTICLE SWARM OPTIMIZATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Particle swarm optimization (PSO) is an evolutionary computation technique originally developed by Kennedy and</head><p>Eberhart [ l l ] , <ref type="bibr">Eberhart and Kennedy [lo]</ref>. The PSO is motivated from the simulation of social behavior instead of the evolution of nature as in the other evolutionary algorithms (genetic algorithms, evolutionary programming, evolutionary strategies, and genetic programming). It is a population-based evolutionary algorithm. Similar to the other population-based evolutionary algorithms, PSO is initialized with a population of random solutions. Unlike the most of the evolutionary algorithms, each potential solution (individual) in PSO is also associated with a randomized velocity, and the potential solutions, called particles, are then "flown" through the problem space [ 151.</p><p>Each particle keeps track of its coordinates in the problem space, which are associated with the best solution (fitness) it has achieved so far. This value is called pbest. Another "best" value that is tracked by the global version of the particle swarm optimizer is the overall best value, and its location, obtained so far by any particle in the population. This location is called gbest.</p><p>The particle swarm optimization concept consists of, at each time step, changing the velocity (accelerating) of each particle flying toward its pbest and gbest locations (global version of PSO). Acceleration is weighted by random terms, with separate random numbers being generated for acceleration toward pbest and gbest locations, respectively. The procedure for implementing the global version of PSO is is given in the List 1. The first part in equation ( <ref type="formula">8</ref>) is the momentum part of the particle. The inertia weight w represents the degree of the momentum of the particles. The second part is the "cognition" part, which represents the independent thinking of the particle itself. The third part is the "social" part, which represents the collaboration among the particles. The constants c1 and c2 represent the weighting of the "cognition" and "social" parts that pull each particle toward pbest and gbest positions. Thus, adjustment of these constants changes the amount of "tension" in the system. LOW values allow Particles to n" far from already found better regions before being tugged back, while high values result in abrupt movement toward, Or Past7 already found 1) Initialize a population (array) of particles with random positions and velocities in the n dimensional problem space. 2) For each particle, evaluate its fitness value. 3) Compare each particle's fitness evaluation with the particle'spbest. If current value is better thanpbest, then set pbest value equal to the current value and the pbest location eaual to the current location in n-dimensional space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4)</head><p>Compare fitness evaluation with the population's overall previous best. If current value is better than gbest, then reset gbest to the current particle's array index and value. 5 ) Change the velocity and position of the particle according to equations ( <ref type="formula">8</ref>) and ( <ref type="formula">9</ref>) [12-131:</p><formula xml:id="formula_1">X j = ( X j + V i ) (9)</formula><p>6) Loop to step 2) until a criterion is met, usually a sufficiently good fitness or a maximum number of iterations (generations).</p><p>where xi =[31,32, ..., xinf stands for the position of the i-th particle, vi = [v;~, vi2, ..., .i,p stands for the velocity of the i-th particle and p ; =[pi,, pi2 ,...,pinIT represents the best previous position (the position giving the best fitness value) of the i-th particle. The index g represents the index of the best particle among all the particles in the group. Variable w is the inertia weight, c1 and c2 are positive constants; rand() and Rand() are two random functions in the range [0, 13. Particles' velocities on each dimension are clamped to a maximum velocity Vmux. If the sum of accelerations would cause the velocity on that dimension to exceed Vmux, which is a parameter specified by the user, then the velocity on that dimension is limited to Vmax.</p><p>Vmux is an important parameter. It determines the resolution with which the regions around the current solutions are better regions.</p><p>Early experience with particle swarm optimization (trial and error, mostly) led us to set the acceleration constants c1 and c2 equal to 2.0 for almost all applications. Vmax is often set at about 10-20% of the dynamic range of the variable on each dimension.</p><p>The population size selected was problem-dependent. Population sizes of 20-50 were probably most common. It is learned that small population sizes are acceptable for PSO to be optimal in terms of minimizing the total number of evaluations (population size times the number of generations) needed to obtain a sufficient solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CO-EVOLUTIONARY PSO</head><p>Two populations of PSOs are involved in the co-evolutionary PSO to solve the min-max problem formulated in the expression (4). The first PSO focuses on evolving the variable vector x with ''fTozen" p and A Only the variable vector x is represented in the population PI The second PSO focuses on evolving Lagrangian multiplier vectors p and 1</p><p>with "frozen" x. Only the multiplier vectors p and A are represented in the population P2. The two PSOs interact with each other through the fitness evaluation. For the first PSO, the problem is a minimum problem and the fitness value of each individual x is evaluated according to</p><p>For the second problem, the problem is a maximum problem and the fitness value of each individual p and 1 is evaluated according to 0-7803-7282-4/02/$10.00 02002 IEEE Since in the PSO algorithm, all the particles (or individuals) survive into the next generation, there is no selection mechanism involved. The cooperation among the particles are through the "history" pbest and gbest, which are updated if better fitness values are obtained so the PSO can be applied to solve both minimum and maximum problems.</p><p>The procedure of the co-evolutionary PSO algorithm is given in the List 2. Within each cycle, the first PSO is run for max-gen-1 generations, then the second PSO is run for max-gen-2 generations, this process is repeated until either an acceptable solution has been obtained or the maximum number of cycles has been reached. The global best in the population P I is the solution for the variable vector x, and the global best in the population P2 is the solution for the Lagrangian multiplier vectors p and A List 2: Procedure of eo-evolutionary PSO 1) Initialize two PSOs.</p><p>2) Run the first PSO for max_gen-1 generations.</p><p>3) Re-evaluate the pbest values for the second PSO if it 4) Run the second PSO for max-gen-2 generations. 5) Re-evaluate the pbest values for the first PSO. 6) Loop to step 2 until a termination condition is met.</p><p>is not the first cycle.</p><p>In the above co-evolutionary PSO algorithm, when one PSO is running, the other serves as its environment, so each PSO has a changing environment from cycle to cycle. Due to the change of the environment between cycles, the pbest values obtained in the previous cycle has to be re-evaluated according to the new environment before starting its evolving, which is shown as step 3 and 5 in the List 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTAL SETTING</head><p>For comparison, three benchmark constrained optimization problems reported in [l] and [8] are used here. The first optimization problem G 1 consists of minimizing:</p><formula xml:id="formula_2">4 17 _- f(x)=5x1 +5x2 +5x3 +5x4 -5 c x , 2 -c x i</formula><p>where O I X i 51, 0 I x i 5100, 0 I x i I 1, i = 1, ..., 9; i = 10,11,12; i = 13.</p><p>The global minimum is known to be</p><p>x*= (1,1,1 , 1,1,1,1,1,1,3,3,3,1)</p><p>with f(x) = -15.</p><p>The second optimization problem G7 consists of minimizing:</p><p>where -10 1 xi 1 10, i = 1,---,10.</p><p>The global minimum is known to be</p><p>x*= (2.171996,2.363683,8.773926,5.095984, <ref type="bibr">0.9906548,1.430574,1.32 1644,9.828726, 8.280092,8.375927)</ref> with Ax") = 24.3062091.</p><p>The last optimization problem G9 consists of minimizing: The global minimum is known to be From Table <ref type="table" target="#tab_0">1</ref>, 2 and 3, it can be easily seen that the coevolutionary PSO can converge very quickly towards the global true optimum, except for G1 problem. For G1 problem, it has big variance over the 50 runs under all three different maximum numbers of cycles. By looking at the results for all 50 runs, it can be seen that the co-evolutionary PSO finds solution either at value between 12 and 13 or at value between 14 and 15. The results for first 20 runs are listed in Table <ref type="table" target="#tab_4">4</ref> for illustration. To have better results, at least for G1 problem, the co-evolutionary PSO algorithm needs to be modified in some way to avoid the algorithm to trap at some local attractors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSIONS</head><p>In this paper, inspired by the co-evolution of swarms, a coevolutionary PSO has been developed to solve min-max problems, and tested on three benchmark problems. The simulation results illuminate that the new algorithm, for most cases, can quickly search towards the global optimum. More works need to be done to improve the new algorithm's ability to escape the local attractors, and to demonstrate the algorithm's ability to fine tune the solution.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Renato A. Krohling* DeDartamento de Engenharia ElCtrica Universidade Federal do EsDirito Santo -UFES Av. Femando Ferrari. CP 01-901 1, CEP 29060-970 EsDirito Santo. ES. Brazil renato@ele.ufes.br For co-evolutionary algorithms (Co-EA), the fitness of an individual depends on not only the individual itself but also the individuals of another EA. Generally, Co-EA can be grouped in two categories: competitive and cooperative.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>problem is expressed as Renato A. Krohling was sponsored by the Brazilian Research Council (CNPq) under Grant 301009/99-6 0-7803-7282-4/02/$10.00 02002 IEEE min f, i = I , ..., 1 where the vector x consists of n variables: x=[x~,x*, ..., XJE 9ifl</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>41 5</head><label>5</label><figDesc>xi 5 4 , with i = 1, ..., n. By introducing the Lagrangian formulation, the dual problem associated with the primal problem (1) can be written as " for i = I , ..., m and p is a mxl multiplier vector for the inequality constraints and I is a 1x1 multiplier for the equality constraints. If the problem (1) satisfies the convexity conditions over S , then the solution of the primal problem (1) is the vector x*of the saddle-point P,A*,p*) of L(x, n, p) so that: Solving the min-max problem min max</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>List 1 :</head><label>1</label><figDesc>Procedure of PSO searched. If Vmax is too high, the PSO facilitates global search, and particles might fly past good solutions. If Vmux is too small, on the other hand, the PSO facilitates local search, and particles may not explore sufficiently beyond locally good regions. In fact, they could become trapped in local optima, unable to move far enough to reach a better position in the problem space [ 141.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>+xi2 I O -2x4 -x 5 + x I o 1 0 -2x, -x7 + X I 1 1 0 -2x, -x9 + X I 2 IO 0-7803-7282-4/02/$10.00 02002 IEEE</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 ,</head><label>1</label><figDesc>2, and 3 list the simulation results for the three benchmark problems averaged over 50 runs, respectively.</figDesc><table><row><cell cols="3">x*= (2.330499J.95 1372,-0.4775414,4.365726,</cell></row><row><cell cols="3">-0.6244870,1.03813 1,1.594227)</cell></row><row><cell cols="2">with Ax*) = 680.6300573.</cell><cell></cell></row><row><cell cols="3">For all three benchmark problems, the population sizes are</cell></row><row><cell cols="3">set as 40 and 30, respectively. The maximum number of</cell></row><row><cell cols="3">generations for each PSO of one cycle is chosen to be 10. To</cell></row><row><cell cols="3">test the convergence speed of the co-evolutionary PSO, three</cell></row><row><cell cols="3">different maximum numbers of cycles are chosen: 40, 80 and</cell></row><row><cell cols="3">120. The particles are randomly initialized within the</cell></row><row><cell cols="3">boundaries for each run. The inertia weight of each PSO is</cell></row><row><cell cols="3">linearly decreased over the course of each run, starting from</cell></row><row><cell cols="3">0.9 and ending at 0.4. Each different parameter setting is run</cell></row><row><cell cols="3">50 times. Each run is terminated only when the maximum</cell></row><row><cell cols="2">number of cycles has been reached.</cell><cell></cell></row><row><cell cols="3">6 EXPERIMENTAL RESULTS AND</cell></row><row><cell cols="2">DISCUSSION</cell><cell></cell></row><row><cell>Max. Number Cycles</cell><cell cols="2">Function minimum values</cell></row><row><cell></cell><cell>Average</cell><cell>variance</cell></row><row><cell>40</cell><cell>-1 3.9637</cell><cell>1.094654</cell></row><row><cell>80</cell><cell>-14.0373</cell><cell>1 .I 19829</cell></row><row><cell>120</cell><cell>-14.1597</cell><cell>1.092294</cell></row><row><cell>40</cell><cell></cell><cell></cell></row><row><cell>80</cell><cell></cell><cell></cell></row><row><cell>120</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Results for GI over 50 runs</figDesc><table><row><cell>Average</cell><cell>variance</cell></row><row><cell>24.70024076</cell><cell>0.21 20471 24</cell></row><row><cell>24.5433936</cell><cell>0.057324594</cell></row><row><cell>24.47762322</cell><cell>0.039600375</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Results for G7 over 50 runs Max. Number Cycles I Function minimum values I</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Results for G9 over 50 runs I Max. Number Cycles I Function minimum values 1</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>First 20 run results for GI with maximum number of cycles 40</figDesc><table><row><cell>-12,9566</cell><cell>-14.9441</cell><cell>-14.9668</cell><cell>-14.9646</cell></row><row><cell>-14.9514</cell><cell>-1 2.9704</cell><cell>-12.9752</cell><cell>-12.9557</cell></row><row><cell>-12.4198</cell><cell>-1 4.9478</cell><cell>-12.9554</cell><cell>-1 2.9834</cell></row><row><cell>-12.9481</cell><cell>-12.9562</cell><cell>-14.9492</cell><cell>-1 4.9532</cell></row><row><cell>-1 4.9604</cell><cell>-14.9426</cell><cell>-14.9486</cell><cell>-1 4.9577</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Evolutionary algorithms for constrained parameter optimization problems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schoenauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Coevolving parasites improve simulated evolution as an optimization procedure</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Hillis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="228" to="234" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Steps towards coevolutionary classification neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Paredis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Life IV</title>
		<imprint>
			<biblScope unit="page" from="359" to="365" />
			<date type="published" when="1994">1994</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Methods for competitive coevolution: Finding opponents worth beating</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Rosin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Belew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 6th int. Conf: on Genetic Algorithms and their Applications</title>
		<meeting>of the 6th int. Conf: on Genetic Algorithms and their Applications<address><addrLine>Pittsburgh, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="313" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">New methods for competitive coevolution</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Rosin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Belew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A genetic algorithm for min-max problems</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J C</forename><surname>Barbosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 1st int. conf: on Evolutionary Computation and its Applications</title>
		<meeting>of the 1st int. conf: on Evolutionary Computation and its Applications<address><addrLine>Moscow, Russia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="99" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A coevolutionary genetic algorithm for constrained optimization</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J C</forename><surname>Barbosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 1999 Congress on Evolutionaiy Computation</title>
		<meeting>of the 1999 Congress on Evolutionaiy Computation</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1605" to="1161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Coevolutionary augmented lagrangian methods for constrained optimization</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Tahk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-C</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="114" to="124" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Nonlinear Programming: Theory and Algorithms, 2nd</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bazaraa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Sherali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Shetty</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A new optimizer using particle swarm theory</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 6th. Int. Symposium on Micro Machine and Human Science</title>
		<meeting>of the 6th. Int. Symposium on Micro Machine and Human Science<address><addrLine>Nagoya, Japan; Piscataway, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Service Center</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page">3943</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Int. Con$ on Neural Networks IV</title>
		<meeting>of the IEEE Int. Con$ on Neural Networks IV<address><addrLine>Piscataway, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Service Center</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Parameter selection in particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionaiy Programming VII: Proc. EP98</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="591" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A modified particle swarm optimizer</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE International Conference on Evolutionary Computation</title>
		<meeting>of the IEEE International Conference on Evolutionary Computation<address><addrLine>Piscataway, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="69" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Study of Vmax of the particle swarm optimization algorithm</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Workshop on Particle Swarm Optimization</title>
		<meeting>of the Workshop on Particle Swarm Optimization<address><addrLine>Indianapolis, IN</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note>IUPUI</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<title level="m">Swarm Intelligence</title>
		<meeting><address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
