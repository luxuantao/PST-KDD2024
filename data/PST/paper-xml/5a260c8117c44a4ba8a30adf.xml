<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Representation Learning on Graphs: Methods and Applications</title>
				<funder>
					<orgName type="full">Canadian governments</orgName>
				</funder>
				<funder ref="#_spQd6tc">
					<orgName type="full">DARPA SIMPLEX, Stanford Data Science Initiative</orgName>
				</funder>
				<funder ref="#_Q8t4eyZ">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_SQ22et2">
					<orgName type="full">NSERC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-04-10">10 Apr 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Stanford University Stanford</orgName>
								<address>
									<postCode>94305</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
							<email>rexying@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Stanford University Stanford</orgName>
								<address>
									<postCode>94305</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Stanford University Stanford</orgName>
								<address>
									<postCode>94305</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Representation Learning on Graphs: Methods and Applications</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-04-10">10 Apr 2018</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1709.05584v3[cs.SI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Machine learning on graphs is an important and ubiquitous task with applications ranging from drug design to friendship recommendation in social networks. The primary challenge in this domain is finding a way to represent, or encode, graph structure so that it can be easily exploited by machine learning models. Traditionally, machine learning approaches relied on user-defined heuristics to extract features encoding structural information about a graph (e.g., degree statistics or kernel functions). However, recent years have seen a surge in approaches that automatically learn to encode graph structure into low-dimensional embeddings, using techniques based on deep learning and nonlinear dimensionality reduction. Here we provide a conceptual review of key advancements in this area of representation learning on graphs, including matrix factorization-based methods, random-walk based algorithms, and graph neural networks. We review methods to embed individual nodes as well as approaches to embed entire (sub)graphs. In doing so, we develop a unified framework to describe these recent approaches, and we highlight a number of important applications and directions for future work.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Graphs are a ubiquitous data structure, employed extensively within computer science and related fields. Social networks, molecular graph structures, biological protein-protein networks, recommender systems-all of these domains and many more can be readily modeled as graphs, which capture interactions (i.e., edges) between individual units (i.e., nodes). As a consequence of their ubiquity, graphs are the backbone of countless systems, allowing relational knowledge about interacting entities to be efficiently stored and accessed <ref type="bibr" target="#b1">[2]</ref>.</p><p>However, graphs are not only useful as structured knowledge repositories: they also play a key role in modern machine learning. Many machine learning applications seek to make predictions or discover new patterns using graph-structured data as feature information. For example, one might wish to classify the role of a protein in a biological interaction graph, predict the role of a person in a collaboration network, recommend new friends to a user in a social network, or predict new therapeutic applications of existing drug molecules, whose structure can be represented as a graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Community structure</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Structural equivalence / roles</head><p>Figure <ref type="figure">1</ref>: Two different views of a character-character interaction graph derived from the Les Mis?rables novel, where two nodes are connected if the corresponding characters interact. The coloring in the left figure emphasizes differences in the nodes' global positions in the graph: nodes have the same color if they belong to the same community, at a global level. In contrast, the coloring in the right figure denotes structural equivalence between nodes, or the fact that two nodes play similar roles in their local neighborhoods (e.g., "bridging nodes" are colored blue). The colorings for both figures were generated using different settings of the node2vec node embedding method <ref type="bibr" target="#b27">[28]</ref>, described in Section 2. Reprinted from <ref type="bibr" target="#b27">[28]</ref> with permission. <ref type="foot" target="#foot_0">1</ref>The central problem in machine learning on graphs is finding a way to incorporate information about graphstructure into a machine learning model. For example, in the case of link prediction in a social network, one might want to encode pairwise properties between nodes, such as relationship strength or the number of common friends. Or in the case of node classification, one might want to include information about the global position of a node in the graph or the structure of the node's local graph neighborhood (Figure <ref type="figure">1</ref>). The challengefrom a machine learning perspective-is that there is no straightforward way to encode this high-dimensional, non-Euclidean information about graph structure into a feature vector.</p><p>To extract structural information from graphs, traditional machine approaches often rely on summary graph statistics (e.g., degrees or clustering coefficients) <ref type="bibr" target="#b5">[6]</ref>, kernel functions <ref type="bibr" target="#b57">[58]</ref>, or carefully engineered features to measure local neighborhood structures <ref type="bibr" target="#b39">[40]</ref>. However, these approaches are limited because these handengineered features are inflexible-i.e., they cannot adapt during the learning process-and designing these features can be a time-consuming and expensive process.</p><p>More recently, there has been a surge of approaches that seek to learn representations that encode structural information about the graph. The idea behind these representation learning approaches is to learn a mapping that embeds nodes, or entire (sub)graphs, as points in a low-dimensional vector space R d . The goal is to optimize this mapping so that geometric relationships in the embedding space reflect the structure of the original graph. After optimizing the embedding space, the learned embeddings can be used as feature inputs for downstream machine learning tasks. The key distinction between representation learning approaches and previous work is how they treat the problem of representing graph structure. Previous work treated this problem as a pre-processing step, using hand-engineered statistics to extract structural information. In contrast, representation learning approaches treat this problem as machine learning task itself, using a data-driven approach to learn embeddings that encode graph structure.</p><p>Here we provide an overview of recent advancements in representation learning on graphs, reviewing techniques for representing both nodes and entire subgraphs. Our survey attempts to merge together multiple, dis-A B Figure <ref type="figure">2</ref>: A, Graph structure of the Zachary Karate Club social network, where nodes are connected if the corresponding individuals are friends. The nodes are colored according to the different communities that exist in the network. B, Twodimensional visualization of node embeddings generated from this graph using the DeepWalk method (Section 2.2.2) <ref type="bibr" target="#b46">[47]</ref>. The distances between nodes in the embedding space reflect similarity in the original graph, and the node embeddings are spatially clustered according to the different color-coded communities. Reprinted with permission from <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b48">49]</ref>.</p><p>parate lines of research that have drawn significant attention across different subfields and venues in recent years-e.g., node embedding methods, which are a popular object of study in the data mining community, and graph convolutional networks, which have drawn considerable attention in major machine learning venues. In doing so, we develop a unified conceptual framework for describing the various approaches and emphasize major conceptual distinctions.</p><p>We focus our review on recent approaches that have garnered significant attention in the machine learning and data mining communities, especially methods that are scalable to massive graphs (e.g., millions of nodes) and inspired by advancements in deep learning. Of course, there are other lines of closely related and relevant work, which we do not review in detail here-including latent space models of social networks <ref type="bibr" target="#b32">[33]</ref>, embedding methods for statistical relational learning <ref type="bibr" target="#b42">[43]</ref>, manifold learning algorithms <ref type="bibr" target="#b37">[38]</ref>, and geometric deep learning <ref type="bibr" target="#b6">[7]</ref>-all of which involve representation learning with graph-structured data. We refer the reader to <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b37">[38]</ref>, and <ref type="bibr" target="#b6">[7]</ref> for comprehensive overviews of these areas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Notation and essential assumptions</head><p>We will assume that the primary input to our representation learning algorithm is an undirected graph G = (V, E) with associated binary adjacency matrix A. <ref type="foot" target="#foot_1">2</ref> We also assume that the methods can make use of a real-valued matrix of node attributes X ? R m?|V| (e.g., representing text or metadata associated with nodes). The goal is to use the information contained in A and X to map each node, or a subgraph, to a vector z ? R d , where d &lt;&lt; |V|.</p><p>Most of the methods we review will optimize this mapping in an unsupervised manner, making use of only information in A and X, without knowledge of a particular downstream machine learning task. However, we will also discuss some approaches for supervised representation learning, where the models make use of classification or regression labels in order to optimize the embeddings. These classification labels may be associated with individual nodes or entire subgraphs and are the prediction targets for downstream machine learning tasks (e.g., they might label protein roles, or the therapeutic properties of a molecule, based on its graph representation).</p><p>Figure <ref type="figure">3</ref>: Overview of the encoder-decoder approach. First the encoder maps the node, v i , to a low-dimensional vector embedding, z i , based on the node's position in the graph, its local neighborhood structure, and/or its attributes. Next, the decoder extracts user-specified information from the low-dimensional embedding; this might be information about v i 's local graph neighborhood (e.g., the identity of its neighbors) or a classification label associated with v i (e.g., a community label). By jointly optimizing the encoder and decoder, the system learns to compress information about graph structure into the low-dimensional embedding space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Embedding nodes</head><p>We begin with a discussion of methods for node embedding, where the goal is to encode nodes as low-dimensional vectors that summarize their graph position and the structure of their local graph neighborhood. These lowdimensional embeddings can be viewed as encoding, or projecting, nodes into a latent space, where geometric relations in this latent space correspond to interactions (e.g., edges) in the original graph <ref type="bibr" target="#b32">[33]</ref>. Figure <ref type="figure">2</ref> visualizes an example embedding of the famous Zachary Karate Club social network <ref type="bibr" target="#b46">[47]</ref>, where two dimensional node embeddings capture the community structure implicit in the social network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Overview of approaches: An encoder-decoder perspective</head><p>Recent years have seen a surge of research on node embeddings, leading to a complicated diversity of notations, motivations, and conceptual models. Thus, before discussing the various techniques, we first develop a unified encoder-decoder framework, which explicitly structures this methodological diversity and puts the various methods on equal notational and conceptual footing.</p><p>In this framework, we organize the various methods around two key mapping functions: an encoder, which maps each node to a low-dimensional vector, or embedding, and a decoder, which decodes structural information about the graph from the learned embeddings (Figure <ref type="figure">3</ref>). The intuition behind the encoder-decoder idea is the following: if we can learn to decode high-dimensional graph information-such as the global positions of nodes in the graph or the structure of local graph neighborhoods-from encoded low-dimensional embeddings, then, in principle, these embeddings should contain all information necessary for downstream machine learning tasks.</p><p>Formally, the encoder is a function, ENC :</p><formula xml:id="formula_0">V ? R d ,<label>(1)</label></formula><p>that maps nodes to vector embeddings z i ? R d (where z i corresponds to the embedding for node v i ? V). The decoder is a function that accepts a set of node embeddings and decodes user-specified graph statistics from these embeddings. For example, the decoder might predict the existence of edges between nodes, given their embeddings <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b35">36]</ref>, or it might predict the community that a node belongs to in the graph <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b34">35]</ref> (Figure <ref type="figure">3</ref>). In principle, many decoders are possible; however, the vast majority of works use a basic pairwise decoder,</p><formula xml:id="formula_1">DEC : R d ? R d ? R + ,<label>(2)</label></formula><p>that maps pairs of node embeddings to a real-valued node similarity measure, which quantifies the similarity of the two nodes in the original graph. When we apply the pairwise decoder to a pair of embeddings (z i ,z j ) we get a reconstruction of the similarity between v i and v j in the original graph, and the goal is optimize the encoder and decoder mappings to minimize the error, or loss, in this reconstruction so that:</p><formula xml:id="formula_2">DEC(ENC(v i ), ENC(v j )) = DEC(z i , z j ) ? s G (v i , v j ),<label>(3)</label></formula><p>where s G is a user-defined, graph-based similarity measure between nodes, defined over the graph G. In other words, we want to optimize our encoder-decoder model so that we can decode pairwise node similarities in the original graph s G (v i , v j ) from the low-dimensional node embeddings z i and z j . For example, one might set s G (v i , v j ) A i,j and define nodes to have a similarity of 1 if they are adjacent and 0 otherwise <ref type="bibr" target="#b0">[1]</ref>, or one might define s G according to the probability of v i and v j co-occurring on a fixed-length random walk over the graph G <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b46">47]</ref>. In practice, most approaches realize the reconstruction objective (Equation <ref type="formula" target="#formula_2">3</ref>) by minimizing an empirical loss L over a set of training node pairs D:</p><formula xml:id="formula_3">L = (v i ,v j )?D (DEC(z i , z j ), s G (v i , v j )) ,<label>(4)</label></formula><p>where : R ? R ? R is a user-specified loss function, which measures the discrepancy between the decoded (i.e., estimated) similarity values DEC(z i , z j ) and the true values s G (v i , v j ).</p><p>Once we have optimized the encoder-decoder system, we can use the trained encoder to generate embeddings for nodes, which can then be used as a feature inputs for downstream machine learning tasks. For example, one could feed the learned embeddings to a logistic regression classifier to predict the community that a node belongs to <ref type="bibr" target="#b46">[47]</ref>, or one could use distances between the embeddings to recommend friendship links in a social network <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b27">28]</ref> (Section 2.7 discusses further applications).</p><p>Adopting this encoder-decoder view, we organize our discussion of the various node embedding methods along the following four methodological components:</p><p>1. A pairwise similarity function s G : V ? V ? R + , defined over the graph G. This function measures the similarity between nodes in G.</p><p>2. An encoder function, ENC, that generates the node embeddings. This function contains a number of trainable parameters that are optimized during the training phase.</p><p>3. A decoder function, DEC, which reconstructs pairwise similarity values from the generated embeddings. This function usually contains no trainable parameters.</p><p>4. A loss function, , which determines how the quality of the pairwise reconstructions is evaluated in order to train the model, i.e., how DEC(z i , z j ) is compared to the true s G (v i , v j ) values.</p><p>As we will show, the primary methodological distinctions between the various node embedding approaches are in how they define these four components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Notes on optimization and implementation details</head><p>All of the methods we review involve optimizing the parameters of the encoder algorithm, ? ENC , by minimizing a loss analogous to Equation (4). <ref type="foot" target="#foot_2">3</ref> In most cases, stochastic gradient descent is used for optimization, though some algorithms do permit closed-form solutions via matrix decomposition (e.g., <ref type="bibr" target="#b8">[9]</ref>). However, note that we will not focus on optimization algorithms here and instead will emphasize high-level differences that exist across different embedding methods, independent of the specifics of the optimization approach. </p><formula xml:id="formula_4">z i -z j 2 2 general DEC(z i , z j ) ? s G (v i , v j ) Matrix Graph Factorization [1] z i z j A i,j DEC(z i , z j ) -s G (v i , v j ) 2 2 factorization GraRep [9] z i z j A i,j , A 2 i,j , ..., A k i,j DEC(z i , z j ) -s G (v i , v j ) 2 2 HOPE [45] z i z j general DEC(z i , z j ) -s G (v i , v j ) 2 2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Random walk</head><p>DeepWalk <ref type="bibr" target="#b46">[47]</ref> </p><formula xml:id="formula_5">e z i z j k?V e z i z k p G (v j |v i ) -s G (v i , v j ) log(DEC(z i , z j ))</formula><p>node2vec <ref type="bibr" target="#b27">[28]</ref> </p><formula xml:id="formula_6">e z i z j k?V e z i z k p G (v j |v i ) (biased) -s G (v i , v j ) log(DEC(z i , z j ))</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Shallow embedding approaches</head><p>The majority of node embedding algorithms rely on what we call shallow embedding. For these shallow embedding approaches, the encoder function-which maps nodes to vector embeddings-is simply an "embedding lookup":</p><formula xml:id="formula_7">ENC(v i ) = Zv i ,<label>(5)</label></formula><p>where Z ? R d?|V| is a matrix containing the embedding vectors for all nodes and v i ? I V is a one-hot indicator vector indicating the column of Z corresponding to node v i . The set of trainable parameters for shallow embedding methods is simply ? ENC = {Z}, i.e., the embedding matrix Z is optimized directly. These approaches are largely inspired by classic matrix factorization techniques for dimensionality reduction <ref type="bibr" target="#b3">[4]</ref> and multi-dimensional scaling <ref type="bibr" target="#b36">[37]</ref>. Indeed, many of these approaches were originally motivated as factorization algorithms, and we reinterpret them within the encoder-decoder framework here. Table <ref type="table" target="#tab_0">1</ref> summarizes some well-known shallow embedding methods within the encoder-decoder framework. Table <ref type="table" target="#tab_0">1</ref> highlights how these methods can be succinctly described according to (i) their decoder function, (ii) their graph-based similarity measure, and (iii) their loss function. The following two sections describe these methods in more detail, distinguishing between matrix factorization-based approaches (Section 2.2.1) and more recent approaches based on random walks (Section 2.2.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Factorization-based approaches</head><p>Early methods for learning representations for nodes largely focused on matrix-factorization approaches, which are directly inspired by classic techniques for dimensionality reduction <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b36">37]</ref>. Laplacian eigenmaps. One of the earliest, and most well-known instances, is the Laplacian eigenmaps (LE) technique <ref type="bibr" target="#b3">[4]</ref>, which we can view within the encoder-decoder framework as a shallow embedding approach in which the decoder is defined as</p><formula xml:id="formula_8">DEC(z i , z j ) = z i -z j 2 2</formula><p>and where the loss function weights pairs of nodes according to their similarity in the graph:</p><formula xml:id="formula_9">L = (v i ,v j )?D DEC(z i , z j ) ? s G (v i , v j ).<label>(6)</label></formula><p>Inner-product methods. Following on the Laplacian eigenmaps technique, there are a large number of recent embedding methodologies based on a pairwise, inner-product decoder:</p><p>1. Run random walks to obtain co-occurrence statistics.</p><p>2. Optimize embeddings based on co-occurrence statistics.</p><formula xml:id="formula_10">? z i z j / p G (v j |v i ) p G (v j |v i ) v i v j</formula><p>Figure <ref type="figure">4</ref>: The random-walk based methods sample a large number of fixed-length random walks starting from each node, v i . The embedding vectors are then optimized so that the dot-product, or angle, between two embeddings, z i and z j , is (roughly) proportional to the probability of visiting v j on a fixed-length random walk starting from v i .</p><p>where the strength of the relationship between two nodes is proportional to the dot product of their embeddings. The Graph Factorization (GF) algorithm<ref type="foot" target="#foot_4">4</ref>  <ref type="bibr" target="#b0">[1]</ref>, GraRep <ref type="bibr" target="#b8">[9]</ref>, and HOPE <ref type="bibr" target="#b44">[45]</ref> all fall firmly within this class. In particular, all three of these methods use an inner-product decoder, a mean-squared-error (MSE) loss,</p><formula xml:id="formula_11">L = (v i ,v j )?D DEC(z i , z j ) -s G (v i , v j ) 2 2 ,<label>(8)</label></formula><p>and they differ primarily in the node similarity measure used, i.e. how they define s G (v i , v j ). The Graph Factorization algorithm defines node similarity directly based on the adjacency matrix (i.e., s G (v i , v j ) A i,j ) <ref type="bibr" target="#b0">[1]</ref>; GraRep considers various powers of the adjacency matrix (e.g., s G (v i , v j ) A 2 i,j ) in order to capture higher-order node similarity <ref type="bibr" target="#b8">[9]</ref>; and the HOPE algorithm supports general similarity measures (e.g., based on Jaccard neighborhood overlaps) <ref type="bibr" target="#b44">[45]</ref>. These various different similarity functions trade-off between modeling "first-order similarity", where s G directly measures connections between nodes (i.e., s G (v i , v j ) A i,j <ref type="bibr" target="#b0">[1]</ref>) and modeling "higher-order similarity", where s G corresponds to more general notions of neighborhood overlap (e.g., s G (v i , v j ) = A 2 i,j <ref type="bibr" target="#b8">[9]</ref>). We refer to these methods in this section as matrix-factorization approaches because, averaging over all nodes, they optimize loss functions (roughly) of the form:</p><formula xml:id="formula_12">L ? Z Z -S 2 2 ,<label>(9)</label></formula><p>where S is a matrix containing pairwise similarity measures (i.e., S i,j s G (v i , v j )) and Z is the matrix of node embeddings. Intuitively, the goal of these methods is simply to learn embeddings for each node such that the inner product between the learned embedding vectors approximates some deterministic measure of node similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Random walk approaches</head><p>Many recent successful methods that also belong to the class of shallow embedding approaches learn the node embeddings based on random walk statistics. Their key innovation is optimizing the node embeddings so that nodes have similar embeddings if they tend to co-occur on short random walks over the graph (Figure <ref type="figure">4</ref>). Thus, instead of using a deterministic measure of node similarity, like the methods of Section 2.2.1, these random walk methods employ a flexible, stochastic measure of node similarity, which has led to superior performance in a number of settings <ref type="bibr" target="#b26">[27]</ref>.</p><formula xml:id="formula_13">A B v ? v 1 v 2 v 3 v 4 v 5 v 6 v 7 v 8 v 9 v 1 v 2 v 3 v s v ? Figure 5</formula><p>: A, Illustration of how node2vec biases the random walk using the p and q parameters. Assuming that the walk just transitioned from v s to v * , the edge labels, ?, are proportional to the probability of the walk taking that edge at next time-step. B, Difference between random-walks that are based on breadth-first search (BFS) and depth-first search (DFS). BFS-like random walks are mainly limited to exploring a node's immediate (i.e., one-hop) neighborhood and are generally more effective for capturing structural roles. DFS-like walks explore further away from the node and are more effective for capturing community structures. Adapted from <ref type="bibr" target="#b27">[28]</ref>.</p><p>DeepWalk and node2vec. Like the matrix factorization approaches described above, DeepWalk and node2vec rely on shallow embedding and use a decoder based on the inner product. However, instead of trying to decode a deterministic node similarity measure, these approaches optimize embeddings to encode the statistics of random walks. The basic idea behind these approaches is to learn embeddings so that (roughly):</p><formula xml:id="formula_14">DEC(z i , z j ) e z i z j v k ?V e z i z k (10) ? p G,T (v j |v i ),</formula><p>where p G,T (v j |v i ) is the probability of visiting v j on a length-T random walk starting at v i , with T usually defined to be in the range T ? {2, ..., 10}. Note that unlike the similarity measures in Section 2.2.1, p G,T (v j |v i ) is both stochastic and asymmetric. More formally, these approaches attempt to minimize the following cross-entropy loss:</p><formula xml:id="formula_15">L = (v i ,v j )?D -log(DEC(z i , z j )),<label>(11)</label></formula><p>where the training set D is generated by sampling random walks starting from each node (i.e., where N pairs for each node v i are sampled from the distribution</p><formula xml:id="formula_16">(v i , v j ) ? p G,T (v j |v j ))</formula><p>. However, naively evaluating the loss in Equation ( <ref type="formula" target="#formula_15">11</ref>) is prohibitively expensive-in particular, O(|D||V|)-since evaluating the denominator of Equation ( <ref type="formula">10</ref>) has time complexity O(|V|). Thus, DeepWalk and node2vec use different optimizations and approximations to compute the loss in Equation <ref type="bibr" target="#b10">(11)</ref>. DeepWalk employs a "hierarchical softmax" technique to compute the normalizing factor, using a binary-tree structure to accelerate the computation <ref type="bibr" target="#b46">[47]</ref>. In contrast, node2vec approximates Equation (11) using "negative sampling": instead of normalizing over the full vertex set, node2vec approximates the normalizing factor using a set of random "negative samples" <ref type="bibr" target="#b27">[28]</ref>. Beyond these algorithmic differences, the key distinction between node2vec and DeepWalk is that node2vec allows for a flexible definition of random walks, whereas DeepWalk uses simple unbiased random walks over the graph. In particular, node2vec introduces two random walk hyperparameters, p and q, that bias the random walk (Figure <ref type="figure">5</ref>.A). The hyperparameter p controls the likelihood of the walk immediately revisiting a node, while q controls the likelihood of the walk revisiting a node's one-hop neighborhood. By introducing these hyperparameters, node2vec is able to smoothly interpolate between walks that are more akin to breadth-first or depth-first search (Figure <ref type="figure">5</ref>.B). Grover et al. found that tuning these parameters allowed the model to trade off between learning embeddings that emphasize community structures or embeddings that emphasize local structural roles <ref type="bibr" target="#b27">[28]</ref> (see also Figure <ref type="figure">1</ref>). Large-scale information network embeddings (LINE). Another highly successful shallow embedding approach, which is not based random walks but is contemporaneous and often compared with DeepWalk and node2vec, is the LINE method <ref type="bibr" target="#b53">[54]</ref>. LINE combines two encoder-decoder objectives that optimize "first-order" and "second-order" node similarity, respectively. The first-order objective uses a decoder based on the sigmoid function,</p><formula xml:id="formula_17">DEC(z i , z j ) = 1 1 + e -z i z j ,<label>(12)</label></formula><p>and an adjacency-based similarity measure (i.e., s G (v i , v j ) = A i,j ). The second-order encoder-decoder objective is similar but considers two-hop adjacency neighborhoods and uses an encoder identical to Equation <ref type="bibr" target="#b9">(10)</ref>. Both the first-order and second-order objectives are optimized using loss functions derived from the KLdivergence metric <ref type="bibr" target="#b53">[54]</ref>. Thus, LINE is conceptually related to node2vec and DeepWalk in that it uses a probabilistic decoder and loss, but it explicitly factorizes first-and second-order similarities, instead of combining them in fixed-length random walks. HARP: Extending random-walk embeddings via graph pre-processing. Recently, Chen et al. <ref type="bibr" target="#b12">[13]</ref> introduced a "meta-strategy", called HARP, for improving various random-walk approaches via a graph preprocessing step. In this approach, a graph coarsening procedure is used to collapse related nodes in G together into "supernodes", and then DeepWalk, node2vec, or LINE is run on this coarsened graph. After embedding the coarsened version of G, the learned embedding of each supernode is used as an initial value for the random walk embeddings of the supernode's constituent nodes (in another round of optimization on a "finer-grained" version of the graph). This general process can be repeated in a hierarchical manner at varying levels of coarseness, and has been shown to consistently improve performance of DeepWalk, node2vec, and LINE <ref type="bibr" target="#b12">[13]</ref>.</p><p>Additional variants of the random-walk idea. There have also been a number of further extensions of the random walk idea. For example, Perozzi et al. <ref type="bibr" target="#b47">[48]</ref> extend the DeepWalk algorithm to learn embeddings using random walks that "skip" or "hop" over multiple nodes at each step, resulting in a similarity measure similar to GraRep <ref type="bibr" target="#b8">[9]</ref>, while Chamberlan et al. <ref type="bibr" target="#b10">[11]</ref> modify the inner-product decoder of node2vec to use a hyperbolic, rather than Euclidean, distance measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Generalized encoder-decoder architectures</head><p>So far all of the node embedding methods we have reviewed have been shallow embedding methods, where the encoder is a simply an embedding lookup (Equation <ref type="formula" target="#formula_7">5</ref>). However, these shallow embedding approaches train unique embedding vectors for each node independently, which leads to a number of drawbacks:</p><p>1. No parameters are shared between nodes in the encoder (i.e., the encoder is simply an embedding lookup based on arbitrary node ids). This can be statistically inefficient, since parameter sharing can act as a powerful form of regularization, and it is also computationally inefficient, since it means that the number of parameters in shallow embedding methods necessarily grows as O(|V|).</p><p>2. Shallow embedding also fails to leverage node attributes during encoding. In many large graphs nodes have attribute information (e.g., user profiles on a social network) that is often highly informative with respect to the node's position and role in the graph.</p><p>3. Shallow embedding methods are inherently transductive <ref type="bibr" target="#b28">[29]</ref>, i.e., they can only generate embeddings for nodes that were present during the training phase, and they cannot generate embeddings for previously unseen nodes unless additional rounds of optimization are performed to optimize the embeddings for these nodes. This is highly problematic for evolving graphs, massive graphs that cannot be fully stored in memory, or domains that require generalizing to new graphs after training. Recently, a number of approaches have been proposed to address some, or all, of these issues. These approaches still fall firmly within the encoder-decoder framework outlined in Section 2.1, but they differ from the shallow embedding methods of Section 2.2 in that they use a more complex encoders, often based on deep neural networks and which depend more generally on the structure and attributes of the graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Neighborhood autoencoder methods</head><p>Deep Neural Graph Representations (DNGR) <ref type="bibr" target="#b9">[10]</ref> and Structural Deep Network Embeddings (SDNE) <ref type="bibr" target="#b58">[59]</ref> address the first problem outlined above: unlike the shallow embedding methods, they directly incorporate graph structure into the encoder algorithm using deep neural networks. The basic idea behind these approaches is that they use autoencoders-a well known approach for deep learning <ref type="bibr" target="#b30">[31]</ref>-in order to compress information about a node's local neighborhood (Figure <ref type="figure">6</ref>). DNGR and SDNE also differ from the previously reviewed approaches in that they use a unary decoder instead of a pairwise one. In these approaches, each node, v i , is associated with a neighborhood vector, s i ? R |V| , which corresponds to v i 's row in the matrix S (recall that S contains pairwise node similarities, i.e., S i,j = s G (v i , v j )). The s i vector contains v i 's similarity with all other nodes in the graph and functions as a high-dimensional vector representation of v i 's neighborhood. The autoencoder objective for DNGR and SDNE is to embed nodes using the s i vectors such that the s i vectors can then be reconstructed from these embeddings:</p><formula xml:id="formula_18">DEC(ENC(s i )) = DEC(z i ) ? s i .<label>(13)</label></formula><p>In other words, the loss for these methods takes the following form:</p><formula xml:id="formula_19">L = v i ?V DEC(z i ) -s i 2 2 . (<label>14</label></formula><formula xml:id="formula_20">)</formula><p>As with the pairwise decoder, we have that the dimension of the z i embeddings is much smaller than |V| (the dimension of the s i vectors), so the goal is to compress the node's neighborhood information into a lowdimensional vector. For both SDNE and DNGR, the encoder and decoder functions consist of multiple stacked neural network layers: each layer of the encoder reduces the dimensionality of its input, and each layer of the decoder increases the dimensionality of its input (Figure <ref type="figure">6</ref>; see <ref type="bibr" target="#b30">[31]</ref> for an overview of deep autoencoders). To generate an embedding for node A, the model aggregates messages from A's local graph neighbors (i.e., B, C, and D), and in turn, the messages coming from these neighbors are based on information aggregated from their respective neighborhoods, and so on. A "depth-2" version of this idea is shown (i.e., information is aggregated from a two-hop neighborhood around node A), but in principle these methods can be of an arbitrary depth. At the final "depth" or "layer" the initial messages are based on the input node attributes. SDNE and DNGR differ in the similarity functions they use to construct the neighborhood vectors s i and also in the exact details of how the autoencoder is optimized. DNGR defines s i according to the pointwise mutual information of two nodes co-occurring on random walks, similar to DeepWalk and node2vec. SDNE simply sets s i A i , i.e., equal to v i 's adjacency vector. SDNE also combines the autoencoder objective (Equation <ref type="formula" target="#formula_18">13</ref>) with the Laplacian eigenmaps objective (Equation <ref type="formula" target="#formula_9">6</ref>) <ref type="bibr" target="#b58">[59]</ref>.</p><p>Note that the encoder in Equation ( <ref type="formula" target="#formula_18">13</ref>) depends on the input s i vector, which contains information about v i 's local graph neighborhood. This dependency allows SDNE and DNGR to incorporate structural information about a node's local neighborhood directly into the encoder as a form of regularization, which is not possible for the shallow embedding approaches (since their encoder depends only on the node id). However, despite this improvement, the autoencoder approaches still suffer from some serious limitations. Most prominently, the input dimension to the autoencoder is fixed at |V|, which can be extremely costly and even intractable for graphs with millions of nodes. In addition, the structure and size of the autoencoder is fixed, so SDNE and DNGR are strictly transductive and cannot cope with evolving graphs, nor can they generalize across graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Neighborhood aggregation and convolutional encoders</head><p>A number of recent node embedding approaches aim to solve the main limitations of the shallow embedding and autoencoder methods by designing encoders that rely on a node's local neighborhood, but not necessarily the entire graph. The intuition behind these approaches is that they generate embeddings for a node by aggregating information from its local neighborhood (Figure <ref type="figure" target="#fig_0">7</ref>).</p><p>Unlike the previously discussed methods, these neighborhood aggregation algorithms rely on node features or attributes (denoted x i ? R m ) to generate embeddings. For example, a social network might have text data (e.g., profile information), or a protein-protein interaction network might have molecular markers associated with each node. The neighborhood aggregation methods leverage this attribute information to inform their embeddings. In cases where attribute data is not given, these methods can use simple graph statistics as attributes (e.g., node degrees) <ref type="bibr" target="#b28">[29]</ref>, or assign each node a one-hot indicator vector as an attribute <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b52">53]</ref>. These methods are often called convolutional because they represent a node as a function of its surrounding neighborhood, in a manner similar to the receptive field of a center-surround convolutional kernel in computer vision <ref type="bibr" target="#b34">[35]</ref>. <ref type="foot" target="#foot_5">5</ref>In the encoding phase, the neighborhood aggregation methods build up the representation for a node in an iterative, or recursive, fashion (see Algorithm 1 for pseudocode). First, the node embeddings are initialized Algorithm 1: Neighborhood-aggregation encoder algorithm. Adapted from <ref type="bibr" target="#b28">[29]</ref>.</p><formula xml:id="formula_21">Input : Graph G(V, E); input features {x v , ?v ? V}; depth K; weight matrices {W k , ?k ? [1, K]}; non-linearity ?; differentiable aggregator functions {AGGREGATE k , ?k ? [1, K]}; neighborhood function N : v ? 2 V Output: Vector representations z v for all v ? V 1 h 0 v ? x v , ?v ? V ; 2 for k = 1...K do 3 for v ? V do 4 h k N (v) ? AGGREGATE k ({h k-1 u , ?u ? N (v)}); 5 h k v ? ? W k ? COMBINE(h k-1 v , h k N (v) ) 6 end 7 h k v ? NORMALIZE(h k v ), ?v ? V 8 end 9 z v ? h K v , ?v ? V</formula><p>to be equal to the input node attributes. Then at each iteration of the encoder algorithm, nodes aggregate the embeddings of their neighbors, using an aggregation function that operates over sets of vectors. After this aggregation, every node is assigned a new embedding, equal to its aggregated neighborhood vector combined with its previous embedding from the last iteration. Finally, this combined embedding is fed through a dense neural network layer and the process repeats. As the process iterates, the node embeddings contain information aggregated from further and further reaches of the graph. However, the dimensionality of the embeddings remains constrained as the process iterates, so the encoder is forced to compress all the neighborhood information into a low dimensional vector. After K iterations the process terminates and the final embedding vectors are output as the node representations.</p><p>There are a number of recent approaches that follow the basic procedure outlined in Algorithm 1, including graph convolutional networks (GCN) <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b55">56]</ref>, column networks <ref type="bibr" target="#b49">[50]</ref>, and the GraphSAGE algorithm <ref type="bibr" target="#b28">[29]</ref>. The trainable parameters in Algorithm 1-a set of aggregation functions and a set weight matrices {W k , ?k ? [1, K]}-specify how to aggregate information from a node's local neighborhood and, unlike the shallow embedding approaches (Section 2.2), these parameters are shared across nodes. The same aggregation function and weight matrices are used to generate embeddings for all nodes, and only the input node attributes and neighborhood structure change depending on which node is being embedded. This parameter sharing increases efficiency (i.e., the parameter dimensions are independent of the size of the graph), provides regularization, and allows this approach to be used to generate embeddings for nodes that were not observed during training <ref type="bibr" target="#b28">[29]</ref>.</p><p>GraphSAGE, column networks, and the various GCN approaches all follow Algorithm 1 but differ primarily in how the aggregation (line 4) and vector combination (line 5) are performed. GraphSAGE uses concatenation in line 5 and permits general aggregation functions; the authors experiment with using the element-wise mean, a max-pooling neural network and LSTMs <ref type="bibr" target="#b31">[32]</ref> as aggregators, and they found the the more complex aggregators, especially the max-pooling neural network, gave significant gains. GCNs and column networks use a weighted sum in line 5 and a (weighted) element-wise mean in line 4.</p><p>Column networks also add an additional "interpolation" term before line 7, setting</p><formula xml:id="formula_22">h k v = ?h k v + (1 -?)h k-1 v , (<label>15</label></formula><formula xml:id="formula_23">)</formula><p>where ? is an interpolation weight computed as a non-linear function of h k-1 v and h k-1 N (v) . This interpolation term allows the model to retain local information as the process iterates (i.e., as k increases and the model integrates information from further reaches of the graph).</p><p>In principle, the GraphSAGE, column network, and GCN encoders can be combined with any of the previously discussed decoders and loss functions, and the entire system can be optimized using SGD. For example, Hamilton et al. <ref type="bibr" target="#b28">[29]</ref> use an identical decoder and loss as node2vec, while Kipf et al. <ref type="bibr" target="#b35">[36]</ref> use a decoder and loss function similar to the Graph Factorization approach.</p><p>Neighborhood aggregation encoders following Algorithm 1 have been found to provide consistent gains compared to their shallow embedding counterparts on both node classification <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b34">35]</ref> and link prediction <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b52">53]</ref> benchmarks. At a high level, these approaches solve the four main limitations of shallow embeddings, noted at the beginning of Section 2.3: they incorporate graph structure into the encoder; they leverage node attributes; their parameter dimension can be made sub-linear in |V|; and they can generate embeddings for nodes that were not present during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Incorporating task-specific supervision</head><p>The basic encoder-decoder framework described thus far is by default unsupervised, i.e., the model is optimized, or trained, over set of node pairs to reconstruct pairwise similarity values s G (v i , v j ), which depend only on the graph G. However, many node embedding algorithms-especially the neighborhood aggregation approaches presented in Section 2.3.2-can also incorporate task-specific supervision <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b59">60]</ref>. In particular, it is common for methods incorporate supervision from node classification tasks in order to learn the embeddings. <ref type="foot" target="#foot_6">6</ref>For simplicity, we discuss the case where nodes have an associated binary classification label, but the approach we describe is easily extended to more complex classification settings.</p><p>Assume that we have a binary classification label, y i ? Z, associated with each node. To learn to map nodes to their labels, we can feed our embedding vectors, z i , through a logistic, or sigmoid, function ?i = ?(z i ?), where ? is a trainable parameter vector. We can then compute the cross-entropy loss between these predicted class probabilities and the true labels:</p><formula xml:id="formula_24">L = v i ?V y i log(?(ENC(v i ) ?)) + (1 -y i ) log(1 -?(ENC(v i ) ?)).<label>(16)</label></formula><p>The gradient computed according to Equation ( <ref type="formula" target="#formula_24">16</ref>) can then be backpropagated through the encoder to optimize its parameters. This task-specific supervision can completely replace the reconstruction loss computed using the decoder (i.e., Equation <ref type="formula" target="#formula_2">3</ref>) <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b34">35]</ref>, or it can be included along with the decoder loss <ref type="bibr" target="#b59">[60]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Extensions to multi-modal graphs</head><p>While we have focused on simple, undirected graphs, many real-world graphs have complex multi-modal, or multi-layer, structures (e.g., heterogeneous node and edge types), and a number of works have introduced strategies to cope with this heterogeneity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.1">Dealing with different node and edge types</head><p>Many graphs contain different types of nodes and edges. For example, recommender system graphs consist of two distinct layers-users and content-while many biological networks have a variety of layers, with distinct interactions between them (e.g., diseases, genes, and drugs).</p><p>A general strategy for dealing with this issue is to (i) use different encoders for nodes of different types <ref type="bibr" target="#b11">[12]</ref> and (ii) extend pairwise decoders with type-specific parameters <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b52">53]</ref>. For example, in graphs with varying The embeddings were generated using the multi-layer OhmNet method and projected to two dimensions using t-SNE. Adapted from <ref type="bibr" target="#b60">[61]</ref>.</p><p>edge types, the standard inner-product edge decoder (i.e., z i z j ? A i,j ) can be replaced with a bilinear form <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b52">53]</ref>:</p><formula xml:id="formula_25">DEC ? (z i , z j ) = z A ? z,<label>(17)</label></formula><p>where ? indexes a particular edge type and A ? is a learned parameter specific to edges of type ? . The matrix, A ? , in Equation ( <ref type="formula" target="#formula_25">17</ref>) can be regularized in various ways (e.g., constrained to be diagonal) <ref type="bibr" target="#b52">[53]</ref>, which can be especially useful when there are a large number of edge types, as in the case for embedding knowledge graphs. Indeed, the literature on knowledge-graph completion-where the goal is predict missing relations in knowledge graphs-contains many related techniques for decoding a large number of edge types (i.e., relations) <ref type="bibr" target="#b42">[43]</ref>. 7  Recently, Dong et al. <ref type="bibr" target="#b18">[19]</ref> also proposed a strategy for sampling random walks from heterogeneous graphs, where the random walks are restricted to only transition between particular types of nodes. This approach allows many of the methods in Section 2.2.2 to be applied on heterogeneous graphs and is complementary to the idea of including type-specific encoders and decoders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2">Tying node embeddings across layers</head><p>In some cases graphs have multiple "layers" that contain copies of the same nodes (Figure <ref type="figure" target="#fig_1">8</ref>.A). For example, in protein-protein interaction networks derived from different tissues (e.g., brain or liver tissue), some proteins occur across multiple tissues. In these cases it can be beneficial to share information across layers, so that a node's embedding in one layer can be informed by its embedding in other layers. Zitnik et al. <ref type="bibr" target="#b60">[61]</ref> offer one solution to this problem, called OhmNet, that combines node2vec with a regularization penalty that ties the embeddings across layers. In particular, assuming that we have a node v i , which belongs to two distinct layers G 1 and G 2 , we can augment the standard embedding loss on this node as follows:</p><formula xml:id="formula_26">L(v i ) = L(v i ) + ? z G 1 i -z G 2 i (<label>18</label></formula><formula xml:id="formula_27">)</formula><p>where L denotes the usual embedding loss for that node (e.g., from Equation <ref type="formula" target="#formula_11">8</ref>or 11), ? denotes the regularization strength, and z G 1 i and z G 2 i denote v i 's embeddings in the two different layers, respectively. Zitnik et al. further extend this idea by exploiting hierarchies between graph layers (Figure <ref type="figure" target="#fig_1">8</ref>.B). For example, in protein-protein interaction graphs derived from various tissues, some layers correspond to interactions throughout large regions (e.g., interactions that occur in any brain tissue) while other interaction graphs are more fine-grained (e.g., only interactions that occur in the frontal lobe). To exploit this structure, embeddings can be learned at the various levels of the hierarchy, and the regularization in Equation ( <ref type="formula" target="#formula_26">18</ref>) can recursively applied between layers that have a parent-child relationship in the hierarchy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Embedding structural roles</head><p>So far, all the approaches we have reviewed optimize node embeddings so that nearby nodes in the graph have similar embeddings. However, in many tasks it is more important to learn representations that correspond to the structural roles of the nodes, independent of their global graph positions (e.g., in communication or transportation networks) <ref type="bibr" target="#b29">[30]</ref>. The node2vec approach introduced in Section 2.2.2 offers one solution to this problem, as Grover et al. found that biasing the random walks allows their model to better capture structural roles (Figure <ref type="figure">5</ref>). However, more recently, Ribeiro et al. <ref type="bibr" target="#b50">[51]</ref> and Donnat et al. <ref type="bibr" target="#b19">[20]</ref> have developed node embedding approaches that are specifically designed to capture structural roles.</p><p>Ribeiro et al. propose struc2vec, which involves generating a a series of weighted auxiliary graphs G k , k = {1, 2, ...} from the original graph G, where the auxiliary graph G k captures structural similarities between nodes' k-hop neighborhoods. In particular, letting R k (v i ) denote the ordered sequence of degrees of the nodes that are exactly k-hops away from v i , the edge-weights, w k (v i , v j ), in auxiliary graph G k are recursively defined as</p><formula xml:id="formula_28">w k (v i , v j ) = w k-1 (v i , v j ) + d(R k (v i ), R k (v j )),<label>(19)</label></formula><p>where</p><formula xml:id="formula_29">w 0 (v i , v j ) = 0 and d(R k (v i ), R k (v j ))</formula><p>measures the "distance" between the ordered degree sequences R k (v i ) and R k (v j ) (e.g., computed via dynamic time warping <ref type="bibr" target="#b50">[51]</ref>). After computing these weighted auxillary graphs, struc2vec runs biased random walks over them and uses these walks as input to the node2vec optimization algorithm. Donnat et al. take a very different approach to capturing structural roles, called GraphWave, which relies on spectral graph wavelets and heat kernels <ref type="bibr" target="#b19">[20]</ref>. In brief, we let L denote the graph Laplacian-i.e., L = D -A where D contains node degrees on the diagonal and A is the adjacency matrix-and we let U and ? i , i = 1...|V| denote the eigenvector matrix and eigenvalues of L, respectively. Finally, we assume that we have a heat kernel, g(?) = e -s? , with pre-defined scale s. Using U and g(?), GraphWave computes a vector, ? v i , corresponding to the structural role of node, v i ? V, as</p><formula xml:id="formula_30">? v i = UGU v i<label>(20)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A B C D</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RolX Struc2vec GraphWave</head><p>Figure <ref type="figure">9</ref>: A, Synthetic barbell graph used as a test dataset for detecting structural roles, where nodes are colored according to their structural roles. In this case, the structural roles (i.e., colors) are computed by examining the degrees of each node's immediate neighbors, and their 2-hop neighbors, and so on (up to |V|-hop neighborhoods). B-D, Visualization of the output of three role-detection algorithms on the barbell graph, where the model outputs are projected using principal components analysis. RolX (B) <ref type="bibr" target="#b29">[30]</ref> is a baseline approach based upon hand-designed features, while struc2vec (C) and GraphWave (D) use different representation learning approaches. Note that all methods correctly differentiate the ends of the barbells from the rest of the graph, but only GraphWave is able to correctly differentiate all the various roles. Note also that there are fewer visible nodes in part D compared to A because GraphWave maps identically colored (i.e., structurally equivalent) nodes to the exact same position in the embedding space. Reprinted from <ref type="bibr" target="#b19">[20]</ref>.</p><p>where G = diag([g(? 1 ), ..., g(? |V| )]) and v i is a one-hot indicator vector corresponding to v i 's row/column in the Laplacian. <ref type="foot" target="#foot_8">8</ref> Donnat et al. show that these ? v i vectors implicitly relate to topological quantities, such as v i 's degree and the number of k-cycles v i is involved in. They find that-with a proper choice of scale, s-WaveGraph is able to effectively capture structural information about a nodes role in a graph (Figure <ref type="figure">9</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">Applications of node embeddings</head><p>The most common use cases for node embeddings are for visualization, clustering, node classification, and link prediction, and each of these use cases is relevant to a number of application domains, ranging from computational social science to computational biology.</p><p>Visualization and pattern discovery. The problem of visualizing graphs in a 2D interface has a long history, with applications throughout data mining, the social sciences, and biology <ref type="bibr" target="#b16">[17]</ref>. Node embeddings offer a powerful new paradigm for graph visualization: because nodes are mapped to real-valued vectors, researchers can easily leverage existing, generic techniques for visualization high-dimensional datasets <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b54">55]</ref>. For example, node embeddings can be combined with well-known techniques such as t-SNE <ref type="bibr" target="#b56">[57]</ref> or principal components analysis (PCA) in order to generate 2D visualizations of graphs <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b53">54]</ref>, which can be useful for discovering communities and other hidden structures (Figures <ref type="figure">2</ref> and<ref type="figure" target="#fig_1">8</ref>).</p><p>Clustering and community detection. In a similar vein as visualization, node embeddings are a powerful tool for clustering related nodes, a task that has countless applications from computational biology (e.g., discovering related drugs) to marketing (e.g., discovering related products) <ref type="bibr" target="#b22">[23]</ref>. Again, because each node is associated with real-valued vector embedding, it is possible to apply any generic clustering algorithm to the set of learned node embeddings (e.g., k-means or DB-scan <ref type="bibr" target="#b21">[22]</ref>).</p><p>This offers an open-ended and powerful alternative to traditional community detection techniques, and it also opens up new methodological opportunities, since node embeddings can capture the functional or structural roles played by different nodes, rather than just community structure.</p><p>Node classification and semi-supervised learning. Node classification is perhaps the most common benchmark task used for evaluating node embeddings. In most cases, the node classification task is a form of semisupervised learning, where labels are only available for a small proportion of nodes, with the goal being to label the full graph based only on this small initial seed set. Common applications of semi-supervised node classification include classifying proteins according to their biological function <ref type="bibr" target="#b27">[28]</ref> and classifying documents, videos, web pages, or individuals into different categories/communities <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b53">54]</ref>. Recently, Hamilton et al. <ref type="bibr" target="#b28">[29]</ref> introduced the task of inductive node classification, where the goal is to classify nodes that were not seen during training, e.g. classifying new documents in evolving information graphs or generalizing to unseen protein-protein interaction networks. Link prediction. Node embeddings are also extremely useful as features for link prediction, where the goal is to predict missing edges, or edges that are likely to form in the future <ref type="bibr" target="#b2">[3]</ref>. Link prediction is at the core of recommender systems and common applications of node embeddings reflect this deep connection, including predicting missing friendship links in social networks <ref type="bibr" target="#b53">[54]</ref> and affinities between users and movies <ref type="bibr" target="#b55">[56]</ref>. Link prediction also has important applications in computational biology. Many biological interaction graphs (e.g., between proteins and other proteins, or drugs and diseases) are incomplete, since they rely on data obtained from costly lab experiments. Predicting links in these noisy graphs is an important method for automatically expanding biological datasets and for recommending new directions for wet-lab experimentation <ref type="bibr" target="#b40">[41]</ref>. More generally, link prediction is closely related to statistical relational learning <ref type="bibr" target="#b23">[24]</ref>, where a common task is to predict missing relations between entities in a knowledge graph <ref type="bibr" target="#b42">[43]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Embedding subgraphs</head><p>We now turn to the task of representation learning on (sub)graphs, where the goal is to encode a set of nodes and edges into a low-dimensional vector embedding. More formally, the goal is to learn a continuous vector representation, z S ? R d , of an induced subgraph G[S] of the full graph G, where S ? V. Note that these methods can embed both subgraphs (S ? V) as well as entire graphs (S = V). The embedding, z S , can then be used to make predictions about the entire subgraph; for example, one might embed graphs corresponding to different molecules to predict their therapeutic properties <ref type="bibr" target="#b20">[21]</ref>.</p><p>Representation learning on subgraphs is closely related to the design of graph kernels, which define a distance measure between subgraphs <ref type="bibr" target="#b57">[58]</ref>. That said, we omit a detailed discussion of graph kernels, which is a large and rich research area of its own, and refer the reader to <ref type="bibr" target="#b57">[58]</ref> for a detailed discussion. The methods we review differ from the traditional graph kernel literature primarily in that we seek to learn useful representations from data, rather than pre-specifying feature representations through a kernel function.</p><p>Many of the methods in this section build upon the techniques used to embed individual nodes, introduced in Section 2. However, unlike the node embedding setting, most subgraph embedding approaches are fullysupervised, being used for subgraph classification, where the goal is to predict a label associated with a particular subgraph. Thus, in this section we will focus on the various different approaches for generating the z S embeddings, with the assumption that these embeddings are being fed through a cross-entropy loss function, analogous to Equation (16).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Sets of node embeddings and convolutional approaches</head><p>There are several subgraph embedding techniques that can be viewed as direct extensions of the convolutional node embedding algorithms (described in Section 2.3.2). The basic intuition behind these approaches is that they equate subgraphs with sets of node embeddings. They use the convolutional neighborhood aggregation idea (i.e., Algorithm 1) to generate embeddings for nodes and then use additional modules to aggregate sets of node embeddings corresponding to subgraphs. The primary distinction between the different approaches in this section is how they aggregate the set of node embeddings corresponding to a subgraph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Sum-based approaches</head><p>For example, "convolutional molecular fingerprints" introduced by Duvenaud et al. <ref type="bibr" target="#b20">[21]</ref> represent subgraphs in molecular graph representations by summing all the individual node embeddings in the subgraph:</p><formula xml:id="formula_31">z S = v i ?S z i ,<label>(21)</label></formula><p>where the embeddings, {z i , ?v i ? S}, are generated using a variant of Algorithm 1. Dai et al. <ref type="bibr" target="#b15">[16]</ref> employ an analogous sum-based approach but note that it has conceptual connections to meanfield inference: if the nodes in the graph are viewed as latent variables in a graphical model, then Algorithm 1 can be viewed as a form of mean-field inference where the message-passing operations have been replaced with differentiable neural network alternatives. Motivated by this connection, Dai et al. <ref type="bibr" target="#b15">[16]</ref> also propose a modified encoder based on Loopy Belief Propagation <ref type="bibr" target="#b41">[42]</ref>. Using the placeholders and notation from Algorithm 1, the basic idea behind this alternative is to construct intermediate embeddings, ? i,j , corresponding to edges, (i, j) ? E:</p><formula xml:id="formula_32">? k i,j = ?(W k E ? COMBINE(x i , AGGREGATE(? k-1 l,i , ?v l ? N (v i ) \ v j })).<label>(22)</label></formula><p>These edge embeddings are then aggregated to form the node embeddings:</p><formula xml:id="formula_33">z i = ?(W k V ? COMBINE(x i , AGGREGATE({? K i,l , ?v l ? N (v i )})).<label>(23)</label></formula><p>Once the embeddings are computed, Dai et al. <ref type="bibr" target="#b15">[16]</ref>, use a simple element-wise sum to combine the node embeddings for a subgraph, as in Equation ( <ref type="formula" target="#formula_31">21</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Graph-coarsening approaches</head><p>Defferrard et al. <ref type="bibr" target="#b17">[18]</ref> and Bruna et al. <ref type="bibr" target="#b7">[8]</ref> also employ convolutional approaches, but instead of summing the node embeddings for the whole graph, they stack convolutional and "graph coarsening" layers (similar to the HARP approach in Section 2.2.2). In the graph coarsening layers, nodes are clustered together (using any graph clustering approach), and the clustered node embeddings are combined using element-wise max-pooling. After clustering, the new coarser graph is again fed through a convolutional encoder and the process repeats. Unlike the convolutional approaches discussed in 2.3.2, Defferrard et al. <ref type="bibr" target="#b17">[18]</ref> and Bruna et al. <ref type="bibr" target="#b7">[8]</ref> also place considerable emphasis on designing convolutional encoders based upon the graph Fourier transform <ref type="bibr" target="#b14">[15]</ref>. However, because the graph Fourier transform requires identifying and manipulating the eigenvectors of the graph Laplacian, naive versions of these approaches are necessarily O(|V| 3 ). State-of-the-art approximations to these spectral approaches (e.g. , using Chebyshev polynomials) are conceptually similar to Algorithm 1, with some minor variations, and we refer the reader to Bronstein et al. <ref type="bibr" target="#b6">[7]</ref> for a thorough discussion of these techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Further variations</head><p>Other variants of the convolutional idea are proposed by Neipert et al. <ref type="bibr" target="#b43">[44]</ref> and Kearnes et al. <ref type="bibr" target="#b33">[34]</ref>. Both advocate alternative methods for aggregating sets of node embeddings corresponding to subgraphs: Kearnes et al. aggregate sets of nodes using "fuzzy" histograms instead of a sum, and they also employ edge embedding layers similar to <ref type="bibr" target="#b15">[16]</ref>. Neipart et al. define an ordering on the nodes-e.g. using a problem specific ordering or by employing an off-the-shelf vertex coloring algorithm-and using this ordering, they concatenate the embeddings for all nodes and feed this concatenated vector through a standard convolutional neural network architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Graph neural networks</head><p>In addition to the convolution-inspired embedding approaches discussed above, there is a related-and chronologically prior-line of work on "graph neural networks" (GNNs) <ref type="bibr" target="#b51">[52]</ref>. Conceptually, the GNN idea is closely related to Algorithm 1. However, instead of aggregating information from neighbors, the intuition behind GNNs is that graphs can be viewed as specifying scaffolding for a "message passing" algorithm between nodes.</p><p>In the original GNN framework <ref type="bibr" target="#b51">[52]</ref> every node v i is initialized with a random embedding h 0 i , and at each iteration of the GNN algorithm nodes accumulate inputs from their neighbors according to</p><formula xml:id="formula_34">h k i = v j ?N (v i ) h(h j , x i , x j ),<label>(24)</label></formula><p>where h is an arbitrary differentiable function of the form h : <ref type="formula" target="#formula_34">24</ref>) is repeatedly applied in a recursive fashion until the embeddings converge, and special care must be taken to ensure that h is a contraction map. Once the embeddings have converged after K iterations, the final output embeddings are computed as z v i = g(h K i ), where g is an arbitrary differentiable function of the form g : R d ? R d . Scarselli et al. <ref type="bibr" target="#b51">[52]</ref> discuss various parameterizations of h and g based on multi-layer perceptrons (MLPs), though they are limited by the need to iterate the message passing to convergence and by the restriction that f must be a contraction map.</p><formula xml:id="formula_35">R d ? R m ? R m ? R d . Equation (</formula><p>Li et al. <ref type="bibr" target="#b38">[39]</ref> extend and modify the GNN framework to use Gated Recurrent Units and back propagation through time <ref type="bibr" target="#b13">[14]</ref>, which removes the need to run Equation <ref type="bibr" target="#b23">(24)</ref> to convergence. Adapting the GNN framework to use modern recurrent units also allows Li et al. to leverage node attributes for initialization and to use the output of intermediate embeddings of subgraphs. In particular, Li et al.'s Gated Graph Neural Networks initialize the h 0 i vectors using node attributes (i.e., h 0 i = x i ) and have update equations of the form</p><formula xml:id="formula_36">h k i = GRU ? ? h k-1 i , v j ?N (v i ) Wh k-1 j ? ? ,<label>(25)</label></formula><p>where W ? R d?d is a trainable weight matrix and GRU denotes the Gated Recurrent Unit introduced by Cho et al. <ref type="bibr" target="#b13">[14]</ref>. Finally, Gilmer et al. <ref type="bibr" target="#b24">[25]</ref> discuss another abstraction of GNNs, considering models of the form</p><formula xml:id="formula_37">h k i = U ? ? h k-1 i , v j ?N (v i ) q(h k-1 i , h k-1 j ) ? ? ,<label>(26)</label></formula><p>where All of these graph neural network approaches can in principle be used for node-level embedding tasks, though they are more often used for subgraph-level embeddings. To compute subgraph embeddings, any of the aggregation procedures described in Section 3.1 could be employed, but Scarselli et al. <ref type="bibr" target="#b51">[52]</ref> also suggest that the aggregation can be done by introducing a "dummy" super-node that is connected to all nodes in the target subgraph.</p><formula xml:id="formula_38">q : R d ? R d ? R d is</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Applications of subgraph embeddings</head><p>The primary use case for subgraph embeddings is for subgraph classification, which has important applications in a number of areas. The most prominent application domain is for classifying the properties of graphs corresponding to different molecules <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b33">34]</ref>. Subgraph embeddings can be used to classify or predict various properties of molecular graphs, including predicting the efficacy of potential solar cell materials <ref type="bibr" target="#b15">[16]</ref>, or predicting the therapeutic effect of candidate drugs <ref type="bibr" target="#b33">[34]</ref>. More generally, subgraph embeddings have been used to classify images (after converting the image to a graph representation) <ref type="bibr" target="#b7">[8]</ref>, to predict whether a computer program satisfies certain formal properties <ref type="bibr" target="#b38">[39]</ref>, and to perform logical reasoning tasks <ref type="bibr" target="#b38">[39]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and future directions</head><p>Representation learning approaches for machine learning on graphs offer a power alternative to traditional feature engineering. In recent years, these approaches have consistently pushed the state of the art on tasks such as node classification and link prediction. However, much work remains to be done, both in improving the performance of these methods, and-perhaps more importantly-in developing consistent theoretical frameworks that future innovations can build upon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Challenges to future progress</head><p>In this review, we attempted to unify a number of previous works, but the field as a whole still lacks a consistent theoretical framework-or set of frameworks-that precisely delineate the goals of representation learning on graphs. At the moment, the implicit goal of most works is to generate representations that perform well on a particular set of classification or link prediction benchmarks (and perhaps also generate qualitatively pleasing visualizations). However, the unchecked proliferation of disparate benchmarks and conceptual models presents a real risk to future progress, and this problem is only exacerbated by the popularity of node and graph embedding techniques across distinct, and somewhat disconnected, subfields within the machine learning and data mining communities. Moving forward as a field will require new theoretical work that more precisely describes the kinds of graph structures that we expect the learned representations to encode, how we expect the models to encode this information, and what constraints (if any) should be imposed upon on these learned latent spaces.</p><p>More developed theoretical foundations would not only benefit researchers in the field-e.g., by informing consistent and meaningful benchmark tasks-these foundations would also allow application domain-experts to more effectively choose and differentiate between the various approaches. Current methods are often evaluated on a variety of distinct benchmarks that emphasize various different graph properties (e.g., community structures, relationship strengths between nodes, or structural roles). However, many real-world applications are more focused, and it is not necessary to have representations that are generically useful for a wide variety of tasks. As a field, we need to make it clear what method should be used when, and prescribing such use-cases requires a more precise theoretical understanding of what exactly our learned representations are encoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Important open problems</head><p>In addition to the general challenges outlined above, there are a number of concrete open problems that remain to be addressed within the area of representation learning on graphs. Scalability. While most of the works we reviewed are highly scalable in theory (i.e., O(|E|) training time), there is still significant work to be done in scaling node and graph embedding approaches to truly massive datasets (e.g., billions of nodes and edges). For example, most methods rely on training and storing a unique embedding for each individual node. Moreover, most evaluation setups assume that the attributes, embeddings, and edge lists of all nodes used for both training and testing can fit in main memory-an assumption that is at odds with the reality of most application domains, where graphs are massive, evolving, and often stored in a distributed fashion. Developing representation learning frameworks that are truly scalable to realistic production settings is necessary to prevent widening the disconnect between the academic research community and the application consumers of these approaches. Decoding higher-order motifs. While much work in recent years has been dedicated to refining and improving the encoder algorithm used to generate node embeddings, most methods still rely on basic pairwise decoders, which predict pairwise relations between nodes and ignore higher-order graph structures involving more than two nodes. It is well-known that higher-order structural motifs are essential to the structure and function of complex networks <ref type="bibr" target="#b4">[5]</ref>, and developing decoding algorithms that are capable of decoding complex motifs is an important direction for future work. Modeling dynamic, temporal graphs. Many application domains involve highly dynamic graphs where timing information is critical-e.g., instant messaging networks or financial transaction graphs. However, we lack embedding approaches that can cope with the unique challenges presented by temporal graphs, such as the task of incorporating timing information about edges. Temporal graphs are becoming an increasingly important object of study <ref type="bibr" target="#b45">[46]</ref>, and extending graph embedding techniques to operate over them will open up a wide range of exciting application domains. Reasoning about large sets of candidate subgraphs. A major technical limitation of current subgraph embedding approaches is that they require the target subgraphs to be pre-specified before the learning process. However, many applications seek to discover subgraphs with certain properties, and these applications require models that can reason over the combinatorially large space of possible candidate subgraphs. For example, one might want to discover central subgraphs in a gene regulatory network, or uncover nefarious sub-communities in a social network. We need improved subgraph embedding approaches that can efficiently reason over large sets of candidate subgraphs, as such improvements are critical to expand the usefulness of subgraph embeddings beyond the task of basic subgraph classification. Improving interpretability. Representation learning is attractive because it relieves much of the burden of hand designing features, but it also comes at a well-known cost of interpretability. We know that embeddingbased approaches give state-of-the-art performance, but the fundamental limitations-and possible underlying biases-of these algorithms are relatively unknown. In order to move forward, care must be taken to develop new techniques to improve the interpretability of the learned representations, beyond visualization and benchmark evaluation. Given the complexities and representational capacities of these approaches, researchers must be ever vigilant to ensure that their methods are truly learning to represent relevant graph information, and not just exploiting statistical tendencies of benchmarks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 7 :</head><label>7</label><figDesc>Figure7: Overview of encoding in the neighborhood aggregation methods. To generate an embedding for node A, the model aggregates messages from A's local graph neighbors (i.e., B, C, and D), and in turn, the messages coming from these neighbors are based on information aggregated from their respective neighborhoods, and so on. A "depth-2" version of this idea is shown (i.e., information is aggregated from a two-hop neighborhood around node A), but in principle these methods can be of an arbitrary depth. At the final "depth" or "layer" the initial messages are based on the input node attributes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: A, Example of a 4-layer graph, where the same nodes occur in multiple different layers.This multi-layer structure can be exploited to regularize learning at the different layers by requiring that the embeddings for the same node in different layers are similar to each other. B, Multi-layer graphs can exhibit hierarchical structure, where non-root layers in the hierarchy contain the union of the edges present in their child layers-e.g., a biological interaction graph derived from the entire human brain contains the union of the interactions in the frontal and temporal lobes. This structure can be exploited by learning embeddings at various levels of the hierarchy, and only applying the regularization between layers that are in a parent-child relationship. C-E, Example application of multi-layer graph embedding to protein-protein interaction graphs derived from different brain tissues; C shows the hierarchy between the different tissue regions, while D and E visualize the protein embeddings generated at the brainstem and whole-brain layers. The embeddings were generated using the multi-layer OhmNet method and projected to two dimensions using t-SNE. Adapted from<ref type="bibr" target="#b60">[61]</ref>.</figDesc><graphic url="image-9.png" coords="14,90.45,211.51,413.10,129.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-3.png" coords="3,96.30,72.00,437.40,147.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-4.png" coords="4,93.49,72.00,397.90,135.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>A summary of some well-known shallow embedding embedding algorithms. Note that the decoders and similarity functions for the random-walk based methods are asymmetric, with the similarity function p G (v j |v i ) corresponding to the probability of visiting v j on a fixed-length random walk starting from v i .</figDesc><table><row><cell>Type</cell><cell>Method</cell><cell>Decoder</cell><cell>Similarity measure</cell><cell>Loss function ( )</cell></row><row><cell></cell><cell>Laplacian Eigenmaps [4]</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>To generate an embedding for a node, v i , the neighborhood autoencoder approaches first extract a highdimensional neighborhood vector s i ? R |V| , which summarizes v i 's similarity to all other nodes in the graph. The s i vector is then fed through a deep autoencoder to reduce its dimensionality, producing the low-dimensional z i embedding.</figDesc><table><row><cell></cell><cell>s i</cell><cell></cell><cell>?i</cell></row><row><cell></cell><cell></cell><cell>z i</cell><cell></cell></row><row><cell>v i</cell><cell>(s i 2 R |V| contains v i 's proximity to all other nodes) 1. Extract high-dimensional neighborhood vector</cell><cell>?</cell><cell>?</cell></row><row><cell></cell><cell cols="3">2. Compress s i to low-dimensional embedding, z i (using deep autoencoder)</cell></row><row><cell>Figure 6:</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>a differentiable function that computes the incoming "messages" from neighbors and U : R d ?R d ? R d is a differentiable "update" function. This framework-termed Message Passing Neural Networks (MPNNs)-generalizes Li et al.'s Gated Graph Neural Networks as well as a number of the earlier mentioned convolutional approaches. Gilmer et al. discuss a number of variants and extensions of MPNNs (e.g., incorporating edge features) from the perspective of predicting the properties of molecules based on their graph structure.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>For this and all subsequent reprinted figures, the original authors retain their copyrights, and permission was obtained from the corresponding author.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Most of the methods we review are easily generalized to work with weighted or directed graphs, and we will explicitly describe how to generalize certain methods to the multi-modal setting (i.e., differing node and edge types).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Occasionally, different methods will add additional auxiliary objectives or regularizers beyond the standard encoder-decoder objective, but we will often omit these details for brevity. A few methods also optimize parameters in the decoder, ?DEC.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>DEC(z i , z j ) = z i z j ,(7)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4"><p>Of course, Ahmed et al.<ref type="bibr" target="#b0">[1]</ref> were not the first researchers to propose factorizing an adjacency matrix, but they were the first to present a scalable O(|E|) algorithm for the purpose of generating node embeddings.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5"><p>These methods also have theoretical connections to approximate spectral kernels on graphs<ref type="bibr" target="#b17">[18]</ref>; see<ref type="bibr" target="#b34">[35]</ref> for a further discussion.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_6"><p>The unsupervised pairwise decoder is already naturally aligned with the link prediction task.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_7"><p>We do not review this literature in detail here, and refer the reader to Nickel et al.<ref type="bibr" target="#b42">[43]</ref> for a recent review.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_8"><p>Note that Equation (20) can be efficiently approximated via Chebyshev polynomials<ref type="bibr" target="#b19">[20]</ref>.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>The authors thank <rs type="person">Marinka Zitnik</rs>, <rs type="person">Zoubin Ghahramani</rs>, <rs type="person">Richard Turner</rs>, <rs type="person">Stephen Bach</rs>, and <rs type="person">Manan Ajay Shah</rs> for their helpful discussions and comments on early drafts. This research has been supported in part by <rs type="funder">NSF</rs> <rs type="grantNumber">IIS-1149837</rs>, <rs type="funder">DARPA SIMPLEX, Stanford Data Science Initiative</rs>, and <rs type="person">Chan Zuckerberg Biohub</rs>. W.L.H. was also supported by the <rs type="grantName">SAP Stanford Graduate Fellowship</rs> and an <rs type="funder">NSERC</rs> <rs type="grantName">PGS-D grant</rs>. The views and conclusions expressed in this material are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the above funding agencies, corporations, or the U.S. and <rs type="funder">Canadian governments</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Q8t4eyZ">
					<idno type="grant-number">IIS-1149837</idno>
				</org>
				<org type="funding" xml:id="_spQd6tc">
					<orgName type="grant-name">SAP Stanford Graduate Fellowship</orgName>
				</org>
				<org type="funding" xml:id="_SQ22et2">
					<orgName type="grant-name">PGS-D grant</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Distributed large-scale natural graph factorization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shervashidze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narayanamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Josifovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Survey of graph database models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Angles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gutierrez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Supervised random walks: predicting and recommending links in social networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Backstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Laplacian eigenmaps and spectral techniques for embedding and clustering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Higher-order organization of complex networks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Gleich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">353</biblScope>
			<biblScope unit="issue">6295</biblScope>
			<biblScope unit="page" from="163" to="166" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Node classification in social networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bhagat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Muthukrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Social Network Data Analytics</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="115" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Geometric deep learning: Going beyond euclidean data</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="18" to="42" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Spectral networks and locally connected networks on graphs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Grarep: Learning graph representations with global structural information</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep neural networks for learning graph representations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Deisenroth</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10359</idno>
		<title level="m">Neural embeddings of graphs in hyperbolic space</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Heterogeneous network embedding via deep architectures</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Harp: Hierarchical representation learning for networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.07845</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Merri?nboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">Fan</forename><surname>Rk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chung</forename></persName>
		</author>
		<title level="m">Spectral Graph Theory</title>
		<imprint>
			<publisher>American Mathematical Soc</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">92</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Discriminative embeddings of latent variable models for structured data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">From visual data exploration to visual data mining: a survey</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C F</forename><surname>De Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Levkowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="378" to="394" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">metapath2vec: Scalable representation learning for heterogeneous networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Donnat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hallac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10321</idno>
		<title level="m">Learning structural node embeddings via diffusion wavelets</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Convolutional networks on graphs for learning molecular fingerprints</title>
		<author>
			<persName><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Iparraguirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bombarell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A density-based algorithm for discovering clusters in large spatial databases with noise</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Community detection in graphs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fortunato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics Reports</title>
		<imprint>
			<biblScope unit="volume">486</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="75" to="174" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Introduction to Statistical Relational Learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Taskar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Neural Message Passing for Quantum Chemistry</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A new model for learning in graph domains</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Monfardini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Scarselli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Joint Conference on Neural Networks</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ferrara</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.09096</idno>
		<title level="m">Graph embedding techniques, applications, and performance: A survey</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04467</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Rolx: structural role extraction &amp; mining in large graphs</title>
		<author>
			<persName><forename type="first">K</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Eliassi-Rad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Akoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koutra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="issue">5786</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Latent space approaches to social network analysis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Handcock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JASA</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">460</biblScope>
			<biblScope unit="page" from="1090" to="1098" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Molecular graph convolutions: moving beyond fingerprints</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Berndl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Riley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer-Aided Molecular Design</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="595" to="608" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Variational graph auto-encoders</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Bayesian Deep Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Nonlinear dimensionality reduction</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Verleysen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Gated graph sequence neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The link-prediction problem for social networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liben-Nowell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1019" to="1031" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Link-based classification</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="496" to="503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Loopy belief propagation for approximate inference: An empirical study</title>
		<author>
			<persName><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A review of relational machine learning for knowledge graphs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gabrilovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="33" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning convolutional neural networks for graphs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Niepert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kutzkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Asymmetric transitivity preserving graph embedding</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Motifs in temporal networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Paranjape</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.02115</idno>
		<title level="m">Walklets: Multiscale graph embeddings for interpretable network classification</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Local Modeling of Attributed Graphs: Algorithms and Applications</title>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
		<respStmt>
			<orgName>Stony Brook University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Column networks for collective classification</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Q</forename><surname>Phung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">struc2vec: Learning node representations from structural identity</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F R</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H P</forename><surname>Saverese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">The graph neural network model</title>
		<author>
			<persName><forename type="first">F</forename><surname>Scarselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hagenbuchner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Monfardini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="80" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van Den Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.06103</idno>
		<title level="m">Modeling relational data with graph convolutional networks</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Line: Large-scale information network embedding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A global geometric framework for nonlinear dimensionality reduction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">De</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Langford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5500</biblScope>
			<biblScope unit="page" from="2319" to="2323" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Van Den Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02263</idno>
		<title level="m">Graph convolutional matrix completion</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Graph kernels</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V N</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Schraudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1201" to="1242" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Structural deep network embedding</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Revisiting semi-supervised learning with graph embeddings</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Predicting multicellular function through multi-layer tissue networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
