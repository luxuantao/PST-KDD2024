<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">L</forename><surname>Fang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Electrical and Information Engineering</orgName>
								<orgName type="institution">Hunan University</orgName>
								<address>
									<postCode>410082</postCode>
									<settlement>Changsha</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution">Duke University</orgName>
								<address>
									<postCode>27708</postCode>
									<settlement>Durham</settlement>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">College of Electrical and Information Engineering</orgName>
								<orgName type="institution">Hunan University</orgName>
								<address>
									<postCode>410082</postCode>
									<settlement>Changsha</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution">Duke University</orgName>
								<address>
									<postCode>27708</postCode>
									<settlement>Durham</settlement>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">62B9D4726272B01170FEDA6DA5BC4CE8</idno>
					<idno type="DOI">10.1109/TMI.2016.2611503</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TMI.2016.2611503, IEEE Transactions on Medical Imaging IEEE Transactions on Medical Imaging 1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Optical coherence tomography</term>
					<term>retina</term>
					<term>ophthalmic imaging</term>
					<term>image reconstruction</term>
					<term>sparse representation</term>
					<term>denoising</term>
					<term>interpolation</term>
					<term>layer segmentation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We demonstrate the usefulness of utilizing a segmentation step for improving the performance of sparsity based image reconstruction algorithms. In specific, we will focus on retinal optical coherence tomography (OCT) reconstruction and propose a novel segmentation based reconstruction framework with sparse representation, termed segmentation based sparse reconstruction (SSR). The SSR method uses automatically segmented retinal layer information to construct layer-specific structural dictionaries. In addition, the SSR method efficiently exploits patch similarities within each segmented layer to enhance the reconstruction performance. Our experimental results on clinical-grade retinal OCT images demonstrate the effectiveness and efficiency of the proposed SSR method for both denoising and interpolation of OCT images.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>reconstruction problems in the image processing <ref type="bibr" target="#b6">[7]</ref>. In the past decade, various models have been proposed to reconstruct high quality OCT images for various applications <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref>. Classical reconstruction approaches often construct a smoothness priori based model (e.g., anisotropic filtering, Tikhonov filtering, and total variation <ref type="bibr" target="#b8">[9]</ref>), and reconstruct the image in spatial domain. Some recent approaches transform the input degraded image into another domain (e.g., using the wavelet transformation <ref type="bibr" target="#b17">[18]</ref>, dual tree complex wavelet transformation <ref type="bibr" target="#b18">[19]</ref>, and curvelets transformation <ref type="bibr" target="#b19">[20]</ref>). While the transform based methods (e.g. wavelet) usually achieve a better reconstruction performance than the spatial domain methods, they are built on a fixed mathematical model and may have limited adaptability <ref type="bibr" target="#b20">[21]</ref> for representing structures inocular OCT volumes.</p><p>Inspired by the sparse coding mechanism of human vision system <ref type="bibr" target="#b21">[22]</ref>, the sparse representation is demonstrated to be a powerful tool for many image processing applications <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref>. The sparse representation decomposes an input image into a linear combination of an over-complete dictionary of basis functions. Basis functions can be chosen from a set of training images similar to the input image <ref type="bibr" target="#b30">[31]</ref> and thus can be more adaptive for the representation of specific features. Several recent works have also applied the sparse representation to OCT image reconstruction problems <ref type="bibr">[4, 6, 12, 14-16, 24, 32-34]</ref>. While different retinal layers have varied pathologic structures <ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref> and even speckle patterns, most of the sparse reconstruction methods only train one general dictionary to represent complex structures and textures in the ocular OCT images.</p><p>The above traditional sparse model directly decomposes each local image patch. Both heavy noise in the test patch and high correlations in the dictionary atoms <ref type="bibr" target="#b22">[23]</ref> may mislead the sparse decomposition process, thus negatively affecting the final reconstruction. More recently, a nonlocal sparse reconstruction model <ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref> has been introduced, which exploits the nonlocal patch self-similarities to improve the reconstruction. Specifically, for each processed patch, the nonlocal based sparse model searches similar patches from the whole image (or a large searching window) and then jointly decomposes the similar patches on the dictionary <ref type="bibr" target="#b39">[40]</ref> to find a more accurate sparse solution. Nonetheless, the nonlocal based sparse representation requires searching the whole image to find the similar patches, which creates very high computational burdens and also will be interfered by the heavy noise in the OCT image. Therefore, how to construct effective spare dictionaries for representing complex structures and efficiently exploiting patch self-similarities for accurate sparse decomposition are the two key issues in the sparse reconstruction model.</p><p>In this paper, we utilize the segmentation algorithm for OCT image reconstruction. We particularly focus on the retina, a layered structure where each layer has its own specific features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Segmentation Based Sparse Reconstruction of Optical Coherence Tomography Images IEEE Transactions on Medical Imaging 2</head><p>Noting that since structural elements of each layer, resulting in speckle, have different size, shape, and distribution, the signal and noise model of each layer is expected to be different <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b40">41]</ref>. Moreover, pathologic structures with distinct features appear in specific layers. For example, drusenoid structures appears immediately below or above the retinal pigment epithelium (RPE) layer <ref type="bibr" target="#b41">[42]</ref>, while hyper-reflective foci associated with age-related macular degeneration are not expected to appear in the nerve fiber layer (NFL) <ref type="bibr" target="#b42">[43]</ref>. Utilizing the structural information in the layers, we propose a segmentation based sparse reconstruction (SSR) model to develop a fast and accurate reconstruction algorithm. Our general approach first utilizes a graph based algorithm <ref type="bibr" target="#b34">[35]</ref> to automatically segment the retinal OCT images into multiple layers. Then, for each layer, SSR constructs a dedicated structural dictionary to better represent the anatomic and pathologic structures within this layer. Finally, instead of searching the whole image, SSR efficiently searches for the similar patches within each layer and exploits the patches' similarities within each layer to improve the sparse decomposition.</p><p>Note that, the strategy of segmentation-based denoising has been previously applied to several other image denoising problems <ref type="bibr" target="#b43">[44]</ref><ref type="bibr" target="#b44">[45]</ref><ref type="bibr" target="#b45">[46]</ref>. In contrast, this paper proposes a segmentation based sparse representation (SSR) model for retinal OCT image reconstruction, which utilizes the segmented layer information to enhance the effectiveness and efficiency of the sparse reconstruction model. Specifically, the main contributions of our paper are detailed as follows.</p><p>1. The SSR method introduces a layer segmentation based structural dictionary construction strategy, which effectively preserves the anatomic and pathologic structures in the OCT image.</p><p>2. The SSR method proposes a layer segmentation based sparse reconstruction strategy, which utilizes the segmented layer information to significantly accelerate the similar patch searching process and exploits the correlations among similar patches to enhance the reconstruction performance.</p><p>The remainder of this paper is organized as follows. Section II briefly reviews the sparse reconstruction model and nonlocal means reconstruction model. We introduce the proposed SSR method for the denoising and interpolation of OCT images in Section III. Experimental results on clinical OCT data are presented in Section IV. Section V concludes this paper and suggests for future works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. BACKGROUND: SPARSE RECONSTRUCTION MODEL AND NONLOCAL MEANS BASED RECONSTRUCTION MODEL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Sparse Reconstruction Model</head><p>Given a degraded image, most sparse reconstruction models first divide the input image into ϒ overlapping patches , 1,2,..., .</p><formula xml:id="formula_0">n m i i × ∈ = ϒ X ℝ</formula><p>The vector form for each patch i X is denoted as</p><formula xml:id="formula_1">1 q i × ∈ x ℝ ( q n m = ×</formula><p>), obtained by lexicographic ordering. For a denoising problem, the sparse reconstruction model assumes that the clean retinal OCT signal can be well represented by a weighted linear combination of a few atoms selected from the dictionary ( ,</p><formula xml:id="formula_2">q z × ∈ D ℝ ) q z</formula><p>&lt; , whereas the noise cannot be decomposed on the dictionary. Therefore, the sparse reconstruction model for the denoising problem can be formulated as follows <ref type="bibr" target="#b46">[47]</ref>:</p><formula xml:id="formula_3">{ } 2 2 0 ˆarg min , i i i i i λ = - + α α x Dα α<label>(1)</label></formula><p>where 1 z i × ∈ α ℝ represents the sparse coefficients vector for the i x and 0 i α is the 0 ℓ -norm, counting the number of non-zero coefficients in i α . To solve (1), there are two main considerations: 1) dictionary D construction, and 2) sparse coefficients vector i α estimation. To address the first problem, popular algorithms <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b47">48]</ref> train one dictionary D from a number of relevant sampled patches</p><formula xml:id="formula_4">{ } 1 ,..., Z = H x</formula><p>x , where Z is the number of training patches. Concretely, the dictionary D can be trained by the following optimization problem:</p><formula xml:id="formula_5">{ } 2 2 0 ârg min , λ = - + D D H DA A<label>(2)</label></formula><p>where</p><formula xml:id="formula_6">{ } ,..., i Z = A α</formula><p>α is the sparse coefficient matrix for the H . This equation can be solved by the K-SVD algorithm [31].</p><p>To address the second problem, which is known to be a nondeterministic polynomial-time hard (NP-hard) <ref type="bibr" target="#b48">[49]</ref>, the orthogonal matching pursuit (OMP) <ref type="bibr" target="#b49">[50]</ref> algorithms can be utilized to obtain an approximate solution for the sparse coefficient vector ˆi α . Then, we can use ˆi Dα to reconstruct the related patch and all the reconstructed patches are returned to their original positions to create the final denoised image.</p><p>For the image interpolation problem, we first denote an original high resolution image as</p><formula xml:id="formula_7">N M H × ∈ Y ℝ</formula><p>, the decimation operator as S , and the corresponding low resolution image as </p><formula xml:id="formula_8">( ) ( ) N S M S L H × = ∈ Y SY ℝ . Given</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Nonlocal Means Reconstruction Model</head><p>For the image denoising and interpolation problems, another very effective reconstruction model is the nonlocal means, which exploits the self-similarities inherent to images <ref type="bibr" target="#b51">[52]</ref>.   image (or a large searching window). The similarity can be measured by the squared 2 ℓ -norm of the intensity differences between two patches:</p><formula xml:id="formula_9">( ) 2 2</formula><p>, ,</p><formula xml:id="formula_10">i j i j d j = - ⊂ Λ x x x x (<label>3</label></formula><formula xml:id="formula_11">)</formula><p>where Λ is a set containing the indexes of all patches in the whole image. Then, the patches that are found to be similar are processed by a weighted average filtering or patch similarity penalty to achieve denoising <ref type="bibr" target="#b51">[52]</ref> or interpolation <ref type="bibr" target="#b52">[53]</ref>, respectively.</p><p>In the sparse reconstruction model, the sparse coefficient estimations are affected by the noise in observation image, thus leading to suboptimal reconstruction. To suppress noise interference, recent works including <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b39">40]</ref> incorporate the nonlocal means into the sparse reconstruction model. Specifically, the nonlocal sparse model first conducts the similar patch search [using <ref type="bibr" target="#b2">(3)</ref>] in the whole image and then jointly exploits correlations among similar patches by decomposing them on the same atoms of the dictionary to improve the sparse coefficient solution. The performance improvement is due to, in the sparse solution process, jointly considering the decisions of multiple similar patches is usually more robust to external disturbances <ref type="bibr" target="#b53">[54]</ref>, similar to the principles of majority voting. However, the nonlocal sparse model requires searching for similar patches across the whole image, which is computational costly. In addition, the heavy noise in the OCT image might still interfere with the similar patch searching process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED SSR METHOD FOR OCT RECONSTRUCTION</head><p>We propose the SSR method, which utilizes the layer specific structural information to enhance the effectiveness and cost efficiency of our previous sparse reconstruction techniques. The SSR method is composed of three main parts: a) layer segmentation; b) layer segmentation based dictionary construction; and c) layer segmentation based sparse reconstruction. The outline of the proposed SSR method is illustrated in Fig. <ref type="figure">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Layer Segmentation</head><p>For all the testing and training retinal images, we utilize the popular graph theory and dynamic programming (GTDP) method <ref type="bibr" target="#b34">[35]</ref> to automatically segment these images into R layers, as illustrated in Fig. <ref type="figure" target="#fig_1">2(b</ref>). The region between two color lines in Fig. <ref type="figure" target="#fig_1">2</ref>(b) represents one layer. Note that the intensity of the vitreous and choroid/sclera regions (above and below the segmented layers, respectively) are not uniformly distributed (due to pathology or limited penetration of the 800 nm OCT beam in the choroid layer). Therefore, we further utilize a k-means algorithm to classify the vitreous and choroid/sclera regions into K parts (e.g., see the white and black regions in Fig. <ref type="figure" target="#fig_1">2(c</ref>)). To exploit the spatial information for the classification, we extract a patch (of size n m × ) for each pixel in the vitreous and choroid/sclera regions, and use its vectorization form for the k-means clustering. We then fuse the results from both the layer segmentation and classification to create a segmentation map, which includes R+K layers (see the Fig. <ref type="figure" target="#fig_1">2(d)</ref>, each color represents one layer). The whole segmentation process is illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Layer Segmentation Based Dictionary Construction</head><p>In the retinal OCT image, different layers contain various types of anatomic and pathologic structures (e.g., vessels, drusen, edema, and fovea), and different thicknesses and speckle structures <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b40">41]</ref>. Therefore, to well represent complex structures in varied layers, we utilize the segmented layer information to train multiple structural dictionaries (each corresponding to one layer), rather than one general dictionary <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b46">47]</ref>.</p><p>Specifically, for denoising, we first employ segmentation maps of training images to extract patches for each specific layer and construct the related</p><formula xml:id="formula_12">R+K training sets { } 1 R K r r + =</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H</head><p>. As in <ref type="bibr" target="#b23">[24]</ref>, the training images can be considered noiseless, which are obtained by registration and averaging of a number of repeated B-scans acquired from spatially very close positions. Then, we train one structural dictionary r D (of size q×s) on one training set r H [see Fig. <ref type="figure">3(a)</ref>], by modifying (2) as the following optimization problem,</p><formula xml:id="formula_13">{ } 2 1 2 0 ârg min , 1,..., , r R K r r r r r r r R K λ + = = - + = + D D H D A A (4)</formula><p>where r A is the sparse coefficient matrix for the training set r H . The optimization problem in ( <ref type="formula">4</ref>) is solved by separately performing the K-SVD algorithm <ref type="bibr" target="#b30">[31]</ref> on each set r H . Note that, to construct the structural dictionary for the layer in the black regions (e.g., vitreous and sclera), we randomly select a small number of training patches from that layer as the dictionary atoms. This is because these regions have less structural information and are easy to be represented.</p><p>For the image interpolation problem, following <ref type="bibr" target="#b3">[4]</ref>, we use a set of high SNR and high resolution images, each acquired by averaging a set of repeated densely sampled B-scans, as our </p><formula xml:id="formula_14">V Train L v v = Y .</formula><p>Utilizing the segmentation maps of the { } , 1  </p><formula xml:id="formula_15">V Train L v v = Y and { } , 1 V Train H v v = Y ,</formula><formula xml:id="formula_16">β = - + = + M M A M A M (<label>6</label></formula><formula xml:id="formula_17">)</formula><p>where β is the regularization parameter for balancing the objective terms. This optimization problem has a closed form solution <ref type="bibr" target="#b54">[55]</ref>,</p><p>( )</p><formula xml:id="formula_18">1 , , , , ˆ( )( ) ( )( ) ,</formula><p>1,..., .</p><formula xml:id="formula_19">H Train L Train T L Train L Train T r r r r r r R K β - = × + ⋅ = + M A A A A I (<label>7</label></formula><formula xml:id="formula_20">)</formula><p>where I is an identity matrix. Note that, since each layer based structural dictionary is designed for one specific layer, it has a significantly smaller number of atoms compared to the universal dictionary in <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b46">47]</ref>, and thus can achieve a more efficient representation. In addition, the dictionary construction step is an off-line process and in practice does not add to the computational cost of denoising or interpolation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Layer Segmentation Based Sparse Reconstruction</head><p>As noted, the anatomic and pathologic structures, intensities, and speckle patterns within each layer are expected to have strong similarities. Therefore, instead of searching the whole image <ref type="bibr" target="#b51">[52]</ref>, we propose to seek the similar patches in a searching window within each segmented layer, which can greatly reduce the search space [see Fig. x using the similarity measure in <ref type="bibr" target="#b2">(3)</ref>. Note that if the rectangular search window goes beyond the boundaries of r-th layer, only the window part within the layer is considered as part of the search region. After finding these similar patches, instead of directly conducting the sparse decomposition (as in Fig. <ref type="figure">5</ref>. Illustration of nearby patch estimation process in the proposed layer segmentation based sparse reconstruction. <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b39">40]</ref>), we apply a weighted average on these similar patches to obtain an average patch</p><formula xml:id="formula_21">, Ave r i x , , , ,<label>1</label></formula><formula xml:id="formula_22">J Ave r r j r j i i i j ω = = ∑ x x<label>(8)</label></formula><p>where , r j i ω is the weight for the patch ,</p><formula xml:id="formula_23">r j i x , computed as ( ) ( ) 2 , 2 , 2 , 2 1 exp exp r j r i i r j i J r j r i i j w w ω = - - = - - ∑ x x x x<label>(9)</label></formula><p>where w is a predetermined scalar. This weighted averaging scheme is an effective way to reduce noise, which affects direct sparse decomposition of the similar patches. Next, we use the average patches for the sparse reconstruction. Since the 3-D OCT image also has strong correlations among nearby slices <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b31">32]</ref>, we simultaneously process the averaged patches from the same position of nearby slices (called as the nearby patches</p><formula xml:id="formula_24">{ } , ,<label>1</label></formula><p>,</p><formula xml:id="formula_25">T Ave r i t t = x</formula><p>where T is number of nearby patches) with a joint sparse decomposition technique. This technique decomposes the nearby patches on the same dictionary atom with different coefficient values, which can enhance the decomposition efficiency. The joint sparse reconstruction for the denoising and interpolation are separately described, as follows (see the Fig. <ref type="figure">5</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Joint Sparse Reconstruction for Denoising</head><p>In denoising, simultaneous decomposition of the nearby</p><formula xml:id="formula_26">averaged patches { } , ,<label>1</label></formula><formula xml:id="formula_27">T Ave r i t t =</formula><p>x in the r-th layer of nearby images with the joint sparse technique amounts to the following problem, </p><formula xml:id="formula_28">{ } { } , ,<label>1 2 , , , , , , 1 2 ˆ1</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F t T</head><formula xml:id="formula_29">= = = = - ≤ = ∑ α α x D α α (<label>10</label></formula><formula xml:id="formula_30">)</formula><p>where F is the maximum number of nonzero coefficients in , ,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ave r i t α</head><p>. This optimization problem is efficiently solved by a simultaneous orthogonal matching pursuit (SOMP) algorithm <ref type="bibr" target="#b55">[56]</ref>. Then, we estimate the reconstructed nearby patches as , , , ˆ, 1,..., .</p><formula xml:id="formula_31">r Ave r i t r i t t T = = x D α<label>(11</label></formula><p>) Note that, for the patches in the layer of the black region (e.g., vitreous and sclera), rather using the SOMP, we use the Euclidean distance to search the most representative atom for each patch. Finally, as in <ref type="bibr" target="#b31">[32]</ref>, a weighted average operation is conducted on the nearby patches and then these recovered nearby patches are returned to the original positions to reconstruct the denoised nearby images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Joint Sparse Reconstruction for Interpolation</head><p>For the interpolation problem, given the averaged patches</p><formula xml:id="formula_32">{ } , , ,<label>1</label></formula><formula xml:id="formula_33">T Ave r L i t t = x</formula><p>from nearby low resolution images, we obtain the</p><formula xml:id="formula_34">low resolution sparse matrix { } , , ,<label>1</label></formula><formula xml:id="formula_35">T Ave r L i t t = α</formula><p>by utilizing the SOMP to solve <ref type="bibr" target="#b9">(10)</ref> with the dictionary L r D . Then, we estimate the corresponding high resolution sparse matrix as , ,  <ref type="bibr" target="#b31">[32]</ref>, we also conduct a weighted average operation on the nearby patches, and return the set of nearby patches { } , , 1</p><p>ˆT r</p><formula xml:id="formula_37">H i t t =</formula><p>x to the original positions to reconstruct the high resolution nearby images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Data Sets</head><p>Our experiments used a dataset of retinal OCT volumes from 41 different human subjects with and without nonneovascular age-related macular degeneration (AMD). The images in this dataset were imaged by a Bioptigen SDOCT system (Durham, NC, USA) with an axial resolution of ~4.5 µm per pixel in tissue. This dataset was originally introduced in our previous works <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b23">24]</ref>, and can be freely downloaded online <ref type="foot" target="#foot_0">1</ref> . This dataset is attained with adherence to the tenets of the Declaration of Helsinki and is a subset of the image captured in the A2A SD-OCT Study, which was registered at ClinicalTrials.gov (Identifier: NCT00734487) and approved by the institutional review boards of the 4 A2A SD-OCT clinics (Devers Eye Institute, Duke Eye Center, Emory Eye Center, and National Eye Institute) <ref type="bibr" target="#b56">[57]</ref>.</p><p>For the denoising problem, images from 28 different human subjects are utilized. Two sets of scans were acquired from each subject. The first scan was focused at the fovea with 40 repeatedly sampled B-scans, each with 900 A-scans. The second scan was a 3D volume, with 900 A-scans and 100 B-scans including the fovea. We registered the first set of repeatedly sampled scans using the StackReg image registration plug-in in ImageJ <ref type="bibr" target="#b57">[58]</ref> and then averaged them to obtain an averaged image of the fovea. The averaged image can be regarded as the "noiseless" reference image to train the dictionaries or compute the quantitative metrics. We selected datasets of 18 subjects to test the denoising performance of the proposed SSR method, while the datasets of the other 10 subjects were utilized for training the dictionaries and setting the parameters. Note that, the datasets of subjects used in the dictionary training stage were different from those used in the testing stage and the segmentation labels in the training stage have been manually corrected.</p><p>The dataset for interpolation problem included the images used for the denoising experiment. We used the averaged image created from the first scan as the high resolution image and subsampled the central foveal B-scan within the second scan as the corresponding low resolution image. Similar to the denoising problem, the high resolution and low resolution image pairs of 10 different subjects are used for training the dictionaries and mappings, while the remaining image pairs from 18 subjects are used for the testing. In addition, densely sampled and real subsampled datasets from another 13 human subjects are also used for the testing. For each subject, the real subsampled dataset has 450 A-scans per B-scan and 100 B-scans per volume, containing the fovea area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Compared Methods</head><p>For the OCT image denoising problem, the proposed SSR method is compared with other five well known denoising approaches: BRFOE <ref type="bibr" target="#b58">[59]</ref>, K-SVD <ref type="bibr" target="#b46">[47]</ref>, PGPD <ref type="bibr" target="#b59">[60]</ref>, BM3D <ref type="bibr" target="#b38">[39]</ref>, and MSBTD <ref type="bibr" target="#b23">[24]</ref>. The BRFOE is a modification of the field-of-experts model, which constructs filters by modeling the noisy image statistics. The K-SVD is a popular sparsity based denoising method, which trains one universal dictionary on the input noisy image. The BM3D is a widely popular benchmark denoising method, which exploits patch self-similarities of the input image by nonlocal searching and 3-D collaborative filtering. The MSBTD is a nonlocal based structural sparse denoising method, which utilizes nonlocal searching to exploit patch self-similarities and uses structural clustering to construct multiple structural dictionaries.</p><p>For the OCT image interpolation problem, we compared the proposed SSR method with five well-known interpolation approaches: Bicubic, Tikhonov <ref type="bibr" target="#b60">[61]</ref>, BM3D <ref type="bibr" target="#b38">[39]</ref>+Bicubic, ScSR <ref type="bibr" target="#b50">[51]</ref>, and SBSDI <ref type="bibr" target="#b3">[4]</ref>. The BM3D+Bicubic method is a combination of the BM3D denoising approach and the Bicubic interpolation approach. The ScSR is a popular sparsity based interpolation method, which utilizes the joint dictionary learning strategy to train a pair of low resolution and high resolution dictionaries. The SBSDI uses structural clustering to train multiple low resolution and high resolution dictionary pairs and employs a joint sparse operation to exploit the correlations among nearby slices for interpolation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Algorithm Parameters</head><p>The parameters of the proposed SSR algorithm were empirically selected based on our experiments on the training data, and kept unchanged for all the test images. As in <ref type="bibr" target="#b34">[35]</ref>, the number of segmented layers R was set to seven. Since the vitreous, choroid, and sclera regions can be generally classified into background areas with less structural information and foreground areas with comparatively rich structural information, the cluster number K was selected to two. We chose the number of nearby slices T to be 5, based on the azimuthal resolution of the OCT volume, as slices from farther distances might have large differences, decreasing the effectiveness of the joint sparse reconstruction. The parameter w in (9) was set to 80. Using larger w values increases the averaging property in (8) and thus will create a stronger smoothing effect. The size of the search window Row Column r r S S × was set to <ref type="bibr">6 40</ref> × . Increasing the size of the search window might further enhance the reconstruction performance, but create more computational cost. In each search window, the target number of similar patches J was set to 60. Further increasing in the number of similar patches number might result in over-smoothing. The sparsity level F for both the dictionary construction and the sparse reconstruction stages was set to 3. The above parameters were similarly set for both denoising and interpolation problems. For the denoising problem, the number of dictionary atoms is separately set to 30 and 80 for the layer of black region (e.g., vitreous and sclera) and other layers, respectively. For the interpolation problem, the number of dictionary atoms is set to 80 for all the layers. Increasing the number of dictionary atoms will improve the performances, but results in higher computational burden. Since most of the structures in the OCT image lay in the horizontal direction, the patch size n m × was set to 5 10 × for the denoising problem. For the interpolation problem, the low resolution image patch size was set to 4 4 × , while the high resolution image patch sizes were chosen to be 4 8 × and 4 16</p><p>× , when 50% and 75% data are missing, respectively. In the Section IV.G, we will further discuss the effect of the patch size on the performance of the proposed SSR method. The parameters of the compared methods: BRFOE <ref type="bibr" target="#b58">[59]</ref>, K-SVD <ref type="bibr" target="#b46">[47]</ref>, PGPD <ref type="bibr" target="#b59">[60]</ref>, BM3D <ref type="bibr" target="#b38">[39]</ref>, and MSBTD <ref type="bibr" target="#b23">[24]</ref>, BM3D <ref type="bibr" target="#b38">[39]</ref>+Bicubic, ScSR <ref type="bibr" target="#b50">[51]</ref>, and SBSDI <ref type="bibr" target="#b3">[4]</ref> are set to the default values as in their references <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b59">60]</ref>. The parameters for the Tikhonov method were tuned to reach the best results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Quantitative Metrics</head><p>We adopted the peak signal-to-noise-ratio (PSNR), mean-to-standard-deviation ratio (MSR) <ref type="bibr" target="#b61">[62]</ref>, contrast-to-noise ratio (CNR) <ref type="bibr" target="#b62">[63]</ref> and Wilcoxon signed-rank test <ref type="bibr" target="#b63">[64]</ref> to quantitatively evaluate the results of the reconstruction methods. PSNR is a global quality metric and its calculation needs a high-quality reference image. Since all the datasets used in our experiments are acquired in clinic (not simulated) with heavy noise, we utilized the registered and averaged images created from the repeatedly sampled scans as the "noiseless" reference image. We used StackReg in <ref type="bibr" target="#b57">[58]</ref> to register the reference image and reconstructed images in order to reduce the motion between them. After the registration, both the reference and recovered images might be slightly resized to compute the PSNR. MSR and CNR are two non-reference quality metrics and their calculations focus on some selected local regions. That is, MSR and CNR compute the means and standard deviations of background regions (e.g., red box #1 in Fig. <ref type="figure">6</ref>) and foreground regions (e.g., red box #2-#6 in Fig. <ref type="figure">6</ref>) in the reconstructed images. The Wilcoxon signed-rank test was used to test for statistical significance between the SSR method and each compared method on the evaluated PSNR, MSR and CNR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Results for OCT Image Denoising</head><p>Fig. <ref type="figure">6</ref> provides visual comparison of denoising results obtained from the BRFOE <ref type="bibr" target="#b58">[59]</ref>, K-SVD <ref type="bibr" target="#b46">[47]</ref>, PGPD <ref type="bibr" target="#b59">[60]</ref>, BM3D <ref type="bibr" target="#b38">[39]</ref>, MSBTD <ref type="bibr" target="#b23">[24]</ref>, and SSR methods on two real retinal OCT images. As can be observed, results from the BPFOE exhibit rather noisy appearance. The K-SVD, PGPD, and BM3D methods significantly remove noise, but appear over-smoothed with visible artifacts (see the zoomed layer areas in red boxes #2, #3, and #4 in Fig. <ref type="figure">6</ref>). Though the MSBTD method can further reduce the artifacts, it still has indistinct layer boundaries (see the zoomed layer areas in red boxes #2, #3, and #4 in Fig. <ref type="figure">6</ref>). By contrast, utilization of the proposed SSR method can achieve noticeably improved noise suppression while preserving the layer structural details as compared to other methods. This demonstrates that the proposed layer-segmentation based dictionary construction and sparse reconstruction strategies can significantly suppress the noise while still achieving better layer structure representation.  <ref type="bibr" target="#b58">[59]</ref>, K-SVD <ref type="bibr" target="#b46">[47]</ref>, PGPD <ref type="bibr" target="#b59">[60]</ref>, BM3D <ref type="bibr" target="#b38">[39]</ref>, MSBTD <ref type="bibr" target="#b23">[24]</ref> Fig. <ref type="figure">6</ref>. Two retinal OCT datasets and their Denoising results using the BRFOE <ref type="bibr" target="#b58">[59]</ref>, K-SVD <ref type="bibr" target="#b46">[47]</ref>, PGPD <ref type="bibr" target="#b59">[60]</ref>, BM3D <ref type="bibr" target="#b38">[39]</ref>, MSBTD <ref type="bibr" target="#b23">[24]</ref> and SSR methods.</p><p>Average quantitative results (over 18 foveal images) of all the test methods are tabulated in the Table <ref type="table" target="#tab_4">I</ref>. The proposed SSR method consistently outperforms the compared methods in terms of the three quantitative metrics (i.e., PSNR, MSR, and CNR). The average running time (over 18 foveal images) of all the test methods are reported in Table <ref type="table" target="#tab_4">I</ref>. All the compared methods as well as the segmentation and sparse reconstruction parts of the proposed SSR method (in both the denoising and interpolation applications) are executed on a desktop PC with an i7-5930 CPU at 3.5 GHz and 64 GB of RAM. As can be seen, the reconstruction part of the SSR method needs much less running time than the non-local based denoising approaches: PGPD, BM3D, and MSBTD. This shows that searching for similar patches within each specific layer can greatly reduce the computational cost in comparison with the non-local similar patch searching strategy. Furthermore, we observe that the reconstruction part of the SSR method is faster than that of the original sparse denoising method (K-SVD). This is because the proposed SSR utilizes much smaller size layer based dictionaries and can reduce the computational cost for the sparse solution. Note that, the main part of the proposed Fig. <ref type="figure">7</ref>. Two real subsampled retinal OCT datasets (with 50% data missing) and their reconstruction results by using the Bicubic, Tikhonov <ref type="bibr" target="#b60">[61]</ref>, BM3D <ref type="bibr" target="#b38">[39]</ref>+Bicubic, ScSR <ref type="bibr" target="#b50">[51]</ref>, SBSDI <ref type="bibr" target="#b3">[4]</ref>, and proposed SSR methods.</p><p>SSR algorithm (except the SOMP code 2 ) is coded with MATLAB, and can be further greatly accelerated with more efficient coding and a general purposed graphics processing unit (GPU).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Results for OCT Image Interpolation</head><p>For interpolation, we conducted the experiments on two sampling conditions (with 50% data missing and with 75% data missing). For the condition with 50% missing, we first tested the Bicubic, Tikhonov <ref type="bibr" target="#b60">[61]</ref>, BM3D <ref type="bibr" target="#b38">[39]</ref>+Bicubic, ScSR <ref type="bibr" target="#b50">[51]</ref>, SBSDI <ref type="bibr" target="#b3">[4]</ref>, and SSR methods on the real subsampled datasets from 13 different subjects. For each dataset, we adopted the central foveal B-scan and another two B-scans located approximately 1.5 mm below and above the fovea. Therefore, there are totally 3×13=39 images for this real subsampled experiment. Fig. <ref type="figure">7</ref> shows two real subsampled images and their visually reconstructed results obtained from all the test 2 Downloaded from: http://spams-devel.gforge.inria.fr/. methods. As can be observed, the Bicubic, Tikhonov, and ScSR methods result in noisy reconstructions. The BM3D+Bicubic can greatly reduce the noise, but blurs the layer boundaries (see the zoomed layer areas in red boxes #2, #3, and #4 in Fig. <ref type="figure">7</ref>). Although the layer boundaries can be preserved in the SBSDI method, it still introduces some artifacts. In contrast, the proposed SSR method can well preserve the structural details while significantly suppressing noise. In addition, we also adopted a regular sampling pattern to remove the 50% data information of the 18 foveal images used in the above denoising problem and used them for the interpolation testing. Table <ref type="table" target="#tab_4">II</ref> reports the average quantitative results (over 39 real subsampled + 18 synthetic subsampled images) of all the test methods. As can be observed, the proposed SSR method delivers the best quantitative results. Furthermore, the reconstruction part of the SSR method requires less running time than the Tikhonov, BM3D+Bicubic, ScSR, and SBSDI methods, but has a higher computational cost than the simple Bicubic method. Note that, for the interpolation problem, the Fig. <ref type="figure">8</ref>. Two synthetic Subsampled Retinal OCT datasets (with 75% data missing) and their reconstruction results by using the Bicubic, Tikhonov <ref type="bibr" target="#b60">[61]</ref>, BM3D <ref type="bibr" target="#b38">[39]</ref>+Bicubic, ScSR <ref type="bibr" target="#b50">[51]</ref>, SBSDI <ref type="bibr" target="#b3">[4]</ref>, and proposed SSR methods. SBSDI and SSR methods adopts similar reconstruction framework, except for the proposed layer segmentation based dictionary construction and similar patch searching strategies.</p><p>For the condition with 75% data missing, we also used the regular sampling pattern to remove the 75% data information of the 18 foveal images in the denoising problem. Fig. <ref type="figure">8</ref> and Table <ref type="table" target="#tab_4">III</ref> show the qualitative and quantitative reconstruction results from all the test methods on datasets with 75% data missing. As can be observed, the proposed SSR method provides the best performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Effects of Patch Size</head><p>In this section, we analyze the effect of the patch size on the performance (in the PSNR sense) of the proposed SSR method. In the analysis of each specific parameter, we vary this parameter in a certain range and set the other parameters to the fixed values described in Section IV. C. Note that, the reported values are the averaged results over all 18 synthetic test images described in Section IV. E and F. For the denoising problem, the patch size was varied from 3×6 to 8×16. The performance of the proposed SSR algorithm under varied patch sizes is  shown in Fig. <ref type="figure" target="#fig_7">9(a)</ref>. For the interpolation problem, we changed the low resolution patch size from 3 × 3 to 8 × 8. The corresponding high resolution patch was enlarged in the horizontal direction according to the interpolation scale number (e.g., two times for 50% data missing and four times for 75% data missing). The performance of the proposed SSR algorithm under different patch sizes for two interpolation cases (e.g., 50% and 75% data missing) is illustrated in Fig. <ref type="figure" target="#fig_7">9</ref>(b). As can be observed in Fig. <ref type="figure" target="#fig_7">9</ref>, small patch sizes negatively affect the performance of our SSR algorithm. This is due to the fact that small patch size contains very limited spatial information for the reconstruction. The SSR algorithm generally performs the best when the patch size is increased to 5×10 and 4×4 for the denoising and interpolation problems, respectively. The performance of the proposed SSR algorithm, when using larger patch sizes, might become stable or even slightly worse based on qualitative evaluation. This is because using too large patches might create an over-smoothing effect, which blurs the final reconstruction results. In addition, using larger patches has higher computational costs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. Effect of Segmentation Errors</head><p>Our next experiment assessed the sensitivity of our denoising algorithm to small errors in segmentation. We segmented a B-Scan using the automatic GTDP technique <ref type="bibr" target="#b34">[35]</ref>. Next, we modified this B-Scan to correct segmentation errors (corrected segmentation). Since automatic and corrected segmentation results were very close, we manually modified the automatic segmentation, intentionally introducing errors in segmentation (manually induced error). As shown in Fig. <ref type="figure" target="#fig_8">10</ref>, the corrected segmentation case might slightly perform better than the automatic and manually induced error segmentation cases. However, these differences are negligible. In general, the segmentation information has been utilized in three stages of the proposed SSR algorithm: dictionary construction, similar patch searching, and sparse representation. Errors in segmentation can potentially affect each of these stages. Since manual corrections can be applied to the automatically segmented images in the offline dictionary construction stage, the segmentation accuracy in this stage can be as high as needed. In the similar patch searching stage, since the similarity metrics are tested for each patch, the search process significantly reduces the effects of segmentation errors on reconstruction. The sparse representation stage is relatively more sensitive to segmentation accuracy, as segmentation error can result in the selection of a dictionary from an incorrect layer to represent the patch being processed. However, even with a suboptimally selected dictionary, the sparse solution process (e.g. the orthogonal matching pursuit algorithm <ref type="bibr" target="#b49">[50]</ref>) can find well-suited atoms to represent the processed patch and the final reconstruction result is expected to be stable, as shown in Fig. <ref type="figure" target="#fig_8">10</ref>. As indicated in Section IV E and F, only with the classic GTDP automatic segmentation algorithm <ref type="bibr" target="#b34">[35]</ref>, the proposed SSR algorithm's performance is superior to several state-of-the-art non-segmentation based reconstruction methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Effect of Image Reconstruction to the Layer Segmentation</head><p>The experiment in Fig. <ref type="figure" target="#fig_8">10</ref> showed that our denoising algorithm is not sensitive to small errors in automated segmentation. In a recursive process, once the SSR denoised images are in hand, they can be segmented again using the GTDP method, which is expected to result in equal or better segmentation. The experiment in Fig. <ref type="figure" target="#fig_9">11</ref> shows such a case. In this example, there is a small error in the segmentation of the inner nuclear layer boundaries delineated by blue and cyan colors near the fovea, when the GTDP technique is applied on the noisy images. When GTDP is applied on the SSR denoised image, these small segmentation errors are mostly eliminated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSIONS</head><p>In this paper, we presented a novel layer-segmentation based sparse reconstruction method named SSR for efficient denoising and interpolation of 3D SDOCT images. Unlike our previous sparse denoising <ref type="bibr" target="#b23">[24]</ref> and interpolation <ref type="bibr" target="#b3">[4]</ref> methods, the proposed SSR method utilizes segmented layer information to construct the structural dictionaries and conduct similar-patch searching. Both the layer-segmentation based dictionaries and similar-patches searching can aid sparse reconstruction in order to achieve better representation, while greatly reducing the computational cost. Our experiments demonstrated the high efficiency and effectiveness of the proposed SSR method over several current state-of-the-art denoising and interpolation approaches.</p><p>Following our previous work, the denoising and interpolation software developed for this project publically will be available at https://sites.google.com/site/leyuanfang/home.</p><p>There is space for improving the performance of our SSR algorithm. One limiting factor in our proposed technique is the utilization of fixed-size rectangular patches. Today, OCT technology is used for imaging a variety of pathologic structures in eyes and other human and animal organs, the shape of which might not be optimally represented by the fixed-size rectangular patches. Therefore, in our future work, we will incorporate shape adaptive patches (e.g. utilizing superpixel <ref type="bibr" target="#b64">[65]</ref> or adaptive kernels <ref type="bibr" target="#b65">[66]</ref>) into the proposed sparse model, which we expect to improve the reconstruction performance. In addition to the fixed-size patch, several parameters need to be tuned for the proposed method. So, a future line of work will also be on designing efficient automatic parameter selection algorithms.</p><p>There are two potential utilities for our segmentation-based reconstruction technique. The first application is the OCT image quality improvement for visual inspection of complex anatomic and pathologic structures (e.g., vessels, drusen, hyperreflective foci, edema, etc.). The second important utility of our reconstruction approach is improving the performance of automated segmentation algorithms. Note that, our algorithm utilizes automated layer segmentation (a problem for which several solutions are available in the literature) and results in denoised images from which other features (e.g. hyperreflective foci, edema, vessel, etc.) can be automatically segmented. The proposed SSR method based on the layer segmentation can even recursively improve the accuracy of segmentation. While our automatic GTDP retinal layer segmentation algorithm is accurate, it is not perfect and occasionally results in erroneous segmentation, especially for noisy images. Utilizing our SSR reconstruction algorithm can improve the GTDP segmentation accuracy as shown in the experiment of Fig. <ref type="figure" target="#fig_1">12</ref>. A complete quantitative assessment of the proposed method impact for enhancing the performance of various automated segmentation methods is a part of our ongoing works.</p><p>In this paper, we utilized the segmented retinal layer information for enhancing volumetric OCT images. However, the proposed mathematical framework is general and applicable to virtually any other tissue. Also, for segmentation, we utilized the GTDP method of <ref type="bibr" target="#b34">[35]</ref>, which can be replaced by any other layer or feature segmentation technique <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b66">[67]</ref><ref type="bibr" target="#b67">[68]</ref><ref type="bibr" target="#b68">[69]</ref>. Therefore, in our future publications, we will investigate the applicability of the proposed segmentation based reconstruction model for enhancing the quality of a wide variety of images from different tissues (e.g. dermatology, Gastroenterology, and cardiology) captured via OCT or other imaging modalities such as MRI or ultrasound.</p><p>Finally, despite the fact that our algorithm utilized the classic GTDP automatic segmentation algorithm <ref type="bibr" target="#b34">[35]</ref>, the final reconstructed results demonstrated the superiority of the proposed SSR algorithm over several state-of-the-art non-segmentations based reconstruction methods. More recent and advanced 3-D segmentation methods such as <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b70">71]</ref>, which are more robust to imaging and pathologic artifacts, can also be utilized to improve segmentation accuracy, if needed. However, more complex 3-D segmentation algorithms often increase the computational load of the overall algorithm.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>3 Fig. 1 .</head><label>31</label><figDesc>Fig. 1. Outline of the proposed SSR algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. Outline for the OCT segmentation. In (b), the retinal OCT image is segmented into seven layers using eight color lines, and the region between two color lines represents one layer. Three distinct regions, above and below the retina include vitreous, visible choroid, and sclera. In (c), the vitreous and choroid/sclera regions are further classified into two clusters (one is the black area and one is the white area). In (d), different color regions represent varied segmented layers or classified regions. The dimly visible regions of choroid can be regarded as the background area (delineated in black) with less structural information. The visible regions of choroid can be considered as the foreground area with comparatively rich structural information, delineated in white. Therefore, we set the clustering number K of the K-means algorithm to 2, which further clusters the vitreous, choroid, and sclera regions into two groups, i.e. the black and white areas in (c) and (d).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .Fig. 4 .</head><label>34</label><figDesc>Layer segmentation based dictionary construction for (a) denoising problem; (b) interpolation problem. Similar patch searching by (a) nonlocal searching; (b) layer segmentation based searching.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>high-resolution training image set { } one frame from each set of the repeated B-Scans, to attain the corresponding low-resolution training image set { } , 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>we can extract spatially matched low resolution and high resolution patches for each layer as the matching training sets { } we separately adopt the semi-coupled dictionary learning algorithm [4] on each training set pair</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>3(b)]. In addition, as described in Section II. A, we further train Following<ref type="bibr" target="#b3">[4]</ref>, we train these mapping functions using the low resolution sparse matrices { }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>4(b)]. Specifically, for each patch r i x in the r-th layer of the test image, we first define a search window (of size Row Column r rS S ×) within the r-th layer, and then find J patches { }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .</head><label>9</label><figDesc>Effect of the patch size on the performance of the proposed SSR algorithm for (a) Denoising and (b) Interpolation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. SSR reconstruction results using three different layer segmentations. The image in (a) is a raw OCT B-Scan. Automatic segmentation of retinal layers using GTDP algorithm (delineated in different colors in the left column) is used to produce the denoised image of the right column in (b). We carefully manually corrected the automatic segmentation of layer boundaries, resulting in the slightly modified layer boundaries shown in the left column of the (c). Corresponding denoised image is shown in the right column of the (c). To artificially create more severe segmentation errors, we intentionally introduced errors in segmentation of the inner nuclear layer in the black box region (manually induced error), resulting in the images of the (d).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Impact of SSR reconstruction on automatic GTDP layer segmentation performance. The raw B-Scan in (a) is segmented using automated GTDP technique in (b). The blue arrow points to a small region with errors in automatic segmentation of the inner nuclear layer boundaries (delineated in blue and cyan colors). SSR denoised image using the segmentation results in (b) is shown in (c). Automatic segmentation of the image in (c) using GTDP technique is shown in (d), where the accuracy of segmentation is improved for the previous erroneously segmented region.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>resolution dictionary L D and the high resolution dictionary H D , which ensures that the sparse coefficient L i α in the space L χ is the same as the sparse coefficient H i α in the space H χ . Inspired by the work of Yang et. al., we utilized a semi-coupled learning algorithm to construct the matched dictionaries L D and H</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>the observation degraded</cell></row><row><cell cols="3">image L Y , the objective of the image interpolation is to obtain</cell></row><row><cell>the ˆH Y such that ˆH Y</cell><cell>≈</cell><cell>H Y . To solve the interpolation</cell></row><row><cell cols="3">problem, recent sparse reconstruction models [51] attempt to</cell></row><row><cell cols="3">infer the relationship of the sparse coefficients and dictionaries</cell></row><row><cell cols="3">between the high resolution space H χ and low resolution space</cell></row><row><cell></cell><cell></cell><cell>D ,</cell></row><row><cell cols="3">and then trained a mapping function M to link the sparse</cell></row><row><cell cols="3">coefficients L i α and H i α [4]. After obtaining the relationship</cell></row><row><cell cols="3">between the spaces L χ and H χ , the sparse reconstruction</cell></row><row><cell cols="3">model can first find the sparse coefficient L i α of each</cell></row><row><cell cols="3">observation patch L i x , and then restore the latent image patches</cell></row><row><cell cols="3">H i x as well as the corresponding high resolution image ˆH Y by</cell></row><row><cell cols="3">utilizing the high resolution dictionary H D and mapping</cell></row><row><cell>function M .</cell><cell></cell><cell></cell></row></table><note><p>L χ . In [51], Yang et. al. jointly trained both the low</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</figDesc><table><row><cell cols="2">Specifically, for each patch i x extracted from the degraded</cell></row><row><cell cols="2">image, the nonlocal means method first searches the W patches</cell></row><row><cell>with the highest similarity to</cell><cell>i x from the whole</cell></row><row><cell>0278-0062 (c) 2016 IEEE.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>,</figDesc><table><row><cell>α</cell><cell>Ave r H i t</cell><cell>=</cell><cell>r M α ×</cell><cell>Ave r L i t</cell><cell></cell><cell>t</cell><cell>=</cell><cell>T</cell><cell>(12)</cell></row><row><cell cols="8">and the nearby high resolution patch set as</cell><cell></cell></row><row><cell></cell><cell cols="4">, , , ˆ, , , r H Ave r H i t r H i t = x D α</cell><cell>t</cell><cell>=</cell><cell cols="2">1,..., . T</cell><cell>(13)</cell></row><row><cell>As in</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE I MEAN</head><label>I</label><figDesc>AND STANDARD DEVIATION OF THE PSNR, MSR, CNR TOGETHER WITH RUNNING TIME (IN SECONDS) FOR 18 FOVEAL IMAGES FROM 18 DIFFERENT SUBJECTS RECONSTRUCTED BY BRFOE</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>MEAN</head><label></label><figDesc>, AND SSR METHODS. "SEG" AND "REC" DENOTES THE REQUIRED RUNNING TIME FOR THE LAYER SEGMENTATION PART (R LAYERS SEGMENTATION) AND SPARSE RECONSTRUCTION PART (INCLUDING VITREOUS AND CHOROID/SCLERA REGIONS CLASSIFICATION), RESPECTIVELY. WHEN P&lt;0.05, THE METRICS (I.E. PSNR, MSR, CNR) FOR EACH TEST METHOD ARE CONSIDERED STATISTICALLY SIGNIFICANT AND WERE MARKED BY "*". BEST RESULTS IN THE MEAN VALUES ARE LABELED IN BOLD. AND STANDARD DEVIATION OF THE PSNR, MSR, CNR TOGETHER WITH RUNNING TIME (IN SECONDS) FOR 18 FOVEAL IMAGES (WITH 50% DATA MISSING) FROM 18 DIFFERENT SUBJECTS AND 39 REAL SUBSAMPLED IMAGES (INCLUDING FOVEAL AND NONFOVEAL IMAGES WITH 50% DATA MISSING) FROM 13 DIFFERENT SUBJECTS RECONSTRUCTED BY BICUBIC, TIKHONOV [61], BM3D [39]+BICUBIC, SCSR [51], SBSDI [4], AND SSR METHODS. "SEG" AND "REC" DENOTES THE REQUIRED RUNNING TIME FOR THE LAYER SEGMENTATION PART (R LAYERS SEGMENTATION) AND SPARSE RECONSTRUCTION PART (INCLUDING VITREOUS AND CHOROID/SCLERA REGIONS CLASSIFICATION), RESPECTIVELY. WHEN P&lt;0.05, THE METRICS (I.E. PSNR, MSR, CNR) FOR EACH TEST METHOD ARE CONSIDERED STATISTICALLY SIGNIFICANT AND WERE MARKED BY "*". BEST RESULTS IN THE MEAN VALUES ARE LABELED IN BOLD.</figDesc><table><row><cell cols="2">Metric\Method</cell><cell>BRFOE</cell><cell>K-SVD</cell><cell>PGPD</cell><cell>BM3D</cell><cell>MSBTD</cell><cell>SSR</cell></row><row><cell></cell><cell>Mean</cell><cell>25.32</cell><cell>27.03</cell><cell>27.01</cell><cell>27.04</cell><cell>27.08</cell><cell>28.10</cell></row><row><cell>PSNR</cell><cell>Stand deviation</cell><cell>1.72</cell><cell>2.47</cell><cell>2.51</cell><cell>2.49</cell><cell>2.47</cell><cell>2.63</cell></row><row><cell></cell><cell>p value</cell><cell>1.96E-04 *</cell><cell>1.96E-04 *</cell><cell>1.96E-04 *</cell><cell>1.96E-04 *</cell><cell>1.96E-04 *</cell><cell></cell></row><row><cell></cell><cell>Mean</cell><cell>7.05</cell><cell>9.79</cell><cell>9.57</cell><cell>9.27</cell><cell>10.96</cell><cell>13.04</cell></row><row><cell>MSR</cell><cell>Stand deviation</cell><cell>0.84</cell><cell>2.34</cell><cell>2.29</cell><cell>2.19</cell><cell>3.37</cell><cell>3.51</cell></row><row><cell></cell><cell>p value</cell><cell>1.96E-04 *</cell><cell>1.96E-04 *</cell><cell>1.96E-04 *</cell><cell>1.96E-04 *</cell><cell>2.33E-04 *</cell><cell></cell></row><row><cell></cell><cell>Mean</cell><cell>3.32</cell><cell>4.41</cell><cell>4.12</cell><cell>4.06</cell><cell>4.58</cell><cell>5.34</cell></row><row><cell>CNR</cell><cell>Stand deviation</cell><cell>1.05</cell><cell>1.34</cell><cell>1.19</cell><cell>1.17</cell><cell>1.32</cell><cell>1.31</cell></row><row><cell></cell><cell>p value</cell><cell>1.96E-04 *</cell><cell>1.96E-04 *</cell><cell>1.96E-04 *</cell><cell>1.96E-04 *</cell><cell>1.96E-04 *</cell><cell></cell></row><row><cell cols="2">Running Time</cell><cell>63.53</cell><cell>2.90</cell><cell>69.35</cell><cell>4.45</cell><cell>1646.35</cell><cell>Seg 0.49</cell><cell>Rec 1.01</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>TABLE II</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Metric\Method</cell><cell>Bicubic</cell><cell>Tikhonov</cell><cell>BM3D+Bicubic</cell><cell>ScSR</cell><cell>SBSDI</cell><cell>SSR</cell></row><row><cell></cell><cell>Mean</cell><cell>18.24</cell><cell>22.47</cell><cell>25.55</cell><cell>22.74</cell><cell>26.07</cell><cell>26.20</cell></row><row><cell>PSNR</cell><cell>Stand deviation</cell><cell>0.77</cell><cell>1.58</cell><cell>2.44</cell><cell>3.09</cell><cell>2.73</cell><cell>2.70</cell></row><row><cell></cell><cell>p value</cell><cell>5.14E-11 *</cell><cell>5.14E-11 *</cell><cell>5.14E-11 *</cell><cell>5.14E-11 *</cell><cell>2.08E-08 *</cell><cell></cell></row><row><cell></cell><cell>Mean</cell><cell>3.53</cell><cell>5.87</cell><cell>9.39</cell><cell>6.76</cell><cell>13.04</cell><cell>14.12</cell></row><row><cell>MSR</cell><cell>Stand deviation</cell><cell>0.37</cell><cell>0.70</cell><cell>1.83</cell><cell>0.92</cell><cell>3.18</cell><cell>3.73</cell></row><row><cell></cell><cell>p value</cell><cell>5.14E-11 *</cell><cell>5.14E-11 *</cell><cell>5.14E-11 *</cell><cell>5.14E-11 *</cell><cell>1.99E-07 *</cell><cell></cell></row><row><cell></cell><cell>Mean</cell><cell>1.62</cell><cell>3.49</cell><cell>4.58</cell><cell>3.21</cell><cell>5.44</cell><cell>5.83</cell></row><row><cell>CNR</cell><cell>Stand deviation</cell><cell>0.45</cell><cell>0.89</cell><cell>1.06</cell><cell>1.02</cell><cell>1.51</cell><cell>1.62</cell></row><row><cell></cell><cell>p value</cell><cell>5.14E-11 *</cell><cell>6.71E-11 *</cell><cell>5.14E-11 *</cell><cell>5.14E-11 *</cell><cell>1.44E-06 *</cell><cell></cell></row><row><cell></cell><cell>Running Time</cell><cell>0.01</cell><cell>2.24</cell><cell>2.34</cell><cell>96.29</cell><cell>4.61</cell><cell>Seg 0.43</cell><cell>Rec 0.53</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>TABLE III</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>MEAN</head><label></label><figDesc>AND STANDARD DEVIATION OF THE PSNR, MSR, CNR TOGETHER WITH RUNNING TIME (IN SECONDS) FOR 18 FOVEAL IMAGES (WITH 75% DATA MISSING) FROM 18 DIFFERENT SUBJECTS BY BICUBIC, TIKHONOV [61], BM3D [39]+BICUBIC, SCSR [51], SBSDI [4], AND SSR METHODS. "SEG" AND "REC" DENOTES THE REQUIRED RUNNING TIME FOR LAYER SEGMENTATION PART (R LAYERS SEGMENTATION) AND SPARSE RECONSTRUCTION PART (INCLUDING VITREOUS AND CHOROID/SCLERA REGIONS CLASSIFICATION), RESPECTIVELY. WHEN P&lt;0.05, THE METRICS (I.E. PSNR, MSR, CNR) FOR EACH TEST METHOD ARE CONSIDERED STATISTICALLY SIGNIFICANT AND WERE MARKED BY "*". BEST RESULTS IN THE MEAN VALUES ARE LABELED IN BOLD.</figDesc><table><row><cell></cell><cell>Metric\Method</cell><cell>Bicubic</cell><cell>Tikhonov</cell><cell>BM3D+Bicubic</cell><cell>ScSR</cell><cell>SBSDI</cell><cell>SSR</cell></row><row><cell></cell><cell>Mean</cell><cell>18.52</cell><cell>22.52</cell><cell>27.26</cell><cell>25.76</cell><cell>28.30</cell><cell>28.31</cell></row><row><cell>PSNR</cell><cell>Stand deviation</cell><cell>0.49</cell><cell>0.95</cell><cell>2.50</cell><cell>1.63</cell><cell>2.54</cell><cell>2.50</cell></row><row><cell></cell><cell>p value</cell><cell>1.96E-04 *</cell><cell>1.96E-04 *</cell><cell>1.96E-04 *</cell><cell>1.96E-04 *</cell><cell>0.31</cell><cell></cell></row><row><cell></cell><cell>Mean</cell><cell>3.63</cell><cell>5.35</cell><cell>10.72</cell><cell>9.00</cell><cell>14.53</cell><cell>15.26</cell></row><row><cell>MSR</cell><cell>Stand deviation</cell><cell>0.47</cell><cell>0.55</cell><cell>0.27</cell><cell>1.05</cell><cell>4.57</cell><cell>4.48</cell></row><row><cell></cell><cell>p value</cell><cell>1.96E-04 *</cell><cell>1.96E-04 *</cell><cell>1.96E-04 *</cell><cell>1.96E-04 *</cell><cell>0.01 *</cell><cell></cell></row><row><cell></cell><cell>Mean</cell><cell>1.68</cell><cell>2.53</cell><cell>4.62</cell><cell>3.82</cell><cell>5.89</cell><cell>6.25</cell></row><row><cell>CNR</cell><cell>Stand deviation</cell><cell>0.56</cell><cell>0.80</cell><cell>1.31</cell><cell>1.26</cell><cell>1.43</cell><cell>1.64</cell></row><row><cell></cell><cell>p value</cell><cell>1.96E-04 *</cell><cell>1.96E-04 *</cell><cell>1.96E-04 *</cell><cell>1.96E-04 *</cell><cell>1.96E-04 *</cell><cell></cell></row><row><cell></cell><cell>Running Time</cell><cell>0.01</cell><cell>1.48</cell><cell>1.14</cell><cell>48.88</cell><cell>2.32</cell><cell>Seg 0.51</cell><cell>Rec 0.31</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Datasets were downloaded at: http://people.duke.edu/~sf59/Fang_TMI_</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>2013.htm.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TMI.2016.2611503, IEEE Transactions on Medical Imaging</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank the A2A Ancillary SDOCT Study group, especially Dr. Cynthia A. Toth, for sharing their dataset of OCT images.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by grants from NIH R01 EY022691 and P30 EY005722, the National Natural Science Foundation for Distinguished Young Scholars of China under Grant No. 61325007, and the National Natural Science Foundation for Young Scientist of China under Grant No. 61501180.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Optical coherence tomography</title>
		<author>
			<persName><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Schuman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Stinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Hee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Flotte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gregory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Puliafito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Fujimoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">254</biblScope>
			<biblScope unit="issue">5035</biblScope>
			<biblScope unit="page" from="1178" to="1181" />
			<date type="published" when="1991-11">Nov. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">4D reconstruction of the beating embryonic heart from two orthogonal sets of parallel optical coherence tomography slice-sequences</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename><surname>Larina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Larin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Dickinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liebling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="578" to="588" />
			<date type="published" when="2013-03">Mar. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Automated 3-D retinal layer segmentation of macular optical coherence tomography images with serous pigment epithelial detachments</title>
		<author>
			<persName><forename type="first">F</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sonka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="441" to="452" />
			<date type="published" when="2015-02">Feb. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fast Acquisition and Reconstruction of Optical Coherence Tomography Images via Sparse Representation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mcnabb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Toth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Izatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Farsiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2034" to="2049" />
			<date type="published" when="2013-11">Nov. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Novel applications of super-resolution in medical imaging</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Toth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Izatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Farsiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Super-Resolution Imaging</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ed</forename></persName>
		</editor>
		<meeting><address><addrLine>ed Boca Raton</addrLine></address></meeting>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="383" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Three dimensional data-driven multi scale atomic tepresentation of optical coherence tomography</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kafieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rabbani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Selesnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1042" to="1062" />
			<date type="published" when="2015-05">May 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A tour of modern image filtering: New insights and methods, both practical and theoretical</title>
		<author>
			<persName><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Mag</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="106" to="128" />
			<date type="published" when="2013-01">Jan. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Comparison of PDE-based nonlinear diffusion approaches for image enhancement and denoising in optical coherence tomography</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Salinas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Fernández</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="761" to="771" />
			<date type="published" when="2007-06">Jun. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Speckle reduction in optical coherence tomography images using digital filtering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ozcan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bilenca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Bouma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Tearney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Opt. Soc. Am</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1901" to="1910" />
			<date type="published" when="2007-07">Jul. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">General Bayesian estimation for speckle noise reduction in optical coherence tomography retinal imagery</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bizheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Clausi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Opt. Exp</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="8338" to="8352" />
			<date type="published" when="2010-04">Apr. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multi-penalty conditional random field approach to super-resolved reconstruction of optical coherence tomography images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Boroomand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bizheva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomed. Opt. Exp</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2032" to="2050" />
			<date type="published" when="2013-04">Apr. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Compressive SD-OCT: the application of compressed sensing in spectral domain optical coherence tomography</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">U</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Opt. Exp</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page" from="22010" to="22019" />
			<date type="published" when="2010-10">Oct. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Modified compressive sensing optical coherence tomography with noise reduction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">U</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Opt. Lett</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="4209" to="4211" />
			<date type="published" when="2012-08">Aug. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Real-time compressive sensing spectral domain optical coherence tomography</title>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">U</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Opt. lett</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="76" to="79" />
			<date type="published" when="2014-01">Jan. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Rapid volumetric OCT image acquisition using compressive sampling</title>
		<author>
			<persName><forename type="first">E</forename><surname>Lebed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Mackenzie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Sarunic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Beg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Opt. Exp</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="21003" to="21012" />
			<date type="published" when="2010-08">Aug. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Quantitative evaluation of transform domains for compressive sampling-based recovery of sparsely sampled volumetric OCT images</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lebed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Sarunic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Beg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="470" to="478" />
			<date type="published" when="2013-02">Feb. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Automated mosaicing of feature-poor optical coherence tomography volumes with an integrated white light imaging system</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Lurie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Angst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Ellerbee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2141" to="2153" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Wavelet-domain medical image denoising using bivariate laplacian mixture model</title>
		<author>
			<persName><forename type="first">H</forename><surname>Rabbani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nezafat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gazor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">2826</biblScope>
			<date type="published" when="2009-12">Dec. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Denoising during optical coherence tomography of the prostate nerves via wavelet shrinkage using dual-tree complex wavelet transform</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chitchian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Fiddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Fried</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Opt</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14031" to="014031" />
			<date type="published" when="2009-01">Jan. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Three-dimensional speckle suppression in optical coherence tomography based on the curvelet transform</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Jian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Tromberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Opt. Exp</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1024" to="1032" />
			<date type="published" when="2010-01">Jan. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dictionaries for sparse representation modeling</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Bruckstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="2010-06">Jun. 2010</date>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="1045" to="1057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Emergence of simple-cell receptive field properties by learning a sparse code for natural images</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Olshausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Field</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">381</biblScope>
			<biblScope unit="issue">6583</biblScope>
			<biblScope unit="page" from="607" to="609" />
			<date type="published" when="1996-06">Jun. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An efficient dictionary learning algorithm and its application to 3-D medical image denoising</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="417" to="427" />
			<date type="published" when="2012-02">Feb. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sparsity based denoising of spectral domain optical coherence tomography images</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Izatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Toth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Farsiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomed. Opt. Express</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="927" to="942" />
			<date type="published" when="2012-05">May 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sparse reconstruction of breast mri using homotopic minimization in a regional sparsified domain</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fieguth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Clausi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="743" to="752" />
			<date type="published" when="2013-03">Mar. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Group-sparse representation with dictionary learning for medical image denoising and fusion</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3450" to="3459" />
			<date type="published" when="2012-12">Dec. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Hierarchical patch-based sparse representation-A new approach for resolution enhancement of 4D-CT lung data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1993" to="2005" />
			<date type="published" when="2012-11">Nov. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Low-dose X-ray CT reconstruction via dictionary learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1682" to="1697" />
			<date type="published" when="2012-09">Sep. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Spectral-spatial hyperspectral image classification via multiscale adaptive sparse representation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="7738" to="7749" />
			<date type="published" when="2014-12">Dec. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Spectral-spatial classification of hyperspectral images with a superpixel-based discriminative sparse model</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="4186" to="4201" />
			<date type="published" when="2015-02">Feb. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The K-SVD: An algorithm for designing of overcomplete dictionaries for sparse representation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Bruckstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4311" to="4322" />
			<date type="published" when="2006-11">Nov. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">3-D Adaptive Sparsity Based Image Compression with Applications to Optical Coherence Tomography</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Izatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Farsiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1306" to="1320" />
			<date type="published" when="2015-06">Jun. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Sparse and low rank decomposition based batch image alignment for speckle reduction of retinal OCT images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Baghaie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Biomed. Imag</title>
		<meeting>IEEE Int. Symp. Biomed. Imag</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1141" to="1147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Enhanced low-rank+ sparsity decomposition for speckle reduction in optical coherence tomography</title>
		<author>
			<persName><forename type="first">I</forename><surname>Kopriva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. biomed. optics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="76008" to="076008" />
			<date type="published" when="2016-07">Jul. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Automatic segmentation of seven retinal layers in SDOCT images congruent with expert manual segmentation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nicholas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Toth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Izatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Farsiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Opt. Express</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="19413" to="19428" />
			<date type="published" when="2010-08">Aug. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Quantitative analysis of retinal layer optical intensities on threedimensional optical coherence tomography</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sonka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Invest. Ophthalmol. Vis. Sci</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="6846" to="6851" />
			<date type="published" when="2013-10">Oct. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Length-adaptive graph search for automatic segmentation of pathological features in optical coherence tomography images</title>
		<author>
			<persName><forename type="first">B</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cunefare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Mahmoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Izatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Farsiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Optics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="76015" to="076015" />
			<date type="published" when="2016-07">Jul. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Homotopic, non-local sparse reconstruction of optical coherence tomography imagery</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bizheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fieguth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Opt. Exp</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="10200" to="10211" />
			<date type="published" when="2012-05">May 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Image denoising by sparse 3-D transform-domain collaborative filtering</title>
		<author>
			<persName><forename type="first">K</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2080" to="2095" />
			<date type="published" when="2007-08">Aug. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Non-local sparse models for image restoration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="2272" to="2279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">An accurate multimodal 3-D vessel segmentation method based on brightness variations on OCT layers and curvelet domain fundus image analysis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kafieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rabbani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hajizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ommani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2815" to="2823" />
			<date type="published" when="2013-10">Oct. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Dry age-related macular degeneration: mechanisms, therapeutic targets, and imaging</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bowes Rickman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Farsiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Toth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Klingeborn</surname></persName>
		</author>
		<idno>ORSF68-ORSF80</idno>
	</analytic>
	<monogr>
		<title level="j">Invest. Ophthalmol. Vis. Sci</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">14</biblScope>
			<date type="published" when="2013-12">Dec. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Progression of intermediate age-related macular degeneration with proliferation and inner retinal migration of hyperreflective Foci</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Christenbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Folgar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V</forename><surname>O'connell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Farsiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Toth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ophthalmol</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1038" to="1045" />
			<date type="published" when="2013-05">May 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Segmentation-based document image denoising</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hedjam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cheriet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Euro. Workshop Vis</title>
		<meeting>Euro. Workshop Vis</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="61" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Segmentation based denoising of PET images: an iterative approach via regional means and affinity propagation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Baqci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Thomasson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Solomon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Mollura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Conf. Med. Image Comput. Comput. Assist. Interv</title>
		<imprint>
			<biblScope unit="page" from="698" to="705" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Signal dependent noise removal from a single image</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Okutomi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>IEEE Int. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2679" to="2683" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Image denoising via sparse and redundant representations over learned dictionaries</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3736" to="3745" />
			<date type="published" when="2006-12">Dec. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Online dictionary learning for sparse coding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Vis</title>
		<meeting>Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="689" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Adaptive greedy approximations</title>
		<author>
			<persName><forename type="first">G</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Avellaneda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Construct. Approx</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="57" to="98" />
			<date type="published" when="1997-03">Mar. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Matching pursuits with time-frequency dictionaries</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Mallat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3397" to="3415" />
			<date type="published" when="1993-12">Dec. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Image super-resolution via sparse representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2861" to="2873" />
			<date type="published" when="2010-11">Nov. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A review of image denoising algorithms, with a new one</title>
		<author>
			<persName><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multiscale Model. Simul</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="490" to="530" />
			<date type="published" when="2005-02">Feb. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Generalizing the nonlocal-means to super-resolution reconstruction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Protter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Takeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="36" to="51" />
			<date type="published" when="2009-01">Jan. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Volterrafaces: Discriminant analysis using volterra kernels</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Vemuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="150" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<title level="m">The Elements of Statistical Learning</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Algorithms for simultaneous sparse approximation. Part I: Greedy pursuit</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Tropp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Strauss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="572" to="588" />
			<date type="published" when="2006-03">Mar. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Quantitative Classification of Eyes with and without Intermediate Age-related Macular Degeneration Using Optical Coherence Tomography</title>
		<author>
			<persName><forename type="first">S</forename><surname>Farsiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V</forename><surname>O'connell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Folgar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Izatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Toth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ophthalmology</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="162" to="172" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A pyramid approach to subpixel registration based on intensity</title>
		<author>
			<persName><forename type="first">P</forename><surname>Thévenaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">E</forename><surname>Ruttimann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Unser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="41" />
			<date type="published" when="1998-01">Jan. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">What makes a good model of natural images?</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Patch Group Based Nonlocal Self-Similarity Prior Learning for Image Denoising</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Abnormal foveal morphology in ocular albinism imaged with spectral-domain optical coherence tomography</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Farsiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Freedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sarin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Koreishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Izatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Toth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Arch. Ophthalmol</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="44" />
			<date type="published" when="2009-01">Jan. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Frequency decomposition and compounding of ultrasound medical images with wavelets packets</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cincotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Loi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pappalardo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="764" to="771" />
			<date type="published" when="2001-08">Aug. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Noise reduction for magnetic resonance images via adaptive multiscale products thresholding</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1089" to="1099" />
			<date type="published" when="2003-09">Sep. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chakraborti</surname></persName>
		</author>
		<title level="m">Nonparametric Statistical Inference</title>
		<meeting><address><addrLine>Raton, FL</addrLine></address></meeting>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">168</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">SLIC superpixels compared to state-of-the-art superpixel methods</title>
		<author>
			<persName><forename type="first">R</forename><surname>Achanta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Susstrunk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2274" to="2281" />
			<date type="published" when="2012-11">Nov. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Kernel regression based segmentation of optical coherence tomography images with diabetic macular edema</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Allingham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Mettu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Cousins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Izatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Farsiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomed. Opt. Exp</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1172" to="1194" />
			<date type="published" when="2015-04">Apr. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Automated segmentation by pixel classification of retinal layers in ophthalmic OCT images</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Vermeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Der Schoot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Lemij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>De Boer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomed. Opt. Exp</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1743" to="1756" />
			<date type="published" when="2011-06">Jun. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Fully automatic segmentation of fluorescein leakage in subjects with diabetic macular edema automatic leakage segmentation in DME</title>
		<author>
			<persName><forename type="first">H</forename><surname>Rabbani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Allingham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Mettu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Cousins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Farsiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Invest. Ophthalmol. Vis. Sci</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1482" to="1492" />
			<date type="published" when="2015-02">Feb. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Adaptation of a support vector machine algorithm for segmentation and visualization of retinal structures in volumetric optical coherence tomography data sets</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Zawadzki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Fuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Wiley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hamann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Werner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Biomed Opt</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">41206</biblScope>
			<date type="published" when="2007-07">Jul. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Three-dimensional segmentation of fluid-associated abnormalities in retinal OCT: probability constrained graph-search-graph-cut</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Niemeijer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Abràmoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sonka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1521" to="1531" />
			<date type="published" when="2012-03">Mar. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Automated 3-D intraretinal layer segmentation of macular spectral-domain optical coherence tomography images</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Garvin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Abràmoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sonka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1436" to="1447" />
			<date type="published" when="2009-09">Sep. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
